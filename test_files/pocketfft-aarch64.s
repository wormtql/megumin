	.text
	.file	"pocketfft_demo.cc"
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function main
.LCPI0_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
	.text
	.globl	main
	.p2align	2
	.type	main,@function
main:                                   // @main
.Lfunc_begin0:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception0
// %bb.0:
	sub	sp, sp, #400
	str	d8, [sp, #288]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #304]            // 16-byte Folded Spill
	add	x29, sp, #304
	stp	x28, x27, [sp, #320]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #336]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #352]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #368]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #384]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	fmov	v0.2d, #-0.50000000
	adrp	x8, .LCPI0_0
	mov	x22, #-7
	mov	w26, #1
	movk	x22, #32767, lsl #48
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI0_0]
	str	q0, [sp]                        // 16-byte Folded Spill
	b	.LBB0_2
.LBB0_1:                                //   in Loop: Header=BB0_2 Depth=1
	add	x26, x26, #1
	cmp	x26, #2, lsl #12                // =8192
	b.eq	.LBB0_108
.LBB0_2:                                // =>This Loop Header: Depth=1
                                        //     Child Loop BB0_18 Depth 2
                                        //     Child Loop BB0_24 Depth 2
                                        //     Child Loop BB0_27 Depth 2
                                        //     Child Loop BB0_37 Depth 2
                                        //     Child Loop BB0_40 Depth 2
                                        //     Child Loop BB0_45 Depth 2
	stp	xzr, xzr, [x29, #-48]
	stur	xzr, [x29, #-32]
.Ltmp0:
	mov	w0, #8
	bl	_Znwm
.Ltmp1:
// %bb.3:                               //   in Loop: Header=BB0_2 Depth=1
	stp	xzr, x0, [x29, #-56]
	str	x26, [x0], #8
	stp	x0, x0, [x29, #-40]
	stp	xzr, xzr, [x29, #-72]
.Ltmp3:
	mov	w0, #8
	bl	_Znwm
.Ltmp4:
// %bb.4:                               //   in Loop: Header=BB0_2 Depth=1
	ldp	x9, x8, [x29, #-48]
	stur	x0, [x29, #-72]
	str	xzr, [x0], #8
	stp	x0, x0, [x29, #-64]
	sub	x20, x8, x9
	cmp	x20, x22
	b.hs	.LBB0_117
// %bb.5:                               //   in Loop: Header=BB0_2 Depth=1
	stp	xzr, xzr, [x29, #-96]
	stur	xzr, [x29, #-80]
	cbz	x20, .LBB0_9
// %bb.6:                               //   in Loop: Header=BB0_2 Depth=1
.Ltmp6:
	mov	x0, x20
	bl	_Znwm
.Ltmp7:
// %bb.7:                               //   in Loop: Header=BB0_2 Depth=1
	asr	x8, x20, #3
	subs	x2, x20, #8
	stur	x0, [x29, #-96]
	add	x19, x0, x8, lsl #3
	str	xzr, [x0], #8
	stur	x19, [x29, #-80]
	b.eq	.LBB0_10
// %bb.8:                               //   in Loop: Header=BB0_2 Depth=1
	mov	w1, wzr
	bl	memset
	mov	x0, x19
	b	.LBB0_10
.LBB0_9:                                //   in Loop: Header=BB0_2 Depth=1
	mov	x0, xzr
	stp	xzr, xzr, [x29, #-96]
	stur	xzr, [x29, #-80]
.LBB0_10:                               //   in Loop: Header=BB0_2 Depth=1
	ldp	x9, x8, [x29, #-48]
	stur	x0, [x29, #-88]
	sub	x21, x8, x9
	cmp	x21, x22
	b.hs	.LBB0_119
// %bb.11:                              //   in Loop: Header=BB0_2 Depth=1
	stp	xzr, xzr, [x29, #-120]
	stur	xzr, [x29, #-104]
	cbz	x21, .LBB0_16
// %bb.12:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp9:
	mov	x0, x21
	bl	_Znwm
.Ltmp10:
// %bb.13:                              //   in Loop: Header=BB0_2 Depth=1
	asr	x8, x21, #3
	mov	x20, x0
	subs	x2, x21, #8
	stur	x0, [x29, #-120]
	add	x19, x0, x8, lsl #3
	str	xzr, [x0], #8
	stur	x19, [x29, #-104]
	b.eq	.LBB0_15
// %bb.14:                              //   in Loop: Header=BB0_2 Depth=1
	mov	w1, wzr
	bl	memset
	mov	x0, x19
.LBB0_15:                               //   in Loop: Header=BB0_2 Depth=1
	ldp	x8, x9, [x29, #-48]
	stur	x0, [x29, #-112]
	sub	x10, x9, x8
	asr	x9, x10, #3
	subs	w11, w9, #1
	b.pl	.LBB0_17
	b	.LBB0_19
.LBB0_16:                               //   in Loop: Header=BB0_2 Depth=1
	mov	x20, xzr
	mov	x0, xzr
	stp	xzr, xzr, [x29, #-120]
	stp	x0, xzr, [x29, #-112]
	ldp	x8, x9, [x29, #-48]
	sub	x10, x9, x8
	asr	x9, x10, #3
	subs	w11, w9, #1
	b.mi	.LBB0_19
.LBB0_17:                               //   in Loop: Header=BB0_2 Depth=1
	ldur	x14, [x29, #-72]
	lsl	x16, x11, #3
	ldur	x15, [x29, #-96]
	mov	w11, w9
	add	x12, x8, x16
	add	x13, x20, x16
	add	x14, x14, x16
	mov	w17, #16
	add	x15, x15, x16
	mov	w16, #32
	mov	w18, #8
.LBB0_18:                               //   Parent Loop BB0_2 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	str	x18, [x14], #-8
	ldr	x0, [x12]
	sub	w11, w11, #1
	str	x17, [x15], #-8
	ldr	x1, [x12]
	cmp	w11, #0
	str	x16, [x13], #-8
	ldr	x2, [x12], #-8
	mul	x18, x0, x18
	mul	x17, x1, x17
	mul	x16, x2, x16
	b.gt	.LBB0_18
.LBB0_19:                               //   in Loop: Header=BB0_2 Depth=1
	str	x26, [sp, #24]                  // 8-byte Folded Spill
	cbz	x10, .LBB0_22
// %bb.20:                              //   in Loop: Header=BB0_2 Depth=1
	cmp	x9, #1
	csinc	x9, x9, xzr, hi
	cmp	x9, #2
	b.hs	.LBB0_23
// %bb.21:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x10, xzr
	mov	w25, #1
	b	.LBB0_26
.LBB0_22:                               //   in Loop: Header=BB0_2 Depth=1
	mov	w25, #1
	b	.LBB0_30
.LBB0_23:                               //   in Loop: Header=BB0_2 Depth=1
	and	x10, x9, #0xfffffffffffffffe
	add	x11, x8, #8
	mov	x12, x10
	mov	w13, #1
	mov	w14, #1
.LBB0_24:                               //   Parent Loop BB0_2 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	x15, x16, [x11, #-8]
	add	x11, x11, #16
	subs	x12, x12, #2
	mul	x13, x15, x13
	mul	x14, x16, x14
	b.ne	.LBB0_24
// %bb.25:                              //   in Loop: Header=BB0_2 Depth=1
	mul	x25, x14, x13
	cmp	x9, x10
	b.eq	.LBB0_28
.LBB0_26:                               //   in Loop: Header=BB0_2 Depth=1
	sub	x9, x9, x10
	add	x8, x8, x10, lsl #3
.LBB0_27:                               //   Parent Loop BB0_2 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x10, [x8], #8
	subs	x9, x9, #1
	mul	x25, x10, x25
	b.ne	.LBB0_27
.LBB0_28:                               //   in Loop: Header=BB0_2 Depth=1
	lsr	x8, x25, #60
	cbnz	x8, .LBB0_127
// %bb.29:                              //   in Loop: Header=BB0_2 Depth=1
	cbz	x25, .LBB0_42
.LBB0_30:                               //   in Loop: Header=BB0_2 Depth=1
	lsl	x22, x25, #3
.Ltmp15:
	mov	x0, x22
	bl	_Znwm
.Ltmp16:
// %bb.31:                              //   in Loop: Header=BB0_2 Depth=1
	mov	w1, wzr
	mov	x2, x22
	mov	x21, x0
	bl	memset
	lsr	x8, x25, #59
	cbnz	x8, .LBB0_125
// %bb.32:                              //   in Loop: Header=BB0_2 Depth=1
	lsl	x20, x25, #4
.Ltmp18:
	mov	x0, x20
	bl	_Znwm
.Ltmp19:
// %bb.33:                              //   in Loop: Header=BB0_2 Depth=1
	mov	w1, wzr
	mov	x2, x20
	mov	x24, x0
	bl	memset
	lsr	x8, x25, #58
	cbnz	x8, .LBB0_123
// %bb.34:                              //   in Loop: Header=BB0_2 Depth=1
	lsl	x23, x25, #5
.Ltmp21:
	mov	x0, x23
	bl	_Znwm
.Ltmp22:
// %bb.35:                              //   in Loop: Header=BB0_2 Depth=1
	mov	w1, wzr
	mov	x2, x23
	add	x19, x21, x25, lsl #3
	stur	x0, [x29, #-8]                  // 8-byte Folded Spill
	bl	memset
	cmp	x19, x21
	cset	w20, eq
	str	w20, [sp, #36]                  // 4-byte Folded Spill
	b.eq	.LBB0_38
// %bb.36:                              //   in Loop: Header=BB0_2 Depth=1
	str	x19, [sp, #48]                  // 8-byte Folded Spill
	mov	x19, x21
.LBB0_37:                               //   Parent Loop BB0_2 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	bl	drand48
	str	q0, [sp, #96]                   // 16-byte Folded Spill
	bl	drand48
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
                                        // kill: def $d0 killed $d0 def $q0
	subs	x22, x22, #8
	mov	v1.d[1], v0.d[0]
	ldr	q0, [sp, #80]                   // 16-byte Folded Reload
	fadd	v0.2d, v1.2d, v0.2d
	fcvtn	v0.2s, v0.2d
	str	d0, [x19], #8
	b.ne	.LBB0_37
	b	.LBB0_39
.LBB0_38:                               //   in Loop: Header=BB0_2 Depth=1
	str	x21, [sp, #48]                  // 8-byte Folded Spill
.LBB0_39:                               //   in Loop: Header=BB0_2 Depth=1
	add	x8, x24, x25, lsl #4
	add	x22, x21, #4
	add	x23, x24, #8
	str	x8, [sp, #72]                   // 8-byte Folded Spill
	ldur	x8, [x29, #-8]                  // 8-byte Folded Reload
	add	x19, x8, x25, lsl #5
	add	x26, x8, #16
.LBB0_40:                               //   Parent Loop BB0_2 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	s0, s8, [x22, #-4]
	fcvt	d1, s0
	fcvt	d2, s8
	stp	d1, d2, [x23, #-8]
	bl	__extendsftf2
	str	q0, [sp, #96]                   // 16-byte Folded Spill
	fmov	s0, s8
	bl	__extendsftf2
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	subs	x25, x25, #1
	add	x22, x22, #8
	add	x23, x23, #16
	stp	q1, q0, [x26, #-16]
	add	x26, x26, #32
	b.ne	.LBB0_40
// %bb.41:                              //   in Loop: Header=BB0_2 Depth=1
	ldur	x8, [x29, #-8]                  // 8-byte Folded Reload
	mov	x23, x19
	stp	x24, x21, [sp, #56]             // 16-byte Folded Spill
	str	x8, [sp, #96]                   // 8-byte Folded Spill
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	str	x8, [sp, #40]                   // 8-byte Folded Spill
	ldp	x9, x8, [x29, #-48]
	stp	xzr, xzr, [x29, #-144]
	stur	xzr, [x29, #-128]
	cmp	x8, x9
	b.ne	.LBB0_43
	b	.LBB0_55
.LBB0_42:                               //   in Loop: Header=BB0_2 Depth=1
	mov	x23, xzr
	mov	x24, xzr
	mov	x21, xzr
	mov	x19, xzr
	mov	w8, #1
	stur	xzr, [x29, #-8]                 // 8-byte Folded Spill
	str	xzr, [sp, #96]                  // 8-byte Folded Spill
	stp	xzr, xzr, [sp, #56]             // 16-byte Folded Spill
	stp	xzr, xzr, [sp, #40]             // 16-byte Folded Spill
	str	xzr, [sp, #72]                  // 8-byte Folded Spill
	str	w8, [sp, #36]                   // 4-byte Folded Spill
	ldp	x9, x8, [x29, #-48]
	stp	xzr, xzr, [x29, #-144]
	stur	xzr, [x29, #-128]
	cmp	x8, x9
	b.eq	.LBB0_55
.LBB0_43:                               //   in Loop: Header=BB0_2 Depth=1
	mov	x26, xzr
	mov	x11, xzr
	mov	x10, xzr
	mov	x25, xzr
	b	.LBB0_45
.LBB0_44:                               //   in Loop: Header=BB0_45 Depth=2
	str	x25, [x10], #8
	stur	x10, [x29, #-136]
	sub	x12, x8, x9
	add	x25, x25, #1
	cmp	x25, x12, asr #3
	b.hs	.LBB0_55
.LBB0_45:                               //   Parent Loop BB0_2 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	x10, x11
	b.ne	.LBB0_44
// %bb.46:                              //   in Loop: Header=BB0_45 Depth=2
	sub	x28, x11, x26
	mov	x8, #9223372036854775800
	cmp	x28, x8
	b.eq	.LBB0_115
// %bb.47:                              //   in Loop: Header=BB0_45 Depth=2
	asr	x20, x28, #3
	cmp	x28, #0
	csinc	x8, x20, xzr, ne
	adds	x8, x8, x20
	lsr	x9, x8, #60
	cset	w10, hs
	cmp	x9, #0
	cset	w9, ne
	orr	w9, w10, w9
	cmp	w9, #0
	mov	x9, #1152921504606846975
	csel	x22, x9, x8, ne
	cbz	x22, .LBB0_54
// %bb.48:                              //   in Loop: Header=BB0_45 Depth=2
	lsl	x0, x22, #3
.Ltmp24:
	bl	_Znwm
.Ltmp25:
// %bb.49:                              //   in Loop: Header=BB0_45 Depth=2
	mov	x27, x0
	add	x20, x27, x20, lsl #3
	cmp	x28, #1
	str	x25, [x20]
	b.lt	.LBB0_51
.LBB0_50:                               //   in Loop: Header=BB0_45 Depth=2
	mov	x0, x27
	mov	x1, x26
	mov	x2, x28
	bl	memmove
.LBB0_51:                               //   in Loop: Header=BB0_45 Depth=2
	cbz	x26, .LBB0_53
// %bb.52:                              //   in Loop: Header=BB0_45 Depth=2
	mov	x0, x26
	bl	_ZdlPv
.LBB0_53:                               //   in Loop: Header=BB0_45 Depth=2
	ldp	x9, x8, [x29, #-48]
	add	x10, x20, #8
	add	x11, x27, x22, lsl #3
	mov	x26, x27
	stp	x27, x10, [x29, #-144]
	stur	x11, [x29, #-128]
	sub	x12, x8, x9
	add	x25, x25, #1
	cmp	x25, x12, asr #3
	b.lo	.LBB0_45
	b	.LBB0_55
.LBB0_54:                               //   in Loop: Header=BB0_45 Depth=2
	mov	x27, xzr
	add	x20, x27, x20, lsl #3
	cmp	x28, #1
	str	x25, [x20]
	b.ge	.LBB0_50
	b	.LBB0_51
.LBB0_55:                               //   in Loop: Header=BB0_2 Depth=1
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	stp	xzr, xzr, [sp, #136]
	str	xzr, [sp, #152]
	subs	x26, x23, x8
	b.eq	.LBB0_59
// %bb.56:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x8, #-31
	movk	x8, #32767, lsl #48
	cmp	x26, x8
	b.hs	.LBB0_109
// %bb.57:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp30:
	mov	x0, x26
	bl	_Znwm
.Ltmp31:
	mov	x22, #-7
	movk	x22, #32767, lsl #48
// %bb.58:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x27, x0
	b	.LBB0_60
.LBB0_59:                               //   in Loop: Header=BB0_2 Depth=1
	mov	x22, #-7
	mov	x27, xzr
	movk	x22, #32767, lsl #48
.LBB0_60:                               //   in Loop: Header=BB0_2 Depth=1
	asr	x8, x26, #5
	ldr	x9, [sp, #96]                   // 8-byte Folded Reload
	ldur	x20, [x29, #-8]                 // 8-byte Folded Reload
	stp	x27, x27, [sp, #136]
	ldr	x25, [sp, #56]                  // 8-byte Folded Reload
	add	x8, x27, x8, lsl #5
	cmp	x9, x19
	str	x8, [sp, #152]
	b.eq	.LBB0_62
// %bb.61:                              //   in Loop: Header=BB0_2 Depth=1
	and	x2, x26, #0xffffffffffffffe0
	mov	x0, x27
	mov	x1, x20
	sub	x8, x26, #32
	and	x19, x8, #0xffffffffffffffe0
	bl	memcpy
	add	x8, x27, x19
	add	x27, x8, #32
.LBB0_62:                               //   in Loop: Header=BB0_2 Depth=1
	ldp	x8, x19, [sp, #40]              // 16-byte Folded Reload
	str	x27, [sp, #144]
	ldr	x23, [sp, #64]                  // 8-byte Folded Reload
	subs	x28, x8, x25
	b.eq	.LBB0_80
// %bb.63:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x8, #-15
	movk	x8, #32767, lsl #48
	cmp	x28, x8
	b.hs	.LBB0_111
// %bb.64:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp36:
	mov	x0, x28
	bl	_Znwm
.Ltmp37:
// %bb.65:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x26, x0
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	cmp	x25, x8
	b.eq	.LBB0_67
.LBB0_66:                               //   in Loop: Header=BB0_2 Depth=1
	and	x2, x28, #0xfffffffffffffff0
	mov	x0, x26
	mov	x1, x24
	bl	memcpy
.LBB0_67:                               //   in Loop: Header=BB0_2 Depth=1
	subs	x27, x19, x23
	stp	xzr, xzr, [sp, #112]
	str	xzr, [sp, #128]
	b.eq	.LBB0_81
// %bb.68:                              //   in Loop: Header=BB0_2 Depth=1
	cmp	x27, x22
	b.hs	.LBB0_113
// %bb.69:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp42:
	mov	x0, x27
	bl	_Znwm
.Ltmp43:
// %bb.70:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x28, x0
	asr	x8, x27, #3
	stp	x28, x28, [sp, #112]
	add	x8, x28, x8, lsl #3
	str	x8, [sp, #128]
	ldr	w8, [sp, #36]                   // 4-byte Folded Reload
	tbnz	w8, #0, .LBB0_72
.LBB0_71:                               //   in Loop: Header=BB0_2 Depth=1
	and	x2, x27, #0xfffffffffffffff8
	mov	x0, x28
	mov	x1, x21
	sub	x8, x27, #8
	and	x19, x8, #0xfffffffffffffff8
	bl	memcpy
	add	x8, x28, x19
	add	x28, x8, #8
.LBB0_72:                               //   in Loop: Header=BB0_2 Depth=1
	ldr	x6, [sp, #136]
	str	x28, [sp, #120]
.Ltmp48:
	sub	x0, x29, #48
	sub	x1, x29, #120
	sub	x2, x29, #120
	sub	x3, x29, #144
	mov	w4, #1
	ldr	x5, [sp, #96]                   // 8-byte Folded Reload
	ldr	q0, [sp]                        // 16-byte Folded Reload
	mov	w7, #1
	bl	_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
.Ltmp49:
// %bb.73:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp50:
	sub	x0, x29, #48
	sub	x1, x29, #96
	sub	x2, x29, #96
	sub	x3, x29, #144
	fmov	d0, #1.00000000
	mov	w4, #1
	mov	x5, x25
	mov	x6, x26
	mov	w7, #1
	bl	_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
.Ltmp51:
// %bb.74:                              //   in Loop: Header=BB0_2 Depth=1
	ldr	x6, [sp, #112]
.Ltmp52:
	sub	x0, x29, #48
	sub	x1, x29, #72
	sub	x2, x29, #72
	sub	x3, x29, #144
	fmov	s0, #1.00000000
	mov	w4, #1
	mov	x5, x23
	mov	w7, #1
	bl	_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
.Ltmp53:
// %bb.75:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp54:
	add	x0, sp, #136
	add	x1, sp, #112
	bl	_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE
.Ltmp55:
// %bb.76:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp56:
	adrp	x0, :got:_ZSt4cout
	ldr	x0, [x0, :got_lo12:_ZSt4cout]
	bl	_ZNSo9_M_insertIeEERSoT_
.Ltmp57:
// %bb.77:                              //   in Loop: Header=BB0_2 Depth=1
	ldr	x8, [x0]
	mov	x27, x0
	ldur	x8, [x8, #-24]
	add	x8, x0, x8
	ldr	x28, [x8, #240]
	cbz	x28, .LBB0_121
// %bb.78:                              //   in Loop: Header=BB0_2 Depth=1
	ldrb	w8, [x28, #56]
	cbz	w8, .LBB0_82
// %bb.79:                              //   in Loop: Header=BB0_2 Depth=1
	ldrb	w1, [x28, #67]
	b	.LBB0_84
.LBB0_80:                               //   in Loop: Header=BB0_2 Depth=1
	mov	x26, xzr
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	cmp	x25, x8
	b.ne	.LBB0_66
	b	.LBB0_67
.LBB0_81:                               //   in Loop: Header=BB0_2 Depth=1
	mov	x28, xzr
	asr	x8, x27, #3
	stp	x28, x28, [sp, #112]
	add	x8, x28, x8, lsl #3
	str	x8, [sp, #128]
	ldr	w8, [sp, #36]                   // 4-byte Folded Reload
	tbz	w8, #0, .LBB0_71
	b	.LBB0_72
.LBB0_82:                               //   in Loop: Header=BB0_2 Depth=1
.Ltmp58:
	mov	x0, x28
	bl	_ZNKSt5ctypeIcE13_M_widen_initEv
.Ltmp59:
// %bb.83:                              //   in Loop: Header=BB0_2 Depth=1
	ldr	x8, [x28]
	ldr	x8, [x8, #48]
.Ltmp60:
	mov	x0, x28
	mov	w1, #10
	blr	x8
	mov	w1, w0
.Ltmp61:
.LBB0_84:                               //   in Loop: Header=BB0_2 Depth=1
.Ltmp62:
	mov	x0, x27
	bl	_ZNSo3putEc
.Ltmp63:
// %bb.85:                              //   in Loop: Header=BB0_2 Depth=1
.Ltmp64:
	bl	_ZNSo5flushEv
.Ltmp65:
// %bb.86:                              //   in Loop: Header=BB0_2 Depth=1
	ldr	x0, [sp, #112]
	cbz	x0, .LBB0_88
// %bb.87:                              //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
.LBB0_88:                               //   in Loop: Header=BB0_2 Depth=1
	cbz	x26, .LBB0_90
// %bb.89:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x0, x26
	bl	_ZdlPv
.LBB0_90:                               //   in Loop: Header=BB0_2 Depth=1
	ldr	x0, [sp, #136]
	cbz	x0, .LBB0_92
// %bb.91:                              //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
.LBB0_92:                               //   in Loop: Header=BB0_2 Depth=1
	ldur	x0, [x29, #-144]
	ldr	x26, [sp, #24]                  // 8-byte Folded Reload
	cbz	x0, .LBB0_94
// %bb.93:                              //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
.LBB0_94:                               //   in Loop: Header=BB0_2 Depth=1
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	cbz	x8, .LBB0_96
// %bb.95:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB0_96:                               //   in Loop: Header=BB0_2 Depth=1
	cbz	x25, .LBB0_98
// %bb.97:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x0, x24
	bl	_ZdlPv
.LBB0_98:                               //   in Loop: Header=BB0_2 Depth=1
	cbz	x23, .LBB0_100
// %bb.99:                              //   in Loop: Header=BB0_2 Depth=1
	mov	x0, x21
	bl	_ZdlPv
.LBB0_100:                              //   in Loop: Header=BB0_2 Depth=1
	ldur	x0, [x29, #-120]
	cbz	x0, .LBB0_102
// %bb.101:                             //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
.LBB0_102:                              //   in Loop: Header=BB0_2 Depth=1
	ldur	x0, [x29, #-96]
	cbz	x0, .LBB0_104
// %bb.103:                             //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
.LBB0_104:                              //   in Loop: Header=BB0_2 Depth=1
	ldur	x0, [x29, #-72]
	cbz	x0, .LBB0_106
// %bb.105:                             //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
.LBB0_106:                              //   in Loop: Header=BB0_2 Depth=1
	ldur	x0, [x29, #-48]
	cbz	x0, .LBB0_1
// %bb.107:                             //   in Loop: Header=BB0_2 Depth=1
	bl	_ZdlPv
	b	.LBB0_1
.LBB0_108:
	ldp	x20, x19, [sp, #384]            // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x22, x21, [sp, #368]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #352]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #336]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #320]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #304]            // 16-byte Folded Reload
	ldr	d8, [sp, #288]                  // 8-byte Folded Reload
	add	sp, sp, #400
	ret
.LBB0_109:
.Ltmp33:
	bl	_ZSt28__throw_bad_array_new_lengthv
.Ltmp34:
// %bb.110:
.LBB0_111:
.Ltmp39:
	bl	_ZSt28__throw_bad_array_new_lengthv
.Ltmp40:
// %bb.112:
.LBB0_113:
.Ltmp45:
	bl	_ZSt28__throw_bad_array_new_lengthv
.Ltmp46:
// %bb.114:
.LBB0_115:
.Ltmp27:
	adrp	x0, .L.str.2
	add	x0, x0, :lo12:.L.str.2
	bl	_ZSt20__throw_length_errorPKc
.Ltmp28:
// %bb.116:
.LBB0_117:
.Ltmp79:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.Ltmp80:
// %bb.118:
.LBB0_119:
.Ltmp76:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.Ltmp77:
// %bb.120:
.LBB0_121:
.Ltmp67:
	bl	_ZSt16__throw_bad_castv
.Ltmp68:
// %bb.122:
.LBB0_123:
.Ltmp70:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.Ltmp71:
// %bb.124:
.LBB0_125:
.Ltmp73:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.Ltmp74:
// %bb.126:
.LBB0_127:
.Ltmp12:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.Ltmp13:
// %bb.128:
.LBB0_129:
.Ltmp44:
	mov	x19, x0
	cbz	x26, .LBB0_152
	b	.LBB0_165
.LBB0_130:
.Ltmp38:
	mov	x19, x0
	ldr	x0, [sp, #136]
	cbz	x0, .LBB0_153
	b	.LBB0_167
.LBB0_131:
.Ltmp32:
	b	.LBB0_169
.LBB0_132:
.Ltmp8:
	mov	x19, x0
	ldur	x0, [x29, #-72]
	cbz	x0, .LBB0_160
	b	.LBB0_176
.LBB0_133:
.Ltmp11:
	mov	x19, x0
	ldur	x0, [x29, #-96]
	cbz	x0, .LBB0_159
	b	.LBB0_175
.LBB0_134:
.Ltmp14:
	mov	x19, x0
	ldur	x0, [x29, #-120]
	cbz	x0, .LBB0_158
	b	.LBB0_174
.LBB0_135:
.Ltmp23:
	b	.LBB0_141
.LBB0_136:
.Ltmp20:
	b	.LBB0_139
.LBB0_137:
.Ltmp17:
	mov	x19, x0
	ldur	x0, [x29, #-120]
	cbz	x0, .LBB0_158
	b	.LBB0_174
.LBB0_138:
.Ltmp75:
.LBB0_139:
	mov	x19, x0
	mov	x23, x21
	b	.LBB0_173
.LBB0_140:
.Ltmp72:
.LBB0_141:
	mov	x19, x0
	mov	x23, x21
	mov	x25, x24
	b	.LBB0_172
.LBB0_142:
.Ltmp69:
	ldp	x25, x23, [sp, #56]             // 16-byte Folded Reload
	mov	x19, x0
	ldur	x20, [x29, #-8]                 // 8-byte Folded Reload
	b	.LBB0_150
.LBB0_143:
.Ltmp2:
	ldur	x8, [x29, #-48]
	mov	x19, x0
	cbnz	x8, .LBB0_161
	b	.LBB0_162
.LBB0_144:
.Ltmp5:
	mov	x19, x0
	ldur	x8, [x29, #-48]
	cbnz	x8, .LBB0_161
	b	.LBB0_162
.LBB0_145:
.Ltmp78:
	mov	x19, x0
	ldur	x0, [x29, #-96]
	cbz	x0, .LBB0_159
	b	.LBB0_175
.LBB0_146:
.Ltmp81:
	mov	x19, x0
	ldur	x0, [x29, #-72]
	cbz	x0, .LBB0_160
	b	.LBB0_176
.LBB0_147:
.Ltmp26:
	b	.LBB0_169
.LBB0_148:
.Ltmp29:
	b	.LBB0_169
.LBB0_149:
.Ltmp66:
	mov	x19, x0
.LBB0_150:
	ldr	x0, [sp, #112]
	cbnz	x0, .LBB0_163
// %bb.151:
	cbnz	x26, .LBB0_165
.LBB0_152:
	ldr	x0, [sp, #136]
	cbnz	x0, .LBB0_167
.LBB0_153:
	ldur	x0, [x29, #-144]
	cbnz	x0, .LBB0_170
.LBB0_154:
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	cbnz	x8, .LBB0_171
.LBB0_155:
	cbnz	x25, .LBB0_172
.LBB0_156:
	cbnz	x23, .LBB0_173
.LBB0_157:
	ldur	x0, [x29, #-120]
	cbnz	x0, .LBB0_174
.LBB0_158:
	ldur	x0, [x29, #-96]
	cbnz	x0, .LBB0_175
.LBB0_159:
	ldur	x0, [x29, #-72]
	cbnz	x0, .LBB0_176
.LBB0_160:
	ldur	x8, [x29, #-48]
	cbz	x8, .LBB0_162
.LBB0_161:
	mov	x0, x8
	bl	_ZdlPv
.LBB0_162:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB0_163:
	bl	_ZdlPv
	cbz	x26, .LBB0_152
	b	.LBB0_165
.LBB0_164:
.Ltmp47:
	mov	x19, x0
	cbz	x26, .LBB0_152
.LBB0_165:
	mov	x0, x26
	bl	_ZdlPv
	ldr	x0, [sp, #136]
	cbz	x0, .LBB0_153
	b	.LBB0_167
.LBB0_166:
.Ltmp41:
	mov	x19, x0
	ldr	x0, [sp, #136]
	cbz	x0, .LBB0_153
.LBB0_167:
	bl	_ZdlPv
	ldur	x0, [x29, #-144]
	cbz	x0, .LBB0_154
	b	.LBB0_170
.LBB0_168:
.Ltmp35:
.LBB0_169:
	ldp	x25, x23, [sp, #56]             // 16-byte Folded Reload
	mov	x19, x0
	ldur	x20, [x29, #-8]                 // 8-byte Folded Reload
	ldur	x0, [x29, #-144]
	cbz	x0, .LBB0_154
.LBB0_170:
	bl	_ZdlPv
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	cbz	x8, .LBB0_155
.LBB0_171:
	mov	x0, x20
	bl	_ZdlPv
	cbz	x25, .LBB0_156
.LBB0_172:
	mov	x0, x25
	bl	_ZdlPv
	cbz	x23, .LBB0_157
.LBB0_173:
	mov	x0, x23
	bl	_ZdlPv
	ldur	x0, [x29, #-120]
	cbz	x0, .LBB0_158
.LBB0_174:
	bl	_ZdlPv
	ldur	x0, [x29, #-96]
	cbz	x0, .LBB0_159
.LBB0_175:
	bl	_ZdlPv
	ldur	x0, [x29, #-72]
	cbz	x0, .LBB0_160
.LBB0_176:
	bl	_ZdlPv
	ldur	x8, [x29, #-48]
	cbnz	x8, .LBB0_161
	b	.LBB0_162
.Lfunc_end0:
	.size	main, .Lfunc_end0-main
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table0:
.Lexception0:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end0-.Lcst_begin0
.Lcst_begin0:
	.uleb128 .Ltmp0-.Lfunc_begin0           // >> Call Site 1 <<
	.uleb128 .Ltmp1-.Ltmp0                  //   Call between .Ltmp0 and .Ltmp1
	.uleb128 .Ltmp2-.Lfunc_begin0           //     jumps to .Ltmp2
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp3-.Lfunc_begin0           // >> Call Site 2 <<
	.uleb128 .Ltmp4-.Ltmp3                  //   Call between .Ltmp3 and .Ltmp4
	.uleb128 .Ltmp5-.Lfunc_begin0           //     jumps to .Ltmp5
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp6-.Lfunc_begin0           // >> Call Site 3 <<
	.uleb128 .Ltmp7-.Ltmp6                  //   Call between .Ltmp6 and .Ltmp7
	.uleb128 .Ltmp8-.Lfunc_begin0           //     jumps to .Ltmp8
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp7-.Lfunc_begin0           // >> Call Site 4 <<
	.uleb128 .Ltmp9-.Ltmp7                  //   Call between .Ltmp7 and .Ltmp9
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp9-.Lfunc_begin0           // >> Call Site 5 <<
	.uleb128 .Ltmp10-.Ltmp9                 //   Call between .Ltmp9 and .Ltmp10
	.uleb128 .Ltmp11-.Lfunc_begin0          //     jumps to .Ltmp11
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp10-.Lfunc_begin0          // >> Call Site 6 <<
	.uleb128 .Ltmp15-.Ltmp10                //   Call between .Ltmp10 and .Ltmp15
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp15-.Lfunc_begin0          // >> Call Site 7 <<
	.uleb128 .Ltmp16-.Ltmp15                //   Call between .Ltmp15 and .Ltmp16
	.uleb128 .Ltmp17-.Lfunc_begin0          //     jumps to .Ltmp17
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp16-.Lfunc_begin0          // >> Call Site 8 <<
	.uleb128 .Ltmp18-.Ltmp16                //   Call between .Ltmp16 and .Ltmp18
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp18-.Lfunc_begin0          // >> Call Site 9 <<
	.uleb128 .Ltmp19-.Ltmp18                //   Call between .Ltmp18 and .Ltmp19
	.uleb128 .Ltmp20-.Lfunc_begin0          //     jumps to .Ltmp20
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp19-.Lfunc_begin0          // >> Call Site 10 <<
	.uleb128 .Ltmp21-.Ltmp19                //   Call between .Ltmp19 and .Ltmp21
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp21-.Lfunc_begin0          // >> Call Site 11 <<
	.uleb128 .Ltmp22-.Ltmp21                //   Call between .Ltmp21 and .Ltmp22
	.uleb128 .Ltmp23-.Lfunc_begin0          //     jumps to .Ltmp23
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp22-.Lfunc_begin0          // >> Call Site 12 <<
	.uleb128 .Ltmp24-.Ltmp22                //   Call between .Ltmp22 and .Ltmp24
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp24-.Lfunc_begin0          // >> Call Site 13 <<
	.uleb128 .Ltmp25-.Ltmp24                //   Call between .Ltmp24 and .Ltmp25
	.uleb128 .Ltmp26-.Lfunc_begin0          //     jumps to .Ltmp26
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp25-.Lfunc_begin0          // >> Call Site 14 <<
	.uleb128 .Ltmp30-.Ltmp25                //   Call between .Ltmp25 and .Ltmp30
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp30-.Lfunc_begin0          // >> Call Site 15 <<
	.uleb128 .Ltmp31-.Ltmp30                //   Call between .Ltmp30 and .Ltmp31
	.uleb128 .Ltmp32-.Lfunc_begin0          //     jumps to .Ltmp32
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp31-.Lfunc_begin0          // >> Call Site 16 <<
	.uleb128 .Ltmp36-.Ltmp31                //   Call between .Ltmp31 and .Ltmp36
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp36-.Lfunc_begin0          // >> Call Site 17 <<
	.uleb128 .Ltmp37-.Ltmp36                //   Call between .Ltmp36 and .Ltmp37
	.uleb128 .Ltmp38-.Lfunc_begin0          //     jumps to .Ltmp38
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp37-.Lfunc_begin0          // >> Call Site 18 <<
	.uleb128 .Ltmp42-.Ltmp37                //   Call between .Ltmp37 and .Ltmp42
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp42-.Lfunc_begin0          // >> Call Site 19 <<
	.uleb128 .Ltmp43-.Ltmp42                //   Call between .Ltmp42 and .Ltmp43
	.uleb128 .Ltmp44-.Lfunc_begin0          //     jumps to .Ltmp44
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp43-.Lfunc_begin0          // >> Call Site 20 <<
	.uleb128 .Ltmp48-.Ltmp43                //   Call between .Ltmp43 and .Ltmp48
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp48-.Lfunc_begin0          // >> Call Site 21 <<
	.uleb128 .Ltmp65-.Ltmp48                //   Call between .Ltmp48 and .Ltmp65
	.uleb128 .Ltmp66-.Lfunc_begin0          //     jumps to .Ltmp66
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp33-.Lfunc_begin0          // >> Call Site 22 <<
	.uleb128 .Ltmp34-.Ltmp33                //   Call between .Ltmp33 and .Ltmp34
	.uleb128 .Ltmp35-.Lfunc_begin0          //     jumps to .Ltmp35
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp39-.Lfunc_begin0          // >> Call Site 23 <<
	.uleb128 .Ltmp40-.Ltmp39                //   Call between .Ltmp39 and .Ltmp40
	.uleb128 .Ltmp41-.Lfunc_begin0          //     jumps to .Ltmp41
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp45-.Lfunc_begin0          // >> Call Site 24 <<
	.uleb128 .Ltmp46-.Ltmp45                //   Call between .Ltmp45 and .Ltmp46
	.uleb128 .Ltmp47-.Lfunc_begin0          //     jumps to .Ltmp47
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp27-.Lfunc_begin0          // >> Call Site 25 <<
	.uleb128 .Ltmp28-.Ltmp27                //   Call between .Ltmp27 and .Ltmp28
	.uleb128 .Ltmp29-.Lfunc_begin0          //     jumps to .Ltmp29
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp79-.Lfunc_begin0          // >> Call Site 26 <<
	.uleb128 .Ltmp80-.Ltmp79                //   Call between .Ltmp79 and .Ltmp80
	.uleb128 .Ltmp81-.Lfunc_begin0          //     jumps to .Ltmp81
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp76-.Lfunc_begin0          // >> Call Site 27 <<
	.uleb128 .Ltmp77-.Ltmp76                //   Call between .Ltmp76 and .Ltmp77
	.uleb128 .Ltmp78-.Lfunc_begin0          //     jumps to .Ltmp78
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp67-.Lfunc_begin0          // >> Call Site 28 <<
	.uleb128 .Ltmp68-.Ltmp67                //   Call between .Ltmp67 and .Ltmp68
	.uleb128 .Ltmp69-.Lfunc_begin0          //     jumps to .Ltmp69
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp70-.Lfunc_begin0          // >> Call Site 29 <<
	.uleb128 .Ltmp71-.Ltmp70                //   Call between .Ltmp70 and .Ltmp71
	.uleb128 .Ltmp72-.Lfunc_begin0          //     jumps to .Ltmp72
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp73-.Lfunc_begin0          // >> Call Site 30 <<
	.uleb128 .Ltmp74-.Ltmp73                //   Call between .Ltmp73 and .Ltmp74
	.uleb128 .Ltmp75-.Lfunc_begin0          //     jumps to .Ltmp75
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp12-.Lfunc_begin0          // >> Call Site 31 <<
	.uleb128 .Ltmp13-.Ltmp12                //   Call between .Ltmp12 and .Ltmp13
	.uleb128 .Ltmp14-.Lfunc_begin0          //     jumps to .Ltmp14
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp13-.Lfunc_begin0          // >> Call Site 32 <<
	.uleb128 .Lfunc_end0-.Ltmp13            //   Call between .Ltmp13 and .Lfunc_end0
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end0:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,"axG",@progbits,_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,comdat
	.weak	_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m // -- Begin function _ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
	.p2align	2
	.type	_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,@function
_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m: // @_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
.Lfunc_begin1:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception1
// %bb.0:
	sub	sp, sp, #224
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x26, x25, [sp, #160]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #176]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x13, x8, [x0]
	mov	x19, x7
	mov	x23, x0
	mov	x21, x6
	mov	x25, x5
	mov	w22, w4
	mov	x20, x3
	mov	x24, x2
	mov	x26, x1
	cmp	x13, x8
	b.eq	.LBB1_8
// %bb.1:
	sub	x9, x8, x13
	sub	x9, x9, #8
	cmp	x9, #8
	b.hs	.LBB1_3
// %bb.2:
	mov	w12, #1
	mov	x9, x13
	b	.LBB1_6
.LBB1_3:
	lsr	x9, x9, #3
	mov	w12, #1
	add	x10, x9, #1
	mov	w15, #1
	and	x11, x10, #0x3ffffffffffffffe
	mov	x14, x11
	add	x9, x13, x11, lsl #3
	add	x13, x13, #8
.LBB1_4:                                // =>This Inner Loop Header: Depth=1
	ldp	x16, x17, [x13, #-8]
	add	x13, x13, #16
	subs	x14, x14, #2
	mul	x12, x16, x12
	mul	x15, x17, x15
	b.ne	.LBB1_4
// %bb.5:
	mul	x12, x15, x12
	cmp	x10, x11
	b.eq	.LBB1_7
.LBB1_6:                                // =>This Inner Loop Header: Depth=1
	ldr	x10, [x9], #8
	cmp	x9, x8
	mul	x12, x10, x12
	b.ne	.LBB1_6
.LBB1_7:
	cbz	x12, .LBB1_18
.LBB1_8:
	cmp	x25, x21
	mov	x0, x23
	cset	w3, eq
	mov	x1, x26
	mov	x2, x24
	mov	x4, x20
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_
	sub	x0, x29, #56
	mov	x1, x23
	mov	x2, x26
	bl	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
	stur	x25, [x29, #-8]
.Ltmp82:
	add	x0, sp, #32
	mov	x1, x23
	mov	x2, x24
	bl	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
.Ltmp83:
// %bb.9:
	and	w8, w22, #0x1
	str	x21, [sp, #80]
	strb	w8, [sp, #24]
.Ltmp85:
	sub	x0, x29, #56
	add	x1, sp, #32
	add	x4, sp, #24
	mov	x2, x20
	ldr	q0, [sp]                        // 16-byte Folded Reload
	mov	x3, x19
	mov	w5, #1
	bl	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.Ltmp86:
// %bb.10:
	ldr	x0, [sp, #56]
	cbz	x0, .LBB1_12
// %bb.11:
	bl	_ZdlPv
.LBB1_12:
	ldr	x0, [sp, #32]
	cbz	x0, .LBB1_14
// %bb.13:
	bl	_ZdlPv
.LBB1_14:
	ldur	x0, [x29, #-32]
	cbz	x0, .LBB1_16
// %bb.15:
	bl	_ZdlPv
.LBB1_16:
	ldur	x0, [x29, #-56]
	cbz	x0, .LBB1_18
// %bb.17:
	bl	_ZdlPv
.LBB1_18:
	ldp	x20, x19, [sp, #208]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	add	sp, sp, #224
	ret
.LBB1_19:
.Ltmp87:
	mov	x19, x0
	add	x0, sp, #32
	bl	_ZN9pocketfft6detail8arr_infoD2Ev
	b	.LBB1_21
.LBB1_20:
.Ltmp84:
	mov	x19, x0
.LBB1_21:
	sub	x0, x29, #56
	bl	_ZN9pocketfft6detail8arr_infoD2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end1:
	.size	_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m, .Lfunc_end1-_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,"aG",@progbits,_ZN9pocketfft6detail3c2cIeEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,comdat
	.p2align	2
GCC_except_table1:
.Lexception1:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end1-.Lcst_begin1
.Lcst_begin1:
	.uleb128 .Lfunc_begin1-.Lfunc_begin1    // >> Call Site 1 <<
	.uleb128 .Ltmp82-.Lfunc_begin1          //   Call between .Lfunc_begin1 and .Ltmp82
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp82-.Lfunc_begin1          // >> Call Site 2 <<
	.uleb128 .Ltmp83-.Ltmp82                //   Call between .Ltmp82 and .Ltmp83
	.uleb128 .Ltmp84-.Lfunc_begin1          //     jumps to .Ltmp84
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp85-.Lfunc_begin1          // >> Call Site 3 <<
	.uleb128 .Ltmp86-.Ltmp85                //   Call between .Ltmp85 and .Ltmp86
	.uleb128 .Ltmp87-.Lfunc_begin1          //     jumps to .Ltmp87
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp86-.Lfunc_begin1          // >> Call Site 4 <<
	.uleb128 .Lfunc_end1-.Ltmp86            //   Call between .Ltmp86 and .Lfunc_end1
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end1:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,"axG",@progbits,_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,comdat
	.weak	_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m // -- Begin function _ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
	.p2align	2
	.type	_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,@function
_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m: // @_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
.Lfunc_begin2:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception2
// %bb.0:
	sub	sp, sp, #208
	str	d8, [sp, #112]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #128]            // 16-byte Folded Spill
	add	x29, sp, #128
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	.cfi_offset b8, -96
	ldp	x13, x8, [x0]
	fmov	d8, d0
	mov	x19, x7
	mov	x23, x0
	mov	x21, x6
	mov	x25, x5
	mov	w22, w4
	mov	x20, x3
	mov	x24, x2
	mov	x26, x1
	cmp	x13, x8
	b.eq	.LBB2_8
// %bb.1:
	sub	x9, x8, x13
	sub	x9, x9, #8
	cmp	x9, #8
	b.hs	.LBB2_3
// %bb.2:
	mov	w12, #1
	mov	x9, x13
	b	.LBB2_6
.LBB2_3:
	lsr	x9, x9, #3
	mov	w12, #1
	add	x10, x9, #1
	mov	w15, #1
	and	x11, x10, #0x3ffffffffffffffe
	mov	x14, x11
	add	x9, x13, x11, lsl #3
	add	x13, x13, #8
.LBB2_4:                                // =>This Inner Loop Header: Depth=1
	ldp	x16, x17, [x13, #-8]
	add	x13, x13, #16
	subs	x14, x14, #2
	mul	x12, x16, x12
	mul	x15, x17, x15
	b.ne	.LBB2_4
// %bb.5:
	mul	x12, x15, x12
	cmp	x10, x11
	b.eq	.LBB2_7
.LBB2_6:                                // =>This Inner Loop Header: Depth=1
	ldr	x10, [x9], #8
	cmp	x9, x8
	mul	x12, x10, x12
	b.ne	.LBB2_6
.LBB2_7:
	cbz	x12, .LBB2_18
.LBB2_8:
	cmp	x25, x21
	mov	x0, x23
	cset	w3, eq
	mov	x1, x26
	mov	x2, x24
	mov	x4, x20
	bl	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_
	add	x0, sp, #56
	mov	x1, x23
	mov	x2, x26
	bl	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
	str	x25, [sp, #104]
.Ltmp88:
	mov	x0, sp
	mov	x1, x23
	mov	x2, x24
	bl	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
.Ltmp89:
// %bb.9:
	and	w8, w22, #0x1
	str	x21, [sp, #48]
	sturb	w8, [x29, #-8]
.Ltmp91:
	fmov	d0, d8
	add	x0, sp, #56
	mov	x1, sp
	sub	x4, x29, #8
	mov	x2, x20
	mov	x3, x19
	mov	w5, #1
	bl	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.Ltmp92:
// %bb.10:
	ldr	x0, [sp, #24]
	cbz	x0, .LBB2_12
// %bb.11:
	bl	_ZdlPv
.LBB2_12:
	ldr	x0, [sp]
	cbz	x0, .LBB2_14
// %bb.13:
	bl	_ZdlPv
.LBB2_14:
	ldr	x0, [sp, #80]
	cbz	x0, .LBB2_16
// %bb.15:
	bl	_ZdlPv
.LBB2_16:
	ldr	x0, [sp, #56]
	cbz	x0, .LBB2_18
// %bb.17:
	bl	_ZdlPv
.LBB2_18:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #128]            // 16-byte Folded Reload
	ldr	d8, [sp, #112]                  // 8-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB2_19:
.Ltmp93:
	mov	x19, x0
	mov	x0, sp
	bl	_ZN9pocketfft6detail8arr_infoD2Ev
	b	.LBB2_21
.LBB2_20:
.Ltmp90:
	mov	x19, x0
.LBB2_21:
	add	x0, sp, #56
	bl	_ZN9pocketfft6detail8arr_infoD2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end2:
	.size	_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m, .Lfunc_end2-_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,"aG",@progbits,_ZN9pocketfft6detail3c2cIdEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,comdat
	.p2align	2
GCC_except_table2:
.Lexception2:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end2-.Lcst_begin2
.Lcst_begin2:
	.uleb128 .Lfunc_begin2-.Lfunc_begin2    // >> Call Site 1 <<
	.uleb128 .Ltmp88-.Lfunc_begin2          //   Call between .Lfunc_begin2 and .Ltmp88
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp88-.Lfunc_begin2          // >> Call Site 2 <<
	.uleb128 .Ltmp89-.Ltmp88                //   Call between .Ltmp88 and .Ltmp89
	.uleb128 .Ltmp90-.Lfunc_begin2          //     jumps to .Ltmp90
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp91-.Lfunc_begin2          // >> Call Site 3 <<
	.uleb128 .Ltmp92-.Ltmp91                //   Call between .Ltmp91 and .Ltmp92
	.uleb128 .Ltmp93-.Lfunc_begin2          //     jumps to .Ltmp93
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp92-.Lfunc_begin2          // >> Call Site 4 <<
	.uleb128 .Lfunc_end2-.Ltmp92            //   Call between .Ltmp92 and .Lfunc_end2
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end2:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,"axG",@progbits,_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,comdat
	.weak	_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m // -- Begin function _ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
	.p2align	2
	.type	_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,@function
_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m: // @_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
.Lfunc_begin3:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception3
// %bb.0:
	sub	sp, sp, #208
	str	d8, [sp, #112]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #128]            // 16-byte Folded Spill
	add	x29, sp, #128
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	.cfi_offset b8, -96
	ldp	x13, x8, [x0]
	fmov	s8, s0
	mov	x19, x7
	mov	x23, x0
	mov	x21, x6
	mov	x25, x5
	mov	w22, w4
	mov	x20, x3
	mov	x24, x2
	mov	x26, x1
	cmp	x13, x8
	b.eq	.LBB3_8
// %bb.1:
	sub	x9, x8, x13
	sub	x9, x9, #8
	cmp	x9, #8
	b.hs	.LBB3_3
// %bb.2:
	mov	w12, #1
	mov	x9, x13
	b	.LBB3_6
.LBB3_3:
	lsr	x9, x9, #3
	mov	w12, #1
	add	x10, x9, #1
	mov	w15, #1
	and	x11, x10, #0x3ffffffffffffffe
	mov	x14, x11
	add	x9, x13, x11, lsl #3
	add	x13, x13, #8
.LBB3_4:                                // =>This Inner Loop Header: Depth=1
	ldp	x16, x17, [x13, #-8]
	add	x13, x13, #16
	subs	x14, x14, #2
	mul	x12, x16, x12
	mul	x15, x17, x15
	b.ne	.LBB3_4
// %bb.5:
	mul	x12, x15, x12
	cmp	x10, x11
	b.eq	.LBB3_7
.LBB3_6:                                // =>This Inner Loop Header: Depth=1
	ldr	x10, [x9], #8
	cmp	x9, x8
	mul	x12, x10, x12
	b.ne	.LBB3_6
.LBB3_7:
	cbz	x12, .LBB3_18
.LBB3_8:
	cmp	x25, x21
	mov	x0, x23
	cset	w3, eq
	mov	x1, x26
	mov	x2, x24
	mov	x4, x20
	bl	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_
	add	x0, sp, #56
	mov	x1, x23
	mov	x2, x26
	bl	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
	str	x25, [sp, #104]
.Ltmp94:
	mov	x0, sp
	mov	x1, x23
	mov	x2, x24
	bl	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
.Ltmp95:
// %bb.9:
	and	w8, w22, #0x1
	str	x21, [sp, #48]
	sturb	w8, [x29, #-8]
.Ltmp97:
	fmov	s0, s8
	add	x0, sp, #56
	mov	x1, sp
	sub	x4, x29, #8
	mov	x2, x20
	mov	x3, x19
	mov	w5, #1
	bl	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.Ltmp98:
// %bb.10:
	ldr	x0, [sp, #24]
	cbz	x0, .LBB3_12
// %bb.11:
	bl	_ZdlPv
.LBB3_12:
	ldr	x0, [sp]
	cbz	x0, .LBB3_14
// %bb.13:
	bl	_ZdlPv
.LBB3_14:
	ldr	x0, [sp, #80]
	cbz	x0, .LBB3_16
// %bb.15:
	bl	_ZdlPv
.LBB3_16:
	ldr	x0, [sp, #56]
	cbz	x0, .LBB3_18
// %bb.17:
	bl	_ZdlPv
.LBB3_18:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #128]            // 16-byte Folded Reload
	ldr	d8, [sp, #112]                  // 8-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB3_19:
.Ltmp99:
	mov	x19, x0
	mov	x0, sp
	bl	_ZN9pocketfft6detail8arr_infoD2Ev
	b	.LBB3_21
.LBB3_20:
.Ltmp96:
	mov	x19, x0
.LBB3_21:
	add	x0, sp, #56
	bl	_ZN9pocketfft6detail8arr_infoD2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end3:
	.size	_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m, .Lfunc_end3-_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,"aG",@progbits,_ZN9pocketfft6detail3c2cIfEEvRKSt6vectorImSaImEERKS2_IlSaIlEESA_S6_bPKSt7complexIT_EPSD_SC_m,comdat
	.p2align	2
GCC_except_table3:
.Lexception3:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end3-.Lcst_begin3
.Lcst_begin3:
	.uleb128 .Lfunc_begin3-.Lfunc_begin3    // >> Call Site 1 <<
	.uleb128 .Ltmp94-.Lfunc_begin3          //   Call between .Lfunc_begin3 and .Ltmp94
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp94-.Lfunc_begin3          // >> Call Site 2 <<
	.uleb128 .Ltmp95-.Ltmp94                //   Call between .Ltmp94 and .Ltmp95
	.uleb128 .Ltmp96-.Lfunc_begin3          //     jumps to .Ltmp96
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp97-.Lfunc_begin3          // >> Call Site 3 <<
	.uleb128 .Ltmp98-.Ltmp97                //   Call between .Ltmp97 and .Ltmp98
	.uleb128 .Ltmp99-.Lfunc_begin3          //     jumps to .Ltmp99
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp98-.Lfunc_begin3          // >> Call Site 4 <<
	.uleb128 .Lfunc_end3-.Ltmp98            //   Call between .Ltmp98 and .Lfunc_end3
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end3:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE
.LCPI4_0:
	.xword	0x0000000000000000              // fp128 NaN
	.xword	0x7fff800000000000
.LCPI4_1:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
	.section	.text._Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE,"axG",@progbits,_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE,comdat
	.weak	_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE
	.p2align	2
	.type	_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE,@function
_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE: // @_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	str	x25, [sp, #80]                  // 8-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x8, x9, [x0]
	cmp	x9, x8
	b.eq	.LBB4_4
// %bb.1:
	adrp	x9, .LCPI4_1
	mov	x19, x0
	mov	x20, x1
	mov	x21, xzr
	mov	x22, xzr
	mov	x23, xzr
	ldr	q0, [x9, :lo12:.LCPI4_1]
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
.LBB4_2:                                // =>This Inner Loop Header: Depth=1
	ldr	x9, [x20]
	add	x24, x8, x22
	add	x25, x9, x21
	ldr	q0, [x24]
	stp	q0, q1, [sp, #16]               // 32-byte Folded Spill
	ldr	s0, [x25]
	bl	__extendsftf2
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [x24, #16]
	str	q0, [sp]                        // 16-byte Folded Spill
	ldr	s0, [x25, #4]
	bl	__extendsftf2
	mov	v1.16b, v0.16b
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	__subtf3
	mov	v1.16b, v0.16b
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	bl	__multf3
	ldr	q1, [sp]                        // 16-byte Folded Reload
	bl	__addtf3
	bl	sqrtl
	ldr	x8, [x19]
	str	q0, [sp]                        // 16-byte Folded Spill
	add	x8, x8, x22
	ldp	q0, q1, [x8]
	bl	cabsl
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	bl	__multf3
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	ldp	x8, x9, [x19]
	mov	v1.16b, v0.16b
	add	x23, x23, #1
	add	x22, x22, #32
	add	x21, x21, #8
	sub	x9, x9, x8
	cmp	x23, x9, asr #5
	b.lo	.LBB4_2
// %bb.3:
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	bl	__divtf3
	b	.LBB4_5
.LBB4_4:
	adrp	x8, .LCPI4_0
	ldr	q0, [x8, :lo12:.LCPI4_0]
.LBB4_5:
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldr	x25, [sp, #80]                  // 8-byte Folded Reload
	add	sp, sp, #144
	b	sqrtl
.Lfunc_end4:
	.size	_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE, .Lfunc_end4-_Z5l2errISt7complexIeES0_IfEEeRKSt6vectorIT_SaIS4_EERKS3_IT0_SaIS9_EE
	.cfi_endproc
                                        // -- End function
	.section	.text.__clang_call_terminate,"axG",@progbits,__clang_call_terminate,comdat
	.hidden	__clang_call_terminate          // -- Begin function __clang_call_terminate
	.weak	__clang_call_terminate
	.p2align	2
	.type	__clang_call_terminate,@function
__clang_call_terminate:                 // @__clang_call_terminate
// %bb.0:
	str	x30, [sp, #-16]!                // 8-byte Folded Spill
	bl	__cxa_begin_catch
	bl	_ZSt9terminatev
.Lfunc_end5:
	.size	__clang_call_terminate, .Lfunc_end5-__clang_call_terminate
                                        // -- End function
	.section	.text._ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_,"axG",@progbits,_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_,comdat
	.weak	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_ // -- Begin function _ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_
	.p2align	2
	.type	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_,@function
_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_: // @_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_
.Lfunc_begin4:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception4
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x21, x4
	mov	x19, x0
	bl	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b
	ldp	x9, x8, [x19]
	sub	x20, x8, x9
	mov	x8, #-7
	movk	x8, #32767, lsl #48
	cmp	x20, x8
	b.hs	.LBB6_16
// %bb.1:
	cbz	x20, .LBB6_3
// %bb.2:
	mov	x0, x20
	bl	_Znwm
	and	x2, x20, #0xfffffffffffffff8
	mov	w1, wzr
	mov	x19, x0
	bl	memset
	ldp	x8, x9, [x21]
	cmp	x8, x9
	b.ne	.LBB6_5
	b	.LBB6_9
.LBB6_3:
	ldp	x8, x9, [x21]
	cmp	x8, x9
	b.eq	.LBB6_10
// %bb.4:
	mov	x19, xzr
.LBB6_5:
	asr	x10, x20, #3
.LBB6_6:                                // =>This Inner Loop Header: Depth=1
	ldr	x11, [x8]
	cmp	x11, x10
	b.hs	.LBB6_13
// %bb.7:                               //   in Loop: Header=BB6_6 Depth=1
	lsl	x11, x11, #3
	ldr	x12, [x19, x11]
	add	x12, x12, #1
	cmp	x12, #2
	str	x12, [x19, x11]
	b.hs	.LBB6_11
// %bb.8:                               //   in Loop: Header=BB6_6 Depth=1
	add	x8, x8, #8
	cmp	x8, x9
	b.ne	.LBB6_6
.LBB6_9:
	mov	x0, x19
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	b	_ZdlPv
.LBB6_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB6_11:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp105:
	adrp	x1, .L.str.4
	add	x1, x1, :lo12:.L.str.4
	bl	_ZNSt16invalid_argumentC1EPKc
.Ltmp106:
// %bb.12:
.Ltmp108:
	adrp	x1, :got:_ZTISt16invalid_argument
	adrp	x2, :got:_ZNSt16invalid_argumentD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt16invalid_argument]
	ldr	x2, [x2, :got_lo12:_ZNSt16invalid_argumentD1Ev]
	bl	__cxa_throw
.Ltmp109:
	b	.LBB6_15
.LBB6_13:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp100:
	adrp	x1, .L.str.3
	add	x1, x1, :lo12:.L.str.3
	bl	_ZNSt16invalid_argumentC1EPKc
.Ltmp101:
// %bb.14:
.Ltmp103:
	adrp	x1, :got:_ZTISt16invalid_argument
	adrp	x2, :got:_ZNSt16invalid_argumentD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt16invalid_argument]
	ldr	x2, [x2, :got_lo12:_ZNSt16invalid_argumentD1Ev]
	bl	__cxa_throw
.Ltmp104:
.LBB6_15:
.LBB6_16:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.LBB6_17:
.Ltmp102:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
	b	.LBB6_20
.LBB6_18:
.Ltmp107:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
	b	.LBB6_21
.LBB6_19:
.Ltmp110:
	mov	x20, x0
.LBB6_20:
	cbz	x19, .LBB6_22
.LBB6_21:
	mov	x0, x19
	bl	_ZdlPv
.LBB6_22:
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end6:
	.size	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_, .Lfunc_end6-_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_,"aG",@progbits,_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_bS6_,comdat
	.p2align	2
GCC_except_table6:
.Lexception4:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end4-.Lcst_begin4
.Lcst_begin4:
	.uleb128 .Lfunc_begin4-.Lfunc_begin4    // >> Call Site 1 <<
	.uleb128 .Ltmp105-.Lfunc_begin4         //   Call between .Lfunc_begin4 and .Ltmp105
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp105-.Lfunc_begin4         // >> Call Site 2 <<
	.uleb128 .Ltmp106-.Ltmp105              //   Call between .Ltmp105 and .Ltmp106
	.uleb128 .Ltmp107-.Lfunc_begin4         //     jumps to .Ltmp107
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp108-.Lfunc_begin4         // >> Call Site 3 <<
	.uleb128 .Ltmp109-.Ltmp108              //   Call between .Ltmp108 and .Ltmp109
	.uleb128 .Ltmp110-.Lfunc_begin4         //     jumps to .Ltmp110
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp109-.Lfunc_begin4         // >> Call Site 4 <<
	.uleb128 .Ltmp100-.Ltmp109              //   Call between .Ltmp109 and .Ltmp100
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp100-.Lfunc_begin4         // >> Call Site 5 <<
	.uleb128 .Ltmp101-.Ltmp100              //   Call between .Ltmp100 and .Ltmp101
	.uleb128 .Ltmp102-.Lfunc_begin4         //     jumps to .Ltmp102
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp103-.Lfunc_begin4         // >> Call Site 6 <<
	.uleb128 .Ltmp104-.Ltmp103              //   Call between .Ltmp103 and .Ltmp104
	.uleb128 .Ltmp110-.Lfunc_begin4         //     jumps to .Ltmp110
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp104-.Lfunc_begin4         // >> Call Site 7 <<
	.uleb128 .Lfunc_end6-.Ltmp104           //   Call between .Ltmp104 and .Lfunc_end6
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end4:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.LCPI7_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
	.section	.text._ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,"axG",@progbits,_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,comdat
	.weak	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
	.p2align	2
	.type	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,@function
_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b: // @_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.Lfunc_begin5:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception5
// %bb.0:
	sub	sp, sp, #256
	str	d8, [sp, #144]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	add	x29, sp, #160
	stp	x28, x27, [sp, #176]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #192]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	ldp	x8, x9, [x2]
	sturb	w5, [x29, #-4]
	stur	q0, [x29, #-32]
	stp	xzr, xzr, [x29, #-48]
	stur	xzr, [x29, #-56]
	cmp	x9, x8
	b.eq	.LBB7_36
// %bb.1:
	adrp	x11, .LCPI7_0
	movi	v8.2s, #1
	mov	x19, x4
	mov	x20, x2
	mov	x21, x3
	mov	x22, x1
	mov	x23, x0
	mov	x10, xzr
	mov	x9, xzr
	sub	x27, x29, #32
	sub	x28, x29, #4
	ldr	q0, [x11, :lo12:.LCPI7_0]
	str	q0, [sp]                        // 16-byte Folded Spill
	ldr	x8, [x8, x9, lsl #3]
	ldr	x9, [x23]
	ldr	x24, [x9, x8, lsl #3]
	stur	x24, [x29, #-64]
	cbz	x10, .LBB7_3
.LBB7_2:
	ldr	x8, [x10, #16]
	cmp	x24, x8
	b.eq	.LBB7_12
.LBB7_3:
.Ltmp111:
	mov	w0, #40
	bl	_Znwm
.Ltmp112:
// %bb.4:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x26, x0, #16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
.Ltmp114:
	mov	x0, x26
	mov	x1, x24
	bl	_ZN9pocketfft6detail11pocketfft_cIeEC2Em
.Ltmp115:
// %bb.5:
	ldur	x24, [x29, #-40]
	stp	x26, x25, [x29, #-48]
	cbz	x24, .LBB7_12
// %bb.6:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB7_8
// %bb.7:
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB7_9
	b	.LBB7_12
.LBB7_8:
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB7_12
.LBB7_9:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB7_28
// %bb.10:
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB7_12
.LBB7_11:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB7_12:
	cmp	x21, #1
	b.ne	.LBB7_14
// %bb.13:
	mov	w0, #1
	b	.LBB7_25
.LBB7_14:
	ldp	x8, x9, [x23]
	cmp	x8, x9
	b.eq	.LBB7_17
// %bb.15:
	sub	x10, x9, x8
	sub	x10, x10, #8
	cmp	x10, #8
	b.hs	.LBB7_18
// %bb.16:
	mov	w11, #1
	mov	x10, x8
	b	.LBB7_21
.LBB7_17:
	mov	w11, #1
	b	.LBB7_22
.LBB7_18:
	lsr	x10, x10, #3
	add	x11, x8, #8
	add	x12, x10, #1
	mov	w15, #1
	and	x13, x12, #0x3ffffffffffffffe
	mov	w16, #1
	mov	x14, x13
	add	x10, x8, x13, lsl #3
.LBB7_19:                               // =>This Inner Loop Header: Depth=1
	ldp	x17, x18, [x11, #-8]
	add	x11, x11, #16
	subs	x14, x14, #2
	mul	x15, x17, x15
	mul	x16, x18, x16
	b.ne	.LBB7_19
// %bb.20:
	mul	x11, x16, x15
	cmp	x12, x13
	b.eq	.LBB7_22
.LBB7_21:                               // =>This Inner Loop Header: Depth=1
	ldr	x12, [x10], #8
	cmp	x10, x9
	mul	x11, x12, x11
	b.ne	.LBB7_21
.LBB7_22:
	ldur	x9, [x29, #-56]
	ldr	x10, [x20]
	ldr	x9, [x10, x9, lsl #3]
	ldr	x8, [x8, x9, lsl #3]
	udiv	x9, x11, x8
	cmp	x8, #1000
	mov	x8, x21
	lsr	x10, x9, #2
	csel	x24, x10, x9, lo
	cbnz	x21, .LBB7_24
// %bb.23:
	bl	_ZNSt6thread20hardware_concurrencyEv
	mov	w8, w0
.LBB7_24:
	cmp	x8, x24
	csel	x8, x8, x24, lo
	cmp	x8, #1
	csinc	x0, x8, xzr, hi
.LBB7_25:
	sub	x8, x29, #64
	stp	x20, x19, [sp, #56]
	str	x28, [sp, #88]
	stp	x23, x8, [sp, #24]
	sub	x8, x29, #56
	stp	x8, x22, [sp, #40]
	sub	x8, x29, #48
	stp	x8, x27, [sp, #72]
.Ltmp117:
	add	x1, sp, #24
	bl	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
.Ltmp118:
// %bb.26:
	ldp	x8, x10, [x20]
	ldur	x9, [x29, #-56]
	ldr	q0, [sp]                        // 16-byte Folded Reload
	add	x9, x9, #1
	sub	x10, x10, x8
	stur	q0, [x29, #-32]
	cmp	x9, x10, asr #3
	stur	x9, [x29, #-56]
	b.hs	.LBB7_29
// %bb.27:
	ldur	x10, [x29, #-48]
	ldr	x8, [x8, x9, lsl #3]
	ldr	x9, [x23]
	ldr	x24, [x9, x8, lsl #3]
	stur	x24, [x29, #-64]
	cbnz	x10, .LBB7_2
	b	.LBB7_3
.LBB7_28:
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB7_11
	b	.LBB7_12
.LBB7_29:
	ldur	x19, [x29, #-40]
	cbz	x19, .LBB7_36
// %bb.30:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB7_32
// %bb.31:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB7_33
	b	.LBB7_36
.LBB7_32:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB7_36
.LBB7_33:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB7_37
// %bb.34:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB7_36
.LBB7_35:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB7_36:
	ldp	x20, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	d8, [sp, #144]                  // 8-byte Folded Reload
	add	sp, sp, #256
	ret
.LBB7_37:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB7_35
	b	.LBB7_36
.LBB7_38:
.Ltmp113:
	b	.LBB7_41
.LBB7_39:
.Ltmp116:
	mov	x19, x0
	mov	x0, x25
	bl	_ZdlPv
	b	.LBB7_42
.LBB7_40:
.Ltmp119:
.LBB7_41:
	mov	x19, x0
.LBB7_42:
	sub	x0, x29, #48
	bl	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end7:
	.size	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b, .Lfunc_end7-_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,"aG",@progbits,_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,comdat
	.p2align	2
GCC_except_table7:
.Lexception5:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end5-.Lcst_begin5
.Lcst_begin5:
	.uleb128 .Ltmp111-.Lfunc_begin5         // >> Call Site 1 <<
	.uleb128 .Ltmp112-.Ltmp111              //   Call between .Ltmp111 and .Ltmp112
	.uleb128 .Ltmp113-.Lfunc_begin5         //     jumps to .Ltmp113
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp114-.Lfunc_begin5         // >> Call Site 2 <<
	.uleb128 .Ltmp115-.Ltmp114              //   Call between .Ltmp114 and .Ltmp115
	.uleb128 .Ltmp116-.Lfunc_begin5         //     jumps to .Ltmp116
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp115-.Lfunc_begin5         // >> Call Site 3 <<
	.uleb128 .Ltmp117-.Ltmp115              //   Call between .Ltmp115 and .Ltmp117
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp117-.Lfunc_begin5         // >> Call Site 4 <<
	.uleb128 .Ltmp118-.Ltmp117              //   Call between .Ltmp117 and .Ltmp118
	.uleb128 .Ltmp119-.Lfunc_begin5         //     jumps to .Ltmp119
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp118-.Lfunc_begin5         // >> Call Site 5 <<
	.uleb128 .Lfunc_end7-.Ltmp118           //   Call between .Ltmp118 and .Lfunc_end7
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end5:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b,"axG",@progbits,_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b,comdat
	.weak	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b // -- Begin function _ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b
	.p2align	2
	.type	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b,@function
_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b: // @_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b
.Lfunc_begin6:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception6
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldp	x10, x9, [x0]
	subs	x9, x9, x10
	b.eq	.LBB8_9
// %bb.1:
	ldp	x0, x10, [x1]
	mov	x8, x2
	asr	x9, x9, #3
	sub	x2, x10, x0
	cmp	x9, x2, asr #3
	b.ne	.LBB8_8
// %bb.2:
	ldp	x1, x10, [x8]
	sub	x8, x10, x1
	cmp	x9, x8, asr #3
	b.ne	.LBB8_8
// %bb.3:
	tbz	w3, #0, .LBB8_7
// %bb.4:
	cmp	x2, x8
	b.ne	.LBB8_10
// %bb.5:
	cbz	x2, .LBB8_7
// %bb.6:
	bl	bcmp
	cbnz	w0, .LBB8_10
.LBB8_7:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB8_8:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x19, x0
.Ltmp120:
	adrp	x1, .L.str.6
	add	x1, x1, :lo12:.L.str.6
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp121:
	b	.LBB8_11
.LBB8_9:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x19, x0
.Ltmp126:
	adrp	x1, .L.str.5
	add	x1, x1, :lo12:.L.str.5
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp127:
	b	.LBB8_11
.LBB8_10:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x19, x0
.Ltmp123:
	adrp	x1, .L.str.7
	add	x1, x1, :lo12:.L.str.7
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp124:
.LBB8_11:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x19
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.LBB8_12:
.Ltmp125:
	b	.LBB8_15
.LBB8_13:
.Ltmp128:
	b	.LBB8_15
.LBB8_14:
.Ltmp122:
.LBB8_15:
	mov	x20, x0
	mov	x0, x19
	bl	__cxa_free_exception
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end8:
	.size	_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b, .Lfunc_end8-_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b,"aG",@progbits,_ZN9pocketfft6detail4util12sanity_checkERKSt6vectorImSaImEERKS2_IlSaIlEESA_b,comdat
	.p2align	2
GCC_except_table8:
.Lexception6:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end6-.Lcst_begin6
.Lcst_begin6:
	.uleb128 .Lfunc_begin6-.Lfunc_begin6    // >> Call Site 1 <<
	.uleb128 .Ltmp120-.Lfunc_begin6         //   Call between .Lfunc_begin6 and .Ltmp120
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp120-.Lfunc_begin6         // >> Call Site 2 <<
	.uleb128 .Ltmp121-.Ltmp120              //   Call between .Ltmp120 and .Ltmp121
	.uleb128 .Ltmp122-.Lfunc_begin6         //     jumps to .Ltmp122
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp121-.Lfunc_begin6         // >> Call Site 3 <<
	.uleb128 .Ltmp126-.Ltmp121              //   Call between .Ltmp121 and .Ltmp126
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp126-.Lfunc_begin6         // >> Call Site 4 <<
	.uleb128 .Ltmp127-.Ltmp126              //   Call between .Ltmp126 and .Ltmp127
	.uleb128 .Ltmp128-.Lfunc_begin6         //     jumps to .Ltmp128
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp127-.Lfunc_begin6         // >> Call Site 5 <<
	.uleb128 .Ltmp123-.Ltmp127              //   Call between .Ltmp127 and .Ltmp123
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp123-.Lfunc_begin6         // >> Call Site 6 <<
	.uleb128 .Ltmp124-.Ltmp123              //   Call between .Ltmp123 and .Ltmp124
	.uleb128 .Ltmp125-.Lfunc_begin6         //     jumps to .Ltmp125
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp124-.Lfunc_begin6         // >> Call Site 7 <<
	.uleb128 .Lfunc_end8-.Ltmp124           //   Call between .Ltmp124 and .Lfunc_end8
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end6:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE,"axG",@progbits,_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE,comdat
	.weak	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE // -- Begin function _ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
	.p2align	2
	.type	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE,@function
_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE: // @_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
.Lfunc_begin7:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception7
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x9, x8, [x1]
	mov	x20, x2
	mov	x21, x1
	mov	x19, x0
	stp	xzr, xzr, [x0]
	str	xzr, [x0, #16]
	subs	x23, x8, x9
	b.eq	.LBB9_3
// %bb.1:
	mov	x8, #-7
	movk	x8, #32767, lsl #48
	cmp	x23, x8
	b.hs	.LBB9_14
// %bb.2:
	mov	x0, x23
	bl	_Znwm
	mov	x22, x0
	b	.LBB9_4
.LBB9_3:
	mov	x22, xzr
.LBB9_4:
	asr	x8, x23, #3
	stp	x22, x22, [x19]
	add	x8, x22, x8, lsl #3
	str	x8, [x19, #16]
	ldp	x1, x8, [x21]
	subs	x21, x8, x1
	b.eq	.LBB9_6
// %bb.5:
	mov	x0, x22
	mov	x2, x21
	bl	memmove
.LBB9_6:
	ldp	x10, x9, [x20]
	add	x8, x22, x21
	stp	xzr, xzr, [x19, #24]
	str	xzr, [x19, #40]
	str	x8, [x19, #8]
	subs	x21, x9, x10
	b.eq	.LBB9_10
// %bb.7:
	mov	x8, #-7
	movk	x8, #32767, lsl #48
	cmp	x21, x8
	b.hs	.LBB9_15
// %bb.8:
.Ltmp129:
	mov	x0, x21
	bl	_Znwm
.Ltmp130:
// %bb.9:
	mov	x22, x0
	b	.LBB9_11
.LBB9_10:
	mov	x22, xzr
.LBB9_11:
	asr	x8, x21, #3
	stp	x22, x22, [x19, #24]
	add	x8, x22, x8, lsl #3
	str	x8, [x19, #40]
	ldp	x1, x8, [x20]
	subs	x20, x8, x1
	b.eq	.LBB9_13
// %bb.12:
	mov	x0, x22
	mov	x2, x20
	bl	memmove
.LBB9_13:
	add	x8, x22, x20
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	str	x8, [x19, #32]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB9_14:
	bl	_ZSt28__throw_bad_array_new_lengthv
.LBB9_15:
.Ltmp131:
	bl	_ZSt28__throw_bad_array_new_lengthv
.Ltmp132:
// %bb.16:
.LBB9_17:
.Ltmp133:
	ldr	x8, [x19]
	mov	x19, x0
	cbz	x8, .LBB9_19
// %bb.18:
	mov	x0, x8
	bl	_ZdlPv
.LBB9_19:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end9:
	.size	_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE, .Lfunc_end9-_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE,"aG",@progbits,_ZN9pocketfft6detail8arr_infoC2ERKSt6vectorImSaImEERKS2_IlSaIlEE,comdat
	.p2align	2
GCC_except_table9:
.Lexception7:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end7-.Lcst_begin7
.Lcst_begin7:
	.uleb128 .Lfunc_begin7-.Lfunc_begin7    // >> Call Site 1 <<
	.uleb128 .Ltmp129-.Lfunc_begin7         //   Call between .Lfunc_begin7 and .Ltmp129
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp129-.Lfunc_begin7         // >> Call Site 2 <<
	.uleb128 .Ltmp130-.Ltmp129              //   Call between .Ltmp129 and .Ltmp130
	.uleb128 .Ltmp133-.Lfunc_begin7         //     jumps to .Ltmp133
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp130-.Lfunc_begin7         // >> Call Site 3 <<
	.uleb128 .Ltmp131-.Ltmp130              //   Call between .Ltmp130 and .Ltmp131
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp131-.Lfunc_begin7         // >> Call Site 4 <<
	.uleb128 .Ltmp132-.Ltmp131              //   Call between .Ltmp131 and .Ltmp132
	.uleb128 .Ltmp133-.Lfunc_begin7         //     jumps to .Ltmp133
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp132-.Lfunc_begin7         // >> Call Site 5 <<
	.uleb128 .Lfunc_end9-.Ltmp132           //   Call between .Ltmp132 and .Lfunc_end9
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end7:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,"axG",@progbits,_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,comdat
	.weak	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ // -- Begin function _ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
	.p2align	2
	.type	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,@function
_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_: // @_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
.Lfunc_begin8:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception8
// %bb.0:
	sub	sp, sp, #336
	stp	x29, x30, [sp, #240]            // 16-byte Folded Spill
	add	x29, sp, #240
	stp	x28, x27, [sp, #256]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #272]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	adrp	x8, .L_MergedGlobals+8
	cmp	x0, #0
	mov	x20, x1
	ldr	x8, [x8, :lo12:.L_MergedGlobals+8]
	csel	x22, x8, x0, eq
	cmp	x22, #1
	b.ne	.LBB10_2
// %bb.1:
	mov	x0, x20
	ldp	x20, x19, [sp, #320]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #240]            // 16-byte Folded Reload
	add	sp, sp, #336
	b	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.LBB10_2:
	adrp	x8, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x8, x8, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	ldarb	w8, [x8]
	tbz	w8, #0, .LBB10_18
.LBB10_3:
	add	x23, sp, #112
	str	x22, [sp, #112]
	movi	v0.2d, #0000000000000000
	add	x19, x23, #56
	mov	x0, x19
	str	xzr, [sp, #152]
	stur	q0, [sp, #120]
	stur	q0, [sp, #136]
	bl	_ZNSt18condition_variableC1Ev
	movi	v0.2d, #0000000000000000
	str	xzr, [sp, #104]
	str	xzr, [sp, #80]
	stp	q0, q0, [sp, #48]
	cbz	x22, .LBB10_10
// %bb.4:
	adrp	x27, _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	adrp	x28, _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	adrp	x21, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	mov	x24, xzr
	add	x25, sp, #104
	add	x26, sp, #48
	add	x27, x27, :lo12:_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	add	x28, x28, :lo12:_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	add	x21, x21, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	b	.LBB10_6
.LBB10_5:                               //   in Loop: Header=BB10_6 Depth=1
	add	x24, x24, #1
	cmp	x22, x24
	b.eq	.LBB10_10
.LBB10_6:                               // =>This Inner Loop Header: Depth=1
	movi	v0.2d, #0000000000000000
	stp	q0, q0, [sp, #16]
.Ltmp137:
	mov	w0, #48
	bl	_Znwm
.Ltmp138:
// %bb.7:                               //   in Loop: Header=BB10_6 Depth=1
	stp	x20, x23, [x0]
	stp	x25, x26, [x0, #16]
	stp	x24, x22, [x0, #32]
	stp	x28, x27, [sp, #32]
	str	x0, [sp, #16]
.Ltmp140:
	add	x1, sp, #16
	mov	x0, x21
	bl	_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE
.Ltmp141:
// %bb.8:                               //   in Loop: Header=BB10_6 Depth=1
	ldr	x8, [sp, #32]
	cbz	x8, .LBB10_5
// %bb.9:                               //   in Loop: Header=BB10_6 Depth=1
.Ltmp146:
	add	x0, sp, #16
	add	x1, sp, #16
	mov	w2, #3
	blr	x8
.Ltmp147:
	b	.LBB10_5
.LBB10_10:
	add	x0, x23, #8
	stur	x0, [x29, #-24]
	bl	pthread_mutex_lock
	cbnz	w0, .LBB10_21
// %bb.11:
	mov	w8, #1
	add	x20, sp, #112
	sturb	w8, [x29, #-16]
	ldar	x8, [x20]
	cbz	x8, .LBB10_13
.LBB10_12:                              // =>This Inner Loop Header: Depth=1
	sub	x1, x29, #24
	mov	x0, x19
	bl	_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE
	ldar	x8, [x20]
	cbnz	x8, .LBB10_12
.LBB10_13:
	ldurb	w8, [x29, #-16]
	cbz	w8, .LBB10_16
// %bb.14:
	ldur	x0, [x29, #-24]
	cbz	x0, .LBB10_16
// %bb.15:
	bl	pthread_mutex_unlock
.LBB10_16:
	ldr	x8, [sp, #104]
	cbnz	x8, .LBB10_23
// %bb.17:
	mov	x0, x19
	bl	_ZNSt18condition_variableD1Ev
	ldp	x20, x19, [sp, #320]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #240]            // 16-byte Folded Reload
	add	sp, sp, #336
	ret
.LBB10_18:
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_acquire
	cbz	w0, .LBB10_3
// %bb.19:
.Ltmp134:
	adrp	x0, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	_ZN9pocketfft6detail9threading11thread_poolC2Ev
.Ltmp135:
// %bb.20:
	adrp	x0, _ZN9pocketfft6detail9threading11thread_poolD2Ev
	adrp	x1, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	adrp	x2, __dso_handle
	add	x0, x0, :lo12:_ZN9pocketfft6detail9threading11thread_poolD2Ev
	add	x1, x1, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x2, x2, :lo12:__dso_handle
	bl	__cxa_atexit
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_release
	b	.LBB10_3
.LBB10_21:
.Ltmp149:
	bl	_ZSt20__throw_system_errori
.Ltmp150:
// %bb.22:
.LBB10_23:
	add	x0, sp, #8
	str	x8, [sp, #8]
	bl	_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv
.Ltmp152:
	add	x0, sp, #8
	bl	_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE
.Ltmp153:
// %bb.24:
.LBB10_25:
.Ltmp136:
	mov	x20, x0
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_abort
	mov	x0, x20
	bl	_Unwind_Resume
.LBB10_26:
.Ltmp154:
	ldr	x8, [sp, #8]
	mov	x20, x0
	cbz	x8, .LBB10_34
// %bb.27:
	add	x0, sp, #8
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
	b	.LBB10_34
.LBB10_28:
.Ltmp151:
	b	.LBB10_31
.LBB10_29:
.Ltmp148:
	bl	__clang_call_terminate
.LBB10_30:
.Ltmp139:
.LBB10_31:
	mov	x20, x0
	b	.LBB10_34
.LBB10_32:
.Ltmp142:
	ldr	x8, [sp, #32]
	mov	x20, x0
	cbz	x8, .LBB10_34
// %bb.33:
.Ltmp143:
	add	x0, sp, #16
	add	x1, sp, #16
	mov	w2, #3
	blr	x8
.Ltmp144:
.LBB10_34:
	ldr	x8, [sp, #104]
	cbz	x8, .LBB10_36
// %bb.35:
	add	x0, sp, #104
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB10_36:
	mov	x0, x19
	bl	_ZNSt18condition_variableD1Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB10_37:
.Ltmp145:
	bl	__clang_call_terminate
.Lfunc_end10:
	.size	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_, .Lfunc_end10-_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,"aG",@progbits,_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,comdat
	.p2align	2
GCC_except_table10:
.Lexception8:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase0-.Lttbaseref0
.Lttbaseref0:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end8-.Lcst_begin8
.Lcst_begin8:
	.uleb128 .Lfunc_begin8-.Lfunc_begin8    // >> Call Site 1 <<
	.uleb128 .Ltmp137-.Lfunc_begin8         //   Call between .Lfunc_begin8 and .Ltmp137
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp137-.Lfunc_begin8         // >> Call Site 2 <<
	.uleb128 .Ltmp138-.Ltmp137              //   Call between .Ltmp137 and .Ltmp138
	.uleb128 .Ltmp139-.Lfunc_begin8         //     jumps to .Ltmp139
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp140-.Lfunc_begin8         // >> Call Site 3 <<
	.uleb128 .Ltmp141-.Ltmp140              //   Call between .Ltmp140 and .Ltmp141
	.uleb128 .Ltmp142-.Lfunc_begin8         //     jumps to .Ltmp142
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp146-.Lfunc_begin8         // >> Call Site 4 <<
	.uleb128 .Ltmp147-.Ltmp146              //   Call between .Ltmp146 and .Ltmp147
	.uleb128 .Ltmp148-.Lfunc_begin8         //     jumps to .Ltmp148
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp134-.Lfunc_begin8         // >> Call Site 5 <<
	.uleb128 .Ltmp135-.Ltmp134              //   Call between .Ltmp134 and .Ltmp135
	.uleb128 .Ltmp136-.Lfunc_begin8         //     jumps to .Ltmp136
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp149-.Lfunc_begin8         // >> Call Site 6 <<
	.uleb128 .Ltmp150-.Ltmp149              //   Call between .Ltmp149 and .Ltmp150
	.uleb128 .Ltmp151-.Lfunc_begin8         //     jumps to .Ltmp151
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp152-.Lfunc_begin8         // >> Call Site 7 <<
	.uleb128 .Ltmp153-.Ltmp152              //   Call between .Ltmp152 and .Ltmp153
	.uleb128 .Ltmp154-.Lfunc_begin8         //     jumps to .Ltmp154
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp153-.Lfunc_begin8         // >> Call Site 8 <<
	.uleb128 .Ltmp143-.Ltmp153              //   Call between .Ltmp153 and .Ltmp143
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp143-.Lfunc_begin8         // >> Call Site 9 <<
	.uleb128 .Ltmp144-.Ltmp143              //   Call between .Ltmp143 and .Ltmp144
	.uleb128 .Ltmp145-.Lfunc_begin8         //     jumps to .Ltmp145
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp144-.Lfunc_begin8         // >> Call Site 10 <<
	.uleb128 .Lfunc_end10-.Ltmp144          //   Call between .Ltmp144 and .Lfunc_end10
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end8:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase0:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end11:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end11-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end12:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end12-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	add	x0, x0, #16
	b	_ZN9pocketfft6detail11pocketfft_cIeED2Ev
.Lfunc_end13:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end13-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end14:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end14-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB15_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB15_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB15_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB15_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB15_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB15_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end15:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end15-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail11pocketfft_cIeEC2Em,"axG",@progbits,_ZN9pocketfft6detail11pocketfft_cIeEC2Em,comdat
	.weak	_ZN9pocketfft6detail11pocketfft_cIeEC2Em // -- Begin function _ZN9pocketfft6detail11pocketfft_cIeEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail11pocketfft_cIeEC2Em,@function
_ZN9pocketfft6detail11pocketfft_cIeEC2Em: // @_ZN9pocketfft6detail11pocketfft_cIeEC2Em
.Lfunc_begin9:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception9
// %bb.0:
	str	d8, [sp, #-64]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -64
	mov	x19, x0
	mov	x20, x0
	str	xzr, [x0]
	str	x1, [x0, #16]
	str	xzr, [x20, #8]!
	cbz	x1, .LBB16_24
// %bb.1:
	mov	x21, x1
	cmp	x1, #50
	b.hs	.LBB16_5
// %bb.2:
	mov	x0, xzr
	mul	x8, x0, x0
	cmp	x8, x21
	b.hi	.LBB16_6
.LBB16_3:
.Ltmp155:
	mov	w0, #48
	bl	_Znwm
.Ltmp156:
// %bb.4:
	mov	x22, x0
.Ltmp158:
	mov	x1, x21
	bl	_ZN9pocketfft6detail5cfftpIeEC2Em
.Ltmp159:
	b	.LBB16_17
.LBB16_5:
	mov	x0, x21
	bl	_ZN9pocketfft6detail4util20largest_prime_factorEm
	mul	x8, x0, x0
	cmp	x8, x21
	b.ls	.LBB16_3
.LBB16_6:
	mov	x0, x21
	bl	_ZN9pocketfft6detail4util10cost_guessEm
	lsl	x8, x21, #1
	fmov	d8, d0
	sub	x0, x8, #1
	bl	_ZN9pocketfft6detail4util15good_size_cmplxEm
	bl	_ZN9pocketfft6detail4util10cost_guessEm
	fadd	d0, d0, d0
	fmov	d1, #1.50000000
	fmul	d0, d0, d1
	fcmp	d0, d8
	b.pl	.LBB16_15
// %bb.7:
.Ltmp167:
	mov	w0, #96
	bl	_Znwm
.Ltmp168:
// %bb.8:
	mov	x22, x0
.Ltmp170:
	mov	x1, x21
	bl	_ZN9pocketfft6detail7fftblueIeEC2Em
.Ltmp171:
// %bb.9:
	ldr	x21, [x20]
	str	x22, [x20]
	cbz	x21, .LBB16_23
// %bb.10:
	ldr	x8, [x21, #64]
	cbz	x8, .LBB16_12
// %bb.11:
	ldur	x0, [x8, #-8]
	bl	free
.LBB16_12:
	ldr	x0, [x21, #40]
	cbz	x0, .LBB16_14
// %bb.13:
	bl	_ZdlPv
.LBB16_14:
	ldr	x8, [x21, #24]
	cbnz	x8, .LBB16_21
	b	.LBB16_22
.LBB16_15:
.Ltmp161:
	mov	w0, #48
	bl	_Znwm
.Ltmp162:
// %bb.16:
	mov	x22, x0
.Ltmp164:
	mov	x1, x21
	bl	_ZN9pocketfft6detail5cfftpIeEC2Em
.Ltmp165:
.LBB16_17:
	ldr	x21, [x19]
	str	x22, [x19]
	cbz	x21, .LBB16_23
// %bb.18:
	ldr	x0, [x21, #24]
	cbz	x0, .LBB16_20
// %bb.19:
	bl	_ZdlPv
.LBB16_20:
	ldr	x8, [x21, #8]
	cbz	x8, .LBB16_22
.LBB16_21:
	ldur	x0, [x8, #-8]
	bl	free
.LBB16_22:
	mov	x0, x21
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	b	_ZdlPv
.LBB16_23:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	ret
.LBB16_24:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x22, x0
.Ltmp173:
	adrp	x1, .L.str.8
	add	x1, x1, :lo12:.L.str.8
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp174:
// %bb.25:
.Ltmp176:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x22
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp177:
// %bb.26:
.LBB16_27:
.Ltmp166:
	b	.LBB16_32
.LBB16_28:
.Ltmp172:
	b	.LBB16_32
.LBB16_29:
.Ltmp163:
	mov	x21, x0
	b	.LBB16_36
.LBB16_30:
.Ltmp169:
	mov	x21, x0
	b	.LBB16_36
.LBB16_31:
.Ltmp160:
.LBB16_32:
	mov	x21, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB16_36
.LBB16_33:
.Ltmp157:
	mov	x21, x0
	b	.LBB16_36
.LBB16_34:
.Ltmp178:
	mov	x21, x0
	b	.LBB16_36
.LBB16_35:
.Ltmp175:
	mov	x21, x0
	mov	x0, x22
	bl	__cxa_free_exception
.LBB16_36:
	mov	x0, x20
	bl	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev
	mov	x0, x19
	bl	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev
	mov	x0, x21
	bl	_Unwind_Resume
.Lfunc_end16:
	.size	_ZN9pocketfft6detail11pocketfft_cIeEC2Em, .Lfunc_end16-_ZN9pocketfft6detail11pocketfft_cIeEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail11pocketfft_cIeEC2Em,"aG",@progbits,_ZN9pocketfft6detail11pocketfft_cIeEC2Em,comdat
	.p2align	2
GCC_except_table16:
.Lexception9:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end9-.Lcst_begin9
.Lcst_begin9:
	.uleb128 .Ltmp155-.Lfunc_begin9         // >> Call Site 1 <<
	.uleb128 .Ltmp156-.Ltmp155              //   Call between .Ltmp155 and .Ltmp156
	.uleb128 .Ltmp157-.Lfunc_begin9         //     jumps to .Ltmp157
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp158-.Lfunc_begin9         // >> Call Site 2 <<
	.uleb128 .Ltmp159-.Ltmp158              //   Call between .Ltmp158 and .Ltmp159
	.uleb128 .Ltmp160-.Lfunc_begin9         //     jumps to .Ltmp160
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp167-.Lfunc_begin9         // >> Call Site 3 <<
	.uleb128 .Ltmp168-.Ltmp167              //   Call between .Ltmp167 and .Ltmp168
	.uleb128 .Ltmp169-.Lfunc_begin9         //     jumps to .Ltmp169
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp170-.Lfunc_begin9         // >> Call Site 4 <<
	.uleb128 .Ltmp171-.Ltmp170              //   Call between .Ltmp170 and .Ltmp171
	.uleb128 .Ltmp172-.Lfunc_begin9         //     jumps to .Ltmp172
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp161-.Lfunc_begin9         // >> Call Site 5 <<
	.uleb128 .Ltmp162-.Ltmp161              //   Call between .Ltmp161 and .Ltmp162
	.uleb128 .Ltmp163-.Lfunc_begin9         //     jumps to .Ltmp163
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp164-.Lfunc_begin9         // >> Call Site 6 <<
	.uleb128 .Ltmp165-.Ltmp164              //   Call between .Ltmp164 and .Ltmp165
	.uleb128 .Ltmp166-.Lfunc_begin9         //     jumps to .Ltmp166
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp165-.Lfunc_begin9         // >> Call Site 7 <<
	.uleb128 .Ltmp173-.Ltmp165              //   Call between .Ltmp165 and .Ltmp173
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp173-.Lfunc_begin9         // >> Call Site 8 <<
	.uleb128 .Ltmp174-.Ltmp173              //   Call between .Ltmp173 and .Ltmp174
	.uleb128 .Ltmp175-.Lfunc_begin9         //     jumps to .Ltmp175
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp176-.Lfunc_begin9         // >> Call Site 9 <<
	.uleb128 .Ltmp177-.Ltmp176              //   Call between .Ltmp176 and .Ltmp177
	.uleb128 .Ltmp178-.Lfunc_begin9         //     jumps to .Ltmp178
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp177-.Lfunc_begin9         // >> Call Site 10 <<
	.uleb128 .Lfunc_end16-.Ltmp177          //   Call between .Ltmp177 and .Lfunc_end16
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end9:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail4util20largest_prime_factorEm,"axG",@progbits,_ZN9pocketfft6detail4util20largest_prime_factorEm,comdat
	.weak	_ZN9pocketfft6detail4util20largest_prime_factorEm // -- Begin function _ZN9pocketfft6detail4util20largest_prime_factorEm
	.p2align	2
	.type	_ZN9pocketfft6detail4util20largest_prime_factorEm,@function
_ZN9pocketfft6detail4util20largest_prime_factorEm: // @_ZN9pocketfft6detail4util20largest_prime_factorEm
	.cfi_startproc
// %bb.0:
	tbnz	w0, #0, .LBB17_4
// %bb.1:
	mov	w8, #2
.LBB17_2:                               // =>This Inner Loop Header: Depth=1
	mov	x9, x0
	lsr	x0, x0, #1
	tbz	w9, #1, .LBB17_2
// %bb.3:
	cmp	x0, #9
	b.lo	.LBB17_5
	b	.LBB17_6
.LBB17_4:
	mov	w8, #1
	cmp	x0, #9
	b.hs	.LBB17_6
.LBB17_5:
	cmp	x0, #1
	csel	x0, x0, x8, hi
	ret
.LBB17_6:
	mov	w9, #3
	b	.LBB17_8
.LBB17_7:                               //   in Loop: Header=BB17_8 Depth=1
	add	x9, x9, #2
	mul	x10, x9, x9
	cmp	x10, x0
	b.hi	.LBB17_5
.LBB17_8:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB17_9 Depth 2
	udiv	x10, x0, x9
	msub	x10, x10, x9, x0
	cbnz	x10, .LBB17_7
.LBB17_9:                               //   Parent Loop BB17_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	udiv	x0, x0, x9
	udiv	x8, x0, x9
	msub	x8, x8, x9, x0
	cbz	x8, .LBB17_9
// %bb.10:                              //   in Loop: Header=BB17_8 Depth=1
	mov	x8, x9
	b	.LBB17_7
.Lfunc_end17:
	.size	_ZN9pocketfft6detail4util20largest_prime_factorEm, .Lfunc_end17-_ZN9pocketfft6detail4util20largest_prime_factorEm
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIeEC2Em,"axG",@progbits,_ZN9pocketfft6detail5cfftpIeEC2Em,comdat
	.weak	_ZN9pocketfft6detail5cfftpIeEC2Em // -- Begin function _ZN9pocketfft6detail5cfftpIeEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIeEC2Em,@function
_ZN9pocketfft6detail5cfftpIeEC2Em:      // @_ZN9pocketfft6detail5cfftpIeEC2Em
.Lfunc_begin10:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception10
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	movi	v0.2d, #0000000000000000
	mov	x22, x0
	cmp	x1, #1
	str	x1, [x0]
	str	xzr, [x0, #40]
	stur	q0, [x0, #24]
	str	q0, [x22, #8]!
	b.eq	.LBB18_15
// %bb.1:
	mov	x19, x0
	cbz	x1, .LBB18_16
// %bb.2:
.Ltmp184:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIeE9factorizeEv
.Ltmp185:
// %bb.3:
	ldp	x8, x9, [x19, #24]
	mov	x20, xzr
	subs	x9, x9, x8
	b.eq	.LBB18_6
// %bb.4:
	mov	x10, #-6148914691236517206
	mov	w11, #1
	movk	x10, #43691
	movk	x10, #10922, lsl #48
	smulh	x9, x9, x10
	asr	x10, x9, #2
	add	x10, x10, x9, lsr #63
	ldr	x9, [x19]
	cmp	x10, #1
	csinc	x10, x10, xzr, hi
.LBB18_5:                               // =>This Inner Loop Header: Depth=1
	ldr	x12, [x8], #24
	mul	x11, x12, x11
	cmp	x12, #11
	sub	x14, x12, #1
	csel	x12, x12, xzr, hi
	add	x12, x12, x20
	subs	x10, x10, #1
	udiv	x13, x9, x11
	sub	x13, x13, #1
	madd	x20, x13, x14, x12
	b.ne	.LBB18_5
.LBB18_6:
	ldr	x8, [x19, #16]
	cmp	x8, x20
	b.eq	.LBB18_14
// %bb.7:
	ldr	x8, [x22]
	cbz	x8, .LBB18_9
// %bb.8:
	ldur	x0, [x8, #-8]
	bl	free
.LBB18_9:
	cbz	x20, .LBB18_12
// %bb.10:
	lsl	x8, x20, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB18_19
// %bb.11:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
	b	.LBB18_13
.LBB18_12:
	mov	x8, xzr
.LBB18_13:
	stp	x8, x20, [x19, #8]
.LBB18_14:
.Ltmp188:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv
.Ltmp189:
.LBB18_15:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB18_16:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp179:
	adrp	x1, .L.str.8
	add	x1, x1, :lo12:.L.str.8
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp180:
// %bb.17:
.Ltmp182:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp183:
// %bb.18:
.LBB18_19:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp186:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp187:
// %bb.20:
.LBB18_21:
.Ltmp181:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
	b	.LBB18_23
.LBB18_22:
.Ltmp190:
	mov	x20, x0
.LBB18_23:
	ldr	x0, [x19, #24]
	cbnz	x0, .LBB18_26
// %bb.24:
	ldr	x8, [x22]
	cbnz	x8, .LBB18_27
.LBB18_25:
	mov	x0, x20
	bl	_Unwind_Resume
.LBB18_26:
	bl	_ZdlPv
	ldr	x8, [x22]
	cbz	x8, .LBB18_25
.LBB18_27:
	ldur	x0, [x8, #-8]
	bl	free
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end18:
	.size	_ZN9pocketfft6detail5cfftpIeEC2Em, .Lfunc_end18-_ZN9pocketfft6detail5cfftpIeEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail5cfftpIeEC2Em,"aG",@progbits,_ZN9pocketfft6detail5cfftpIeEC2Em,comdat
	.p2align	2
GCC_except_table18:
.Lexception10:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end10-.Lcst_begin10
.Lcst_begin10:
	.uleb128 .Ltmp184-.Lfunc_begin10        // >> Call Site 1 <<
	.uleb128 .Ltmp189-.Ltmp184              //   Call between .Ltmp184 and .Ltmp189
	.uleb128 .Ltmp190-.Lfunc_begin10        //     jumps to .Ltmp190
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp189-.Lfunc_begin10        // >> Call Site 2 <<
	.uleb128 .Ltmp179-.Ltmp189              //   Call between .Ltmp189 and .Ltmp179
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp179-.Lfunc_begin10        // >> Call Site 3 <<
	.uleb128 .Ltmp180-.Ltmp179              //   Call between .Ltmp179 and .Ltmp180
	.uleb128 .Ltmp181-.Lfunc_begin10        //     jumps to .Ltmp181
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp182-.Lfunc_begin10        // >> Call Site 4 <<
	.uleb128 .Ltmp183-.Ltmp182              //   Call between .Ltmp182 and .Ltmp183
	.uleb128 .Ltmp190-.Lfunc_begin10        //     jumps to .Ltmp190
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp183-.Lfunc_begin10        // >> Call Site 5 <<
	.uleb128 .Ltmp186-.Ltmp183              //   Call between .Ltmp183 and .Ltmp186
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp186-.Lfunc_begin10        // >> Call Site 6 <<
	.uleb128 .Ltmp187-.Ltmp186              //   Call between .Ltmp186 and .Ltmp187
	.uleb128 .Ltmp190-.Lfunc_begin10        //     jumps to .Ltmp190
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp187-.Lfunc_begin10        // >> Call Site 7 <<
	.uleb128 .Lfunc_end18-.Ltmp187          //   Call between .Ltmp187 and .Lfunc_end18
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end10:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev,"axG",@progbits,_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev,comdat
	.weak	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev // -- Begin function _ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev
	.p2align	2
	.type	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev,@function
_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev: // @_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0]
	cbz	x20, .LBB19_6
// %bb.1:
	ldr	x0, [x20, #24]
	cbz	x0, .LBB19_3
// %bb.2:
	bl	_ZdlPv
.LBB19_3:
	ldr	x8, [x20, #8]
	cbz	x8, .LBB19_5
// %bb.4:
	ldur	x0, [x8, #-8]
	bl	free
.LBB19_5:
	mov	x0, x20
	bl	_ZdlPv
.LBB19_6:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end19:
	.size	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev, .Lfunc_end19-_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIeEESt14default_deleteIS3_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZN9pocketfft6detail4util10cost_guessEm
.LCPI20_0:
	.xword	0x3ff199999999999a              // double 1.1000000000000001
	.section	.text._ZN9pocketfft6detail4util10cost_guessEm,"axG",@progbits,_ZN9pocketfft6detail4util10cost_guessEm,comdat
	.weak	_ZN9pocketfft6detail4util10cost_guessEm
	.p2align	2
	.type	_ZN9pocketfft6detail4util10cost_guessEm,@function
_ZN9pocketfft6detail4util10cost_guessEm: // @_ZN9pocketfft6detail4util10cost_guessEm
	.cfi_startproc
// %bb.0:
	movi	d0, #0000000000000000
	mov	x8, x0
	tbnz	w0, #0, .LBB20_3
// %bb.1:
	movi	d0, #0000000000000000
	fmov	d1, #2.00000000
	mov	x9, x0
.LBB20_2:                               // =>This Inner Loop Header: Depth=1
	lsr	x8, x9, #1
	fadd	d0, d0, d1
	mov	w10, w9
	mov	x9, x8
	tbz	w10, #1, .LBB20_2
.LBB20_3:
	adrp	x9, .LCPI20_0
	cmp	x8, #9
	b.hs	.LBB20_7
.LBB20_4:
	cmp	x8, #1
	b.ls	.LBB20_6
// %bb.5:
	ucvtf	d1, x8
	ldr	d2, [x9, :lo12:.LCPI20_0]
	cmp	x8, #6
	fmul	d2, d1, d2
	fcsel	d1, d1, d2, lo
	fadd	d0, d0, d1
.LBB20_6:
	ucvtf	d1, x0
	fmul	d0, d0, d1
	ret
.LBB20_7:
	mov	w10, #3
	ldr	d1, [x9, :lo12:.LCPI20_0]
	b	.LBB20_9
.LBB20_8:                               //   in Loop: Header=BB20_9 Depth=1
	add	x10, x10, #2
	mul	x11, x10, x10
	cmp	x11, x8
	b.hi	.LBB20_4
.LBB20_9:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB20_11 Depth 2
	udiv	x11, x8, x10
	msub	x11, x11, x10, x8
	cbnz	x11, .LBB20_8
// %bb.10:                              //   in Loop: Header=BB20_9 Depth=1
	ucvtf	d2, x10
	cmp	x10, #6
	fmul	d3, d2, d1
	fcsel	d2, d2, d3, lo
.LBB20_11:                              //   Parent Loop BB20_9 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	udiv	x8, x8, x10
	fadd	d0, d2, d0
	udiv	x11, x8, x10
	msub	x11, x11, x10, x8
	cbz	x11, .LBB20_11
	b	.LBB20_8
.Lfunc_end20:
	.size	_ZN9pocketfft6detail4util10cost_guessEm, .Lfunc_end20-_ZN9pocketfft6detail4util10cost_guessEm
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail4util15good_size_cmplxEm,"axG",@progbits,_ZN9pocketfft6detail4util15good_size_cmplxEm,comdat
	.weak	_ZN9pocketfft6detail4util15good_size_cmplxEm // -- Begin function _ZN9pocketfft6detail4util15good_size_cmplxEm
	.p2align	2
	.type	_ZN9pocketfft6detail4util15good_size_cmplxEm,@function
_ZN9pocketfft6detail4util15good_size_cmplxEm: // @_ZN9pocketfft6detail4util15good_size_cmplxEm
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	cmp	x0, #13
	b.hs	.LBB21_2
.LBB21_1:
	mov	x0, x8
	ret
.LBB21_2:
	lsl	x0, x8, #1
	cbz	x0, .LBB21_18
// %bb.3:
	mov	w9, #1
	mov	w10, #11
.LBB21_4:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB21_6 Depth 2
                                        //       Child Loop BB21_8 Depth 3
                                        //         Child Loop BB21_9 Depth 4
                                        //         Child Loop BB21_11 Depth 4
                                        //           Child Loop BB21_12 Depth 5
	cmp	x9, x0
	b.hs	.LBB21_17
// %bb.5:                               //   in Loop: Header=BB21_4 Depth=1
	mov	x11, x9
.LBB21_6:                               //   Parent Loop BB21_4 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB21_8 Depth 3
                                        //         Child Loop BB21_9 Depth 4
                                        //         Child Loop BB21_11 Depth 4
                                        //           Child Loop BB21_12 Depth 5
	cmp	x11, x0
	b.hs	.LBB21_16
// %bb.7:                               //   in Loop: Header=BB21_6 Depth=2
	mov	x12, x11
.LBB21_8:                               //   Parent Loop BB21_4 Depth=1
                                        //     Parent Loop BB21_6 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB21_9 Depth 4
                                        //         Child Loop BB21_11 Depth 4
                                        //           Child Loop BB21_12 Depth 5
	mov	x14, x12
.LBB21_9:                               //   Parent Loop BB21_4 Depth=1
                                        //     Parent Loop BB21_6 Depth=2
                                        //       Parent Loop BB21_8 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	mov	x13, x14
	lsl	x14, x14, #1
	cmp	x13, x8
	b.lo	.LBB21_9
	b	.LBB21_11
.LBB21_10:                              //   in Loop: Header=BB21_11 Depth=4
	add	x13, x13, x13, lsl #1
.LBB21_11:                              //   Parent Loop BB21_4 Depth=1
                                        //     Parent Loop BB21_6 Depth=2
                                        //       Parent Loop BB21_8 Depth=3
                                        // =>      This Loop Header: Depth=4
                                        //           Child Loop BB21_12 Depth 5
	cmp	x13, x8
	b.lo	.LBB21_10
.LBB21_12:                              //   Parent Loop BB21_4 Depth=1
                                        //     Parent Loop BB21_6 Depth=2
                                        //       Parent Loop BB21_8 Depth=3
                                        //         Parent Loop BB21_11 Depth=4
                                        // =>        This Inner Loop Header: Depth=5
	b.ls	.LBB21_1
// %bb.13:                              //   in Loop: Header=BB21_12 Depth=5
	cmp	x13, x0
	csel	x0, x13, x0, lo
	tbnz	w13, #0, .LBB21_15
// %bb.14:                              //   in Loop: Header=BB21_12 Depth=5
	lsr	x13, x13, #1
	cmp	x13, x8
	b.lo	.LBB21_10
	b	.LBB21_12
.LBB21_15:                              //   in Loop: Header=BB21_8 Depth=3
	add	x12, x12, x12, lsl #2
	cmp	x12, x0
	b.lo	.LBB21_8
.LBB21_16:                              //   in Loop: Header=BB21_6 Depth=2
	lsl	x12, x11, #3
	sub	x11, x12, x11
	cmp	x11, x0
	b.lo	.LBB21_6
.LBB21_17:                              //   in Loop: Header=BB21_4 Depth=1
	mul	x9, x9, x10
	cmp	x9, x0
	b.lo	.LBB21_4
.LBB21_18:
	ret
.Lfunc_end21:
	.size	_ZN9pocketfft6detail4util15good_size_cmplxEm, .Lfunc_end21-_ZN9pocketfft6detail4util15good_size_cmplxEm
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN9pocketfft6detail7fftblueIeEC2Em
.LCPI22_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
.LCPI22_1:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
	.section	.text._ZN9pocketfft6detail7fftblueIeEC2Em,"axG",@progbits,_ZN9pocketfft6detail7fftblueIeEC2Em,comdat
	.weak	_ZN9pocketfft6detail7fftblueIeEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail7fftblueIeEC2Em,@function
_ZN9pocketfft6detail7fftblueIeEC2Em:    // @_ZN9pocketfft6detail7fftblueIeEC2Em
.Lfunc_begin11:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception11
// %bb.0:
	sub	sp, sp, #256
	stp	x29, x30, [sp, #176]            // 16-byte Folded Spill
	add	x29, sp, #176
	stp	x26, x25, [sp, #192]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	lsl	x8, x1, #1
	mov	x20, x0
	sub	x0, x8, #1
	str	x1, [x20]
	bl	_ZN9pocketfft6detail4util15good_size_cmplxEm
	add	x19, x20, #16
	mov	x1, x0
	str	x0, [x20, #8]
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIeEC2Em
	ldp	x21, x8, [x20]
	add	x8, x21, x8, lsr #1
	adds	x22, x8, #1
	b.eq	.LBB22_3
// %bb.1:
	lsl	x8, x22, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB22_27
// %bb.2:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
	b	.LBB22_4
.LBB22_3:
	mov	x8, xzr
.LBB22_4:
	add	x9, x8, x21, lsl #5
	lsl	x1, x21, #1
	stp	x8, x22, [x20, #64]
	stp	x8, x9, [x20, #80]
.Ltmp194:
	sub	x0, x29, #56
	bl	_ZN9pocketfft6detail13sincos_2pibynIeEC2Em
.Ltmp195:
// %bb.5:
	adrp	x8, .LCPI22_0
	adrp	x9, .LCPI22_1
	ldr	x10, [x20, #80]
	ldr	q1, [x8, :lo12:.LCPI22_0]
	ldr	q0, [x9, :lo12:.LCPI22_1]
	str	q1, [sp]                        // 16-byte Folded Spill
	stp	q1, q0, [x10]
	ldr	x8, [x20]
	cmp	x8, #2
	b.lo	.LBB22_11
// %bb.6:
	mov	x21, xzr
	mov	x23, xzr
	mov	x22, #-1
	mov	w24, #1
	b	.LBB22_9
.LBB22_7:                               //   in Loop: Header=BB22_9 Depth=1
	add	x8, x25, x9
	ldur	x11, [x29, #-32]
	ldp	x9, x10, [x29, #-48]
	sub	x8, x8, x23
	add	x8, x22, x8
	ldur	x12, [x29, #-16]
	and	x9, x9, x8
	lsr	x8, x8, x10
	add	x9, x11, x9, lsl #5
	add	x8, x12, x8, lsl #5
	ldp	q2, q1, [x9]
	ldr	q0, [x8]
	stp	q0, q2, [sp, #48]               // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stp	q1, q0, [sp, #16]               // 32-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	ldp	q1, q0, [sp, #48]               // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]
	ldurb	w8, [x29, #-65]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-65]
	ldur	q0, [x29, #-80]
.LBB22_8:                               //   in Loop: Header=BB22_9 Depth=1
	ldr	x8, [x20, #80]
	add	x9, x23, x24, lsl #1
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	mvn	x10, x25
	add	x23, x10, x9
	add	x24, x24, #1
	add	x8, x8, x21, lsl #4
	add	x21, x21, #2
	sub	x22, x22, #2
	stp	q1, q0, [x8, #32]
	ldr	x8, [x20]
	cmp	x24, x8
	b.hs	.LBB22_11
.LBB22_9:                               // =>This Inner Loop Header: Depth=1
	add	x9, x23, x21
	lsl	x8, x8, #1
	add	x9, x9, #1
	cmp	x9, x8
	ldur	x9, [x29, #-56]
	csel	x25, xzr, x8, lo
	sub	x8, x23, x25
	add	x8, x21, x8
	add	x8, x8, #1
	cmp	x9, x8, lsl #1
	b.lo	.LBB22_7
// %bb.10:                              //   in Loop: Header=BB22_9 Depth=1
	ldp	x9, x10, [x29, #-48]
	ldur	x11, [x29, #-32]
	ldur	x12, [x29, #-16]
	and	x9, x9, x8
	lsr	x8, x8, x10
	add	x9, x11, x9, lsl #5
	add	x8, x12, x8, lsl #5
	ldp	q2, q1, [x9]
	ldr	q0, [x8]
	stp	q0, q2, [sp, #48]               // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stp	q1, q0, [sp, #16]               // 32-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	ldp	q1, q0, [sp, #48]               // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__addtf3
	b	.LBB22_8
.LBB22_11:
	ldr	x22, [x20, #8]
	lsl	x8, x22, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB22_25
// %bb.12:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	mov	x0, x22
	bl	__floatunditf
	mov	v1.16b, v0.16b
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	__divtf3
	ldr	x22, [x20, #80]
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	ldr	q1, [x22]
	bl	__multf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q1, [x22, #16]
	ldr	q0, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x21]
	ldr	x8, [x20]
	cmp	x8, #2
	b.lo	.LBB22_15
// %bb.13:
	mov	x22, xzr
	add	x23, x21, #32
	mov	x24, #-1
	mov	w25, #1
.LBB22_14:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x20, #80]
	ldr	q0, [sp, #80]                   // 16-byte Folded Reload
	add	x26, x8, x22
	ldr	q1, [x26, #32]
	bl	__multf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q1, [x26, #48]
	ldr	q0, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	x8, [x20, #8]
	add	x9, x23, x22
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	add	x25, x25, #1
	add	x22, x22, #32
	add	x8, x24, x8
	sub	x24, x24, #1
	add	x8, x21, x8, lsl #5
	stp	q1, q0, [x8]
	stp	q1, q0, [x9]
	ldr	x8, [x20]
	cmp	x25, x8
	b.lo	.LBB22_14
.LBB22_15:
	ldr	x9, [x20, #8]
	sub	x9, x9, x8
	cmp	x8, x9
	b.hi	.LBB22_17
// %bb.16:
	add	x9, x9, #1
	add	x10, x8, #1
	cmp	x9, x10
	add	x0, x21, x8, lsl #5
	csinc	x9, x9, x8, hi
	mov	w1, wzr
	sub	x9, x9, x8
	lsl	x2, x9, #5
	bl	memset
.LBB22_17:
.Ltmp197:
	mov	x0, x19
	mov	x1, x21
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
.Ltmp198:
// %bb.18:
	mov	x8, xzr
	mov	x9, #-1
.LBB22_19:                              // =>This Inner Loop Header: Depth=1
	add	x11, x21, x8
	ldr	x10, [x20, #88]
	add	x9, x9, #1
	ldp	q1, q0, [x11]
	add	x10, x10, x8
	add	x8, x8, #32
	stp	q1, q0, [x10]
	ldr	x10, [x20, #8]
	cmp	x9, x10, lsr #1
	b.lo	.LBB22_19
// %bb.20:
	ldur	x0, [x21, #-8]
	bl	free
	ldur	x8, [x29, #-16]
	cbz	x8, .LBB22_22
// %bb.21:
	ldur	x0, [x8, #-8]
	bl	free
.LBB22_22:
	ldur	x8, [x29, #-32]
	cbz	x8, .LBB22_24
// %bb.23:
	ldur	x0, [x8, #-8]
	bl	free
.LBB22_24:
	ldp	x20, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #176]            // 16-byte Folded Reload
	add	sp, sp, #256
	ret
.LBB22_25:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp200:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp201:
// %bb.26:
.LBB22_27:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp191:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp192:
// %bb.28:
.LBB22_29:
.Ltmp193:
	mov	x22, x0
	b	.LBB22_36
.LBB22_30:
.Ltmp199:
	mov	x22, x0
	ldur	x0, [x21, #-8]
	bl	free
	b	.LBB22_32
.LBB22_31:
.Ltmp202:
	mov	x22, x0
.LBB22_32:
	sub	x0, x29, #56
	bl	_ZN9pocketfft6detail13sincos_2pibynIeED2Ev
	b	.LBB22_34
.LBB22_33:
.Ltmp196:
	mov	x22, x0
.LBB22_34:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB22_36
// %bb.35:
	ldur	x0, [x8, #-8]
	bl	free
.LBB22_36:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIeED2Ev
	mov	x0, x22
	bl	_Unwind_Resume
.Lfunc_end22:
	.size	_ZN9pocketfft6detail7fftblueIeEC2Em, .Lfunc_end22-_ZN9pocketfft6detail7fftblueIeEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail7fftblueIeEC2Em,"aG",@progbits,_ZN9pocketfft6detail7fftblueIeEC2Em,comdat
	.p2align	2
GCC_except_table22:
.Lexception11:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end11-.Lcst_begin11
.Lcst_begin11:
	.uleb128 .Lfunc_begin11-.Lfunc_begin11  // >> Call Site 1 <<
	.uleb128 .Ltmp194-.Lfunc_begin11        //   Call between .Lfunc_begin11 and .Ltmp194
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp194-.Lfunc_begin11        // >> Call Site 2 <<
	.uleb128 .Ltmp195-.Ltmp194              //   Call between .Ltmp194 and .Ltmp195
	.uleb128 .Ltmp196-.Lfunc_begin11        //     jumps to .Ltmp196
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp195-.Lfunc_begin11        // >> Call Site 3 <<
	.uleb128 .Ltmp197-.Ltmp195              //   Call between .Ltmp195 and .Ltmp197
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp197-.Lfunc_begin11        // >> Call Site 4 <<
	.uleb128 .Ltmp198-.Ltmp197              //   Call between .Ltmp197 and .Ltmp198
	.uleb128 .Ltmp199-.Lfunc_begin11        //     jumps to .Ltmp199
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp198-.Lfunc_begin11        // >> Call Site 5 <<
	.uleb128 .Ltmp200-.Ltmp198              //   Call between .Ltmp198 and .Ltmp200
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp200-.Lfunc_begin11        // >> Call Site 6 <<
	.uleb128 .Ltmp201-.Ltmp200              //   Call between .Ltmp200 and .Ltmp201
	.uleb128 .Ltmp202-.Lfunc_begin11        //     jumps to .Ltmp202
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp201-.Lfunc_begin11        // >> Call Site 7 <<
	.uleb128 .Ltmp191-.Ltmp201              //   Call between .Ltmp201 and .Ltmp191
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp191-.Lfunc_begin11        // >> Call Site 8 <<
	.uleb128 .Ltmp192-.Ltmp191              //   Call between .Ltmp191 and .Ltmp192
	.uleb128 .Ltmp193-.Lfunc_begin11        //     jumps to .Ltmp193
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp192-.Lfunc_begin11        // >> Call Site 9 <<
	.uleb128 .Lfunc_end22-.Ltmp192          //   Call between .Ltmp192 and .Lfunc_end22
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end11:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev,"axG",@progbits,_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev,comdat
	.weak	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev // -- Begin function _ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev
	.p2align	2
	.type	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev,@function
_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev: // @_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0]
	cbz	x20, .LBB23_8
// %bb.1:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB23_3
// %bb.2:
	ldur	x0, [x8, #-8]
	bl	free
.LBB23_3:
	ldr	x0, [x20, #40]
	cbz	x0, .LBB23_5
// %bb.4:
	bl	_ZdlPv
.LBB23_5:
	ldr	x8, [x20, #24]
	cbz	x8, .LBB23_7
// %bb.6:
	ldur	x0, [x8, #-8]
	bl	free
.LBB23_7:
	mov	x0, x20
	bl	_ZdlPv
.LBB23_8:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end23:
	.size	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev, .Lfunc_end23-_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIeEESt14default_deleteIS3_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIeE9factorizeEv,"axG",@progbits,_ZN9pocketfft6detail5cfftpIeE9factorizeEv,comdat
	.weak	_ZN9pocketfft6detail5cfftpIeE9factorizeEv // -- Begin function _ZN9pocketfft6detail5cfftpIeE9factorizeEv
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIeE9factorizeEv,@function
_ZN9pocketfft6detail5cfftpIeE9factorizeEv: // @_ZN9pocketfft6detail5cfftpIeE9factorizeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	x24, [x0]
	mov	x19, x0
	tst	x24, #0x7
	b.eq	.LBB24_7
// %bb.1:
	mov	x25, x24
.LBB24_2:
	tst	x25, #0x3
	b.eq	.LBB24_16
// %bb.3:
	mov	x24, x25
.LBB24_4:
	tbnz	w24, #0, .LBB24_32
// %bb.5:
	ldp	x8, x9, [x19, #32]
	cmp	x8, x9
	b.eq	.LBB24_25
// %bb.6:
	mov	w9, #2
	stp	xzr, xzr, [x8, #8]
	str	x9, [x8]
	ldp	x21, x25, [x19, #24]
	add	x8, x25, #24
	str	x8, [x19, #32]
	b	.LBB24_31
.LBB24_7:
	ldr	x8, [x19, #32]
	mov	x27, #9223372036854775800
	mov	w28, #24
	mov	w26, #8
	b	.LBB24_9
.LBB24_8:                               //   in Loop: Header=BB24_9 Depth=1
	stp	xzr, xzr, [x8, #8]
	str	x26, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	lsr	x25, x24, #3
	tst	x24, #0x38
	mov	x24, x25
	b.ne	.LBB24_2
.LBB24_9:                               // =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB24_8
// %bb.10:                              //   in Loop: Header=BB24_9 Depth=1
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB24_55
// %bb.11:                              //   in Loop: Header=BB24_9 Depth=1
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x25, x11, x8, ne
	add	x8, x25, x25, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x23, x23, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x23, #8]
	str	x26, [x23]
	b.lt	.LBB24_13
// %bb.12:                              //   in Loop: Header=BB24_9 Depth=1
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB24_13:                              //   in Loop: Header=BB24_9 Depth=1
	cbz	x20, .LBB24_15
// %bb.14:                              //   in Loop: Header=BB24_9 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB24_15:                              //   in Loop: Header=BB24_9 Depth=1
	madd	x9, x25, x28, x22
	add	x8, x23, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	lsr	x25, x24, #3
	tst	x24, #0x38
	mov	x24, x25
	b.eq	.LBB24_9
	b	.LBB24_2
.LBB24_16:
	ldr	x8, [x19, #32]
	mov	x27, #9223372036854775800
	mov	w28, #24
	mov	w26, #4
	b	.LBB24_18
.LBB24_17:                              //   in Loop: Header=BB24_18 Depth=1
	stp	xzr, xzr, [x8, #8]
	str	x26, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	lsr	x24, x25, #2
	tst	x25, #0xc
	mov	x25, x24
	b.ne	.LBB24_4
.LBB24_18:                              // =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB24_17
// %bb.19:                              //   in Loop: Header=BB24_18 Depth=1
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB24_55
// %bb.20:                              //   in Loop: Header=BB24_18 Depth=1
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x24, x11, x8, ne
	add	x8, x24, x24, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x23, x23, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x23, #8]
	str	x26, [x23]
	b.lt	.LBB24_22
// %bb.21:                              //   in Loop: Header=BB24_18 Depth=1
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB24_22:                              //   in Loop: Header=BB24_18 Depth=1
	cbz	x20, .LBB24_24
// %bb.23:                              //   in Loop: Header=BB24_18 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB24_24:                              //   in Loop: Header=BB24_18 Depth=1
	madd	x9, x24, x28, x22
	add	x8, x23, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	lsr	x24, x25, #2
	tst	x25, #0xc
	mov	x25, x24
	b.eq	.LBB24_18
	b	.LBB24_4
.LBB24_25:
	ldr	x20, [x19, #24]
	sub	x22, x8, x20
	mov	x8, #9223372036854775800
	cmp	x22, x8
	b.eq	.LBB24_55
// %bb.26:
	mov	x9, #-6148914691236517206
	asr	x8, x22, #3
	movk	x9, #43691
	cmp	x22, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x26, x11, x8, ne
	add	x8, x26, x26, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	mov	w8, #24
	mov	x21, x0
	cmp	x22, #1
	madd	x25, x23, x8, x0
	mov	w8, #2
	stp	xzr, xzr, [x25, #8]
	str	x8, [x25]
	b.lt	.LBB24_28
// %bb.27:
	mov	x0, x21
	mov	x1, x20
	mov	x2, x22
	bl	memmove
.LBB24_28:
	add	x22, x25, #24
	cbz	x20, .LBB24_30
// %bb.29:
	mov	x0, x20
	bl	_ZdlPv
.LBB24_30:
	mov	w8, #24
	stp	x21, x22, [x19, #24]
	madd	x8, x26, x8, x21
	str	x8, [x19, #40]
.LBB24_31:
	ldr	x8, [x25]
	lsr	x24, x24, #1
	ldr	x9, [x21]
	str	x8, [x21]
	str	x9, [x25]
.LBB24_32:
	cmp	x24, #9
	b.hs	.LBB24_36
.LBB24_33:
	cmp	x24, #1
	b.ls	.LBB24_54
// %bb.34:
	ldp	x8, x9, [x19, #32]
	cmp	x8, x9
	b.eq	.LBB24_48
// %bb.35:
	stp	xzr, xzr, [x8, #8]
	str	x24, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	b	.LBB24_54
.LBB24_36:
	mov	w25, #3
	mov	x27, #9223372036854775800
	mov	w28, #24
	b	.LBB24_38
.LBB24_37:                              //   in Loop: Header=BB24_38 Depth=1
	add	x25, x25, #2
	mul	x8, x25, x25
	cmp	x8, x24
	b.hi	.LBB24_33
.LBB24_38:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB24_41 Depth 2
	udiv	x8, x24, x25
	msub	x8, x8, x25, x24
	cbnz	x8, .LBB24_37
// %bb.39:                              //   in Loop: Header=BB24_38 Depth=1
	ldr	x8, [x19, #32]
	b	.LBB24_41
.LBB24_40:                              //   in Loop: Header=BB24_41 Depth=2
	stp	xzr, xzr, [x8, #8]
	str	x25, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	udiv	x24, x24, x25
	udiv	x9, x24, x25
	msub	x9, x9, x25, x24
	cbnz	x9, .LBB24_37
.LBB24_41:                              //   Parent Loop BB24_38 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB24_40
// %bb.42:                              //   in Loop: Header=BB24_41 Depth=2
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB24_55
// %bb.43:                              //   in Loop: Header=BB24_41 Depth=2
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x26, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x26, xzr, ne
	adds	x8, x8, x26
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x23, x11, x8, ne
	add	x8, x23, x23, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x26, x26, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x26, #8]
	str	x25, [x26]
	b.lt	.LBB24_45
// %bb.44:                              //   in Loop: Header=BB24_41 Depth=2
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB24_45:                              //   in Loop: Header=BB24_41 Depth=2
	cbz	x20, .LBB24_47
// %bb.46:                              //   in Loop: Header=BB24_41 Depth=2
	mov	x0, x20
	bl	_ZdlPv
.LBB24_47:                              //   in Loop: Header=BB24_41 Depth=2
	madd	x9, x23, x28, x22
	add	x8, x26, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	udiv	x24, x24, x25
	udiv	x9, x24, x25
	msub	x9, x9, x25, x24
	cbz	x9, .LBB24_41
	b	.LBB24_37
.LBB24_48:
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	mov	x8, #9223372036854775800
	cmp	x21, x8
	b.eq	.LBB24_55
// %bb.49:
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x25, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x25, xzr, ne
	adds	x8, x8, x25
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x23, x11, x8, ne
	add	x8, x23, x23, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	mov	w8, #24
	mov	x22, x0
	cmp	x21, #1
	madd	x25, x25, x8, x0
	stp	xzr, xzr, [x25, #8]
	str	x24, [x25]
	b.lt	.LBB24_51
// %bb.50:
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB24_51:
	add	x21, x25, #24
	cbz	x20, .LBB24_53
// %bb.52:
	mov	x0, x20
	bl	_ZdlPv
.LBB24_53:
	mov	w8, #24
	stp	x22, x21, [x19, #24]
	madd	x8, x23, x8, x22
	str	x8, [x19, #40]
.LBB24_54:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB24_55:
	adrp	x0, .L.str.2
	add	x0, x0, :lo12:.L.str.2
	bl	_ZSt20__throw_length_errorPKc
.Lfunc_end24:
	.size	_ZN9pocketfft6detail5cfftpIeE9factorizeEv, .Lfunc_end24-_ZN9pocketfft6detail5cfftpIeE9factorizeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv,"axG",@progbits,_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv,comdat
	.weak	_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv // -- Begin function _ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv,@function
_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv: // @_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #352
	stp	x29, x30, [sp, #256]            // 16-byte Folded Spill
	add	x29, sp, #256
	stp	x28, x27, [sp, #272]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #288]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #304]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #320]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #336]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x24, x0
	ldr	x1, [x0]
	sub	x0, x29, #64
	bl	_ZN9pocketfft6detail13sincos_2pibynIeEC2Em
	ldp	x8, x9, [x24, #24]
	cmp	x9, x8
	b.eq	.LBB25_19
// %bb.1:
	mov	x26, #-6148914691236517206
	mov	x21, xzr
	mov	x25, xzr
	mov	w11, #1
	movk	x26, #43691
	b	.LBB25_4
.LBB25_2:                               //   in Loop: Header=BB25_4 Depth=1
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	add	x21, x21, x8
.LBB25_3:                               //   in Loop: Header=BB25_4 Depth=1
	ldp	x8, x9, [x24, #24]
	add	x25, x25, #1
	mov	x11, x27
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB25_19
.LBB25_4:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB25_8 Depth 2
                                        //       Child Loop BB25_11 Depth 3
                                        //     Child Loop BB25_17 Depth 2
	mov	w9, #24
	madd	x8, x25, x9, x8
	ldp	x9, x10, [x24]
	ldr	x19, [x8]
	add	x10, x10, x21, lsl #5
	mul	x27, x19, x11
	cmp	x19, #2
	str	x10, [x8, #8]
	udiv	x12, x9, x27
	sub	x9, x19, #1
	sub	x13, x12, #1
	madd	x21, x13, x9, x21
	b.lo	.LBB25_3
// %bb.5:                               //   in Loop: Header=BB25_4 Depth=1
	stp	x27, x21, [sp, #8]              // 16-byte Folded Spill
	mov	x21, x24
	cmp	x12, #2
	str	x25, [sp, #104]                 // 8-byte Folded Spill
	str	x19, [sp, #48]                  // 8-byte Folded Spill
	b.lo	.LBB25_13
// %bb.6:                               //   in Loop: Header=BB25_4 Depth=1
	lsl	x28, x11, #1
	neg	x20, x11
	mov	x25, x11
	mov	w9, #1
	mov	x27, x12
	str	x11, [sp, #40]                  // 8-byte Folded Spill
	stp	x28, x13, [sp, #24]             // 16-byte Folded Spill
	b	.LBB25_8
.LBB25_7:                               //   in Loop: Header=BB25_8 Depth=2
	ldp	x19, x9, [sp, #48]              // 16-byte Folded Reload
	ldp	x13, x11, [sp, #32]             // 16-byte Folded Reload
	ldr	x8, [sp, #24]                   // 8-byte Folded Reload
	add	x9, x9, #1
	cmp	x9, x19
	sub	x20, x20, x11
	add	x25, x25, x11
	add	x28, x28, x8
	b.eq	.LBB25_13
.LBB25_8:                               //   Parent Loop BB25_4 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB25_11 Depth 3
	sub	x8, x9, #1
	mov	x23, x28
	mov	x26, x25
	mov	x24, x20
	mul	x8, x8, x13
	mov	w19, #1
	str	x9, [sp, #56]                   // 8-byte Folded Spill
	sub	x22, x8, #1
	b	.LBB25_11
.LBB25_9:                               //   in Loop: Header=BB25_11 Depth=3
	ldp	x9, x10, [x29, #-56]
	add	x8, x24, x8
	ldur	x11, [x29, #-40]
	ldur	x12, [x29, #-24]
	and	x9, x9, x8
	lsr	x8, x8, x10
	add	x9, x11, x9, lsl #5
	add	x8, x12, x8, lsl #5
	ldp	q2, q1, [x9]
	ldr	q0, [x8]
	stp	q0, q2, [sp, #112]              // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stp	q1, q0, [sp, #64]               // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #112]              // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	ldr	q0, [sp, #128]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	ldurb	w8, [x29, #-65]
	mov	x12, x27
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-65]
	ldur	q0, [x29, #-80]
.LBB25_10:                              //   in Loop: Header=BB25_11 Depth=3
	ldr	x8, [x21, #24]
	mov	w9, #24
	ldr	x10, [sp, #104]                 // 8-byte Folded Reload
	add	x24, x24, x20
	add	x26, x26, x25
	add	x23, x23, x28
	madd	x8, x10, x9, x8
	add	x9, x22, x19
	add	x19, x19, #1
	cmp	x19, x12
	ldr	x8, [x8, #8]
	add	x8, x8, x9, lsl #5
	stp	q1, q0, [x8]
	b.eq	.LBB25_7
.LBB25_11:                              //   Parent Loop BB25_4 Depth=1
                                        //     Parent Loop BB25_8 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldur	x8, [x29, #-64]
	cmp	x23, x8
	b.hi	.LBB25_9
// %bb.12:                              //   in Loop: Header=BB25_11 Depth=3
	ldp	x8, x9, [x29, #-56]
	ldur	x10, [x29, #-40]
	ldur	x11, [x29, #-24]
	and	x8, x8, x26
	lsr	x9, x26, x9
	add	x8, x10, x8, lsl #5
	add	x9, x11, x9, lsl #5
	ldp	q2, q1, [x8]
	ldr	q0, [x9]
	stp	q0, q2, [sp, #112]              // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q1, q0, [sp, #64]               // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #112]              // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	ldr	q0, [sp, #128]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	mov	x12, x27
	b	.LBB25_10
.LBB25_13:                              //   in Loop: Header=BB25_4 Depth=1
	mov	x24, x21
	mov	x26, #-6148914691236517206
	ldp	x27, x21, [sp, #8]              // 16-byte Folded Reload
	movk	x26, #43691
	cmp	x19, #12
	ldr	x25, [sp, #104]                 // 8-byte Folded Reload
	b.lo	.LBB25_3
// %bb.14:                              //   in Loop: Header=BB25_4 Depth=1
	ldr	x8, [x24, #24]
	mov	w10, #24
	ldr	x9, [x24, #8]
	mul	x22, x12, x11
	mov	x20, xzr
	mov	x23, xzr
	madd	x8, x25, x10, x8
	add	x9, x9, x21, lsl #5
	str	x9, [x8, #16]
	b	.LBB25_17
.LBB25_15:                              //   in Loop: Header=BB25_17 Depth=2
	ldp	x10, x11, [x29, #-56]
	sub	x8, x9, x8
	ldur	x9, [x29, #-40]
	ldur	x12, [x29, #-24]
	and	x10, x10, x8
	lsr	x8, x8, x11
	add	x9, x9, x10, lsl #5
	add	x8, x12, x8, lsl #5
	ldp	q2, q1, [x9]
	ldr	q0, [x8]
	stp	q0, q2, [sp, #112]              // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stp	q1, q0, [sp, #64]               // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #112]              // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	ldr	q0, [sp, #128]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]
	ldurb	w8, [x29, #-81]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-81]
	ldp	q1, q0, [x29, #-112]            // 16-byte Folded Reload
.LBB25_16:                              //   in Loop: Header=BB25_17 Depth=2
	ldr	x8, [x24, #24]
	mov	w9, #24
	add	x23, x23, #1
	subs	x19, x19, #1
	madd	x8, x25, x9, x8
	ldr	x8, [x8, #16]
	add	x8, x8, x20
	add	x20, x20, #32
	stp	q1, q0, [x8]
	b.eq	.LBB25_2
.LBB25_17:                              //   Parent Loop BB25_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mul	x8, x22, x23
	ldur	x9, [x29, #-64]
	cmp	x9, x8, lsl #1
	b.lo	.LBB25_15
// %bb.18:                              //   in Loop: Header=BB25_17 Depth=2
	ldp	x9, x10, [x29, #-56]
	ldur	x11, [x29, #-40]
	ldur	x12, [x29, #-24]
	and	x9, x9, x8
	lsr	x8, x8, x10
	add	x9, x11, x9, lsl #5
	add	x8, x12, x8, lsl #5
	ldp	q2, q1, [x9]
	ldr	q0, [x8]
	stp	q0, q2, [sp, #112]              // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stp	q1, q0, [sp, #64]               // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #112]              // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	ldr	q0, [sp, #128]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	b	.LBB25_16
.LBB25_19:
	ldur	x8, [x29, #-24]
	cbz	x8, .LBB25_21
// %bb.20:
	ldur	x0, [x8, #-8]
	bl	free
.LBB25_21:
	ldur	x8, [x29, #-40]
	cbz	x8, .LBB25_23
// %bb.22:
	ldur	x0, [x8, #-8]
	bl	free
.LBB25_23:
	ldp	x20, x19, [sp, #336]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #320]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #304]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #288]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #272]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #256]            // 16-byte Folded Reload
	add	sp, sp, #352
	ret
.Lfunc_end25:
	.size	_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv, .Lfunc_end25-_ZN9pocketfft6detail5cfftpIeE12comp_twiddleEv
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIeEC2Em
.LCPI26_0:
	.xword	0x8469898cc51701b8              // fp128 0.785398163397448309615660845819875699
	.xword	0x3ffe921fb54442d1
.LCPI26_1:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
.LCPI26_2:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIeEC2Em,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIeEC2Em,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIeEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIeEC2Em,@function
_ZN9pocketfft6detail13sincos_2pibynIeEC2Em: // @_ZN9pocketfft6detail13sincos_2pibynIeEC2Em
.Lfunc_begin12:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception12
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	str	x25, [sp, #64]                  // 8-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	movi	v0.2d, #0000000000000000
	mov	x19, x0
	mov	x22, x0
	str	x1, [x0]
	mov	x0, x1
	mov	x20, x1
	str	q0, [x22, #24]!
	bl	__floatunditf
	mov	v1.16b, v0.16b
	add	x8, x20, #2
	movi	v0.2d, #0000000000000000
	mov	x21, xzr
	lsr	x23, x8, #1
	mov	w8, #1
	stur	q0, [x19, #40]
.LBB26_1:                               // =>This Inner Loop Header: Depth=1
	add	x21, x21, #1
	lsl	x25, x8, x21
	lsl	x9, x25, x21
	cmp	x9, x23
	b.lo	.LBB26_1
// %bb.2:
	adrp	x8, .LCPI26_0
	ldr	q0, [x8, :lo12:.LCPI26_0]
	bl	__divtf3
	lsl	x8, x25, #5
	sub	x24, x25, #1
	add	x0, x8, #64
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	stp	x24, x21, [x19, #8]
	bl	malloc
	cbz	x0, .LBB26_21
// %bb.3:
	adrp	x9, .LCPI26_1
	adrp	x10, .LCPI26_2
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	ldr	q0, [x9, :lo12:.LCPI26_1]
	ldr	q1, [x10, :lo12:.LCPI26_2]
	stur	x0, [x8, #-8]
	stp	x8, x25, [x19, #24]
	stp	q1, q0, [sp]                    // 32-byte Folded Spill
	stp	q0, q1, [x8]
	cbz	x21, .LBB26_9
// %bb.4:
	mov	x24, xzr
	mov	w21, #1
.LBB26_5:                               // =>This Inner Loop Header: Depth=1
.Ltmp203:
	mov	x0, x21
	mov	x1, x20
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	bl	_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme
.Ltmp204:
// %bb.6:                               //   in Loop: Header=BB26_5 Depth=1
	ldr	x8, [x19, #24]
	add	x21, x21, #1
	add	x8, x8, x24
	add	x24, x24, #32
	stp	q0, q1, [x8, #32]
	ldr	x8, [x19, #32]
	cmp	x21, x8
	b.lo	.LBB26_5
// %bb.7:
	ldr	x24, [x19, #8]
	ldp	x8, x9, [x19, #40]
	add	x23, x24, x23
	add	x24, x24, #1
	udiv	x21, x23, x24
	cmp	x9, x21
	b.ne	.LBB26_10
.LBB26_8:
	ldp	q0, q1, [sp]                    // 32-byte Folded Reload
	cmp	x9, #2
	stp	q1, q0, [x8]
	b.hs	.LBB26_17
	b	.LBB26_20
.LBB26_9:
	mov	x9, xzr
	add	x23, x24, x23
	add	x24, x24, #1
	ldr	x8, [x19, #40]
	udiv	x21, x23, x24
	cmp	x9, x21
	b.eq	.LBB26_8
.LBB26_10:
	cbz	x8, .LBB26_12
// %bb.11:
	ldur	x0, [x8, #-8]
	bl	free
.LBB26_12:
	cmp	x24, x23
	b.ls	.LBB26_14
// %bb.13:
	mov	x8, xzr
	b	.LBB26_16
.LBB26_14:
	lsl	x8, x21, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB26_23
// %bb.15:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
.LBB26_16:
	mov	x9, x21
	stp	x8, x21, [x19, #40]
	ldp	q0, q1, [sp]                    // 32-byte Folded Reload
	cmp	x9, #2
	stp	q1, q0, [x8]
	b.lo	.LBB26_20
.LBB26_17:
	mov	x21, xzr
	mov	w23, #1
.LBB26_18:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #8]
	madd	x0, x23, x8, x23
.Ltmp208:
	mov	x1, x20
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	bl	_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme
.Ltmp209:
// %bb.19:                              //   in Loop: Header=BB26_18 Depth=1
	ldr	x8, [x19, #40]
	add	x23, x23, #1
	add	x8, x8, x21
	add	x21, x21, #32
	stp	q0, q1, [x8, #32]
	ldr	x8, [x19, #48]
	cmp	x23, x8
	b.lo	.LBB26_18
.LBB26_20:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	ldr	x25, [sp, #64]                  // 8-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB26_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp211:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp212:
// %bb.22:
.LBB26_23:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp206:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp207:
// %bb.24:
.LBB26_25:
.Ltmp213:
	b	.LBB26_28
.LBB26_26:
.Ltmp210:
	b	.LBB26_28
.LBB26_27:
.Ltmp205:
.LBB26_28:
	mov	x20, x0
	ldr	x8, [x19, #40]
	cbnz	x8, .LBB26_31
// %bb.29:
	ldr	x8, [x22]
	cbnz	x8, .LBB26_32
.LBB26_30:
	mov	x0, x20
	bl	_Unwind_Resume
.LBB26_31:
	ldur	x0, [x8, #-8]
	bl	free
	ldr	x8, [x22]
	cbz	x8, .LBB26_30
.LBB26_32:
	ldur	x0, [x8, #-8]
	bl	free
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end26:
	.size	_ZN9pocketfft6detail13sincos_2pibynIeEC2Em, .Lfunc_end26-_ZN9pocketfft6detail13sincos_2pibynIeEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail13sincos_2pibynIeEC2Em,"aG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIeEC2Em,comdat
	.p2align	2
GCC_except_table26:
.Lexception12:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end12-.Lcst_begin12
.Lcst_begin12:
	.uleb128 .Lfunc_begin12-.Lfunc_begin12  // >> Call Site 1 <<
	.uleb128 .Ltmp203-.Lfunc_begin12        //   Call between .Lfunc_begin12 and .Ltmp203
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp203-.Lfunc_begin12        // >> Call Site 2 <<
	.uleb128 .Ltmp204-.Ltmp203              //   Call between .Ltmp203 and .Ltmp204
	.uleb128 .Ltmp205-.Lfunc_begin12        //     jumps to .Ltmp205
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp208-.Lfunc_begin12        // >> Call Site 3 <<
	.uleb128 .Ltmp209-.Ltmp208              //   Call between .Ltmp208 and .Ltmp209
	.uleb128 .Ltmp210-.Lfunc_begin12        //     jumps to .Ltmp210
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp209-.Lfunc_begin12        // >> Call Site 4 <<
	.uleb128 .Ltmp211-.Ltmp209              //   Call between .Ltmp209 and .Ltmp211
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp211-.Lfunc_begin12        // >> Call Site 5 <<
	.uleb128 .Ltmp212-.Ltmp211              //   Call between .Ltmp211 and .Ltmp212
	.uleb128 .Ltmp213-.Lfunc_begin12        //     jumps to .Ltmp213
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp212-.Lfunc_begin12        // >> Call Site 6 <<
	.uleb128 .Ltmp206-.Ltmp212              //   Call between .Ltmp212 and .Ltmp206
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp206-.Lfunc_begin12        // >> Call Site 7 <<
	.uleb128 .Ltmp207-.Ltmp206              //   Call between .Ltmp206 and .Ltmp207
	.uleb128 .Ltmp213-.Lfunc_begin12        //     jumps to .Ltmp213
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp207-.Lfunc_begin12        // >> Call Site 8 <<
	.uleb128 .Lfunc_end26-.Ltmp207          //   Call between .Ltmp207 and .Lfunc_end26
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end12:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIeED2Ev,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIeED2Ev,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIeED2Ev // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIeED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIeED2Ev,@function
_ZN9pocketfft6detail13sincos_2pibynIeED2Ev: // @_ZN9pocketfft6detail13sincos_2pibynIeED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x8, [x0, #40]
	cbz	x8, .LBB27_2
// %bb.1:
	ldur	x0, [x8, #-8]
	bl	free
.LBB27_2:
	ldr	x8, [x19, #24]
	cbz	x8, .LBB27_4
// %bb.3:
	ldur	x0, [x8, #-8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	free
.LBB27_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end27:
	.size	_ZN9pocketfft6detail13sincos_2pibynIeED2Ev, .Lfunc_end27-_ZN9pocketfft6detail13sincos_2pibynIeED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme,@function
_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme: // @_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	add	x29, sp, #160
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mov	x8, x0
	lsl	x0, x0, #3
	cmp	x0, x1, lsl #2
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	b.hs	.LBB28_4
// %bb.1:
	lsl	x9, x1, #1
	subs	x8, x0, x9
	b.hs	.LBB28_7
// %bb.2:
	cmp	x0, x1
	b.hs	.LBB28_11
// %bb.3:
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	cosl
	b	.LBB28_15
.LBB28_4:
	sub	x8, x1, x8
	lsl	x9, x1, #1
	lsl	x0, x8, #3
	subs	x8, x0, x9
	b.hs	.LBB28_9
// %bb.5:
	cmp	x0, x1
	b.hs	.LBB28_13
// %bb.6:
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	cosl
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	sinl
	str	q0, [sp, #64]
	ldrb	w8, [sp, #79]
	eor	w8, w8, #0x80
	strb	w8, [sp, #79]
	ldr	q1, [sp, #64]
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB28_7:
	cmp	x8, x1
	b.hs	.LBB28_14
// %bb.8:
	mov	x0, x8
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	sinl
	str	q0, [sp, #32]
	ldrb	w8, [sp, #47]
	eor	w8, w8, #0x80
	strb	w8, [sp, #47]
	ldr	q0, [sp, #32]
	b	.LBB28_12
.LBB28_9:
	cmp	x8, x1
	b.hs	.LBB28_16
// %bb.10:
	mov	x0, x8
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	sinl
	stur	q0, [x29, #-64]
	ldurb	w8, [x29, #-49]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-49]
	ldur	q0, [x29, #-64]
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	cosl
	stur	q0, [x29, #-48]
	ldurb	w8, [x29, #-33]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-33]
	ldur	q1, [x29, #-48]
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB28_11:
	sub	x0, x9, x0
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	sinl
.LBB28_12:
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	cosl
	mov	v1.16b, v0.16b
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB28_13:
	sub	x0, x9, x0
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	sinl
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	cosl
	str	q0, [sp, #80]
	ldrb	w8, [sp, #95]
	eor	w8, w8, #0x80
	strb	w8, [sp, #95]
	ldr	q1, [sp, #80]
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB28_14:
	sub	x0, x9, x8
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	cosl
	str	q0, [sp, #48]
	ldrb	w8, [sp, #63]
	eor	w8, w8, #0x80
	strb	w8, [sp, #63]
	ldr	q0, [sp, #48]
.LBB28_15:
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	sinl
	mov	v1.16b, v0.16b
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB28_16:
	sub	x0, x9, x8
	bl	__floatunditf
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	cosl
	stur	q0, [x29, #-32]
	ldurb	w8, [x29, #-17]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-17]
	ldur	q0, [x29, #-32]
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	sinl
	stur	q0, [x29, #-16]
	ldurb	w8, [x29, #-1]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-1]
	ldur	q1, [x29, #-16]
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end28:
	.size	_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme, .Lfunc_end28-_ZN9pocketfft6detail13sincos_2pibynIeE4calcEmme
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIeED2Ev,"axG",@progbits,_ZN9pocketfft6detail5cfftpIeED2Ev,comdat
	.weak	_ZN9pocketfft6detail5cfftpIeED2Ev // -- Begin function _ZN9pocketfft6detail5cfftpIeED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIeED2Ev,@function
_ZN9pocketfft6detail5cfftpIeED2Ev:      // @_ZN9pocketfft6detail5cfftpIeED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x0, [x0, #24]
	cbz	x0, .LBB29_2
// %bb.1:
	bl	_ZdlPv
.LBB29_2:
	ldr	x8, [x19, #8]
	cbz	x8, .LBB29_4
// %bb.3:
	ldur	x0, [x8, #-8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	free
.LBB29_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end29:
	.size	_ZN9pocketfft6detail5cfftpIeED2Ev, .Lfunc_end29-_ZN9pocketfft6detail5cfftpIeED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
.LCPI30_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
	.section	.text._ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,@function
_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e: // @_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
.Lfunc_begin13:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception13
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x28, x27, [sp, #64]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	ldr	x23, [x0]
	mov	x20, x1
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	cbz	x23, .LBB30_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB30_4
// %bb.2:
	mov	v1.16b, v0.16b
	ldr	q0, [x20]
	bl	__multf3
	ldr	q1, [x20, #16]
	str	q0, [x20]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [x20, #16]
	b	.LBB30_31
.LBB30_3:
	mov	x27, xzr
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.ne	.LBB30_6
	b	.LBB30_23
.LBB30_4:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB30_32
// %bb.5:
	add	x8, x0, #64
	and	x27, x8, #0xffffffffffffffc0
	stur	x0, [x27, #-8]
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.eq	.LBB30_23
.LBB30_6:
	mov	x26, #-6148914691236517206
	str	x27, [sp, #8]                   // 8-byte Folded Spill
	mov	x22, x27
	adrp	x27, .LJTI30_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x20
	add	x27, x27, :lo12:.LJTI30_0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB30_12
.LBB30_7:
	adr	x10, .LBB30_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB30_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp222:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp223:
	mov	x0, x21
	mov	x21, x22
	b	.LBB30_16
.LBB30_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp220:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp221:
	mov	x0, x21
	mov	x21, x22
	b	.LBB30_16
.LBB30_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp226:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp227:
	mov	x0, x21
	mov	x21, x22
	b	.LBB30_16
.LBB30_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp218:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp219:
	mov	x0, x21
	mov	x21, x22
	b	.LBB30_16
.LBB30_12:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp228:
	mov	x0, x19
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
.Ltmp229:
	mov	x0, x22
	b	.LBB30_16
.LBB30_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp216:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp217:
	mov	x0, x21
	mov	x21, x22
	b	.LBB30_16
.LBB30_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp224:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp225:
	mov	x0, x21
	mov	x21, x22
	b	.LBB30_16
.LBB30_15:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp214:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp215:
	mov	x0, x21
	mov	x21, x22
.LBB30_16:
	ldp	x8, x9, [x19, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB30_18
// %bb.17:
	ldr	x23, [x19]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB30_7
	b	.LBB30_12
.LBB30_18:
	ldr	x27, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x20
	b.eq	.LBB30_23
// %bb.19:
	adrp	x8, .LCPI30_0
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	x22, [x19]
	ldr	q1, [x8, :lo12:.LCPI30_0]
	bl	__eqtf2
	cbz	w0, .LBB30_27
// %bb.20:
	cbz	x22, .LBB30_29
// %bb.21:
	mov	x21, xzr
	add	x20, x20, #16
	add	x22, x27, #16
.LBB30_22:                              // =>This Inner Loop Header: Depth=1
	ldur	q0, [x22, #-16]
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [x22], #32
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	add	x21, x21, #1
	stp	q1, q0, [x20, #-16]
	add	x20, x20, #32
	ldr	x8, [x19]
	cmp	x21, x8
	b.lo	.LBB30_22
	b	.LBB30_30
.LBB30_23:
	adrp	x8, .LCPI30_0
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [x8, :lo12:.LCPI30_0]
	bl	__eqtf2
	cbz	w0, .LBB30_29
// %bb.24:
	ldr	x19, [x19]
	cbz	x19, .LBB30_29
// %bb.25:
	add	x20, x20, #16
.LBB30_26:                              // =>This Inner Loop Header: Depth=1
	ldur	q0, [x20, #-16]
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [x20]
	stur	q0, [x20, #-16]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	subs	x19, x19, #1
	str	q0, [x20], #32
	b.ne	.LBB30_26
	b	.LBB30_29
.LBB30_27:
	cbz	x22, .LBB30_29
// %bb.28:
	lsl	x2, x22, #5
	mov	x0, x20
	mov	x1, x21
	bl	memmove
.LBB30_29:
	cbz	x27, .LBB30_31
.LBB30_30:
	ldur	x0, [x27, #-8]
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	add	sp, sp, #144
	b	free
.LBB30_31:
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	add	sp, sp, #144
	ret
.LBB30_32:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB30_33:
.Ltmp230:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB30_35
// %bb.34:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB30_35:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end30:
	.size	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e, .Lfunc_end30-_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,comdat
.LJTI30_0:
	.byte	(.LBB30_8-.LBB30_8)>>2
	.byte	(.LBB30_9-.LBB30_8)>>2
	.byte	(.LBB30_10-.LBB30_8)>>2
	.byte	(.LBB30_11-.LBB30_8)>>2
	.byte	(.LBB30_12-.LBB30_8)>>2
	.byte	(.LBB30_13-.LBB30_8)>>2
	.byte	(.LBB30_14-.LBB30_8)>>2
	.byte	(.LBB30_12-.LBB30_8)>>2
	.byte	(.LBB30_12-.LBB30_8)>>2
	.byte	(.LBB30_15-.LBB30_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e,comdat
	.p2align	2
GCC_except_table30:
.Lexception13:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end13-.Lcst_begin13
.Lcst_begin13:
	.uleb128 .Lfunc_begin13-.Lfunc_begin13  // >> Call Site 1 <<
	.uleb128 .Ltmp222-.Lfunc_begin13        //   Call between .Lfunc_begin13 and .Ltmp222
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp222-.Lfunc_begin13        // >> Call Site 2 <<
	.uleb128 .Ltmp215-.Ltmp222              //   Call between .Ltmp222 and .Ltmp215
	.uleb128 .Ltmp230-.Lfunc_begin13        //     jumps to .Ltmp230
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp215-.Lfunc_begin13        // >> Call Site 3 <<
	.uleb128 .Lfunc_end30-.Ltmp215          //   Call between .Ltmp215 and .Lfunc_end30
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end13:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
.LCPI31_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
	.section	.text._ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,@function
_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e: // @_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
.Lfunc_begin14:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception14
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x28, x27, [sp, #64]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	ldr	x23, [x0]
	mov	x20, x1
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	cbz	x23, .LBB31_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB31_4
// %bb.2:
	mov	v1.16b, v0.16b
	ldr	q0, [x20]
	bl	__multf3
	ldr	q1, [x20, #16]
	str	q0, [x20]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [x20, #16]
	b	.LBB31_31
.LBB31_3:
	mov	x27, xzr
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.ne	.LBB31_6
	b	.LBB31_23
.LBB31_4:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB31_32
// %bb.5:
	add	x8, x0, #64
	and	x27, x8, #0xffffffffffffffc0
	stur	x0, [x27, #-8]
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.eq	.LBB31_23
.LBB31_6:
	mov	x26, #-6148914691236517206
	str	x27, [sp, #8]                   // 8-byte Folded Spill
	mov	x22, x27
	adrp	x27, .LJTI31_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x20
	add	x27, x27, :lo12:.LJTI31_0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB31_12
.LBB31_7:
	adr	x10, .LBB31_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB31_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp239:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp240:
	mov	x0, x21
	mov	x21, x22
	b	.LBB31_16
.LBB31_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp237:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp238:
	mov	x0, x21
	mov	x21, x22
	b	.LBB31_16
.LBB31_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp243:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp244:
	mov	x0, x21
	mov	x21, x22
	b	.LBB31_16
.LBB31_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp235:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp236:
	mov	x0, x21
	mov	x21, x22
	b	.LBB31_16
.LBB31_12:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp245:
	mov	x0, x19
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
.Ltmp246:
	mov	x0, x22
	b	.LBB31_16
.LBB31_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp233:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp234:
	mov	x0, x21
	mov	x21, x22
	b	.LBB31_16
.LBB31_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp241:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp242:
	mov	x0, x21
	mov	x21, x22
	b	.LBB31_16
.LBB31_15:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp231:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.Ltmp232:
	mov	x0, x21
	mov	x21, x22
.LBB31_16:
	ldp	x8, x9, [x19, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB31_18
// %bb.17:
	ldr	x23, [x19]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB31_7
	b	.LBB31_12
.LBB31_18:
	ldr	x27, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x20
	b.eq	.LBB31_23
// %bb.19:
	adrp	x8, .LCPI31_0
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	x22, [x19]
	ldr	q1, [x8, :lo12:.LCPI31_0]
	bl	__eqtf2
	cbz	w0, .LBB31_27
// %bb.20:
	cbz	x22, .LBB31_29
// %bb.21:
	mov	x21, xzr
	add	x20, x20, #16
	add	x22, x27, #16
.LBB31_22:                              // =>This Inner Loop Header: Depth=1
	ldur	q0, [x22, #-16]
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [x22], #32
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	add	x21, x21, #1
	stp	q1, q0, [x20, #-16]
	add	x20, x20, #32
	ldr	x8, [x19]
	cmp	x21, x8
	b.lo	.LBB31_22
	b	.LBB31_30
.LBB31_23:
	adrp	x8, .LCPI31_0
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [x8, :lo12:.LCPI31_0]
	bl	__eqtf2
	cbz	w0, .LBB31_29
// %bb.24:
	ldr	x19, [x19]
	cbz	x19, .LBB31_29
// %bb.25:
	add	x20, x20, #16
.LBB31_26:                              // =>This Inner Loop Header: Depth=1
	ldur	q0, [x20, #-16]
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [x20]
	stur	q0, [x20, #-16]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	subs	x19, x19, #1
	str	q0, [x20], #32
	b.ne	.LBB31_26
	b	.LBB31_29
.LBB31_27:
	cbz	x22, .LBB31_29
// %bb.28:
	lsl	x2, x22, #5
	mov	x0, x20
	mov	x1, x21
	bl	memmove
.LBB31_29:
	cbz	x27, .LBB31_31
.LBB31_30:
	ldur	x0, [x27, #-8]
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	add	sp, sp, #144
	b	free
.LBB31_31:
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	add	sp, sp, #144
	ret
.LBB31_32:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB31_33:
.Ltmp247:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB31_35
// %bb.34:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB31_35:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end31:
	.size	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e, .Lfunc_end31-_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,comdat
.LJTI31_0:
	.byte	(.LBB31_8-.LBB31_8)>>2
	.byte	(.LBB31_9-.LBB31_8)>>2
	.byte	(.LBB31_10-.LBB31_8)>>2
	.byte	(.LBB31_11-.LBB31_8)>>2
	.byte	(.LBB31_12-.LBB31_8)>>2
	.byte	(.LBB31_13-.LBB31_8)>>2
	.byte	(.LBB31_14-.LBB31_8)>>2
	.byte	(.LBB31_12-.LBB31_8)>>2
	.byte	(.LBB31_12-.LBB31_8)>>2
	.byte	(.LBB31_15-.LBB31_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e,comdat
	.p2align	2
GCC_except_table31:
.Lexception14:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end14-.Lcst_begin14
.Lcst_begin14:
	.uleb128 .Lfunc_begin14-.Lfunc_begin14  // >> Call Site 1 <<
	.uleb128 .Ltmp239-.Lfunc_begin14        //   Call between .Lfunc_begin14 and .Ltmp239
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp239-.Lfunc_begin14        // >> Call Site 2 <<
	.uleb128 .Ltmp232-.Ltmp239              //   Call between .Ltmp239 and .Ltmp232
	.uleb128 .Ltmp247-.Lfunc_begin14        //     jumps to .Ltmp247
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp232-.Lfunc_begin14        // >> Call Site 3 <<
	.uleb128 .Lfunc_end31-.Ltmp232          //   Call between .Ltmp232 and .Lfunc_end31
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end14:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #432
	stp	x29, x30, [sp, #336]            // 16-byte Folded Spill
	add	x29, sp, #336
	stp	x28, x27, [sp, #352]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #368]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #384]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #400]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #416]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x25, x2
	subs	x8, x1, #1
	stp	x4, x3, [sp, #72]               // 16-byte Folded Spill
	b.ne	.LBB32_4
// %bb.1:
	cbz	x25, .LBB32_10
// %bb.2:
	add	x8, x25, x25, lsl #1
	lsl	x21, x8, #5
	ldp	x9, x8, [sp, #72]               // 16-byte Folded Reload
	lsl	x20, x25, #5
	lsl	x22, x25, #6
	add	x19, x9, #16
	add	x23, x8, #64
.LBB32_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q2, q0, [x23, #-64]
	stp	q0, q2, [x29, #-48]             // 32-byte Folded Spill
	ldp	q1, q0, [x23]
	stp	q1, q0, [x29, #-112]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldp	q2, q0, [x23, #-32]
	stp	q0, q2, [x29, #-112]            // 32-byte Folded Spill
	ldp	q1, q0, [x23, #32]
	str	q1, [sp, #160]                  // 16-byte Folded Spill
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x19, #-16]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x20
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x21
	add	x19, x19, #32
	subs	x25, x25, #1
	add	x23, x23, #128
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB32_3
	b	.LBB32_10
.LBB32_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x1, [sp, #64]                   // 8-byte Folded Spill
	cbz	x25, .LBB32_10
// %bb.5:
	ldp	x11, x23, [sp, #64]             // 16-byte Folded Reload
	lsl	x12, x25, #1
	mov	w9, #96
	ldr	x10, [sp, #80]                  // 8-byte Folded Reload
	mov	x28, x5
	mov	x27, xzr
	stp	x5, x25, [sp, #48]              // 16-byte Folded Spill
	mul	x8, x25, x11
	lsl	x24, x11, #5
	add	x21, x10, #32
	lsl	x10, x11, #7
	mov	x11, x5
	madd	x20, x8, x9, x23
	ldr	x9, [sp]                        // 8-byte Folded Reload
	stp	x10, x12, [sp, #32]             // 16-byte Folded Spill
	add	x10, x12, x25
	add	x19, x23, x8, lsl #6
	add	x8, x23, x8, lsl #5
	str	x10, [sp, #24]                  // 8-byte Folded Spill
	add	x10, x28, x9, lsl #6
	add	x9, x28, x9, lsl #5
	stp	x9, x10, [sp, #8]               // 16-byte Folded Spill
	b	.LBB32_7
.LBB32_6:                               //   in Loop: Header=BB32_7 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	add	x20, x20, x24
	add	x23, x23, x24
	ldr	x25, [sp, #56]                  // 8-byte Folded Reload
	add	x19, x19, x24
	add	x21, x21, x8
	ldp	x27, x8, [sp, #96]              // 16-byte Folded Reload
	add	x27, x27, #1
	cmp	x27, x25
	add	x8, x8, x24
	b.eq	.LBB32_10
.LBB32_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB32_9 Depth 2
	str	x21, [sp, #88]                  // 8-byte Folded Spill
	ldr	x21, [sp, #64]                  // 8-byte Folded Reload
	str	x8, [sp, #104]                  // 8-byte Folded Spill
	lsl	x8, x27, #2
	mov	w9, #2
	ldr	x22, [sp, #80]                  // 8-byte Folded Reload
	mul	x8, x8, x21
	bfi	x9, x27, #2, #62
	mul	x9, x9, x21
	add	x8, x22, x8, lsl #5
	add	x9, x22, x9, lsl #5
	ldp	q2, q0, [x8]
	ldr	q1, [x9]
	stp	q0, q1, [x29, #-48]             // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q2, q0, [x29, #-112]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	mov	w8, #1
	mov	w9, #3
	bfi	x8, x27, #2, #62
	bfi	x9, x27, #2, #62
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	mul	x8, x8, x21
	mul	x9, x9, x21
	add	x8, x22, x8, lsl #5
	add	x9, x22, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #160]                  // 16-byte Folded Spill
	ldr	q1, [x9]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #160]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	mul	x22, x27, x21
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	add	x8, x27, x8
	mul	x28, x8, x21
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x26, [sp, #72]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	add	x8, x26, x22, lsl #5
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x28, lsl #5
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	add	x8, x27, x25
	str	x27, [sp, #96]                  // 8-byte Folded Spill
	stp	q1, q0, [x10]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	add	x9, x27, x9
	mul	x22, x8, x21
	mul	x25, x9, x21
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x22, lsl #5
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x25, lsl #5
	ldr	x28, [sp, #48]                  // 8-byte Folded Reload
	ldp	x26, x27, [sp, #8]              // 16-byte Folded Reload
	cmp	x21, #2
	ldr	x21, [sp, #88]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB32_6
// %bb.8:                               //   in Loop: Header=BB32_7 Depth=1
	mov	x25, xzr
	ldr	x22, [sp]                       // 8-byte Folded Reload
.LBB32_9:                               //   Parent Loop BB32_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x21, x25
	add	x9, x8, x24
	add	x10, x9, x24
	ldp	q2, q0, [x8]
	add	x8, x10, x24
	stp	q0, q2, [x29, #-48]             // 32-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q0, q1, [x29, #-80]             // 32-byte Folded Spill
	ldp	q1, q0, [x10]
	stp	q1, q0, [x29, #-144]            // 32-byte Folded Spill
	ldr	q0, [x8]
	str	q0, [sp, #160]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x23, x25
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x25
	ldr	q1, [x8]
	stp	q0, q1, [sp, #144]              // 32-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #112]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldr	q0, [sp, #112]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #144]              // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	add	x8, x8, x25
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x25
	ldr	q1, [x8]
	stp	q0, q1, [x29, #-128]            // 32-byte Folded Spill
	ldr	q1, [x8, #16]
	stur	q1, [x29, #-160]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-128]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x25
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x27, x25
	ldr	q1, [x8]
	stur	q1, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stp	q1, q0, [x29, #-96]             // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-48]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x25
	subs	x22, x22, #1
	add	x25, x25, #32
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB32_9
	b	.LBB32_6
.LBB32_10:
	ldp	x20, x19, [sp, #416]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #400]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #384]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #368]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #352]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #336]            // 16-byte Folded Reload
	add	sp, sp, #432
	ret
.Lfunc_end32:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end32-_ZNK9pocketfft6detail5cfftpIeE5pass4ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI33_0:
	.xword	0xc908b2fb1366ea95              // fp128 0.707106781186547524400844362104848992
	.xword	0x3ffe6a09e667f3bc
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #688
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	str	x5, [sp, #192]                  // 8-byte Folded Spill
	stp	x4, x3, [sp, #136]              // 16-byte Folded Spill
	b.ne	.LBB33_4
// %bb.1:
	cbz	x2, .LBB33_10
// %bb.2:
	ldr	x9, [sp, #136]                  // 8-byte Folded Reload
	mov	w8, #224
	add	x10, x2, x2, lsl #2
	lsl	x23, x2, #5
	mul	x21, x2, x8
	adrp	x8, .LCPI33_0
	add	x19, x9, #16
	add	x9, x2, x2, lsl #1
	lsl	x20, x9, #5
	lsl	x24, x9, #6
	ldr	x9, [sp, #144]                  // 8-byte Folded Reload
	lsl	x22, x10, #5
	lsl	x25, x2, #6
	lsl	x26, x2, #7
	ldr	q0, [x8, :lo12:.LCPI33_0]
	add	x27, x9, #128
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
.LBB33_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q2, q0, [x27, #-96]
	mov	x28, x2
	ldr	q1, [x27, #32]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x27, #48]
	stp	q2, q0, [x29, #-176]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q2, q0, [x27, #-32]
	stp	q0, q2, [x29, #-192]            // 32-byte Folded Spill
	ldp	q1, q0, [x27, #96]
	stp	q1, q0, [x29, #-224]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stur	q0, [x29, #-64]
	ldurb	w8, [x29, #-49]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-49]
	ldur	q0, [x29, #-64]
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q2, q0, [x27, #-128]
	stp	q0, q2, [x29, #-240]            // 32-byte Folded Spill
	ldp	q1, q0, [x27]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	q2, [x27, #-64]
	stp	q2, q0, [x29, #-256]            // 32-byte Folded Spill
	ldur	q0, [x27, #-48]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q1, q0, [x27, #64]
	stp	q1, q0, [sp, #320]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	stp	q1, q0, [x19, #-16]
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #320]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x26
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x25
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x24
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x23
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x20
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	mov	x2, x28
	add	x8, x19, x21
	add	x19, x19, #32
	subs	x2, x28, #1
	add	x27, x27, #256
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB33_3
	b	.LBB33_10
.LBB33_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x1, [sp, #128]                  // 8-byte Folded Spill
	cbz	x2, .LBB33_10
// %bb.5:
	lsl	x8, x2, #2
	lsl	x9, x2, #1
	ldp	x14, x20, [sp, #128]            // 16-byte Folded Reload
	mov	w12, #96
	mov	w10, #224
	stp	x9, x8, [sp, #104]              // 16-byte Folded Spill
	add	x9, x9, x2
	add	x8, x8, x2
	lsl	x11, x9, #1
	ldr	x21, [sp, #144]                 // 8-byte Folded Reload
	mov	x27, xzr
	ldr	x15, [sp]                       // 8-byte Folded Reload
	str	x2, [sp, #120]                  // 8-byte Folded Spill
	stp	x8, x9, [sp, #88]               // 16-byte Folded Spill
	lsl	x9, x2, #3
	sub	x9, x9, x2
	mul	x8, x2, x14
	ldr	x7, [sp, #192]                  // 8-byte Folded Reload
	stp	x9, x11, [sp, #72]              // 16-byte Folded Spill
	lsl	x9, x14, #5
	lsl	x11, x14, #8
	madd	x17, x8, x12, x20
	madd	x25, x8, x10, x20
	add	x6, x20, x8, lsl #5
	stp	x11, x9, [sp, #56]              // 16-byte Folded Spill
	add	x9, x9, x21
	add	x9, x9, #48
	madd	x10, x14, x10, x21
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	add	x9, x15, x15, lsl #2
	lsl	x9, x9, #5
	add	x0, x10, #48
	add	x11, x9, x21
	lsl	x10, x15, #7
	add	x16, x11, #208
	add	x11, x15, x15, lsl #1
	lsl	x12, x11, #5
	lsl	x11, x11, #6
	add	x13, x12, x21
	add	x9, x7, x9
	add	x18, x13, #144
	mov	w13, #160
	madd	x1, x8, x13, x20
	add	x13, x10, x21
	add	x3, x13, #128
	lsl	x13, x15, #6
	add	x14, x13, x21
	add	x10, x7, x10
	add	x4, x14, #64
	add	x14, x11, x21
	add	x11, x7, x11
	add	x5, x14, #192
	mov	w14, #192
	stp	x9, x10, [sp, #24]              // 16-byte Folded Spill
	adrp	x10, .LCPI33_0
	str	x11, [sp, #48]                  // 8-byte Folded Spill
	add	x11, x7, x13
	add	x9, x7, x15, lsl #5
	add	x13, x20, x8, lsl #6
	ldr	q0, [x10, :lo12:.LCPI33_0]
	str	x11, [sp, #40]                  // 8-byte Folded Spill
	madd	x11, x8, x14, x20
	ldp	x28, x24, [sp, #32]             // 16-byte Folded Reload
	str	x9, [sp, #16]                   // 8-byte Folded Spill
	add	x8, x20, x8, lsl #7
	add	x9, x7, x12
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	b	.LBB33_7
.LBB33_6:                               //   in Loop: Header=BB33_7 Depth=1
	ldp	x10, x8, [sp, #56]              // 16-byte Folded Reload
	mov	x9, x27
	ldp	x13, x11, [sp, #272]            // 16-byte Folded Reload
	ldp	x5, x4, [sp, #224]              // 16-byte Folded Reload
	add	x9, x9, x10
	add	x25, x25, x8
	ldp	x15, x14, [sp, #256]            // 16-byte Folded Reload
	add	x16, x11, x10
	add	x18, x13, x10
	ldp	x3, x1, [sp, #240]              // 16-byte Folded Reload
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	add	x4, x4, x10
	ldr	x12, [sp, #288]                 // 8-byte Folded Reload
	add	x0, x15, x10
	add	x5, x5, x10
	ldr	x27, [sp, #160]                 // 8-byte Folded Reload
	add	x3, x3, x10
	ldr	x19, [sp, #200]                 // 8-byte Folded Reload
	add	x21, x12, x10
	ldr	x2, [sp, #120]                  // 8-byte Folded Reload
	ldp	x10, x9, [sp, #296]             // 16-byte Folded Reload
	add	x27, x27, #1
	add	x17, x14, x8
	ldp	x7, x6, [sp, #208]              // 16-byte Folded Reload
	add	x1, x1, x8
	add	x13, x19, x8
	add	x20, x10, x8
	cmp	x27, x2
	add	x11, x7, x8
	add	x6, x6, x8
	add	x8, x9, x8
	b.eq	.LBB33_10
.LBB33_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB33_9 Depth 2
	stp	x20, x8, [sp, #296]             // 16-byte Folded Spill
	mov	w8, #1
	str	x25, [sp, #152]                 // 8-byte Folded Spill
	ldr	x25, [sp, #128]                 // 8-byte Folded Reload
	bfi	x8, x27, #3, #61
	mov	w9, #5
	ldr	x23, [sp, #144]                 // 8-byte Folded Reload
	bfi	x9, x27, #3, #61
	mul	x8, x8, x25
	stp	x13, x11, [sp, #200]            // 16-byte Folded Spill
	mul	x9, x9, x25
	stp	x6, x5, [sp, #216]              // 16-byte Folded Spill
	stp	x4, x3, [sp, #232]              // 16-byte Folded Spill
	lsl	x22, x27, #3
	add	x8, x23, x8, lsl #5
	stp	x1, x0, [sp, #248]              // 16-byte Folded Spill
	add	x9, x23, x9, lsl #5
	stp	x17, x18, [sp, #264]            // 16-byte Folded Spill
	stp	x16, x21, [sp, #280]            // 16-byte Folded Spill
	mov	x19, x2
	ldp	q2, q0, [x8]
	ldr	q1, [x9]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q2, q0, [x29, #-176]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	mov	w8, #3
	mov	w9, #7
	bfi	x8, x27, #3, #61
	bfi	x9, x27, #3, #61
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mul	x8, x8, x25
	mul	x9, x9, x25
	add	x8, x23, x8, lsl #5
	add	x9, x23, x9, lsl #5
	ldp	q2, q0, [x8]
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stur	q1, [x29, #-160]                // 16-byte Folded Spill
	stp	q2, q0, [x29, #-224]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stur	q0, [x29, #-32]
	ldurb	w8, [x29, #-17]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-17]
	ldur	q0, [x29, #-32]
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	mov	w8, #4
	mul	x9, x22, x25
	bfi	x8, x27, #3, #61
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mul	x8, x8, x25
	add	x9, x23, x9, lsl #5
	add	x8, x23, x8, lsl #5
	ldp	q2, q0, [x9]
	str	q2, [sp, #416]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	stp	q0, q1, [x29, #-240]            // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	mov	w8, #2
	mov	w9, #6
	bfi	x8, x27, #3, #61
	bfi	x9, x27, #3, #61
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	mul	x8, x8, x25
	mul	x9, x9, x25
	add	x8, x23, x8, lsl #5
	add	x9, x23, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #320]                  // 16-byte Folded Spill
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stur	q1, [x29, #-256]                // 16-byte Folded Spill
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #320]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	mul	x22, x27, x25
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	add	x8, x27, x8
	mul	x23, x8, x25
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #160]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x26, [sp, #136]                 // 8-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	add	x8, x26, x22, lsl #5
	stp	q1, q0, [x8]
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #320]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x23, lsl #5
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	stp	q1, q0, [x10]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	add	x8, x27, x8
	add	x9, x27, x9
	mul	x22, x8, x25
	mul	x23, x9, x25
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x22, lsl #5
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	add	x10, x26, x23, lsl #5
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	ldr	x9, [sp, #88]                   // 8-byte Folded Reload
	add	x8, x27, x19
	stp	q1, q0, [x10]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	add	x9, x27, x9
	mul	x22, x8, x25
	mul	x23, x9, x25
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x22, lsl #5
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x23, lsl #5
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	str	x27, [sp, #160]                 // 8-byte Folded Spill
	ldr	x9, [sp, #72]                   // 8-byte Folded Reload
	stp	q1, q0, [x10]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	add	x8, x27, x8
	add	x9, x27, x9
	mul	x22, x8, x25
	mul	x23, x9, x25
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x22, lsl #5
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	ldp	x21, x20, [sp, #16]             // 16-byte Folded Reload
	add	x8, x26, x23, lsl #5
	cmp	x25, #2
	ldr	x25, [sp, #152]                 // 8-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	ldr	x27, [sp, #184]                 // 8-byte Folded Reload
	ldr	x26, [sp, #48]                  // 8-byte Folded Reload
	ldr	x19, [sp, #8]                   // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB33_6
// %bb.8:                               //   in Loop: Header=BB33_7 Depth=1
	mov	x22, xzr
	ldr	x23, [sp]                       // 8-byte Folded Reload
.LBB33_9:                               //   Parent Loop BB33_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x27, x22
	ldr	x9, [sp, #280]                  // 8-byte Folded Reload
	add	x9, x9, x22
	ldp	q2, q0, [x8, #-16]
	ldur	q1, [x9, #-16]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x9]
	stp	q2, q0, [x29, #-176]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #272]                  // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	add	x8, x8, x22
	add	x9, x9, x22
	ldp	q2, q0, [x8, #-16]
	ldur	q1, [x9, #-16]
	stp	q0, q1, [x29, #-208]            // 32-byte Folded Spill
	ldr	q0, [x9]
	stp	q2, q0, [x29, #-240]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stur	q0, [x29, #-48]
	ldurb	w8, [x29, #-33]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-33]
	ldur	q0, [x29, #-48]
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	x8, [sp, #288]                  // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	x9, [sp, #240]                  // 8-byte Folded Reload
	add	x8, x8, x22
	add	x9, x9, x22
	ldp	q2, q0, [x8, #32]
	ldr	q1, [x9, #32]
	stp	q0, q1, [x29, #-208]            // 32-byte Folded Spill
	ldr	q0, [x9, #48]
	stp	q2, q0, [x29, #-240]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #224]              // 16-byte Folded Reload
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	add	x9, x9, x22
	add	x8, x8, x22
	ldr	q1, [x9, #32]
	ldp	q2, q0, [x8, #32]
	str	q2, [sp, #336]                  // 16-byte Folded Spill
	stp	q0, q1, [x29, #-240]            // 32-byte Folded Spill
	ldr	q0, [x9, #48]
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #384]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #384]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #296]                  // 8-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldr	q0, [sp, #352]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #336]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #304]                  // 8-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x22
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #336]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #200]                  // 8-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x22
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-160]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #400]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #208]                  // 8-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	add	x8, x8, x22
	ldr	q1, [x8]
	stp	q0, q1, [x29, #-224]            // 32-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #400]                  // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-224]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #216]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x22
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-144]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stur	q1, [x29, #-224]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #248]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x24, x22
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-144]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stur	q1, [x29, #-224]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x22
	ldr	q1, [x8]
	stur	q1, [x29, #-112]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stp	q1, q0, [x29, #-160]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x25, x22
	subs	x23, x23, #1
	add	x22, x22, #32
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB33_9
	b	.LBB33_6
.LBB33_10:
	add	sp, sp, #688
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end33:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end33-_ZNK9pocketfft6detail5cfftpIeE5pass8ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x2
	cmp	x1, #1
	stp	x4, x3, [sp, #40]               // 16-byte Folded Spill
	b.ne	.LBB34_4
// %bb.1:
	cbz	x19, .LBB34_12
// %bb.2:
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	lsl	x20, x19, #5
	add	x21, x8, #16
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	add	x22, x8, #32
.LBB34_3:                               // =>This Inner Loop Header: Depth=1
	ldur	q0, [x22, #-32]
	ldr	q1, [x22]
	stp	q1, q0, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldur	q0, [x22, #-16]
	ldr	q1, [x22, #16]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x21, #-16]
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x20
	add	x21, x21, #32
	subs	x19, x19, #1
	add	x22, x22, #64
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB34_3
	b	.LBB34_12
.LBB34_4:
	cbz	x19, .LBB34_12
// %bb.5:
	mov	x22, x1
	subs	x8, x1, #1
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	b.ls	.LBB34_10
// %bb.6:
	lsl	x11, x22, #5
	lsl	x10, x22, #6
	mul	x8, x19, x22
	mov	x23, x5
	mov	x25, xzr
	stp	x10, x11, [sp, #8]              // 16-byte Folded Spill
	ldp	x10, x9, [sp, #40]              // 16-byte Folded Reload
	add	x27, x9, #48
	add	x9, x11, x9
	add	x20, x9, #48
	str	x22, [sp, #24]                  // 8-byte Folded Spill
	add	x8, x10, x8, lsl #5
	add	x28, x10, #32
	add	x24, x8, #32
.LBB34_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB34_8 Depth 2
	mov	w9, #1
	lsl	x8, x25, #1
	bfi	x9, x25, #1, #63
	ldr	x10, [sp, #48]                  // 8-byte Folded Reload
	mul	x8, x8, x22
	mul	x9, x9, x22
	add	x21, x10, x8, lsl #5
	add	x26, x10, x9, lsl #5
	ldr	q0, [x21]
	ldr	q1, [x26]
	stp	q0, q1, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q0, [x21, #16]
	ldr	q1, [x26, #16]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	mul	x8, x25, x22
	ldr	x21, [sp, #40]                  // 8-byte Folded Reload
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	add	x8, x21, x8, lsl #5
	stp	q1, q0, [x8]
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x25, x19
	mov	x26, xzr
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	str	x25, [sp, #56]                  // 8-byte Folded Spill
	mul	x8, x8, x22
	add	x8, x21, x8, lsl #5
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
.LBB34_8:                               //   Parent Loop BB34_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x22, x27, x26
	add	x25, x20, x26
	ldur	q0, [x22, #-16]
	ldur	q1, [x25, #-16]
	stp	q0, q1, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q0, [x22]
	ldr	q1, [x25]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	add	x8, x28, x26
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x23, x26
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #64]                   // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x24, x26
	subs	x21, x21, #1
	add	x26, x26, #32
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	stp	q1, q0, [x8]
	b.ne	.LBB34_8
// %bb.9:                               //   in Loop: Header=BB34_7 Depth=1
	ldp	x9, x8, [sp, #8]                // 16-byte Folded Reload
	ldr	x25, [sp, #56]                  // 8-byte Folded Reload
	ldr	x22, [sp, #24]                  // 8-byte Folded Reload
	add	x27, x27, x9
	add	x20, x20, x9
	add	x25, x25, #1
	add	x24, x24, x8
	add	x28, x28, x8
	cmp	x25, x19
	b.ne	.LBB34_7
	b	.LBB34_12
.LBB34_10:
	mul	x8, x19, x22
	lsl	x21, x22, #5
	lsl	x22, x22, #6
	lsl	x23, x8, #5
	ldp	x9, x8, [sp, #40]               // 16-byte Folded Reload
	add	x20, x9, #16
	add	x24, x8, #16
.LBB34_11:                              // =>This Inner Loop Header: Depth=1
	add	x25, x24, x21
	ldur	q0, [x24, #-16]
	ldur	q1, [x25, #-16]
	stp	q0, q1, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q0, [x24]
	ldr	q1, [x25]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x20, #-16]
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x23
	subs	x19, x19, #1
	add	x20, x20, x21
	add	x24, x24, x22
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB34_11
.LBB34_12:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end34:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end34-_ZNK9pocketfft6detail5cfftpIeE5pass2ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI35_0:
	.xword	0x0000000000000000              // fp128 0.5
	.xword	0x3ffe000000000000
.LCPI35_1:
	.xword	0xa73b25742d7078b8              // fp128 0.866025403784438646763723170752936161
	.xword	0x3ffebb67ae8584ca
.LCPI35_2:
	.xword	0xa73b25742d7078b8              // fp128 -0.866025403784438646763723170752936161
	.xword	0xbffebb67ae8584ca
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #384
	stp	x29, x30, [sp, #288]            // 16-byte Folded Spill
	add	x29, sp, #288
	stp	x28, x27, [sp, #304]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #320]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #336]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #352]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #368]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x23, x2
	subs	x8, x1, #1
	stp	x4, x3, [sp, #48]               // 16-byte Folded Spill
	b.ne	.LBB35_4
// %bb.1:
	cbz	x23, .LBB35_10
// %bb.2:
	adrp	x8, .LCPI35_0
	adrp	x9, .LCPI35_1
	adrp	x10, .LCPI35_2
	lsl	x19, x23, #6
	lsl	x21, x23, #5
	ldr	q0, [x8, :lo12:.LCPI35_0]
	ldp	x11, x8, [sp, #48]              // 16-byte Folded Reload
	add	x20, x11, #16
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI35_1]
	add	x22, x8, #48
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI35_2]
	str	q0, [sp, #96]                   // 16-byte Folded Spill
.LBB35_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x22, #-32]
	ldur	q1, [x22, #-48]
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stp	q1, q0, [x29, #-48]             // 32-byte Folded Spill
	ldp	q0, q1, [x22]
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x22, #32]
	str	q1, [sp, #128]                  // 16-byte Folded Spill
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [sp, #128]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x20, #-16]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x21
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x19
	add	x20, x20, #32
	subs	x23, x23, #1
	add	x22, x22, #96
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB35_3
	b	.LBB35_10
.LBB35_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x1, [sp, #40]                   // 8-byte Folded Spill
	cbz	x23, .LBB35_10
// %bb.5:
	ldp	x12, x27, [sp, #40]             // 16-byte Folded Reload
	lsl	x18, x23, #1
	adrp	x10, .LCPI35_1
	ldr	x19, [sp, #56]                  // 8-byte Folded Reload
	mov	x13, xzr
	mov	x22, x5
	str	x23, [sp, #72]                  // 8-byte Folded Spill
	add	x9, x12, x12, lsl #1
	mul	x8, x23, x12
	lsl	x9, x9, #5
	lsl	x11, x12, #5
	add	x26, x19, x11
	add	x20, x19, x12, lsl #6
	add	x24, x27, x8, lsl #6
	add	x21, x27, x8, lsl #5
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	adrp	x9, .LCPI35_0
	stp	x11, x18, [sp, #16]             // 16-byte Folded Spill
	adrp	x11, .LCPI35_2
	ldr	x8, [sp]                        // 8-byte Folded Reload
	str	x5, [sp, #32]                   // 8-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI35_0]
	add	x28, x5, x8, lsl #5
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI35_1]
	str	q0, [sp, #96]                   // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI35_2]
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	b	.LBB35_7
.LBB35_6:                               //   in Loop: Header=BB35_7 Depth=1
	ldp	x9, x8, [sp, #8]                // 16-byte Folded Reload
	ldp	x13, x23, [sp, #64]             // 16-byte Folded Reload
	add	x19, x19, x9
	add	x26, x26, x9
	add	x24, x24, x8
	add	x20, x20, x9
	add	x13, x13, #1
	add	x27, x27, x8
	add	x21, x21, x8
	cmp	x13, x23
	b.eq	.LBB35_10
.LBB35_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB35_9 Depth 2
	ldr	x25, [sp, #40]                  // 8-byte Folded Reload
	add	x8, x13, x13, lsl #1
	add	x9, x8, #2
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	mov	x23, x13
	mul	x8, x8, x25
	mul	x9, x9, x25
	add	x10, x25, x8
	add	x8, x11, x8, lsl #5
	add	x10, x11, x10, lsl #5
	add	x9, x11, x9, lsl #5
	ldp	q1, q0, [x8]
	stp	q1, q0, [x29, #-48]             // 32-byte Folded Spill
	ldp	q2, q0, [x10]
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #128]                  // 16-byte Folded Spill
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [sp, #128]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x23, x25
	ldr	x22, [sp, #48]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	add	x8, x22, x8, lsl #5
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	str	x23, [sp, #64]                  // 8-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	add	x8, x23, x8
	add	x9, x23, x9
	mul	x23, x8, x25
	mul	x8, x9, x25
	stur	x8, [x29, #-96]                 // 8-byte Folded Spill
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x23, lsl #5
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-96]                 // 8-byte Folded Reload
	cmp	x25, #2
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	add	x8, x22, x8, lsl #5
	ldr	x22, [sp, #32]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB35_6
// %bb.8:                               //   in Loop: Header=BB35_7 Depth=1
	mov	x23, xzr
	ldr	x25, [sp]                       // 8-byte Folded Reload
.LBB35_9:                               //   Parent Loop BB35_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x19, x23
	add	x9, x26, x23
	add	x10, x20, x23
	ldp	q1, q0, [x8, #32]
	stp	q0, q1, [x29, #-48]             // 32-byte Folded Spill
	ldp	q2, q0, [x9, #32]
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	str	q1, [sp, #128]                  // 16-byte Folded Spill
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [sp, #128]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x27, x23
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x23
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-112]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #112]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldr	q0, [sp, #112]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x23
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x23
	ldr	q1, [x8]
	stur	q1, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stp	q1, q0, [x29, #-96]             // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-48]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x24, x23
	subs	x25, x25, #1
	add	x23, x23, #32
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB35_9
	b	.LBB35_6
.LBB35_10:
	ldp	x20, x19, [sp, #368]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #352]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #336]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #320]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #304]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #288]            // 16-byte Folded Reload
	add	sp, sp, #384
	ret
.Lfunc_end35:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end35-_ZNK9pocketfft6detail5cfftpIeE5pass3ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI36_0:
	.xword	0xf82be73980c0b9dc              // fp128 0.30901699437494742410229341718281908
	.xword	0x3ffd3c6ef372fe94
.LCPI36_1:
	.xword	0x7c15f39cc0605cee              // fp128 -0.80901699437494742410229341718281908
	.xword	0xbffe9e3779b97f4a
.LCPI36_2:
	.xword	0xdedb4265add35f34              // fp128 -0.587785252292473129168705954639072828
	.xword	0xbffe2cf2304755a5
.LCPI36_3:
	.xword	0xf5e6376e1a30d4ec              // fp128 -0.951056516295153572116439333379382144
	.xword	0xbffee6f0e134454f
.LCPI36_4:
	.xword	0xf5e6376e1a30d4ec              // fp128 0.951056516295153572116439333379382144
	.xword	0x3ffee6f0e134454f
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #576
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x27, x2
	subs	x8, x1, #1
	stp	x4, x3, [sp, #96]               // 16-byte Folded Spill
	b.ne	.LBB36_4
// %bb.1:
	cbz	x27, .LBB36_10
// %bb.2:
	ldr	x9, [sp, #96]                   // 8-byte Folded Reload
	adrp	x10, .LCPI36_1
	add	x8, x27, x27, lsl #1
	lsl	x20, x27, #6
	lsl	x21, x8, #5
	adrp	x8, .LCPI36_2
	add	x19, x9, #16
	adrp	x9, .LCPI36_0
	lsl	x22, x27, #7
	lsl	x23, x27, #5
	ldr	q0, [x9, :lo12:.LCPI36_0]
	adrp	x9, .LCPI36_3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI36_1]
	adrp	x10, .LCPI36_4
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI36_2]
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI36_3]
	add	x24, x8, #80
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI36_4]
	str	q0, [sp, #272]                  // 16-byte Folded Spill
.LBB36_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x24, #-64]
	ldur	q1, [x24, #-80]
	stp	q1, q0, [x29, #-96]             // 32-byte Folded Spill
	ldur	q0, [x24, #-32]
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x24, #48]
	stp	q1, q2, [x29, #-192]            // 32-byte Folded Spill
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q2, q0, [x24, #-16]
	stp	q2, q0, [x29, #-224]            // 32-byte Folded Spill
	ldp	q1, q0, [x24, #16]
	stp	q1, q0, [x29, #-256]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x19, #-16]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x19]
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #240]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x23
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x20
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x21
	add	x19, x19, #32
	subs	x27, x27, #1
	add	x24, x24, #160
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB36_3
	b	.LBB36_10
.LBB36_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x5, [sp, #88]                   // 8-byte Folded Spill
	cbz	x27, .LBB36_10
// %bb.5:
	lsl	x11, x27, #2
	lsl	x10, x27, #1
	ldp	x23, x22, [sp, #96]             // 16-byte Folded Reload
	mul	x8, x27, x1
	mov	w9, #96
	stp	x10, x11, [sp, #56]             // 16-byte Folded Spill
	add	x10, x10, x27
	ldr	x14, [sp]                       // 8-byte Folded Reload
	mov	x24, x1
	madd	x16, x8, x9, x23
	add	x9, x1, x1, lsl #2
	str	x10, [sp, #48]                  // 8-byte Folded Spill
	lsl	x10, x1, #5
	lsl	x9, x9, #5
	ldr	x13, [sp, #88]                  // 8-byte Folded Reload
	add	x17, x22, x10
	add	x18, x22, x1, lsl #7
	mov	x15, xzr
	add	x2, x23, x8, lsl #6
	stp	x9, x10, [sp, #32]              // 16-byte Folded Spill
	lsl	x10, x14, #6
	add	x11, x10, x22
	add	x9, x14, x14, lsl #1
	add	x0, x11, #64
	adrp	x11, .LCPI36_0
	add	x10, x13, x10
	lsl	x9, x9, #5
	add	x12, x9, x22
	add	x9, x13, x9
	add	x1, x12, #96
	add	x12, x13, x14, lsl #5
	str	x10, [sp, #24]                  // 8-byte Folded Spill
	adrp	x10, .LCPI36_1
	ldr	q0, [x11, :lo12:.LCPI36_0]
	adrp	x11, .LCPI36_3
	str	x12, [sp, #16]                  // 8-byte Folded Spill
	adrp	x12, .LCPI36_2
	add	x19, x23, x8, lsl #5
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI36_1]
	adrp	x10, .LCPI36_4
	mov	x25, x9
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI36_2]
	add	x12, x23, x8, lsl #7
	stp	x24, x27, [sp, #72]             // 16-byte Folded Spill
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI36_3]
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI36_4]
	str	q0, [sp, #240]                  // 16-byte Folded Spill
	b	.LBB36_7
.LBB36_6:                               //   in Loop: Header=BB36_7 Depth=1
	ldp	x13, x12, [sp, #144]            // 16-byte Folded Reload
	ldp	x9, x8, [sp, #32]               // 16-byte Folded Reload
	ldp	x11, x10, [sp, #160]            // 16-byte Folded Reload
	ldr	x14, [sp, #136]                 // 8-byte Folded Reload
	add	x22, x22, x9
	ldp	x15, x3, [sp, #112]             // 16-byte Folded Reload
	add	x17, x11, x9
	add	x18, x12, x9
	add	x0, x13, x9
	add	x1, x14, x9
	ldr	x9, [sp, #128]                  // 8-byte Folded Reload
	add	x16, x10, x8
	ldp	x24, x27, [sp, #72]             // 16-byte Folded Reload
	add	x15, x15, #1
	add	x23, x23, x8
	add	x2, x9, x8
	add	x12, x3, x8
	add	x19, x19, x8
	cmp	x15, x27
	b.eq	.LBB36_10
.LBB36_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB36_9 Depth 2
	add	x26, x15, x15, lsl #2
	ldr	x28, [sp, #104]                 // 8-byte Folded Reload
	add	x8, x26, #4
	stp	x12, x2, [sp, #120]             // 16-byte Folded Spill
	mul	x9, x26, x24
	stp	x1, x0, [sp, #136]              // 16-byte Folded Spill
	mul	x8, x8, x24
	stp	x18, x17, [sp, #152]            // 16-byte Folded Spill
	add	x10, x24, x9
	str	x16, [sp, #168]                 // 8-byte Folded Spill
	add	x9, x28, x9, lsl #5
	mov	x20, x15
	add	x10, x28, x10, lsl #5
	add	x8, x28, x8, lsl #5
	ldp	q1, q0, [x9]
	ldp	q2, q3, [x10]
	stp	q1, q0, [x29, #-96]             // 32-byte Folded Spill
	ldp	q1, q0, [x8]
	stp	q2, q1, [x29, #-192]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-160]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x26, #2
	add	x9, x26, #3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mul	x8, x8, x24
	mul	x9, x9, x24
	add	x8, x28, x8, lsl #5
	add	x9, x28, x9, lsl #5
	ldp	q2, q0, [x8]
	ldr	q1, [x9]
	stp	q1, q0, [x29, #-224]            // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q2, q0, [x29, #-256]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x20, x24
	ldr	x28, [sp, #96]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	add	x26, x28, x8, lsl #5
	str	q0, [x26]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x26, #16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	add	x8, x20, x27
	add	x9, x20, x9
	mul	x26, x8, x24
	mul	x27, x9, x24
	bl	__subtf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x28, x26, lsl #5
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x27, lsl #5
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	ldp	x9, x8, [sp, #48]               // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	str	x20, [sp, #112]                 // 8-byte Folded Spill
	add	x9, x20, x9
	add	x8, x20, x8
	mul	x27, x9, x24
	mul	x26, x8, x24
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x28, x26, lsl #5
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x27, lsl #5
	cmp	x24, #2
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	ldr	x24, [sp, #88]                  // 8-byte Folded Reload
	ldr	x20, [sp, #24]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB36_6
// %bb.8:                               //   in Loop: Header=BB36_7 Depth=1
	mov	x26, xzr
	ldr	x27, [sp]                       // 8-byte Folded Reload
.LBB36_9:                               //   Parent Loop BB36_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x22, x26
	ldp	x10, x9, [sp, #152]             // 16-byte Folded Reload
	ldr	q0, [x8, #32]
	add	x9, x9, x26
	add	x10, x10, x26
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x8, #48]
	ldp	q2, q3, [x9, #32]
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	stp	q1, q2, [x29, #-192]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-160]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #136]              // 16-byte Folded Reload
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	add	x9, x9, x26
	add	x8, x8, x26
	ldr	q1, [x9, #32]
	ldp	q2, q0, [x8, #32]
	stp	q1, q0, [x29, #-224]            // 32-byte Folded Spill
	ldr	q0, [x9, #48]
	stp	q2, q0, [x29, #-256]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-128]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	add	x28, x23, x26
	str	q0, [x28, #32]
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x28, #48]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #224]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x24, x26
	str	q0, [sp, #208]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	str	q1, [sp, #272]                  // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #176]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #192]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #272]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #192]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #192]                  // 16-byte Folded Spill
	ldr	q0, [sp, #176]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #208]                  // 16-byte Folded Reload
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x26
	ldr	q1, [sp, #192]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #224]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x25, x26
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-256]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	str	q1, [sp, #272]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldr	q0, [sp, #304]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #120]                  // 8-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x26
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q1, [x8]
	stur	q1, [x29, #-144]                // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stur	q1, [x29, #-208]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #128]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x26
	ldr	q1, [x8]
	stur	q1, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q1, [x8, #16]
	stp	q1, q0, [x29, #-144]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	subs	x27, x27, #1
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	add	x8, x8, x26
	add	x26, x26, #32
	stp	q1, q0, [x8, #32]
	b.ne	.LBB36_9
	b	.LBB36_6
.LBB36_10:
	add	sp, sp, #576
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end36:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end36-_ZNK9pocketfft6detail5cfftpIeE5pass5ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI37_0:
	.xword	0x16cbef0b3c8a771c              // fp128 0.623489801858733530525004884004239828
	.xword	0x3ffe3f3a0e28bedd
.LCPI37_1:
	.xword	0x26942fdd4d81e548              // fp128 -0.222520933956314404288902564496794804
	.xword	0xbffcc7b90e302458
.LCPI37_2:
	.xword	0x0d26e313e929fdcb              // fp128 -0.90096886790241912623610231950744512
	.xword	0xbffecd4bca9cb5c7
.LCPI37_3:
	.xword	0x8e3954a4ef51dd5c              // fp128 -0.974927912181823607018131682993931188
	.xword	0xbffef329c0558e96
.LCPI37_4:
	.xword	0xb0bb3599ce804ff5              // fp128 -0.78183148246802980870844452667405784
	.xword	0xbffe904c37505de4
.LCPI37_5:
	.xword	0x1005772daf64d3b2              // fp128 -0.433883739117558120475768332848359021
	.xword	0xbffdbc4c04d71abc
.LCPI37_6:
	.xword	0x1005772daf64d3b2              // fp128 0.433883739117558120475768332848359021
	.xword	0x3ffdbc4c04d71abc
.LCPI37_7:
	.xword	0xb0bb3599ce804ff5              // fp128 0.78183148246802980870844452667405784
	.xword	0x3ffe904c37505de4
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #752
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	stp	x4, x3, [sp, #136]              // 16-byte Folded Spill
	b.ne	.LBB37_4
// %bb.1:
	cbz	x2, .LBB37_10
// %bb.2:
	adrp	x9, .LCPI37_0
	adrp	x10, .LCPI37_1
	adrp	x12, .LCPI37_2
	ldr	x8, [sp, #136]                  // 8-byte Folded Reload
	add	x11, x2, x2, lsl #2
	lsl	x19, x2, #7
	ldr	q0, [x9, :lo12:.LCPI37_0]
	adrp	x9, .LCPI37_3
	add	x20, x8, #16
	add	x8, x2, x2, lsl #1
	lsl	x21, x8, #5
	lsl	x24, x8, #6
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI37_1]
	adrp	x10, .LCPI37_4
	ldr	x8, [sp, #144]                  // 8-byte Folded Reload
	lsl	x22, x11, #5
	lsl	x23, x2, #6
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI37_2]
	adrp	x12, .LCPI37_5
	lsl	x25, x2, #5
	add	x26, x8, #112
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI37_3]
	adrp	x9, .LCPI37_6
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI37_4]
	adrp	x10, .LCPI37_7
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI37_5]
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI37_6]
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI37_7]
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
.LBB37_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x26, #-96]
	mov	x27, x2
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q1, [x26, #-112]
	ldur	q0, [x26, #-64]
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x26, #80]
	stp	q2, q1, [x29, #-208]            // 32-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q2, q0, [x26, #-48]
	str	q2, [sp, #464]                  // 16-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x26, #48]
	str	q1, [sp, #448]                  // 16-byte Folded Spill
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #448]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #432]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q2, q0, [x26, #-16]
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [x26, #16]
	str	q1, [sp, #384]                  // 16-byte Folded Spill
	stp	q0, q2, [sp, #400]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x20, #-16]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x25
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x24
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x23
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x22
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x21
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	mov	x2, x27
	add	x8, x20, x19
	add	x20, x20, #32
	subs	x2, x27, #1
	add	x26, x26, #224
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB37_3
	b	.LBB37_10
.LBB37_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	str	x5, [sp, #128]                  // 8-byte Folded Spill
	cbz	x2, .LBB37_10
// %bb.5:
	lsl	x9, x2, #1
	lsl	x10, x2, #2
	ldp	x19, x27, [sp, #136]            // 16-byte Folded Reload
	mul	x8, x2, x1
	mov	w15, #96
	str	x9, [sp, #104]                  // 8-byte Folded Spill
	add	x9, x9, x2
	lsl	x11, x9, #1
	ldr	x16, [sp, #8]                   // 8-byte Folded Reload
	madd	x5, x8, x15, x19
	ldr	x15, [sp, #128]                 // 8-byte Folded Reload
	stp	x10, x9, [sp, #88]              // 16-byte Folded Spill
	add	x9, x10, x2
	add	x10, x19, x8, lsl #7
	add	x12, x16, x16, lsl #1
	lsl	x12, x12, #5
	mov	x23, x1
	stp	x9, x11, [sp, #72]              // 16-byte Folded Spill
	mov	w9, #224
	str	x10, [sp, #160]                 // 8-byte Folded Spill
	lsl	x10, x1, #5
	mul	x9, x1, x9
	add	x17, x27, x10
	lsl	x14, x16, #7
	mov	x25, xzr
	stp	x23, x2, [sp, #112]             // 16-byte Folded Spill
	stp	x9, x10, [sp, #56]              // 16-byte Folded Spill
	lsl	x10, x16, #6
	add	x11, x10, x27
	mov	w9, #192
	add	x0, x11, #64
	add	x11, x16, x16, lsl #2
	lsl	x11, x11, #5
	add	x10, x15, x10
	add	x13, x11, x27
	madd	x18, x1, x9, x27
	add	x1, x13, #160
	add	x13, x12, x27
	add	x12, x15, x12
	stp	x10, x12, [sp, #40]             // 16-byte Folded Spill
	adrp	x10, .LCPI37_0
	add	x3, x13, #96
	add	x13, x14, x27
	add	x11, x15, x11
	mov	w12, #160
	add	x4, x13, #128
	add	x13, x15, x14
	madd	x6, x8, x12, x19
	adrp	x12, .LCPI37_1
	ldr	q0, [x10, :lo12:.LCPI37_0]
	adrp	x10, .LCPI37_3
	str	x13, [sp, #32]                  // 8-byte Folded Spill
	adrp	x13, .LCPI37_2
	ldp	x24, x22, [sp, #40]             // 16-byte Folded Reload
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	add	x14, x15, x16, lsl #5
	ldr	q0, [x12, :lo12:.LCPI37_1]
	adrp	x12, .LCPI37_4
	ldr	x28, [sp, #32]                  // 8-byte Folded Reload
	stp	x11, x14, [sp, #16]             // 16-byte Folded Spill
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI37_2]
	adrp	x13, .LCPI37_5
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI37_3]
	adrp	x10, .LCPI37_6
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI37_4]
	adrp	x12, .LCPI37_7
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI37_5]
	add	x13, x19, x8, lsl #6
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI37_6]
	add	x10, x19, x8, lsl #5
	madd	x8, x8, x9, x19
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI37_7]
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	b	.LBB37_7
.LBB37_6:                               //   in Loop: Header=BB37_7 Depth=1
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	mov	x8, x25
	ldp	x12, x11, [sp, #240]            // 16-byte Folded Reload
	add	x8, x8, x9
	ldr	x25, [sp, #152]                 // 8-byte Folded Reload
	ldp	x14, x13, [sp, #224]            // 16-byte Folded Reload
	ldp	x16, x15, [sp, #208]            // 16-byte Folded Reload
	str	x8, [sp, #160]                  // 8-byte Folded Spill
	add	x25, x25, #1
	ldp	x20, x19, [sp, #168]            // 16-byte Folded Reload
	ldr	x8, [sp, #56]                   // 8-byte Folded Reload
	ldp	x6, x5, [sp, #192]              // 16-byte Folded Reload
	add	x27, x20, x8
	add	x17, x12, x8
	add	x18, x11, x8
	add	x0, x13, x8
	add	x1, x14, x8
	add	x3, x15, x8
	add	x4, x16, x8
	ldr	x7, [sp, #184]                  // 8-byte Folded Reload
	ldp	x10, x8, [sp, #256]             // 16-byte Folded Reload
	add	x19, x19, x9
	add	x5, x5, x9
	ldp	x23, x2, [sp, #112]             // 16-byte Folded Reload
	add	x6, x6, x9
	add	x13, x7, x9
	add	x10, x10, x9
	add	x8, x8, x9
	cmp	x25, x2
	b.eq	.LBB37_10
.LBB37_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB37_9 Depth 2
	str	x8, [sp, #264]                  // 8-byte Folded Spill
	lsl	x8, x25, #3
	sub	x20, x8, x25
	ldr	x26, [sp, #144]                 // 8-byte Folded Reload
	stp	x18, x10, [sp, #248]            // 16-byte Folded Spill
	add	x8, x20, #6
	mul	x9, x20, x23
	stp	x27, x19, [sp, #168]            // 16-byte Folded Spill
	mul	x8, x8, x23
	stp	x13, x6, [sp, #184]             // 16-byte Folded Spill
	add	x10, x23, x9
	stp	x5, x4, [sp, #200]              // 16-byte Folded Spill
	add	x9, x26, x9, lsl #5
	stp	x3, x1, [sp, #216]              // 16-byte Folded Spill
	add	x10, x26, x10, lsl #5
	add	x8, x26, x8, lsl #5
	stp	x0, x17, [sp, #232]             // 16-byte Folded Spill
	mov	x19, x2
	ldp	q1, q0, [x9]
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q2, q0, [x10]
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x8]
	stp	q2, q1, [x29, #-208]            // 32-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #2
	add	x9, x20, #5
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mul	x8, x8, x23
	mul	x9, x9, x23
	add	x8, x26, x8, lsl #5
	add	x9, x26, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #464]                  // 16-byte Folded Spill
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #448]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #432]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #3
	add	x9, x20, #4
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	mul	x8, x8, x23
	mul	x9, x9, x23
	add	x8, x26, x8, lsl #5
	add	x9, x26, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	stp	q2, q0, [sp, #384]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x25, x23
	ldr	x21, [sp, #136]                 // 8-byte Folded Reload
	add	x20, x21, x8, lsl #5
	str	q0, [x20]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20, #16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	add	x8, x25, x19
	add	x9, x25, x9
	mul	x20, x8, x23
	mul	x26, x9, x23
	bl	__subtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x20, lsl #5
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x26, lsl #5
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	x9, [sp, #72]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x23
	mul	x26, x9, x23
	bl	__subtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x20, lsl #5
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x26, lsl #5
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldp	x9, x8, [sp, #88]               // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	str	x25, [sp, #152]                 // 8-byte Folded Spill
	add	x9, x25, x9
	add	x8, x25, x8
	mul	x26, x9, x23
	mul	x20, x8, x23
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x20, lsl #5
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	ldp	x27, x19, [sp, #16]             // 16-byte Folded Reload
	add	x8, x21, x26, lsl #5
	cmp	x23, #2
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	ldr	x23, [sp, #128]                 // 8-byte Folded Reload
	ldr	x25, [sp, #160]                 // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB37_6
// %bb.8:                               //   in Loop: Header=BB37_7 Depth=1
	mov	x26, xzr
	ldr	x20, [sp, #8]                   // 8-byte Folded Reload
.LBB37_9:                               //   Parent Loop BB37_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	ldp	x9, x10, [sp, #240]             // 16-byte Folded Reload
	add	x8, x8, x26
	add	x9, x9, x26
	add	x10, x10, x26
	ldr	q1, [x8, #32]
	ldr	q0, [x8, #48]
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q2, q0, [x9, #32]
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	stp	q2, q1, [x29, #-208]            // 32-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #224]              // 16-byte Folded Reload
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	add	x9, x9, x26
	add	x8, x8, x26
	ldp	q2, q0, [x8, #32]
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #464]                  // 16-byte Folded Spill
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #448]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #432]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #208]              // 16-byte Folded Reload
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	add	x9, x9, x26
	add	x8, x8, x26
	ldp	q2, q0, [x8, #32]
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	stp	q2, q0, [sp, #384]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	add	x21, x8, x26
	str	q0, [x21, #32]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x21, #48]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x23, x26
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	str	q1, [sp, #272]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #352]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x27, x26
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	ldp	q1, q2, [x8]
	add	x9, x9, x26
	str	q1, [sp, #368]                  // 16-byte Folded Spill
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	str	q2, [sp, #336]                  // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x26
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	str	q1, [sp, #272]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #352]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x26
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	ldp	q1, q2, [x8]
	add	x9, x9, x26
	str	q1, [sp, #368]                  // 16-byte Folded Spill
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	str	q2, [sp, #336]                  // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-128]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x24, x26
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	stur	q1, [x29, #-192]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x26
	ldr	x9, [sp, #200]                  // 8-byte Folded Reload
	ldp	q1, q2, [x8]
	add	x9, x9, x26
	stur	q1, [x29, #-128]                // 16-byte Folded Spill
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stur	q2, [x29, #-160]                // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-128]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x25, x26
	subs	x20, x20, #1
	add	x26, x26, #32
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB37_9
	b	.LBB37_6
.LBB37_10:
	add	sp, sp, #752
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end37:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end37-_ZNK9pocketfft6detail5cfftpIeE5pass7ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI38_0:
	.xword	0x9ab7f42d86f0d233              // fp128 0.841253532831181168861811648919367736
	.xword	0x3ffeaeb8c8764f0b
.LCPI38_1:
	.xword	0x5d3ef32457c6d64d              // fp128 0.415415013001886425529274149229623209
	.xword	0x3ffda9628d9c712b
.LCPI38_2:
	.xword	0xae3195b1d88fde6c              // fp128 0.142314838273285140443792668616369701
	.xword	0x3ffc2375f640f44d
.LCPI38_3:
	.xword	0x6abb6d39b8208cdf              // fp128 0.654860733945285064056925072466293599
	.xword	0x3ffe4f49e7f77588
.LCPI38_4:
	.xword	0x730f9b19848fb8e0              // fp128 0.959492973614497389890368057066327693
	.xword	0x3ffeeb42a9bcd505
.LCPI38_5:
	.xword	0x35f3c16be82729d8              // fp128 -0.909631995354518371411715383079028459
	.xword	0xbffed1bb48eee2c1
.LCPI38_6:
	.xword	0xb3d83c97abe14dd6              // fp128 -0.540640817455597582107635954318691673
	.xword	0xbffe14cedf8bb580
.LCPI38_7:
	.xword	0xf6f09deb712450b8              // fp128 -0.989821441880932732376092037776718829
	.xword	0xbffefac9e043842e
.LCPI38_8:
	.xword	0x122496a483c5ac91              // fp128 -0.755749574354258283774035843972344387
	.xword	0xbffe82f19bb3a28a
.LCPI38_9:
	.xword	0xf7b05d1c551985c8              // fp128 -0.281732556841429697711417915346616884
	.xword	0xbffd207e7fd768db
.LCPI38_10:
	.xword	0xf7b05d1c551985c8              // fp128 0.281732556841429697711417915346616884
	.xword	0x3ffd207e7fd768db
.LCPI38_11:
	.xword	0xf6f09deb712450b8              // fp128 0.989821441880932732376092037776718829
	.xword	0x3ffefac9e043842e
.LCPI38_12:
	.xword	0xb3d83c97abe14dd6              // fp128 0.540640817455597582107635954318691673
	.xword	0x3ffe14cedf8bb580
.LCPI38_13:
	.xword	0x35f3c16be82729d8              // fp128 0.909631995354518371411715383079028459
	.xword	0x3ffed1bb48eee2c1
	.section	.text._ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #1136
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	str	x5, [sp, #216]                  // 8-byte Folded Spill
	stp	x4, x3, [sp, #192]              // 16-byte Folded Spill
	b.ne	.LBB38_4
// %bb.1:
	cbz	x2, .LBB38_10
// %bb.2:
	mov	w10, #224
	ldr	x11, [sp, #192]                 // 8-byte Folded Reload
	add	x8, x2, x2, lsl #1
	add	x9, x2, x2, lsl #2
	mul	x10, x2, x10
	lsl	x18, x8, #6
	add	x20, x11, #16
	lsl	x11, x9, #5
	lsl	x26, x8, #5
	adrp	x8, .LCPI38_0
	lsl	x23, x2, #7
	lsl	x24, x2, #8
	str	x10, [sp, #416]                 // 8-byte Folded Spill
	ldr	x10, [sp, #200]                 // 8-byte Folded Reload
	stp	x11, x18, [sp, #440]            // 16-byte Folded Spill
	adrp	x11, .LCPI38_1
	ldr	q0, [x8, :lo12:.LCPI38_0]
	adrp	x8, .LCPI38_3
	add	x25, x10, #176
	add	x10, x2, x2, lsl #3
	lsl	x27, x10, #5
	adrp	x10, .LCPI38_2
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI38_1]
	adrp	x11, .LCPI38_4
	lsl	x28, x2, #6
	lsl	x19, x9, #6
	lsl	x21, x2, #5
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI38_2]
	adrp	x10, .LCPI38_5
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI38_3]
	adrp	x8, .LCPI38_6
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI38_4]
	adrp	x11, .LCPI38_7
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI38_5]
	adrp	x10, .LCPI38_8
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI38_6]
	adrp	x8, .LCPI38_9
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI38_7]
	adrp	x11, .LCPI38_10
	str	q0, [sp, #800]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI38_8]
	adrp	x10, .LCPI38_11
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI38_9]
	adrp	x8, .LCPI38_12
	str	q0, [sp, #784]                  // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI38_10]
	adrp	x11, .LCPI38_13
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI38_11]
	str	q0, [sp, #560]                  // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI38_12]
	str	q0, [sp, #544]                  // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI38_13]
	str	q0, [sp, #768]                  // 16-byte Folded Spill
.LBB38_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x25, #-160]
	mov	x22, x2
	ldur	q1, [x25, #-176]
	ldur	q3, [x25, #-128]
	stp	q1, q0, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x25, #144]
	stp	q2, q1, [x29, #-240]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-208]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #752]                  // 16-byte Folded Spill
	ldp	q2, q0, [x25, #-112]
	stur	q2, [x29, #-256]                // 16-byte Folded Spill
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q1, q0, [x25, #112]
	str	q1, [sp, #864]                  // 16-byte Folded Spill
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	ldp	q2, q0, [x25, #-80]
	str	q2, [sp, #848]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [x25, #80]
	str	q1, [sp, #832]                  // 16-byte Folded Spill
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #720]                  // 16-byte Folded Spill
	ldp	q2, q3, [x25, #-48]
	ldp	q1, q0, [x25, #48]
	stp	q1, q2, [sp, #672]              // 32-byte Folded Spill
	stp	q0, q3, [sp, #832]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #672]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #624]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #688]                  // 16-byte Folded Spill
	ldp	q2, q0, [x25, #-16]
	str	q2, [sp, #608]                  // 16-byte Folded Spill
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldp	q1, q0, [x25, #16]
	stp	q1, q0, [sp, #512]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x20, #-16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #832]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x21
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x19
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x28
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x27
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x26
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x24
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x23
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #416]                  // 8-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	add	x8, x20, x8
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-144]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #440]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	add	x8, x20, x8
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #448]                  // 8-byte Folded Reload
	mov	x2, x22
	subs	x2, x22, #1
	add	x25, x25, #352
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	add	x8, x20, x8
	add	x20, x20, #32
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB38_3
	b	.LBB38_10
.LBB38_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	cbz	x2, .LBB38_10
// %bb.5:
	ldp	x27, x19, [sp, #192]            // 16-byte Folded Reload
	mul	x8, x2, x1
	mov	w10, #192
	mov	w11, #352
	ldr	x4, [sp, #8]                    // 8-byte Folded Reload
	ldr	x22, [sp, #216]                 // 8-byte Folded Reload
	lsl	x9, x2, #2
	madd	x10, x8, x10, x27
	add	x5, x9, x2
	lsl	x12, x4, #6
	add	x13, x4, x4, lsl #1
	lsl	x14, x13, #5
	lsl	x17, x4, #7
	add	x15, x14, x19
	add	x18, x17, x19
	str	x10, [sp, #392]                 // 8-byte Folded Spill
	mul	x10, x1, x11
	add	x21, x15, #96
	mov	w15, #224
	add	x26, x18, #128
	add	x18, x4, x4, lsl #2
	mul	x0, x4, x15
	str	x9, [sp, #176]                  // 8-byte Folded Spill
	str	x10, [sp, #160]                 // 8-byte Folded Spill
	add	x10, x12, x19
	add	x7, x10, #64
	add	x10, x4, x4, lsl #3
	lsl	x10, x10, #5
	mov	w9, #320
	add	x11, x10, x19
	lsl	x13, x13, #6
	add	x20, x11, #288
	lsl	x11, x4, #8
	add	x16, x11, x19
	mov	x28, x1
	add	x24, x16, #256
	add	x16, x0, x19
	add	x16, x16, #224
	madd	x6, x1, x9, x19
	add	x1, x13, x19
	add	x13, x22, x13
	add	x12, x22, x12
	add	x11, x22, x11
	str	x16, [sp, #384]                 // 8-byte Folded Spill
	lsl	x16, x18, #5
	add	x18, x16, x19
	add	x16, x22, x16
	stp	x11, x12, [sp, #96]             // 16-byte Folded Spill
	adrp	x12, .LCPI38_2
	add	x10, x22, x10
	mov	w3, #160
	str	x16, [sp, #152]                 // 8-byte Folded Spill
	add	x16, x22, x17
	lsl	x17, x2, #3
	mov	w11, #288
	madd	x3, x8, x3, x27
	stp	x13, x16, [sp, #136]            // 16-byte Folded Spill
	add	x13, x22, x14
	add	x14, x22, x0
	add	x0, x17, x2
	madd	x15, x8, x15, x27
	str	x10, [sp, #88]                  // 8-byte Folded Spill
	str	x13, [sp, #128]                 // 8-byte Folded Spill
	adrp	x13, .LCPI38_0
	str	x14, [sp, #112]                 // 8-byte Folded Spill
	adrp	x14, .LCPI38_1
	stp	x0, x17, [sp, #56]              // 16-byte Folded Spill
	sub	x17, x17, x2
	ldr	q0, [x13, :lo12:.LCPI38_0]
	adrp	x13, .LCPI38_3
	madd	x9, x8, x9, x27
	mov	x25, xzr
	madd	x10, x8, x11, x27
	add	x18, x18, #160
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI38_1]
	adrp	x14, .LCPI38_4
	add	x1, x1, #192
	add	x16, x27, x8, lsl #7
	add	x11, x27, x8, lsl #5
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI38_2]
	adrp	x12, .LCPI38_5
	str	x5, [sp, #168]                  // 8-byte Folded Spill
	str	x2, [sp, #184]                  // 8-byte Folded Spill
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI38_3]
	adrp	x13, .LCPI38_6
	str	x28, [sp, #120]                 // 8-byte Folded Spill
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI38_4]
	adrp	x14, .LCPI38_7
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI38_5]
	adrp	x12, .LCPI38_8
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI38_6]
	adrp	x13, .LCPI38_9
	str	q0, [sp, #800]                  // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI38_7]
	adrp	x14, .LCPI38_10
	str	q0, [sp, #784]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI38_8]
	adrp	x12, .LCPI38_11
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI38_9]
	adrp	x13, .LCPI38_12
	str	q0, [sp, #768]                  // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI38_10]
	mov	w14, #96
	str	q0, [sp, #560]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI38_11]
	adrp	x12, .LCPI38_13
	madd	x14, x8, x14, x27
	str	q0, [sp, #544]                  // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI38_12]
	add	x13, x27, x8, lsl #8
	add	x8, x27, x8, lsl #6
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI38_13]
	lsl	x12, x5, #1
	str	q0, [sp, #752]                  // 16-byte Folded Spill
	str	x12, [sp, #80]                  // 8-byte Folded Spill
	lsl	x12, x2, #1
	str	x12, [sp, #72]                  // 8-byte Folded Spill
	add	x12, x12, x2
	stp	x17, x12, [sp, #40]             // 16-byte Folded Spill
	lsl	x17, x28, #5
	lsl	x12, x12, #1
	add	x23, x19, x17
	stp	x12, x17, [sp, #24]             // 16-byte Folded Spill
	add	x17, x22, x4, lsl #5
	str	x17, [sp, #16]                  // 8-byte Folded Spill
	b	.LBB38_7
.LBB38_6:                               //   in Loop: Header=BB38_7 Depth=1
	mov	x8, x9
	ldr	x9, [sp, #32]                   // 8-byte Folded Reload
	ldp	x10, x11, [sp, #376]            // 16-byte Folded Reload
	add	x8, x8, x9
	ldr	x0, [sp, #352]                  // 8-byte Folded Reload
	ldp	x18, x16, [sp, #296]            // 16-byte Folded Reload
	str	x8, [sp, #392]                  // 8-byte Folded Spill
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	ldp	x14, x13, [sp, #320]            // 16-byte Folded Reload
	ldp	x3, x1, [sp, #280]              // 16-byte Folded Reload
	add	x11, x11, x8
	add	x0, x0, x8
	ldr	x23, [sp, #224]                 // 8-byte Folded Reload
	add	x6, x16, x8
	ldr	x15, [sp, #312]                 // 8-byte Folded Reload
	add	x7, x18, x8
	add	x20, x10, x8
	add	x21, x14, x8
	add	x23, x23, x8
	add	x24, x13, x8
	add	x26, x15, x8
	str	x11, [sp, #384]                 // 8-byte Folded Spill
	add	x18, x1, x8
	add	x3, x3, x8
	ldp	x8, x17, [sp, #360]             // 16-byte Folded Reload
	mov	x1, x3
	ldp	x5, x4, [sp, #264]              // 16-byte Folded Reload
	ldp	x12, x11, [sp, #336]            // 16-byte Folded Reload
	add	x17, x17, x9
	add	x8, x8, x9
	ldp	x22, x19, [sp, #248]            // 16-byte Folded Reload
	add	x4, x4, x9
	add	x15, x5, x9
	ldp	x30, x27, [sp, #232]            // 16-byte Folded Reload
	add	x11, x11, x9
	add	x10, x12, x9
	ldr	x25, [sp, #208]                 // 8-byte Folded Reload
	add	x13, x22, x9
	ldr	x2, [sp, #184]                  // 8-byte Folded Reload
	add	x16, x19, x9
	add	x30, x30, x9
	mov	x3, x4
	add	x25, x25, #1
	add	x14, x27, x9
	ldr	x28, [sp, #120]                 // 8-byte Folded Reload
	mov	x9, x11
	mov	x11, x30
	mov	x27, x17
	mov	x19, x0
	cmp	x25, x2
	b.eq	.LBB38_10
.LBB38_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB38_9 Depth 2
	mov	w17, #11
	stp	x27, x20, [sp, #368]            // 16-byte Folded Spill
	stp	x21, x24, [sp, #320]            // 16-byte Folded Spill
	ldr	x24, [sp, #200]                 // 8-byte Folded Reload
	mul	x20, x25, x17
	stp	x10, x9, [sp, #336]             // 16-byte Folded Spill
	stp	x19, x8, [sp, #352]             // 16-byte Folded Spill
	mov	x21, x2
	add	x8, x20, #10
	stp	x23, x11, [sp, #224]            // 16-byte Folded Spill
	mul	x9, x20, x28
	stp	x14, x13, [sp, #240]            // 16-byte Folded Spill
	mul	x8, x8, x28
	stp	x16, x15, [sp, #256]            // 16-byte Folded Spill
	add	x10, x28, x9
	stp	x3, x1, [sp, #272]              // 16-byte Folded Spill
	add	x9, x24, x9, lsl #5
	stp	x18, x7, [sp, #288]             // 16-byte Folded Spill
	add	x10, x24, x10, lsl #5
	add	x8, x24, x8, lsl #5
	stp	x6, x26, [sp, #304]             // 16-byte Folded Spill
	ldr	q0, [x9]
	ldp	q2, q3, [x10]
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [x9, #16]
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x8]
	stp	q2, q1, [x29, #-240]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-208]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #720]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #2
	add	x9, x20, #9
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q3, [x8]
	str	q2, [sp, #864]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stur	q1, [x29, #-256]                // 16-byte Folded Spill
	stp	q0, q3, [x29, #-240]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #3
	add	x9, x20, #8
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #832]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q1, q0, [sp, #848]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #4
	add	x9, x20, #7
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q3, [x8]
	str	q2, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #688]                  // 16-byte Folded Spill
	stp	q0, q3, [sp, #832]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #688]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #624]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #5
	add	x9, x20, #6
	str	q0, [sp, #688]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #512]                  // 16-byte Folded Spill
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q0, q1, [sp, #592]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x25, x28
	ldr	x22, [sp, #192]                 // 8-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	add	x20, x22, x8, lsl #5
	str	q0, [x20]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #832]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20, #16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #800]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x21
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	x9, [sp, #56]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	x9, [sp, #40]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	str	x25, [sp, #208]                 // 8-byte Folded Spill
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	cmp	x28, #2
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x27, x26, [sp, #128]            // 16-byte Folded Reload
	ldp	x23, x19, [sp, #104]            // 16-byte Folded Reload
	ldp	x20, x25, [sp, #88]             // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	ldr	x9, [sp, #392]                  // 8-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB38_6
// %bb.8:                               //   in Loop: Header=BB38_7 Depth=1
	mov	x10, xzr
	ldr	x11, [sp, #8]                   // 8-byte Folded Reload
	str	x9, [sp, #392]                  // 8-byte Folded Spill
.LBB38_9:                               //   Parent Loop BB38_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	stur	x10, [x29, #-32]                // 8-byte Folded Spill
	ldr	x9, [sp, #224]                  // 8-byte Folded Reload
	str	x11, [sp, #440]                 // 8-byte Folded Spill
	ldur	x11, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x10
	add	x9, x9, x10
	ldr	x10, [sp, #304]                 // 8-byte Folded Reload
	ldr	q1, [x8, #32]
	add	x10, x10, x11
	ldp	q2, q3, [x9, #32]
	ldr	q0, [x8, #48]
	stp	q1, q0, [x29, #-160]            // 32-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	stp	q1, q2, [x29, #-256]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-224]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #296]                  // 8-byte Folded Reload
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #376]                  // 8-byte Folded Reload
	ldp	q2, q0, [x8, #32]
	add	x9, x9, x10
	str	q2, [sp, #848]                  // 16-byte Folded Spill
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #864]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #848]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #320]                  // 8-byte Folded Reload
	str	q0, [sp, #720]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #328]                  // 8-byte Folded Reload
	add	x9, x9, x10
	ldp	q2, q3, [x8, #32]
	ldp	q1, q0, [x9, #32]
	stp	q2, q1, [sp, #816]              // 32-byte Folded Spill
	stp	q0, q3, [sp, #848]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #848]              // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #816]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #624]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #848]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #312]                  // 8-byte Folded Reload
	str	q0, [sp, #688]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	add	x9, x9, x10
	ldp	q2, q3, [x8, #32]
	str	q2, [sp, #640]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #672]                  // 16-byte Folded Spill
	stp	q0, q3, [sp, #816]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #816]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #672]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #816]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #288]                  // 8-byte Folded Reload
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #280]                  // 8-byte Folded Reload
	ldp	q2, q0, [x8, #32]
	add	x9, x9, x10
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #592]                  // 16-byte Folded Spill
	stp	q2, q0, [sp, #496]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #832]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #368]                  // 8-byte Folded Reload
	mov	x24, x20
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	mov	x20, x25
	mov	x25, x23
	mov	x23, x19
	mov	x19, x27
	mov	x27, x26
	mov	x26, x22
	mov	x22, x21
	add	x21, x8, x9
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	str	q0, [x21, #32]
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x21, #48]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	mov	x21, x22
	mov	x22, x26
	mov	x26, x27
	mov	x27, x19
	mov	x19, x23
	mov	x23, x25
	mov	x25, x20
	mov	x20, x24
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #216]                  // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	add	x8, x8, x9
	ldp	q0, q1, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	str	q1, [sp, #400]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #232]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x24, x8
	add	x9, x9, x10
	ldp	q1, q2, [x8]
	str	q1, [sp, #480]                  // 16-byte Folded Spill
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #344]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	add	x8, x28, x8
	ldp	q0, q1, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	str	q1, [sp, #400]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #360]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x25, x8
	add	x9, x9, x10
	ldp	q1, q2, [x8]
	str	q1, [sp, #480]                  // 16-byte Folded Spill
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #336]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	add	x8, x23, x8
	ldp	q0, q1, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	str	q1, [sp, #400]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #240]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x19, x8
	add	x9, x9, x10
	ldp	q1, q2, [x8]
	str	q1, [sp, #480]                  // 16-byte Folded Spill
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #248]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	add	x8, x27, x8
	ldp	q0, q1, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	str	q1, [sp, #400]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x26, x8
	add	x9, x9, x10
	ldp	q1, q2, [x8]
	str	q1, [sp, #480]                  // 16-byte Folded Spill
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	add	x8, x22, x8
	ldp	q0, q1, [x8]
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	stur	q1, [x29, #-240]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-192]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #272]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x21, x8
	add	x9, x9, x10
	ldp	q1, q2, [x8]
	stur	q1, [x29, #-176]                // 16-byte Folded Spill
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	stur	q2, [x29, #-208]                // 16-byte Folded Spill
	stp	q1, q0, [x9, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x11, [sp, #440]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	ldr	x9, [sp, #392]                  // 8-byte Folded Reload
	subs	x11, x11, #1
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	add	x8, x9, x10
	add	x10, x10, #32
	stp	q1, q0, [x8, #32]
	b.ne	.LBB38_9
	b	.LBB38_6
.LBB38_10:
	add	sp, sp, #1136
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end38:
	.size	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end38-_ZNK9pocketfft6detail5cfftpIeE6pass11ILb1ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
.LCPI39_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
.LCPI39_1:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_,@function
_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_: // @_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #432
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #5
	mov	x25, x7
	add	x0, x8, #64
	mov	x19, x6
	mov	x20, x2
	str	x5, [sp, #88]                   // 8-byte Folded Spill
	str	x4, [sp, #120]                  // 8-byte Folded Spill
	mov	x24, x3
	mov	x27, x1
	bl	malloc
	cbz	x0, .LBB39_76
// %bb.1:
	adrp	x8, .LCPI39_0
	adrp	x10, .LCPI39_1
	add	x9, x0, #64
	add	x21, x20, #1
	mul	x26, x24, x27
	and	x9, x9, #0xffffffffffffffc0
	ldr	q0, [x8, :lo12:.LCPI39_0]
	subs	x12, x20, #2
	ldr	q1, [x10, :lo12:.LCPI39_1]
	lsr	x8, x21, #1
	stur	x0, [x9, #-8]
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	stp	q0, q1, [x9]
	str	x24, [sp, #128]                 // 8-byte Folded Spill
	stp	x27, x20, [sp, #200]            // 16-byte Folded Spill
	str	x26, [sp, #216]                 // 8-byte Folded Spill
	b.lo	.LBB39_8
// %bb.2:
	sub	x16, x20, #1
	add	x8, x25, #48
	add	x9, x9, #48
	mov	x10, x16
.LBB39_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x8, #-16]
	subs	x10, x10, #1
	add	x8, x8, #32
	stur	q0, [x29, #-32]
	ldurb	w11, [x29, #-17]
	eor	w11, w11, #0x80
	sturb	w11, [x29, #-17]
	ldur	q0, [x29, #-32]
	stp	q1, q0, [x9, #-16]
	add	x9, x9, #32
	b.ne	.LBB39_3
// %bb.4:
	cbz	x24, .LBB39_28
// %bb.5:
	cbnz	x27, .LBB39_10
// %bb.6:
	cmp	x21, #3
	b.ls	.LBB39_64
// %bb.7:
	ldr	x26, [sp, #216]                 // 8-byte Folded Reload
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	mov	w9, wzr
	b	.LBB39_42
.LBB39_8:
	cbz	x24, .LBB39_64
// %bb.9:
	cbz	x27, .LBB39_64
.LBB39_10:
	mul	x8, x20, x27
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	lsl	x28, x27, #5
	mov	x19, x24
	lsl	x22, x8, #5
	ldr	x26, [sp, #88]                  // 8-byte Folded Reload
	ldr	x27, [sp, #120]                 // 8-byte Folded Reload
	str	x12, [sp, #152]                 // 8-byte Folded Spill
.LBB39_11:                              // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	mov	x2, x28
	bl	memcpy
	add	x27, x27, x22
	add	x26, x26, x28
	subs	x19, x19, #1
	b.ne	.LBB39_11
// %bb.12:
	sub	x8, x20, #1
	cmp	x21, #3
	stur	x22, [x29, #-160]               // 8-byte Folded Spill
	str	x21, [sp, #160]                 // 8-byte Folded Spill
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	stur	x28, [x29, #-144]               // 8-byte Folded Spill
	b.ls	.LBB39_20
// %bb.13:
	ldr	x9, [sp, #200]                  // 8-byte Folded Reload
	cbz	x9, .LBB39_41
// %bb.14:
	ldr	x11, [sp, #112]                 // 8-byte Folded Reload
	neg	x10, x28
	mov	w8, #2
	ldr	x13, [sp, #16]                  // 8-byte Folded Reload
	cmp	x11, #2
	stur	x10, [x29, #-208]               // 8-byte Folded Spill
	ldr	x12, [sp, #216]                 // 8-byte Folded Reload
	csel	x8, x11, x8, hi
	mul	x9, x9, x13
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	ldr	x11, [sp, #120]                 // 8-byte Folded Reload
	str	x8, [sp, #192]                  // 8-byte Folded Spill
	mul	x8, x12, x13
	add	x10, x14, x12, lsl #5
	add	x9, x11, x9, lsl #5
	add	x22, x10, #16
	add	x25, x9, #16
	lsl	x10, x12, #5
	add	x9, x11, x28
	add	x8, x14, x8, lsl #5
	add	x27, x9, #16
	add	x20, x8, #16
	neg	x8, x10
	mov	w9, #1
	stp	x8, x10, [sp, #168]             // 16-byte Folded Spill
.LBB39_15:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB39_16 Depth 2
                                        //       Child Loop BB39_17 Depth 3
	mov	x23, xzr
	stp	x9, x20, [x29, #-200]           // 16-byte Folded Spill
	stp	x27, x25, [x29, #-184]          // 16-byte Folded Spill
	stur	x22, [x29, #-168]               // 8-byte Folded Spill
.LBB39_16:                              //   Parent Loop BB39_15 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB39_17 Depth 3
	mov	x19, x20
	mov	x28, x27
	mov	x24, x22
	mov	x26, x25
	ldr	x21, [sp, #200]                 // 8-byte Folded Reload
.LBB39_17:                              //   Parent Loop BB39_15 Depth=1
                                        //     Parent Loop BB39_16 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q3, [x28, #-16]
	ldp	q1, q0, [x26, #-16]
	stp	q1, q2, [x29, #-112]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-80]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x24, #-16]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	subs	x21, x21, #1
	add	x26, x26, #32
	add	x24, x24, #32
	add	x28, x28, #32
	stp	q1, q0, [x19, #-16]
	add	x19, x19, #32
	b.ne	.LBB39_17
// %bb.18:                              //   in Loop: Header=BB39_16 Depth=2
	ldur	x8, [x29, #-160]                // 8-byte Folded Reload
	add	x23, x23, #1
	ldur	x28, [x29, #-144]               // 8-byte Folded Reload
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	add	x25, x25, x8
	add	x27, x27, x8
	add	x22, x22, x28
	add	x20, x20, x28
	cmp	x23, x24
	b.ne	.LBB39_16
// %bb.19:                              //   in Loop: Header=BB39_15 Depth=1
	ldp	x8, x9, [x29, #-208]            // 16-byte Folded Reload
	ldp	x25, x22, [x29, #-176]          // 16-byte Folded Reload
	ldp	x20, x27, [x29, #-192]          // 16-byte Folded Reload
	add	x9, x9, #1
	add	x25, x25, x8
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	add	x22, x22, x8
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	add	x27, x27, x28
	add	x20, x20, x8
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	cmp	x9, x8
	b.ne	.LBB39_15
.LBB39_20:
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	ldr	x26, [sp, #216]                 // 8-byte Folded Reload
	cbz	x27, .LBB39_34
// %bb.21:
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	cmp	x8, #3
	b.ls	.LBB39_30
// %bb.22:
	ldr	x9, [sp, #112]                  // 8-byte Folded Reload
	mov	w8, #2
	mov	x19, xzr
	lsl	x22, x26, #5
	cmp	x9, #2
	csel	x8, x9, x8, hi
	ldr	x9, [sp, #88]                   // 8-byte Folded Reload
	sub	x20, x8, #1
	add	x9, x9, x26, lsl #5
	add	x21, x9, #16
.LBB39_23:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB39_24 Depth 2
                                        //       Child Loop BB39_25 Depth 3
	mul	x24, x19, x27
	mov	x23, xzr
	mov	x25, x21
.LBB39_24:                              //   Parent Loop BB39_23 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB39_25 Depth 3
	ldr	x8, [sp, #88]                   // 8-byte Folded Reload
	add	x26, x23, x24
	mov	x27, x25
	mov	x28, x20
	add	x8, x8, x26, lsl #5
	ldp	q0, q1, [x8]
.LBB39_25:                              //   Parent Loop BB39_23 Depth=1
                                        //     Parent Loop BB39_24 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	stur	q1, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q1, [x27, #-16]
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q1, [x27]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	subs	x28, x28, #1
	add	x27, x27, x22
	b.ne	.LBB39_25
// %bb.26:                              //   in Loop: Header=BB39_24 Depth=2
	ldr	x8, [sp, #120]                  // 8-byte Folded Reload
	add	x23, x23, #1
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	add	x25, x25, #32
	add	x8, x8, x26, lsl #5
	cmp	x23, x27
	stp	q0, q1, [x8]
	b.ne	.LBB39_24
// %bb.27:                              //   in Loop: Header=BB39_23 Depth=1
	ldur	x8, [x29, #-144]                // 8-byte Folded Reload
	add	x19, x19, #1
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	ldr	x26, [sp, #216]                 // 8-byte Folded Reload
	add	x21, x21, x8
	cmp	x19, x24
	b.ne	.LBB39_23
	b	.LBB39_34
.LBB39_28:
	mov	w9, #1
	cmp	x21, #3
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	b.hi	.LBB39_42
// %bb.29:
	mov	w8, wzr
	subs	x10, x27, #1
	str	x10, [sp, #208]                 // 8-byte Folded Spill
	b.eq	.LBB39_36
	b	.LBB39_62
.LBB39_30:
	ldr	x9, [sp, #120]                  // 8-byte Folded Reload
	mov	x8, xzr
	ldr	x10, [sp, #88]                  // 8-byte Folded Reload
	add	x9, x9, #16
	add	x10, x10, #16
.LBB39_31:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB39_32 Depth 2
	mov	x11, x10
	mov	x12, x9
	mov	x13, x27
.LBB39_32:                              //   Parent Loop BB39_31 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x13, x13, #1
	add	x11, x11, #32
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB39_32
// %bb.33:                              //   in Loop: Header=BB39_31 Depth=1
	add	x8, x8, #1
	add	x9, x9, x28
	add	x10, x10, x28
	cmp	x8, x24
	b.ne	.LBB39_31
.LBB39_34:
	ldp	x12, x10, [sp, #152]            // 16-byte Folded Reload
	mov	w9, wzr
	mov	w8, wzr
	ldr	x16, [sp, #16]                  // 8-byte Folded Reload
	ldr	x20, [sp, #208]                 // 8-byte Folded Reload
	cmp	x10, #4
	b.hs	.LBB39_42
// %bb.35:
	subs	x10, x27, #1
	str	x10, [sp, #208]                 // 8-byte Folded Spill
	b.ne	.LBB39_62
.LBB39_36:
	cmp	x26, #0
	eor	w8, w8, #0x1
	cset	w9, eq
	orr	w8, w8, w9
	tbnz	w8, #0, .LBB39_64
// %bb.37:
	mul	x8, x16, x24
	ldr	x12, [sp, #216]                 // 8-byte Folded Reload
	ldp	x13, x11, [sp, #112]            // 16-byte Folded Reload
	mov	w9, #2
	mov	w24, #1
	mul	x8, x8, x27
	lsl	x19, x12, #5
	neg	x23, x19
	cmp	x13, #2
	add	x10, x11, x12, lsl #5
	add	x8, x11, x8, lsl #5
	csel	x20, x13, x9, hi
	add	x21, x10, #16
	add	x22, x8, #16
.LBB39_38:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB39_39 Depth 2
	mov	x25, x22
	mov	x26, x21
	ldr	x27, [sp, #216]                 // 8-byte Folded Reload
.LBB39_39:                              //   Parent Loop BB39_38 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q2, q3, [x26, #-16]
	ldp	q1, q0, [x25, #-16]
	stp	q1, q2, [x29, #-112]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-80]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x26, #-16]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	subs	x27, x27, #1
	add	x26, x26, #32
	stp	q1, q0, [x25, #-16]
	add	x25, x25, #32
	b.ne	.LBB39_39
// %bb.40:                              //   in Loop: Header=BB39_38 Depth=1
	add	x24, x24, #1
	add	x21, x21, x19
	add	x22, x22, x23
	cmp	x24, x20
	b.ne	.LBB39_38
	b	.LBB39_64
.LBB39_41:
	ldp	x20, x26, [sp, #208]            // 16-byte Folded Reload
	ldr	x16, [sp, #16]                  // 8-byte Folded Reload
	ldr	x12, [sp, #152]                 // 8-byte Folded Reload
.LBB39_42:
	ldr	x11, [sp, #112]                 // 8-byte Folded Reload
	str	w9, [sp, #4]                    // 4-byte Folded Spill
	mul	x9, x26, x12
	ldr	x12, [sp, #88]                  // 8-byte Folded Reload
	lsl	x14, x26, #5
	mul	x8, x26, x16
	sub	x10, x11, #1
	cmp	x11, #2
	add	x9, x12, x9, lsl #5
	lsl	x8, x8, #5
	str	x16, [sp, #16]                  // 8-byte Folded Spill
	neg	x17, x14
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	mov	w10, #2
	csel	x10, x11, x10, hi
	ldr	x11, [sp, #120]                 // 8-byte Folded Reload
	sub	x13, x20, #3
	stp	x17, x14, [sp, #96]             // 16-byte Folded Spill
	str	x10, [sp, #80]                  // 8-byte Folded Spill
	add	x10, x12, x14
	add	x15, x10, #16
	add	x10, x12, x26, lsl #6
	add	x10, x10, #16
	add	x16, x11, x8
	add	x8, x12, x8
	add	x8, x8, #16
	stp	x9, x10, [sp, #168]             // 16-byte Folded Spill
	mov	w9, #96
	add	x10, x11, x14
	sub	x11, x20, #4
	madd	x9, x26, x9, x12
	add	x14, x10, #16
	mul	x10, x26, x11
	str	x8, [sp, #160]                  // 8-byte Folded Spill
	add	x8, x9, #16
	add	x9, x12, x26, lsl #7
	add	x9, x9, #16
	lsl	x11, x26, #6
	add	x18, x12, x10, lsl #5
	neg	x10, x11
	stp	x8, x13, [sp, #64]              // 16-byte Folded Spill
	mul	x8, x26, x13
	stp	x9, x18, [sp, #48]              // 16-byte Folded Spill
	add	x9, x12, x8, lsl #5
	add	x8, x12, #16
	stp	x10, x11, [sp, #136]            // 16-byte Folded Spill
	stp	x8, x9, [sp, #32]               // 16-byte Folded Spill
	lsl	x8, x26, #1
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	mov	w8, #1
	stur	x8, [x29, #-200]                // 8-byte Folded Spill
	str	x15, [sp, #192]                 // 8-byte Folded Spill
	b	.LBB39_44
.LBB39_43:                              //   in Loop: Header=BB39_44 Depth=1
	ldp	x16, x9, [x29, #-208]           // 16-byte Folded Reload
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	add	x9, x9, #1
	add	x16, x16, x8
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	add	x14, x14, x8
	ldr	x8, [sp, #80]                   // 8-byte Folded Reload
	stur	x9, [x29, #-200]                // 8-byte Folded Spill
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	cmp	x9, x8
	b.eq	.LBB39_61
.LBB39_44:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB39_46 Depth 2
                                        //     Child Loop BB39_50 Depth 2
                                        //       Child Loop BB39_52 Depth 3
                                        //     Child Loop BB39_58 Depth 2
                                        //       Child Loop BB39_59 Depth 3
	stur	x14, [x29, #-168]               // 8-byte Folded Spill
	stur	x16, [x29, #-208]               // 8-byte Folded Spill
	cbz	x26, .LBB39_53
// %bb.45:                              //   in Loop: Header=BB39_44 Depth=1
	ldp	x19, x8, [x29, #-208]           // 16-byte Folded Reload
	mov	x21, xzr
	ldr	x10, [sp, #184]                 // 8-byte Folded Reload
	ldur	x25, [x29, #-168]               // 8-byte Folded Reload
	add	x11, x10, x8, lsl #5
	lsl	x9, x8, #1
	add	x23, x10, x8, lsl #6
	add	x8, x11, #16
	stur	x11, [x29, #-144]               // 8-byte Folded Spill
	stur	x8, [x29, #-160]                // 8-byte Folded Spill
	add	x8, x23, #16
	stp	x8, x9, [x29, #-184]            // 16-byte Folded Spill
	ldr	x20, [sp, #88]                  // 8-byte Folded Reload
.LBB39_46:                              //   Parent Loop BB39_44 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x27, x20, x21
	ldur	x8, [x29, #-144]                // 8-byte Folded Reload
	add	x28, x15, x21
	ldr	q0, [x8]
	ldr	q1, [x27]
	stp	q1, q0, [x29, #-80]             // 32-byte Folded Spill
	ldur	q1, [x28, #-16]
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x23]
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	add	x22, x8, x21
	ldur	q1, [x22, #-16]
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x24, x25, x21
	ldr	q1, [x27, #16]
	stur	q1, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q1, [x28]
	stur	q0, [x24, #-16]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q1, [x22]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-160]                // 8-byte Folded Reload
	str	q0, [x24]
	ldr	q1, [x8]
	stp	q1, q1, [x29, #-64]             // 16-byte Folded Spill
	ldurb	w8, [x29, #-33]
	ldr	x9, [sp, #160]                  // 8-byte Folded Reload
	eor	w8, w8, #0x80
	add	x22, x9, x21
	sturb	w8, [x29, #-33]
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	ldur	q0, [x29, #-48]
	add	x24, x8, x21
	ldur	x8, [x29, #-184]                // 8-byte Folded Reload
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x22]
	ldr	q1, [x8]
	stp	q0, q1, [x29, #-96]             // 32-byte Folded Spill
	ldr	q0, [x24, #16]
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x27, x19, x21
	ldur	q1, [x22, #-16]
	stur	q1, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q1, [x24]
	str	q0, [x27]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	subs	x26, x26, #1
	add	x21, x21, #32
	str	q0, [x27, #16]
	b.ne	.LBB39_46
// %bb.47:                              //   in Loop: Header=BB39_44 Depth=1
	ldr	x26, [sp, #216]                 // 8-byte Folded Reload
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	cmp	x8, #4
	b.lo	.LBB39_54
.LBB39_48:                              //   in Loop: Header=BB39_44 Depth=1
	ldp	x24, x25, [sp, #40]             // 16-byte Folded Reload
	mov	w20, #3
	ldp	x8, x23, [sp, #56]              // 16-byte Folded Reload
	ldr	x10, [sp, #72]                  // 8-byte Folded Reload
	b	.LBB39_50
.LBB39_49:                              //   in Loop: Header=BB39_50 Depth=2
	ldp	x9, x8, [sp, #136]              // 16-byte Folded Reload
	ldp	x10, x20, [x29, #-192]          // 16-byte Folded Reload
	ldur	x11, [x29, #-160]               // 8-byte Folded Reload
	add	x24, x24, x9
	add	x23, x23, x8
	add	x25, x25, x8
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	sub	x10, x10, #2
	add	x20, x20, #2
	add	x11, x11, x9
	ldr	x26, [sp, #216]                 // 8-byte Folded Reload
	cmp	x20, x8
	mov	x8, x11
	b.hs	.LBB39_55
.LBB39_50:                              //   Parent Loop BB39_44 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB39_52 Depth 3
	ldp	x19, x11, [x29, #-208]          // 16-byte Folded Reload
	stur	x8, [x29, #-160]                // 8-byte Folded Spill
	ldp	x8, x28, [x29, #-176]           // 16-byte Folded Reload
	stp	x10, x20, [x29, #-192]          // 16-byte Folded Spill
	ldr	x10, [sp, #208]                 // 8-byte Folded Reload
	add	x8, x8, x11
	cmp	x8, x10
	csel	x9, x10, xzr, hi
	sub	x8, x8, x9
	add	x9, x8, x11
	cmp	x9, x10
	csel	x10, x10, xzr, hi
	sub	x9, x9, x10
	stur	x9, [x29, #-176]                // 8-byte Folded Spill
	cbz	x26, .LBB39_49
// %bb.51:                              //   in Loop: Header=BB39_50 Depth=2
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	mov	x22, xzr
	ldur	x10, [x29, #-176]               // 8-byte Folded Reload
	add	x8, x9, x8, lsl #5
	add	x9, x9, x10, lsl #5
	ldp	q1, q0, [x8]
	stp	q0, q1, [x29, #-80]             // 32-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	x27, [sp, #216]                 // 8-byte Folded Reload
.LBB39_52:                              //   Parent Loop BB39_44 Depth=1
                                        //     Parent Loop BB39_50 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x21, x23, x22
	add	x26, x25, x22
	ldur	q0, [x21, #-16]
	ldur	q1, [x26, #-16]
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	add	x20, x28, x22
	mov	v1.16b, v0.16b
	ldur	q0, [x20, #-16]
	bl	__addtf3
	ldr	q1, [x21]
	stur	q0, [x20, #-16]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	stur	q1, [x29, #-128]                // 16-byte Folded Spill
	ldr	q1, [x26]
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	ldr	q0, [x20]
	bl	__addtf3
	add	x21, x24, x22
	ldur	x8, [x29, #-160]                // 8-byte Folded Reload
	str	q0, [x20]
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	add	x26, x8, x22
	ldr	q1, [x21, #16]
	stur	q1, [x29, #-144]                // 16-byte Folded Spill
	ldr	q1, [x26, #16]
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	add	x20, x19, x22
	mov	v1.16b, v0.16b
	ldr	q0, [x20]
	bl	__subtf3
	ldr	q1, [x21]
	str	q0, [x20]
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	stur	q1, [x29, #-128]                // 16-byte Folded Spill
	ldr	q1, [x26]
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	ldr	q0, [x20, #16]
	bl	__addtf3
	subs	x27, x27, #1
	add	x22, x22, #32
	str	q0, [x20, #16]
	b.ne	.LBB39_52
	b	.LBB39_49
.LBB39_53:                              //   in Loop: Header=BB39_44 Depth=1
	ldur	x8, [x29, #-200]                // 8-byte Folded Reload
	lsl	x8, x8, #1
	stur	x8, [x29, #-176]                // 8-byte Folded Spill
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	cmp	x8, #4
	b.hs	.LBB39_48
.LBB39_54:                              //   in Loop: Header=BB39_44 Depth=1
	ldr	x10, [sp, #72]                  // 8-byte Folded Reload
	mov	w20, #3
.LBB39_55:                              //   in Loop: Header=BB39_44 Depth=1
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	ldur	x14, [x29, #-168]               // 8-byte Folded Reload
	cmp	x20, x8
	b.hs	.LBB39_43
// %bb.56:                              //   in Loop: Header=BB39_44 Depth=1
	cbz	x26, .LBB39_43
// %bb.57:                              //   in Loop: Header=BB39_44 Depth=1
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	mul	x8, x9, x20
	mul	x9, x9, x10
	ldr	x10, [sp, #32]                  // 8-byte Folded Reload
	add	x21, x10, x8, lsl #4
	add	x22, x10, x9, lsl #4
.LBB39_58:                              //   Parent Loop BB39_44 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB39_59 Depth 3
	ldp	x19, x8, [x29, #-208]           // 16-byte Folded Reload
	mov	x23, xzr
	mov	x24, x26
	ldur	x9, [x29, #-176]                // 8-byte Folded Reload
	add	x8, x9, x8
	ldr	x9, [sp, #208]                  // 8-byte Folded Reload
	cmp	x8, x9
	csel	x9, x9, xzr, hi
	sub	x8, x8, x9
	stur	x8, [x29, #-176]                // 8-byte Folded Spill
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	add	x8, x9, x8, lsl #5
	ldp	q1, q0, [x8]
	stp	q0, q1, [x29, #-80]             // 32-byte Folded Spill
.LBB39_59:                              //   Parent Loop BB39_44 Depth=1
                                        //     Parent Loop BB39_58 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x27, x14, x23
	add	x25, x21, x23
	ldur	q1, [x27, #-16]
	ldur	q0, [x25, #-16]
	stur	q1, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [x25]
	stur	q0, [x27, #-16]
	ldr	q2, [x27]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stur	q2, [x29, #-96]                 // 16-byte Folded Spill
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x25, x22, x23
	add	x28, x19, x23
	str	q0, [x27]
	ldr	q1, [x25]
	ldr	q2, [x28]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	stur	q2, [x29, #-96]                 // 16-byte Folded Spill
	bl	__multf3
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x25, #-16]
	str	q0, [x28]
	ldr	q2, [x28, #16]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	stur	q2, [x29, #-96]                 // 16-byte Folded Spill
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	x14, [x29, #-168]               // 8-byte Folded Reload
	subs	x24, x24, #1
	add	x23, x23, #32
	str	q0, [x28, #16]
	b.ne	.LBB39_59
// %bb.60:                              //   in Loop: Header=BB39_58 Depth=2
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	add	x20, x20, #1
	add	x21, x21, x8
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	add	x22, x22, x8
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	cmp	x20, x8
	b.ne	.LBB39_58
	b	.LBB39_43
.LBB39_61:
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	mov	w8, #1
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	ldr	x16, [sp, #16]                  // 8-byte Folded Reload
	ldr	w9, [sp, #4]                    // 4-byte Folded Reload
	subs	x10, x27, #1
	str	x10, [sp, #208]                 // 8-byte Folded Spill
	b.eq	.LBB39_36
.LBB39_62:
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cbz	w8, .LBB39_64
// %bb.63:
	tbz	w9, #0, .LBB39_67
.LBB39_64:
	ldr	x8, [sp, #184]                  // 8-byte Folded Reload
	cbz	x8, .LBB39_66
// %bb.65:
	ldur	x0, [x8, #-8]
	add	sp, sp, #432
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	free
.LBB39_66:
	add	sp, sp, #432
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB39_67:
	ldp	x15, x12, [sp, #112]            // 16-byte Folded Reload
	mov	w10, #2
	mul	x8, x16, x24
	ldp	x17, x13, [sp, #208]            // 16-byte Folded Reload
	sub	x9, x16, #1
	lsl	x21, x27, #5
	cmp	x15, #2
	mul	x8, x8, x27
	csel	x10, x15, x10, hi
	mul	x9, x9, x17
	add	x11, x12, x13, lsl #5
	lsl	x13, x13, #5
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	add	x10, x11, #16
	add	x9, x14, x9, lsl #5
	add	x26, x11, #48
	stur	x10, [x29, #-184]               // 8-byte Folded Spill
	neg	x10, x13
	str	x13, [sp, #160]                 // 8-byte Folded Spill
	str	x10, [sp, #144]                 // 8-byte Folded Spill
	add	x10, x12, x8, lsl #5
	add	x8, x9, #16
	add	x23, x10, #48
	mov	w12, #1
	stur	x8, [x29, #-168]                // 8-byte Folded Spill
	mov	w8, #32
	sub	x8, x8, x21
	str	x8, [sp, #136]                  // 8-byte Folded Spill
	add	x8, x14, #16
	stur	x8, [x29, #-176]                // 8-byte Folded Spill
	sub	x8, x21, #32
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	stur	x10, [x29, #-192]               // 8-byte Folded Spill
	b	.LBB39_69
.LBB39_68:                              //   in Loop: Header=BB39_69 Depth=1
	ldp	x10, x9, [x29, #-192]           // 16-byte Folded Reload
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	ldr	x12, [sp, #176]                 // 8-byte Folded Reload
	add	x9, x9, x8
	add	x12, x12, #1
	stur	x9, [x29, #-184]                // 8-byte Folded Spill
	ldr	x9, [sp, #144]                  // 8-byte Folded Reload
	add	x10, x10, x9
	stur	x10, [x29, #-192]               // 8-byte Folded Spill
	ldur	x10, [x29, #-168]               // 8-byte Folded Reload
	ldr	x11, [sp, #136]                 // 8-byte Folded Reload
	add	x10, x10, x11
	stur	x10, [x29, #-168]               // 8-byte Folded Spill
	ldr	x26, [sp, #216]                 // 8-byte Folded Reload
	ldr	x10, [sp, #112]                 // 8-byte Folded Reload
	add	x26, x26, x8
	ldur	x8, [x29, #-176]                // 8-byte Folded Reload
	add	x8, x8, x10
	stur	x8, [x29, #-176]                // 8-byte Folded Spill
	ldr	x23, [sp, #192]                 // 8-byte Folded Reload
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	ldr	x16, [sp, #168]                 // 8-byte Folded Reload
	add	x23, x23, x9
	cmp	x12, x8
	b.eq	.LBB39_64
.LBB39_69:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB39_75 Depth 2
                                        //     Child Loop BB39_71 Depth 2
                                        //       Child Loop BB39_72 Depth 3
	sub	x8, x16, #1
	cmp	x27, #1
	str	x26, [sp, #216]                 // 8-byte Folded Spill
	str	x23, [sp, #192]                 // 8-byte Folded Spill
	stp	x8, x12, [sp, #168]             // 16-byte Folded Spill
	b.ls	.LBB39_74
// %bb.70:                              //   in Loop: Header=BB39_69 Depth=1
	mul	x9, x12, x24
	mov	x20, xzr
	mul	x8, x16, x24
	stp	x8, x9, [x29, #-208]            // 16-byte Folded Spill
.LBB39_71:                              //   Parent Loop BB39_69 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB39_72 Depth 3
	ldp	x9, x8, [x29, #-208]            // 16-byte Folded Reload
	ldr	x10, [sp, #120]                 // 8-byte Folded Reload
	add	x9, x20, x9
	add	x8, x20, x8
	mul	x9, x9, x27
	mul	x8, x8, x27
	add	x27, x10, x9, lsl #5
	add	x19, x10, x8, lsl #5
	ldp	q1, q0, [x27]
	ldp	q2, q3, [x19]
	stp	q2, q1, [x29, #-112]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-80]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x19]
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__subtf3
	ldp	x22, x25, [x29, #-176]          // 16-byte Folded Reload
	mov	x24, x23
	mov	x19, x26
	ldr	x28, [sp, #208]                 // 8-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x27]
.LBB39_72:                              //   Parent Loop BB39_69 Depth=1
                                        //     Parent Loop BB39_71 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q0, [x19, #-16]
	stp	q0, q2, [x29, #-80]             // 32-byte Folded Spill
	ldp	q1, q0, [x24, #-16]
	stp	q1, q0, [x29, #-144]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q0, q1, [x22, #-16]
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	stur	q1, [x29, #-160]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-128]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	ldp	q1, q2, [x25, #-16]
	stur	q1, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stur	q2, [x29, #-128]                // 16-byte Folded Spill
	stp	q1, q0, [x19, #-16]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	mov	v1.16b, v2.16b
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	subs	x28, x28, #1
	add	x25, x25, #32
	add	x19, x19, #32
	add	x22, x22, #32
	stp	q1, q0, [x24, #-16]
	add	x24, x24, #32
	b.ne	.LBB39_72
// %bb.73:                              //   in Loop: Header=BB39_71 Depth=2
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	add	x20, x20, #1
	add	x26, x26, x21
	add	x23, x23, x21
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	cmp	x20, x24
	b.ne	.LBB39_71
	b	.LBB39_68
.LBB39_74:                              //   in Loop: Header=BB39_69 Depth=1
	mov	x19, xzr
	mov	x20, x24
.LBB39_75:                              //   Parent Loop BB39_69 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldur	x8, [x29, #-184]                // 8-byte Folded Reload
	add	x22, x8, x19
	ldur	x8, [x29, #-192]                // 8-byte Folded Reload
	add	x23, x8, x19
	ldp	q2, q3, [x22, #-16]
	ldp	q1, q0, [x23]
	stp	q2, q1, [x29, #-112]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-80]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x22, #-16]
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__subtf3
	subs	x20, x20, #1
	add	x19, x19, x21
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x23]
	b.ne	.LBB39_75
	b	.LBB39_68
.LBB39_76:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end39:
	.size	_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_, .Lfunc_end39-_ZNK9pocketfft6detail5cfftpIeE5passgILb1ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #432
	stp	x29, x30, [sp, #336]            // 16-byte Folded Spill
	add	x29, sp, #336
	stp	x28, x27, [sp, #352]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #368]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #384]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #400]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #416]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x25, x2
	subs	x8, x1, #1
	stp	x4, x3, [sp, #72]               // 16-byte Folded Spill
	b.ne	.LBB40_4
// %bb.1:
	cbz	x25, .LBB40_10
// %bb.2:
	add	x8, x25, x25, lsl #1
	lsl	x21, x8, #5
	ldp	x9, x8, [sp, #72]               // 16-byte Folded Reload
	lsl	x20, x25, #5
	lsl	x22, x25, #6
	add	x19, x9, #16
	add	x23, x8, #64
.LBB40_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q2, q0, [x23, #-64]
	stp	q0, q2, [x29, #-48]             // 32-byte Folded Spill
	ldp	q1, q0, [x23]
	stp	q1, q0, [x29, #-112]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldp	q2, q0, [x23, #-32]
	stp	q0, q2, [x29, #-112]            // 32-byte Folded Spill
	ldp	q1, q0, [x23, #32]
	str	q1, [sp, #160]                  // 16-byte Folded Spill
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x19, #-16]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x20
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x21
	add	x19, x19, #32
	subs	x25, x25, #1
	add	x23, x23, #128
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB40_3
	b	.LBB40_10
.LBB40_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x1, [sp, #64]                   // 8-byte Folded Spill
	cbz	x25, .LBB40_10
// %bb.5:
	ldp	x11, x23, [sp, #64]             // 16-byte Folded Reload
	lsl	x12, x25, #1
	mov	w9, #96
	ldr	x10, [sp, #80]                  // 8-byte Folded Reload
	mov	x28, x5
	mov	x27, xzr
	stp	x5, x25, [sp, #48]              // 16-byte Folded Spill
	mul	x8, x25, x11
	lsl	x24, x11, #5
	add	x21, x10, #32
	lsl	x10, x11, #7
	mov	x11, x5
	madd	x20, x8, x9, x23
	ldr	x9, [sp]                        // 8-byte Folded Reload
	stp	x10, x12, [sp, #32]             // 16-byte Folded Spill
	add	x10, x12, x25
	add	x19, x23, x8, lsl #6
	add	x8, x23, x8, lsl #5
	str	x10, [sp, #24]                  // 8-byte Folded Spill
	add	x10, x28, x9, lsl #6
	add	x9, x28, x9, lsl #5
	stp	x9, x10, [sp, #8]               // 16-byte Folded Spill
	b	.LBB40_7
.LBB40_6:                               //   in Loop: Header=BB40_7 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	add	x20, x20, x24
	add	x23, x23, x24
	ldr	x25, [sp, #56]                  // 8-byte Folded Reload
	add	x19, x19, x24
	add	x21, x21, x8
	ldp	x27, x8, [sp, #96]              // 16-byte Folded Reload
	add	x27, x27, #1
	cmp	x27, x25
	add	x8, x8, x24
	b.eq	.LBB40_10
.LBB40_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB40_9 Depth 2
	str	x21, [sp, #88]                  // 8-byte Folded Spill
	ldr	x21, [sp, #64]                  // 8-byte Folded Reload
	str	x8, [sp, #104]                  // 8-byte Folded Spill
	lsl	x8, x27, #2
	mov	w9, #2
	ldr	x22, [sp, #80]                  // 8-byte Folded Reload
	mul	x8, x8, x21
	bfi	x9, x27, #2, #62
	mul	x9, x9, x21
	add	x8, x22, x8, lsl #5
	add	x9, x22, x9, lsl #5
	ldp	q2, q0, [x8]
	ldr	q1, [x9]
	stp	q0, q1, [x29, #-48]             // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q2, q0, [x29, #-112]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	mov	w8, #1
	mov	w9, #3
	bfi	x8, x27, #2, #62
	bfi	x9, x27, #2, #62
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	mul	x8, x8, x21
	mul	x9, x9, x21
	add	x8, x22, x8, lsl #5
	add	x9, x22, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #160]                  // 16-byte Folded Spill
	ldr	q1, [x9]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #160]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	mul	x22, x27, x21
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	add	x8, x27, x8
	mul	x28, x8, x21
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x26, [sp, #72]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	add	x8, x26, x22, lsl #5
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x28, lsl #5
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	add	x8, x27, x25
	str	x27, [sp, #96]                  // 8-byte Folded Spill
	stp	q1, q0, [x10]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	add	x9, x27, x9
	mul	x22, x8, x21
	mul	x25, x9, x21
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x22, lsl #5
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x25, lsl #5
	ldr	x28, [sp, #48]                  // 8-byte Folded Reload
	ldp	x26, x27, [sp, #8]              // 16-byte Folded Reload
	cmp	x21, #2
	ldr	x21, [sp, #88]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB40_6
// %bb.8:                               //   in Loop: Header=BB40_7 Depth=1
	mov	x25, xzr
	ldr	x22, [sp]                       // 8-byte Folded Reload
.LBB40_9:                               //   Parent Loop BB40_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x21, x25
	add	x9, x8, x24
	add	x10, x9, x24
	ldp	q2, q0, [x8]
	add	x8, x10, x24
	stp	q0, q2, [x29, #-48]             // 32-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q0, q1, [x29, #-80]             // 32-byte Folded Spill
	ldp	q1, q0, [x10]
	stp	q1, q0, [x29, #-144]            // 32-byte Folded Spill
	ldr	q0, [x8]
	str	q0, [sp, #160]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x23, x25
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x28, x25
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q3, q0, [x8]
	stp	q0, q3, [sp, #144]              // 32-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldr	q0, [sp, #112]                  // 16-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #160]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #144]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	add	x8, x8, x25
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x25
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-128]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x25
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x27, x25
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-64]             // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-48]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x25
	subs	x22, x22, #1
	add	x25, x25, #32
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB40_9
	b	.LBB40_6
.LBB40_10:
	ldp	x20, x19, [sp, #416]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #400]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #384]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #368]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #352]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #336]            // 16-byte Folded Reload
	add	sp, sp, #432
	ret
.Lfunc_end40:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end40-_ZNK9pocketfft6detail5cfftpIeE5pass4ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI41_0:
	.xword	0xc908b2fb1366ea95              // fp128 0.707106781186547524400844362104848992
	.xword	0x3ffe6a09e667f3bc
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #688
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	str	x5, [sp, #192]                  // 8-byte Folded Spill
	stp	x4, x3, [sp, #136]              // 16-byte Folded Spill
	b.ne	.LBB41_4
// %bb.1:
	cbz	x2, .LBB41_10
// %bb.2:
	ldr	x9, [sp, #136]                  // 8-byte Folded Reload
	mov	w8, #224
	add	x10, x2, x2, lsl #2
	lsl	x23, x2, #5
	mul	x21, x2, x8
	adrp	x8, .LCPI41_0
	add	x19, x9, #16
	add	x9, x2, x2, lsl #1
	lsl	x20, x9, #5
	lsl	x24, x9, #6
	ldr	x9, [sp, #144]                  // 8-byte Folded Reload
	lsl	x22, x10, #5
	lsl	x25, x2, #6
	lsl	x26, x2, #7
	ldr	q0, [x8, :lo12:.LCPI41_0]
	add	x27, x9, #128
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
.LBB41_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q2, q0, [x27, #-96]
	mov	x28, x2
	ldr	q1, [x27, #32]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x27, #48]
	stp	q2, q0, [x29, #-176]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q2, q3, [x27, #-32]
	stur	q2, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x27, #96]
	stur	q1, [x29, #-224]                // 16-byte Folded Spill
	stp	q0, q3, [x29, #-208]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stur	q0, [x29, #-64]
	ldurb	w8, [x29, #-49]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-49]
	ldur	q0, [x29, #-64]
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q2, q0, [x27, #-128]
	stp	q0, q2, [x29, #-240]            // 32-byte Folded Spill
	ldp	q1, q0, [x27]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	q2, [x27, #-64]
	stp	q2, q0, [x29, #-256]            // 32-byte Folded Spill
	ldur	q0, [x27, #-48]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q1, q0, [x27, #64]
	stp	q1, q0, [sp, #320]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	stp	q1, q0, [x19, #-16]
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #320]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x26
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x25
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x24
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x23
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x20
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	mov	x2, x28
	add	x8, x19, x21
	add	x19, x19, #32
	subs	x2, x28, #1
	add	x27, x27, #256
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB41_3
	b	.LBB41_10
.LBB41_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x1, [sp, #128]                  // 8-byte Folded Spill
	cbz	x2, .LBB41_10
// %bb.5:
	lsl	x8, x2, #2
	lsl	x9, x2, #1
	ldp	x14, x20, [sp, #128]            // 16-byte Folded Reload
	mov	w12, #96
	mov	w10, #224
	stp	x9, x8, [sp, #104]              // 16-byte Folded Spill
	add	x9, x9, x2
	add	x8, x8, x2
	lsl	x11, x9, #1
	ldr	x21, [sp, #144]                 // 8-byte Folded Reload
	mov	x27, xzr
	ldr	x15, [sp]                       // 8-byte Folded Reload
	str	x2, [sp, #120]                  // 8-byte Folded Spill
	stp	x8, x9, [sp, #88]               // 16-byte Folded Spill
	lsl	x9, x2, #3
	sub	x9, x9, x2
	mul	x8, x2, x14
	ldr	x7, [sp, #192]                  // 8-byte Folded Reload
	stp	x9, x11, [sp, #72]              // 16-byte Folded Spill
	lsl	x9, x14, #5
	lsl	x11, x14, #8
	madd	x17, x8, x12, x20
	madd	x25, x8, x10, x20
	add	x6, x20, x8, lsl #5
	stp	x11, x9, [sp, #56]              // 16-byte Folded Spill
	add	x9, x9, x21
	add	x9, x9, #48
	madd	x10, x14, x10, x21
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	add	x9, x15, x15, lsl #2
	lsl	x9, x9, #5
	add	x0, x10, #48
	add	x11, x9, x21
	lsl	x10, x15, #7
	add	x16, x11, #208
	add	x11, x15, x15, lsl #1
	lsl	x12, x11, #5
	lsl	x11, x11, #6
	add	x13, x12, x21
	add	x9, x7, x9
	add	x18, x13, #144
	mov	w13, #160
	madd	x1, x8, x13, x20
	add	x13, x10, x21
	add	x3, x13, #128
	lsl	x13, x15, #6
	add	x14, x13, x21
	add	x10, x7, x10
	add	x4, x14, #64
	add	x14, x11, x21
	add	x11, x7, x11
	add	x5, x14, #192
	mov	w14, #192
	stp	x9, x10, [sp, #24]              // 16-byte Folded Spill
	adrp	x10, .LCPI41_0
	str	x11, [sp, #48]                  // 8-byte Folded Spill
	add	x11, x7, x13
	add	x9, x7, x15, lsl #5
	add	x13, x20, x8, lsl #6
	ldr	q0, [x10, :lo12:.LCPI41_0]
	str	x11, [sp, #40]                  // 8-byte Folded Spill
	madd	x11, x8, x14, x20
	ldp	x28, x24, [sp, #32]             // 16-byte Folded Reload
	str	x9, [sp, #16]                   // 8-byte Folded Spill
	add	x8, x20, x8, lsl #7
	add	x9, x7, x12
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	b	.LBB41_7
.LBB41_6:                               //   in Loop: Header=BB41_7 Depth=1
	ldp	x10, x8, [sp, #56]              // 16-byte Folded Reload
	mov	x9, x27
	ldp	x13, x11, [sp, #272]            // 16-byte Folded Reload
	ldp	x5, x4, [sp, #224]              // 16-byte Folded Reload
	add	x9, x9, x10
	add	x25, x25, x8
	ldp	x15, x14, [sp, #256]            // 16-byte Folded Reload
	add	x16, x11, x10
	add	x18, x13, x10
	ldp	x3, x1, [sp, #240]              // 16-byte Folded Reload
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	add	x4, x4, x10
	ldr	x12, [sp, #288]                 // 8-byte Folded Reload
	add	x0, x15, x10
	add	x5, x5, x10
	ldr	x27, [sp, #160]                 // 8-byte Folded Reload
	add	x3, x3, x10
	ldr	x19, [sp, #200]                 // 8-byte Folded Reload
	add	x21, x12, x10
	ldr	x2, [sp, #120]                  // 8-byte Folded Reload
	ldp	x10, x9, [sp, #296]             // 16-byte Folded Reload
	add	x27, x27, #1
	add	x17, x14, x8
	ldp	x7, x6, [sp, #208]              // 16-byte Folded Reload
	add	x1, x1, x8
	add	x13, x19, x8
	add	x20, x10, x8
	cmp	x27, x2
	add	x11, x7, x8
	add	x6, x6, x8
	add	x8, x9, x8
	b.eq	.LBB41_10
.LBB41_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB41_9 Depth 2
	stp	x20, x8, [sp, #296]             // 16-byte Folded Spill
	mov	w8, #1
	str	x25, [sp, #152]                 // 8-byte Folded Spill
	ldr	x25, [sp, #128]                 // 8-byte Folded Reload
	bfi	x8, x27, #3, #61
	mov	w9, #5
	ldr	x23, [sp, #144]                 // 8-byte Folded Reload
	bfi	x9, x27, #3, #61
	mul	x8, x8, x25
	stp	x13, x11, [sp, #200]            // 16-byte Folded Spill
	mul	x9, x9, x25
	stp	x6, x5, [sp, #216]              // 16-byte Folded Spill
	stp	x4, x3, [sp, #232]              // 16-byte Folded Spill
	lsl	x22, x27, #3
	add	x8, x23, x8, lsl #5
	stp	x1, x0, [sp, #248]              // 16-byte Folded Spill
	add	x9, x23, x9, lsl #5
	stp	x17, x18, [sp, #264]            // 16-byte Folded Spill
	stp	x16, x21, [sp, #280]            // 16-byte Folded Spill
	mov	x19, x2
	ldp	q2, q0, [x8]
	ldr	q1, [x9]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q2, q0, [x29, #-176]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	mov	w8, #3
	mov	w9, #7
	bfi	x8, x27, #3, #61
	bfi	x9, x27, #3, #61
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mul	x8, x8, x25
	mul	x9, x9, x25
	add	x8, x23, x8, lsl #5
	add	x9, x23, x9, lsl #5
	ldp	q2, q0, [x8]
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stur	q1, [x29, #-160]                // 16-byte Folded Spill
	stp	q2, q0, [x29, #-224]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stur	q0, [x29, #-32]
	ldurb	w8, [x29, #-17]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-17]
	ldur	q0, [x29, #-32]
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	mov	w8, #4
	mul	x9, x22, x25
	bfi	x8, x27, #3, #61
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mul	x8, x8, x25
	add	x9, x23, x9, lsl #5
	add	x8, x23, x8, lsl #5
	ldp	q2, q0, [x9]
	str	q2, [sp, #416]                  // 16-byte Folded Spill
	ldr	q1, [x8]
	stp	q0, q1, [x29, #-240]            // 32-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	mov	w8, #2
	mov	w9, #6
	bfi	x8, x27, #3, #61
	bfi	x9, x27, #3, #61
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	mul	x8, x8, x25
	mul	x9, x9, x25
	add	x8, x23, x8, lsl #5
	add	x9, x23, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #320]                  // 16-byte Folded Spill
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stur	q1, [x29, #-256]                // 16-byte Folded Spill
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #320]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	mul	x22, x27, x25
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	add	x8, x27, x8
	mul	x23, x8, x25
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #160]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x26, [sp, #136]                 // 8-byte Folded Reload
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	add	x8, x26, x22, lsl #5
	stp	q1, q0, [x8]
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #320]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x23, lsl #5
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	stp	q1, q0, [x10]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	add	x8, x27, x8
	add	x9, x27, x9
	mul	x22, x8, x25
	mul	x23, x9, x25
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x22, lsl #5
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x23, lsl #5
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	ldr	x9, [sp, #88]                   // 8-byte Folded Reload
	add	x8, x27, x19
	stp	q1, q0, [x10]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	add	x9, x27, x9
	mul	x22, x8, x25
	mul	x23, x9, x25
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x22, lsl #5
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	add	x10, x26, x23, lsl #5
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	str	x27, [sp, #160]                 // 8-byte Folded Spill
	ldr	x9, [sp, #72]                   // 8-byte Folded Reload
	stp	q1, q0, [x10]
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	add	x8, x27, x8
	add	x9, x27, x9
	mul	x22, x8, x25
	mul	x23, x9, x25
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x26, x22, lsl #5
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	ldp	x21, x20, [sp, #16]             // 16-byte Folded Reload
	add	x8, x26, x23, lsl #5
	cmp	x25, #2
	ldr	x25, [sp, #152]                 // 8-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	ldr	x27, [sp, #184]                 // 8-byte Folded Reload
	ldr	x26, [sp, #48]                  // 8-byte Folded Reload
	ldr	x19, [sp, #8]                   // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB41_6
// %bb.8:                               //   in Loop: Header=BB41_7 Depth=1
	mov	x22, xzr
	ldr	x23, [sp]                       // 8-byte Folded Reload
.LBB41_9:                               //   Parent Loop BB41_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x27, x22
	ldr	x9, [sp, #280]                  // 8-byte Folded Reload
	add	x9, x9, x22
	ldp	q2, q0, [x8, #-16]
	ldur	q1, [x9, #-16]
	stp	q0, q1, [x29, #-112]            // 32-byte Folded Spill
	ldr	q0, [x9]
	stp	q2, q0, [x29, #-176]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #272]                  // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	add	x8, x8, x22
	add	x9, x9, x22
	ldp	q2, q0, [x8, #-16]
	ldur	q1, [x9, #-16]
	stp	q0, q1, [x29, #-208]            // 32-byte Folded Spill
	ldr	q0, [x9]
	stp	q2, q0, [x29, #-240]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stur	q0, [x29, #-48]
	ldurb	w8, [x29, #-33]
	eor	w8, w8, #0x80
	sturb	w8, [x29, #-33]
	ldur	q0, [x29, #-48]
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	x8, [sp, #288]                  // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	x9, [sp, #240]                  // 8-byte Folded Reload
	add	x8, x8, x22
	add	x9, x9, x22
	ldp	q2, q0, [x8, #32]
	ldr	q1, [x9, #32]
	stp	q0, q1, [x29, #-208]            // 32-byte Folded Spill
	ldr	q0, [x9, #48]
	stp	q2, q0, [x29, #-240]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #224]              // 16-byte Folded Reload
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	add	x9, x9, x22
	add	x8, x8, x22
	ldr	q1, [x9, #32]
	ldp	q2, q0, [x8, #32]
	str	q2, [sp, #352]                  // 16-byte Folded Spill
	stp	q0, q1, [x29, #-240]            // 32-byte Folded Spill
	ldr	q0, [x9, #48]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #352]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #296]                  // 8-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [sp, #352]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #304]                  // 8-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x22
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #200]                  // 8-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x22
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #208]                  // 8-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	add	x8, x8, x22
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-224]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #216]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x22
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #248]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x24, x22
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	add	x8, x8, x22
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x26, x22
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-128]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x25, x22
	subs	x23, x23, #1
	add	x22, x22, #32
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB41_9
	b	.LBB41_6
.LBB41_10:
	add	sp, sp, #688
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end41:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end41-_ZNK9pocketfft6detail5cfftpIeE5pass8ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x2
	cmp	x1, #1
	stp	x4, x3, [sp, #40]               // 16-byte Folded Spill
	b.ne	.LBB42_4
// %bb.1:
	cbz	x19, .LBB42_12
// %bb.2:
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	lsl	x20, x19, #5
	add	x21, x8, #16
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	add	x22, x8, #32
.LBB42_3:                               // =>This Inner Loop Header: Depth=1
	ldur	q0, [x22, #-32]
	ldr	q1, [x22]
	stp	q1, q0, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldur	q0, [x22, #-16]
	ldr	q1, [x22, #16]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x21, #-16]
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x20
	add	x21, x21, #32
	subs	x19, x19, #1
	add	x22, x22, #64
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB42_3
	b	.LBB42_12
.LBB42_4:
	cbz	x19, .LBB42_12
// %bb.5:
	mov	x22, x1
	subs	x8, x1, #1
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	b.ls	.LBB42_10
// %bb.6:
	lsl	x11, x22, #5
	lsl	x10, x22, #6
	mul	x8, x19, x22
	mov	x23, x5
	mov	x25, xzr
	stp	x10, x11, [sp, #8]              // 16-byte Folded Spill
	ldp	x10, x9, [sp, #40]              // 16-byte Folded Reload
	add	x27, x9, #48
	add	x9, x11, x9
	add	x20, x9, #48
	str	x22, [sp, #24]                  // 8-byte Folded Spill
	add	x8, x10, x8, lsl #5
	add	x28, x10, #32
	add	x24, x8, #32
.LBB42_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB42_8 Depth 2
	mov	w9, #1
	lsl	x8, x25, #1
	bfi	x9, x25, #1, #63
	ldr	x10, [sp, #48]                  // 8-byte Folded Reload
	mul	x8, x8, x22
	mul	x9, x9, x22
	add	x21, x10, x8, lsl #5
	add	x26, x10, x9, lsl #5
	ldr	q0, [x21]
	ldr	q1, [x26]
	stp	q0, q1, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q0, [x21, #16]
	ldr	q1, [x26, #16]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	mul	x8, x25, x22
	ldr	x21, [sp, #40]                  // 8-byte Folded Reload
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	add	x8, x21, x8, lsl #5
	stp	q1, q0, [x8]
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x25, x19
	mov	x26, xzr
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	str	x25, [sp, #56]                  // 8-byte Folded Spill
	mul	x8, x8, x22
	add	x8, x21, x8, lsl #5
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
.LBB42_8:                               //   Parent Loop BB42_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x22, x27, x26
	add	x25, x20, x26
	ldur	q0, [x22, #-16]
	ldur	q1, [x25, #-16]
	stp	q0, q1, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q0, [x22]
	ldr	q1, [x25]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	add	x8, x28, x26
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x23, x26
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q2, q0, [x8]
	stp	q0, q2, [x29, #-48]             // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #64]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x24, x26
	subs	x21, x21, #1
	add	x26, x26, #32
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stp	q1, q0, [x8]
	b.ne	.LBB42_8
// %bb.9:                               //   in Loop: Header=BB42_7 Depth=1
	ldp	x9, x8, [sp, #8]                // 16-byte Folded Reload
	ldr	x25, [sp, #56]                  // 8-byte Folded Reload
	ldr	x22, [sp, #24]                  // 8-byte Folded Reload
	add	x27, x27, x9
	add	x20, x20, x9
	add	x25, x25, #1
	add	x24, x24, x8
	add	x28, x28, x8
	cmp	x25, x19
	b.ne	.LBB42_7
	b	.LBB42_12
.LBB42_10:
	mul	x8, x19, x22
	lsl	x21, x22, #5
	lsl	x22, x22, #6
	lsl	x23, x8, #5
	ldp	x9, x8, [sp, #40]               // 16-byte Folded Reload
	add	x20, x9, #16
	add	x24, x8, #16
.LBB42_11:                              // =>This Inner Loop Header: Depth=1
	add	x25, x24, x21
	ldur	q0, [x24, #-16]
	ldur	q1, [x25, #-16]
	stp	q0, q1, [x29, #-32]             // 32-byte Folded Spill
	bl	__addtf3
	str	q0, [sp, #64]                   // 16-byte Folded Spill
	ldr	q0, [x24]
	ldr	q1, [x25]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	bl	__addtf3
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	stp	q1, q0, [x20, #-16]
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x23
	subs	x19, x19, #1
	add	x20, x20, x21
	add	x24, x24, x22
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB42_11
.LBB42_12:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end42:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end42-_ZNK9pocketfft6detail5cfftpIeE5pass2ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI43_0:
	.xword	0x0000000000000000              // fp128 0.5
	.xword	0x3ffe000000000000
.LCPI43_1:
	.xword	0xa73b25742d7078b8              // fp128 -0.866025403784438646763723170752936161
	.xword	0xbffebb67ae8584ca
.LCPI43_2:
	.xword	0xa73b25742d7078b8              // fp128 0.866025403784438646763723170752936161
	.xword	0x3ffebb67ae8584ca
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #384
	stp	x29, x30, [sp, #288]            // 16-byte Folded Spill
	add	x29, sp, #288
	stp	x28, x27, [sp, #304]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #320]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #336]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #352]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #368]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x23, x2
	subs	x8, x1, #1
	stp	x4, x3, [sp, #48]               // 16-byte Folded Spill
	b.ne	.LBB43_4
// %bb.1:
	cbz	x23, .LBB43_10
// %bb.2:
	adrp	x8, .LCPI43_0
	adrp	x9, .LCPI43_1
	adrp	x10, .LCPI43_2
	lsl	x19, x23, #6
	lsl	x21, x23, #5
	ldr	q0, [x8, :lo12:.LCPI43_0]
	ldp	x11, x8, [sp, #48]              // 16-byte Folded Reload
	add	x20, x11, #16
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI43_1]
	add	x22, x8, #48
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI43_2]
	str	q0, [sp, #96]                   // 16-byte Folded Spill
.LBB43_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x22, #-32]
	ldur	q1, [x22, #-48]
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stp	q1, q0, [x29, #-48]             // 32-byte Folded Spill
	ldp	q0, q1, [x22]
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x22, #32]
	str	q1, [sp, #128]                  // 16-byte Folded Spill
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [sp, #128]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x20, #-16]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x21
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x19
	add	x20, x20, #32
	subs	x23, x23, #1
	add	x22, x22, #96
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB43_3
	b	.LBB43_10
.LBB43_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x1, [sp, #40]                   // 8-byte Folded Spill
	cbz	x23, .LBB43_10
// %bb.5:
	ldp	x12, x27, [sp, #40]             // 16-byte Folded Reload
	lsl	x18, x23, #1
	adrp	x10, .LCPI43_1
	ldr	x19, [sp, #56]                  // 8-byte Folded Reload
	mov	x13, xzr
	mov	x22, x5
	str	x23, [sp, #72]                  // 8-byte Folded Spill
	add	x9, x12, x12, lsl #1
	mul	x8, x23, x12
	lsl	x9, x9, #5
	lsl	x11, x12, #5
	add	x26, x19, x11
	add	x20, x19, x12, lsl #6
	add	x24, x27, x8, lsl #6
	add	x21, x27, x8, lsl #5
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	adrp	x9, .LCPI43_0
	stp	x11, x18, [sp, #16]             // 16-byte Folded Spill
	adrp	x11, .LCPI43_2
	ldr	x8, [sp]                        // 8-byte Folded Reload
	str	x5, [sp, #32]                   // 8-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI43_0]
	add	x28, x5, x8, lsl #5
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI43_1]
	str	q0, [sp, #96]                   // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI43_2]
	str	q0, [sp, #80]                   // 16-byte Folded Spill
	b	.LBB43_7
.LBB43_6:                               //   in Loop: Header=BB43_7 Depth=1
	ldp	x9, x8, [sp, #8]                // 16-byte Folded Reload
	ldp	x13, x23, [sp, #64]             // 16-byte Folded Reload
	add	x19, x19, x9
	add	x26, x26, x9
	add	x24, x24, x8
	add	x20, x20, x9
	add	x13, x13, #1
	add	x27, x27, x8
	add	x21, x21, x8
	cmp	x13, x23
	b.eq	.LBB43_10
.LBB43_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB43_9 Depth 2
	ldr	x25, [sp, #40]                  // 8-byte Folded Reload
	add	x8, x13, x13, lsl #1
	add	x9, x8, #2
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	mov	x23, x13
	mul	x8, x8, x25
	mul	x9, x9, x25
	add	x10, x25, x8
	add	x8, x11, x8, lsl #5
	add	x10, x11, x10, lsl #5
	add	x9, x11, x9, lsl #5
	ldp	q1, q0, [x8]
	stp	q1, q0, [x29, #-48]             // 32-byte Folded Spill
	ldp	q2, q0, [x10]
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #128]                  // 16-byte Folded Spill
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [sp, #128]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x23, x25
	ldr	x22, [sp, #48]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	add	x8, x22, x8, lsl #5
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	str	x23, [sp, #64]                  // 8-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	add	x8, x23, x8
	add	x9, x23, x9
	mul	x23, x8, x25
	mul	x8, x9, x25
	stur	x8, [x29, #-96]                 // 8-byte Folded Spill
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x23, lsl #5
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-96]                 // 8-byte Folded Reload
	cmp	x25, #2
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	add	x8, x22, x8, lsl #5
	ldr	x22, [sp, #32]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB43_6
// %bb.8:                               //   in Loop: Header=BB43_7 Depth=1
	mov	x23, xzr
	ldr	x25, [sp]                       // 8-byte Folded Reload
.LBB43_9:                               //   Parent Loop BB43_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x19, x23
	add	x9, x26, x23
	add	x10, x20, x23
	ldp	q1, q0, [x8, #32]
	stp	q0, q1, [x29, #-48]             // 32-byte Folded Spill
	ldp	q2, q0, [x9, #32]
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	str	q1, [sp, #128]                  // 16-byte Folded Spill
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [sp, #128]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x27, x23
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [sp, #144]                  // 16-byte Folded Reload
	ldr	q1, [sp, #80]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x23
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #144]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #128]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldr	q1, [sp, #144]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x23
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x23
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-64]             // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-48]             // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x24, x23
	subs	x25, x25, #1
	add	x23, x23, #32
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB43_9
	b	.LBB43_6
.LBB43_10:
	ldp	x20, x19, [sp, #368]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #352]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #336]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #320]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #304]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #288]            // 16-byte Folded Reload
	add	sp, sp, #384
	ret
.Lfunc_end43:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end43-_ZNK9pocketfft6detail5cfftpIeE5pass3ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI44_0:
	.xword	0xf82be73980c0b9dc              // fp128 0.30901699437494742410229341718281908
	.xword	0x3ffd3c6ef372fe94
.LCPI44_1:
	.xword	0x7c15f39cc0605cee              // fp128 -0.80901699437494742410229341718281908
	.xword	0xbffe9e3779b97f4a
.LCPI44_2:
	.xword	0xdedb4265add35f34              // fp128 0.587785252292473129168705954639072828
	.xword	0x3ffe2cf2304755a5
.LCPI44_3:
	.xword	0xf5e6376e1a30d4ec              // fp128 0.951056516295153572116439333379382144
	.xword	0x3ffee6f0e134454f
.LCPI44_4:
	.xword	0xf5e6376e1a30d4ec              // fp128 -0.951056516295153572116439333379382144
	.xword	0xbffee6f0e134454f
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #576
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x27, x2
	subs	x8, x1, #1
	stp	x4, x3, [sp, #96]               // 16-byte Folded Spill
	b.ne	.LBB44_4
// %bb.1:
	cbz	x27, .LBB44_10
// %bb.2:
	ldr	x9, [sp, #96]                   // 8-byte Folded Reload
	adrp	x10, .LCPI44_1
	add	x8, x27, x27, lsl #1
	lsl	x20, x27, #6
	lsl	x21, x8, #5
	adrp	x8, .LCPI44_2
	add	x19, x9, #16
	adrp	x9, .LCPI44_0
	lsl	x22, x27, #7
	lsl	x23, x27, #5
	ldr	q0, [x9, :lo12:.LCPI44_0]
	adrp	x9, .LCPI44_3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI44_1]
	adrp	x10, .LCPI44_4
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI44_2]
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI44_3]
	add	x24, x8, #80
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI44_4]
	str	q0, [sp, #272]                  // 16-byte Folded Spill
.LBB44_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x24, #-64]
	ldur	q1, [x24, #-80]
	stp	q1, q0, [x29, #-96]             // 32-byte Folded Spill
	ldur	q0, [x24, #-32]
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x24, #48]
	stp	q1, q2, [x29, #-192]            // 32-byte Folded Spill
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q2, q0, [x24, #-16]
	stp	q2, q0, [x29, #-224]            // 32-byte Folded Spill
	ldp	q1, q0, [x24, #16]
	stp	q1, q0, [x29, #-256]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x19, #-16]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x19]
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #240]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x23
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x22
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x20
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x21
	add	x19, x19, #32
	subs	x27, x27, #1
	add	x24, x24, #160
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB44_3
	b	.LBB44_10
.LBB44_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	str	x5, [sp, #88]                   // 8-byte Folded Spill
	cbz	x27, .LBB44_10
// %bb.5:
	lsl	x11, x27, #2
	lsl	x10, x27, #1
	ldp	x23, x22, [sp, #96]             // 16-byte Folded Reload
	mul	x8, x27, x1
	mov	w9, #96
	stp	x10, x11, [sp, #56]             // 16-byte Folded Spill
	add	x10, x10, x27
	ldr	x14, [sp]                       // 8-byte Folded Reload
	mov	x24, x1
	madd	x16, x8, x9, x23
	add	x9, x1, x1, lsl #2
	str	x10, [sp, #48]                  // 8-byte Folded Spill
	lsl	x10, x1, #5
	lsl	x9, x9, #5
	ldr	x13, [sp, #88]                  // 8-byte Folded Reload
	add	x17, x22, x10
	add	x18, x22, x1, lsl #7
	mov	x15, xzr
	add	x2, x23, x8, lsl #6
	stp	x9, x10, [sp, #32]              // 16-byte Folded Spill
	lsl	x10, x14, #6
	add	x11, x10, x22
	add	x9, x14, x14, lsl #1
	add	x0, x11, #64
	adrp	x11, .LCPI44_0
	add	x10, x13, x10
	lsl	x9, x9, #5
	add	x12, x9, x22
	add	x9, x13, x9
	add	x1, x12, #96
	add	x12, x13, x14, lsl #5
	str	x10, [sp, #24]                  // 8-byte Folded Spill
	adrp	x10, .LCPI44_1
	ldr	q0, [x11, :lo12:.LCPI44_0]
	adrp	x11, .LCPI44_3
	str	x12, [sp, #16]                  // 8-byte Folded Spill
	adrp	x12, .LCPI44_2
	add	x19, x23, x8, lsl #5
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI44_1]
	adrp	x10, .LCPI44_4
	mov	x25, x9
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI44_2]
	add	x12, x23, x8, lsl #7
	stp	x24, x27, [sp, #72]             // 16-byte Folded Spill
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI44_3]
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI44_4]
	str	q0, [sp, #240]                  // 16-byte Folded Spill
	b	.LBB44_7
.LBB44_6:                               //   in Loop: Header=BB44_7 Depth=1
	ldp	x13, x12, [sp, #144]            // 16-byte Folded Reload
	ldp	x9, x8, [sp, #32]               // 16-byte Folded Reload
	ldp	x11, x10, [sp, #160]            // 16-byte Folded Reload
	ldr	x14, [sp, #136]                 // 8-byte Folded Reload
	add	x22, x22, x9
	ldp	x15, x3, [sp, #112]             // 16-byte Folded Reload
	add	x17, x11, x9
	add	x18, x12, x9
	add	x0, x13, x9
	add	x1, x14, x9
	ldr	x9, [sp, #128]                  // 8-byte Folded Reload
	add	x16, x10, x8
	ldp	x24, x27, [sp, #72]             // 16-byte Folded Reload
	add	x15, x15, #1
	add	x23, x23, x8
	add	x2, x9, x8
	add	x12, x3, x8
	add	x19, x19, x8
	cmp	x15, x27
	b.eq	.LBB44_10
.LBB44_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB44_9 Depth 2
	add	x26, x15, x15, lsl #2
	ldr	x28, [sp, #104]                 // 8-byte Folded Reload
	add	x8, x26, #4
	stp	x12, x2, [sp, #120]             // 16-byte Folded Spill
	mul	x9, x26, x24
	stp	x1, x0, [sp, #136]              // 16-byte Folded Spill
	mul	x8, x8, x24
	stp	x18, x17, [sp, #152]            // 16-byte Folded Spill
	add	x10, x24, x9
	str	x16, [sp, #168]                 // 8-byte Folded Spill
	add	x9, x28, x9, lsl #5
	mov	x20, x15
	add	x10, x28, x10, lsl #5
	add	x8, x28, x8, lsl #5
	ldp	q1, q0, [x9]
	ldp	q2, q3, [x10]
	stp	q1, q0, [x29, #-96]             // 32-byte Folded Spill
	ldp	q1, q0, [x8]
	stp	q2, q1, [x29, #-192]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-160]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x26, #2
	add	x9, x26, #3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mul	x8, x8, x24
	mul	x9, x9, x24
	add	x8, x28, x8, lsl #5
	add	x9, x28, x9, lsl #5
	ldp	q2, q0, [x8]
	ldr	q1, [x9]
	stp	q1, q0, [x29, #-224]            // 32-byte Folded Spill
	ldr	q0, [x9, #16]
	stp	q2, q0, [x29, #-256]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x20, x24
	ldr	x28, [sp, #96]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	add	x26, x28, x8, lsl #5
	str	q0, [x26]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x26, #16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	add	x8, x20, x27
	add	x9, x20, x9
	mul	x26, x8, x24
	mul	x27, x9, x24
	bl	__subtf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x28, x26, lsl #5
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x27, lsl #5
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	ldp	x9, x8, [sp, #48]               // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	str	x20, [sp, #112]                 // 8-byte Folded Spill
	add	x9, x20, x9
	add	x8, x20, x8
	mul	x27, x9, x24
	mul	x26, x8, x24
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x28, x26, lsl #5
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x28, x27, lsl #5
	cmp	x24, #2
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	ldr	x24, [sp, #88]                  // 8-byte Folded Reload
	ldr	x20, [sp, #24]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB44_6
// %bb.8:                               //   in Loop: Header=BB44_7 Depth=1
	mov	x26, xzr
	ldr	x27, [sp]                       // 8-byte Folded Reload
.LBB44_9:                               //   Parent Loop BB44_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x22, x26
	ldp	x10, x9, [sp, #152]             // 16-byte Folded Reload
	ldr	q0, [x8, #32]
	add	x9, x9, x26
	add	x10, x10, x26
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x8, #48]
	ldp	q2, q3, [x9, #32]
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	stp	q1, q2, [x29, #-192]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-160]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #136]              // 16-byte Folded Reload
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	add	x9, x9, x26
	add	x8, x8, x26
	ldr	q1, [x9, #32]
	ldp	q2, q0, [x8, #32]
	stp	q1, q0, [x29, #-224]            // 32-byte Folded Spill
	ldr	q0, [x9, #48]
	stp	q2, q0, [x29, #-256]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-128]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	add	x28, x23, x26
	str	q0, [x28, #32]
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x28, #48]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldr	q1, [sp, #256]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #224]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x24, x26
	str	q0, [sp, #176]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #208]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #192]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #272]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #192]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #192]                  // 16-byte Folded Spill
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	ldr	q1, [sp, #176]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldr	q0, [sp, #288]                  // 16-byte Folded Reload
	ldr	q1, [sp, #208]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x19, x26
	ldr	q1, [sp, #192]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #224]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x25, x26
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #120]                  // 8-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldr	q1, [sp, #240]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x26
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [x8]
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #128]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x26
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-96]             // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	subs	x27, x27, #1
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	add	x8, x8, x26
	add	x26, x26, #32
	stp	q1, q0, [x8, #32]
	b.ne	.LBB44_9
	b	.LBB44_6
.LBB44_10:
	add	sp, sp, #576
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end44:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end44-_ZNK9pocketfft6detail5cfftpIeE5pass5ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI45_0:
	.xword	0x16cbef0b3c8a771c              // fp128 0.623489801858733530525004884004239828
	.xword	0x3ffe3f3a0e28bedd
.LCPI45_1:
	.xword	0x26942fdd4d81e548              // fp128 -0.222520933956314404288902564496794804
	.xword	0xbffcc7b90e302458
.LCPI45_2:
	.xword	0x0d26e313e929fdcb              // fp128 -0.90096886790241912623610231950744512
	.xword	0xbffecd4bca9cb5c7
.LCPI45_3:
	.xword	0x8e3954a4ef51dd5c              // fp128 0.974927912181823607018131682993931188
	.xword	0x3ffef329c0558e96
.LCPI45_4:
	.xword	0xb0bb3599ce804ff5              // fp128 0.78183148246802980870844452667405784
	.xword	0x3ffe904c37505de4
.LCPI45_5:
	.xword	0x1005772daf64d3b2              // fp128 0.433883739117558120475768332848359021
	.xword	0x3ffdbc4c04d71abc
.LCPI45_6:
	.xword	0x1005772daf64d3b2              // fp128 -0.433883739117558120475768332848359021
	.xword	0xbffdbc4c04d71abc
.LCPI45_7:
	.xword	0xb0bb3599ce804ff5              // fp128 -0.78183148246802980870844452667405784
	.xword	0xbffe904c37505de4
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #752
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	stp	x4, x3, [sp, #136]              // 16-byte Folded Spill
	b.ne	.LBB45_4
// %bb.1:
	cbz	x2, .LBB45_10
// %bb.2:
	adrp	x9, .LCPI45_0
	adrp	x10, .LCPI45_1
	adrp	x12, .LCPI45_2
	ldr	x8, [sp, #136]                  // 8-byte Folded Reload
	add	x11, x2, x2, lsl #2
	lsl	x19, x2, #7
	ldr	q0, [x9, :lo12:.LCPI45_0]
	adrp	x9, .LCPI45_3
	add	x20, x8, #16
	add	x8, x2, x2, lsl #1
	lsl	x21, x8, #5
	lsl	x24, x8, #6
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI45_1]
	adrp	x10, .LCPI45_4
	ldr	x8, [sp, #144]                  // 8-byte Folded Reload
	lsl	x22, x11, #5
	lsl	x23, x2, #6
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI45_2]
	adrp	x12, .LCPI45_5
	lsl	x25, x2, #5
	add	x26, x8, #112
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI45_3]
	adrp	x9, .LCPI45_6
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI45_4]
	adrp	x10, .LCPI45_7
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI45_5]
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldr	q0, [x9, :lo12:.LCPI45_6]
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI45_7]
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
.LBB45_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x26, #-96]
	mov	x27, x2
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q1, [x26, #-112]
	ldur	q0, [x26, #-64]
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x26, #80]
	stp	q2, q1, [x29, #-208]            // 32-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q2, q0, [x26, #-48]
	str	q2, [sp, #464]                  // 16-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x26, #48]
	str	q1, [sp, #448]                  // 16-byte Folded Spill
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #448]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #432]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q2, q0, [x26, #-16]
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [x26, #16]
	str	q1, [sp, #384]                  // 16-byte Folded Spill
	stp	q0, q2, [sp, #400]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x20, #-16]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x25
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x24
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x23
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x22
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x21
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	mov	x2, x27
	add	x8, x20, x19
	add	x20, x20, #32
	subs	x2, x27, #1
	add	x26, x26, #224
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB45_3
	b	.LBB45_10
.LBB45_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	str	x5, [sp, #128]                  // 8-byte Folded Spill
	cbz	x2, .LBB45_10
// %bb.5:
	lsl	x9, x2, #1
	lsl	x10, x2, #2
	ldp	x19, x27, [sp, #136]            // 16-byte Folded Reload
	mul	x8, x2, x1
	mov	w15, #96
	str	x9, [sp, #104]                  // 8-byte Folded Spill
	add	x9, x9, x2
	lsl	x11, x9, #1
	ldr	x16, [sp, #8]                   // 8-byte Folded Reload
	madd	x5, x8, x15, x19
	ldr	x15, [sp, #128]                 // 8-byte Folded Reload
	stp	x10, x9, [sp, #88]              // 16-byte Folded Spill
	add	x9, x10, x2
	add	x10, x19, x8, lsl #7
	add	x12, x16, x16, lsl #1
	lsl	x12, x12, #5
	mov	x23, x1
	stp	x9, x11, [sp, #72]              // 16-byte Folded Spill
	mov	w9, #224
	str	x10, [sp, #160]                 // 8-byte Folded Spill
	lsl	x10, x1, #5
	mul	x9, x1, x9
	add	x17, x27, x10
	lsl	x14, x16, #7
	mov	x25, xzr
	stp	x23, x2, [sp, #112]             // 16-byte Folded Spill
	stp	x9, x10, [sp, #56]              // 16-byte Folded Spill
	lsl	x10, x16, #6
	add	x11, x10, x27
	mov	w9, #192
	add	x0, x11, #64
	add	x11, x16, x16, lsl #2
	lsl	x11, x11, #5
	add	x10, x15, x10
	add	x13, x11, x27
	madd	x18, x1, x9, x27
	add	x1, x13, #160
	add	x13, x12, x27
	add	x12, x15, x12
	stp	x10, x12, [sp, #40]             // 16-byte Folded Spill
	adrp	x10, .LCPI45_0
	add	x3, x13, #96
	add	x13, x14, x27
	add	x11, x15, x11
	mov	w12, #160
	add	x4, x13, #128
	add	x13, x15, x14
	madd	x6, x8, x12, x19
	adrp	x12, .LCPI45_1
	ldr	q0, [x10, :lo12:.LCPI45_0]
	adrp	x10, .LCPI45_3
	str	x13, [sp, #32]                  // 8-byte Folded Spill
	adrp	x13, .LCPI45_2
	ldp	x24, x22, [sp, #40]             // 16-byte Folded Reload
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	add	x14, x15, x16, lsl #5
	ldr	q0, [x12, :lo12:.LCPI45_1]
	adrp	x12, .LCPI45_4
	ldr	x28, [sp, #32]                  // 8-byte Folded Reload
	stp	x11, x14, [sp, #16]             // 16-byte Folded Spill
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI45_2]
	adrp	x13, .LCPI45_5
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI45_3]
	adrp	x10, .LCPI45_6
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI45_4]
	adrp	x12, .LCPI45_7
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI45_5]
	add	x13, x19, x8, lsl #6
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI45_6]
	add	x10, x19, x8, lsl #5
	madd	x8, x8, x9, x19
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI45_7]
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	b	.LBB45_7
.LBB45_6:                               //   in Loop: Header=BB45_7 Depth=1
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	mov	x8, x25
	ldp	x12, x11, [sp, #240]            // 16-byte Folded Reload
	add	x8, x8, x9
	ldr	x25, [sp, #152]                 // 8-byte Folded Reload
	ldp	x14, x13, [sp, #224]            // 16-byte Folded Reload
	ldp	x16, x15, [sp, #208]            // 16-byte Folded Reload
	str	x8, [sp, #160]                  // 8-byte Folded Spill
	add	x25, x25, #1
	ldp	x20, x19, [sp, #168]            // 16-byte Folded Reload
	ldr	x8, [sp, #56]                   // 8-byte Folded Reload
	ldp	x6, x5, [sp, #192]              // 16-byte Folded Reload
	add	x27, x20, x8
	add	x17, x12, x8
	add	x18, x11, x8
	add	x0, x13, x8
	add	x1, x14, x8
	add	x3, x15, x8
	add	x4, x16, x8
	ldr	x7, [sp, #184]                  // 8-byte Folded Reload
	ldp	x10, x8, [sp, #256]             // 16-byte Folded Reload
	add	x19, x19, x9
	add	x5, x5, x9
	ldp	x23, x2, [sp, #112]             // 16-byte Folded Reload
	add	x6, x6, x9
	add	x13, x7, x9
	add	x10, x10, x9
	add	x8, x8, x9
	cmp	x25, x2
	b.eq	.LBB45_10
.LBB45_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB45_9 Depth 2
	str	x8, [sp, #264]                  // 8-byte Folded Spill
	lsl	x8, x25, #3
	sub	x20, x8, x25
	ldr	x26, [sp, #144]                 // 8-byte Folded Reload
	stp	x18, x10, [sp, #248]            // 16-byte Folded Spill
	add	x8, x20, #6
	mul	x9, x20, x23
	stp	x27, x19, [sp, #168]            // 16-byte Folded Spill
	mul	x8, x8, x23
	stp	x13, x6, [sp, #184]             // 16-byte Folded Spill
	add	x10, x23, x9
	stp	x5, x4, [sp, #200]              // 16-byte Folded Spill
	add	x9, x26, x9, lsl #5
	stp	x3, x1, [sp, #216]              // 16-byte Folded Spill
	add	x10, x26, x10, lsl #5
	add	x8, x26, x8, lsl #5
	stp	x0, x17, [sp, #232]             // 16-byte Folded Spill
	mov	x19, x2
	ldp	q1, q0, [x9]
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q2, q0, [x10]
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x8]
	stp	q2, q1, [x29, #-208]            // 32-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #2
	add	x9, x20, #5
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mul	x8, x8, x23
	mul	x9, x9, x23
	add	x8, x26, x8, lsl #5
	add	x9, x26, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #464]                  // 16-byte Folded Spill
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #448]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #432]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #3
	add	x9, x20, #4
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	mul	x8, x8, x23
	mul	x9, x9, x23
	add	x8, x26, x8, lsl #5
	add	x9, x26, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	stp	q2, q0, [sp, #384]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x25, x23
	ldr	x21, [sp, #136]                 // 8-byte Folded Reload
	add	x20, x21, x8, lsl #5
	str	q0, [x20]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20, #16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	add	x8, x25, x19
	add	x9, x25, x9
	mul	x20, x8, x23
	mul	x26, x9, x23
	bl	__subtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x20, lsl #5
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x26, lsl #5
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	x9, [sp, #72]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x23
	mul	x26, x9, x23
	bl	__subtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x20, lsl #5
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x26, lsl #5
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldp	x9, x8, [sp, #88]               // 16-byte Folded Reload
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	str	x25, [sp, #152]                 // 8-byte Folded Spill
	add	x9, x25, x9
	add	x8, x25, x8
	mul	x26, x9, x23
	mul	x20, x8, x23
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x20, lsl #5
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldp	q1, q0, [x29, #-144]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__subtf3
	ldp	x27, x19, [sp, #16]             // 16-byte Folded Reload
	add	x8, x21, x26, lsl #5
	cmp	x23, #2
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	ldr	x23, [sp, #128]                 // 8-byte Folded Reload
	ldr	x25, [sp, #160]                 // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB45_6
// %bb.8:                               //   in Loop: Header=BB45_7 Depth=1
	mov	x26, xzr
	ldr	x20, [sp, #8]                   // 8-byte Folded Reload
.LBB45_9:                               //   Parent Loop BB45_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	ldp	x9, x10, [sp, #240]             // 16-byte Folded Reload
	add	x8, x8, x26
	add	x9, x9, x26
	add	x10, x10, x26
	ldr	q1, [x8, #32]
	ldr	q0, [x8, #48]
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldp	q2, q0, [x9, #32]
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	stp	q2, q1, [x29, #-208]            // 32-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #224]              // 16-byte Folded Reload
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	add	x9, x9, x26
	add	x8, x8, x26
	ldp	q2, q0, [x8, #32]
	str	q2, [sp, #448]                  // 16-byte Folded Spill
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #464]                  // 16-byte Folded Spill
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #448]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #432]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	ldp	x9, x8, [sp, #208]              // 16-byte Folded Reload
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	add	x9, x9, x26
	add	x8, x8, x26
	ldp	q2, q0, [x8, #32]
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #416]                  // 16-byte Folded Spill
	stp	q2, q0, [sp, #384]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #384]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	add	x21, x8, x26
	str	q0, [x21, #32]
	ldp	q1, q0, [x29, #-112]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x21, #48]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x23, x26
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	ldr	q0, [x8]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #352]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #352]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x27, x26
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	ldr	q2, [sp, #272]                  // 16-byte Folded Reload
	add	x9, x9, x26
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [sp, #352]              // 32-byte Folded Spill
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #304]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #352]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #368]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x19, x26
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	ldr	q0, [x8]
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #288]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #352]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #272]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #272]                  // 16-byte Folded Spill
	ldr	q0, [sp, #336]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
	ldr	q0, [sp, #352]                  // 16-byte Folded Reload
	ldr	q1, [sp, #288]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x28, x26
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	ldr	q2, [sp, #272]                  // 16-byte Folded Reload
	add	x9, x9, x26
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [sp, #352]              // 32-byte Folded Spill
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #368]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #336]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #368]              // 32-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	ldr	q0, [sp, #400]                  // 16-byte Folded Reload
	ldr	q1, [sp, #352]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #384]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	ldr	q1, [sp, #336]                  // 16-byte Folded Reload
	add	x8, x8, x26
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [sp, #432]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #416]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-128]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x24, x26
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	ldp	q3, q0, [x8]
	stp	q0, q3, [x29, #-144]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x26
	ldr	x9, [sp, #200]                  // 8-byte Folded Reload
	ldur	q2, [x29, #-192]                // 16-byte Folded Reload
	add	x9, x9, x26
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [x29, #-144]            // 32-byte Folded Spill
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-128]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x25, x26
	subs	x20, x20, #1
	add	x26, x26, #32
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x8, #32]
	b.ne	.LBB45_9
	b	.LBB45_6
.LBB45_10:
	add	sp, sp, #752
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end45:
	.size	_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end45-_ZNK9pocketfft6detail5cfftpIeE5pass7ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
.LCPI46_0:
	.xword	0x9ab7f42d86f0d233              // fp128 0.841253532831181168861811648919367736
	.xword	0x3ffeaeb8c8764f0b
.LCPI46_1:
	.xword	0x5d3ef32457c6d64d              // fp128 0.415415013001886425529274149229623209
	.xword	0x3ffda9628d9c712b
.LCPI46_2:
	.xword	0xae3195b1d88fde6c              // fp128 0.142314838273285140443792668616369701
	.xword	0x3ffc2375f640f44d
.LCPI46_3:
	.xword	0x6abb6d39b8208cdf              // fp128 0.654860733945285064056925072466293599
	.xword	0x3ffe4f49e7f77588
.LCPI46_4:
	.xword	0x730f9b19848fb8e0              // fp128 0.959492973614497389890368057066327693
	.xword	0x3ffeeb42a9bcd505
.LCPI46_5:
	.xword	0x35f3c16be82729d8              // fp128 0.909631995354518371411715383079028459
	.xword	0x3ffed1bb48eee2c1
.LCPI46_6:
	.xword	0xb3d83c97abe14dd6              // fp128 0.540640817455597582107635954318691673
	.xword	0x3ffe14cedf8bb580
.LCPI46_7:
	.xword	0xf6f09deb712450b8              // fp128 0.989821441880932732376092037776718829
	.xword	0x3ffefac9e043842e
.LCPI46_8:
	.xword	0x122496a483c5ac91              // fp128 0.755749574354258283774035843972344387
	.xword	0x3ffe82f19bb3a28a
.LCPI46_9:
	.xword	0xf7b05d1c551985c8              // fp128 0.281732556841429697711417915346616884
	.xword	0x3ffd207e7fd768db
.LCPI46_10:
	.xword	0xf7b05d1c551985c8              // fp128 -0.281732556841429697711417915346616884
	.xword	0xbffd207e7fd768db
.LCPI46_11:
	.xword	0xf6f09deb712450b8              // fp128 -0.989821441880932732376092037776718829
	.xword	0xbffefac9e043842e
.LCPI46_12:
	.xword	0xb3d83c97abe14dd6              // fp128 -0.540640817455597582107635954318691673
	.xword	0xbffe14cedf8bb580
.LCPI46_13:
	.xword	0x35f3c16be82729d8              // fp128 -0.909631995354518371411715383079028459
	.xword	0xbffed1bb48eee2c1
	.section	.text._ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #1136
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	str	x5, [sp, #216]                  // 8-byte Folded Spill
	stp	x4, x3, [sp, #192]              // 16-byte Folded Spill
	b.ne	.LBB46_4
// %bb.1:
	cbz	x2, .LBB46_10
// %bb.2:
	mov	w10, #224
	ldr	x11, [sp, #192]                 // 8-byte Folded Reload
	add	x8, x2, x2, lsl #1
	add	x9, x2, x2, lsl #2
	mul	x10, x2, x10
	lsl	x18, x8, #6
	add	x20, x11, #16
	lsl	x11, x9, #5
	lsl	x26, x8, #5
	adrp	x8, .LCPI46_0
	lsl	x23, x2, #7
	lsl	x24, x2, #8
	str	x10, [sp, #416]                 // 8-byte Folded Spill
	ldr	x10, [sp, #200]                 // 8-byte Folded Reload
	stp	x11, x18, [sp, #440]            // 16-byte Folded Spill
	adrp	x11, .LCPI46_1
	ldr	q0, [x8, :lo12:.LCPI46_0]
	adrp	x8, .LCPI46_3
	add	x25, x10, #176
	add	x10, x2, x2, lsl #3
	lsl	x27, x10, #5
	adrp	x10, .LCPI46_2
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI46_1]
	adrp	x11, .LCPI46_4
	lsl	x28, x2, #6
	lsl	x19, x9, #6
	lsl	x21, x2, #5
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI46_2]
	adrp	x10, .LCPI46_5
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI46_3]
	adrp	x8, .LCPI46_6
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI46_4]
	adrp	x11, .LCPI46_7
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI46_5]
	adrp	x10, .LCPI46_8
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI46_6]
	adrp	x8, .LCPI46_9
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI46_7]
	adrp	x11, .LCPI46_10
	str	q0, [sp, #800]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI46_8]
	adrp	x10, .LCPI46_11
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI46_9]
	adrp	x8, .LCPI46_12
	str	q0, [sp, #784]                  // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI46_10]
	adrp	x11, .LCPI46_13
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	ldr	q0, [x10, :lo12:.LCPI46_11]
	str	q0, [sp, #560]                  // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI46_12]
	str	q0, [sp, #544]                  // 16-byte Folded Spill
	ldr	q0, [x11, :lo12:.LCPI46_13]
	str	q0, [sp, #768]                  // 16-byte Folded Spill
.LBB46_3:                               // =>This Inner Loop Header: Depth=1
	ldp	q0, q2, [x25, #-160]
	mov	x22, x2
	ldur	q1, [x25, #-176]
	ldur	q3, [x25, #-128]
	stp	q1, q0, [x29, #-144]            // 32-byte Folded Spill
	ldp	q1, q0, [x25, #144]
	stp	q2, q1, [x29, #-240]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-208]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #752]                  // 16-byte Folded Spill
	ldp	q2, q0, [x25, #-112]
	stur	q2, [x29, #-256]                // 16-byte Folded Spill
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q1, q0, [x25, #112]
	str	q1, [sp, #864]                  // 16-byte Folded Spill
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	ldp	q2, q0, [x25, #-80]
	str	q2, [sp, #848]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [x25, #80]
	str	q1, [sp, #832]                  // 16-byte Folded Spill
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #720]                  // 16-byte Folded Spill
	ldp	q2, q3, [x25, #-48]
	ldp	q1, q0, [x25, #48]
	stp	q1, q2, [sp, #672]              // 32-byte Folded Spill
	stp	q0, q3, [sp, #832]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #672]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #624]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #688]                  // 16-byte Folded Spill
	ldp	q2, q0, [x25, #-16]
	str	q2, [sp, #608]                  // 16-byte Folded Spill
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldp	q1, q0, [x25, #16]
	stp	q1, q0, [sp, #512]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x20, #-16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #832]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x21
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x19
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x28
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x27
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x26
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, x24
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x20, x23
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8, #-16]
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #416]                  // 8-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	add	x8, x20, x8
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-144]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #752]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #440]                  // 8-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	add	x8, x20, x8
	stp	q1, q0, [x8, #-16]
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #448]                  // 8-byte Folded Reload
	mov	x2, x22
	subs	x2, x22, #1
	add	x25, x25, #352
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	add	x8, x20, x8
	add	x20, x20, #32
	stp	q1, q0, [x8, #-16]
	b.ne	.LBB46_3
	b	.LBB46_10
.LBB46_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	cbz	x2, .LBB46_10
// %bb.5:
	ldp	x27, x19, [sp, #192]            // 16-byte Folded Reload
	mul	x8, x2, x1
	mov	w10, #192
	mov	w11, #352
	ldr	x4, [sp, #8]                    // 8-byte Folded Reload
	ldr	x22, [sp, #216]                 // 8-byte Folded Reload
	lsl	x9, x2, #2
	madd	x10, x8, x10, x27
	add	x5, x9, x2
	lsl	x12, x4, #6
	add	x13, x4, x4, lsl #1
	lsl	x14, x13, #5
	lsl	x17, x4, #7
	add	x15, x14, x19
	add	x18, x17, x19
	str	x10, [sp, #392]                 // 8-byte Folded Spill
	mul	x10, x1, x11
	add	x21, x15, #96
	mov	w15, #224
	add	x26, x18, #128
	add	x18, x4, x4, lsl #2
	mul	x0, x4, x15
	str	x9, [sp, #176]                  // 8-byte Folded Spill
	str	x10, [sp, #160]                 // 8-byte Folded Spill
	add	x10, x12, x19
	add	x7, x10, #64
	add	x10, x4, x4, lsl #3
	lsl	x10, x10, #5
	mov	w9, #320
	add	x11, x10, x19
	lsl	x13, x13, #6
	add	x20, x11, #288
	lsl	x11, x4, #8
	add	x16, x11, x19
	mov	x28, x1
	add	x24, x16, #256
	add	x16, x0, x19
	add	x16, x16, #224
	madd	x6, x1, x9, x19
	add	x1, x13, x19
	add	x13, x22, x13
	add	x12, x22, x12
	add	x11, x22, x11
	str	x16, [sp, #384]                 // 8-byte Folded Spill
	lsl	x16, x18, #5
	add	x18, x16, x19
	add	x16, x22, x16
	stp	x11, x12, [sp, #96]             // 16-byte Folded Spill
	adrp	x12, .LCPI46_2
	add	x10, x22, x10
	mov	w3, #160
	str	x16, [sp, #152]                 // 8-byte Folded Spill
	add	x16, x22, x17
	lsl	x17, x2, #3
	mov	w11, #288
	madd	x3, x8, x3, x27
	stp	x13, x16, [sp, #136]            // 16-byte Folded Spill
	add	x13, x22, x14
	add	x14, x22, x0
	add	x0, x17, x2
	madd	x15, x8, x15, x27
	str	x10, [sp, #88]                  // 8-byte Folded Spill
	str	x13, [sp, #128]                 // 8-byte Folded Spill
	adrp	x13, .LCPI46_0
	str	x14, [sp, #112]                 // 8-byte Folded Spill
	adrp	x14, .LCPI46_1
	stp	x0, x17, [sp, #56]              // 16-byte Folded Spill
	sub	x17, x17, x2
	ldr	q0, [x13, :lo12:.LCPI46_0]
	adrp	x13, .LCPI46_3
	madd	x9, x8, x9, x27
	mov	x25, xzr
	madd	x10, x8, x11, x27
	add	x18, x18, #160
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI46_1]
	adrp	x14, .LCPI46_4
	add	x1, x1, #192
	add	x16, x27, x8, lsl #7
	add	x11, x27, x8, lsl #5
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI46_2]
	adrp	x12, .LCPI46_5
	str	x5, [sp, #168]                  // 8-byte Folded Spill
	str	x2, [sp, #184]                  // 8-byte Folded Spill
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI46_3]
	adrp	x13, .LCPI46_6
	str	x28, [sp, #120]                 // 8-byte Folded Spill
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI46_4]
	adrp	x14, .LCPI46_7
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI46_5]
	adrp	x12, .LCPI46_8
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI46_6]
	adrp	x13, .LCPI46_9
	str	q0, [sp, #800]                  // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI46_7]
	adrp	x14, .LCPI46_10
	str	q0, [sp, #784]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI46_8]
	adrp	x12, .LCPI46_11
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI46_9]
	adrp	x13, .LCPI46_12
	str	q0, [sp, #768]                  // 16-byte Folded Spill
	ldr	q0, [x14, :lo12:.LCPI46_10]
	mov	w14, #96
	str	q0, [sp, #560]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI46_11]
	adrp	x12, .LCPI46_13
	madd	x14, x8, x14, x27
	str	q0, [sp, #544]                  // 16-byte Folded Spill
	ldr	q0, [x13, :lo12:.LCPI46_12]
	add	x13, x27, x8, lsl #8
	add	x8, x27, x8, lsl #6
	str	q0, [sp, #528]                  // 16-byte Folded Spill
	ldr	q0, [x12, :lo12:.LCPI46_13]
	lsl	x12, x5, #1
	str	q0, [sp, #752]                  // 16-byte Folded Spill
	str	x12, [sp, #80]                  // 8-byte Folded Spill
	lsl	x12, x2, #1
	str	x12, [sp, #72]                  // 8-byte Folded Spill
	add	x12, x12, x2
	stp	x17, x12, [sp, #40]             // 16-byte Folded Spill
	lsl	x17, x28, #5
	lsl	x12, x12, #1
	add	x23, x19, x17
	stp	x12, x17, [sp, #24]             // 16-byte Folded Spill
	add	x17, x22, x4, lsl #5
	str	x17, [sp, #16]                  // 8-byte Folded Spill
	b	.LBB46_7
.LBB46_6:                               //   in Loop: Header=BB46_7 Depth=1
	mov	x8, x9
	ldr	x9, [sp, #32]                   // 8-byte Folded Reload
	ldp	x10, x11, [sp, #376]            // 16-byte Folded Reload
	add	x8, x8, x9
	ldr	x0, [sp, #352]                  // 8-byte Folded Reload
	ldp	x18, x16, [sp, #296]            // 16-byte Folded Reload
	str	x8, [sp, #392]                  // 8-byte Folded Spill
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	ldp	x14, x13, [sp, #320]            // 16-byte Folded Reload
	ldp	x3, x1, [sp, #280]              // 16-byte Folded Reload
	add	x11, x11, x8
	add	x0, x0, x8
	ldr	x23, [sp, #224]                 // 8-byte Folded Reload
	add	x6, x16, x8
	ldr	x15, [sp, #312]                 // 8-byte Folded Reload
	add	x7, x18, x8
	add	x20, x10, x8
	add	x21, x14, x8
	add	x23, x23, x8
	add	x24, x13, x8
	add	x26, x15, x8
	str	x11, [sp, #384]                 // 8-byte Folded Spill
	add	x18, x1, x8
	add	x3, x3, x8
	ldp	x8, x17, [sp, #360]             // 16-byte Folded Reload
	mov	x1, x3
	ldp	x5, x4, [sp, #264]              // 16-byte Folded Reload
	ldp	x12, x11, [sp, #336]            // 16-byte Folded Reload
	add	x17, x17, x9
	add	x8, x8, x9
	ldp	x22, x19, [sp, #248]            // 16-byte Folded Reload
	add	x4, x4, x9
	add	x15, x5, x9
	ldp	x30, x27, [sp, #232]            // 16-byte Folded Reload
	add	x11, x11, x9
	add	x10, x12, x9
	ldr	x25, [sp, #208]                 // 8-byte Folded Reload
	add	x13, x22, x9
	ldr	x2, [sp, #184]                  // 8-byte Folded Reload
	add	x16, x19, x9
	add	x30, x30, x9
	mov	x3, x4
	add	x25, x25, #1
	add	x14, x27, x9
	ldr	x28, [sp, #120]                 // 8-byte Folded Reload
	mov	x9, x11
	mov	x11, x30
	mov	x27, x17
	mov	x19, x0
	cmp	x25, x2
	b.eq	.LBB46_10
.LBB46_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB46_9 Depth 2
	mov	w17, #11
	stp	x27, x20, [sp, #368]            // 16-byte Folded Spill
	stp	x21, x24, [sp, #320]            // 16-byte Folded Spill
	ldr	x24, [sp, #200]                 // 8-byte Folded Reload
	mul	x20, x25, x17
	stp	x10, x9, [sp, #336]             // 16-byte Folded Spill
	stp	x19, x8, [sp, #352]             // 16-byte Folded Spill
	mov	x21, x2
	add	x8, x20, #10
	stp	x23, x11, [sp, #224]            // 16-byte Folded Spill
	mul	x9, x20, x28
	stp	x14, x13, [sp, #240]            // 16-byte Folded Spill
	mul	x8, x8, x28
	stp	x16, x15, [sp, #256]            // 16-byte Folded Spill
	add	x10, x28, x9
	stp	x3, x1, [sp, #272]              // 16-byte Folded Spill
	add	x9, x24, x9, lsl #5
	stp	x18, x7, [sp, #288]             // 16-byte Folded Spill
	add	x10, x24, x10, lsl #5
	add	x8, x24, x8, lsl #5
	stp	x6, x26, [sp, #304]             // 16-byte Folded Spill
	ldr	q0, [x9]
	ldp	q2, q3, [x10]
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [x9, #16]
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x8]
	stp	q2, q1, [x29, #-240]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-208]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #720]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-208]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #2
	add	x9, x20, #9
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q3, [x8]
	str	q2, [sp, #864]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stur	q1, [x29, #-256]                // 16-byte Folded Spill
	stp	q0, q3, [x29, #-240]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-240]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #3
	add	x9, x20, #8
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #832]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q1, q0, [sp, #848]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #4
	add	x9, x20, #7
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q3, [x8]
	str	q2, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	str	q1, [sp, #688]                  // 16-byte Folded Spill
	stp	q0, q3, [sp, #832]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #688]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #624]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #832]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x20, #5
	add	x9, x20, #6
	str	q0, [sp, #688]                  // 16-byte Folded Spill
	mul	x8, x8, x28
	mul	x9, x9, x28
	add	x8, x24, x8, lsl #5
	add	x9, x24, x9, lsl #5
	ldp	q2, q0, [x8]
	str	q2, [sp, #512]                  // 16-byte Folded Spill
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q0, q1, [sp, #592]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	bl	__addtf3
	mul	x8, x25, x28
	ldr	x22, [sp, #192]                 // 8-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	add	x20, x22, x8, lsl #5
	str	q0, [x20]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #832]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x20, #16]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #800]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x21
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	x9, [sp, #56]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	x9, [sp, #40]                   // 8-byte Folded Reload
	mov	v1.16b, v0.16b
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #496]              // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #496]              // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	str	x25, [sp, #208]                 // 8-byte Folded Spill
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	add	x8, x25, x8
	add	x9, x25, x9
	mul	x20, x8, x28
	mul	x24, x9, x28
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__addtf3
	add	x8, x22, x20, lsl #5
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	stp	q1, q0, [x8]
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	add	x8, x22, x24, lsl #5
	cmp	x28, #2
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x27, x26, [sp, #128]            // 16-byte Folded Reload
	ldp	x23, x19, [sp, #104]            // 16-byte Folded Reload
	ldp	x20, x25, [sp, #88]             // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	ldr	x9, [sp, #392]                  // 8-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	stp	q1, q0, [x8]
	b.lo	.LBB46_6
// %bb.8:                               //   in Loop: Header=BB46_7 Depth=1
	mov	x10, xzr
	ldr	x11, [sp, #8]                   // 8-byte Folded Reload
	str	x9, [sp, #392]                  // 8-byte Folded Spill
.LBB46_9:                               //   Parent Loop BB46_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	stur	x10, [x29, #-32]                // 8-byte Folded Spill
	ldr	x9, [sp, #224]                  // 8-byte Folded Reload
	str	x11, [sp, #440]                 // 8-byte Folded Spill
	ldur	x11, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x10
	add	x9, x9, x10
	ldr	x10, [sp, #304]                 // 8-byte Folded Reload
	ldr	q1, [x8, #32]
	add	x10, x10, x11
	ldp	q2, q3, [x9, #32]
	ldr	q0, [x8, #48]
	stp	q1, q0, [x29, #-160]            // 32-byte Folded Spill
	ldp	q1, q0, [x10, #32]
	stp	q1, q2, [x29, #-256]            // 32-byte Folded Spill
	stp	q0, q3, [x29, #-224]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-224]            // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #296]                  // 8-byte Folded Reload
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #376]                  // 8-byte Folded Reload
	ldp	q2, q0, [x8, #32]
	add	x9, x9, x10
	str	q2, [sp, #848]                  // 16-byte Folded Spill
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #864]                  // 16-byte Folded Spill
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #848]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #656]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-256]            // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #320]                  // 8-byte Folded Reload
	str	q0, [sp, #720]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #328]                  // 8-byte Folded Reload
	add	x9, x9, x10
	ldp	q2, q3, [x8, #32]
	ldp	q1, q0, [x9, #32]
	stp	q2, q1, [sp, #816]              // 32-byte Folded Spill
	stp	q0, q3, [sp, #848]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q1, q0, [sp, #848]              // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-256]                // 16-byte Folded Spill
	ldp	q0, q1, [sp, #816]              // 32-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #624]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #848]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #312]                  // 8-byte Folded Reload
	str	q0, [sp, #688]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	add	x9, x9, x10
	ldp	q2, q3, [x8, #32]
	str	q2, [sp, #640]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #672]                  // 16-byte Folded Spill
	stp	q0, q3, [sp, #816]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #816]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #672]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #816]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #288]                  // 8-byte Folded Reload
	str	q0, [sp, #672]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x8, x9
	ldr	x9, [sp, #280]                  // 8-byte Folded Reload
	ldp	q2, q0, [x8, #32]
	add	x9, x9, x10
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldp	q1, q0, [x9, #32]
	str	q1, [sp, #592]                  // 16-byte Folded Spill
	stp	q2, q0, [sp, #496]              // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #592]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #640]                  // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #832]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #368]                  // 8-byte Folded Reload
	mov	x24, x20
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	mov	x20, x25
	mov	x25, x23
	mov	x23, x19
	mov	x19, x27
	mov	x27, x26
	mov	x26, x22
	mov	x22, x21
	add	x21, x8, x9
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	str	q0, [x21, #32]
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-256]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [x21, #48]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	mov	x21, x22
	mov	x22, x26
	mov	x26, x27
	mov	x27, x19
	mov	x19, x23
	mov	x23, x25
	mov	x25, x20
	mov	x20, x24
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldr	x8, [sp, #216]                  // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x8, x9
	ldr	q0, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldr	q0, [sp, #480]                  // 16-byte Folded Reload
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #232]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x24, x8
	ldr	q2, [sp, #400]                  // 16-byte Folded Reload
	add	x9, x9, x10
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [sp, #464]              // 32-byte Folded Spill
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #344]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x28, x8
	ldr	q0, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #360]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x25, x8
	ldr	q2, [sp, #400]                  // 16-byte Folded Reload
	add	x9, x9, x10
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [sp, #464]              // 32-byte Folded Spill
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #336]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x23, x8
	ldr	q0, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #240]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x19, x8
	ldr	q2, [sp, #400]                  // 16-byte Folded Reload
	add	x9, x9, x10
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [sp, #464]              // 32-byte Folded Spill
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #248]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldr	q0, [sp, #496]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x27, x8
	ldr	q0, [x8]
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #416]                  // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldp	q0, q1, [sp, #464]              // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #400]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	ldr	q0, [sp, #448]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #480]                  // 16-byte Folded Spill
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x26, x8
	ldr	q2, [sp, #400]                  // 16-byte Folded Reload
	add	x9, x9, x10
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [sp, #464]              // 32-byte Folded Spill
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #480]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #448]                  // 16-byte Folded Spill
	ldp	q1, q0, [sp, #480]              // 32-byte Folded Reload
	bl	__multf3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #512]                  // 16-byte Folded Reload
	ldr	q1, [sp, #464]                  // 16-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #496]                  // 16-byte Folded Reload
	bl	__addtf3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	ldr	q1, [sp, #448]                  // 16-byte Folded Reload
	add	x8, x8, x9
	stp	q1, q0, [x8, #32]
	ldur	q0, [x29, #-176]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-224]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldr	q0, [sp, #816]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-160]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-192]            // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldr	q0, [sp, #656]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #704]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #608]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	ldr	q1, [sp, #528]                  // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #688]                  // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #672]                  // 16-byte Folded Reload
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-192]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-176]            // 32-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__subtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	add	x8, x22, x8
	ldr	q0, [x8]
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	stur	q0, [x29, #-224]                // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-192]            // 32-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-240]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldur	q0, [x29, #-208]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-176]                // 16-byte Folded Spill
	ldur	q0, [x29, #-192]                // 16-byte Folded Reload
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x9, [sp, #272]                  // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x8, x21, x8
	ldur	q2, [x29, #-240]                // 16-byte Folded Reload
	add	x9, x9, x10
	ldp	q3, q1, [x8]
	stp	q2, q0, [x9, #32]
	mov	v0.16b, v1.16b
	stp	q1, q3, [x29, #-192]            // 32-byte Folded Spill
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-208]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-176]            // 32-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-160]                // 16-byte Folded Spill
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	ldur	q1, [x29, #-192]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-160]                // 16-byte Folded Reload
	bl	__addtf3
	ldr	x11, [sp, #440]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	ldr	x9, [sp, #392]                  // 8-byte Folded Reload
	subs	x11, x11, #1
	ldur	q1, [x29, #-208]                // 16-byte Folded Reload
	add	x8, x9, x10
	add	x10, x10, #32
	stp	q1, q0, [x8, #32]
	b.ne	.LBB46_9
	b	.LBB46_6
.LBB46_10:
	add	sp, sp, #1136
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end46:
	.size	_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end46-_ZNK9pocketfft6detail5cfftpIeE6pass11ILb0ENS0_5cmplxIeEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
.LCPI47_0:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
.LCPI47_1:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
	.section	.text._ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_,@function
_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_: // @_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #416
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #5
	mov	x25, x7
	add	x0, x8, #64
	mov	x19, x6
	mov	x20, x2
	str	x5, [sp, #88]                   // 8-byte Folded Spill
	str	x4, [sp, #120]                  // 8-byte Folded Spill
	mov	x24, x3
	mov	x27, x1
	bl	malloc
	cbz	x0, .LBB47_85
// %bb.1:
	adrp	x8, .LCPI47_0
	adrp	x10, .LCPI47_1
	add	x9, x0, #64
	add	x22, x20, #1
	mul	x21, x24, x27
	and	x13, x9, #0xffffffffffffffc0
	ldr	q0, [x8, :lo12:.LCPI47_0]
	subs	x14, x20, #2
	ldr	q1, [x10, :lo12:.LCPI47_1]
	lsr	x8, x22, #1
	stur	x0, [x13, #-8]
	str	x13, [sp, #184]                 // 8-byte Folded Spill
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	stp	q0, q1, [x13]
	str	x24, [sp, #128]                 // 8-byte Folded Spill
	str	x27, [sp, #200]                 // 8-byte Folded Spill
	stur	x21, [x29, #-200]               // 8-byte Folded Spill
	str	x20, [sp, #208]                 // 8-byte Folded Spill
	b.lo	.LBB47_4
// %bb.2:
	sub	x16, x20, #1
	cmp	x16, #2
	b.hs	.LBB47_6
// %bb.3:
	mov	w8, #1
	b	.LBB47_13
.LBB47_4:
	cbz	x24, .LBB47_73
// %bb.5:
	cbnz	x27, .LBB47_17
	b	.LBB47_73
.LBB47_6:
	cmp	xzr, x14, lsr #59
	add	x11, x13, #32
	lsl	x10, x14, #5
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB47_13
// %bb.7:
	tbnz	w9, #0, .LBB47_13
// %bb.8:
	add	x11, x13, #48
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB47_13
// %bb.9:
	tbnz	w9, #0, .LBB47_13
// %bb.10:
	and	x9, x16, #0xfffffffffffffffe
	orr	x8, x16, #0x1
	add	x10, x25, #48
	add	x11, x13, #80
	mov	x12, x9
.LBB47_11:                              // =>This Inner Loop Header: Depth=1
	ldp	q2, q0, [x10]
	subs	x12, x12, #2
	ldur	q1, [x10, #-16]
	stp	q2, q0, [x11, #-32]
	ldr	q3, [x10, #32]
	add	x10, x10, #64
	stur	q1, [x11, #-48]
	str	q3, [x11], #64
	b.ne	.LBB47_11
// %bb.12:
	cmp	x16, x9
	b.eq	.LBB47_15
.LBB47_13:
	sub	x9, x20, x8
	lsl	x8, x8, #5
	add	x10, x25, x8
	add	x11, x13, x8
	add	x8, x10, #16
	add	x10, x11, #16
.LBB47_14:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x8, #-16]
	subs	x9, x9, #1
	add	x8, x8, #32
	stp	q0, q1, [x10, #-16]
	add	x10, x10, #32
	b.ne	.LBB47_14
.LBB47_15:
	cbz	x24, .LBB47_35
// %bb.16:
	cbz	x27, .LBB47_37
.LBB47_17:
	mul	x8, x20, x27
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	lsl	x21, x27, #5
	mov	x19, x24
	lsl	x28, x8, #5
	ldr	x26, [sp, #88]                  // 8-byte Folded Reload
	ldr	x27, [sp, #120]                 // 8-byte Folded Reload
	str	x14, [sp, #152]                 // 8-byte Folded Spill
.LBB47_18:                              // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	mov	x2, x21
	bl	memcpy
	add	x27, x27, x28
	add	x26, x26, x21
	subs	x19, x19, #1
	b.ne	.LBB47_18
// %bb.19:
	sub	x8, x20, #1
	cmp	x22, #3
	str	x22, [sp, #160]                 // 8-byte Folded Spill
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	stur	x21, [x29, #-128]               // 8-byte Folded Spill
	b.ls	.LBB47_27
// %bb.20:
	ldr	x9, [sp, #200]                  // 8-byte Folded Reload
	cbz	x9, .LBB47_50
// %bb.21:
	ldr	x11, [sp, #112]                 // 8-byte Folded Reload
	neg	x10, x21
	mov	w8, #2
	ldr	x13, [sp, #16]                  // 8-byte Folded Reload
	ldur	x12, [x29, #-200]               // 8-byte Folded Reload
	cmp	x11, #2
	stur	x10, [x29, #-192]               // 8-byte Folded Spill
	csel	x8, x11, x8, hi
	mul	x9, x9, x13
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	ldr	x11, [sp, #120]                 // 8-byte Folded Reload
	str	x8, [sp, #192]                  // 8-byte Folded Spill
	mul	x8, x12, x13
	add	x10, x14, x12, lsl #5
	add	x9, x11, x9, lsl #5
	add	x22, x10, #16
	add	x25, x9, #16
	lsl	x10, x12, #5
	add	x9, x11, x21
	add	x8, x14, x8, lsl #5
	add	x27, x9, #16
	add	x20, x8, #16
	neg	x8, x10
	mov	w9, #1
	stp	x8, x10, [sp, #168]             // 16-byte Folded Spill
	stur	x28, [x29, #-144]               // 8-byte Folded Spill
.LBB47_22:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB47_23 Depth 2
                                        //       Child Loop BB47_24 Depth 3
	mov	x23, xzr
	stp	x9, x20, [x29, #-184]           // 16-byte Folded Spill
	stp	x27, x25, [x29, #-168]          // 16-byte Folded Spill
	stur	x22, [x29, #-152]               // 8-byte Folded Spill
.LBB47_23:                              //   Parent Loop BB47_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB47_24 Depth 3
	mov	x19, x20
	mov	x28, x27
	mov	x24, x22
	mov	x26, x25
	ldr	x21, [sp, #200]                 // 8-byte Folded Reload
.LBB47_24:                              //   Parent Loop BB47_22 Depth=1
                                        //     Parent Loop BB47_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q3, [x28, #-16]
	ldp	q1, q0, [x26, #-16]
	stp	q1, q2, [x29, #-96]             // 32-byte Folded Spill
	stp	q0, q3, [x29, #-64]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x24, #-16]
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	subs	x21, x21, #1
	add	x26, x26, #32
	add	x24, x24, #32
	add	x28, x28, #32
	stp	q1, q0, [x19, #-16]
	add	x19, x19, #32
	b.ne	.LBB47_24
// %bb.25:                              //   in Loop: Header=BB47_23 Depth=2
	ldur	x28, [x29, #-144]               // 8-byte Folded Reload
	add	x23, x23, #1
	ldur	x21, [x29, #-128]               // 8-byte Folded Reload
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	add	x25, x25, x28
	add	x27, x27, x28
	add	x22, x22, x21
	add	x20, x20, x21
	cmp	x23, x24
	b.ne	.LBB47_23
// %bb.26:                              //   in Loop: Header=BB47_22 Depth=1
	ldp	x8, x9, [x29, #-192]            // 16-byte Folded Reload
	ldp	x25, x22, [x29, #-160]          // 16-byte Folded Reload
	ldp	x20, x27, [x29, #-176]          // 16-byte Folded Reload
	add	x9, x9, #1
	add	x25, x25, x8
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	add	x22, x22, x8
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	add	x27, x27, x21
	add	x20, x20, x8
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	cmp	x9, x8
	b.ne	.LBB47_22
.LBB47_27:
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	cbz	x27, .LBB47_43
// %bb.28:
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	cmp	x8, #3
	b.ls	.LBB47_39
// %bb.29:
	ldr	x9, [sp, #112]                  // 8-byte Folded Reload
	mov	w8, #2
	ldur	x10, [x29, #-200]               // 8-byte Folded Reload
	mov	x19, xzr
	cmp	x9, #2
	csel	x8, x9, x8, hi
	ldr	x9, [sp, #88]                   // 8-byte Folded Reload
	sub	x20, x8, #1
	lsl	x22, x10, #5
	add	x9, x9, x10, lsl #5
	add	x21, x9, #16
.LBB47_30:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB47_31 Depth 2
                                        //       Child Loop BB47_32 Depth 3
	mul	x24, x19, x27
	mov	x23, xzr
	mov	x25, x21
.LBB47_31:                              //   Parent Loop BB47_30 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB47_32 Depth 3
	ldr	x8, [sp, #88]                   // 8-byte Folded Reload
	add	x26, x23, x24
	mov	x27, x25
	mov	x28, x20
	add	x8, x8, x26, lsl #5
	ldp	q0, q1, [x8]
.LBB47_32:                              //   Parent Loop BB47_30 Depth=1
                                        //     Parent Loop BB47_31 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	stur	q1, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q1, [x27, #-16]
	bl	__addtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldr	q1, [x27]
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	subs	x28, x28, #1
	add	x27, x27, x22
	b.ne	.LBB47_32
// %bb.33:                              //   in Loop: Header=BB47_31 Depth=2
	ldr	x8, [sp, #120]                  // 8-byte Folded Reload
	add	x23, x23, #1
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	add	x25, x25, #32
	add	x8, x8, x26, lsl #5
	cmp	x23, x27
	stp	q0, q1, [x8]
	b.ne	.LBB47_31
// %bb.34:                              //   in Loop: Header=BB47_30 Depth=1
	ldur	x8, [x29, #-128]                // 8-byte Folded Reload
	add	x19, x19, #1
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	add	x21, x21, x8
	cmp	x19, x24
	b.ne	.LBB47_30
	b	.LBB47_43
.LBB47_35:
	mov	w9, #1
	cmp	x22, #3
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	b.hi	.LBB47_51
// %bb.36:
	mov	w8, wzr
	subs	x10, x27, #1
	str	x10, [sp, #208]                 // 8-byte Folded Spill
	b.eq	.LBB47_45
	b	.LBB47_71
.LBB47_37:
	cmp	x22, #3
	b.ls	.LBB47_73
// %bb.38:
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	mov	w9, wzr
	ldur	x21, [x29, #-200]               // 8-byte Folded Reload
	b	.LBB47_51
.LBB47_39:
	ldr	x9, [sp, #120]                  // 8-byte Folded Reload
	mov	x8, xzr
	ldr	x10, [sp, #88]                  // 8-byte Folded Reload
	add	x9, x9, #16
	add	x10, x10, #16
.LBB47_40:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB47_41 Depth 2
	mov	x11, x10
	mov	x12, x9
	mov	x13, x27
.LBB47_41:                              //   Parent Loop BB47_40 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x13, x13, #1
	add	x11, x11, #32
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB47_41
// %bb.42:                              //   in Loop: Header=BB47_40 Depth=1
	add	x8, x8, #1
	add	x9, x9, x21
	add	x10, x10, x21
	cmp	x8, x24
	b.ne	.LBB47_40
.LBB47_43:
	ldp	x14, x10, [sp, #152]            // 16-byte Folded Reload
	mov	w9, wzr
	mov	w8, wzr
	ldur	x21, [x29, #-200]               // 8-byte Folded Reload
	ldr	x16, [sp, #16]                  // 8-byte Folded Reload
	ldr	x20, [sp, #208]                 // 8-byte Folded Reload
	cmp	x10, #4
	b.hs	.LBB47_51
// %bb.44:
	subs	x10, x27, #1
	str	x10, [sp, #208]                 // 8-byte Folded Spill
	b.ne	.LBB47_71
.LBB47_45:
	cmp	x21, #0
	eor	w8, w8, #0x1
	cset	w9, eq
	orr	w8, w8, w9
	tbnz	w8, #0, .LBB47_73
// %bb.46:
	mul	x8, x16, x24
	ldur	x12, [x29, #-200]               // 8-byte Folded Reload
	ldp	x13, x11, [sp, #112]            // 16-byte Folded Reload
	mov	w9, #2
	mov	w24, #1
	mul	x8, x8, x27
	lsl	x19, x12, #5
	neg	x23, x19
	cmp	x13, #2
	add	x10, x11, x12, lsl #5
	add	x8, x11, x8, lsl #5
	csel	x20, x13, x9, hi
	add	x21, x10, #16
	add	x22, x8, #16
.LBB47_47:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB47_48 Depth 2
	mov	x25, x22
	mov	x26, x21
	ldur	x27, [x29, #-200]               // 8-byte Folded Reload
.LBB47_48:                              //   Parent Loop BB47_47 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q2, q3, [x26, #-16]
	ldp	q1, q0, [x25, #-16]
	stp	q1, q2, [x29, #-96]             // 32-byte Folded Spill
	stp	q0, q3, [x29, #-64]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x26, #-16]
	ldp	q1, q0, [x29, #-96]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	subs	x27, x27, #1
	add	x26, x26, #32
	stp	q1, q0, [x25, #-16]
	add	x25, x25, #32
	b.ne	.LBB47_48
// %bb.49:                              //   in Loop: Header=BB47_47 Depth=1
	add	x24, x24, #1
	add	x21, x21, x19
	add	x22, x22, x23
	cmp	x24, x20
	b.ne	.LBB47_47
	b	.LBB47_73
.LBB47_50:
	ldur	x21, [x29, #-200]               // 8-byte Folded Reload
	ldr	x16, [sp, #16]                  // 8-byte Folded Reload
	ldr	x20, [sp, #208]                 // 8-byte Folded Reload
	ldr	x14, [sp, #152]                 // 8-byte Folded Reload
.LBB47_51:
	ldr	x11, [sp, #112]                 // 8-byte Folded Reload
	str	w9, [sp, #4]                    // 4-byte Folded Spill
	ldr	x12, [sp, #88]                  // 8-byte Folded Reload
	mul	x9, x21, x14
	lsl	x14, x21, #5
	mul	x8, x21, x16
	sub	x10, x11, #1
	cmp	x11, #2
	add	x9, x12, x9, lsl #5
	lsl	x8, x8, #5
	str	x16, [sp, #16]                  // 8-byte Folded Spill
	neg	x17, x14
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	mov	w10, #2
	csel	x10, x11, x10, hi
	ldr	x11, [sp, #120]                 // 8-byte Folded Reload
	sub	x13, x20, #3
	stp	x17, x14, [sp, #96]             // 16-byte Folded Spill
	str	x10, [sp, #80]                  // 8-byte Folded Spill
	add	x10, x12, x14
	add	x15, x10, #16
	add	x10, x12, x21, lsl #6
	add	x10, x10, #16
	add	x16, x11, x8
	add	x8, x12, x8
	add	x8, x8, #16
	stp	x9, x10, [sp, #168]             // 16-byte Folded Spill
	mov	w9, #96
	add	x10, x11, x14
	sub	x11, x20, #4
	madd	x9, x21, x9, x12
	add	x14, x10, #16
	mul	x10, x21, x11
	str	x8, [sp, #160]                  // 8-byte Folded Spill
	add	x8, x9, #16
	add	x9, x12, x21, lsl #7
	add	x9, x9, #16
	lsl	x11, x21, #6
	add	x18, x12, x10, lsl #5
	neg	x10, x11
	stp	x8, x13, [sp, #64]              // 16-byte Folded Spill
	mul	x8, x21, x13
	stp	x9, x18, [sp, #48]              // 16-byte Folded Spill
	add	x9, x12, x8, lsl #5
	add	x8, x12, #16
	stp	x10, x11, [sp, #136]            // 16-byte Folded Spill
	stp	x8, x9, [sp, #32]               // 16-byte Folded Spill
	lsl	x8, x21, #1
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	mov	w8, #1
	stur	x8, [x29, #-184]                // 8-byte Folded Spill
	str	x15, [sp, #192]                 // 8-byte Folded Spill
	b	.LBB47_53
.LBB47_52:                              //   in Loop: Header=BB47_53 Depth=1
	ldp	x16, x9, [x29, #-192]           // 16-byte Folded Reload
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	add	x9, x9, #1
	add	x16, x16, x8
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	add	x14, x14, x8
	ldr	x8, [sp, #80]                   // 8-byte Folded Reload
	stur	x9, [x29, #-184]                // 8-byte Folded Spill
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	cmp	x9, x8
	b.eq	.LBB47_70
.LBB47_53:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB47_55 Depth 2
                                        //     Child Loop BB47_59 Depth 2
                                        //       Child Loop BB47_61 Depth 3
                                        //     Child Loop BB47_67 Depth 2
                                        //       Child Loop BB47_68 Depth 3
	stur	x14, [x29, #-152]               // 8-byte Folded Spill
	stur	x16, [x29, #-192]               // 8-byte Folded Spill
	cbz	x21, .LBB47_62
// %bb.54:                              //   in Loop: Header=BB47_53 Depth=1
	ldp	x19, x8, [x29, #-192]           // 16-byte Folded Reload
	mov	x26, x21
	mov	x21, xzr
	ldr	x10, [sp, #184]                 // 8-byte Folded Reload
	ldur	x25, [x29, #-152]               // 8-byte Folded Reload
	add	x11, x10, x8, lsl #5
	lsl	x9, x8, #1
	add	x23, x10, x8, lsl #6
	add	x8, x11, #16
	stur	x11, [x29, #-128]               // 8-byte Folded Spill
	stur	x8, [x29, #-144]                // 8-byte Folded Spill
	add	x8, x23, #16
	stp	x8, x9, [x29, #-168]            // 16-byte Folded Spill
	ldr	x20, [sp, #88]                  // 8-byte Folded Reload
.LBB47_55:                              //   Parent Loop BB47_53 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x27, x20, x21
	ldur	x8, [x29, #-128]                // 8-byte Folded Reload
	add	x28, x15, x21
	ldr	q0, [x8]
	ldr	q1, [x27]
	stp	q1, q0, [x29, #-64]             // 32-byte Folded Spill
	ldur	q1, [x28, #-16]
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q0, [x23]
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	add	x22, x8, x21
	ldur	q1, [x22, #-16]
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x24, x25, x21
	ldr	q1, [x27, #16]
	stur	q1, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q1, [x28]
	stur	q0, [x24, #-16]
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldr	q1, [x22]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	x8, [x29, #-144]                // 8-byte Folded Reload
	str	q0, [x24]
	ldr	q1, [x8]
	stp	q1, q1, [x29, #-48]             // 16-byte Folded Spill
	ldurb	w8, [x29, #-17]
	ldr	x9, [sp, #160]                  // 8-byte Folded Reload
	eor	w8, w8, #0x80
	add	x22, x9, x21
	sturb	w8, [x29, #-17]
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	ldur	q0, [x29, #-32]
	add	x24, x8, x21
	ldur	x8, [x29, #-168]                // 8-byte Folded Reload
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldr	q0, [x22]
	ldr	q1, [x8]
	stp	q0, q1, [x29, #-80]             // 32-byte Folded Spill
	ldr	q0, [x24, #16]
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x27, x19, x21
	ldur	q1, [x22, #-16]
	stur	q1, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q1, [x24]
	str	q0, [x27]
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	subs	x26, x26, #1
	add	x21, x21, #32
	str	q0, [x27, #16]
	b.ne	.LBB47_55
// %bb.56:                              //   in Loop: Header=BB47_53 Depth=1
	ldur	x21, [x29, #-200]               // 8-byte Folded Reload
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	cmp	x8, #4
	b.lo	.LBB47_63
.LBB47_57:                              //   in Loop: Header=BB47_53 Depth=1
	ldp	x24, x25, [sp, #40]             // 16-byte Folded Reload
	mov	w20, #3
	ldp	x8, x23, [sp, #56]              // 16-byte Folded Reload
	ldr	x10, [sp, #72]                  // 8-byte Folded Reload
	b	.LBB47_59
.LBB47_58:                              //   in Loop: Header=BB47_59 Depth=2
	ldp	x9, x8, [sp, #136]              // 16-byte Folded Reload
	ldp	x10, x20, [x29, #-176]          // 16-byte Folded Reload
	ldur	x11, [x29, #-144]               // 8-byte Folded Reload
	add	x24, x24, x9
	add	x23, x23, x8
	add	x25, x25, x8
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	sub	x10, x10, #2
	add	x20, x20, #2
	add	x11, x11, x9
	ldur	x21, [x29, #-200]               // 8-byte Folded Reload
	cmp	x20, x8
	mov	x8, x11
	b.hs	.LBB47_64
.LBB47_59:                              //   Parent Loop BB47_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB47_61 Depth 3
	ldp	x19, x11, [x29, #-192]          // 16-byte Folded Reload
	stur	x8, [x29, #-144]                // 8-byte Folded Spill
	ldp	x8, x28, [x29, #-160]           // 16-byte Folded Reload
	stp	x10, x20, [x29, #-176]          // 16-byte Folded Spill
	ldr	x10, [sp, #208]                 // 8-byte Folded Reload
	add	x8, x8, x11
	cmp	x8, x10
	csel	x9, x10, xzr, hi
	sub	x8, x8, x9
	add	x9, x8, x11
	cmp	x9, x10
	csel	x10, x10, xzr, hi
	sub	x9, x9, x10
	stur	x9, [x29, #-160]                // 8-byte Folded Spill
	cbz	x21, .LBB47_58
// %bb.60:                              //   in Loop: Header=BB47_59 Depth=2
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	mov	x22, xzr
	ldur	x10, [x29, #-160]               // 8-byte Folded Reload
	ldur	x27, [x29, #-200]               // 8-byte Folded Reload
	add	x8, x9, x8, lsl #5
	add	x9, x9, x10, lsl #5
	ldp	q1, q0, [x8]
	stp	q0, q1, [x29, #-64]             // 32-byte Folded Spill
	ldp	q1, q0, [x9]
	stp	q0, q1, [x29, #-96]             // 32-byte Folded Spill
.LBB47_61:                              //   Parent Loop BB47_53 Depth=1
                                        //     Parent Loop BB47_59 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x26, x23, x22
	add	x21, x25, x22
	ldur	q0, [x26, #-16]
	ldur	q1, [x21, #-16]
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x20, x28, x22
	mov	v1.16b, v0.16b
	ldur	q0, [x20, #-16]
	bl	__addtf3
	ldr	q1, [x26]
	stur	q0, [x20, #-16]
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	stur	q1, [x29, #-112]                // 16-byte Folded Spill
	ldr	q1, [x21]
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	ldr	q0, [x20]
	bl	__addtf3
	add	x21, x24, x22
	ldur	x8, [x29, #-144]                // 8-byte Folded Reload
	str	q0, [x20]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	add	x26, x8, x22
	ldr	q1, [x21, #16]
	stur	q1, [x29, #-128]                // 16-byte Folded Spill
	ldr	q1, [x26, #16]
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-128]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	add	x20, x19, x22
	mov	v1.16b, v0.16b
	ldr	q0, [x20]
	bl	__subtf3
	ldr	q1, [x21]
	str	q0, [x20]
	ldur	q0, [x29, #-96]                 // 16-byte Folded Reload
	stur	q1, [x29, #-112]                // 16-byte Folded Spill
	ldr	q1, [x26]
	bl	__multf3
	stur	q0, [x29, #-128]                // 16-byte Folded Spill
	ldur	q0, [x29, #-112]                // 16-byte Folded Reload
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__addtf3
	mov	v1.16b, v0.16b
	ldr	q0, [x20, #16]
	bl	__addtf3
	subs	x27, x27, #1
	add	x22, x22, #32
	str	q0, [x20, #16]
	b.ne	.LBB47_61
	b	.LBB47_58
.LBB47_62:                              //   in Loop: Header=BB47_53 Depth=1
	ldur	x8, [x29, #-184]                // 8-byte Folded Reload
	lsl	x8, x8, #1
	stur	x8, [x29, #-160]                // 8-byte Folded Spill
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	cmp	x8, #4
	b.hs	.LBB47_57
.LBB47_63:                              //   in Loop: Header=BB47_53 Depth=1
	ldr	x10, [sp, #72]                  // 8-byte Folded Reload
	mov	w20, #3
.LBB47_64:                              //   in Loop: Header=BB47_53 Depth=1
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	ldur	x14, [x29, #-152]               // 8-byte Folded Reload
	cmp	x20, x8
	b.hs	.LBB47_52
// %bb.65:                              //   in Loop: Header=BB47_53 Depth=1
	cbz	x21, .LBB47_52
// %bb.66:                              //   in Loop: Header=BB47_53 Depth=1
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	mul	x8, x9, x20
	mul	x9, x9, x10
	ldr	x10, [sp, #32]                  // 8-byte Folded Reload
	add	x22, x10, x8, lsl #4
	add	x23, x10, x9, lsl #4
.LBB47_67:                              //   Parent Loop BB47_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB47_68 Depth 3
	ldp	x19, x8, [x29, #-192]           // 16-byte Folded Reload
	mov	x24, xzr
	mov	x25, x21
	ldur	x9, [x29, #-160]                // 8-byte Folded Reload
	add	x8, x9, x8
	ldr	x9, [sp, #208]                  // 8-byte Folded Reload
	cmp	x8, x9
	csel	x9, x9, xzr, hi
	sub	x8, x8, x9
	stur	x8, [x29, #-160]                // 8-byte Folded Spill
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	add	x8, x9, x8, lsl #5
	ldp	q1, q0, [x8]
	stp	q0, q1, [x29, #-64]             // 32-byte Folded Spill
.LBB47_68:                              //   Parent Loop BB47_53 Depth=1
                                        //     Parent Loop BB47_67 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x27, x14, x24
	add	x26, x22, x24
	ldur	q1, [x27, #-16]
	ldur	q0, [x26, #-16]
	stur	q1, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [x26]
	stur	q0, [x27, #-16]
	ldr	q2, [x27]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	stur	q2, [x29, #-80]                 // 16-byte Folded Spill
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x26, x23, x24
	add	x28, x19, x24
	str	q0, [x27]
	ldr	q1, [x26]
	ldr	q2, [x28]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stur	q2, [x29, #-80]                 // 16-byte Folded Spill
	bl	__multf3
	mov	v1.16b, v0.16b
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	bl	__subtf3
	ldur	q1, [x26, #-16]
	str	q0, [x28]
	ldr	q2, [x28, #16]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	stur	q2, [x29, #-80]                 // 16-byte Folded Spill
	bl	__multf3
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	x14, [x29, #-152]               // 8-byte Folded Reload
	subs	x25, x25, #1
	add	x24, x24, #32
	str	q0, [x28, #16]
	b.ne	.LBB47_68
// %bb.69:                              //   in Loop: Header=BB47_67 Depth=2
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	add	x20, x20, #1
	add	x22, x22, x8
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	add	x23, x23, x8
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	cmp	x20, x8
	b.ne	.LBB47_67
	b	.LBB47_52
.LBB47_70:
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	mov	w8, #1
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	ldr	x16, [sp, #16]                  // 8-byte Folded Reload
	ldr	w9, [sp, #4]                    // 4-byte Folded Reload
	subs	x10, x27, #1
	str	x10, [sp, #208]                 // 8-byte Folded Spill
	b.eq	.LBB47_45
.LBB47_71:
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cbz	w8, .LBB47_73
// %bb.72:
	tbz	w9, #0, .LBB47_76
.LBB47_73:
	ldr	x8, [sp, #184]                  // 8-byte Folded Reload
	cbz	x8, .LBB47_75
// %bb.74:
	ldur	x0, [x8, #-8]
	add	sp, sp, #416
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	free
.LBB47_75:
	add	sp, sp, #416
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB47_76:
	ldp	x15, x12, [sp, #112]            // 16-byte Folded Reload
	mov	w10, #2
	mul	x8, x16, x24
	ldur	x13, [x29, #-200]               // 8-byte Folded Reload
	sub	x9, x16, #1
	ldr	x17, [sp, #208]                 // 8-byte Folded Reload
	lsl	x21, x27, #5
	cmp	x15, #2
	mul	x8, x8, x27
	csel	x10, x15, x10, hi
	add	x11, x12, x13, lsl #5
	mul	x9, x9, x17
	lsl	x13, x13, #5
	add	x26, x11, #48
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	add	x10, x11, #16
	add	x9, x14, x9, lsl #5
	stur	x10, [x29, #-168]               // 8-byte Folded Spill
	neg	x10, x13
	str	x13, [sp, #160]                 // 8-byte Folded Spill
	str	x10, [sp, #144]                 // 8-byte Folded Spill
	add	x10, x12, x8, lsl #5
	add	x8, x9, #16
	add	x23, x10, #48
	mov	w12, #1
	stur	x8, [x29, #-152]                // 8-byte Folded Spill
	mov	w8, #32
	sub	x8, x8, x21
	str	x8, [sp, #136]                  // 8-byte Folded Spill
	add	x8, x14, #16
	stur	x8, [x29, #-160]                // 8-byte Folded Spill
	sub	x8, x21, #32
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	stur	x10, [x29, #-176]               // 8-byte Folded Spill
	b	.LBB47_78
.LBB47_77:                              //   in Loop: Header=BB47_78 Depth=1
	ldp	x10, x9, [x29, #-176]           // 16-byte Folded Reload
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	ldr	x12, [sp, #176]                 // 8-byte Folded Reload
	ldur	x26, [x29, #-200]               // 8-byte Folded Reload
	add	x9, x9, x8
	add	x12, x12, #1
	add	x26, x26, x8
	stur	x9, [x29, #-168]                // 8-byte Folded Spill
	ldr	x9, [sp, #144]                  // 8-byte Folded Reload
	add	x10, x10, x9
	stur	x10, [x29, #-176]               // 8-byte Folded Spill
	ldp	x8, x10, [x29, #-160]           // 16-byte Folded Reload
	ldr	x11, [sp, #136]                 // 8-byte Folded Reload
	add	x10, x10, x11
	stur	x10, [x29, #-152]               // 8-byte Folded Spill
	ldr	x10, [sp, #112]                 // 8-byte Folded Reload
	add	x8, x8, x10
	stur	x8, [x29, #-160]                // 8-byte Folded Spill
	ldr	x23, [sp, #192]                 // 8-byte Folded Reload
	ldr	x8, [sp, #152]                  // 8-byte Folded Reload
	ldr	x16, [sp, #168]                 // 8-byte Folded Reload
	add	x23, x23, x9
	cmp	x12, x8
	b.eq	.LBB47_73
.LBB47_78:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB47_84 Depth 2
                                        //     Child Loop BB47_80 Depth 2
                                        //       Child Loop BB47_81 Depth 3
	sub	x8, x16, #1
	cmp	x27, #1
	stur	x26, [x29, #-200]               // 8-byte Folded Spill
	str	x23, [sp, #192]                 // 8-byte Folded Spill
	stp	x8, x12, [sp, #168]             // 16-byte Folded Spill
	b.ls	.LBB47_83
// %bb.79:                              //   in Loop: Header=BB47_78 Depth=1
	mul	x9, x12, x24
	mov	x20, xzr
	mul	x8, x16, x24
	stp	x8, x9, [x29, #-192]            // 16-byte Folded Spill
.LBB47_80:                              //   Parent Loop BB47_78 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB47_81 Depth 3
	ldp	x9, x8, [x29, #-192]            // 16-byte Folded Reload
	ldr	x10, [sp, #120]                 // 8-byte Folded Reload
	add	x9, x20, x9
	add	x8, x20, x8
	mul	x9, x9, x27
	mul	x8, x8, x27
	add	x27, x10, x9, lsl #5
	add	x19, x10, x8, lsl #5
	ldp	q1, q0, [x27]
	ldp	q2, q3, [x19]
	stp	q2, q1, [x29, #-96]             // 32-byte Folded Spill
	stp	q0, q3, [x29, #-64]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x19]
	ldp	q0, q1, [x29, #-96]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	ldp	x22, x25, [x29, #-160]          // 16-byte Folded Reload
	mov	x24, x23
	mov	x19, x26
	ldr	x28, [sp, #208]                 // 8-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	stp	q1, q0, [x27]
.LBB47_81:                              //   Parent Loop BB47_78 Depth=1
                                        //     Parent Loop BB47_80 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q0, [x19, #-16]
	stp	q0, q2, [x29, #-64]             // 32-byte Folded Spill
	ldp	q1, q0, [x24, #-16]
	stp	q1, q0, [x29, #-128]            // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-64]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q3, [x22, #-16]
	ldr	q0, [x22], #32
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	stp	q0, q3, [x29, #-128]            // 32-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-144]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-144]                // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-96]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-80]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q3, [x25, #-16]
	ldr	q1, [x25], #32
	ldur	q2, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q3, [x29, #-96]             // 32-byte Folded Spill
	stp	q2, q0, [x19, #-16]
	mov	v0.16b, v1.16b
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-80]             // 32-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-48]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-96]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-64]                 // 16-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	subs	x28, x28, #1
	add	x19, x19, #32
	stp	q1, q0, [x24, #-16]
	add	x24, x24, #32
	b.ne	.LBB47_81
// %bb.82:                              //   in Loop: Header=BB47_80 Depth=2
	ldr	x24, [sp, #128]                 // 8-byte Folded Reload
	add	x20, x20, #1
	add	x26, x26, x21
	add	x23, x23, x21
	ldr	x27, [sp, #200]                 // 8-byte Folded Reload
	cmp	x20, x24
	b.ne	.LBB47_80
	b	.LBB47_77
.LBB47_83:                              //   in Loop: Header=BB47_78 Depth=1
	mov	x19, xzr
	mov	x20, x24
.LBB47_84:                              //   Parent Loop BB47_78 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldur	x8, [x29, #-168]                // 8-byte Folded Reload
	add	x22, x8, x19
	ldur	x8, [x29, #-176]                // 8-byte Folded Reload
	add	x23, x8, x19
	ldp	q2, q3, [x22, #-16]
	ldp	q1, q0, [x23]
	stp	q2, q1, [x29, #-96]             // 32-byte Folded Spill
	stp	q0, q3, [x29, #-64]             // 32-byte Folded Spill
	mov	v0.16b, v2.16b
	bl	__addtf3
	stur	q0, [x29, #-112]                // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__addtf3
	ldur	q1, [x29, #-112]                // 16-byte Folded Reload
	stp	q1, q0, [x22, #-16]
	ldp	q0, q1, [x29, #-96]             // 32-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-80]                 // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-64]             // 32-byte Folded Reload
	bl	__subtf3
	subs	x20, x20, #1
	add	x19, x19, x21
	ldur	q1, [x29, #-80]                 // 16-byte Folded Reload
	stp	q1, q0, [x23]
	b.ne	.LBB47_84
	b	.LBB47_77
.LBB47_85:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end47:
	.size	_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_, .Lfunc_end47-_ZNK9pocketfft6detail5cfftpIeE5passgILb0ENS0_5cmplxIeEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail11pocketfft_cIeED2Ev,"axG",@progbits,_ZN9pocketfft6detail11pocketfft_cIeED2Ev,comdat
	.weak	_ZN9pocketfft6detail11pocketfft_cIeED2Ev // -- Begin function _ZN9pocketfft6detail11pocketfft_cIeED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail11pocketfft_cIeED2Ev,@function
_ZN9pocketfft6detail11pocketfft_cIeED2Ev: // @_ZN9pocketfft6detail11pocketfft_cIeED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0, #8]
	cbz	x20, .LBB48_8
// %bb.1:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB48_3
// %bb.2:
	ldur	x0, [x8, #-8]
	bl	free
.LBB48_3:
	ldr	x0, [x20, #40]
	cbz	x0, .LBB48_5
// %bb.4:
	bl	_ZdlPv
.LBB48_5:
	ldr	x8, [x20, #24]
	cbz	x8, .LBB48_7
// %bb.6:
	ldur	x0, [x8, #-8]
	bl	free
.LBB48_7:
	mov	x0, x20
	bl	_ZdlPv
.LBB48_8:
	ldr	x20, [x19]
	str	xzr, [x19, #8]
	cbz	x20, .LBB48_14
// %bb.9:
	ldr	x0, [x20, #24]
	cbz	x0, .LBB48_11
// %bb.10:
	bl	_ZdlPv
.LBB48_11:
	ldr	x8, [x20, #8]
	cbz	x8, .LBB48_13
// %bb.12:
	ldur	x0, [x8, #-8]
	bl	free
.LBB48_13:
	mov	x0, x20
	bl	_ZdlPv
.LBB48_14:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end48:
	.size	_ZN9pocketfft6detail11pocketfft_cIeED2Ev, .Lfunc_end48-_ZN9pocketfft6detail11pocketfft_cIeED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB49_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB49_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB49_4
	b	.LBB49_8
.LBB49_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB49_8
.LBB49_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB49_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB49_8
.LBB49_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB49_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB49_6
.LBB49_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end49:
	.size	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end49-_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIeEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,"axG",@progbits,_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,comdat
	.weak	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv // -- Begin function _ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
	.p2align	2
	.type	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,@function
_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv: // @_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.Lfunc_begin15:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception15
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	str	x23, [sp, #128]                 // 8-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	x8, [x0, #8]
	mov	x19, x0
	ldr	x8, [x8]
	lsl	x8, x8, #5
	cbz	x8, .LBB50_3
// %bb.1:
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB50_25
// %bb.2:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	b	.LBB50_4
.LBB50_3:
	mov	x22, xzr
.LBB50_4:
	ldp	x8, x2, [x19, #16]
	ldr	x9, [x19, #32]
	ldr	x10, [x19]
	ldr	x8, [x8]
	ldr	x9, [x9]
	cmp	x8, #0
	ldr	x3, [x9, x8, lsl #3]
	csel	x20, x10, x2, eq
.Ltmp248:
	add	x0, sp, #8
	mov	x1, x20
	bl	_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m
.Ltmp249:
.LBB50_5:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB50_13 Depth 2
                                        //     Child Loop BB50_19 Depth 2
	ldr	x8, [sp, #104]
	cbz	x8, .LBB50_20
// %bb.6:                               //   in Loop: Header=BB50_5 Depth=1
.Ltmp251:
	add	x0, sp, #8
	mov	w1, #1
	bl	_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm
.Ltmp252:
// %bb.7:                               //   in Loop: Header=BB50_5 Depth=1
	ldr	x8, [x19, #64]
	mov	x21, x22
	ldr	x23, [x19, #24]
	ldrb	w8, [x8]
	cbz	w8, .LBB50_10
// %bb.8:                               //   in Loop: Header=BB50_5 Depth=1
	ldr	x8, [sp, #88]
	mov	x21, x22
	cmp	x8, #32
	b.ne	.LBB50_10
// %bb.9:                               //   in Loop: Header=BB50_5 Depth=1
	ldr	x8, [sp, #80]
	ldr	x9, [x23, #48]
	add	x21, x9, x8
.LBB50_10:                              //   in Loop: Header=BB50_5 Depth=1
	ldp	x9, x10, [x19, #48]
	ldr	x13, [sp, #56]
	ldr	x14, [x20, #48]
	ldr	x8, [x19, #40]
	ldr	x0, [x9]
	ldr	q0, [x10]
	add	x9, x14, x13
	cmp	x9, x21
	b.eq	.LBB50_14
// %bb.11:                              //   in Loop: Header=BB50_5 Depth=1
	ldr	x9, [sp, #32]
	ldr	x10, [sp, #96]
	ldr	x11, [x9]
	ldr	x11, [x11, x10, lsl #3]
	cbz	x11, .LBB50_14
// %bb.12:                              //   in Loop: Header=BB50_5 Depth=1
	mov	x11, xzr
	ldr	x12, [sp, #64]
	add	x13, x14, x13
	mov	x14, x21
.LBB50_13:                              //   Parent Loop BB50_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q2, q1, [x13]
	add	x11, x11, #1
	add	x13, x13, x12
	stp	q2, q1, [x14], #32
	ldr	x15, [x9]
	ldr	x15, [x15, x10, lsl #3]
	cmp	x11, x15
	b.lo	.LBB50_13
.LBB50_14:                              //   in Loop: Header=BB50_5 Depth=1
	ldrb	w2, [x8]
.Ltmp254:
	mov	x1, x21
	bl	_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb
.Ltmp255:
// %bb.15:                              //   in Loop: Header=BB50_5 Depth=1
	ldr	x8, [sp, #80]
	ldr	x9, [x23, #48]
	add	x8, x9, x8
	cmp	x8, x21
	b.eq	.LBB50_5
// %bb.16:                              //   in Loop: Header=BB50_5 Depth=1
	ldr	x9, [sp, #40]
	ldr	x10, [sp, #96]
	ldr	x9, [x9]
	ldr	x9, [x9, x10, lsl #3]
	cbz	x9, .LBB50_5
// %bb.17:                              //   in Loop: Header=BB50_5 Depth=1
	ldp	q1, q0, [x21]
	stp	q1, q0, [x8]
	ldr	x8, [sp, #40]
	ldr	x9, [sp, #96]
	ldr	x8, [x8]
	ldr	x8, [x8, x9, lsl #3]
	cmp	x8, #2
	b.lo	.LBB50_5
// %bb.18:                              //   in Loop: Header=BB50_5 Depth=1
	add	x8, x21, #32
	mov	w9, #1
.LBB50_19:                              //   Parent Loop BB50_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	x10, x11, [sp, #80]
	ldr	x12, [x23, #48]
	ldp	q1, q0, [x8], #32
	madd	x10, x11, x9, x10
	add	x9, x9, #1
	add	x10, x12, x10
	stp	q1, q0, [x10]
	ldr	x10, [sp, #40]
	ldr	x11, [sp, #96]
	ldr	x10, [x10]
	ldr	x10, [x10, x11, lsl #3]
	cmp	x9, x10
	b.lo	.LBB50_19
	b	.LBB50_5
.LBB50_20:
	ldr	x0, [sp, #8]
	cbz	x0, .LBB50_22
// %bb.21:
	bl	_ZdlPv
.LBB50_22:
	cbz	x22, .LBB50_24
// %bb.23:
	ldur	x0, [x22, #-8]
	bl	free
.LBB50_24:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	ldr	x23, [sp, #128]                 // 8-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB50_25:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB50_26:
.Ltmp250:
	mov	x19, x0
	cbz	x22, .LBB50_31
	b	.LBB50_33
.LBB50_27:
.Ltmp256:
	b	.LBB50_29
.LBB50_28:
.Ltmp253:
.LBB50_29:
	mov	x19, x0
	ldr	x0, [sp, #8]
	cbnz	x0, .LBB50_32
// %bb.30:
	cbnz	x22, .LBB50_33
.LBB50_31:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB50_32:
	bl	_ZdlPv
	cbz	x22, .LBB50_31
.LBB50_33:
	ldur	x0, [x22, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end50:
	.size	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv, .Lfunc_end50-_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
	.cfi_endproc
	.section	.gcc_except_table._ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,"aG",@progbits,_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,comdat
	.p2align	2
GCC_except_table50:
.Lexception15:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end15-.Lcst_begin15
.Lcst_begin15:
	.uleb128 .Ltmp248-.Lfunc_begin15        // >> Call Site 1 <<
	.uleb128 .Ltmp249-.Ltmp248              //   Call between .Ltmp248 and .Ltmp249
	.uleb128 .Ltmp250-.Lfunc_begin15        //     jumps to .Ltmp250
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp251-.Lfunc_begin15        // >> Call Site 2 <<
	.uleb128 .Ltmp252-.Ltmp251              //   Call between .Ltmp251 and .Ltmp252
	.uleb128 .Ltmp253-.Lfunc_begin15        //     jumps to .Ltmp253
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp254-.Lfunc_begin15        // >> Call Site 3 <<
	.uleb128 .Ltmp255-.Ltmp254              //   Call between .Ltmp254 and .Ltmp255
	.uleb128 .Ltmp256-.Lfunc_begin15        //     jumps to .Ltmp256
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp255-.Lfunc_begin15        // >> Call Site 4 <<
	.uleb128 .Lfunc_end50-.Ltmp255          //   Call between .Ltmp255 and .Lfunc_end50
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end15:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE // -- Begin function _ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE,@function
_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE: // @_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE
.Lfunc_begin16:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception16
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	str	x23, [sp, #96]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	add	x19, x0, #136
	mov	x20, x0
	mov	x0, x19
	mov	x21, x1
	bl	pthread_mutex_lock
	cbnz	w0, .LBB51_23
// %bb.1:
	add	x8, x20, #208
	ldarb	w8, [x8]
	tbnz	w8, #0, .LBB51_24
// %bb.2:
	add	x1, x20, #216
	mov	w0, #1
	bl	__aarch64_ldadd8_acq_rel
	ldp	x8, x23, [x20, #184]
	cmp	x8, x23
	b.eq	.LBB51_6
// %bb.3:
	add	x22, x8, #136
.LBB51_4:                               // =>This Inner Loop Header: Depth=1
	sub	x1, x22, #32
	mov	w0, #1
	bl	__aarch64_swp1_acq_rel
	cbz	w0, .LBB51_13
// %bb.5:                               //   in Loop: Header=BB51_4 Depth=1
	add	x8, x22, #192
	add	x9, x22, #56
	mov	x22, x8
	cmp	x9, x23
	b.ne	.LBB51_4
.LBB51_6:
	mov	x8, x21
	stp	xzr, xzr, [sp]
	ldp	x22, x9, [x8, #16]!
	stp	xzr, x9, [sp, #16]
	cbz	x22, .LBB51_8
// %bb.7:
	ldr	q0, [x21]
	str	x22, [sp, #16]
	stp	xzr, xzr, [x8]
	str	q0, [sp]
.LBB51_8:
	add	x21, x20, #80
	mov	x0, x21
	bl	pthread_mutex_lock
	cbnz	w0, .LBB51_27
// %bb.9:
	add	x1, x20, #128
	mov	w0, #1
	bl	__aarch64_ldadd8_acq_rel
	ldr	x9, [x20, #64]
	ldr	x8, [x20, #48]
	sub	x9, x9, #32
	cmp	x8, x9
	b.eq	.LBB51_19
// %bb.10:
	stp	xzr, xzr, [x8]
	str	xzr, [x8, #16]
	ldp	x10, x9, [sp, #16]
	str	x9, [x8, #24]
	cbz	x10, .LBB51_12
// %bb.11:
	ldr	q0, [sp]
	mov	x9, sp
	str	q0, [x8]
	ldr	x10, [sp, #16]
	str	x10, [x8, #16]
	stp	xzr, xzr, [x9, #16]!
.LBB51_12:
	ldr	x8, [x20, #48]
	add	x8, x8, #32
	str	x8, [x20, #48]
	b	.LBB51_20
.LBB51_13:
	add	x1, x20, #216
	mov	x0, #-1
	bl	__aarch64_ldadd8_acq_rel
	sub	x20, x22, #80
	mov	x0, x20
	bl	pthread_mutex_lock
	cbnz	w0, .LBB51_29
// %bb.14:
	mov	x10, x21
	stp	xzr, xzr, [sp, #32]
	str	xzr, [sp, #48]
	ldp	x9, x8, [x10, #16]!
	cbz	x9, .LBB51_16
// %bb.15:
	ldr	q0, [x21]
	stp	xzr, xzr, [x10]
	str	q0, [sp, #32]
.LBB51_16:
	ldur	q0, [x22, #-24]
	ldr	q1, [sp, #32]
	str	q0, [sp, #32]
	ldur	x10, [x22, #-8]
	stur	q1, [x22, #-24]
	str	x10, [sp, #48]
	ldr	x11, [x22]
	stur	x9, [x22, #-8]
	str	x11, [sp, #56]
	str	x8, [x22]
	cbz	x10, .LBB51_18
// %bb.17:
.Ltmp266:
	add	x0, sp, #32
	add	x1, sp, #32
	mov	w2, #3
	blr	x10
.Ltmp267:
.LBB51_18:
	mov	x0, x20
	bl	pthread_mutex_unlock
	sub	x0, x22, #128
	bl	_ZNSt18condition_variable10notify_oneEv
	b	.LBB51_22
.LBB51_19:
.Ltmp272:
	mov	x1, sp
	mov	x0, x20
	bl	_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_
.Ltmp273:
.LBB51_20:
	mov	x0, x21
	bl	pthread_mutex_unlock
	ldr	x8, [sp, #16]
	cbz	x8, .LBB51_22
// %bb.21:
.Ltmp278:
	mov	x0, sp
	mov	x1, sp
	mov	w2, #3
	blr	x8
.Ltmp279:
.LBB51_22:
	mov	x0, x19
	bl	pthread_mutex_unlock
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldr	x23, [sp, #96]                  // 8-byte Folded Reload
	add	sp, sp, #144
	ret
.LBB51_23:
	bl	_ZSt20__throw_system_errori
.LBB51_24:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp257:
	adrp	x1, .L.str.12
	add	x1, x1, :lo12:.L.str.12
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp258:
// %bb.25:
.Ltmp260:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp261:
// %bb.26:
.LBB51_27:
.Ltmp269:
	bl	_ZSt20__throw_system_errori
.Ltmp270:
// %bb.28:
.LBB51_29:
.Ltmp263:
	bl	_ZSt20__throw_system_errori
.Ltmp264:
// %bb.30:
.LBB51_31:
.Ltmp268:
	bl	__clang_call_terminate
.LBB51_32:
.Ltmp274:
	mov	x20, x0
	mov	x0, x21
	bl	pthread_mutex_unlock
	ldr	x22, [sp, #16]
	b	.LBB51_38
.LBB51_33:
.Ltmp265:
	mov	x20, x0
	b	.LBB51_40
.LBB51_34:
.Ltmp280:
	bl	__clang_call_terminate
.LBB51_35:
.Ltmp262:
	mov	x20, x0
	b	.LBB51_40
.LBB51_36:
.Ltmp259:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
	b	.LBB51_40
.LBB51_37:
.Ltmp271:
	mov	x20, x0
.LBB51_38:
	cbz	x22, .LBB51_40
// %bb.39:
.Ltmp275:
	mov	x0, sp
	mov	x1, sp
	mov	w2, #3
	blr	x22
.Ltmp276:
.LBB51_40:
	mov	x0, x19
	bl	pthread_mutex_unlock
	mov	x0, x20
	bl	_Unwind_Resume
.LBB51_41:
.Ltmp277:
	bl	__clang_call_terminate
.Lfunc_end51:
	.size	_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE, .Lfunc_end51-_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE,"aG",@progbits,_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE,comdat
	.p2align	2
GCC_except_table51:
.Lexception16:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase1-.Lttbaseref1
.Lttbaseref1:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end16-.Lcst_begin16
.Lcst_begin16:
	.uleb128 .Lfunc_begin16-.Lfunc_begin16  // >> Call Site 1 <<
	.uleb128 .Ltmp266-.Lfunc_begin16        //   Call between .Lfunc_begin16 and .Ltmp266
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp266-.Lfunc_begin16        // >> Call Site 2 <<
	.uleb128 .Ltmp267-.Ltmp266              //   Call between .Ltmp266 and .Ltmp267
	.uleb128 .Ltmp268-.Lfunc_begin16        //     jumps to .Ltmp268
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp272-.Lfunc_begin16        // >> Call Site 3 <<
	.uleb128 .Ltmp273-.Ltmp272              //   Call between .Ltmp272 and .Ltmp273
	.uleb128 .Ltmp274-.Lfunc_begin16        //     jumps to .Ltmp274
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp278-.Lfunc_begin16        // >> Call Site 4 <<
	.uleb128 .Ltmp279-.Ltmp278              //   Call between .Ltmp278 and .Ltmp279
	.uleb128 .Ltmp280-.Lfunc_begin16        //     jumps to .Ltmp280
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp279-.Lfunc_begin16        // >> Call Site 5 <<
	.uleb128 .Ltmp257-.Ltmp279              //   Call between .Ltmp279 and .Ltmp257
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp257-.Lfunc_begin16        // >> Call Site 6 <<
	.uleb128 .Ltmp258-.Ltmp257              //   Call between .Ltmp257 and .Ltmp258
	.uleb128 .Ltmp259-.Lfunc_begin16        //     jumps to .Ltmp259
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp260-.Lfunc_begin16        // >> Call Site 7 <<
	.uleb128 .Ltmp261-.Ltmp260              //   Call between .Ltmp260 and .Ltmp261
	.uleb128 .Ltmp262-.Lfunc_begin16        //     jumps to .Ltmp262
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp269-.Lfunc_begin16        // >> Call Site 8 <<
	.uleb128 .Ltmp270-.Ltmp269              //   Call between .Ltmp269 and .Ltmp270
	.uleb128 .Ltmp271-.Lfunc_begin16        //     jumps to .Ltmp271
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp263-.Lfunc_begin16        // >> Call Site 9 <<
	.uleb128 .Ltmp264-.Ltmp263              //   Call between .Ltmp263 and .Ltmp264
	.uleb128 .Ltmp265-.Lfunc_begin16        //     jumps to .Ltmp265
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp264-.Lfunc_begin16        // >> Call Site 10 <<
	.uleb128 .Ltmp275-.Ltmp264              //   Call between .Ltmp264 and .Ltmp275
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp275-.Lfunc_begin16        // >> Call Site 11 <<
	.uleb128 .Ltmp276-.Ltmp275              //   Call between .Ltmp275 and .Ltmp276
	.uleb128 .Ltmp277-.Lfunc_begin16        //     jumps to .Ltmp277
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp276-.Lfunc_begin16        // >> Call Site 12 <<
	.uleb128 .Lfunc_end51-.Ltmp276          //   Call between .Ltmp276 and .Lfunc_end51
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end16:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase1:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m,"axG",@progbits,_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m,comdat
	.weak	_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m // -- Begin function _ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m
	.p2align	2
	.type	_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m,@function
_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m: // @_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m
.Lfunc_begin17:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception17
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x10, x9, [x1]
	mov	x8, #-7
	movk	x8, #32767, lsl #48
	sub	x24, x9, x10
	cmp	x24, x8
	b.hs	.LBB52_22
// %bb.1:
	mov	x20, x3
	mov	x23, x2
	mov	x22, x1
	mov	x19, x0
	stp	xzr, xzr, [x0]
	str	xzr, [x0, #16]
	cbz	x24, .LBB52_3
// %bb.2:
	mov	x0, x24
	asr	x25, x24, #3
	bl	_Znwm
	and	x2, x24, #0xfffffffffffffff8
	add	x24, x0, x25, lsl #3
	mov	w1, wzr
	mov	x21, x0
	str	x0, [x19]
	str	x24, [x19, #16]
	bl	memset
	b	.LBB52_4
.LBB52_3:
	mov	x21, xzr
	stp	xzr, xzr, [x19]
	str	xzr, [x19, #16]
.LBB52_4:
	stp	x22, x23, [x19, #24]
	lsl	x10, x20, #3
	ldr	x8, [x22, #24]
	str	xzr, [x19, #40]
	ldr	x9, [x23, #24]
	str	x24, [x19, #8]
	ldr	x11, [x8, x10]
	stp	x11, xzr, [x19, #56]
	ldr	x12, [x9, x10]
	ldp	x10, x11, [x22]
	stp	x12, x20, [x19, #80]
	cmp	x10, x11
	b.eq	.LBB52_7
// %bb.5:
	sub	x12, x11, x10
	sub	x12, x12, #8
	cmp	x12, #8
	b.hs	.LBB52_8
// %bb.6:
	mov	w13, #1
	mov	x12, x10
	b	.LBB52_11
.LBB52_7:
	mov	w13, #1
	b	.LBB52_12
.LBB52_8:
	lsr	x12, x12, #3
	add	x16, x10, #8
	add	x14, x12, #1
	mov	w13, #1
	and	x15, x14, #0x3ffffffffffffffe
	mov	w18, #1
	mov	x17, x15
	add	x12, x10, x15, lsl #3
.LBB52_9:                               // =>This Inner Loop Header: Depth=1
	ldp	x0, x1, [x16, #-8]
	add	x16, x16, #16
	subs	x17, x17, #2
	mul	x13, x0, x13
	mul	x18, x1, x18
	b.ne	.LBB52_9
// %bb.10:
	mul	x13, x18, x13
	cmp	x14, x15
	b.eq	.LBB52_12
.LBB52_11:                              // =>This Inner Loop Header: Depth=1
	ldr	x14, [x12], #8
	cmp	x12, x11
	mul	x13, x14, x13
	b.ne	.LBB52_11
.LBB52_12:
	ldr	x11, [x10, x20, lsl #3]
	mrs	x14, TPIDR_EL0
	add	x12, x14, :tprel_hi12:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	add	x12, x12, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	udiv	x11, x13, x11
	ldr	x12, [x12]
	cmp	x12, #1
	str	x11, [x19, #96]
	b.eq	.LBB52_21
// %bb.13:
	cbz	x12, .LBB52_23
// %bb.14:
	add	x13, x14, :tprel_hi12:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x13, x13, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	ldr	x15, [x13]
	cmp	x15, x12
	b.hs	.LBB52_25
// %bb.15:
	udiv	x16, x11, x12
	msub	x17, x16, x12, x11
	cmp	x15, x17
	cinc	x12, x16, lo
	subs	x18, x24, x21
	b.eq	.LBB52_20
// %bb.16:
	cmp	x15, x17
	asr	x18, x18, #3
	csel	x17, x15, x17, lo
	cmp	x18, #1
	madd	x15, x16, x15, x17
	mov	x13, xzr
	mov	x14, xzr
	csinc	x16, x18, xzr, hi
	b	.LBB52_18
.LBB52_17:                              //   in Loop: Header=BB52_18 Depth=1
	sub	x16, x16, #1
	sub	x20, x20, #1
	add	x10, x10, #8
	add	x21, x21, #8
	add	x8, x8, #8
	add	x9, x9, #8
	cbz	x16, .LBB52_20
.LBB52_18:                              // =>This Inner Loop Header: Depth=1
	cbz	x20, .LBB52_17
// %bb.19:                              //   in Loop: Header=BB52_18 Depth=1
	ldr	x17, [x10]
	ldr	x18, [x21]
	udiv	x11, x11, x17
	udiv	x17, x15, x11
	add	x18, x18, x17
	msub	x15, x17, x11, x15
	str	x18, [x21]
	ldr	x18, [x8]
	madd	x14, x18, x17, x14
	str	x14, [x19, #40]
	ldr	x18, [x9]
	madd	x13, x18, x17, x13
	str	x13, [x19, #64]
	b	.LBB52_17
.LBB52_20:
	str	x12, [x19, #96]
.LBB52_21:
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB52_22:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.LBB52_23:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp281:
	adrp	x1, .L.str.9
	add	x1, x1, :lo12:.L.str.9
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp282:
// %bb.24:
.Ltmp284:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp285:
	b	.LBB52_27
.LBB52_25:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp287:
	adrp	x1, .L.str.10
	add	x1, x1, :lo12:.L.str.10
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp288:
// %bb.26:
.Ltmp290:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp291:
.LBB52_27:
.LBB52_28:
.Ltmp292:
	b	.LBB52_31
.LBB52_29:
.Ltmp289:
	b	.LBB52_33
.LBB52_30:
.Ltmp286:
.LBB52_31:
	mov	x20, x0
	b	.LBB52_34
.LBB52_32:
.Ltmp283:
.LBB52_33:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
.LBB52_34:
	ldr	x0, [x19]
	cbz	x0, .LBB52_36
// %bb.35:
	bl	_ZdlPv
.LBB52_36:
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end52:
	.size	_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m, .Lfunc_end52-_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m,"aG",@progbits,_ZN9pocketfft6detail10multi_iterILm1EEC2ERKNS0_8arr_infoES5_m,comdat
	.p2align	2
GCC_except_table52:
.Lexception17:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end17-.Lcst_begin17
.Lcst_begin17:
	.uleb128 .Lfunc_begin17-.Lfunc_begin17  // >> Call Site 1 <<
	.uleb128 .Ltmp281-.Lfunc_begin17        //   Call between .Lfunc_begin17 and .Ltmp281
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp281-.Lfunc_begin17        // >> Call Site 2 <<
	.uleb128 .Ltmp282-.Ltmp281              //   Call between .Ltmp281 and .Ltmp282
	.uleb128 .Ltmp283-.Lfunc_begin17        //     jumps to .Ltmp283
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp284-.Lfunc_begin17        // >> Call Site 3 <<
	.uleb128 .Ltmp285-.Ltmp284              //   Call between .Ltmp284 and .Ltmp285
	.uleb128 .Ltmp286-.Lfunc_begin17        //     jumps to .Ltmp286
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp285-.Lfunc_begin17        // >> Call Site 4 <<
	.uleb128 .Ltmp287-.Ltmp285              //   Call between .Ltmp285 and .Ltmp287
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp287-.Lfunc_begin17        // >> Call Site 5 <<
	.uleb128 .Ltmp288-.Ltmp287              //   Call between .Ltmp287 and .Ltmp288
	.uleb128 .Ltmp289-.Lfunc_begin17        //     jumps to .Ltmp289
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp290-.Lfunc_begin17        // >> Call Site 6 <<
	.uleb128 .Ltmp291-.Ltmp290              //   Call between .Ltmp290 and .Ltmp291
	.uleb128 .Ltmp292-.Lfunc_begin17        //     jumps to .Ltmp292
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp291-.Lfunc_begin17        // >> Call Site 7 <<
	.uleb128 .Lfunc_end52-.Ltmp291          //   Call between .Ltmp291 and .Lfunc_end52
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end17:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10multi_iterILm1EE7advanceEm,"axG",@progbits,_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm,comdat
	.weak	_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm // -- Begin function _ZN9pocketfft6detail10multi_iterILm1EE7advanceEm
	.p2align	2
	.type	_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm,@function
_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm: // @_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm
.Lfunc_begin18:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception18
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x8, [x0, #96]
	cmp	x8, x1
	b.lo	.LBB53_13
// %bb.1:
	cbz	x1, .LBB53_12
// %bb.2:
	ldp	x8, x9, [x0]
	sub	x10, x9, x8
	lsr	x9, x10, #3
	cmp	w9, #0
	b.le	.LBB53_10
// %bb.3:
	ubfx	x10, x10, #3, #32
	mov	x9, xzr
	add	x10, x10, #1
	b	.LBB53_5
.LBB53_4:                               //   in Loop: Header=BB53_5 Depth=1
	add	x9, x9, #1
	cmp	x9, x1
	b.eq	.LBB53_12
.LBB53_5:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB53_8 Depth 2
	ldr	x11, [x0, #40]
	add	x12, x0, x9, lsl #3
	mov	x13, x10
	str	x11, [x12, #48]
	ldr	x11, [x0, #64]
	str	x11, [x12, #72]
	ldp	x11, x12, [x0, #24]
	b	.LBB53_8
.LBB53_6:                               //   in Loop: Header=BB53_8 Depth=2
	str	xzr, [x8, x14]
	ldr	x17, [x17, x14]
	ldr	x16, [x16, x14]
	ldr	x18, [x0, #40]
	msub	x16, x16, x17, x18
	ldr	x17, [x12]
	str	x16, [x0, #40]
	ldr	x16, [x17, x14]
	ldr	x14, [x15, x14]
	ldr	x15, [x0, #64]
	msub	x14, x14, x16, x15
	str	x14, [x0, #64]
.LBB53_7:                               //   in Loop: Header=BB53_8 Depth=2
	sub	x13, x13, #1
	cmp	x13, #1
	b.ls	.LBB53_4
.LBB53_8:                               //   Parent Loop BB53_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x15, [x0, #88]
	sub	w14, w13, #2
	cmp	x15, x14
	b.eq	.LBB53_7
// %bb.9:                               //   in Loop: Header=BB53_8 Depth=2
	lsl	x14, x14, #3
	ldr	x16, [x11, #24]
	ldr	x17, [x0, #40]
	ldr	x18, [x0, #64]
	ldr	x15, [x16, x14]
	add	x17, x17, x15
	ldr	x15, [x12, #24]
	str	x17, [x0, #40]
	ldr	x17, [x15, x14]
	add	x17, x18, x17
	str	x17, [x0, #64]
	ldr	x17, [x8, x14]
	add	x18, x17, #1
	ldr	x17, [x11]
	str	x18, [x8, x14]
	ldr	x2, [x17, x14]
	cmp	x18, x2
	b.hs	.LBB53_6
	b	.LBB53_4
.LBB53_10:
	add	x8, x0, #48
	mov	x9, x1
.LBB53_11:                              // =>This Inner Loop Header: Depth=1
	ldr	x10, [x0, #40]
	subs	x9, x9, #1
	str	x10, [x8]
	ldr	x10, [x0, #64]
	str	x10, [x8, #24]
	add	x8, x8, #8
	b.ne	.LBB53_11
.LBB53_12:
	ldr	x8, [x0, #96]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	sub	x8, x8, x1
	str	x8, [x0, #96]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB53_13:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x19, x0
.Ltmp293:
	adrp	x1, .L.str.11
	add	x1, x1, :lo12:.L.str.11
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp294:
// %bb.14:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x19
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.LBB53_15:
.Ltmp295:
	mov	x20, x0
	mov	x0, x19
	bl	__cxa_free_exception
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end53:
	.size	_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm, .Lfunc_end53-_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10multi_iterILm1EE7advanceEm,"aG",@progbits,_ZN9pocketfft6detail10multi_iterILm1EE7advanceEm,comdat
	.p2align	2
GCC_except_table53:
.Lexception18:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end18-.Lcst_begin18
.Lcst_begin18:
	.uleb128 .Lfunc_begin18-.Lfunc_begin18  // >> Call Site 1 <<
	.uleb128 .Ltmp293-.Lfunc_begin18        //   Call between .Lfunc_begin18 and .Ltmp293
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp293-.Lfunc_begin18        // >> Call Site 2 <<
	.uleb128 .Ltmp294-.Ltmp293              //   Call between .Ltmp293 and .Ltmp294
	.uleb128 .Ltmp295-.Lfunc_begin18        //     jumps to .Ltmp295
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp294-.Lfunc_begin18        // >> Call Site 3 <<
	.uleb128 .Lfunc_end53-.Ltmp294          //   Call between .Ltmp294 and .Lfunc_end53
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end18:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb,"axG",@progbits,_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb,comdat
	.weak	_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb // -- Begin function _ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb
	.p2align	2
	.type	_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb,@function
_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb: // @_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	ldr	x0, [x0]
	cbz	x0, .LBB54_3
// %bb.1:
	tbz	w2, #0, .LBB54_5
// %bb.2:
	b	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
.LBB54_3:
	ldr	x0, [x8, #8]
	tbz	w2, #0, .LBB54_6
// %bb.4:
	b	_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe
.LBB54_5:
	b	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
.LBB54_6:
	b	_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe
.Lfunc_end54:
	.size	_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb, .Lfunc_end54-_ZNK9pocketfft6detail11pocketfft_cIeE4execIeEEvPNS0_5cmplxIT_EEeb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe
.LCPI55_0:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
.LCPI55_1:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
	.section	.text._ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe,@function
_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe: // @_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe
.Lfunc_begin19:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception19
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x26, x25, [sp, #128]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	x19, x0
	ldr	x23, [x0, #8]
	mov	x20, x1
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	cbz	x23, .LBB55_6
// %bb.1:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB55_22
// %bb.2:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	ldr	x8, [x19]
	cbz	x8, .LBB55_7
.LBB55_3:
	mov	x23, xzr
	mov	x24, xzr
.LBB55_4:                               // =>This Inner Loop Header: Depth=1
	add	x9, x20, x23
	ldr	x8, [x19, #80]
	ldp	q0, q2, [x9]
	add	x8, x8, x23
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	str	q2, [sp, #48]                   // 16-byte Folded Spill
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q0, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	add	x8, x21, x23
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	add	x24, x24, #1
	add	x23, x23, #32
	stp	q1, q0, [x8]
	ldr	x22, [x19]
	cmp	x24, x22
	b.lo	.LBB55_4
// %bb.5:
	ldr	x23, [x19, #8]
	b	.LBB55_8
.LBB55_6:
	mov	x21, xzr
	ldr	x8, [x19]
	cbnz	x8, .LBB55_3
.LBB55_7:
	mov	x22, xzr
.LBB55_8:
	adrp	x8, .LCPI55_0
	ldr	q0, [x21]
	ldr	q1, [x8, :lo12:.LCPI55_0]
	stur	q1, [x29, #-16]                 // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x21, #16]
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	cmp	x22, x23
	b.hs	.LBB55_11
// %bb.9:
	add	x8, x21, x22, lsl #5
	add	x8, x8, #16
.LBB55_10:                              // =>This Inner Loop Header: Depth=1
	stp	q1, q0, [x8, #-16]
	add	x22, x22, #1
	ldr	x9, [x19, #8]
	add	x8, x8, #32
	cmp	x22, x9
	b.lo	.LBB55_10
.LBB55_11:
	add	x22, x19, #16
.Ltmp296:
	adrp	x8, .LCPI55_1
	mov	x0, x22
	mov	x1, x21
	ldr	q0, [x8, :lo12:.LCPI55_1]
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
.Ltmp297:
// %bb.12:
	ldp	q0, q1, [x21]
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	x8, [x19, #88]
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	ldr	q0, [x8]
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	stp	q1, q0, [x21]
	ldr	x8, [x19, #8]
	sub	x9, x8, #3
	cmn	x9, #5
	b.hi	.LBB55_15
// %bb.13:
	mov	x23, xzr
	mov	x24, #-1
	mov	w25, #1
.LBB55_14:                              // =>This Inner Loop Header: Depth=1
	add	x26, x21, x23
	ldr	x8, [x19, #88]
	ldp	q0, q1, [x26, #32]
	add	x8, x8, x23
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	q0, [x8, #32]
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x8, #48]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	stp	q1, q0, [x26, #32]
	ldr	x8, [x19, #8]
	ldr	x9, [x19, #88]
	add	x8, x24, x8
	add	x26, x21, x8, lsl #5
	add	x8, x9, x23
	ldp	q0, q1, [x26]
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	q0, [x8, #32]
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x8, #48]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	add	x25, x25, #1
	sub	x24, x24, #1
	add	x23, x23, #32
	stp	q1, q0, [x26]
	ldr	x8, [x19, #8]
	add	x9, x8, #1
	cmp	x25, x9, lsr #1
	b.lo	.LBB55_14
.LBB55_15:
	tbnz	w8, #0, .LBB55_17
// %bb.16:
	lsl	x8, x8, #4
	ldr	x9, [x19, #88]
	and	x8, x8, #0xffffffffffffffe0
	add	x23, x21, x8
	add	x8, x9, x8
	ldp	q0, q1, [x23]
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	q0, [x8]
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	stp	q1, q0, [x23]
.LBB55_17:
.Ltmp298:
	mov	x0, x22
	mov	x1, x21
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
.Ltmp299:
// %bb.18:
	ldr	x8, [x19]
	cbz	x8, .LBB55_21
// %bb.19:
	mov	x22, xzr
	mov	x23, xzr
.LBB55_20:                              // =>This Inner Loop Header: Depth=1
	add	x9, x21, x22
	ldr	x8, [x19, #80]
	ldp	q0, q2, [x9]
	add	x8, x8, x22
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	str	q2, [sp, #48]                   // 16-byte Folded Spill
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q0, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	ldr	q0, [sp, #32]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	add	x8, x20, x22
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	add	x23, x23, #1
	add	x22, x22, #32
	stp	q1, q0, [x8]
	ldr	x8, [x19]
	cmp	x23, x8
	b.lo	.LBB55_20
.LBB55_21:
	ldur	x0, [x21, #-8]
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #192
	b	free
.LBB55_22:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB55_23:
.Ltmp300:
	mov	x19, x0
	ldur	x0, [x21, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end55:
	.size	_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe, .Lfunc_end55-_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIeE3fftILb1EeEEvPNS0_5cmplxIT0_EEe,comdat
	.p2align	2
GCC_except_table55:
.Lexception19:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end19-.Lcst_begin19
.Lcst_begin19:
	.uleb128 .Lfunc_begin19-.Lfunc_begin19  // >> Call Site 1 <<
	.uleb128 .Ltmp296-.Lfunc_begin19        //   Call between .Lfunc_begin19 and .Ltmp296
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp296-.Lfunc_begin19        // >> Call Site 2 <<
	.uleb128 .Ltmp297-.Ltmp296              //   Call between .Ltmp296 and .Ltmp297
	.uleb128 .Ltmp300-.Lfunc_begin19        //     jumps to .Ltmp300
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp297-.Lfunc_begin19        // >> Call Site 3 <<
	.uleb128 .Ltmp298-.Ltmp297              //   Call between .Ltmp297 and .Ltmp298
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp298-.Lfunc_begin19        // >> Call Site 4 <<
	.uleb128 .Ltmp299-.Ltmp298              //   Call between .Ltmp298 and .Ltmp299
	.uleb128 .Ltmp300-.Lfunc_begin19        //     jumps to .Ltmp300
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp299-.Lfunc_begin19        // >> Call Site 5 <<
	.uleb128 .Lfunc_end55-.Ltmp299          //   Call between .Ltmp299 and .Lfunc_end55
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end19:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe
.LCPI56_0:
	.xword	0x0000000000000000              // fp128 0
	.xword	0x0000000000000000
.LCPI56_1:
	.xword	0x0000000000000000              // fp128 1
	.xword	0x3fff000000000000
	.section	.text._ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe,@function
_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe: // @_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe
.Lfunc_begin20:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception20
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x26, x25, [sp, #128]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	x19, x0
	ldr	x23, [x0, #8]
	mov	x20, x1
	stur	q0, [x29, #-48]                 // 16-byte Folded Spill
	cbz	x23, .LBB56_6
// %bb.1:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB56_22
// %bb.2:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	ldr	x8, [x19]
	cbz	x8, .LBB56_7
.LBB56_3:
	mov	x23, xzr
	mov	x24, xzr
.LBB56_4:                               // =>This Inner Loop Header: Depth=1
	add	x9, x20, x23
	ldr	x8, [x19, #80]
	ldp	q0, q1, [x9]
	add	x8, x8, x23
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	q0, [x8]
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	add	x8, x21, x23
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	add	x24, x24, #1
	add	x23, x23, #32
	stp	q1, q0, [x8]
	ldr	x22, [x19]
	cmp	x24, x22
	b.lo	.LBB56_4
// %bb.5:
	ldr	x23, [x19, #8]
	b	.LBB56_8
.LBB56_6:
	mov	x21, xzr
	ldr	x8, [x19]
	cbnz	x8, .LBB56_3
.LBB56_7:
	mov	x22, xzr
.LBB56_8:
	adrp	x8, .LCPI56_0
	ldr	q0, [x21]
	ldr	q1, [x8, :lo12:.LCPI56_0]
	stur	q1, [x29, #-16]                 // 16-byte Folded Spill
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x21, #16]
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	cmp	x22, x23
	b.hs	.LBB56_11
// %bb.9:
	add	x8, x21, x22, lsl #5
	add	x8, x8, #16
.LBB56_10:                              // =>This Inner Loop Header: Depth=1
	stp	q1, q0, [x8, #-16]
	add	x22, x22, #1
	ldr	x9, [x19, #8]
	add	x8, x8, #32
	cmp	x22, x9
	b.lo	.LBB56_10
.LBB56_11:
	add	x22, x19, #16
.Ltmp301:
	adrp	x8, .LCPI56_1
	mov	x0, x22
	mov	x1, x21
	ldr	q0, [x8, :lo12:.LCPI56_1]
	str	q0, [sp]                        // 16-byte Folded Spill
	bl	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb1ENS0_5cmplxIeEEEEvPT0_e
.Ltmp302:
// %bb.12:
	ldp	q0, q2, [x21]
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	x8, [x19, #88]
	str	q2, [sp, #48]                   // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q0, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	stp	q1, q0, [x21]
	ldr	x8, [x19, #8]
	sub	x9, x8, #3
	cmn	x9, #5
	b.hi	.LBB56_15
// %bb.13:
	mov	x23, xzr
	mov	x24, #-1
	mov	w25, #1
.LBB56_14:                              // =>This Inner Loop Header: Depth=1
	add	x26, x21, x23
	ldr	x8, [x19, #88]
	ldp	q0, q2, [x26, #32]
	add	x8, x8, x23
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q0, q1, [x8, #32]
	str	q2, [sp, #48]                   // 16-byte Folded Spill
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q0, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	stp	q1, q0, [x26, #32]
	ldr	x8, [x19, #8]
	ldr	x9, [x19, #88]
	add	x8, x24, x8
	add	x26, x21, x8, lsl #5
	add	x8, x9, x23
	ldp	q0, q2, [x26]
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q0, q1, [x8, #32]
	str	q2, [sp, #48]                   // 16-byte Folded Spill
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q0, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	add	x25, x25, #1
	sub	x24, x24, #1
	add	x23, x23, #32
	stp	q1, q0, [x26]
	ldr	x8, [x19, #8]
	add	x9, x8, #1
	cmp	x25, x9, lsr #1
	b.lo	.LBB56_14
.LBB56_15:
	tbnz	w8, #0, .LBB56_17
// %bb.16:
	lsl	x8, x8, #4
	ldr	x9, [x19, #88]
	and	x8, x8, #0xffffffffffffffe0
	add	x23, x21, x8
	add	x8, x9, x8
	ldp	q0, q2, [x23]
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldp	q0, q1, [x8]
	str	q2, [sp, #48]                   // 16-byte Folded Spill
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	mov	v0.16b, v2.16b
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q0, q1, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__addtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q0, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__subtf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	stp	q1, q0, [x23]
.LBB56_17:
.Ltmp303:
	mov	x0, x22
	mov	x1, x21
	ldr	q0, [sp]                        // 16-byte Folded Reload
	bl	_ZNK9pocketfft6detail5cfftpIeE8pass_allILb0ENS0_5cmplxIeEEEEvPT0_e
.Ltmp304:
// %bb.18:
	ldr	x8, [x19]
	cbz	x8, .LBB56_21
// %bb.19:
	mov	x22, xzr
	mov	x23, xzr
.LBB56_20:                              // =>This Inner Loop Header: Depth=1
	add	x9, x21, x22
	ldr	x8, [x19, #80]
	ldp	q0, q1, [x9]
	add	x8, x8, x22
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldr	q0, [x8]
	str	q1, [sp, #16]                   // 16-byte Folded Spill
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldr	q0, [x8, #16]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	bl	__multf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldp	q1, q0, [x29, #-32]             // 32-byte Folded Reload
	bl	__multf3
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	bl	__subtf3
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldur	q0, [x29, #-32]                 // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldr	q1, [sp, #48]                   // 16-byte Folded Reload
	bl	__multf3
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	bl	__addtf3
	stur	q0, [x29, #-16]                 // 16-byte Folded Spill
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	ldr	q0, [sp, #32]                   // 16-byte Folded Reload
	bl	__multf3
	stur	q0, [x29, #-32]                 // 16-byte Folded Spill
	ldur	q0, [x29, #-16]                 // 16-byte Folded Reload
	ldur	q1, [x29, #-48]                 // 16-byte Folded Reload
	bl	__multf3
	add	x8, x20, x22
	ldur	q1, [x29, #-32]                 // 16-byte Folded Reload
	add	x23, x23, #1
	add	x22, x22, #32
	stp	q1, q0, [x8]
	ldr	x8, [x19]
	cmp	x23, x8
	b.lo	.LBB56_20
.LBB56_21:
	ldur	x0, [x21, #-8]
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #192
	b	free
.LBB56_22:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB56_23:
.Ltmp305:
	mov	x19, x0
	ldur	x0, [x21, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end56:
	.size	_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe, .Lfunc_end56-_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIeE3fftILb0EeEEvPNS0_5cmplxIT0_EEe,comdat
	.p2align	2
GCC_except_table56:
.Lexception20:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end20-.Lcst_begin20
.Lcst_begin20:
	.uleb128 .Lfunc_begin20-.Lfunc_begin20  // >> Call Site 1 <<
	.uleb128 .Ltmp301-.Lfunc_begin20        //   Call between .Lfunc_begin20 and .Ltmp301
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp301-.Lfunc_begin20        // >> Call Site 2 <<
	.uleb128 .Ltmp302-.Ltmp301              //   Call between .Ltmp301 and .Ltmp302
	.uleb128 .Ltmp305-.Lfunc_begin20        //     jumps to .Ltmp305
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp302-.Lfunc_begin20        // >> Call Site 3 <<
	.uleb128 .Ltmp303-.Ltmp302              //   Call between .Ltmp302 and .Ltmp303
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp303-.Lfunc_begin20        // >> Call Site 4 <<
	.uleb128 .Ltmp304-.Ltmp303              //   Call between .Ltmp303 and .Ltmp304
	.uleb128 .Ltmp305-.Lfunc_begin20        //     jumps to .Ltmp305
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp304-.Lfunc_begin20        // >> Call Site 5 <<
	.uleb128 .Lfunc_end56-.Ltmp304          //   Call between .Ltmp304 and .Lfunc_end56
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end20:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_poolC2Ev,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_poolC2Ev,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_poolC2Ev // -- Begin function _ZN9pocketfft6detail9threading11thread_poolC2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_poolC2Ev,@function
_ZN9pocketfft6detail9threading11thread_poolC2Ev: // @_ZN9pocketfft6detail9threading11thread_poolC2Ev
.Lfunc_begin21:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception21
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	adrp	x8, .L_MergedGlobals+8
	mov	x1, xzr
	movi	v0.2d, #0000000000000000
	mov	x19, x0
	ldr	x20, [x8, :lo12:.L_MergedGlobals+8]
	stp	q0, q0, [x0]
	stp	q0, q0, [x0, #32]
	str	q0, [x0, #64]
	bl	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm
	movi	v0.2d, #0000000000000000
	add	x21, x19, #184
	str	xzr, [x19, #112]
	str	xzr, [x19, #168]
	stp	q0, q0, [x19, #80]
	stur	q0, [x19, #136]
	movi	v0.2d, #0000000000000000
	stur	q0, [x19, #152]
.Ltmp306:
	add	x2, x29, #24
	mov	x0, x21
	mov	x1, x20
	bl	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_
.Ltmp307:
// %bb.1:
.Ltmp309:
	mov	x0, x19
	bl	_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv
.Ltmp310:
// %bb.2:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB57_3:
.Ltmp311:
	ldp	x22, x23, [x19, #184]
	mov	x20, x0
	cmp	x22, x23
	b.eq	.LBB57_9
.LBB57_4:                               // =>This Inner Loop Header: Depth=1
	ldr	x8, [x22, #128]
	cbz	x8, .LBB57_6
// %bb.5:                               //   in Loop: Header=BB57_4 Depth=1
	add	x0, x22, #112
.Ltmp312:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp313:
.LBB57_6:                               //   in Loop: Header=BB57_4 Depth=1
	add	x0, x22, #8
	bl	_ZNSt18condition_variableD1Ev
	ldr	x8, [x22], #192
	cbnz	x8, .LBB57_11
// %bb.7:                               //   in Loop: Header=BB57_4 Depth=1
	cmp	x22, x23
	b.ne	.LBB57_4
// %bb.8:
	ldr	x22, [x21]
.LBB57_9:
	cbz	x22, .LBB57_14
// %bb.10:
	ldur	x0, [x22, #-8]
	bl	free
	b	.LBB57_14
.LBB57_11:
	bl	_ZSt9terminatev
.LBB57_12:
.Ltmp314:
	bl	__clang_call_terminate
.LBB57_13:
.Ltmp308:
	mov	x20, x0
.LBB57_14:
	mov	x0, x19
	bl	_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end57:
	.size	_ZN9pocketfft6detail9threading11thread_poolC2Ev, .Lfunc_end57-_ZN9pocketfft6detail9threading11thread_poolC2Ev
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading11thread_poolC2Ev,"aG",@progbits,_ZN9pocketfft6detail9threading11thread_poolC2Ev,comdat
	.p2align	2
GCC_except_table57:
.Lexception21:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase2-.Lttbaseref2
.Lttbaseref2:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end21-.Lcst_begin21
.Lcst_begin21:
	.uleb128 .Lfunc_begin21-.Lfunc_begin21  // >> Call Site 1 <<
	.uleb128 .Ltmp306-.Lfunc_begin21        //   Call between .Lfunc_begin21 and .Ltmp306
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp306-.Lfunc_begin21        // >> Call Site 2 <<
	.uleb128 .Ltmp307-.Ltmp306              //   Call between .Ltmp306 and .Ltmp307
	.uleb128 .Ltmp308-.Lfunc_begin21        //     jumps to .Ltmp308
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp309-.Lfunc_begin21        // >> Call Site 3 <<
	.uleb128 .Ltmp310-.Ltmp309              //   Call between .Ltmp309 and .Ltmp310
	.uleb128 .Ltmp311-.Lfunc_begin21        //     jumps to .Ltmp311
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp312-.Lfunc_begin21        // >> Call Site 4 <<
	.uleb128 .Ltmp313-.Ltmp312              //   Call between .Ltmp312 and .Ltmp313
	.uleb128 .Ltmp314-.Lfunc_begin21        //     jumps to .Ltmp314
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp313-.Lfunc_begin21        // >> Call Site 5 <<
	.uleb128 .Lfunc_end57-.Ltmp313          //   Call between .Ltmp313 and .Lfunc_end57
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end21:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase2:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_poolD2Ev,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_poolD2Ev,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_poolD2Ev // -- Begin function _ZN9pocketfft6detail9threading11thread_poolD2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_poolD2Ev,@function
_ZN9pocketfft6detail9threading11thread_poolD2Ev: // @_ZN9pocketfft6detail9threading11thread_poolD2Ev
.Lfunc_begin22:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception22
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
.Ltmp315:
	bl	_ZN9pocketfft6detail9threading11thread_pool8shutdownEv
.Ltmp316:
// %bb.1:
	ldp	x20, x21, [x19, #184]
	cmp	x20, x21
	b.eq	.LBB58_7
.LBB58_2:                               // =>This Inner Loop Header: Depth=1
	ldr	x8, [x20, #128]
	cbz	x8, .LBB58_4
// %bb.3:                               //   in Loop: Header=BB58_2 Depth=1
	add	x0, x20, #112
.Ltmp318:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp319:
.LBB58_4:                               //   in Loop: Header=BB58_2 Depth=1
	add	x0, x20, #8
	bl	_ZNSt18condition_variableD1Ev
	ldr	x8, [x20], #192
	cbnz	x8, .LBB58_10
// %bb.5:                               //   in Loop: Header=BB58_2 Depth=1
	cmp	x20, x21
	b.ne	.LBB58_2
// %bb.6:
	ldr	x20, [x19, #184]
.LBB58_7:
	cbz	x20, .LBB58_9
// %bb.8:
	ldur	x0, [x20, #-8]
	bl	free
.LBB58_9:
	mov	x0, x19
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	b	_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev
.LBB58_10:
	bl	_ZSt9terminatev
.LBB58_11:
.Ltmp317:
	mov	x20, x0
	add	x0, x19, #184
	bl	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev
	mov	x0, x19
	bl	_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev
	mov	x0, x20
	bl	__clang_call_terminate
.LBB58_12:
.Ltmp320:
	bl	__clang_call_terminate
.Lfunc_end58:
	.size	_ZN9pocketfft6detail9threading11thread_poolD2Ev, .Lfunc_end58-_ZN9pocketfft6detail9threading11thread_poolD2Ev
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading11thread_poolD2Ev,"aG",@progbits,_ZN9pocketfft6detail9threading11thread_poolD2Ev,comdat
	.p2align	2
GCC_except_table58:
.Lexception22:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase3-.Lttbaseref3
.Lttbaseref3:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end22-.Lcst_begin22
.Lcst_begin22:
	.uleb128 .Ltmp315-.Lfunc_begin22        // >> Call Site 1 <<
	.uleb128 .Ltmp316-.Ltmp315              //   Call between .Ltmp315 and .Ltmp316
	.uleb128 .Ltmp317-.Lfunc_begin22        //     jumps to .Ltmp317
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp318-.Lfunc_begin22        // >> Call Site 2 <<
	.uleb128 .Ltmp319-.Ltmp318              //   Call between .Ltmp318 and .Ltmp319
	.uleb128 .Ltmp320-.Lfunc_begin22        //     jumps to .Ltmp320
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp319-.Lfunc_begin22        // >> Call Site 3 <<
	.uleb128 .Lfunc_end58-.Ltmp319          //   Call between .Ltmp319 and .Lfunc_end58
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end22:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase3:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_,"axG",@progbits,_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_,comdat
	.weak	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_ // -- Begin function _ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_
	.p2align	2
	.type	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_,@function
_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_: // @_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x8, #-6148914691236517206
	movk	x8, #43691
	movk	x8, #170, lsl #48
	cmp	x1, x8
	b.hs	.LBB59_7
// %bb.1:
	mov	x20, x1
	mov	x19, x0
	stp	xzr, xzr, [x0]
	str	xzr, [x0, #16]
	cbz	x1, .LBB59_6
// %bb.2:
	mov	w8, #192
	orr	x9, xzr, #0x40
	madd	x0, x20, x8, x9
	bl	malloc
	cbz	x0, .LBB59_8
// %bb.3:
	add	x8, x0, #64
	mov	w9, #192
	and	x21, x8, #0xffffffffffffffc0
	madd	x8, x20, x9, x21
	stur	x0, [x21, #-8]
	stp	x21, x21, [x19]
	str	x8, [x19, #16]
.LBB59_4:                               // =>This Inner Loop Header: Depth=1
	movi	v0.2d, #0000000000000000
	add	x0, x21, #8
	stp	q0, q0, [x21, #160]
	stp	q0, q0, [x21, #128]
	stp	q0, q0, [x21, #96]
	stp	q0, q0, [x21, #64]
	stp	q0, q0, [x21, #32]
	stp	q0, q0, [x21]
	bl	_ZNSt18condition_variableC1Ev
	movi	v0.2d, #0000000000000000
	str	xzr, [x21, #88]
	strb	wzr, [x21, #104]
	subs	x20, x20, #1
	stur	q0, [x21, #72]
	stur	q0, [x21, #56]
	stp	q0, q0, [x21, #112]
	add	x21, x21, #192
	b.ne	.LBB59_4
// %bb.5:
	str	x21, [x19, #8]
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB59_6:
	mov	x21, xzr
	stp	xzr, xzr, [x19]
	stp	x21, xzr, [x19, #8]
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB59_7:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.LBB59_8:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end59:
	.size	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_, .Lfunc_end59-_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEEC2EmRKS6_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_pool14create_threadsEv,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv // -- Begin function _ZN9pocketfft6detail9threading11thread_pool14create_threadsEv
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv,@function
_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv: // @_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv
.Lfunc_begin23:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception23
// %bb.0:
	sub	sp, sp, #96
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x25, [sp, #32]                  // 8-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	add	x19, x0, #136
	mov	x20, x0
	mov	x0, x19
	bl	pthread_mutex_lock
	cbnz	w0, .LBB60_14
// %bb.1:
	ldp	x21, x8, [x20, #184]
	subs	x8, x8, x21
	b.eq	.LBB60_12
// %bb.2:
	mov	x9, #-6148914691236517206
	adrp	x24, _ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE+16
	movk	x9, #43691
	mov	x22, xzr
	movk	x9, #10922, lsl #48
	add	x24, x24, :lo12:_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE+16
	smulh	x8, x8, x9
	asr	x9, x8, #5
	add	x8, x9, x8, lsr #63
	cmp	x8, #1
	csinc	x8, x8, xzr, hi
	sub	x23, x8, #1
	add	x25, x21, x22
	add	x8, x25, #104
	stlrb	wzr, [x8]
	ldr	x8, [x25, #128]
	cbz	x8, .LBB60_5
.LBB60_3:
	add	x0, x25, #112
.Ltmp321:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp322:
// %bb.4:
	add	x8, x21, x22
	stp	xzr, xzr, [x8, #128]
.LBB60_5:                               // =>This Inner Loop Header: Depth=1
	str	xzr, [sp, #8]
.Ltmp324:
	mov	w0, #24
	bl	_Znwm
.Ltmp325:
// %bb.6:                               //   in Loop: Header=BB60_5 Depth=1
	stp	x24, x25, [x0]
	str	x20, [x0, #16]
	str	x0, [x29, #24]
.Ltmp327:
	add	x0, sp, #8
	add	x1, x29, #24
	mov	x2, xzr
	bl	_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE
.Ltmp328:
// %bb.7:                               //   in Loop: Header=BB60_5 Depth=1
	ldr	x0, [x29, #24]
	cbz	x0, .LBB60_9
// %bb.8:                               //   in Loop: Header=BB60_5 Depth=1
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
	blr	x8
.LBB60_9:                               //   in Loop: Header=BB60_5 Depth=1
	ldr	x8, [x21, x22]
	cbnz	x8, .LBB60_13
// %bb.10:                              //   in Loop: Header=BB60_5 Depth=1
	ldr	x8, [sp, #8]
	str	x8, [x21, x22]
	cbz	x23, .LBB60_12
// %bb.11:                              //   in Loop: Header=BB60_5 Depth=1
	ldr	x21, [x20, #184]
	sub	x23, x23, #1
	add	x22, x22, #192
	add	x25, x21, x22
	add	x8, x25, #104
	stlrb	wzr, [x8]
	ldr	x8, [x25, #128]
	cbnz	x8, .LBB60_3
	b	.LBB60_5
.LBB60_12:
	mov	x0, x19
	bl	pthread_mutex_unlock
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x25, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB60_13:
	bl	_ZSt9terminatev
.LBB60_14:
	bl	_ZSt20__throw_system_errori
.LBB60_15:
.Ltmp323:
	bl	__clang_call_terminate
.LBB60_16:
.Ltmp326:
	mov	x21, x0
	b	.LBB60_19
.LBB60_17:
.Ltmp329:
	ldr	x8, [x29, #24]
	mov	x21, x0
	cbz	x8, .LBB60_19
// %bb.18:
	ldr	x9, [x8]
	mov	x0, x8
	ldr	x9, [x9, #8]
	blr	x9
.LBB60_19:
	mov	x0, x21
	bl	__cxa_begin_catch
.Ltmp330:
	mov	x0, x20
	bl	_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv
.Ltmp331:
// %bb.20:
.Ltmp332:
	bl	__cxa_rethrow
.Ltmp333:
// %bb.21:
.LBB60_22:
.Ltmp334:
	mov	x20, x0
.Ltmp335:
	bl	__cxa_end_catch
.Ltmp336:
// %bb.23:
	mov	x0, x19
	bl	pthread_mutex_unlock
	mov	x0, x20
	bl	_Unwind_Resume
.LBB60_24:
.Ltmp337:
	bl	__clang_call_terminate
.Lfunc_end60:
	.size	_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv, .Lfunc_end60-_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading11thread_pool14create_threadsEv,"aG",@progbits,_ZN9pocketfft6detail9threading11thread_pool14create_threadsEv,comdat
	.p2align	2
GCC_except_table60:
.Lexception23:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase4-.Lttbaseref4
.Lttbaseref4:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end23-.Lcst_begin23
.Lcst_begin23:
	.uleb128 .Ltmp321-.Lfunc_begin23        // >> Call Site 1 <<
	.uleb128 .Ltmp322-.Ltmp321              //   Call between .Ltmp321 and .Ltmp322
	.uleb128 .Ltmp323-.Lfunc_begin23        //     jumps to .Ltmp323
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp324-.Lfunc_begin23        // >> Call Site 2 <<
	.uleb128 .Ltmp325-.Ltmp324              //   Call between .Ltmp324 and .Ltmp325
	.uleb128 .Ltmp326-.Lfunc_begin23        //     jumps to .Ltmp326
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp327-.Lfunc_begin23        // >> Call Site 3 <<
	.uleb128 .Ltmp328-.Ltmp327              //   Call between .Ltmp327 and .Ltmp328
	.uleb128 .Ltmp329-.Lfunc_begin23        //     jumps to .Ltmp329
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp328-.Lfunc_begin23        // >> Call Site 4 <<
	.uleb128 .Ltmp330-.Ltmp328              //   Call between .Ltmp328 and .Ltmp330
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp330-.Lfunc_begin23        // >> Call Site 5 <<
	.uleb128 .Ltmp333-.Ltmp330              //   Call between .Ltmp330 and .Ltmp333
	.uleb128 .Ltmp334-.Lfunc_begin23        //     jumps to .Ltmp334
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp335-.Lfunc_begin23        // >> Call Site 6 <<
	.uleb128 .Ltmp336-.Ltmp335              //   Call between .Ltmp335 and .Ltmp336
	.uleb128 .Ltmp337-.Lfunc_begin23        //     jumps to .Ltmp337
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp336-.Lfunc_begin23        // >> Call Site 7 <<
	.uleb128 .Lfunc_end60-.Ltmp336          //   Call between .Ltmp336 and .Lfunc_end60
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end23:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase4:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev,"axG",@progbits,_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev,comdat
	.weak	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev // -- Begin function _ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev
	.p2align	2
	.type	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev,@function
_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev: // @_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev
.Lfunc_begin24:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception24
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x20, x21, [x0]
	cmp	x20, x21
	b.eq	.LBB61_7
// %bb.1:
	mov	x19, x0
.LBB61_2:                               // =>This Inner Loop Header: Depth=1
	ldr	x8, [x20, #128]
	cbz	x8, .LBB61_4
// %bb.3:                               //   in Loop: Header=BB61_2 Depth=1
	add	x0, x20, #112
.Ltmp338:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp339:
.LBB61_4:                               //   in Loop: Header=BB61_2 Depth=1
	add	x0, x20, #8
	bl	_ZNSt18condition_variableD1Ev
	ldr	x8, [x20], #192
	cbnz	x8, .LBB61_10
// %bb.5:                               //   in Loop: Header=BB61_2 Depth=1
	cmp	x20, x21
	b.ne	.LBB61_2
// %bb.6:
	ldr	x20, [x19]
.LBB61_7:
	cbz	x20, .LBB61_9
// %bb.8:
	ldur	x0, [x20, #-8]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	b	free
.LBB61_9:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB61_10:
	bl	_ZSt9terminatev
.LBB61_11:
.Ltmp340:
	bl	__clang_call_terminate
.Lfunc_end61:
	.size	_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev, .Lfunc_end61-_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev
	.cfi_endproc
	.section	.gcc_except_table._ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev,"aG",@progbits,_ZNSt6vectorIN9pocketfft6detail9threading11thread_pool6workerENS2_17aligned_allocatorIS4_EEED2Ev,comdat
	.p2align	2
GCC_except_table61:
.Lexception24:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase5-.Lttbaseref5
.Lttbaseref5:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end24-.Lcst_begin24
.Lcst_begin24:
	.uleb128 .Ltmp338-.Lfunc_begin24        // >> Call Site 1 <<
	.uleb128 .Ltmp339-.Ltmp338              //   Call between .Ltmp338 and .Ltmp339
	.uleb128 .Ltmp340-.Lfunc_begin24        //     jumps to .Ltmp340
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp339-.Lfunc_begin24        // >> Call Site 2 <<
	.uleb128 .Lfunc_end61-.Ltmp339          //   Call between .Ltmp339 and .Lfunc_end61
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end24:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase5:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev,"axG",@progbits,_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev,comdat
	.weak	_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev // -- Begin function _ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev,@function
_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev: // @_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev
	.cfi_startproc
// %bb.0:
	b	_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev
.Lfunc_end62:
	.size	_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev, .Lfunc_end62-_ZN9pocketfft6detail9threading16concurrent_queueISt8functionIFvvEEED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm,"axG",@progbits,_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm,comdat
	.weak	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm // -- Begin function _ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm
	.p2align	2
	.type	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm,@function
_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm: // @_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm
.Lfunc_begin25:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception25
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	lsr	x8, x1, #4
	mov	w9, #5
	cmp	x8, #5
	mov	x11, #-3
	csel	x10, x8, x9, hi
	movk	x11, #4095, lsl #48
	add	x9, x10, #3
	cmp	x10, x11
	str	x9, [x0, #8]
	b.hs	.LBB63_5
// %bb.1:
	mov	x19, x0
	lsl	x0, x9, #3
	mov	x20, x1
	add	x22, x8, #1
	bl	_Znwm
	ldr	x8, [x19, #8]
	str	x0, [x19]
	sub	x8, x8, x22
	lsl	x8, x8, #2
	and	x8, x8, #0xfffffffffffffff8
	add	x21, x0, x8
	add	x23, x21, x22, lsl #3
	mov	x22, x21
.LBB63_2:                               // =>This Inner Loop Header: Depth=1
.Ltmp341:
	mov	w0, #512
	bl	_Znwm
.Ltmp342:
// %bb.3:                               //   in Loop: Header=BB63_2 Depth=1
	str	x0, [x22], #8
	cmp	x22, x23
	b.lo	.LBB63_2
// %bb.4:
	ldr	x8, [x21]
	and	x11, x20, #0xf
	ldr	x9, [x23, #-8]!
	add	x10, x8, #512
	stp	x8, x8, [x19, #16]
	add	x8, x9, #512
	stp	x10, x21, [x19, #32]
	add	x10, x9, x11, lsl #5
	stp	x8, x23, [x19, #64]
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	stp	x10, x9, [x19, #48]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB63_5:
	bl	_ZSt17__throw_bad_allocv
.LBB63_6:
.Ltmp343:
	bl	__cxa_begin_catch
	cmp	x22, x21
	b.ls	.LBB63_8
.LBB63_7:                               // =>This Inner Loop Header: Depth=1
	ldr	x0, [x21], #8
	bl	_ZdlPv
	cmp	x21, x22
	b.lo	.LBB63_7
.LBB63_8:
.Ltmp344:
	bl	__cxa_rethrow
.Ltmp345:
// %bb.9:
.LBB63_10:
.Ltmp346:
	mov	x20, x0
.Ltmp347:
	bl	__cxa_end_catch
.Ltmp348:
// %bb.11:
	mov	x0, x20
	bl	__cxa_begin_catch
	ldr	x0, [x19]
	bl	_ZdlPv
	stp	xzr, xzr, [x19]
.Ltmp350:
	bl	__cxa_rethrow
.Ltmp351:
// %bb.12:
.LBB63_13:
.Ltmp352:
	mov	x19, x0
.Ltmp353:
	bl	__cxa_end_catch
.Ltmp354:
// %bb.14:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB63_15:
.Ltmp355:
	bl	__clang_call_terminate
.LBB63_16:
.Ltmp349:
	bl	__clang_call_terminate
.Lfunc_end63:
	.size	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm, .Lfunc_end63-_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm
	.cfi_endproc
	.section	.gcc_except_table._ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm,"aG",@progbits,_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EE17_M_initialize_mapEm,comdat
	.p2align	2
GCC_except_table63:
.Lexception25:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase6-.Lttbaseref6
.Lttbaseref6:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end25-.Lcst_begin25
.Lcst_begin25:
	.uleb128 .Lfunc_begin25-.Lfunc_begin25  // >> Call Site 1 <<
	.uleb128 .Ltmp341-.Lfunc_begin25        //   Call between .Lfunc_begin25 and .Ltmp341
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp341-.Lfunc_begin25        // >> Call Site 2 <<
	.uleb128 .Ltmp342-.Ltmp341              //   Call between .Ltmp341 and .Ltmp342
	.uleb128 .Ltmp343-.Lfunc_begin25        //     jumps to .Ltmp343
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp342-.Lfunc_begin25        // >> Call Site 3 <<
	.uleb128 .Ltmp344-.Ltmp342              //   Call between .Ltmp342 and .Ltmp344
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp344-.Lfunc_begin25        // >> Call Site 4 <<
	.uleb128 .Ltmp345-.Ltmp344              //   Call between .Ltmp344 and .Ltmp345
	.uleb128 .Ltmp346-.Lfunc_begin25        //     jumps to .Ltmp346
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp347-.Lfunc_begin25        // >> Call Site 5 <<
	.uleb128 .Ltmp348-.Ltmp347              //   Call between .Ltmp347 and .Ltmp348
	.uleb128 .Ltmp349-.Lfunc_begin25        //     jumps to .Ltmp349
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp348-.Lfunc_begin25        // >> Call Site 6 <<
	.uleb128 .Ltmp350-.Ltmp348              //   Call between .Ltmp348 and .Ltmp350
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp350-.Lfunc_begin25        // >> Call Site 7 <<
	.uleb128 .Ltmp351-.Ltmp350              //   Call between .Ltmp350 and .Ltmp351
	.uleb128 .Ltmp352-.Lfunc_begin25        //     jumps to .Ltmp352
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp353-.Lfunc_begin25        // >> Call Site 8 <<
	.uleb128 .Ltmp354-.Ltmp353              //   Call between .Ltmp353 and .Ltmp354
	.uleb128 .Ltmp355-.Lfunc_begin25        //     jumps to .Ltmp355
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp354-.Lfunc_begin25        // >> Call Site 9 <<
	.uleb128 .Lfunc_end63-.Ltmp354          //   Call between .Ltmp354 and .Lfunc_end63
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end25:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase6:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv // -- Begin function _ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv,@function
_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv: // @_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	w8, #1
	add	x9, x0, #208
	stlrb	w8, [x9]
	ldp	x20, x21, [x0, #184]
	cmp	x20, x21
	b.eq	.LBB64_8
// %bb.1:
	mov	x19, x0
.LBB64_2:                               // =>This Inner Loop Header: Depth=1
	add	x0, x20, #8
	bl	_ZNSt18condition_variable10notify_allEv
	add	x20, x20, #192
	cmp	x20, x21
	b.ne	.LBB64_2
// %bb.3:
	ldp	x20, x19, [x19, #184]
	b	.LBB64_5
.LBB64_4:                               //   in Loop: Header=BB64_5 Depth=1
	add	x20, x20, #192
.LBB64_5:                               // =>This Inner Loop Header: Depth=1
	cmp	x20, x19
	b.eq	.LBB64_8
// %bb.6:                               //   in Loop: Header=BB64_5 Depth=1
	ldr	x8, [x20]
	cbz	x8, .LBB64_4
// %bb.7:                               //   in Loop: Header=BB64_5 Depth=1
	mov	x0, x20
	bl	_ZNSt6thread4joinEv
	b	.LBB64_4
.LBB64_8:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end64:
	.size	_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv, .Lfunc_end64-_ZN9pocketfft6detail9threading11thread_pool15shutdown_lockedEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev,"axG",@progbits,_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev,comdat
	.weak	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev // -- Begin function _ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev
	.p2align	2
	.type	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev,@function
_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev: // @_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	bl	_ZNSt6thread6_StateD2Ev
	mov	x0, x19
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	_ZdlPv
.Lfunc_end65:
	.size	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev, .Lfunc_end65-_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv,"axG",@progbits,_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv,comdat
	.weak	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv // -- Begin function _ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv
	.p2align	2
	.type	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv,@function
_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv: // @_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv
	.cfi_startproc
// %bb.0:
	ldp	x0, x3, [x0, #8]
	add	x1, x3, #208
	add	x2, x3, #216
	b	_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE
.Lfunc_end66:
	.size	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv, .Lfunc_end66-_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE // -- Begin function _ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE,@function
_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE: // @_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE
.Lfunc_begin26:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception26
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #96]             // 16-byte Folded Spill
	add	x29, sp, #96
	str	x27, [sp, #112]                 // 8-byte Folded Spill
	stp	x26, x25, [sp, #128]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	movi	v0.2d, #0000000000000000
	add	x23, x0, #56
	mov	x22, x0
	mov	x0, x23
	ldarb	wzr, [x1]
	mov	x19, x3
	mov	x20, x2
	mov	x21, x1
	stp	q0, q0, [sp]
	str	x23, [sp, #48]
	strb	wzr, [sp, #56]
	bl	pthread_mutex_lock
	cbnz	w0, .LBB67_46
// %bb.1:
	add	x24, x22, #8
	add	x26, x22, #112
	add	x25, x19, #80
	b	.LBB67_3
.LBB67_2:                               //   in Loop: Header=BB67_3 Depth=1
	mov	x0, x23
	str	x23, [sp, #48]
	strb	wzr, [sp, #56]
	bl	pthread_mutex_lock
	cbnz	w0, .LBB67_46
.LBB67_3:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB67_4 Depth 2
                                        //     Child Loop BB67_11 Depth 2
                                        //       Child Loop BB67_14 Depth 3
	mov	w9, #1
	ldr	x8, [x22, #128]
	strb	w9, [sp, #56]
	cbnz	x8, .LBB67_8
.LBB67_4:                               //   Parent Loop BB67_3 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldarb	w8, [x21]
	tbnz	w8, #0, .LBB67_6
// %bb.5:                               //   in Loop: Header=BB67_4 Depth=2
	add	x1, sp, #48
	mov	x0, x24
	bl	_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE
	ldr	x8, [x22, #128]
	cbz	x8, .LBB67_4
	b	.LBB67_7
.LBB67_6:                               //   in Loop: Header=BB67_3 Depth=1
	ldr	x8, [x22, #128]
.LBB67_7:                               //   in Loop: Header=BB67_3 Depth=1
	ldrb	w9, [sp, #56]
.LBB67_8:                               //   in Loop: Header=BB67_3 Depth=1
	ldp	x11, x12, [sp, #16]
	ldr	q0, [x26]
	ldr	q1, [sp]
	ldr	x10, [x22, #136]
	str	q0, [sp]
	str	q1, [x26]
	stp	x8, x10, [sp, #16]
	stp	x11, x12, [x22, #128]
	cbz	w9, .LBB67_11
// %bb.9:                               //   in Loop: Header=BB67_3 Depth=1
	ldr	x0, [sp, #48]
	cbz	x0, .LBB67_11
// %bb.10:                              //   in Loop: Header=BB67_3 Depth=1
	bl	pthread_mutex_unlock
.LBB67_11:                              //   Parent Loop BB67_3 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB67_14 Depth 3
	ldr	x8, [sp, #16]
	cbz	x8, .LBB67_31
// %bb.12:                              //   in Loop: Header=BB67_11 Depth=2
	ldr	x8, [sp, #24]
.Ltmp356:
	mov	x0, sp
	blr	x8
.Ltmp357:
// %bb.13:                              //   in Loop: Header=BB67_11 Depth=2
	add	x8, x19, #128
	ldar	x8, [x8]
	cbz	x8, .LBB67_34
.LBB67_14:                              //   Parent Loop BB67_3 Depth=1
                                        //     Parent Loop BB67_11 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x8, x19, #128
	ldar	x8, [x8]
	cbz	x8, .LBB67_34
// %bb.15:                              //   in Loop: Header=BB67_14 Depth=3
	mov	x0, x25
	bl	pthread_mutex_lock
	cbnz	w0, .LBB67_42
// %bb.16:                              //   in Loop: Header=BB67_14 Depth=3
	ldr	x8, [x19, #48]
	ldr	x10, [x19, #16]
	cmp	x8, x10
	b.eq	.LBB67_33
// %bb.17:                              //   in Loop: Header=BB67_14 Depth=3
	mov	x11, x10
	stp	xzr, xzr, [sp, #56]
	str	xzr, [sp, #48]
	ldp	x8, x9, [x11, #16]!
	cbz	x8, .LBB67_19
// %bb.18:                              //   in Loop: Header=BB67_14 Depth=3
	ldr	q0, [x10]
	stp	xzr, xzr, [x11]
	str	q0, [sp, #48]
.LBB67_19:                              //   in Loop: Header=BB67_14 Depth=3
	ldp	x10, x11, [sp, #16]
	stp	x8, x9, [sp, #16]
	ldr	q0, [sp]
	ldr	q1, [sp, #48]
	str	q0, [sp, #48]
	str	q1, [sp]
	stp	x10, x11, [sp, #64]
	cbz	x10, .LBB67_21
// %bb.20:                              //   in Loop: Header=BB67_14 Depth=3
.Ltmp361:
	add	x0, sp, #48
	add	x1, sp, #48
	mov	w2, #3
	blr	x10
.Ltmp362:
.LBB67_21:                              //   in Loop: Header=BB67_14 Depth=3
	add	x1, x19, #128
	mov	x0, #-1
	bl	__aarch64_ldadd8_acq_rel
	ldr	x0, [x19, #16]
	ldr	x8, [x19, #32]
	sub	x9, x8, #32
	ldr	x8, [x0, #16]
	cmp	x0, x9
	b.eq	.LBB67_26
// %bb.22:                              //   in Loop: Header=BB67_14 Depth=3
	cbz	x8, .LBB67_25
// %bb.23:                              //   in Loop: Header=BB67_14 Depth=3
.Ltmp364:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp365:
// %bb.24:                              //   in Loop: Header=BB67_14 Depth=3
	ldr	x0, [x19, #16]
.LBB67_25:                              //   in Loop: Header=BB67_14 Depth=3
	add	x8, x0, #32
	b	.LBB67_29
.LBB67_26:                              //   in Loop: Header=BB67_14 Depth=3
	cbz	x8, .LBB67_28
// %bb.27:                              //   in Loop: Header=BB67_14 Depth=3
.Ltmp367:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp368:
.LBB67_28:                              //   in Loop: Header=BB67_14 Depth=3
	ldr	x0, [x19, #24]
	bl	_ZdlPv
	ldr	x8, [x19, #40]
	add	x9, x8, #8
	str	x9, [x19, #40]
	ldr	x8, [x8, #8]
	add	x9, x8, #512
	stp	x8, x9, [x19, #24]
.LBB67_29:                              //   in Loop: Header=BB67_14 Depth=3
	mov	x0, x25
	str	x8, [x19, #16]
	bl	pthread_mutex_unlock
	mov	x0, #-1
	mov	x1, x20
	bl	__aarch64_ldadd8_acq_rel
	ldr	x8, [sp, #16]
	cbz	x8, .LBB67_44
// %bb.30:                              //   in Loop: Header=BB67_14 Depth=3
	ldr	x8, [sp, #24]
.Ltmp370:
	mov	x0, sp
	blr	x8
.Ltmp371:
	b	.LBB67_14
.LBB67_31:                              //   in Loop: Header=BB67_11 Depth=2
	add	x8, x19, #128
	ldar	x8, [x8]
	cbz	x8, .LBB67_40
// %bb.32:                              //   in Loop: Header=BB67_11 Depth=2
	add	x1, x22, #104
	mov	w0, #1
	mov	w27, #1
	bl	__aarch64_swp1_acq_rel
	cbnz	w0, .LBB67_35
	b	.LBB67_14
.LBB67_33:                              //   in Loop: Header=BB67_11 Depth=2
	mov	x0, x25
	bl	pthread_mutex_unlock
.LBB67_34:                              //   in Loop: Header=BB67_11 Depth=2
	add	x8, x22, #104
	mov	w27, wzr
	stlrb	wzr, [x8]
.LBB67_35:                              //   in Loop: Header=BB67_11 Depth=2
	ldr	x8, [sp, #16]
	cbz	x8, .LBB67_37
.LBB67_36:                              //   in Loop: Header=BB67_11 Depth=2
.Ltmp376:
	mov	x0, sp
	mov	x1, sp
	mov	w2, #3
	blr	x8
.Ltmp377:
.LBB67_37:                              //   in Loop: Header=BB67_11 Depth=2
	ldarb	w8, [x21]
	tst	w8, #0x1
	cset	w8, eq
	orr	w8, w27, w8
	tbz	w8, #0, .LBB67_41
// %bb.38:                              //   in Loop: Header=BB67_11 Depth=2
	movi	v0.2d, #0000000000000000
	stp	q0, q0, [sp]
	tbnz	w27, #0, .LBB67_2
// %bb.39:                              //   in Loop: Header=BB67_11 Depth=2
	ldar	x8, [x20]
	cbnz	x8, .LBB67_11
	b	.LBB67_2
.LBB67_40:                              //   in Loop: Header=BB67_11 Depth=2
	mov	w27, wzr
	ldr	x8, [sp, #16]
	cbnz	x8, .LBB67_36
	b	.LBB67_37
.LBB67_41:
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #96]             // 16-byte Folded Reload
	ldr	x27, [sp, #112]                 // 8-byte Folded Reload
	add	sp, sp, #192
	ret
.LBB67_42:
.Ltmp359:
	bl	_ZSt20__throw_system_errori
.Ltmp360:
// %bb.43:
.LBB67_44:
.Ltmp373:
	bl	_ZSt25__throw_bad_function_callv
.Ltmp374:
// %bb.45:
.LBB67_46:
.Ltmp379:
	bl	_ZSt20__throw_system_errori
.Ltmp380:
// %bb.47:
.LBB67_48:
.Ltmp381:
	b	.LBB67_56
.LBB67_49:
.Ltmp378:
	bl	__clang_call_terminate
.LBB67_50:
.Ltmp358:
	b	.LBB67_56
.LBB67_51:
.Ltmp369:
	bl	__clang_call_terminate
.LBB67_52:
.Ltmp366:
	bl	__clang_call_terminate
.LBB67_53:
.Ltmp363:
	bl	__clang_call_terminate
.LBB67_54:
.Ltmp372:
	b	.LBB67_56
.LBB67_55:
.Ltmp375:
.LBB67_56:
	mov	x19, x0
	ldr	x8, [sp, #16]
	cbz	x8, .LBB67_58
// %bb.57:
.Ltmp382:
	mov	x0, sp
	mov	x1, sp
	mov	w2, #3
	blr	x8
.Ltmp383:
.LBB67_58:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB67_59:
.Ltmp384:
	bl	__clang_call_terminate
.Lfunc_end67:
	.size	_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE, .Lfunc_end67-_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE,"aG",@progbits,_ZN9pocketfft6detail9threading11thread_pool6worker11worker_mainERSt6atomicIbERS4_ImERNS1_16concurrent_queueISt8functionIFvvEEEE,comdat
	.p2align	2
GCC_except_table67:
.Lexception26:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase7-.Lttbaseref7
.Lttbaseref7:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end26-.Lcst_begin26
.Lcst_begin26:
	.uleb128 .Ltmp356-.Lfunc_begin26        // >> Call Site 1 <<
	.uleb128 .Ltmp357-.Ltmp356              //   Call between .Ltmp356 and .Ltmp357
	.uleb128 .Ltmp358-.Lfunc_begin26        //     jumps to .Ltmp358
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp361-.Lfunc_begin26        // >> Call Site 2 <<
	.uleb128 .Ltmp362-.Ltmp361              //   Call between .Ltmp361 and .Ltmp362
	.uleb128 .Ltmp363-.Lfunc_begin26        //     jumps to .Ltmp363
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp362-.Lfunc_begin26        // >> Call Site 3 <<
	.uleb128 .Ltmp364-.Ltmp362              //   Call between .Ltmp362 and .Ltmp364
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp364-.Lfunc_begin26        // >> Call Site 4 <<
	.uleb128 .Ltmp365-.Ltmp364              //   Call between .Ltmp364 and .Ltmp365
	.uleb128 .Ltmp366-.Lfunc_begin26        //     jumps to .Ltmp366
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp367-.Lfunc_begin26        // >> Call Site 5 <<
	.uleb128 .Ltmp368-.Ltmp367              //   Call between .Ltmp367 and .Ltmp368
	.uleb128 .Ltmp369-.Lfunc_begin26        //     jumps to .Ltmp369
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp368-.Lfunc_begin26        // >> Call Site 6 <<
	.uleb128 .Ltmp370-.Ltmp368              //   Call between .Ltmp368 and .Ltmp370
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp370-.Lfunc_begin26        // >> Call Site 7 <<
	.uleb128 .Ltmp371-.Ltmp370              //   Call between .Ltmp370 and .Ltmp371
	.uleb128 .Ltmp372-.Lfunc_begin26        //     jumps to .Ltmp372
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp371-.Lfunc_begin26        // >> Call Site 8 <<
	.uleb128 .Ltmp376-.Ltmp371              //   Call between .Ltmp371 and .Ltmp376
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp376-.Lfunc_begin26        // >> Call Site 9 <<
	.uleb128 .Ltmp377-.Ltmp376              //   Call between .Ltmp376 and .Ltmp377
	.uleb128 .Ltmp378-.Lfunc_begin26        //     jumps to .Ltmp378
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp359-.Lfunc_begin26        // >> Call Site 10 <<
	.uleb128 .Ltmp374-.Ltmp359              //   Call between .Ltmp359 and .Ltmp374
	.uleb128 .Ltmp375-.Lfunc_begin26        //     jumps to .Ltmp375
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp379-.Lfunc_begin26        // >> Call Site 11 <<
	.uleb128 .Ltmp380-.Ltmp379              //   Call between .Ltmp379 and .Ltmp380
	.uleb128 .Ltmp381-.Lfunc_begin26        //     jumps to .Ltmp381
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp382-.Lfunc_begin26        // >> Call Site 12 <<
	.uleb128 .Ltmp383-.Ltmp382              //   Call between .Ltmp382 and .Ltmp383
	.uleb128 .Ltmp384-.Lfunc_begin26        //     jumps to .Ltmp384
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp383-.Lfunc_begin26        // >> Call Site 13 <<
	.uleb128 .Lfunc_end67-.Ltmp383          //   Call between .Ltmp383 and .Lfunc_end67
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end26:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase7:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev,"axG",@progbits,_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev,comdat
	.weak	_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev // -- Begin function _ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev
	.p2align	2
	.type	_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev,@function
_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev: // @_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev
.Lfunc_begin27:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception27
// %bb.0:
	sub	sp, sp, #112
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	str	x21, [sp, #80]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x8, x9, [x0, #32]
	mov	x19, x0
	ldr	q0, [x0, #16]
	ldr	q1, [x0, #48]
	stp	x8, x9, [sp, #48]
	ldp	x8, x10, [x0, #64]
	str	q0, [sp, #32]
	str	q1, [sp]
	stp	x8, x10, [sp, #16]
.Ltmp385:
	add	x1, sp, #32
	mov	x2, sp
	bl	_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_
.Ltmp386:
// %bb.1:
	ldr	x0, [x19]
	cbz	x0, .LBB68_7
// %bb.2:
	ldr	x20, [x19, #72]
	ldr	x8, [x19, #40]
	add	x9, x20, #8
	cmp	x8, x9
	b.hs	.LBB68_6
// %bb.3:
	sub	x21, x8, #8
.LBB68_4:                               // =>This Inner Loop Header: Depth=1
	ldr	x0, [x21, #8]!
	bl	_ZdlPv
	cmp	x21, x20
	b.lo	.LBB68_4
// %bb.5:
	ldr	x0, [x19]
.LBB68_6:
	bl	_ZdlPv
.LBB68_7:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldr	x21, [sp, #80]                  // 8-byte Folded Reload
	add	sp, sp, #112
	ret
.LBB68_8:
.Ltmp387:
	mov	x20, x0
	mov	x0, x19
	bl	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev
	mov	x0, x20
	bl	__clang_call_terminate
.Lfunc_end68:
	.size	_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev, .Lfunc_end68-_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev
	.cfi_endproc
	.section	.gcc_except_table._ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev,"aG",@progbits,_ZNSt5dequeISt8functionIFvvEESaIS2_EED2Ev,comdat
	.p2align	2
GCC_except_table68:
.Lexception27:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase8-.Lttbaseref8
.Lttbaseref8:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end27-.Lcst_begin27
.Lcst_begin27:
	.uleb128 .Ltmp385-.Lfunc_begin27        // >> Call Site 1 <<
	.uleb128 .Ltmp386-.Ltmp385              //   Call between .Ltmp385 and .Ltmp386
	.uleb128 .Ltmp387-.Lfunc_begin27        //     jumps to .Ltmp387
	.byte	1                               //   On action: 1
.Lcst_end27:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase8:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev,"axG",@progbits,_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev,comdat
	.weak	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev // -- Begin function _ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev
	.p2align	2
	.type	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev,@function
_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev: // @_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	ldr	x0, [x0]
	cbz	x0, .LBB69_6
// %bb.1:
	ldr	x20, [x19, #72]
	ldr	x8, [x19, #40]
	add	x9, x20, #8
	cmp	x8, x9
	b.hs	.LBB69_5
// %bb.2:
	sub	x21, x8, #8
.LBB69_3:                               // =>This Inner Loop Header: Depth=1
	ldr	x0, [x21, #8]!
	bl	_ZdlPv
	cmp	x21, x20
	b.lo	.LBB69_3
// %bb.4:
	ldr	x0, [x19]
.LBB69_5:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	b	_ZdlPv
.LBB69_6:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end69:
	.size	_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev, .Lfunc_end69-_ZNSt11_Deque_baseISt8functionIFvvEESaIS2_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_,"axG",@progbits,_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_,comdat
	.weak	_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_ // -- Begin function _ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_
	.p2align	2
	.type	_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_,@function
_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_: // @_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_
.Lfunc_begin28:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception28
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldr	x9, [x1, #24]
	mov	x20, x1
	ldr	x8, [x2, #24]
	mov	x19, x2
	add	x22, x9, #8
	cmp	x22, x8
	b.lo	.LBB70_4
// %bb.1:
	ldr	x21, [x20]
	cmp	x9, x8
	b.eq	.LBB70_46
.LBB70_2:
	ldr	x20, [x20, #16]
	b	.LBB70_37
.LBB70_3:                               //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x19, #24]
	add	x22, x22, #8
	cmp	x22, x8
	b.hs	.LBB70_45
.LBB70_4:                               // =>This Inner Loop Header: Depth=1
	ldr	x21, [x22]
	ldr	x8, [x21, #16]
	cbz	x8, .LBB70_6
// %bb.5:                               //   in Loop: Header=BB70_4 Depth=1
.Ltmp388:
	mov	x0, x21
	mov	x1, x21
	mov	w2, #3
	blr	x8
.Ltmp389:
.LBB70_6:                               //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #48]
	cbz	x8, .LBB70_8
// %bb.7:                               //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #32
.Ltmp390:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp391:
.LBB70_8:                               //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #80]
	cbz	x8, .LBB70_10
// %bb.9:                               //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #64
.Ltmp392:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp393:
.LBB70_10:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #112]
	cbz	x8, .LBB70_12
// %bb.11:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #96
.Ltmp394:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp395:
.LBB70_12:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #144]
	cbz	x8, .LBB70_14
// %bb.13:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #128
.Ltmp396:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp397:
.LBB70_14:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #176]
	cbz	x8, .LBB70_16
// %bb.15:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #160
.Ltmp398:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp399:
.LBB70_16:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #208]
	cbz	x8, .LBB70_18
// %bb.17:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #192
.Ltmp400:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp401:
.LBB70_18:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #240]
	cbz	x8, .LBB70_20
// %bb.19:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #224
.Ltmp402:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp403:
.LBB70_20:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #272]
	cbz	x8, .LBB70_22
// %bb.21:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #256
.Ltmp404:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp405:
.LBB70_22:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #304]
	cbz	x8, .LBB70_24
// %bb.23:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #288
.Ltmp406:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp407:
.LBB70_24:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #336]
	cbz	x8, .LBB70_26
// %bb.25:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #320
.Ltmp408:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp409:
.LBB70_26:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #368]
	cbz	x8, .LBB70_28
// %bb.27:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #352
.Ltmp410:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp411:
.LBB70_28:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #400]
	cbz	x8, .LBB70_30
// %bb.29:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #384
.Ltmp412:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp413:
.LBB70_30:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #432]
	cbz	x8, .LBB70_32
// %bb.31:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #416
.Ltmp414:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp415:
.LBB70_32:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #464]
	cbz	x8, .LBB70_34
// %bb.33:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #448
.Ltmp416:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp417:
.LBB70_34:                              //   in Loop: Header=BB70_4 Depth=1
	ldr	x8, [x21, #496]
	cbz	x8, .LBB70_3
// %bb.35:                              //   in Loop: Header=BB70_4 Depth=1
	add	x0, x21, #480
.Ltmp418:
	mov	x1, x0
	mov	w2, #3
	blr	x8
.Ltmp419:
	b	.LBB70_3
.LBB70_36:                              //   in Loop: Header=BB70_37 Depth=1
	add	x21, x21, #32
.LBB70_37:                              // =>This Inner Loop Header: Depth=1
	cmp	x21, x20
	b.eq	.LBB70_40
// %bb.38:                              //   in Loop: Header=BB70_37 Depth=1
	ldr	x8, [x21, #16]
	cbz	x8, .LBB70_36
// %bb.39:                              //   in Loop: Header=BB70_37 Depth=1
.Ltmp421:
	mov	x0, x21
	mov	x1, x21
	mov	w2, #3
	blr	x8
.Ltmp422:
	b	.LBB70_36
.LBB70_40:
	ldp	x19, x20, [x19]
	b	.LBB70_42
.LBB70_41:                              //   in Loop: Header=BB70_42 Depth=1
	add	x20, x20, #32
.LBB70_42:                              // =>This Inner Loop Header: Depth=1
	cmp	x20, x19
	b.eq	.LBB70_51
// %bb.43:                              //   in Loop: Header=BB70_42 Depth=1
	ldr	x8, [x20, #16]
	cbz	x8, .LBB70_41
// %bb.44:                              //   in Loop: Header=BB70_42 Depth=1
.Ltmp424:
	mov	x0, x20
	mov	x1, x20
	mov	w2, #3
	blr	x8
.Ltmp425:
	b	.LBB70_41
.LBB70_45:
	ldr	x9, [x20, #24]
	ldr	x21, [x20]
	cmp	x9, x8
	b.ne	.LBB70_2
.LBB70_46:
	ldr	x19, [x19]
	b	.LBB70_48
.LBB70_47:                              //   in Loop: Header=BB70_48 Depth=1
	add	x21, x21, #32
.LBB70_48:                              // =>This Inner Loop Header: Depth=1
	cmp	x21, x19
	b.eq	.LBB70_51
// %bb.49:                              //   in Loop: Header=BB70_48 Depth=1
	ldr	x8, [x21, #16]
	cbz	x8, .LBB70_47
// %bb.50:                              //   in Loop: Header=BB70_48 Depth=1
.Ltmp427:
	mov	x0, x21
	mov	x1, x21
	mov	w2, #3
	blr	x8
.Ltmp428:
	b	.LBB70_47
.LBB70_51:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB70_52:
.Ltmp429:
	bl	__clang_call_terminate
.LBB70_53:
.Ltmp426:
	bl	__clang_call_terminate
.LBB70_54:
.Ltmp423:
	bl	__clang_call_terminate
.LBB70_55:
.Ltmp420:
	bl	__clang_call_terminate
.Lfunc_end70:
	.size	_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_, .Lfunc_end70-_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_
	.cfi_endproc
	.section	.gcc_except_table._ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_,"aG",@progbits,_ZNSt5dequeISt8functionIFvvEESaIS2_EE19_M_destroy_data_auxESt15_Deque_iteratorIS2_RS2_PS2_ES8_,comdat
	.p2align	2
GCC_except_table70:
.Lexception28:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase9-.Lttbaseref9
.Lttbaseref9:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end28-.Lcst_begin28
.Lcst_begin28:
	.uleb128 .Ltmp388-.Lfunc_begin28        // >> Call Site 1 <<
	.uleb128 .Ltmp419-.Ltmp388              //   Call between .Ltmp388 and .Ltmp419
	.uleb128 .Ltmp420-.Lfunc_begin28        //     jumps to .Ltmp420
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp421-.Lfunc_begin28        // >> Call Site 2 <<
	.uleb128 .Ltmp422-.Ltmp421              //   Call between .Ltmp421 and .Ltmp422
	.uleb128 .Ltmp423-.Lfunc_begin28        //     jumps to .Ltmp423
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp424-.Lfunc_begin28        // >> Call Site 3 <<
	.uleb128 .Ltmp425-.Ltmp424              //   Call between .Ltmp424 and .Ltmp425
	.uleb128 .Ltmp426-.Lfunc_begin28        //     jumps to .Ltmp426
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp427-.Lfunc_begin28        // >> Call Site 4 <<
	.uleb128 .Ltmp428-.Ltmp427              //   Call between .Ltmp427 and .Ltmp428
	.uleb128 .Ltmp429-.Lfunc_begin28        //     jumps to .Ltmp429
	.byte	1                               //   On action: 1
.Lcst_end28:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase9:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading11thread_pool8shutdownEv,"axG",@progbits,_ZN9pocketfft6detail9threading11thread_pool8shutdownEv,comdat
	.weak	_ZN9pocketfft6detail9threading11thread_pool8shutdownEv // -- Begin function _ZN9pocketfft6detail9threading11thread_pool8shutdownEv
	.p2align	2
	.type	_ZN9pocketfft6detail9threading11thread_pool8shutdownEv,@function
_ZN9pocketfft6detail9threading11thread_pool8shutdownEv: // @_ZN9pocketfft6detail9threading11thread_pool8shutdownEv
.Lfunc_begin29:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception29
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	add	x19, x0, #136
	mov	x20, x0
	mov	x0, x19
	bl	pthread_mutex_lock
	cbnz	w0, .LBB71_9
// %bb.1:
	add	x8, x20, #208
	mov	w9, #1
	stlrb	w9, [x8]
	ldp	x21, x22, [x20, #184]
	cmp	x21, x22
	b.eq	.LBB71_8
.LBB71_2:                               // =>This Inner Loop Header: Depth=1
	add	x0, x21, #8
	bl	_ZNSt18condition_variable10notify_allEv
	add	x21, x21, #192
	cmp	x21, x22
	b.ne	.LBB71_2
// %bb.3:
	ldp	x21, x20, [x20, #184]
	b	.LBB71_5
.LBB71_4:                               //   in Loop: Header=BB71_5 Depth=1
	add	x21, x21, #192
.LBB71_5:                               // =>This Inner Loop Header: Depth=1
	cmp	x21, x20
	b.eq	.LBB71_8
// %bb.6:                               //   in Loop: Header=BB71_5 Depth=1
	ldr	x8, [x21]
	cbz	x8, .LBB71_4
// %bb.7:                               //   in Loop: Header=BB71_5 Depth=1
.Ltmp430:
	mov	x0, x21
	bl	_ZNSt6thread4joinEv
.Ltmp431:
	b	.LBB71_4
.LBB71_8:
	mov	x0, x19
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	b	pthread_mutex_unlock
.LBB71_9:
	bl	_ZSt20__throw_system_errori
.LBB71_10:
.Ltmp432:
	mov	x20, x0
	mov	x0, x19
	bl	pthread_mutex_unlock
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end71:
	.size	_ZN9pocketfft6detail9threading11thread_pool8shutdownEv, .Lfunc_end71-_ZN9pocketfft6detail9threading11thread_pool8shutdownEv
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading11thread_pool8shutdownEv,"aG",@progbits,_ZN9pocketfft6detail9threading11thread_pool8shutdownEv,comdat
	.p2align	2
GCC_except_table71:
.Lexception29:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end29-.Lcst_begin29
.Lcst_begin29:
	.uleb128 .Ltmp430-.Lfunc_begin29        // >> Call Site 1 <<
	.uleb128 .Ltmp431-.Ltmp430              //   Call between .Ltmp430 and .Ltmp431
	.uleb128 .Ltmp432-.Lfunc_begin29        //     jumps to .Ltmp432
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp431-.Lfunc_begin29        // >> Call Site 2 <<
	.uleb128 .Lfunc_end71-.Ltmp431          //   Call between .Ltmp431 and .Lfunc_end71
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end29:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_,"axG",@progbits,_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_,comdat
	.weak	_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_ // -- Begin function _ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_
	.p2align	2
	.type	_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_,@function
_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_: // @_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldp	x10, x11, [x0, #40]
	mov	x9, #288230376151711743
	ldr	x8, [x0, #72]
	ldr	x12, [x0, #56]
	ldr	x13, [x0, #32]
	sub	x10, x8, x10
	cmp	x8, #0
	ldr	x14, [x0, #16]
	lsr	x10, x10, #3
	cset	w15, ne
	sub	x11, x11, x12
	sub	x10, x10, x15
	sub	x12, x13, x14
	lsl	x10, x10, #4
	add	x10, x10, x11, asr #5
	add	x10, x10, x12, asr #5
	cmp	x10, x9
	b.eq	.LBB72_6
// %bb.1:
	ldp	x9, x10, [x0]
	mov	x20, x1
	mov	x19, x0
	sub	x8, x8, x9
	sub	x8, x10, x8, asr #3
	cmp	x8, #1
	b.hi	.LBB72_3
// %bb.2:
	mov	x0, x19
	mov	w1, #1
	mov	w2, wzr
	bl	_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb
.LBB72_3:
	mov	w0, #512
	bl	_Znwm
	ldr	x8, [x19, #72]
	mov	x9, x20
	str	x0, [x8, #8]
	ldr	x8, [x19, #48]
	stp	xzr, xzr, [x8, #8]
	str	xzr, [x8]
	ldp	x10, x11, [x9, #16]!
	str	x11, [x8, #24]
	cbz	x10, .LBB72_5
// %bb.4:
	ldr	q0, [x20]
	str	q0, [x8]
	ldr	x10, [x20, #16]
	str	x10, [x8, #16]
	stp	xzr, xzr, [x9]
.LBB72_5:
	ldr	x8, [x19, #72]
	add	x9, x8, #8
	str	x9, [x19, #72]
	ldr	x8, [x8, #8]
	add	x9, x8, #512
	str	x8, [x19, #48]
	stp	x8, x9, [x19, #56]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB72_6:
	adrp	x0, .L.str.13
	add	x0, x0, :lo12:.L.str.13
	bl	_ZSt20__throw_length_errorPKc
.Lfunc_end72:
	.size	_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_, .Lfunc_end72-_ZNSt5dequeISt8functionIFvvEESaIS2_EE16_M_push_back_auxIJS2_EEEvDpOT_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb,"axG",@progbits,_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb,comdat
	.weak	_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb // -- Begin function _ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb
	.p2align	2
	.type	_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb,@function
_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb: // @_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	x20, x1
	ldr	x8, [x0, #72]
	ldr	x1, [x0, #40]
	mov	x19, x0
	ldr	x10, [x0, #8]
	mov	w21, w2
	sub	x9, x8, x1
	asr	x23, x9, #3
	add	x8, x23, #1
	add	x25, x8, x20
	cmp	x10, x25, lsl #1
	b.ls	.LBB73_4
// %bb.1:
	ldr	x11, [x19]
	sub	x10, x10, x25
	lsl	x10, x10, #2
	tst	w21, #0x1
	and	x10, x10, #0xfffffffffffffff8
	csel	x12, x20, xzr, ne
	add	x10, x11, x10
	add	x2, x9, #8
	add	x20, x10, x12, lsl #3
	cmp	x20, x1
	b.hs	.LBB73_8
// %bb.2:
	cbz	x2, .LBB73_11
// %bb.3:
	mov	x0, x20
	b	.LBB73_10
.LBB73_4:
	cmp	x10, x20
	csel	x8, x20, x10, lo
	add	x8, x10, x8
	add	x24, x8, #2
	lsr	x8, x24, #60
	cbnz	x8, .LBB73_12
// %bb.5:
	lsl	x0, x24, #3
	bl	_Znwm
	ldr	x1, [x19, #40]
	sub	x8, x24, x25
	ldr	x9, [x19, #72]
	lsl	x8, x8, #2
	tst	w21, #0x1
	and	x8, x8, #0xfffffffffffffff8
	csel	x10, x20, xzr, ne
	add	x8, x0, x8
	sub	x9, x9, x1
	mov	x22, x0
	add	x20, x8, x10, lsl #3
	adds	x2, x9, #8
	b.eq	.LBB73_7
// %bb.6:
	mov	x0, x20
	bl	memmove
.LBB73_7:
	ldr	x0, [x19]
	bl	_ZdlPv
	stp	x22, x24, [x19]
	b	.LBB73_11
.LBB73_8:
	cbz	x2, .LBB73_11
// %bb.9:
	add	x8, x20, x8, lsl #3
	sub	x0, x8, x2
.LBB73_10:
	bl	memmove
.LBB73_11:
	str	x20, [x19, #40]
	lsl	x9, x23, #3
	ldr	x8, [x20]
	add	x11, x20, x9
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	add	x10, x8, #512
	str	x11, [x19, #72]
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	stp	x8, x10, [x19, #24]
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
	ldr	x8, [x20, x9]
	add	x9, x8, #512
	stp	x8, x9, [x19, #56]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB73_12:
	lsr	x8, x24, #61
	cbz	x8, .LBB73_14
// %bb.13:
	bl	_ZSt28__throw_bad_array_new_lengthv
.LBB73_14:
	bl	_ZSt17__throw_bad_allocv
.Lfunc_end73:
	.size	_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb, .Lfunc_end73-_ZNSt5dequeISt8functionIFvvEESaIS2_EE17_M_reallocate_mapEmb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,"axG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,comdat
	.weak	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data // -- Begin function _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.p2align	2
	.type	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,@function
_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data: // @_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.cfi_startproc
// %bb.0:
	ldr	x0, [x0]
	b	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
.Lfunc_end74:
	.size	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data, .Lfunc_end74-_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,"axG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,comdat
	.weak	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation // -- Begin function _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.p2align	2
	.type	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,@function
_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation: // @_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	cmp	w2, #3
	b.hi	.LBB75_3
// %bb.1:
	adrp	x9, .LJTI75_0
	mov	w8, w2
	add	x9, x9, :lo12:.LJTI75_0
	mov	x19, x0
	adr	x10, .LBB75_2
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB75_2:
	adrp	x8, _ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	add	x8, x8, :lo12:_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	str	x8, [x19]
.LBB75_3:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB75_4:
	ldr	x8, [x1]
	str	x8, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB75_5:
	mov	w0, #48
	ldr	x20, [x1]
	bl	_Znwm
	ldp	q0, q1, [x20]
	ldr	q2, [x20, #32]
	stp	q0, q1, [x0]
	str	x0, [x19]
	str	q2, [x0, #32]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB75_6:
	ldr	x0, [x19]
	cbz	x0, .LBB75_3
// %bb.7:
	bl	_ZdlPv
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end75:
	.size	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation, .Lfunc_end75-_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.cfi_endproc
	.section	.rodata._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,"aG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,comdat
.LJTI75_0:
	.byte	(.LBB75_2-.LBB75_2)>>2
	.byte	(.LBB75_4-.LBB75_2)>>2
	.byte	(.LBB75_5-.LBB75_2)>>2
	.byte	(.LBB75_6-.LBB75_2)>>2
                                        // -- End function
	.section	.text._ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,"axG",@progbits,_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,comdat
	.weak	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv // -- Begin function _ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
	.p2align	2
	.type	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,@function
_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv: // @_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
.Lfunc_begin30:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception30
// %bb.0:
	sub	sp, sp, #48
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mrs	x8, TPIDR_EL0
	mov	x19, x0
	ldp	x10, x11, [x0, #32]
	add	x9, x8, :tprel_hi12:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x8, x8, :tprel_hi12:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	add	x9, x9, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x8, x8, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	ldr	x0, [x0]
	str	x10, [x9]
	str	x11, [x8]
.Ltmp433:
	bl	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.Ltmp434:
// %bb.1:
	ldr	x20, [x19, #8]
	add	x19, x20, #8
	mov	x0, x19
	bl	pthread_mutex_lock
	cbnz	w0, .LBB76_11
.LBB76_2:
	mov	x0, #-1
	mov	x1, x20
	bl	__aarch64_ldadd8_acq_rel
	cmp	x0, #1
	b.ne	.LBB76_4
// %bb.3:
	add	x0, x20, #56
	bl	_ZNSt18condition_variable10notify_allEv
.LBB76_4:
	mov	x0, x19
	bl	pthread_mutex_unlock
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #48
	ret
.LBB76_5:
.Ltmp435:
	bl	__cxa_begin_catch
	ldr	x20, [x19, #24]
	mov	x0, x20
	bl	pthread_mutex_lock
	cbnz	w0, .LBB76_12
// %bb.6:
	mov	x8, sp
	bl	_ZSt17current_exceptionv
	ldr	x8, [x19, #16]
	ldr	x9, [sp]
	str	xzr, [sp]
	ldr	x10, [x8]
	str	x10, [sp, #8]
	str	x9, [x8]
	cbz	x10, .LBB76_8
// %bb.7:
	add	x0, sp, #8
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB76_8:
	ldr	x8, [sp]
	cbz	x8, .LBB76_10
// %bb.9:
	mov	x0, sp
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB76_10:
	mov	x0, x20
	bl	pthread_mutex_unlock
	bl	__cxa_end_catch
	ldr	x20, [x19, #8]
	add	x19, x20, #8
	mov	x0, x19
	bl	pthread_mutex_lock
	cbz	w0, .LBB76_2
.LBB76_11:
	bl	_ZSt20__throw_system_errori
.LBB76_12:
.Ltmp436:
	bl	_ZSt20__throw_system_errori
.Ltmp437:
// %bb.13:
.LBB76_14:
.Ltmp438:
	mov	x19, x0
.Ltmp439:
	bl	__cxa_end_catch
.Ltmp440:
// %bb.15:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB76_16:
.Ltmp441:
	bl	__clang_call_terminate
.Lfunc_end76:
	.size	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv, .Lfunc_end76-_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
	.cfi_endproc
	.section	.gcc_except_table._ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,"aG",@progbits,_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,comdat
	.p2align	2
GCC_except_table76:
.Lexception30:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase10-.Lttbaseref10
.Lttbaseref10:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end30-.Lcst_begin30
.Lcst_begin30:
	.uleb128 .Ltmp433-.Lfunc_begin30        // >> Call Site 1 <<
	.uleb128 .Ltmp434-.Ltmp433              //   Call between .Ltmp433 and .Ltmp434
	.uleb128 .Ltmp435-.Lfunc_begin30        //     jumps to .Ltmp435
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp434-.Lfunc_begin30        // >> Call Site 2 <<
	.uleb128 .Ltmp436-.Ltmp434              //   Call between .Ltmp434 and .Ltmp436
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp436-.Lfunc_begin30        // >> Call Site 3 <<
	.uleb128 .Ltmp437-.Ltmp436              //   Call between .Ltmp436 and .Ltmp437
	.uleb128 .Ltmp438-.Lfunc_begin30        //     jumps to .Ltmp438
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp439-.Lfunc_begin30        // >> Call Site 4 <<
	.uleb128 .Ltmp440-.Ltmp439              //   Call between .Ltmp439 and .Ltmp440
	.uleb128 .Ltmp441-.Lfunc_begin30        //     jumps to .Ltmp441
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp440-.Lfunc_begin30        // >> Call Site 5 <<
	.uleb128 .Lfunc_end76-.Ltmp440          //   Call between .Ltmp440 and .Lfunc_end76
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end30:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase10:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,"axG",@progbits,_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,comdat
	.weak	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b // -- Begin function _ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
	.p2align	2
	.type	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,@function
_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b: // @_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.Lfunc_begin31:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception31
// %bb.0:
	sub	sp, sp, #224
	str	d8, [sp, #112]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #128]            // 16-byte Folded Spill
	add	x29, sp, #128
	stp	x28, x27, [sp, #144]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #160]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #176]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	ldp	x8, x9, [x2]
	sturb	w5, [x29, #-20]
	stur	d0, [x29, #-8]
	stp	xzr, xzr, [x29, #-40]
	stur	xzr, [x29, #-48]
	cmp	x9, x8
	b.eq	.LBB77_36
// %bb.1:
	movi	v8.2s, #1
	mov	x19, x4
	mov	x20, x2
	mov	x21, x3
	mov	x22, x1
	mov	x23, x0
	mov	x10, xzr
	mov	x9, xzr
	sub	x28, x29, #20
	mov	x27, #4607182418800017408
	ldr	x8, [x8, x9, lsl #3]
	ldr	x9, [x23]
	ldr	x24, [x9, x8, lsl #3]
	stur	x24, [x29, #-56]
	cbz	x10, .LBB77_3
.LBB77_2:
	ldr	x8, [x10, #16]
	cmp	x24, x8
	b.eq	.LBB77_12
.LBB77_3:
.Ltmp442:
	mov	w0, #40
	bl	_Znwm
.Ltmp443:
// %bb.4:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x26, x0, #16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
.Ltmp445:
	mov	x0, x26
	mov	x1, x24
	bl	_ZN9pocketfft6detail11pocketfft_cIdEC2Em
.Ltmp446:
// %bb.5:
	ldur	x24, [x29, #-32]
	stp	x26, x25, [x29, #-40]
	cbz	x24, .LBB77_12
// %bb.6:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB77_8
// %bb.7:
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB77_9
	b	.LBB77_12
.LBB77_8:
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_12
.LBB77_9:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB77_28
// %bb.10:
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB77_12
.LBB77_11:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_12:
	cmp	x21, #1
	b.ne	.LBB77_14
// %bb.13:
	mov	w0, #1
	b	.LBB77_25
.LBB77_14:
	ldp	x8, x9, [x23]
	cmp	x8, x9
	b.eq	.LBB77_17
// %bb.15:
	sub	x10, x9, x8
	sub	x10, x10, #8
	cmp	x10, #8
	b.hs	.LBB77_18
// %bb.16:
	mov	w11, #1
	mov	x10, x8
	b	.LBB77_21
.LBB77_17:
	mov	w11, #1
	b	.LBB77_22
.LBB77_18:
	lsr	x10, x10, #3
	add	x11, x8, #8
	add	x12, x10, #1
	mov	w15, #1
	and	x13, x12, #0x3ffffffffffffffe
	mov	w16, #1
	mov	x14, x13
	add	x10, x8, x13, lsl #3
.LBB77_19:                              // =>This Inner Loop Header: Depth=1
	ldp	x17, x18, [x11, #-8]
	add	x11, x11, #16
	subs	x14, x14, #2
	mul	x15, x17, x15
	mul	x16, x18, x16
	b.ne	.LBB77_19
// %bb.20:
	mul	x11, x16, x15
	cmp	x12, x13
	b.eq	.LBB77_22
.LBB77_21:                              // =>This Inner Loop Header: Depth=1
	ldr	x12, [x10], #8
	cmp	x10, x9
	mul	x11, x12, x11
	b.ne	.LBB77_21
.LBB77_22:
	ldur	x9, [x29, #-48]
	ldr	x10, [x20]
	ldr	x9, [x10, x9, lsl #3]
	ldr	x8, [x8, x9, lsl #3]
	udiv	x9, x11, x8
	cmp	x8, #1000
	mov	x8, x21
	lsr	x10, x9, #2
	csel	x24, x10, x9, lo
	cbnz	x21, .LBB77_24
// %bb.23:
	bl	_ZNSt6thread20hardware_concurrencyEv
	mov	w8, w0
.LBB77_24:
	cmp	x8, x24
	csel	x8, x8, x24, lo
	cmp	x8, #1
	csinc	x0, x8, xzr, hi
.LBB77_25:
	sub	x8, x29, #56
	stp	x20, x19, [sp, #32]
	stp	x23, x8, [sp]
	sub	x8, x29, #48
	stp	x8, x22, [sp, #16]
	sub	x8, x29, #40
	str	x8, [sp, #48]
	sub	x8, x29, #8
	stp	x8, x28, [sp, #56]
.Ltmp448:
	mov	x1, sp
	bl	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
.Ltmp449:
// %bb.26:
	ldp	x8, x10, [x20]
	stur	x27, [x29, #-8]
	ldur	x9, [x29, #-48]
	add	x9, x9, #1
	sub	x10, x10, x8
	cmp	x9, x10, asr #3
	stur	x9, [x29, #-48]
	b.hs	.LBB77_29
// %bb.27:
	ldur	x10, [x29, #-40]
	ldr	x8, [x8, x9, lsl #3]
	ldr	x9, [x23]
	ldr	x24, [x9, x8, lsl #3]
	stur	x24, [x29, #-56]
	cbnz	x10, .LBB77_2
	b	.LBB77_3
.LBB77_28:
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_11
	b	.LBB77_12
.LBB77_29:
	ldur	x19, [x29, #-32]
	cbz	x19, .LBB77_36
// %bb.30:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB77_32
// %bb.31:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB77_33
	b	.LBB77_36
.LBB77_32:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_36
.LBB77_33:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB77_37
// %bb.34:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB77_36
.LBB77_35:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_36:
	ldp	x20, x19, [sp, #208]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #160]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #128]            // 16-byte Folded Reload
	ldr	d8, [sp, #112]                  // 8-byte Folded Reload
	add	sp, sp, #224
	ret
.LBB77_37:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_35
	b	.LBB77_36
.LBB77_38:
.Ltmp444:
	b	.LBB77_41
.LBB77_39:
.Ltmp447:
	mov	x19, x0
	mov	x0, x25
	bl	_ZdlPv
	b	.LBB77_42
.LBB77_40:
.Ltmp450:
.LBB77_41:
	mov	x19, x0
.LBB77_42:
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end77:
	.size	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b, .Lfunc_end77-_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,"aG",@progbits,_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,comdat
	.p2align	2
GCC_except_table77:
.Lexception31:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end31-.Lcst_begin31
.Lcst_begin31:
	.uleb128 .Ltmp442-.Lfunc_begin31        // >> Call Site 1 <<
	.uleb128 .Ltmp443-.Ltmp442              //   Call between .Ltmp442 and .Ltmp443
	.uleb128 .Ltmp444-.Lfunc_begin31        //     jumps to .Ltmp444
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp445-.Lfunc_begin31        // >> Call Site 2 <<
	.uleb128 .Ltmp446-.Ltmp445              //   Call between .Ltmp445 and .Ltmp446
	.uleb128 .Ltmp447-.Lfunc_begin31        //     jumps to .Ltmp447
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp446-.Lfunc_begin31        // >> Call Site 3 <<
	.uleb128 .Ltmp448-.Ltmp446              //   Call between .Ltmp446 and .Ltmp448
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp448-.Lfunc_begin31        // >> Call Site 4 <<
	.uleb128 .Ltmp449-.Ltmp448              //   Call between .Ltmp448 and .Ltmp449
	.uleb128 .Ltmp450-.Lfunc_begin31        //     jumps to .Ltmp450
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp449-.Lfunc_begin31        // >> Call Site 5 <<
	.uleb128 .Lfunc_end77-.Ltmp449          //   Call between .Ltmp449 and .Lfunc_end77
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end31:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB78_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB78_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB78_4
	b	.LBB78_8
.LBB78_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_8
.LBB78_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB78_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB78_8
.LBB78_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB78_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_6
.LBB78_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end78:
	.size	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end78-_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIdEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,"axG",@progbits,_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,comdat
	.weak	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ // -- Begin function _ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
	.p2align	2
	.type	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,@function
_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_: // @_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
.Lfunc_begin32:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception32
// %bb.0:
	sub	sp, sp, #336
	stp	x29, x30, [sp, #240]            // 16-byte Folded Spill
	add	x29, sp, #240
	stp	x28, x27, [sp, #256]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #272]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	adrp	x8, .L_MergedGlobals+8
	cmp	x0, #0
	mov	x20, x1
	ldr	x8, [x8, :lo12:.L_MergedGlobals+8]
	csel	x22, x8, x0, eq
	cmp	x22, #1
	b.ne	.LBB79_2
// %bb.1:
	mov	x0, x20
	ldp	x20, x19, [sp, #320]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #240]            // 16-byte Folded Reload
	add	sp, sp, #336
	b	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.LBB79_2:
	adrp	x8, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x8, x8, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	ldarb	w8, [x8]
	tbz	w8, #0, .LBB79_18
.LBB79_3:
	add	x23, sp, #112
	str	x22, [sp, #112]
	movi	v0.2d, #0000000000000000
	add	x19, x23, #56
	mov	x0, x19
	str	xzr, [sp, #152]
	stur	q0, [sp, #120]
	stur	q0, [sp, #136]
	bl	_ZNSt18condition_variableC1Ev
	movi	v0.2d, #0000000000000000
	str	xzr, [sp, #104]
	str	xzr, [sp, #80]
	stp	q0, q0, [sp, #48]
	cbz	x22, .LBB79_10
// %bb.4:
	adrp	x27, _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	adrp	x28, _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	adrp	x21, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	mov	x24, xzr
	add	x25, sp, #104
	add	x26, sp, #48
	add	x27, x27, :lo12:_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	add	x28, x28, :lo12:_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	add	x21, x21, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	b	.LBB79_6
.LBB79_5:                               //   in Loop: Header=BB79_6 Depth=1
	add	x24, x24, #1
	cmp	x22, x24
	b.eq	.LBB79_10
.LBB79_6:                               // =>This Inner Loop Header: Depth=1
	movi	v0.2d, #0000000000000000
	stp	q0, q0, [sp, #16]
.Ltmp454:
	mov	w0, #48
	bl	_Znwm
.Ltmp455:
// %bb.7:                               //   in Loop: Header=BB79_6 Depth=1
	stp	x20, x23, [x0]
	stp	x25, x26, [x0, #16]
	stp	x24, x22, [x0, #32]
	stp	x28, x27, [sp, #32]
	str	x0, [sp, #16]
.Ltmp457:
	add	x1, sp, #16
	mov	x0, x21
	bl	_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE
.Ltmp458:
// %bb.8:                               //   in Loop: Header=BB79_6 Depth=1
	ldr	x8, [sp, #32]
	cbz	x8, .LBB79_5
// %bb.9:                               //   in Loop: Header=BB79_6 Depth=1
.Ltmp463:
	add	x0, sp, #16
	add	x1, sp, #16
	mov	w2, #3
	blr	x8
.Ltmp464:
	b	.LBB79_5
.LBB79_10:
	add	x0, x23, #8
	stur	x0, [x29, #-24]
	bl	pthread_mutex_lock
	cbnz	w0, .LBB79_21
// %bb.11:
	mov	w8, #1
	add	x20, sp, #112
	sturb	w8, [x29, #-16]
	ldar	x8, [x20]
	cbz	x8, .LBB79_13
.LBB79_12:                              // =>This Inner Loop Header: Depth=1
	sub	x1, x29, #24
	mov	x0, x19
	bl	_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE
	ldar	x8, [x20]
	cbnz	x8, .LBB79_12
.LBB79_13:
	ldurb	w8, [x29, #-16]
	cbz	w8, .LBB79_16
// %bb.14:
	ldur	x0, [x29, #-24]
	cbz	x0, .LBB79_16
// %bb.15:
	bl	pthread_mutex_unlock
.LBB79_16:
	ldr	x8, [sp, #104]
	cbnz	x8, .LBB79_23
// %bb.17:
	mov	x0, x19
	bl	_ZNSt18condition_variableD1Ev
	ldp	x20, x19, [sp, #320]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #240]            // 16-byte Folded Reload
	add	sp, sp, #336
	ret
.LBB79_18:
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_acquire
	cbz	w0, .LBB79_3
// %bb.19:
.Ltmp451:
	adrp	x0, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	_ZN9pocketfft6detail9threading11thread_poolC2Ev
.Ltmp452:
// %bb.20:
	adrp	x0, _ZN9pocketfft6detail9threading11thread_poolD2Ev
	adrp	x1, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	adrp	x2, __dso_handle
	add	x0, x0, :lo12:_ZN9pocketfft6detail9threading11thread_poolD2Ev
	add	x1, x1, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x2, x2, :lo12:__dso_handle
	bl	__cxa_atexit
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_release
	b	.LBB79_3
.LBB79_21:
.Ltmp466:
	bl	_ZSt20__throw_system_errori
.Ltmp467:
// %bb.22:
.LBB79_23:
	add	x0, sp, #8
	str	x8, [sp, #8]
	bl	_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv
.Ltmp469:
	add	x0, sp, #8
	bl	_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE
.Ltmp470:
// %bb.24:
.LBB79_25:
.Ltmp453:
	mov	x20, x0
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_abort
	mov	x0, x20
	bl	_Unwind_Resume
.LBB79_26:
.Ltmp471:
	ldr	x8, [sp, #8]
	mov	x20, x0
	cbz	x8, .LBB79_34
// %bb.27:
	add	x0, sp, #8
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
	b	.LBB79_34
.LBB79_28:
.Ltmp468:
	b	.LBB79_31
.LBB79_29:
.Ltmp465:
	bl	__clang_call_terminate
.LBB79_30:
.Ltmp456:
.LBB79_31:
	mov	x20, x0
	b	.LBB79_34
.LBB79_32:
.Ltmp459:
	ldr	x8, [sp, #32]
	mov	x20, x0
	cbz	x8, .LBB79_34
// %bb.33:
.Ltmp460:
	add	x0, sp, #16
	add	x1, sp, #16
	mov	w2, #3
	blr	x8
.Ltmp461:
.LBB79_34:
	ldr	x8, [sp, #104]
	cbz	x8, .LBB79_36
// %bb.35:
	add	x0, sp, #104
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB79_36:
	mov	x0, x19
	bl	_ZNSt18condition_variableD1Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB79_37:
.Ltmp462:
	bl	__clang_call_terminate
.Lfunc_end79:
	.size	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_, .Lfunc_end79-_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,"aG",@progbits,_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,comdat
	.p2align	2
GCC_except_table79:
.Lexception32:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase11-.Lttbaseref11
.Lttbaseref11:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end32-.Lcst_begin32
.Lcst_begin32:
	.uleb128 .Lfunc_begin32-.Lfunc_begin32  // >> Call Site 1 <<
	.uleb128 .Ltmp454-.Lfunc_begin32        //   Call between .Lfunc_begin32 and .Ltmp454
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp454-.Lfunc_begin32        // >> Call Site 2 <<
	.uleb128 .Ltmp455-.Ltmp454              //   Call between .Ltmp454 and .Ltmp455
	.uleb128 .Ltmp456-.Lfunc_begin32        //     jumps to .Ltmp456
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp457-.Lfunc_begin32        // >> Call Site 3 <<
	.uleb128 .Ltmp458-.Ltmp457              //   Call between .Ltmp457 and .Ltmp458
	.uleb128 .Ltmp459-.Lfunc_begin32        //     jumps to .Ltmp459
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp463-.Lfunc_begin32        // >> Call Site 4 <<
	.uleb128 .Ltmp464-.Ltmp463              //   Call between .Ltmp463 and .Ltmp464
	.uleb128 .Ltmp465-.Lfunc_begin32        //     jumps to .Ltmp465
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp451-.Lfunc_begin32        // >> Call Site 5 <<
	.uleb128 .Ltmp452-.Ltmp451              //   Call between .Ltmp451 and .Ltmp452
	.uleb128 .Ltmp453-.Lfunc_begin32        //     jumps to .Ltmp453
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp466-.Lfunc_begin32        // >> Call Site 6 <<
	.uleb128 .Ltmp467-.Ltmp466              //   Call between .Ltmp466 and .Ltmp467
	.uleb128 .Ltmp468-.Lfunc_begin32        //     jumps to .Ltmp468
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp469-.Lfunc_begin32        // >> Call Site 7 <<
	.uleb128 .Ltmp470-.Ltmp469              //   Call between .Ltmp469 and .Ltmp470
	.uleb128 .Ltmp471-.Lfunc_begin32        //     jumps to .Ltmp471
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp470-.Lfunc_begin32        // >> Call Site 8 <<
	.uleb128 .Ltmp460-.Ltmp470              //   Call between .Ltmp470 and .Ltmp460
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp460-.Lfunc_begin32        // >> Call Site 9 <<
	.uleb128 .Ltmp461-.Ltmp460              //   Call between .Ltmp460 and .Ltmp461
	.uleb128 .Ltmp462-.Lfunc_begin32        //     jumps to .Ltmp462
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp461-.Lfunc_begin32        // >> Call Site 10 <<
	.uleb128 .Lfunc_end79-.Ltmp461          //   Call between .Ltmp461 and .Lfunc_end79
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end32:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase11:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end80:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end80-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end81:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end81-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	add	x0, x0, #16
	b	_ZN9pocketfft6detail11pocketfft_cIdED2Ev
.Lfunc_end82:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end82-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end83:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end83-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB84_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB84_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB84_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB84_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB84_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB84_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end84:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end84-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail11pocketfft_cIdEC2Em,"axG",@progbits,_ZN9pocketfft6detail11pocketfft_cIdEC2Em,comdat
	.weak	_ZN9pocketfft6detail11pocketfft_cIdEC2Em // -- Begin function _ZN9pocketfft6detail11pocketfft_cIdEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail11pocketfft_cIdEC2Em,@function
_ZN9pocketfft6detail11pocketfft_cIdEC2Em: // @_ZN9pocketfft6detail11pocketfft_cIdEC2Em
.Lfunc_begin33:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception33
// %bb.0:
	str	d8, [sp, #-64]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -64
	mov	x19, x0
	mov	x20, x0
	str	xzr, [x0]
	str	x1, [x0, #16]
	str	xzr, [x20, #8]!
	cbz	x1, .LBB85_24
// %bb.1:
	mov	x21, x1
	cmp	x1, #50
	b.hs	.LBB85_5
// %bb.2:
	mov	x0, xzr
	mul	x8, x0, x0
	cmp	x8, x21
	b.hi	.LBB85_6
.LBB85_3:
.Ltmp472:
	mov	w0, #48
	bl	_Znwm
.Ltmp473:
// %bb.4:
	mov	x22, x0
.Ltmp475:
	mov	x1, x21
	bl	_ZN9pocketfft6detail5cfftpIdEC2Em
.Ltmp476:
	b	.LBB85_17
.LBB85_5:
	mov	x0, x21
	bl	_ZN9pocketfft6detail4util20largest_prime_factorEm
	mul	x8, x0, x0
	cmp	x8, x21
	b.ls	.LBB85_3
.LBB85_6:
	mov	x0, x21
	bl	_ZN9pocketfft6detail4util10cost_guessEm
	lsl	x8, x21, #1
	fmov	d8, d0
	sub	x0, x8, #1
	bl	_ZN9pocketfft6detail4util15good_size_cmplxEm
	bl	_ZN9pocketfft6detail4util10cost_guessEm
	fadd	d0, d0, d0
	fmov	d1, #1.50000000
	fmul	d0, d0, d1
	fcmp	d0, d8
	b.pl	.LBB85_15
// %bb.7:
.Ltmp484:
	mov	w0, #96
	bl	_Znwm
.Ltmp485:
// %bb.8:
	mov	x22, x0
.Ltmp487:
	mov	x1, x21
	bl	_ZN9pocketfft6detail7fftblueIdEC2Em
.Ltmp488:
// %bb.9:
	ldr	x21, [x20]
	str	x22, [x20]
	cbz	x21, .LBB85_23
// %bb.10:
	ldr	x8, [x21, #64]
	cbz	x8, .LBB85_12
// %bb.11:
	ldur	x0, [x8, #-8]
	bl	free
.LBB85_12:
	ldr	x0, [x21, #40]
	cbz	x0, .LBB85_14
// %bb.13:
	bl	_ZdlPv
.LBB85_14:
	ldr	x8, [x21, #24]
	cbnz	x8, .LBB85_21
	b	.LBB85_22
.LBB85_15:
.Ltmp478:
	mov	w0, #48
	bl	_Znwm
.Ltmp479:
// %bb.16:
	mov	x22, x0
.Ltmp481:
	mov	x1, x21
	bl	_ZN9pocketfft6detail5cfftpIdEC2Em
.Ltmp482:
.LBB85_17:
	ldr	x21, [x19]
	str	x22, [x19]
	cbz	x21, .LBB85_23
// %bb.18:
	ldr	x0, [x21, #24]
	cbz	x0, .LBB85_20
// %bb.19:
	bl	_ZdlPv
.LBB85_20:
	ldr	x8, [x21, #8]
	cbz	x8, .LBB85_22
.LBB85_21:
	ldur	x0, [x8, #-8]
	bl	free
.LBB85_22:
	mov	x0, x21
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	b	_ZdlPv
.LBB85_23:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	ret
.LBB85_24:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x22, x0
.Ltmp490:
	adrp	x1, .L.str.8
	add	x1, x1, :lo12:.L.str.8
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp491:
// %bb.25:
.Ltmp493:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x22
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp494:
// %bb.26:
.LBB85_27:
.Ltmp483:
	b	.LBB85_32
.LBB85_28:
.Ltmp489:
	b	.LBB85_32
.LBB85_29:
.Ltmp480:
	mov	x21, x0
	b	.LBB85_36
.LBB85_30:
.Ltmp486:
	mov	x21, x0
	b	.LBB85_36
.LBB85_31:
.Ltmp477:
.LBB85_32:
	mov	x21, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB85_36
.LBB85_33:
.Ltmp474:
	mov	x21, x0
	b	.LBB85_36
.LBB85_34:
.Ltmp495:
	mov	x21, x0
	b	.LBB85_36
.LBB85_35:
.Ltmp492:
	mov	x21, x0
	mov	x0, x22
	bl	__cxa_free_exception
.LBB85_36:
	mov	x0, x20
	bl	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev
	mov	x0, x19
	bl	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev
	mov	x0, x21
	bl	_Unwind_Resume
.Lfunc_end85:
	.size	_ZN9pocketfft6detail11pocketfft_cIdEC2Em, .Lfunc_end85-_ZN9pocketfft6detail11pocketfft_cIdEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail11pocketfft_cIdEC2Em,"aG",@progbits,_ZN9pocketfft6detail11pocketfft_cIdEC2Em,comdat
	.p2align	2
GCC_except_table85:
.Lexception33:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end33-.Lcst_begin33
.Lcst_begin33:
	.uleb128 .Ltmp472-.Lfunc_begin33        // >> Call Site 1 <<
	.uleb128 .Ltmp473-.Ltmp472              //   Call between .Ltmp472 and .Ltmp473
	.uleb128 .Ltmp474-.Lfunc_begin33        //     jumps to .Ltmp474
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp475-.Lfunc_begin33        // >> Call Site 2 <<
	.uleb128 .Ltmp476-.Ltmp475              //   Call between .Ltmp475 and .Ltmp476
	.uleb128 .Ltmp477-.Lfunc_begin33        //     jumps to .Ltmp477
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp484-.Lfunc_begin33        // >> Call Site 3 <<
	.uleb128 .Ltmp485-.Ltmp484              //   Call between .Ltmp484 and .Ltmp485
	.uleb128 .Ltmp486-.Lfunc_begin33        //     jumps to .Ltmp486
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp487-.Lfunc_begin33        // >> Call Site 4 <<
	.uleb128 .Ltmp488-.Ltmp487              //   Call between .Ltmp487 and .Ltmp488
	.uleb128 .Ltmp489-.Lfunc_begin33        //     jumps to .Ltmp489
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp478-.Lfunc_begin33        // >> Call Site 5 <<
	.uleb128 .Ltmp479-.Ltmp478              //   Call between .Ltmp478 and .Ltmp479
	.uleb128 .Ltmp480-.Lfunc_begin33        //     jumps to .Ltmp480
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp481-.Lfunc_begin33        // >> Call Site 6 <<
	.uleb128 .Ltmp482-.Ltmp481              //   Call between .Ltmp481 and .Ltmp482
	.uleb128 .Ltmp483-.Lfunc_begin33        //     jumps to .Ltmp483
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp482-.Lfunc_begin33        // >> Call Site 7 <<
	.uleb128 .Ltmp490-.Ltmp482              //   Call between .Ltmp482 and .Ltmp490
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp490-.Lfunc_begin33        // >> Call Site 8 <<
	.uleb128 .Ltmp491-.Ltmp490              //   Call between .Ltmp490 and .Ltmp491
	.uleb128 .Ltmp492-.Lfunc_begin33        //     jumps to .Ltmp492
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp493-.Lfunc_begin33        // >> Call Site 9 <<
	.uleb128 .Ltmp494-.Ltmp493              //   Call between .Ltmp493 and .Ltmp494
	.uleb128 .Ltmp495-.Lfunc_begin33        //     jumps to .Ltmp495
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp494-.Lfunc_begin33        // >> Call Site 10 <<
	.uleb128 .Lfunc_end85-.Ltmp494          //   Call between .Ltmp494 and .Lfunc_end85
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end33:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIdEC2Em,"axG",@progbits,_ZN9pocketfft6detail5cfftpIdEC2Em,comdat
	.weak	_ZN9pocketfft6detail5cfftpIdEC2Em // -- Begin function _ZN9pocketfft6detail5cfftpIdEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIdEC2Em,@function
_ZN9pocketfft6detail5cfftpIdEC2Em:      // @_ZN9pocketfft6detail5cfftpIdEC2Em
.Lfunc_begin34:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception34
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	movi	v0.2d, #0000000000000000
	mov	x22, x0
	cmp	x1, #1
	str	x1, [x0]
	str	xzr, [x0, #40]
	stur	q0, [x0, #24]
	str	q0, [x22, #8]!
	b.eq	.LBB86_15
// %bb.1:
	mov	x19, x0
	cbz	x1, .LBB86_16
// %bb.2:
.Ltmp501:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIdE9factorizeEv
.Ltmp502:
// %bb.3:
	ldp	x8, x9, [x19, #24]
	mov	x20, xzr
	subs	x9, x9, x8
	b.eq	.LBB86_6
// %bb.4:
	mov	x10, #-6148914691236517206
	mov	w11, #1
	movk	x10, #43691
	movk	x10, #10922, lsl #48
	smulh	x9, x9, x10
	asr	x10, x9, #2
	add	x10, x10, x9, lsr #63
	ldr	x9, [x19]
	cmp	x10, #1
	csinc	x10, x10, xzr, hi
.LBB86_5:                               // =>This Inner Loop Header: Depth=1
	ldr	x12, [x8], #24
	mul	x11, x12, x11
	cmp	x12, #11
	sub	x14, x12, #1
	csel	x12, x12, xzr, hi
	add	x12, x12, x20
	subs	x10, x10, #1
	udiv	x13, x9, x11
	sub	x13, x13, #1
	madd	x20, x13, x14, x12
	b.ne	.LBB86_5
.LBB86_6:
	ldr	x8, [x19, #16]
	cmp	x8, x20
	b.eq	.LBB86_14
// %bb.7:
	ldr	x8, [x22]
	cbz	x8, .LBB86_9
// %bb.8:
	ldur	x0, [x8, #-8]
	bl	free
.LBB86_9:
	cbz	x20, .LBB86_12
// %bb.10:
	lsl	x8, x20, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB86_19
// %bb.11:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
	b	.LBB86_13
.LBB86_12:
	mov	x8, xzr
.LBB86_13:
	stp	x8, x20, [x19, #8]
.LBB86_14:
.Ltmp505:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv
.Ltmp506:
.LBB86_15:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB86_16:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp496:
	adrp	x1, .L.str.8
	add	x1, x1, :lo12:.L.str.8
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp497:
// %bb.17:
.Ltmp499:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp500:
// %bb.18:
.LBB86_19:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp503:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp504:
// %bb.20:
.LBB86_21:
.Ltmp498:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
	b	.LBB86_23
.LBB86_22:
.Ltmp507:
	mov	x20, x0
.LBB86_23:
	ldr	x0, [x19, #24]
	cbnz	x0, .LBB86_26
// %bb.24:
	ldr	x8, [x22]
	cbnz	x8, .LBB86_27
.LBB86_25:
	mov	x0, x20
	bl	_Unwind_Resume
.LBB86_26:
	bl	_ZdlPv
	ldr	x8, [x22]
	cbz	x8, .LBB86_25
.LBB86_27:
	ldur	x0, [x8, #-8]
	bl	free
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end86:
	.size	_ZN9pocketfft6detail5cfftpIdEC2Em, .Lfunc_end86-_ZN9pocketfft6detail5cfftpIdEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail5cfftpIdEC2Em,"aG",@progbits,_ZN9pocketfft6detail5cfftpIdEC2Em,comdat
	.p2align	2
GCC_except_table86:
.Lexception34:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end34-.Lcst_begin34
.Lcst_begin34:
	.uleb128 .Ltmp501-.Lfunc_begin34        // >> Call Site 1 <<
	.uleb128 .Ltmp506-.Ltmp501              //   Call between .Ltmp501 and .Ltmp506
	.uleb128 .Ltmp507-.Lfunc_begin34        //     jumps to .Ltmp507
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp506-.Lfunc_begin34        // >> Call Site 2 <<
	.uleb128 .Ltmp496-.Ltmp506              //   Call between .Ltmp506 and .Ltmp496
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp496-.Lfunc_begin34        // >> Call Site 3 <<
	.uleb128 .Ltmp497-.Ltmp496              //   Call between .Ltmp496 and .Ltmp497
	.uleb128 .Ltmp498-.Lfunc_begin34        //     jumps to .Ltmp498
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp499-.Lfunc_begin34        // >> Call Site 4 <<
	.uleb128 .Ltmp500-.Ltmp499              //   Call between .Ltmp499 and .Ltmp500
	.uleb128 .Ltmp507-.Lfunc_begin34        //     jumps to .Ltmp507
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp500-.Lfunc_begin34        // >> Call Site 5 <<
	.uleb128 .Ltmp503-.Ltmp500              //   Call between .Ltmp500 and .Ltmp503
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp503-.Lfunc_begin34        // >> Call Site 6 <<
	.uleb128 .Ltmp504-.Ltmp503              //   Call between .Ltmp503 and .Ltmp504
	.uleb128 .Ltmp507-.Lfunc_begin34        //     jumps to .Ltmp507
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp504-.Lfunc_begin34        // >> Call Site 7 <<
	.uleb128 .Lfunc_end86-.Ltmp504          //   Call between .Ltmp504 and .Lfunc_end86
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end34:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev,"axG",@progbits,_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev,comdat
	.weak	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev // -- Begin function _ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev
	.p2align	2
	.type	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev,@function
_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev: // @_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0]
	cbz	x20, .LBB87_6
// %bb.1:
	ldr	x0, [x20, #24]
	cbz	x0, .LBB87_3
// %bb.2:
	bl	_ZdlPv
.LBB87_3:
	ldr	x8, [x20, #8]
	cbz	x8, .LBB87_5
// %bb.4:
	ldur	x0, [x8, #-8]
	bl	free
.LBB87_5:
	mov	x0, x20
	bl	_ZdlPv
.LBB87_6:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end87:
	.size	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev, .Lfunc_end87-_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIdEESt14default_deleteIS3_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN9pocketfft6detail7fftblueIdEC2Em
.LCPI88_0:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZN9pocketfft6detail7fftblueIdEC2Em,"axG",@progbits,_ZN9pocketfft6detail7fftblueIdEC2Em,comdat
	.weak	_ZN9pocketfft6detail7fftblueIdEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail7fftblueIdEC2Em,@function
_ZN9pocketfft6detail7fftblueIdEC2Em:    // @_ZN9pocketfft6detail7fftblueIdEC2Em
.Lfunc_begin35:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception35
// %bb.0:
	sub	sp, sp, #112
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	lsl	x8, x1, #1
	mov	x20, x0
	sub	x0, x8, #1
	str	x1, [x20]
	bl	_ZN9pocketfft6detail4util15good_size_cmplxEm
	add	x19, x20, #16
	mov	x1, x0
	str	x0, [x20, #8]
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIdEC2Em
	ldp	x21, x8, [x20]
	add	x8, x21, x8, lsr #1
	adds	x22, x8, #1
	b.eq	.LBB88_3
// %bb.1:
	lsl	x8, x22, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB88_27
// %bb.2:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
	b	.LBB88_4
.LBB88_3:
	mov	x8, xzr
.LBB88_4:
	add	x9, x8, x21, lsl #4
	lsl	x1, x21, #1
	stp	x8, x22, [x20, #64]
	stp	x8, x9, [x20, #80]
.Ltmp511:
	add	x0, sp, #8
	bl	_ZN9pocketfft6detail13sincos_2pibynIdEC2Em
.Ltmp512:
// %bb.5:
	adrp	x8, .LCPI88_0
	ldr	x9, [x20, #80]
	ldr	q0, [x8, :lo12:.LCPI88_0]
	str	q0, [x9]
	ldr	x12, [x20]
	cmp	x12, #2
	b.lo	.LBB88_11
// %bb.6:
	mov	x8, xzr
	mov	x10, xzr
	mov	x9, #-1
	mov	w11, #1
	b	.LBB88_9
.LBB88_7:                               //   in Loop: Header=BB88_9 Depth=1
	add	x13, x12, x14
	ldr	x15, [sp, #32]
	ldp	x14, x16, [sp, #16]
	sub	x13, x13, x10
	add	x13, x9, x13
	ldr	x17, [sp, #48]
	and	x14, x14, x13
	lsr	x13, x13, x16
	add	x14, x15, x14, lsl #4
	add	x13, x17, x13, lsl #4
	ldp	d4, d0, [x14]
	ldp	d2, d3, [x13]
	fneg	d1, d0
	fmul	d0, d0, d2
	fmul	d1, d3, d1
	fnmadd	d0, d4, d3, d0
.LBB88_8:                               //   in Loop: Header=BB88_9 Depth=1
	fmadd	d1, d4, d2, d1
	ldr	x13, [x20, #80]
	add	x10, x10, x11, lsl #1
	add	x11, x11, #1
	sub	x9, x9, #2
	add	x13, x13, x8, lsl #3
	add	x8, x8, #2
	stp	d1, d0, [x13, #16]
	mvn	x13, x12
	ldr	x12, [x20]
	add	x10, x13, x10
	cmp	x11, x12
	b.hs	.LBB88_11
.LBB88_9:                               // =>This Inner Loop Header: Depth=1
	add	x13, x10, x8
	lsl	x12, x12, #1
	add	x13, x13, #1
	ldr	x14, [sp, #8]
	cmp	x13, x12
	csel	x12, xzr, x12, lo
	sub	x13, x10, x12
	add	x13, x8, x13
	add	x13, x13, #1
	cmp	x14, x13, lsl #1
	b.lo	.LBB88_7
// %bb.10:                              //   in Loop: Header=BB88_9 Depth=1
	ldp	x14, x16, [sp, #16]
	ldr	x15, [sp, #32]
	ldr	x17, [sp, #48]
	and	x14, x14, x13
	lsr	x13, x13, x16
	add	x14, x15, x14, lsl #4
	add	x13, x17, x13, lsl #4
	ldp	d4, d0, [x14]
	ldp	d2, d3, [x13]
	fneg	d1, d0
	fmul	d0, d0, d2
	fmul	d1, d3, d1
	fmadd	d0, d4, d3, d0
	b	.LBB88_8
.LBB88_11:
	ldr	x21, [x20, #8]
	lsl	x8, x21, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB88_25
// %bb.12:
	ucvtf	d0, x21
	fmov	d1, #1.00000000
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	fdiv	d0, d1, d0
	stur	x0, [x21, #-8]
	ldr	x8, [x20, #80]
	ldr	q1, [x8]
	fmul	v1.2d, v1.2d, v0.d[0]
	str	q1, [x21]
	ldr	x10, [x20]
	cmp	x10, #2
	b.lo	.LBB88_15
// %bb.13:
	add	x8, x21, #16
	mov	x9, #-1
	mov	w11, #1
.LBB88_14:                              // =>This Inner Loop Header: Depth=1
	ldr	x10, [x20, #80]
	ldr	q1, [x10, x11, lsl #4]
	add	x11, x11, #1
	ldr	x10, [x20, #8]
	add	x10, x9, x10
	fmul	v1.2d, v1.2d, v0.d[0]
	lsl	x10, x10, #4
	sub	x9, x9, #1
	str	q1, [x21, x10]
	ldr	q1, [x21, x10]
	str	q1, [x8], #16
	ldr	x10, [x20]
	cmp	x11, x10
	b.lo	.LBB88_14
.LBB88_15:
	ldr	x8, [x20, #8]
	sub	x8, x8, x10
	cmp	x10, x8
	b.hi	.LBB88_17
// %bb.16:
	add	x8, x8, #1
	add	x9, x10, #1
	cmp	x8, x9
	add	x0, x21, x10, lsl #4
	csinc	x8, x8, x10, hi
	mov	w1, wzr
	sub	x8, x8, x10
	lsl	x2, x8, #4
	bl	memset
.LBB88_17:
.Ltmp514:
	fmov	d0, #1.00000000
	mov	x0, x19
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
.Ltmp515:
// %bb.18:
	mov	x8, xzr
	mov	x9, #-1
.LBB88_19:                              // =>This Inner Loop Header: Depth=1
	ldr	q0, [x21, x8]
	add	x9, x9, #1
	ldr	x10, [x20, #88]
	str	q0, [x10, x8]
	add	x8, x8, #16
	ldr	x10, [x20, #8]
	cmp	x9, x10, lsr #1
	b.lo	.LBB88_19
// %bb.20:
	ldur	x0, [x21, #-8]
	bl	free
	ldr	x8, [sp, #48]
	cbz	x8, .LBB88_22
// %bb.21:
	ldur	x0, [x8, #-8]
	bl	free
.LBB88_22:
	ldr	x8, [sp, #32]
	cbz	x8, .LBB88_24
// %bb.23:
	ldur	x0, [x8, #-8]
	bl	free
.LBB88_24:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #112
	ret
.LBB88_25:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp517:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp518:
// %bb.26:
.LBB88_27:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp508:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp509:
// %bb.28:
.LBB88_29:
.Ltmp510:
	mov	x22, x0
	b	.LBB88_36
.LBB88_30:
.Ltmp516:
	mov	x22, x0
	ldur	x0, [x21, #-8]
	bl	free
	b	.LBB88_32
.LBB88_31:
.Ltmp519:
	mov	x22, x0
.LBB88_32:
	add	x0, sp, #8
	bl	_ZN9pocketfft6detail13sincos_2pibynIdED2Ev
	b	.LBB88_34
.LBB88_33:
.Ltmp513:
	mov	x22, x0
.LBB88_34:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB88_36
// %bb.35:
	ldur	x0, [x8, #-8]
	bl	free
.LBB88_36:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIdED2Ev
	mov	x0, x22
	bl	_Unwind_Resume
.Lfunc_end88:
	.size	_ZN9pocketfft6detail7fftblueIdEC2Em, .Lfunc_end88-_ZN9pocketfft6detail7fftblueIdEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail7fftblueIdEC2Em,"aG",@progbits,_ZN9pocketfft6detail7fftblueIdEC2Em,comdat
	.p2align	2
GCC_except_table88:
.Lexception35:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end35-.Lcst_begin35
.Lcst_begin35:
	.uleb128 .Lfunc_begin35-.Lfunc_begin35  // >> Call Site 1 <<
	.uleb128 .Ltmp511-.Lfunc_begin35        //   Call between .Lfunc_begin35 and .Ltmp511
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp511-.Lfunc_begin35        // >> Call Site 2 <<
	.uleb128 .Ltmp512-.Ltmp511              //   Call between .Ltmp511 and .Ltmp512
	.uleb128 .Ltmp513-.Lfunc_begin35        //     jumps to .Ltmp513
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp512-.Lfunc_begin35        // >> Call Site 3 <<
	.uleb128 .Ltmp514-.Ltmp512              //   Call between .Ltmp512 and .Ltmp514
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp514-.Lfunc_begin35        // >> Call Site 4 <<
	.uleb128 .Ltmp515-.Ltmp514              //   Call between .Ltmp514 and .Ltmp515
	.uleb128 .Ltmp516-.Lfunc_begin35        //     jumps to .Ltmp516
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp515-.Lfunc_begin35        // >> Call Site 5 <<
	.uleb128 .Ltmp517-.Ltmp515              //   Call between .Ltmp515 and .Ltmp517
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp517-.Lfunc_begin35        // >> Call Site 6 <<
	.uleb128 .Ltmp518-.Ltmp517              //   Call between .Ltmp517 and .Ltmp518
	.uleb128 .Ltmp519-.Lfunc_begin35        //     jumps to .Ltmp519
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp518-.Lfunc_begin35        // >> Call Site 7 <<
	.uleb128 .Ltmp508-.Ltmp518              //   Call between .Ltmp518 and .Ltmp508
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp508-.Lfunc_begin35        // >> Call Site 8 <<
	.uleb128 .Ltmp509-.Ltmp508              //   Call between .Ltmp508 and .Ltmp509
	.uleb128 .Ltmp510-.Lfunc_begin35        //     jumps to .Ltmp510
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp509-.Lfunc_begin35        // >> Call Site 9 <<
	.uleb128 .Lfunc_end88-.Ltmp509          //   Call between .Ltmp509 and .Lfunc_end88
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end35:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev,"axG",@progbits,_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev,comdat
	.weak	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev // -- Begin function _ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev
	.p2align	2
	.type	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev,@function
_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev: // @_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0]
	cbz	x20, .LBB89_8
// %bb.1:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB89_3
// %bb.2:
	ldur	x0, [x8, #-8]
	bl	free
.LBB89_3:
	ldr	x0, [x20, #40]
	cbz	x0, .LBB89_5
// %bb.4:
	bl	_ZdlPv
.LBB89_5:
	ldr	x8, [x20, #24]
	cbz	x8, .LBB89_7
// %bb.6:
	ldur	x0, [x8, #-8]
	bl	free
.LBB89_7:
	mov	x0, x20
	bl	_ZdlPv
.LBB89_8:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end89:
	.size	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev, .Lfunc_end89-_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIdEESt14default_deleteIS3_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIdE9factorizeEv,"axG",@progbits,_ZN9pocketfft6detail5cfftpIdE9factorizeEv,comdat
	.weak	_ZN9pocketfft6detail5cfftpIdE9factorizeEv // -- Begin function _ZN9pocketfft6detail5cfftpIdE9factorizeEv
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIdE9factorizeEv,@function
_ZN9pocketfft6detail5cfftpIdE9factorizeEv: // @_ZN9pocketfft6detail5cfftpIdE9factorizeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	x24, [x0]
	mov	x19, x0
	tst	x24, #0x7
	b.eq	.LBB90_7
// %bb.1:
	mov	x25, x24
.LBB90_2:
	tst	x25, #0x3
	b.eq	.LBB90_16
// %bb.3:
	mov	x24, x25
.LBB90_4:
	tbnz	w24, #0, .LBB90_32
// %bb.5:
	ldp	x8, x9, [x19, #32]
	cmp	x8, x9
	b.eq	.LBB90_25
// %bb.6:
	mov	w9, #2
	stp	xzr, xzr, [x8, #8]
	str	x9, [x8]
	ldp	x21, x25, [x19, #24]
	add	x8, x25, #24
	str	x8, [x19, #32]
	b	.LBB90_31
.LBB90_7:
	ldr	x8, [x19, #32]
	mov	x27, #9223372036854775800
	mov	w28, #24
	mov	w26, #8
	b	.LBB90_9
.LBB90_8:                               //   in Loop: Header=BB90_9 Depth=1
	stp	xzr, xzr, [x8, #8]
	str	x26, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	lsr	x25, x24, #3
	tst	x24, #0x38
	mov	x24, x25
	b.ne	.LBB90_2
.LBB90_9:                               // =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB90_8
// %bb.10:                              //   in Loop: Header=BB90_9 Depth=1
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB90_55
// %bb.11:                              //   in Loop: Header=BB90_9 Depth=1
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x25, x11, x8, ne
	add	x8, x25, x25, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x23, x23, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x23, #8]
	str	x26, [x23]
	b.lt	.LBB90_13
// %bb.12:                              //   in Loop: Header=BB90_9 Depth=1
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB90_13:                              //   in Loop: Header=BB90_9 Depth=1
	cbz	x20, .LBB90_15
// %bb.14:                              //   in Loop: Header=BB90_9 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB90_15:                              //   in Loop: Header=BB90_9 Depth=1
	madd	x9, x25, x28, x22
	add	x8, x23, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	lsr	x25, x24, #3
	tst	x24, #0x38
	mov	x24, x25
	b.eq	.LBB90_9
	b	.LBB90_2
.LBB90_16:
	ldr	x8, [x19, #32]
	mov	x27, #9223372036854775800
	mov	w28, #24
	mov	w26, #4
	b	.LBB90_18
.LBB90_17:                              //   in Loop: Header=BB90_18 Depth=1
	stp	xzr, xzr, [x8, #8]
	str	x26, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	lsr	x24, x25, #2
	tst	x25, #0xc
	mov	x25, x24
	b.ne	.LBB90_4
.LBB90_18:                              // =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB90_17
// %bb.19:                              //   in Loop: Header=BB90_18 Depth=1
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB90_55
// %bb.20:                              //   in Loop: Header=BB90_18 Depth=1
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x24, x11, x8, ne
	add	x8, x24, x24, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x23, x23, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x23, #8]
	str	x26, [x23]
	b.lt	.LBB90_22
// %bb.21:                              //   in Loop: Header=BB90_18 Depth=1
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB90_22:                              //   in Loop: Header=BB90_18 Depth=1
	cbz	x20, .LBB90_24
// %bb.23:                              //   in Loop: Header=BB90_18 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB90_24:                              //   in Loop: Header=BB90_18 Depth=1
	madd	x9, x24, x28, x22
	add	x8, x23, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	lsr	x24, x25, #2
	tst	x25, #0xc
	mov	x25, x24
	b.eq	.LBB90_18
	b	.LBB90_4
.LBB90_25:
	ldr	x20, [x19, #24]
	sub	x22, x8, x20
	mov	x8, #9223372036854775800
	cmp	x22, x8
	b.eq	.LBB90_55
// %bb.26:
	mov	x9, #-6148914691236517206
	asr	x8, x22, #3
	movk	x9, #43691
	cmp	x22, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x26, x11, x8, ne
	add	x8, x26, x26, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	mov	w8, #24
	mov	x21, x0
	cmp	x22, #1
	madd	x25, x23, x8, x0
	mov	w8, #2
	stp	xzr, xzr, [x25, #8]
	str	x8, [x25]
	b.lt	.LBB90_28
// %bb.27:
	mov	x0, x21
	mov	x1, x20
	mov	x2, x22
	bl	memmove
.LBB90_28:
	add	x22, x25, #24
	cbz	x20, .LBB90_30
// %bb.29:
	mov	x0, x20
	bl	_ZdlPv
.LBB90_30:
	mov	w8, #24
	stp	x21, x22, [x19, #24]
	madd	x8, x26, x8, x21
	str	x8, [x19, #40]
.LBB90_31:
	ldr	x8, [x25]
	lsr	x24, x24, #1
	ldr	x9, [x21]
	str	x8, [x21]
	str	x9, [x25]
.LBB90_32:
	cmp	x24, #9
	b.hs	.LBB90_36
.LBB90_33:
	cmp	x24, #1
	b.ls	.LBB90_54
// %bb.34:
	ldp	x8, x9, [x19, #32]
	cmp	x8, x9
	b.eq	.LBB90_48
// %bb.35:
	stp	xzr, xzr, [x8, #8]
	str	x24, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	b	.LBB90_54
.LBB90_36:
	mov	w25, #3
	mov	x27, #9223372036854775800
	mov	w28, #24
	b	.LBB90_38
.LBB90_37:                              //   in Loop: Header=BB90_38 Depth=1
	add	x25, x25, #2
	mul	x8, x25, x25
	cmp	x8, x24
	b.hi	.LBB90_33
.LBB90_38:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB90_41 Depth 2
	udiv	x8, x24, x25
	msub	x8, x8, x25, x24
	cbnz	x8, .LBB90_37
// %bb.39:                              //   in Loop: Header=BB90_38 Depth=1
	ldr	x8, [x19, #32]
	b	.LBB90_41
.LBB90_40:                              //   in Loop: Header=BB90_41 Depth=2
	stp	xzr, xzr, [x8, #8]
	str	x25, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	udiv	x24, x24, x25
	udiv	x9, x24, x25
	msub	x9, x9, x25, x24
	cbnz	x9, .LBB90_37
.LBB90_41:                              //   Parent Loop BB90_38 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB90_40
// %bb.42:                              //   in Loop: Header=BB90_41 Depth=2
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB90_55
// %bb.43:                              //   in Loop: Header=BB90_41 Depth=2
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x26, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x26, xzr, ne
	adds	x8, x8, x26
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x23, x11, x8, ne
	add	x8, x23, x23, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x26, x26, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x26, #8]
	str	x25, [x26]
	b.lt	.LBB90_45
// %bb.44:                              //   in Loop: Header=BB90_41 Depth=2
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB90_45:                              //   in Loop: Header=BB90_41 Depth=2
	cbz	x20, .LBB90_47
// %bb.46:                              //   in Loop: Header=BB90_41 Depth=2
	mov	x0, x20
	bl	_ZdlPv
.LBB90_47:                              //   in Loop: Header=BB90_41 Depth=2
	madd	x9, x23, x28, x22
	add	x8, x26, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	udiv	x24, x24, x25
	udiv	x9, x24, x25
	msub	x9, x9, x25, x24
	cbz	x9, .LBB90_41
	b	.LBB90_37
.LBB90_48:
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	mov	x8, #9223372036854775800
	cmp	x21, x8
	b.eq	.LBB90_55
// %bb.49:
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x25, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x25, xzr, ne
	adds	x8, x8, x25
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x23, x11, x8, ne
	add	x8, x23, x23, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	mov	w8, #24
	mov	x22, x0
	cmp	x21, #1
	madd	x25, x25, x8, x0
	stp	xzr, xzr, [x25, #8]
	str	x24, [x25]
	b.lt	.LBB90_51
// %bb.50:
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB90_51:
	add	x21, x25, #24
	cbz	x20, .LBB90_53
// %bb.52:
	mov	x0, x20
	bl	_ZdlPv
.LBB90_53:
	mov	w8, #24
	stp	x22, x21, [x19, #24]
	madd	x8, x23, x8, x22
	str	x8, [x19, #40]
.LBB90_54:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB90_55:
	adrp	x0, .L.str.2
	add	x0, x0, :lo12:.L.str.2
	bl	_ZSt20__throw_length_errorPKc
.Lfunc_end90:
	.size	_ZN9pocketfft6detail5cfftpIdE9factorizeEv, .Lfunc_end90-_ZN9pocketfft6detail5cfftpIdE9factorizeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv,"axG",@progbits,_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv,comdat
	.weak	_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv // -- Begin function _ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv,@function
_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv: // @_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x19, x0
	ldr	x1, [x0]
	add	x0, sp, #8
	bl	_ZN9pocketfft6detail13sincos_2pibynIdEC2Em
	ldp	x13, x8, [x19, #24]
	cmp	x8, x13
	b.eq	.LBB91_19
// %bb.1:
	mov	x11, #-6148914691236517206
	mov	x8, xzr
	mov	x9, xzr
	mov	w14, #1
	mov	w10, #24
	movk	x11, #43691
	b	.LBB91_4
.LBB91_2:                               //   in Loop: Header=BB91_4 Depth=1
	add	x8, x8, x13
.LBB91_3:                               //   in Loop: Header=BB91_4 Depth=1
	ldp	x13, x14, [x19, #24]
	add	x9, x9, #1
	sub	x14, x14, x13
	asr	x14, x14, #3
	mul	x15, x14, x11
	mov	x14, x12
	cmp	x9, x15
	b.hs	.LBB91_19
.LBB91_4:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB91_8 Depth 2
                                        //       Child Loop BB91_11 Depth 3
                                        //     Child Loop BB91_17 Depth 2
	madd	x17, x9, x10, x13
	ldp	x15, x18, [x19]
	ldr	x13, [x17]
	add	x18, x18, x8, lsl #4
	mul	x12, x13, x14
	sub	x0, x13, #1
	cmp	x13, #2
	str	x18, [x17, #8]
	udiv	x15, x15, x12
	sub	x16, x15, #1
	madd	x8, x16, x0, x8
	b.lo	.LBB91_3
// %bb.5:                               //   in Loop: Header=BB91_4 Depth=1
	cmp	x15, #2
	b.lo	.LBB91_13
// %bb.6:                               //   in Loop: Header=BB91_4 Depth=1
	lsl	x17, x14, #1
	neg	x18, x14
	mov	x0, x17
	mov	x1, x14
	mov	w2, #1
	b	.LBB91_8
.LBB91_7:                               //   in Loop: Header=BB91_8 Depth=2
	add	x2, x2, #1
	sub	x18, x18, x14
	add	x1, x1, x14
	add	x0, x0, x17
	cmp	x2, x13
	b.eq	.LBB91_13
.LBB91_8:                               //   Parent Loop BB91_4 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB91_11 Depth 3
	sub	x3, x2, #1
	mov	x4, x1
	mov	x6, x18
	mov	w7, #1
	mul	x5, x3, x16
	mov	x3, x0
	sub	x5, x5, #1
	b	.LBB91_11
.LBB91_9:                               //   in Loop: Header=BB91_11 Depth=3
	ldp	x21, x23, [sp, #16]
	add	x20, x6, x20
	ldr	x22, [sp, #32]
	ldr	x24, [sp, #48]
	and	x21, x21, x20
	lsr	x20, x20, x23
	add	x21, x22, x21, lsl #4
	add	x20, x24, x20, lsl #4
	ldp	d5, d0, [x21]
	ldp	d2, d3, [x20]
	fneg	d1, d0
	fmul	d4, d0, d2
	fmul	d1, d3, d1
	fmadd	d0, d5, d2, d1
	fnmadd	d1, d5, d3, d4
.LBB91_10:                              //   in Loop: Header=BB91_11 Depth=3
	ldr	x20, [x19, #24]
	add	x21, x5, x7
	add	x7, x7, #1
	add	x6, x6, x18
	add	x4, x4, x1
	add	x3, x3, x0
	madd	x20, x9, x10, x20
	cmp	x7, x15
	ldr	x20, [x20, #8]
	add	x20, x20, x21, lsl #4
	stp	d0, d1, [x20]
	b.eq	.LBB91_7
.LBB91_11:                              //   Parent Loop BB91_4 Depth=1
                                        //     Parent Loop BB91_8 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	x20, [sp, #8]
	cmp	x3, x20
	b.hi	.LBB91_9
// %bb.12:                              //   in Loop: Header=BB91_11 Depth=3
	ldp	x20, x22, [sp, #16]
	ldr	x21, [sp, #32]
	ldr	x23, [sp, #48]
	and	x20, x20, x4
	add	x20, x21, x20, lsl #4
	lsr	x21, x4, x22
	add	x21, x23, x21, lsl #4
	ldp	d5, d0, [x20]
	ldp	d2, d3, [x21]
	fneg	d1, d0
	fmul	d4, d0, d2
	fmul	d1, d3, d1
	fmadd	d0, d5, d2, d1
	fmadd	d1, d5, d3, d4
	b	.LBB91_10
.LBB91_13:                              //   in Loop: Header=BB91_4 Depth=1
	cmp	x13, #12
	b.lo	.LBB91_3
// %bb.14:                              //   in Loop: Header=BB91_4 Depth=1
	ldr	x18, [x19, #24]
	mul	x14, x15, x14
	ldr	x0, [x19, #8]
	mov	x16, xzr
	mov	x17, xzr
	mov	x15, x13
	madd	x18, x9, x10, x18
	add	x0, x0, x8, lsl #4
	str	x0, [x18, #16]
	b	.LBB91_17
.LBB91_15:                              //   in Loop: Header=BB91_17 Depth=2
	ldp	x1, x2, [sp, #16]
	sub	x18, x0, x18
	ldr	x0, [sp, #32]
	ldr	x3, [sp, #48]
	and	x1, x1, x18
	lsr	x18, x18, x2
	add	x0, x0, x1, lsl #4
	add	x18, x3, x18, lsl #4
	ldp	d5, d0, [x0]
	ldp	d2, d3, [x18]
	fneg	d1, d0
	fmul	d4, d0, d2
	fmul	d1, d3, d1
	fmadd	d0, d5, d2, d1
	fnmadd	d1, d5, d3, d4
.LBB91_16:                              //   in Loop: Header=BB91_17 Depth=2
	ldr	x18, [x19, #24]
	add	x17, x17, #1
	subs	x15, x15, #1
	madd	x18, x9, x10, x18
	ldr	x18, [x18, #16]
	add	x18, x18, x16
	add	x16, x16, #16
	stp	d0, d1, [x18]
	b.eq	.LBB91_2
.LBB91_17:                              //   Parent Loop BB91_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mul	x18, x14, x17
	ldr	x0, [sp, #8]
	cmp	x0, x18, lsl #1
	b.lo	.LBB91_15
// %bb.18:                              //   in Loop: Header=BB91_17 Depth=2
	ldp	x0, x2, [sp, #16]
	ldr	x1, [sp, #32]
	ldr	x3, [sp, #48]
	and	x0, x0, x18
	lsr	x18, x18, x2
	add	x0, x1, x0, lsl #4
	add	x18, x3, x18, lsl #4
	ldp	d5, d0, [x0]
	ldp	d2, d3, [x18]
	fneg	d1, d0
	fmul	d4, d0, d2
	fmul	d1, d3, d1
	fmadd	d0, d5, d2, d1
	fmadd	d1, d5, d3, d4
	b	.LBB91_16
.LBB91_19:
	ldr	x8, [sp, #48]
	cbz	x8, .LBB91_21
// %bb.20:
	ldur	x0, [x8, #-8]
	bl	free
.LBB91_21:
	ldr	x8, [sp, #32]
	cbz	x8, .LBB91_23
// %bb.22:
	ldur	x0, [x8, #-8]
	bl	free
.LBB91_23:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.Lfunc_end91:
	.size	_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv, .Lfunc_end91-_ZN9pocketfft6detail5cfftpIdE12comp_twiddleEv
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIdEC2Em
.LCPI92_0:
	.xword	0x8469898cc51701b8              // fp128 0.785398163397448309615660845819875699
	.xword	0x3ffe921fb54442d1
.LCPI92_1:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIdEC2Em,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIdEC2Em,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIdEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIdEC2Em,@function
_ZN9pocketfft6detail13sincos_2pibynIdEC2Em: // @_ZN9pocketfft6detail13sincos_2pibynIdEC2Em
.Lfunc_begin36:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception36
// %bb.0:
	sub	sp, sp, #96
	str	d8, [sp, #16]                   // 8-byte Folded Spill
	stp	x29, x30, [sp, #24]             // 16-byte Folded Spill
	add	x29, sp, #24
	str	x25, [sp, #40]                  // 8-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 72
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w30, -64
	.cfi_offset w29, -72
	.cfi_offset b8, -80
	movi	v0.2d, #0000000000000000
	mov	x19, x0
	mov	x22, x0
	str	x1, [x0]
	mov	x0, x1
	mov	x20, x1
	str	q0, [x22, #24]!
	bl	__floatunditf
	adrp	x8, .LCPI92_0
	mov	v1.16b, v0.16b
	ldr	q0, [x8, :lo12:.LCPI92_0]
	bl	__divtf3
	add	x8, x20, #2
	mov	x21, xzr
	movi	v1.2d, #0000000000000000
	lsr	x23, x8, #1
	mov	w8, #1
	stur	q1, [x19, #40]
.LBB92_1:                               // =>This Inner Loop Header: Depth=1
	add	x21, x21, #1
	lsl	x25, x8, x21
	lsl	x9, x25, x21
	cmp	x9, x23
	b.lo	.LBB92_1
// %bb.2:
	bl	__trunctfdf2
	lsl	x8, x25, #4
	sub	x24, x25, #1
	add	x0, x8, #64
	fmov	d8, d0
	stp	x24, x21, [x19, #8]
	bl	malloc
	cbz	x0, .LBB92_21
// %bb.3:
	adrp	x9, .LCPI92_1
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	ldr	q0, [x9, :lo12:.LCPI92_1]
	stur	x0, [x8, #-8]
	stp	x8, x25, [x19, #24]
	str	q0, [sp]                        // 16-byte Folded Spill
	str	q0, [x8]
	cbz	x21, .LBB92_9
// %bb.4:
	mov	x24, xzr
	mov	w21, #1
.LBB92_5:                               // =>This Inner Loop Header: Depth=1
.Ltmp520:
	fmov	d0, d8
	mov	x0, x21
	mov	x1, x20
	bl	_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd
.Ltmp521:
// %bb.6:                               //   in Loop: Header=BB92_5 Depth=1
	ldr	x8, [x19, #24]
	add	x21, x21, #1
	add	x8, x8, x24
	add	x24, x24, #16
	stp	d0, d1, [x8, #16]
	ldr	x8, [x19, #32]
	cmp	x21, x8
	b.lo	.LBB92_5
// %bb.7:
	ldr	x24, [x19, #8]
	ldp	x8, x9, [x19, #40]
	add	x23, x24, x23
	add	x24, x24, #1
	udiv	x21, x23, x24
	cmp	x9, x21
	b.ne	.LBB92_10
.LBB92_8:
	ldr	q0, [sp]                        // 16-byte Folded Reload
	cmp	x9, #2
	str	q0, [x8]
	b.hs	.LBB92_17
	b	.LBB92_20
.LBB92_9:
	mov	x9, xzr
	add	x23, x24, x23
	add	x24, x24, #1
	ldr	x8, [x19, #40]
	udiv	x21, x23, x24
	cmp	x9, x21
	b.eq	.LBB92_8
.LBB92_10:
	cbz	x8, .LBB92_12
// %bb.11:
	ldur	x0, [x8, #-8]
	bl	free
.LBB92_12:
	cmp	x24, x23
	b.ls	.LBB92_14
// %bb.13:
	mov	x8, xzr
	b	.LBB92_16
.LBB92_14:
	lsl	x8, x21, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB92_23
// %bb.15:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
.LBB92_16:
	mov	x9, x21
	stp	x8, x21, [x19, #40]
	ldr	q0, [sp]                        // 16-byte Folded Reload
	cmp	x9, #2
	str	q0, [x8]
	b.lo	.LBB92_20
.LBB92_17:
	mov	x21, xzr
	mov	w23, #1
.LBB92_18:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #8]
	madd	x0, x23, x8, x23
.Ltmp525:
	fmov	d0, d8
	mov	x1, x20
	bl	_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd
.Ltmp526:
// %bb.19:                              //   in Loop: Header=BB92_18 Depth=1
	ldr	x8, [x19, #40]
	add	x23, x23, #1
	add	x8, x8, x21
	add	x21, x21, #16
	stp	d0, d1, [x8, #16]
	ldr	x8, [x19, #48]
	cmp	x23, x8
	b.lo	.LBB92_18
.LBB92_20:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #24]             // 16-byte Folded Reload
	ldr	x25, [sp, #40]                  // 8-byte Folded Reload
	ldr	d8, [sp, #16]                   // 8-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB92_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp528:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp529:
// %bb.22:
.LBB92_23:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp523:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp524:
// %bb.24:
.LBB92_25:
.Ltmp530:
	b	.LBB92_28
.LBB92_26:
.Ltmp527:
	b	.LBB92_28
.LBB92_27:
.Ltmp522:
.LBB92_28:
	mov	x20, x0
	ldr	x8, [x19, #40]
	cbnz	x8, .LBB92_31
// %bb.29:
	ldr	x8, [x22]
	cbnz	x8, .LBB92_32
.LBB92_30:
	mov	x0, x20
	bl	_Unwind_Resume
.LBB92_31:
	ldur	x0, [x8, #-8]
	bl	free
	ldr	x8, [x22]
	cbz	x8, .LBB92_30
.LBB92_32:
	ldur	x0, [x8, #-8]
	bl	free
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end92:
	.size	_ZN9pocketfft6detail13sincos_2pibynIdEC2Em, .Lfunc_end92-_ZN9pocketfft6detail13sincos_2pibynIdEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail13sincos_2pibynIdEC2Em,"aG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIdEC2Em,comdat
	.p2align	2
GCC_except_table92:
.Lexception36:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end36-.Lcst_begin36
.Lcst_begin36:
	.uleb128 .Lfunc_begin36-.Lfunc_begin36  // >> Call Site 1 <<
	.uleb128 .Ltmp520-.Lfunc_begin36        //   Call between .Lfunc_begin36 and .Ltmp520
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp520-.Lfunc_begin36        // >> Call Site 2 <<
	.uleb128 .Ltmp521-.Ltmp520              //   Call between .Ltmp520 and .Ltmp521
	.uleb128 .Ltmp522-.Lfunc_begin36        //     jumps to .Ltmp522
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp525-.Lfunc_begin36        // >> Call Site 3 <<
	.uleb128 .Ltmp526-.Ltmp525              //   Call between .Ltmp525 and .Ltmp526
	.uleb128 .Ltmp527-.Lfunc_begin36        //     jumps to .Ltmp527
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp526-.Lfunc_begin36        // >> Call Site 4 <<
	.uleb128 .Ltmp528-.Ltmp526              //   Call between .Ltmp526 and .Ltmp528
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp528-.Lfunc_begin36        // >> Call Site 5 <<
	.uleb128 .Ltmp529-.Ltmp528              //   Call between .Ltmp528 and .Ltmp529
	.uleb128 .Ltmp530-.Lfunc_begin36        //     jumps to .Ltmp530
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp529-.Lfunc_begin36        // >> Call Site 6 <<
	.uleb128 .Ltmp523-.Ltmp529              //   Call between .Ltmp529 and .Ltmp523
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp523-.Lfunc_begin36        // >> Call Site 7 <<
	.uleb128 .Ltmp524-.Ltmp523              //   Call between .Ltmp523 and .Ltmp524
	.uleb128 .Ltmp530-.Lfunc_begin36        //     jumps to .Ltmp530
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp524-.Lfunc_begin36        // >> Call Site 8 <<
	.uleb128 .Lfunc_end92-.Ltmp524          //   Call between .Ltmp524 and .Lfunc_end92
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end36:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIdED2Ev,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIdED2Ev,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIdED2Ev // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIdED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIdED2Ev,@function
_ZN9pocketfft6detail13sincos_2pibynIdED2Ev: // @_ZN9pocketfft6detail13sincos_2pibynIdED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x8, [x0, #40]
	cbz	x8, .LBB93_2
// %bb.1:
	ldur	x0, [x8, #-8]
	bl	free
.LBB93_2:
	ldr	x8, [x19, #24]
	cbz	x8, .LBB93_4
// %bb.3:
	ldur	x0, [x8, #-8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	free
.LBB93_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end93:
	.size	_ZN9pocketfft6detail13sincos_2pibynIdED2Ev, .Lfunc_end93-_ZN9pocketfft6detail13sincos_2pibynIdED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd,@function
_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd: // @_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd
	.cfi_startproc
// %bb.0:
	stp	d9, d8, [sp, #-32]!             // 16-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset b8, -24
	.cfi_offset b9, -32
	lsl	x8, x0, #3
	cmp	x8, x1, lsl #2
	b.hs	.LBB94_4
// %bb.1:
	lsl	x9, x1, #1
	subs	x10, x8, x9
	b.hs	.LBB94_7
// %bb.2:
	cmp	x8, x1
	b.hs	.LBB94_11
// %bb.3:
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fmov	d8, d0
	b	.LBB94_16
.LBB94_4:
	sub	x8, x1, x0
	lsl	x9, x8, #3
	lsl	x8, x1, #1
	subs	x10, x9, x8
	b.hs	.LBB94_9
// %bb.5:
	cmp	x9, x1
	b.hs	.LBB94_13
// %bb.6:
	ucvtf	d1, x9
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fmov	d8, d0
	b	.LBB94_18
.LBB94_7:
	cmp	x10, x1
	b.hs	.LBB94_15
// %bb.8:
	ucvtf	d1, x10
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fneg	d8, d0
	b	.LBB94_12
.LBB94_9:
	cmp	x10, x1
	b.hs	.LBB94_17
// %bb.10:
	ucvtf	d1, x10
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fneg	d8, d0
	b	.LBB94_14
.LBB94_11:
	sub	x8, x9, x8
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fmov	d8, d0
.LBB94_12:
	fmov	d0, d9
	bl	cos
	fmov	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.LBB94_13:
	sub	x8, x8, x9
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fmov	d8, d0
.LBB94_14:
	fmov	d0, d9
	bl	cos
	fneg	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.LBB94_15:
	sub	x8, x9, x10
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fneg	d8, d0
.LBB94_16:
	fmov	d0, d9
	bl	sin
	fmov	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.LBB94_17:
	sub	x8, x8, x10
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fneg	d8, d0
.LBB94_18:
	fmov	d0, d9
	bl	sin
	fneg	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.Lfunc_end94:
	.size	_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd, .Lfunc_end94-_ZN9pocketfft6detail13sincos_2pibynIdE4calcEmmd
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIdED2Ev,"axG",@progbits,_ZN9pocketfft6detail5cfftpIdED2Ev,comdat
	.weak	_ZN9pocketfft6detail5cfftpIdED2Ev // -- Begin function _ZN9pocketfft6detail5cfftpIdED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIdED2Ev,@function
_ZN9pocketfft6detail5cfftpIdED2Ev:      // @_ZN9pocketfft6detail5cfftpIdED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x0, [x0, #24]
	cbz	x0, .LBB95_2
// %bb.1:
	bl	_ZdlPv
.LBB95_2:
	ldr	x8, [x19, #8]
	cbz	x8, .LBB95_4
// %bb.3:
	ldur	x0, [x8, #-8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	free
.LBB95_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end95:
	.size	_ZN9pocketfft6detail5cfftpIdED2Ev, .Lfunc_end95-_ZN9pocketfft6detail5cfftpIdED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d // -- Begin function _ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,@function
_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d: // @_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
.Lfunc_begin37:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception37
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x20, x0
	ldr	x23, [x0]
	mov	x19, x1
                                        // kill: def $d0 killed $d0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB96_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB96_4
// %bb.2:
	ldr	q0, [x19]
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.2d, v0.2d, v1.d[0]
	str	q0, [x19]
	b	.LBB96_41
.LBB96_3:
	mov	x22, xzr
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.ne	.LBB96_6
	b	.LBB96_23
.LBB96_4:
	lsl	x8, x23, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB96_42
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.eq	.LBB96_23
.LBB96_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI96_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x19
	add	x27, x27, :lo12:.LJTI96_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB96_17
.LBB96_7:
	adr	x10, .LBB96_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB96_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp539:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp540:
	mov	x0, x21
	mov	x21, x22
	b	.LBB96_15
.LBB96_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp537:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp538:
	mov	x0, x21
	mov	x21, x22
	b	.LBB96_15
.LBB96_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp543:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp544:
	mov	x0, x21
	mov	x21, x22
	b	.LBB96_15
.LBB96_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp535:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp536:
	mov	x0, x21
	mov	x21, x22
	b	.LBB96_15
.LBB96_12:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp533:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp534:
	mov	x0, x21
	mov	x21, x22
	b	.LBB96_15
.LBB96_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp541:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp542:
	mov	x0, x21
	mov	x21, x22
	b	.LBB96_15
.LBB96_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp531:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp532:
	mov	x0, x21
	mov	x21, x22
.LBB96_15:
	ldp	x8, x9, [x20, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB96_18
// %bb.16:
	ldr	x23, [x20]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB96_7
.LBB96_17:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp545:
	mov	x0, x20
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
.Ltmp546:
	mov	x0, x22
	b	.LBB96_15
.LBB96_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x19
	b.eq	.LBB96_23
// %bb.19:
	fmov	d0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x20]
	fcmp	d1, d0
	b.eq	.LBB96_27
// %bb.20:
	cbz	x8, .LBB96_39
// %bb.21:
	mov	x8, xzr
.LBB96_22:                              // =>This Inner Loop Header: Depth=1
	lsl	x9, x8, #4
	add	x8, x8, #1
	ldr	q0, [x22, x9]
	fmul	v0.2d, v0.2d, v1.d[0]
	str	q0, [x19, x9]
	ldr	x9, [x20]
	cmp	x8, x9
	b.lo	.LBB96_22
	b	.LBB96_40
.LBB96_23:
	fmov	d0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fcmp	d1, d0
	b.eq	.LBB96_39
// %bb.24:
	ldr	x8, [x20]
	cbz	x8, .LBB96_39
// %bb.25:
	cmp	x8, #4
	b.hs	.LBB96_29
// %bb.26:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	mov	x9, xzr
	b	.LBB96_37
.LBB96_27:
	cbz	x8, .LBB96_39
// %bb.28:
	lsl	x2, x8, #4
	mov	x0, x19
	mov	x1, x21
	bl	memmove
	b	.LBB96_39
.LBB96_29:
	sub	x10, x8, #1
	mov	x9, xzr
	lsl	x11, x10, #4
	cmp	xzr, x10, lsr #60
	add	x12, x19, x11
	cset	w10, ne
	cmp	x12, x19
	b.lo	.LBB96_36
// %bb.30:
	tbnz	w10, #0, .LBB96_36
// %bb.31:
	add	x12, x19, #8
	add	x11, x12, x11
	cmp	x11, x12
	b.lo	.LBB96_36
// %bb.32:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	tbnz	w10, #0, .LBB96_37
// %bb.33:
	and	x9, x8, #0xfffffffffffffffc
	add	x10, x19, #32
	mov	x11, x9
	dup	v0.2d, v7.d[0]
.LBB96_34:                              // =>This Inner Loop Header: Depth=1
	ld2	{ v1.2d, v2.2d }, [x10]
	sub	x12, x10, #32
	subs	x11, x11, #4
	ld2	{ v3.2d, v4.2d }, [x12]
	fmul	v5.2d, v1.2d, v7.d[0]
	fmul	v6.2d, v2.2d, v7.d[0]
	fmul	v1.2d, v3.2d, v0.2d
	fmul	v2.2d, v4.2d, v0.2d
	st2	{ v5.2d, v6.2d }, [x10]
	add	x10, x10, #64
	st2	{ v1.2d, v2.2d }, [x12]
	b.ne	.LBB96_34
// %bb.35:
	cmp	x8, x9
	b.ne	.LBB96_37
	b	.LBB96_39
.LBB96_36:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
.LBB96_37:
	sub	x8, x8, x9
	add	x9, x19, x9, lsl #4
.LBB96_38:                              // =>This Inner Loop Header: Depth=1
	ldr	q0, [x9]
	subs	x8, x8, #1
	fmul	v0.2d, v0.2d, v7.d[0]
	str	q0, [x9], #16
	b.ne	.LBB96_38
.LBB96_39:
	cbz	x22, .LBB96_41
.LBB96_40:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB96_41:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB96_42:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB96_43:
.Ltmp547:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB96_45
// %bb.44:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB96_45:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end96:
	.size	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d, .Lfunc_end96-_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,comdat
.LJTI96_0:
	.byte	(.LBB96_8-.LBB96_8)>>2
	.byte	(.LBB96_9-.LBB96_8)>>2
	.byte	(.LBB96_10-.LBB96_8)>>2
	.byte	(.LBB96_11-.LBB96_8)>>2
	.byte	(.LBB96_17-.LBB96_8)>>2
	.byte	(.LBB96_12-.LBB96_8)>>2
	.byte	(.LBB96_13-.LBB96_8)>>2
	.byte	(.LBB96_17-.LBB96_8)>>2
	.byte	(.LBB96_17-.LBB96_8)>>2
	.byte	(.LBB96_14-.LBB96_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d,comdat
	.p2align	2
GCC_except_table96:
.Lexception37:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end37-.Lcst_begin37
.Lcst_begin37:
	.uleb128 .Ltmp539-.Lfunc_begin37        // >> Call Site 1 <<
	.uleb128 .Ltmp546-.Ltmp539              //   Call between .Ltmp539 and .Ltmp546
	.uleb128 .Ltmp547-.Lfunc_begin37        //     jumps to .Ltmp547
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp546-.Lfunc_begin37        // >> Call Site 2 <<
	.uleb128 .Lfunc_end96-.Ltmp546          //   Call between .Ltmp546 and .Lfunc_end96
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end37:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d // -- Begin function _ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,@function
_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d: // @_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d
.Lfunc_begin38:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception38
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x20, x0
	ldr	x23, [x0]
	mov	x19, x1
                                        // kill: def $d0 killed $d0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB97_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB97_4
// %bb.2:
	ldr	q0, [x19]
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.2d, v0.2d, v1.d[0]
	str	q0, [x19]
	b	.LBB97_41
.LBB97_3:
	mov	x22, xzr
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.ne	.LBB97_6
	b	.LBB97_23
.LBB97_4:
	lsl	x8, x23, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB97_42
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.eq	.LBB97_23
.LBB97_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI97_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x19
	add	x27, x27, :lo12:.LJTI97_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB97_17
.LBB97_7:
	adr	x10, .LBB97_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB97_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp556:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp557:
	mov	x0, x21
	mov	x21, x22
	b	.LBB97_15
.LBB97_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp554:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp555:
	mov	x0, x21
	mov	x21, x22
	b	.LBB97_15
.LBB97_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp560:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp561:
	mov	x0, x21
	mov	x21, x22
	b	.LBB97_15
.LBB97_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp552:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp553:
	mov	x0, x21
	mov	x21, x22
	b	.LBB97_15
.LBB97_12:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp550:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp551:
	mov	x0, x21
	mov	x21, x22
	b	.LBB97_15
.LBB97_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp558:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp559:
	mov	x0, x21
	mov	x21, x22
	b	.LBB97_15
.LBB97_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp548:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.Ltmp549:
	mov	x0, x21
	mov	x21, x22
.LBB97_15:
	ldp	x8, x9, [x20, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB97_18
// %bb.16:
	ldr	x23, [x20]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB97_7
.LBB97_17:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp562:
	mov	x0, x20
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
.Ltmp563:
	mov	x0, x22
	b	.LBB97_15
.LBB97_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x19
	b.eq	.LBB97_23
// %bb.19:
	fmov	d0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x20]
	fcmp	d1, d0
	b.eq	.LBB97_27
// %bb.20:
	cbz	x8, .LBB97_39
// %bb.21:
	mov	x8, xzr
.LBB97_22:                              // =>This Inner Loop Header: Depth=1
	lsl	x9, x8, #4
	add	x8, x8, #1
	ldr	q0, [x22, x9]
	fmul	v0.2d, v0.2d, v1.d[0]
	str	q0, [x19, x9]
	ldr	x9, [x20]
	cmp	x8, x9
	b.lo	.LBB97_22
	b	.LBB97_40
.LBB97_23:
	fmov	d0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fcmp	d1, d0
	b.eq	.LBB97_39
// %bb.24:
	ldr	x8, [x20]
	cbz	x8, .LBB97_39
// %bb.25:
	cmp	x8, #4
	b.hs	.LBB97_29
// %bb.26:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	mov	x9, xzr
	b	.LBB97_37
.LBB97_27:
	cbz	x8, .LBB97_39
// %bb.28:
	lsl	x2, x8, #4
	mov	x0, x19
	mov	x1, x21
	bl	memmove
	b	.LBB97_39
.LBB97_29:
	sub	x10, x8, #1
	mov	x9, xzr
	lsl	x11, x10, #4
	cmp	xzr, x10, lsr #60
	add	x12, x19, x11
	cset	w10, ne
	cmp	x12, x19
	b.lo	.LBB97_36
// %bb.30:
	tbnz	w10, #0, .LBB97_36
// %bb.31:
	add	x12, x19, #8
	add	x11, x12, x11
	cmp	x11, x12
	b.lo	.LBB97_36
// %bb.32:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	tbnz	w10, #0, .LBB97_37
// %bb.33:
	and	x9, x8, #0xfffffffffffffffc
	add	x10, x19, #32
	mov	x11, x9
	dup	v0.2d, v7.d[0]
.LBB97_34:                              // =>This Inner Loop Header: Depth=1
	ld2	{ v1.2d, v2.2d }, [x10]
	sub	x12, x10, #32
	subs	x11, x11, #4
	ld2	{ v3.2d, v4.2d }, [x12]
	fmul	v5.2d, v1.2d, v7.d[0]
	fmul	v6.2d, v2.2d, v7.d[0]
	fmul	v1.2d, v3.2d, v0.2d
	fmul	v2.2d, v4.2d, v0.2d
	st2	{ v5.2d, v6.2d }, [x10]
	add	x10, x10, #64
	st2	{ v1.2d, v2.2d }, [x12]
	b.ne	.LBB97_34
// %bb.35:
	cmp	x8, x9
	b.ne	.LBB97_37
	b	.LBB97_39
.LBB97_36:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
.LBB97_37:
	sub	x8, x8, x9
	add	x9, x19, x9, lsl #4
.LBB97_38:                              // =>This Inner Loop Header: Depth=1
	ldr	q0, [x9]
	subs	x8, x8, #1
	fmul	v0.2d, v0.2d, v7.d[0]
	str	q0, [x9], #16
	b.ne	.LBB97_38
.LBB97_39:
	cbz	x22, .LBB97_41
.LBB97_40:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB97_41:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB97_42:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB97_43:
.Ltmp564:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB97_45
// %bb.44:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB97_45:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end97:
	.size	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d, .Lfunc_end97-_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,comdat
.LJTI97_0:
	.byte	(.LBB97_8-.LBB97_8)>>2
	.byte	(.LBB97_9-.LBB97_8)>>2
	.byte	(.LBB97_10-.LBB97_8)>>2
	.byte	(.LBB97_11-.LBB97_8)>>2
	.byte	(.LBB97_17-.LBB97_8)>>2
	.byte	(.LBB97_12-.LBB97_8)>>2
	.byte	(.LBB97_13-.LBB97_8)>>2
	.byte	(.LBB97_17-.LBB97_8)>>2
	.byte	(.LBB97_17-.LBB97_8)>>2
	.byte	(.LBB97_14-.LBB97_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d,comdat
	.p2align	2
GCC_except_table97:
.Lexception38:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end38-.Lcst_begin38
.Lcst_begin38:
	.uleb128 .Ltmp556-.Lfunc_begin38        // >> Call Site 1 <<
	.uleb128 .Ltmp563-.Ltmp556              //   Call between .Ltmp556 and .Ltmp563
	.uleb128 .Ltmp564-.Lfunc_begin38        //     jumps to .Ltmp564
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp563-.Lfunc_begin38        // >> Call Site 2 <<
	.uleb128 .Lfunc_end97-.Ltmp563          //   Call between .Ltmp563 and .Lfunc_end97
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end38:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	str	x23, [sp, #-48]!                // 8-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	subs	x8, x1, #1
	b.ne	.LBB98_4
// %bb.1:
	cbz	x2, .LBB98_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #8
	lsl	x9, x2, #4
	lsl	x10, x10, #4
	lsl	x11, x2, #5
	add	x12, x3, #32
.LBB98_3:                               // =>This Inner Loop Header: Depth=1
	ldp	d0, d1, [x12, #-32]
	add	x13, x8, x11
	add	x14, x8, x9
	ldp	d2, d3, [x12]
	subs	x2, x2, #1
	ldp	d4, d5, [x12, #-16]
	ldp	d6, d7, [x12, #16]
	fadd	d16, d0, d2
	fadd	d18, d1, d3
	fsub	d0, d0, d2
	fsub	d1, d1, d3
	add	x12, x12, #64
	fadd	d17, d4, d6
	fsub	d3, d4, d6
	fadd	d19, d5, d7
	fsub	d2, d5, d7
	fsub	d4, d16, d17
	fadd	d6, d16, d17
	fsub	d5, d18, d19
	fadd	d7, d0, d2
	fsub	d0, d0, d2
	stp	d4, d5, [x13, #-8]
	fadd	d5, d18, d19
	fsub	d4, d1, d3
	fadd	d1, d1, d3
	add	x13, x8, x10
	stp	d6, d5, [x8, #-8]
	add	x8, x8, #16
	stp	d7, d4, [x14, #-8]
	stp	d0, d1, [x13, #-8]
	b.ne	.LBB98_3
	b	.LBB98_10
.LBB98_4:
	cbz	x2, .LBB98_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #48
	lsl	x10, x2, #1
	mov	x9, xzr
	add	x11, x3, #16
	lsl	x12, x1, #6
	madd	x14, x0, x14, x4
	add	x13, x10, x2
	lsl	x15, x1, #4
	add	x16, x5, x8, lsl #5
	add	x17, x4, x0, lsl #5
	add	x18, x5, x8, lsl #4
	add	x0, x4, x0, lsl #4
	mov	x6, x4
	b	.LBB98_7
.LBB98_6:                               //   in Loop: Header=BB98_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x12
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB98_10
.LBB98_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB98_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #4
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #4
	ldp	d0, d1, [x7]
	add	x20, x3, x20, lsl #4
	add	x7, x3, x21, lsl #4
	ldp	d2, d3, [x19]
	mul	x19, x9, x1
	add	x21, x9, x13
	ldp	d4, d5, [x20]
	add	x20, x9, x2
	ldp	d6, d7, [x7]
	fadd	d16, d0, d2
	fadd	d17, d1, d3
	fsub	d0, d0, d2
	add	x7, x9, x10
	fsub	d1, d1, d3
	add	x19, x4, x19, lsl #4
	fadd	d2, d4, d6
	fsub	d3, d4, d6
	fadd	d18, d5, d7
	fsub	d4, d5, d7
	mul	x7, x7, x1
	mul	x20, x20, x1
	fadd	d5, d16, d2
	fsub	d2, d16, d2
	fadd	d6, d17, d18
	fsub	d7, d17, d18
	add	x7, x4, x7, lsl #4
	add	x20, x4, x20, lsl #4
	stp	d5, d6, [x19]
	mul	x19, x21, x1
	fadd	d5, d0, d4
	fsub	d6, d1, d3
	fsub	d0, d0, d4
	fadd	d1, d1, d3
	stp	d2, d7, [x7]
	add	x7, x4, x19, lsl #4
	stp	d5, d6, [x20]
	stp	d0, d1, [x7]
	b.lo	.LBB98_6
// %bb.8:                               //   in Loop: Header=BB98_7 Depth=1
	mov	x7, xzr
	mov	x19, x8
.LBB98_9:                               //   Parent Loop BB98_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x11, x7
	subs	x19, x19, #1
	add	x21, x20, x15
	add	x22, x21, x15
	add	x23, x22, x15
	ldp	d0, d1, [x21]
	add	x21, x18, x7
	ldp	d2, d3, [x23]
	ldp	d4, d7, [x22]
	ldp	d5, d6, [x20]
	fsub	d17, d1, d3
	add	x20, x5, x7
	fsub	d18, d0, d2
	fadd	d0, d0, d2
	fadd	d1, d1, d3
	fsub	d16, d5, d4
	fadd	d4, d5, d4
	fsub	d5, d6, d7
	fadd	d6, d6, d7
	ldp	d2, d19, [x20]
	add	x20, x6, x7
	fadd	d20, d16, d17
	fsub	d7, d4, d0
	fsub	d3, d5, d18
	fsub	d16, d16, d17
	ldp	d21, d22, [x21]
	add	x21, x16, x7
	fadd	d5, d5, d18
	fneg	d23, d20
	fadd	d0, d4, d0
	fmul	d17, d3, d19
	fsub	d4, d6, d1
	fneg	d24, d7
	fadd	d1, d6, d1
	fneg	d6, d16
	fmul	d19, d19, d23
	str	d0, [x20, #16]
	ldp	d23, d18, [x21]
	fmadd	d17, d20, d2, d17
	fmul	d20, d4, d22
	add	x21, x0, x7
	str	d1, [x20, #24]
	fmadd	d2, d3, d2, d19
	fmul	d3, d22, d24
	add	x20, x17, x7
	fmul	d0, d5, d18
	fmul	d6, d18, d6
	fmadd	d1, d7, d21, d20
	str	d17, [x21, #16]
	fmadd	d3, d4, d21, d3
	str	d2, [x21, #24]
	add	x21, x14, x7
	add	x7, x7, #16
	fmadd	d0, d16, d23, d0
	fmadd	d4, d5, d23, d6
	str	d1, [x20, #16]
	str	d3, [x20, #24]
	str	d0, [x21, #16]
	str	d4, [x21, #24]
	b.ne	.LBB98_9
	b	.LBB98_6
.LBB98_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp], #48                  // 8-byte Folded Reload
	ret
.Lfunc_end98:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end98-_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI99_0:
	.xword	0x3fe6a09e667f3bcd              // double 0.70710678118654757
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	str	d8, [sp, #96]                   // 8-byte Folded Spill
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 208
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	subs	x8, x1, #1
	str	x4, [sp, #88]                   // 8-byte Folded Spill
	str	x3, [sp, #104]                  // 8-byte Folded Spill
	b.ne	.LBB99_4
// %bb.1:
	cbz	x2, .LBB99_10
// %bb.2:
	mov	w11, #112
	ldr	x8, [sp, #88]                   // 8-byte Folded Reload
	adrp	x17, .LCPI99_0
	ldr	x16, [sp, #104]                 // 8-byte Folded Reload
	add	x13, x2, x2, lsl #1
	add	x12, x2, x2, lsl #2
	mul	x10, x2, x11
	add	x8, x8, #8
	lsl	x9, x13, #4
	lsl	x11, x12, #4
	lsl	x12, x2, #4
	lsl	x13, x13, #5
	lsl	x14, x2, #5
	lsl	x15, x2, #6
	add	x16, x16, #64
	ldr	d0, [x17, :lo12:.LCPI99_0]
.LBB99_3:                               // =>This Inner Loop Header: Depth=1
	ldp	d1, d2, [x16, #-48]
	add	x17, x8, x15
	add	x18, x8, x13
	ldp	d3, d4, [x16, #16]
	subs	x2, x2, #1
	ldp	d5, d7, [x16, #-16]
	fadd	d6, d1, d3
	fsub	d1, d1, d3
	ldp	d17, d3, [x16, #48]
	fadd	d16, d2, d4
	fsub	d2, d2, d4
	ldp	d4, d19, [x16, #-64]
	fadd	d18, d5, d17
	fsub	d5, d5, d17
	fadd	d20, d7, d3
	fsub	d3, d7, d3
	ldp	d21, d7, [x16]
	ldp	d17, d23, [x16, #-32]
	fsub	d26, d1, d3
	fadd	d1, d1, d3
	ldp	d25, d27, [x16, #32]
	fadd	d28, d4, d21
	fsub	d3, d2, d5
	fadd	d30, d19, d7
	fadd	d22, d6, d18
	fadd	d24, d16, d20
	fadd	d2, d2, d5
	fadd	d29, d17, d25
	fneg	d5, d26
	fadd	d31, d23, d27
	fsub	d16, d16, d20
	fsub	d6, d6, d18
	fadd	d18, d3, d1
	fsub	d1, d3, d1
	fsub	d26, d2, d26
	fadd	d20, d28, d29
	fsub	d2, d5, d2
	fadd	d3, d30, d31
	fsub	d5, d19, d7
	fsub	d19, d28, d29
	fsub	d4, d4, d21
	fsub	d17, d17, d25
	fsub	d28, d30, d31
	fsub	d7, d20, d22
	fsub	d23, d23, d27
	fsub	d21, d3, d24
	fmul	d1, d1, d0
	fmul	d18, d18, d0
	fmul	d25, d26, d0
	fmul	d2, d2, d0
	add	x16, x16, #128
	stur	d7, [x17, #-8]
	fadd	d7, d16, d19
	str	d21, [x17]
	add	x17, x8, x14
	fsub	d16, d19, d16
	fsub	d21, d28, d6
	fadd	d6, d6, d28
	fadd	d19, d4, d23
	stur	d7, [x17, #-8]
	fsub	d7, d5, d17
	fsub	d4, d4, d23
	fadd	d5, d5, d17
	stur	d16, [x18, #-8]
	str	d21, [x17]
	add	x17, x8, x12
	fadd	d16, d1, d7
	str	d6, [x18]
	fadd	d6, d18, d19
	fsub	d1, d7, d1
	add	x18, x8, x11
	fadd	d7, d25, d4
	fsub	d18, d19, d18
	str	d16, [x17]
	fadd	d16, d2, d5
	stur	d6, [x17, #-8]
	add	x17, x8, x9
	fadd	d6, d22, d20
	str	d1, [x18]
	fadd	d1, d24, d3
	fsub	d3, d4, d25
	fsub	d2, d5, d2
	stur	d7, [x17, #-8]
	str	d16, [x17]
	add	x17, x8, x10
	stur	d18, [x18, #-8]
	stur	d6, [x8, #-8]
	str	d1, [x8], #16
	stur	d3, [x17, #-8]
	str	d2, [x17]
	b.ne	.LBB99_3
	b	.LBB99_10
.LBB99_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	cbz	x2, .LBB99_10
// %bb.5:
	lsl	x8, x2, #2
	lsl	x10, x2, #1
	ldr	x16, [sp, #8]                   // 8-byte Folded Reload
	lsl	x13, x1, #7
	mul	x11, x2, x1
	ldr	x4, [sp, #88]                   // 8-byte Folded Reload
	stp	x10, x8, [sp, #64]              // 16-byte Folded Spill
	add	x10, x10, x2
	add	x8, x8, x2
	lsl	x18, x10, #1
	mov	w12, #112
	mov	w14, #48
	mov	x9, xzr
	stp	x8, x10, [sp, #48]              // 16-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	ldr	x10, [sp, #104]                 // 8-byte Folded Reload
	madd	x17, x11, x12, x4
	add	x25, x4, x11, lsl #4
	madd	x7, x11, x14, x4
	add	x30, x4, x11, lsl #5
	stp	x8, x18, [sp, #32]              // 16-byte Folded Spill
	lsl	x8, x1, #4
	madd	x12, x1, x12, x10
	str	x2, [sp, #80]                   // 8-byte Folded Spill
	stp	x13, x8, [sp, #16]              // 16-byte Folded Spill
	add	x8, x8, x10
	add	x18, x8, #24
	add	x8, x16, x16, lsl #2
	lsl	x8, x8, #4
	add	x20, x12, #24
	add	x13, x8, x10
	lsl	x12, x16, #6
	add	x6, x13, #104
	add	x13, x16, x16, lsl #1
	lsl	x15, x13, #4
	lsl	x13, x13, #5
	add	x14, x15, x10
	add	x29, x5, x12
	add	x19, x14, #72
	mov	w14, #80
	add	x26, x5, x13
	add	x8, x5, x8
	madd	x21, x11, x14, x4
	add	x14, x12, x10
	add	x22, x14, #64
	lsl	x14, x16, #5
	add	x3, x14, x10
	adrp	x12, .LCPI99_0
	add	x23, x3, #32
	add	x3, x13, x10
	add	x24, x3, #96
	mov	w3, #96
	add	x27, x5, x14
	add	x13, x5, x16, lsl #4
	madd	x28, x11, x3, x4
	add	x14, x4, x11, lsl #6
	add	x15, x5, x15
	ldr	d0, [x12, :lo12:.LCPI99_0]
	mov	x3, x10
	b	.LBB99_7
.LBB99_6:                               //   in Loop: Header=BB99_7 Depth=1
	ldp	x11, x10, [sp, #16]             // 16-byte Folded Reload
	add	x9, x9, #1
	ldr	x2, [sp, #80]                   // 8-byte Folded Reload
	add	x18, x18, x11
	add	x6, x6, x11
	add	x17, x17, x10
	add	x7, x7, x10
	add	x19, x19, x11
	add	x20, x20, x11
	add	x21, x21, x10
	add	x3, x3, x11
	add	x22, x22, x11
	add	x23, x23, x11
	add	x24, x24, x11
	add	x4, x4, x10
	add	x25, x25, x10
	add	x28, x28, x10
	add	x30, x30, x10
	add	x14, x14, x10
	cmp	x9, x2
	b.eq	.LBB99_10
.LBB99_7:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB99_9 Depth 2
	mov	w11, #1
	mov	w12, #5
	bfi	x11, x9, #3, #61
	mov	w10, #3
	mov	w16, #7
	ldr	x0, [sp, #104]                  // 8-byte Folded Reload
	mul	x11, x11, x1
	bfi	x12, x9, #3, #61
	bfi	x10, x9, #3, #61
	bfi	x16, x9, #3, #61
	mul	x12, x12, x1
	cmp	x1, #2
	add	x11, x0, x11, lsl #4
	mul	x10, x10, x1
	mul	x16, x16, x1
	add	x12, x0, x12, lsl #4
	ldp	d1, d2, [x11]
	add	x10, x0, x10, lsl #4
	add	x11, x0, x16, lsl #4
	ldp	d3, d4, [x12]
	mov	w12, #2
	mov	w16, #6
	ldp	d5, d6, [x10]
	lsl	x10, x9, #3
	bfi	x12, x9, #3, #61
	ldp	d7, d16, [x11]
	mov	w11, #4
	mul	x10, x10, x1
	bfi	x11, x9, #3, #61
	bfi	x16, x9, #3, #61
	fadd	d17, d1, d3
	fadd	d18, d2, d4
	mul	x11, x11, x1
	fadd	d19, d5, d7
	fsub	d3, d1, d3
	fsub	d2, d2, d4
	fsub	d4, d5, d7
	fsub	d5, d6, d16
	add	x10, x0, x10, lsl #4
	mul	x12, x12, x1
	add	x11, x0, x11, lsl #4
	mul	x16, x16, x1
	fadd	d20, d6, d16
	fadd	d6, d17, d19
	fsub	d1, d17, d19
	fadd	d16, d3, d5
	ldp	d19, d21, [x10]
	add	x10, x0, x12, lsl #4
	fsub	d3, d3, d5
	ldp	d5, d22, [x11]
	add	x11, x0, x16, lsl #4
	fadd	d7, d18, d20
	fsub	d17, d2, d4
	fadd	d2, d2, d4
	fsub	d18, d18, d20
	fneg	d25, d3
	ldp	d4, d20, [x10]
	fadd	d27, d21, d22
	ldp	d24, d26, [x11]
	fadd	d23, d17, d16
	fsub	d16, d17, d16
	fadd	d17, d19, d5
	fsub	d5, d19, d5
	ldp	x12, x10, [sp, #64]             // 16-byte Folded Reload
	fadd	d28, d4, d24
	fsub	d19, d21, d22
	fadd	d29, d20, d26
	mul	x11, x9, x1
	ldr	x0, [sp, #88]                   // 8-byte Folded Reload
	fsub	d3, d2, d3
	fsub	d2, d25, d2
	fsub	d4, d4, d24
	fadd	d21, d17, d28
	add	x10, x9, x10
	fadd	d22, d27, d29
	add	x11, x0, x11, lsl #4
	mul	x10, x10, x1
	add	x12, x9, x12
	fsub	d17, d17, d28
	fsub	d20, d20, d26
	fadd	d24, d6, d21
	fsub	d6, d21, d6
	fadd	d25, d7, d22
	fsub	d7, d22, d7
	fsub	d21, d27, d29
	add	x10, x0, x10, lsl #4
	mul	x12, x12, x1
	fmul	d23, d23, d0
	fmul	d16, d16, d0
	stp	d24, d25, [x11]
	ldp	x16, x11, [sp, #32]             // 16-byte Folded Reload
	stp	d6, d7, [x10]
	fadd	d6, d18, d17
	fsub	d7, d21, d1
	fsub	d17, d17, d18
	add	x11, x9, x11
	fadd	d1, d1, d21
	fadd	d18, d5, d20
	fsub	d21, d19, d4
	mul	x10, x11, x1
	add	x11, x0, x12, lsl #4
	add	x12, x9, x2
	fmul	d3, d3, d0
	fmul	d2, d2, d0
	fsub	d5, d5, d20
	stp	d6, d7, [x11]
	ldr	x11, [sp, #48]                  // 8-byte Folded Reload
	add	x10, x0, x10, lsl #4
	mul	x12, x12, x1
	fadd	d6, d16, d21
	fadd	d4, d19, d4
	add	x11, x9, x11
	add	x16, x9, x16
	stp	d17, d1, [x10]
	fadd	d1, d23, d18
	mul	x10, x11, x1
	add	x11, x0, x12, lsl #4
	ldr	x12, [sp, #56]                  // 8-byte Folded Reload
	fsub	d7, d18, d23
	fsub	d16, d21, d16
	add	x10, x0, x10, lsl #4
	stp	d1, d6, [x11]
	add	x12, x9, x12
	mul	x11, x16, x1
	fadd	d1, d3, d5
	fadd	d6, d2, d4
	mul	x12, x12, x1
	fsub	d3, d5, d3
	fsub	d2, d4, d2
	stp	d7, d16, [x10]
	add	x10, x0, x11, lsl #4
	add	x12, x0, x12, lsl #4
	stp	d1, d6, [x12]
	stp	d3, d2, [x10]
	b.lo	.LBB99_6
// %bb.8:                               //   in Loop: Header=BB99_7 Depth=1
	mov	x12, xzr
	ldr	x11, [sp, #8]                   // 8-byte Folded Reload
.LBB99_9:                               //   Parent Loop BB99_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x10, x18, x12
	add	x16, x6, x12
	subs	x11, x11, #1
	ldp	d1, d2, [x10, #-8]
	add	x10, x19, x12
	ldp	d3, d4, [x16, #-8]
	add	x16, x20, x12
	ldp	d5, d6, [x10, #-8]
	add	x10, x3, x12
	ldp	d7, d17, [x16, #-8]
	add	x16, x22, x12
	fadd	d16, d1, d3
	ldp	d19, d21, [x10, #16]
	add	x10, x24, x12
	fadd	d18, d2, d4
	ldp	d22, d23, [x16, #16]
	add	x16, x23, x12
	fsub	d1, d1, d3
	fsub	d2, d2, d4
	fadd	d3, d6, d17
	ldp	d4, d26, [x10, #16]
	fsub	d6, d6, d17
	fadd	d20, d5, d7
	ldp	d17, d25, [x16, #16]
	fsub	d5, d5, d7
	fadd	d24, d19, d22
	fadd	d30, d21, d23
	fadd	d28, d18, d3
	fsub	d29, d1, d6
	fadd	d7, d16, d20
	fadd	d27, d17, d4
	fadd	d1, d1, d6
	fsub	d6, d2, d5
	fadd	d31, d25, d26
	fadd	d2, d2, d5
	fsub	d16, d16, d20
	fneg	d20, d29
	fsub	d3, d18, d3
	fadd	d5, d24, d27
	add	x10, x15, x12
	fadd	d18, d6, d1
	fsub	d1, d6, d1
	fadd	d6, d30, d31
	fsub	d29, d2, d29
	fsub	d2, d20, d2
	fsub	d19, d19, d22
	fsub	d8, d5, d7
	fsub	d20, d21, d23
	fsub	d23, d24, d27
	fsub	d4, d17, d4
	ldp	d22, d24, [x10]
	fsub	d17, d6, d28
	fadd	d5, d7, d5
	fneg	d21, d8
	fadd	d6, d28, d6
	add	x10, x4, x12
	fsub	d27, d30, d31
	add	x16, x8, x12
	fmul	d18, d18, d0
	fmul	d1, d1, d0
	fmul	d2, d2, d0
	fmul	d7, d24, d21
	fmul	d21, d17, d24
	str	d5, [x10, #16]
	fsub	d24, d25, d26
	str	d6, [x10, #24]
	add	x10, x13, x12
	fadd	d6, d3, d23
	fsub	d3, d23, d3
	fmadd	d5, d8, d22, d21
	fmadd	d7, d17, d22, d7
	ldp	d21, d22, [x10]
	fsub	d17, d27, d16
	add	x10, x14, x12
	fneg	d23, d6
	fadd	d16, d16, d27
	ldp	d25, d27, [x16]
	str	d5, [x10, #16]
	fneg	d5, d3
	fmul	d26, d17, d22
	str	d7, [x10, #24]
	fmul	d22, d22, d23
	fadd	d23, d19, d24
	add	x10, x5, x12
	add	x16, x30, x12
	fmul	d5, d27, d5
	fmul	d7, d16, d27
	fmadd	d6, d6, d21, d26
	fsub	d26, d20, d4
	fmadd	d17, d17, d21, d22
	fadd	d21, d18, d23
	fadd	d4, d20, d4
	fmadd	d5, d16, d25, d5
	fmadd	d3, d3, d25, d7
	ldp	d22, d16, [x10]
	fadd	d7, d1, d26
	fneg	d25, d21
	add	x10, x28, x12
	str	d6, [x16, #16]
	str	d17, [x16, #24]
	fmul	d6, d29, d0
	add	x16, x25, x12
	fsub	d1, d26, d1
	fmul	d17, d7, d16
	str	d3, [x10, #16]
	fmul	d3, d16, d25
	str	d5, [x10, #24]
	add	x10, x29, x12
	fsub	d5, d19, d24
	fadd	d20, d2, d4
	fsub	d2, d4, d2
	fmadd	d16, d21, d22, d17
	fsub	d17, d23, d18
	fmadd	d3, d7, d22, d3
	ldp	d7, d18, [x10]
	add	x10, x27, x12
	fadd	d19, d6, d5
	str	d16, [x16, #16]
	fneg	d16, d17
	str	d3, [x16, #24]
	fsub	d5, d5, d6
	ldp	d21, d3, [x10]
	add	x10, x26, x12
	fmul	d6, d1, d18
	fneg	d22, d19
	fmul	d16, d18, d16
	fneg	d24, d5
	add	x16, x7, x12
	ldp	d4, d23, [x10]
	fmul	d18, d20, d3
	fmadd	d6, d17, d7, d6
	fmul	d3, d3, d22
	fmadd	d1, d1, d7, d16
	add	x10, x21, x12
	fmul	d16, d2, d23
	fmul	d17, d23, d24
	fmadd	d7, d19, d21, d18
	fmadd	d3, d20, d21, d3
	str	d1, [x10, #24]
	str	d6, [x10, #16]
	add	x10, x17, x12
	fmadd	d1, d5, d4, d16
	fmadd	d2, d2, d4, d17
	add	x12, x12, #16
	str	d7, [x16, #16]
	str	d3, [x16, #24]
	str	d1, [x10, #16]
	str	d2, [x10, #24]
	b.ne	.LBB99_9
	b	.LBB99_6
.LBB99_10:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	ldr	d8, [sp, #96]                   // 8-byte Folded Reload
	add	sp, sp, #208
	ret
.Lfunc_end99:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end99-_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 176
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	cmp	x1, #1
	str	x5, [sp, #56]                   // 8-byte Folded Spill
	b.ne	.LBB100_16
// %bb.1:
	cbz	x2, .LBB100_45
// %bb.2:
	mov	x8, xzr
	subs	x9, x2, #1
	b.eq	.LBB100_14
// %bb.3:
	cmp	xzr, x9, lsr #60
	add	x11, x4, x2, lsl #4
	lsl	x9, x9, #4
	cset	w10, ne
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB100_14
// %bb.4:
	tbnz	w10, #0, .LBB100_14
// %bb.5:
	add	x11, x11, #8
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB100_14
// %bb.6:
	tbnz	w10, #0, .LBB100_14
// %bb.7:
	add	x11, x4, #8
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB100_14
// %bb.8:
	tbnz	w10, #0, .LBB100_14
// %bb.9:
	add	x11, x4, x9
	cmp	x11, x4
	b.lo	.LBB100_14
// %bb.10:
	tbnz	w10, #0, .LBB100_14
// %bb.11:
	and	x8, x2, #0xfffffffffffffffe
	add	x9, x9, #16
	mov	x10, x8
	mov	x11, x4
	mov	x12, x3
.LBB100_12:                             // =>This Inner Loop Header: Depth=1
	ld4	{ v0.2d, v1.2d, v2.2d, v3.2d }, [x12], #64
	fadd	v4.2d, v0.2d, v2.2d
	add	x13, x11, x9
	fadd	v5.2d, v1.2d, v3.2d
	subs	x10, x10, #2
	st2	{ v4.2d, v5.2d }, [x11], #32
	fsub	v4.2d, v0.2d, v2.2d
	fsub	v5.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x13]
	b.ne	.LBB100_12
// %bb.13:
	cmp	x8, x2
	b.eq	.LBB100_45
.LBB100_14:
	add	x9, x8, x2
	add	x10, x4, x8, lsl #4
	add	x11, x3, x8, lsl #5
	sub	x8, x2, x8
	add	x12, x4, x9, lsl #4
	add	x9, x10, #8
	add	x10, x12, #8
	add	x11, x11, #16
.LBB100_15:                             // =>This Inner Loop Header: Depth=1
	ldp	d0, d1, [x11, #-16]
	subs	x8, x8, #1
	ldp	d2, d3, [x11], #32
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stur	d4, [x9, #-8]
	str	d5, [x9], #16
	stur	d0, [x10, #-8]
	str	d1, [x10], #16
	b.ne	.LBB100_15
	b	.LBB100_45
.LBB100_16:
	cbz	x2, .LBB100_45
// %bb.17:
	subs	x6, x1, #1
	b.ls	.LBB100_43
// %bb.18:
	lsl	x13, x2, #4
	sub	x14, x1, #2
	add	x13, x13, #16
	mul	x12, x2, x1
	cmp	xzr, x14, lsr #60
	lsl	x16, x14, #4
	mul	x8, x13, x1
	mov	x9, xzr
	mov	x10, xzr
	mov	x11, xzr
	add	x18, x12, #1
	cset	w21, ne
	add	x0, x3, #16
	lsl	x15, x1, #5
	stp	x8, x16, [sp, #40]              // 16-byte Folded Spill
	and	x8, x6, #0xfffffffffffffffe
	add	x7, x16, #32
	add	x19, x4, #16
	lsl	x20, x12, #4
	add	x24, x3, #8
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	orr	x8, x6, #0x1
	lsl	x22, x1, #1
	add	x23, x4, #8
	mov	x25, x1
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldr	x8, [sp, #56]                   // 8-byte Folded Reload
	stp	x23, x15, [sp, #16]             // 16-byte Folded Spill
	sub	x8, x8, #8
	stp	x18, x8, [sp, #64]              // 16-byte Folded Spill
.LBB100_19:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB100_31 Depth 2
                                        //     Child Loop BB100_35 Depth 2
	mov	w14, #1
	lsl	x13, x11, #1
	bfi	x14, x11, #1, #63
	mul	x26, x11, x1
	mul	x13, x13, x1
	cmp	x6, #2
	mul	x14, x14, x1
	add	x30, x4, x26, lsl #4
	add	x13, x3, x13, lsl #4
	add	x14, x3, x14, lsl #4
	ldp	d0, d1, [x13]
	add	x13, x11, x2
	ldp	d2, d3, [x14]
	mul	x13, x13, x1
	mov	w14, #1
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	add	x13, x4, x13, lsl #4
	stp	d4, d5, [x30]
	stp	d0, d1, [x13]
	b.lo	.LBB100_34
// %bb.20:                              //   in Loop: Header=BB100_19 Depth=1
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	add	x18, x30, #24
	add	x29, x30, #16
	add	x14, x18, x16
	add	x13, x8, x26
	add	x28, x4, x13, lsl #4
	add	x27, x28, #8
	add	x13, x28, x16
	cmp	x13, x28
	add	x13, x27, x16
	cset	w17, lo
	cmp	x13, x27
	orr	w5, w17, w21
	cset	w17, lo
	cmp	x14, x18
	add	x13, x29, x16
	cset	w14, lo
	cmp	x13, x29
	cset	w13, lo
	tbnz	w5, #0, .LBB100_33
// %bb.21:                              //   in Loop: Header=BB100_19 Depth=1
	orr	w17, w17, w21
	tbnz	w17, #0, .LBB100_33
// %bb.22:                              //   in Loop: Header=BB100_19 Depth=1
	orr	w14, w14, w21
	tbnz	w14, #0, .LBB100_33
// %bb.23:                              //   in Loop: Header=BB100_19 Depth=1
	orr	w13, w13, w21
	mov	w14, #1
	tbnz	w13, #0, .LBB100_34
// %bb.24:                              //   in Loop: Header=BB100_19 Depth=1
	add	x13, x26, x1
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	mov	x14, x4
	mov	x23, x22
	add	x5, x4, x13, lsl #4
	mov	x22, x24
	add	x24, x30, x8
	sub	x13, x5, #8
	cmp	x29, x5
	mov	x15, x6
	cset	w14, lo
	cmp	x18, x13
	sub	x6, x24, #8
	cset	w17, lo
	cmp	x6, x29
	and	w8, w14, w17
	cset	w14, hi
	cmp	x28, x13
	cset	w30, lo
	cmp	x24, x29
	cset	w26, hi
	cmp	x27, x13
	cset	w17, lo
	cmp	x6, x18
	cset	w29, hi
	cmp	x28, x5
	cset	w13, lo
	cmp	x24, x18
	cset	w18, hi
	cmp	x27, x5
	cset	w5, lo
	cmp	x24, x28
	cset	w28, hi
	cmp	x6, x27
	mov	w16, w21
	cset	w27, hi
	tbnz	w8, #0, .LBB100_40
// %bb.25:                              //   in Loop: Header=BB100_19 Depth=1
	and	w8, w14, w30
	mov	x6, x15
	mov	x24, x22
	tbnz	w8, #0, .LBB100_41
// %bb.26:                              //   in Loop: Header=BB100_19 Depth=1
	and	w8, w26, w17
	mov	x22, x23
	tbnz	w8, #0, .LBB100_39
// %bb.27:                              //   in Loop: Header=BB100_19 Depth=1
	and	w8, w29, w13
	mov	w21, w16
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB100_38
// %bb.28:                              //   in Loop: Header=BB100_19 Depth=1
	and	w8, w18, w5
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB100_37
// %bb.29:                              //   in Loop: Header=BB100_19 Depth=1
	and	w8, w28, w27
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB100_34
// %bb.30:                              //   in Loop: Header=BB100_19 Depth=1
	mov	x14, x19
	ldr	x18, [sp, #32]                  // 8-byte Folded Reload
	mov	x26, x0
	ldr	x27, [sp, #56]                  // 8-byte Folded Reload
	mov	x28, x19
.LBB100_31:                             //   Parent Loop BB100_19 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x26, x7
	subs	x18, x18, #2
	ld2	{ v0.2d, v1.2d }, [x26], #32
	ld2	{ v2.2d, v3.2d }, [x8]
	add	x8, x14, x20
	fadd	v4.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v6.2d, v1.2d, v3.2d
	fsub	v0.2d, v0.2d, v2.2d
	st2	{ v4.2d, v5.2d }, [x28], #32
	ld2	{ v1.2d, v2.2d }, [x27], #32
	fmul	v3.2d, v6.2d, v2.2d
	fneg	v5.2d, v0.2d
	mov	x14, x28
	fmla	v3.2d, v1.2d, v0.2d
	fmul	v4.2d, v2.2d, v5.2d
	fmla	v4.2d, v1.2d, v6.2d
	st2	{ v3.2d, v4.2d }, [x8]
	b.ne	.LBB100_31
// %bb.32:                              //   in Loop: Header=BB100_19 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cmp	x6, x8
	b.ne	.LBB100_34
	b	.LBB100_36
.LBB100_33:                             //   in Loop: Header=BB100_19 Depth=1
	mov	w14, #1
.LBB100_34:                             //   in Loop: Header=BB100_19 Depth=1
	add	x8, x14, x10
	add	x13, x14, x12
	add	x17, x14, x25
	add	x18, x14, x9
	add	x27, x24, x8, lsl #4
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	sub	x26, x1, x14
	add	x28, x23, x13, lsl #4
	add	x29, x24, x17, lsl #4
	add	x18, x23, x18, lsl #4
	add	x30, x8, x14, lsl #4
.LBB100_35:                             //   Parent Loop BB100_19 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	d0, d2, [x27, #-8]
	subs	x26, x26, #1
	add	x27, x27, #16
	ldp	d1, d3, [x29, #-8]
	add	x29, x29, #16
	ldr	d6, [x30]
	fsub	d4, d0, d1
	fadd	d0, d0, d1
	fsub	d5, d2, d3
	fadd	d1, d2, d3
	fneg	d7, d4
	stur	d0, [x18, #-8]
	fmul	d16, d5, d6
	str	d1, [x18], #16
	fmul	d6, d6, d7
	ldur	d7, [x30, #-8]
	add	x30, x30, #16
	fmadd	d2, d4, d7, d16
	fmadd	d3, d5, d7, d6
	stur	d2, [x28, #-8]
	str	d3, [x28], #16
	b.ne	.LBB100_35
.LBB100_36:                             //   in Loop: Header=BB100_19 Depth=1
	add	x11, x11, #1
	add	x0, x0, x15
	add	x19, x19, x7
	add	x10, x10, x22
	add	x12, x12, x1
	add	x25, x25, x22
	add	x9, x9, x1
	cmp	x11, x2
	b.ne	.LBB100_19
	b	.LBB100_45
.LBB100_37:                             //   in Loop: Header=BB100_19 Depth=1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	mov	w14, #1
	b	.LBB100_34
.LBB100_38:                             //   in Loop: Header=BB100_19 Depth=1
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB100_34
.LBB100_39:                             //   in Loop: Header=BB100_19 Depth=1
	ldp	x23, x15, [sp, #16]             // 16-byte Folded Reload
	mov	w21, w16
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB100_34
.LBB100_40:                             //   in Loop: Header=BB100_19 Depth=1
	mov	x6, x15
	mov	w21, w16
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	mov	x24, x22
	b	.LBB100_42
.LBB100_41:                             //   in Loop: Header=BB100_19 Depth=1
	mov	w14, #1
	mov	w21, w16
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
.LBB100_42:                             //   in Loop: Header=BB100_19 Depth=1
	mov	x22, x23
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	b	.LBB100_34
.LBB100_43:
	mul	x10, x2, x1
	add	x8, x4, #8
	lsl	x9, x1, #4
	add	x11, x3, #8
	lsl	x10, x10, #4
	lsl	x12, x1, #5
.LBB100_44:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	d0, d1, [x11, #-8]
	add	x11, x11, x12
	ldp	d2, d3, [x13, #-8]
	add	x13, x8, x10
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stur	d4, [x8, #-8]
	str	d5, [x8]
	add	x8, x8, x9
	stur	d0, [x13, #-8]
	str	d1, [x13]
	b.ne	.LBB100_44
.LBB100_45:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end100:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end100-_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI101_0:
	.xword	0xbfebb67ae8584caa              // double -0.8660254037844386
	.xword	0x3febb67ae8584caa              // double 0.8660254037844386
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3
.LCPI101_1:
	.xword	0x3febb67ae8584caa              // double 0.8660254037844386
.LCPI101_2:
	.xword	0xbfebb67ae8584caa              // double -0.8660254037844386
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x20, x19, [sp, #-16]!           // 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	subs	x8, x1, #1
	b.ne	.LBB101_4
// %bb.1:
	cbz	x2, .LBB101_10
// %bb.2:
	adrp	x10, .LCPI101_0
	lsl	x8, x2, #5
	fmov	v0.2d, #-0.50000000
	add	x9, x3, #16
	ldr	q1, [x10, :lo12:.LCPI101_0]
	mov	x10, x2
.LBB101_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q2, q3, [x9]
	subs	x10, x10, #1
	fadd	v4.2d, v2.2d, v3.2d
	fsub	v2.2d, v2.2d, v3.2d
	ldur	q3, [x9, #-16]
	add	x9, x9, #48
	fmul	v5.2d, v4.2d, v0.2d
	fmul	v2.2d, v2.2d, v1.2d
	fadd	v5.2d, v3.2d, v5.2d
	ext	v2.16b, v2.16b, v2.16b, #8
	fadd	v3.2d, v3.2d, v4.2d
	fadd	v4.2d, v2.2d, v5.2d
	fsub	v2.2d, v5.2d, v2.2d
	str	q3, [x4]
	str	q4, [x4, x2, lsl #4]
	str	q2, [x4, x8]
	add	x4, x4, #16
	b.ne	.LBB101_3
	b	.LBB101_10
.LBB101_4:
	cbz	x2, .LBB101_10
// %bb.5:
	mul	x16, x2, x1
	adrp	x17, .LCPI101_0
	adrp	x18, .LCPI101_1
	adrp	x0, .LCPI101_2
	lsl	x11, x1, #4
	add	x12, x1, x1, lsl #1
	fmov	v1.2d, #-0.50000000
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #4
	add	x13, x3, x11
	add	x14, x4, x16, lsl #5
	add	x15, x3, x1, lsl #5
	add	x16, x4, x16, lsl #4
	ldr	q0, [x17, :lo12:.LCPI101_0]
	add	x17, x5, x8, lsl #4
	ldr	d2, [x18, :lo12:.LCPI101_1]
	fmov	d3, #0.50000000
	ldr	d4, [x0, :lo12:.LCPI101_2]
	mov	x18, x4
	mov	x0, x3
	b	.LBB101_7
.LBB101_6:                              //   in Loop: Header=BB101_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x0, x0, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x18, x18, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB101_10
.LBB101_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB101_9 Depth 2
	add	x6, x9, x9, lsl #1
	cmp	x1, #2
	add	x7, x6, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	ldr	q5, [x3, x6, lsl #4]
	mul	x6, x9, x1
	ldr	q6, [x3, x19, lsl #4]
	add	x19, x9, x10
	ldr	q7, [x3, x7, lsl #4]
	add	x7, x9, x2
	mul	x19, x19, x1
	mul	x7, x7, x1
	fadd	v16.2d, v6.2d, v7.2d
	fsub	v6.2d, v6.2d, v7.2d
	fmul	v7.2d, v16.2d, v1.2d
	fmul	v6.2d, v6.2d, v0.2d
	fadd	v7.2d, v5.2d, v7.2d
	ext	v6.16b, v6.16b, v6.16b, #8
	fadd	v5.2d, v5.2d, v16.2d
	fadd	v16.2d, v6.2d, v7.2d
	str	q5, [x4, x6, lsl #4]
	fsub	v6.2d, v7.2d, v6.2d
	str	q16, [x4, x7, lsl #4]
	str	q6, [x4, x19, lsl #4]
	b.lo	.LBB101_6
// %bb.8:                               //   in Loop: Header=BB101_7 Depth=1
	mov	x6, xzr
	mov	x7, x8
.LBB101_9:                              //   Parent Loop BB101_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x19, x15, x6
	add	x20, x13, x6
	subs	x7, x7, #1
	ldp	d5, d16, [x19, #16]
	add	x19, x0, x6
	ldp	d6, d7, [x20, #16]
	add	x20, x17, x6
	ldp	d19, d20, [x19, #16]
	add	x19, x5, x6
	fadd	d17, d6, d5
	fsub	d5, d6, d5
	fadd	d18, d7, d16
	fsub	d7, d7, d16
	ldp	d24, d22, [x19]
	add	x19, x18, x6
	fmul	d16, d17, d3
	fmul	d5, d5, d4
	fmul	d6, d18, d3
	fmul	d7, d7, d2
	fadd	d17, d19, d17
	fadd	d18, d20, d18
	fsub	d16, d19, d16
	fsub	d6, d20, d6
	stp	d17, d18, [x19, #16]
	add	x19, x14, x6
	fadd	d21, d16, d7
	fsub	d7, d16, d7
	fadd	d23, d5, d6
	fsub	d5, d6, d5
	fneg	d16, d21
	fneg	d26, d7
	fmul	d6, d23, d22
	fmul	d16, d22, d16
	ldp	d22, d25, [x20]
	fmadd	d6, d21, d24, d6
	add	x20, x16, x6
	add	x6, x6, #16
	fmadd	d16, d23, d24, d16
	fmul	d19, d5, d25
	fmul	d20, d25, d26
	stp	d6, d16, [x20, #16]
	fmadd	d7, d7, d22, d19
	fmadd	d5, d5, d22, d20
	stp	d7, d5, [x19, #16]
	b.ne	.LBB101_9
	b	.LBB101_6
.LBB101_10:
	ldp	x20, x19, [sp], #16             // 16-byte Folded Reload
	ret
.Lfunc_end101:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end101-_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI102_0:
	.xword	0x3fd3c6ef372fe950              // double 0.30901699437494745
.LCPI102_1:
	.xword	0xbfe9e3779b97f4a8              // double -0.80901699437494745
.LCPI102_2:
	.xword	0xbfe2cf2304755a5e              // double -0.58778525229247314
.LCPI102_3:
	.xword	0xbfee6f0e134454ff              // double -0.95105651629515353
.LCPI102_4:
	.xword	0x3fee6f0e134454ff              // double 0.95105651629515353
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	str	x29, [sp, #-96]!                // 8-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w29, -96
	subs	x8, x1, #1
	b.ne	.LBB102_4
// %bb.1:
	cbz	x2, .LBB102_10
// %bb.2:
	adrp	x11, .LCPI102_0
	adrp	x12, .LCPI102_1
	adrp	x13, .LCPI102_2
	adrp	x14, .LCPI102_3
	adrp	x15, .LCPI102_4
	add	x10, x2, x2, lsl #1
	add	x8, x4, #8
	lsl	x9, x2, #5
	lsl	x10, x10, #4
	ldr	d0, [x11, :lo12:.LCPI102_0]
	ldr	d1, [x12, :lo12:.LCPI102_1]
	lsl	x11, x2, #6
	ldr	d2, [x13, :lo12:.LCPI102_2]
	lsl	x12, x2, #4
	ldr	d3, [x14, :lo12:.LCPI102_3]
	add	x13, x3, #40
	ldr	d4, [x15, :lo12:.LCPI102_4]
.LBB102_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d5, d6, [x13, #-24]
	add	x14, x8, x12
	add	x15, x8, x11
	ldp	d17, d7, [x13, #24]
	subs	x2, x2, #1
	ldp	d16, d19, [x13, #-8]
	ldp	d20, d18, [x13, #8]
	fadd	d22, d6, d7
	fsub	d6, d6, d7
	ldp	d24, d7, [x13, #-40]
	fadd	d21, d5, d17
	fsub	d5, d5, d17
	fsub	d23, d16, d20
	fadd	d16, d16, d20
	fsub	d17, d19, d18
	fadd	d18, d19, d18
	add	x13, x13, #80
	fmadd	d19, d21, d0, d24
	fmadd	d25, d22, d0, d7
	fmul	d26, d23, d2
	fadd	d27, d24, d21
	fmul	d20, d17, d2
	fmadd	d21, d21, d1, d24
	fmadd	d24, d22, d1, d7
	fmul	d17, d17, d4
	fmadd	d19, d16, d1, d19
	fmadd	d25, d18, d1, d25
	fmadd	d26, d5, d3, d26
	fmul	d23, d23, d4
	fmadd	d20, d6, d3, d20
	fadd	d27, d27, d16
	fmadd	d16, d16, d0, d21
	fmadd	d6, d6, d2, d17
	fmadd	d17, d18, d0, d24
	fadd	d7, d7, d22
	fmadd	d5, d5, d2, d23
	fsub	d21, d25, d26
	fsub	d28, d19, d20
	fadd	d19, d19, d20
	fadd	d20, d25, d26
	fadd	d7, d7, d18
	stp	d19, d21, [x15, #-8]
	fsub	d19, d16, d6
	stp	d28, d20, [x14, #-8]
	fadd	d20, d17, d5
	add	x14, x8, x9
	fadd	d6, d16, d6
	fsub	d5, d17, d5
	stp	d27, d7, [x8, #-8]
	stp	d19, d20, [x14, #-8]
	add	x14, x8, x10
	add	x8, x8, #16
	stp	d6, d5, [x14, #-8]
	b.ne	.LBB102_3
	b	.LBB102_10
.LBB102_4:
	cbz	x2, .LBB102_10
// %bb.5:
	adrp	x23, .LCPI102_1
	mul	x22, x2, x1
	mov	w14, #48
	add	x18, x8, x8, lsl #1
	adrp	x20, .LCPI102_0
	adrp	x24, .LCPI102_2
	adrp	x25, .LCPI102_3
	ldr	d1, [x23, :lo12:.LCPI102_1]
	adrp	x23, .LCPI102_4
	lsl	x7, x8, #5
	lsl	x21, x18, #4
	lsl	x11, x2, #1
	lsl	x13, x1, #4
	madd	x14, x22, x14, x4
	add	x15, x1, x1, lsl #2
	add	x18, x7, x3
	add	x0, x21, x3
	mov	x9, xzr
	lsl	x10, x2, #2
	add	x12, x11, x2
	lsl	x15, x15, #4
	add	x16, x3, x13
	add	x17, x3, x1, lsl #6
	add	x18, x18, #32
	add	x0, x0, #48
	add	x6, x4, x22, lsl #5
	add	x7, x5, x7
	add	x19, x5, x8, lsl #4
	ldr	d0, [x20, :lo12:.LCPI102_0]
	add	x20, x4, x22, lsl #6
	ldr	d2, [x24, :lo12:.LCPI102_2]
	add	x21, x5, x21
	ldr	d3, [x25, :lo12:.LCPI102_3]
	add	x22, x4, x22, lsl #4
	ldr	d4, [x23, :lo12:.LCPI102_4]
	mov	x23, x4
	mov	x24, x3
	b	.LBB102_7
.LBB102_6:                              //   in Loop: Header=BB102_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x13
	add	x24, x24, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x23, x23, x13
	add	x6, x6, x13
	add	x20, x20, x13
	add	x22, x22, x13
	cmp	x9, x2
	b.eq	.LBB102_10
.LBB102_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_9 Depth 2
	add	x25, x9, x9, lsl #2
	cmp	x1, #2
	add	x27, x25, #4
	add	x29, x25, #2
	mul	x26, x25, x1
	add	x25, x25, #3
	mul	x27, x27, x1
	add	x28, x1, x26
	mul	x29, x29, x1
	mul	x25, x25, x1
	add	x26, x3, x26, lsl #4
	add	x28, x3, x28, lsl #4
	add	x27, x3, x27, lsl #4
	add	x25, x3, x25, lsl #4
	ldp	d5, d6, [x28]
	add	x28, x3, x29, lsl #4
	ldp	d7, d16, [x27]
	add	x27, x9, x10
	ldp	d17, d18, [x28]
	ldp	d19, d20, [x25]
	fadd	d23, d5, d7
	fadd	d25, d6, d16
	ldp	d21, d22, [x26]
	fsub	d5, d5, d7
	fsub	d6, d6, d16
	fsub	d26, d17, d19
	fadd	d7, d17, d19
	fsub	d24, d18, d20
	fadd	d16, d18, d20
	fmadd	d17, d23, d0, d21
	fadd	d27, d21, d23
	fmadd	d19, d25, d0, d22
	fadd	d28, d22, d25
	fmul	d20, d26, d2
	mul	x25, x9, x1
	fmul	d18, d24, d2
	add	x26, x9, x2
	fmadd	d17, d7, d1, d17
	fadd	d27, d27, d7
	fmadd	d19, d16, d1, d19
	mul	x26, x26, x1
	fmadd	d20, d5, d3, d20
	fadd	d28, d28, d16
	fmadd	d18, d6, d3, d18
	add	x25, x4, x25, lsl #4
	fmadd	d21, d23, d1, d21
	fmul	d23, d24, d4
	fmadd	d22, d25, d1, d22
	fmul	d24, d26, d4
	fadd	d30, d19, d20
	add	x26, x4, x26, lsl #4
	fsub	d29, d17, d18
	str	d27, [x25]
	str	d28, [x25, #8]
	mul	x25, x27, x1
	fadd	d17, d17, d18
	fmadd	d7, d7, d0, d21
	str	d30, [x26, #8]
	fmadd	d6, d6, d2, d23
	str	d29, [x26]
	add	x26, x9, x11
	fmadd	d16, d16, d0, d22
	fmadd	d5, d5, d2, d24
	add	x27, x9, x12
	fsub	d18, d19, d20
	add	x25, x4, x25, lsl #4
	mul	x26, x26, x1
	mul	x27, x27, x1
	fadd	d19, d16, d5
	fsub	d5, d16, d5
	str	d17, [x25]
	fsub	d17, d7, d6
	fadd	d6, d7, d6
	add	x26, x4, x26, lsl #4
	str	d18, [x25, #8]
	add	x25, x4, x27, lsl #4
	str	d17, [x26]
	str	d19, [x26, #8]
	str	d6, [x25]
	str	d5, [x25, #8]
	b.lo	.LBB102_6
// %bb.8:                               //   in Loop: Header=BB102_7 Depth=1
	mov	x25, xzr
	mov	x26, x8
.LBB102_9:                              //   Parent Loop BB102_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x27, x16, x25
	add	x28, x18, x25
	add	x29, x0, x25
	subs	x26, x26, #1
	ldp	d5, d6, [x27, #16]
	add	x27, x17, x25
	ldp	d7, d16, [x28, #16]
	add	x28, x23, x25
	ldp	d20, d17, [x29, #16]
	ldp	d18, d19, [x27, #16]
	add	x27, x24, x25
	fadd	d25, d7, d20
	fsub	d7, d7, d20
	fsub	d22, d16, d17
	fadd	d16, d16, d17
	fadd	d21, d5, d18
	fsub	d5, d5, d18
	fadd	d23, d6, d19
	fsub	d6, d6, d19
	ldp	d24, d19, [x27, #16]
	fmul	d26, d22, d2
	fmul	d18, d7, d2
	add	x27, x5, x25
	fmul	d22, d22, d4
	fmul	d7, d7, d4
	fmadd	d20, d21, d0, d24
	fadd	d27, d24, d21
	fmadd	d17, d23, d0, d19
	fmadd	d26, d6, d3, d26
	fadd	d28, d19, d23
	fmadd	d18, d5, d3, d18
	fmadd	d21, d21, d1, d24
	fmadd	d19, d23, d1, d19
	fmadd	d20, d25, d1, d20
	fadd	d24, d27, d25
	fmadd	d17, d16, d1, d17
	fmadd	d6, d6, d2, d22
	ldp	d29, d30, [x27]
	fadd	d27, d28, d16
	fmadd	d21, d25, d0, d21
	fsub	d31, d20, d26
	add	x27, x21, x25
	fadd	d28, d17, d18
	fmadd	d16, d16, d0, d19
	fadd	d19, d20, d26
	fmadd	d5, d5, d2, d7
	stp	d24, d27, [x28, #16]
	add	x28, x19, x25
	fneg	d23, d31
	fsub	d7, d17, d18
	fmul	d22, d28, d30
	fsub	d17, d21, d6
	ldp	d26, d27, [x28]
	fneg	d24, d19
	fadd	d25, d16, d5
	fmul	d23, d30, d23
	fadd	d6, d21, d6
	fmadd	d18, d31, d29, d22
	add	x28, x7, x25
	fsub	d5, d16, d5
	fmadd	d20, d28, d29, d23
	fneg	d28, d17
	ldp	d22, d23, [x27]
	fneg	d16, d6
	add	x27, x22, x25
	stp	d18, d20, [x27, #16]
	add	x27, x20, x25
	fmul	d21, d7, d23
	fmul	d23, d23, d24
	fmul	d24, d25, d27
	fmul	d27, d27, d28
	ldp	d28, d29, [x28]
	add	x28, x6, x25
	fmadd	d18, d19, d22, d21
	fmadd	d7, d7, d22, d23
	fmadd	d17, d17, d26, d24
	fmadd	d20, d25, d26, d27
	fmul	d19, d5, d29
	fmul	d16, d29, d16
	stp	d18, d7, [x27, #16]
	add	x27, x14, x25
	add	x25, x25, #16
	stp	d17, d20, [x28, #16]
	fmadd	d6, d6, d28, d19
	fmadd	d5, d5, d28, d16
	stp	d6, d5, [x27, #16]
	b.ne	.LBB102_9
	b	.LBB102_6
.LBB102_10:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldr	x29, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end102:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end102-_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI103_0:
	.xword	0x3fe3f3a0e28bedd1              // double 0.62348980185873348
.LCPI103_1:
	.xword	0xbfcc7b90e3024582              // double -0.22252093395631439
.LCPI103_2:
	.xword	0xbfecd4bca9cb5c71              // double -0.90096886790241915
.LCPI103_3:
	.xword	0xbfef329c0558e969              // double -0.97492791218182361
.LCPI103_4:
	.xword	0xbfe904c37505de4b              // double -0.7818314824680298
.LCPI103_5:
	.xword	0xbfdbc4c04d71abc1              // double -0.43388373911755812
.LCPI103_6:
	.xword	0x3fdbc4c04d71abc1              // double 0.43388373911755812
.LCPI103_7:
	.xword	0x3fe904c37505de4b              // double 0.7818314824680298
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #272
	stp	d15, d14, [sp, #112]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #128]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #144]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #160]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #176]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #192]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #208]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 272
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #64]               // 16-byte Folded Spill
	str	x2, [sp, #56]                   // 8-byte Folded Spill
	b.ne	.LBB103_4
// %bb.1:
	cbz	x2, .LBB103_10
// %bb.2:
	adrp	x16, .LCPI103_2
	adrp	x11, .LCPI103_0
	adrp	x12, .LCPI103_1
	adrp	x17, .LCPI103_3
	add	x15, x2, x2, lsl #2
	ldr	d2, [x16, :lo12:.LCPI103_2]
	adrp	x16, .LCPI103_5
	ldr	d0, [x11, :lo12:.LCPI103_0]
	lsl	x11, x15, #4
	ldr	d1, [x12, :lo12:.LCPI103_1]
	adrp	x12, .LCPI103_4
	ldr	d3, [x17, :lo12:.LCPI103_3]
	adrp	x15, .LCPI103_6
	ldp	x17, x8, [sp, #56]              // 16-byte Folded Reload
	add	x14, x2, x2, lsl #1
	ldr	d5, [x16, :lo12:.LCPI103_5]
	adrp	x16, .LCPI103_7
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	lsl	x9, x2, #6
	add	x8, x8, #8
	lsl	x10, x14, #4
	ldr	d4, [x12, :lo12:.LCPI103_4]
	lsl	x12, x17, #5
	lsl	x14, x14, #5
	ldr	d6, [x15, :lo12:.LCPI103_6]
	lsl	x15, x17, #4
	add	x13, x13, #56
	ldr	d7, [x16, :lo12:.LCPI103_7]
.LBB103_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d27, d24, [x13, #24]
	add	x16, x8, x15
	mov	x18, x17
	ldp	d21, d26, [x13, #-24]
	add	x17, x8, x14
	ldp	d22, d16, [x13, #-40]
	ldp	d23, d18, [x13, #40]
	fsub	d19, d26, d24
	ldp	d29, d20, [x13, #-56]
	fadd	d25, d22, d23
	fsub	d22, d22, d23
	fadd	d17, d16, d18
	fsub	d16, d16, d18
	ldp	d9, d28, [x13, #8]
	fadd	d18, d21, d27
	fsub	d21, d21, d27
	ldp	d27, d31, [x13, #-8]
	fmadd	d30, d25, d0, d29
	fmul	d8, d19, d3
	fadd	d23, d26, d24
	fmadd	d24, d17, d0, d20
	fmul	d26, d21, d3
	fmadd	d12, d25, d1, d29
	fadd	d10, d27, d9
	fsub	d27, d27, d9
	fsub	d11, d31, d28
	fmadd	d30, d18, d1, d30
	fmadd	d8, d16, d4, d8
	fadd	d28, d31, d28
	fmadd	d24, d23, d1, d24
	fmadd	d26, d22, d4, d26
	fmul	d14, d19, d6
	fmul	d19, d19, d7
	fmadd	d30, d10, d2, d30
	add	x13, x13, #112
	fmadd	d31, d11, d5, d8
	fadd	d8, d29, d25
	fmadd	d24, d28, d2, d24
	fmadd	d26, d27, d5, d26
	fmadd	d25, d25, d2, d29
	fadd	d29, d20, d17
	fsub	d9, d30, d31
	fadd	d8, d8, d18
	fadd	d13, d26, d24
	fadd	d30, d30, d31
	fmadd	d31, d18, d2, d12
	fmul	d12, d21, d6
	fsub	d24, d24, d26
	fmadd	d18, d18, d0, d25
	stur	d9, [x16, #-8]
	fmadd	d9, d17, d1, d20
	str	d13, [x16]
	fmadd	d13, d16, d3, d14
	stur	d30, [x17, #-8]
	fadd	d26, d8, d10
	fmadd	d30, d10, d0, d31
	fmadd	d8, d22, d3, d12
	fmadd	d31, d23, d2, d9
	fmadd	d17, d17, d2, d20
	fmul	d20, d21, d7
	fmadd	d9, d11, d7, d13
	fmadd	d16, d16, d5, d19
	fmadd	d18, d10, d1, d18
	str	d24, [x17]
	add	x16, x8, x12
	fmadd	d21, d28, d0, d31
	fmadd	d31, d27, d7, d8
	fmadd	d17, d23, d0, d17
	fmadd	d19, d22, d5, d20
	fadd	d22, d30, d9
	fmadd	d16, d11, d3, d16
	fsub	d24, d30, d9
	add	x17, x8, x11
	fadd	d20, d31, d21
	fsub	d21, d21, d31
	fmadd	d17, d28, d1, d17
	fmadd	d19, d27, d3, d19
	fadd	d23, d29, d23
	stur	d22, [x17, #-8]
	stur	d24, [x16, #-8]
	str	d20, [x16]
	fsub	d20, d18, d16
	fadd	d22, d19, d17
	add	x16, x8, x10
	str	d21, [x17]
	mov	x17, x18
	fadd	d21, d23, d28
	fadd	d16, d18, d16
	fsub	d17, d17, d19
	stur	d20, [x16, #-8]
	str	d22, [x16]
	add	x16, x8, x9
	subs	x17, x18, #1
	stur	d26, [x8, #-8]
	str	d21, [x8], #16
	stur	d16, [x16, #-8]
	str	d17, [x16]
	b.ne	.LBB103_3
	b	.LBB103_10
.LBB103_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	cbz	x2, .LBB103_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x11, x2, #2
	ldr	x12, [sp, #8]                   // 8-byte Folded Reload
	adrp	x27, .LCPI103_2
	mov	w14, #112
	mul	x10, x2, x1
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	lsl	x3, x12, #5
	add	x23, x5, x3
	mov	w30, #96
	stp	x11, x8, [sp, #32]              // 16-byte Folded Spill
	add	x8, x11, x2
	mul	x2, x1, x14
	add	x7, x12, x12, lsl #1
	mov	w21, #48
	mov	w24, #80
	stp	x8, x18, [sp, #16]              // 16-byte Folded Spill
	adrp	x26, .LCPI103_1
	ldp	x11, x8, [sp, #64]              // 16-byte Folded Reload
	adrp	x28, .LCPI103_4
	adrp	x14, .LCPI103_7
	ldr	d2, [x27, :lo12:.LCPI103_2]
	adrp	x27, .LCPI103_5
	lsl	x22, x7, #4
	lsl	x25, x12, #6
	lsl	x16, x1, #4
	madd	x21, x10, x21, x11
	add	x4, x3, x8
	adrp	x3, .LCPI103_0
	add	x6, x4, #32
	add	x4, x12, x12, lsl #2
	lsl	x4, x4, #4
	madd	x0, x1, x30, x8
	ldr	d15, [x3, :lo12:.LCPI103_0]
	adrp	x3, .LCPI103_3
	add	x19, x4, x8
	add	x20, x25, x8
	add	x7, x19, #80
	add	x19, x22, x8
	ldr	d3, [x3, :lo12:.LCPI103_3]
	adrp	x3, .LCPI103_6
	madd	x24, x10, x24, x11
	mov	x9, xzr
	madd	x30, x10, x30, x11
	add	x15, x11, x10, lsl #6
	add	x18, x8, x16
	add	x19, x19, #48
	add	x20, x20, #64
	add	x22, x5, x22
	add	x25, x5, x25
	ldr	d1, [x26, :lo12:.LCPI103_1]
	add	x26, x5, x12, lsl #4
	ldr	d4, [x28, :lo12:.LCPI103_4]
	ldr	d0, [x27, :lo12:.LCPI103_5]
	add	x27, x11, x10, lsl #5
	add	x28, x5, x4
	ldr	d5, [x3, :lo12:.LCPI103_6]
	add	x29, x11, x10, lsl #4
	ldr	d6, [x14, :lo12:.LCPI103_7]
	mov	x4, x11
	mov	x3, x8
	ldr	x17, [sp, #72]                  // 8-byte Folded Reload
	str	d5, [sp, #96]                   // 8-byte Folded Spill
	stp	d4, d6, [sp, #80]               // 16-byte Folded Spill
	b	.LBB103_7
.LBB103_6:                              //   in Loop: Header=BB103_7 Depth=1
	add	x9, x9, #1
	add	x15, x15, x16
	add	x3, x3, x2
	add	x18, x18, x2
	add	x0, x0, x2
	add	x6, x6, x2
	add	x7, x7, x2
	add	x19, x19, x2
	add	x20, x20, x2
	add	x4, x4, x16
	add	x21, x21, x16
	add	x24, x24, x16
	add	x27, x27, x16
	add	x29, x29, x16
	add	x30, x30, x16
	ldr	d5, [sp, #96]                   // 8-byte Folded Reload
	cmp	x9, x12
	b.eq	.LBB103_10
.LBB103_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB103_9 Depth 2
	lsl	x10, x9, #3
	cmp	x1, #2
	sub	x10, x10, x9
	fmov	d6, d0
	add	x14, x10, #6
	add	x13, x10, #2
	mul	x11, x10, x1
	add	x8, x10, #5
	mul	x14, x14, x1
	add	x12, x1, x11
	mul	x13, x13, x1
	mul	x8, x8, x1
	add	x11, x17, x11, lsl #4
	add	x12, x17, x12, lsl #4
	add	x14, x17, x14, lsl #4
	add	x8, x17, x8, lsl #4
	ldp	d20, d22, [x12]
	add	x12, x17, x13, lsl #4
	add	x13, x10, #3
	ldp	d21, d25, [x14]
	add	x10, x10, #4
	ldp	d26, d27, [x12]
	mul	x12, x13, x1
	ldp	d28, d29, [x8]
	mul	x8, x10, x1
	fadd	d23, d20, d21
	ldp	d24, d18, [x11]
	add	x10, x17, x12, lsl #4
	fadd	d19, d22, d25
	add	x8, x17, x8, lsl #4
	fadd	d17, d26, d28
	fadd	d16, d27, d29
	fsub	d25, d22, d25
	ldp	d30, d31, [x10]
	fadd	d8, d24, d23
	fadd	d9, d18, d19
	ldp	d10, d11, [x8]
	fsub	d27, d27, d29
	mul	x8, x9, x1
	ldp	x12, x13, [sp, #56]             // 16-byte Folded Reload
	fsub	d21, d20, d21
	fadd	d29, d8, d17
	fadd	d8, d9, d16
	fadd	d22, d30, d10
	fmadd	d9, d23, d15, d24
	fadd	d20, d31, d11
	fmadd	d12, d19, d15, d18
	fmul	d13, d27, d3
	fsub	d26, d26, d28
	add	x8, x13, x8, lsl #4
	fsub	d31, d31, d11
	fadd	d28, d29, d22
	fadd	d29, d8, d20
	fmadd	d8, d17, d1, d9
	fmadd	d9, d16, d1, d12
	fmadd	d11, d25, d4, d13
	fsub	d30, d30, d10
	fmadd	d10, d23, d1, d24
	str	d28, [x8]
	fmul	d28, d26, d3
	str	d29, [x8, #8]
	fmadd	d29, d22, d2, d8
	add	x8, x9, x12
	fmadd	d8, d20, d2, d9
	fmadd	d9, d31, d0, d11
	fmadd	d11, d19, d1, d18
	fmadd	d28, d21, d4, d28
	mul	x8, x8, x1
	fmul	d12, d27, d5
	fmul	d14, d26, d5
	ldr	x10, [sp, #24]                  // 8-byte Folded Reload
	fmadd	d10, d17, d2, d10
	fsub	d13, d29, d9
	add	x8, x13, x8, lsl #4
	fmadd	d28, d30, d0, d28
	ldr	x11, [sp, #48]                  // 8-byte Folded Reload
	add	x10, x9, x10
	fmadd	d11, d16, d2, d11
	fmadd	d12, d25, d3, d12
	fadd	d29, d29, d9
	str	d13, [x8]
	fmadd	d13, d21, d3, d14
	fadd	d9, d28, d8
	ldr	d5, [sp, #88]                   // 8-byte Folded Reload
	mul	x10, x10, x1
	add	x11, x9, x11
	fmadd	d10, d22, d15, d10
	fmadd	d11, d20, d15, d11
	fmadd	d12, d31, d5, d12
	fmadd	d13, d30, d5, d13
	str	d9, [x8, #8]
	mul	x8, x11, x1
	ldr	x11, [sp, #16]                  // 8-byte Folded Reload
	add	x10, x13, x10, lsl #4
	fsub	d28, d8, d28
	fmadd	d23, d23, d2, d24
	fadd	d24, d13, d11
	add	x8, x13, x8, lsl #4
	add	x11, x9, x11
	str	d29, [x10]
	fsub	d29, d10, d12
	fmul	d27, d27, d5
	fmadd	d18, d19, d2, d18
	fmul	d19, d26, d5
	str	d28, [x10, #8]
	mul	x10, x11, x1
	str	d24, [x8, #8]
	fmadd	d17, d17, d15, d23
	str	d29, [x8]
	fmadd	d23, d25, d0, d27
	add	x8, x13, x10, lsl #4
	fmadd	d16, d16, d15, d18
	ldp	x11, x10, [sp, #32]             // 16-byte Folded Reload
	fmadd	d18, d21, d0, d19
	fadd	d19, d10, d12
	fmadd	d17, d22, d1, d17
	fmadd	d22, d31, d3, d23
	fmadd	d16, d20, d1, d16
	fsub	d21, d11, d13
	add	x11, x9, x11
	add	x10, x9, x10
	fmadd	d18, d30, d3, d18
	mul	x11, x11, x1
	str	d19, [x8]
	mul	x10, x10, x1
	fsub	d19, d17, d22
	fadd	d17, d17, d22
	str	d21, [x8, #8]
	fadd	d20, d18, d16
	fsub	d16, d16, d18
	add	x10, x13, x10, lsl #4
	add	x8, x13, x11, lsl #4
	str	d19, [x10]
	str	d20, [x10, #8]
	str	d17, [x8]
	str	d16, [x8, #8]
	b.lo	.LBB103_6
// %bb.8:                               //   in Loop: Header=BB103_7 Depth=1
	mov	x14, xzr
	ldr	x10, [sp, #8]                   // 8-byte Folded Reload
.LBB103_9:                              //   Parent Loop BB103_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x18, x14
	add	x11, x0, x14
	subs	x10, x10, #1
	ldp	d24, d18, [x8, #16]
	add	x8, x6, x14
	ldp	d25, d21, [x11, #16]
	add	x11, x7, x14
	ldp	d26, d27, [x8, #16]
	add	x8, x3, x14
	ldp	d28, d29, [x11, #16]
	fadd	d19, d24, d25
	add	x11, x19, x14
	ldp	d23, d5, [x8, #16]
	add	x8, x20, x14
	fadd	d17, d18, d21
	fsub	d16, d26, d28
	fadd	d22, d26, d28
	fsub	d7, d27, d29
	fsub	d20, d18, d21
	ldp	d30, d31, [x11, #16]
	fmadd	d9, d19, d15, d23
	fsub	d24, d24, d25
	ldp	d8, d26, [x8, #16]
	fmul	d10, d7, d3
	fadd	d29, d27, d29
	fmadd	d11, d17, d15, d5
	fmul	d12, d16, d3
	fmadd	d9, d22, d1, d9
	add	x8, x5, x14
	fadd	d25, d30, d8
	fsub	d27, d30, d8
	fsub	d28, d31, d26
	fmadd	d10, d20, d4, d10
	fadd	d26, d31, d26
	fmadd	d30, d29, d1, d11
	fmadd	d31, d24, d4, d12
	fmov	d18, d5
	fmadd	d8, d25, d2, d9
	fmov	d5, d16
	fmadd	d9, d28, d0, d10
	add	x11, x28, x14
	fmadd	d30, d26, d2, d30
	fmov	d16, d15
	fmadd	d31, d27, d0, d31
	fmov	d21, d7
	ldp	d14, d12, [x8]
	fsub	d10, d8, d9
	fadd	d8, d8, d9
	fmov	d7, d0
	fadd	d6, d18, d17
	fadd	d11, d31, d30
	fsub	d30, d30, d31
	add	x8, x4, x14
	fneg	d13, d10
	fadd	d6, d6, d29
	fmul	d15, d11, d12
	fmul	d9, d12, d13
	fadd	d13, d23, d19
	ldp	d12, d31, [x11]
	fmadd	d0, d10, d14, d15
	fneg	d15, d8
	fadd	d6, d6, d26
	add	x11, x29, x14
	fmadd	d10, d11, d14, d9
	fmadd	d11, d19, d1, d23
	fadd	d13, d13, d22
	fmadd	d19, d19, d2, d23
	fmul	d4, d30, d31
	str	d0, [sp, #104]                  // 8-byte Folded Spill
	ldr	d0, [sp, #96]                   // 8-byte Folded Reload
	fmul	d31, d31, d15
	fmadd	d11, d22, d2, d11
	fadd	d13, d13, d25
	fmul	d14, d21, d0
	fmadd	d9, d8, d12, d4
	fmadd	d8, d17, d1, d18
	fmul	d15, d5, d0
	fmov	d4, d5
	ldr	d5, [sp, #88]                   // 8-byte Folded Reload
	fmadd	d30, d30, d12, d31
	fmadd	d11, d25, d16, d11
	fmadd	d14, d20, d3, d14
	stp	d13, d6, [x8, #16]
	fmadd	d8, d29, d2, d8
	fmadd	d31, d24, d3, d15
	fmov	d15, d16
	fmov	d0, d20
	fmul	d20, d21, d5
	fmul	d21, d4, d5
	fmadd	d12, d28, d5, d14
	add	x8, x30, x14
	fmadd	d6, d26, d16, d8
	ldr	d16, [sp, #104]                 // 8-byte Folded Reload
	fmadd	d31, d27, d5, d31
	fmadd	d19, d22, d15, d19
	fmadd	d21, d24, d7, d21
	fsub	d23, d11, d12
	stp	d16, d10, [x11, #16]
	add	x11, x26, x14
	fmadd	d16, d17, d2, d18
	fadd	d8, d31, d6
	fmadd	d18, d0, d7, d20
	fmadd	d19, d25, d1, d19
	fmadd	d21, d27, d3, d21
	ldp	d4, d17, [x11]
	fneg	d22, d23
	fmadd	d16, d29, d15, d16
	fmadd	d18, d28, d3, d18
	add	x11, x23, x14
	stp	d9, d30, [x8, #16]
	add	x8, x25, x14
	fsub	d6, d6, d31
	fmov	d0, d7
	fmul	d20, d8, d17
	fmul	d17, d17, d22
	fmadd	d16, d26, d1, d16
	fadd	d22, d11, d12
	fmadd	d20, d23, d4, d20
	fmadd	d4, d8, d4, d17
	fsub	d17, d19, d18
	fadd	d18, d19, d18
	ldp	d28, d19, [x11]
	fadd	d26, d21, d16
	fneg	d25, d22
	ldp	d23, d24, [x8]
	fneg	d27, d17
	add	x11, x22, x14
	fsub	d16, d16, d21
	add	x8, x27, x14
	fmul	d21, d26, d19
	fmul	d19, d19, d27
	fmul	d29, d6, d24
	ldp	d27, d30, [x11]
	fmul	d24, d24, d25
	fneg	d25, d18
	stp	d20, d4, [x8, #16]
	add	x8, x24, x14
	fmadd	d4, d22, d23, d29
	fmadd	d17, d17, d28, d21
	fmadd	d19, d26, d28, d19
	add	x11, x21, x14
	fmadd	d6, d6, d23, d24
	fmul	d20, d16, d30
	fmul	d22, d30, d25
	stp	d4, d6, [x8, #16]
	fmadd	d4, d18, d27, d20
	fmadd	d6, d16, d27, d22
	add	x8, x15, x14
	stp	d17, d19, [x11, #16]
	add	x14, x14, #16
	stp	d4, d6, [x8, #16]
	ldr	d4, [sp, #80]                   // 8-byte Folded Reload
	b.ne	.LBB103_9
	b	.LBB103_6
.LBB103_10:
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #176]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #160]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #144]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #128]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.Lfunc_end103:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end103-_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI104_0:
	.xword	0x3feaeb8c8764f0ba              // double 0.84125353283118121
.LCPI104_1:
	.xword	0x3fda9628d9c712b6              // double 0.41541501300188644
.LCPI104_2:
	.xword	0x3fc2375f640f44db              // double 0.14231483827328514
.LCPI104_3:
	.xword	0x3fe4f49e7f775887              // double 0.6548607339452851
.LCPI104_4:
	.xword	0x3feeb42a9bcd5057              // double 0.95949297361449736
.LCPI104_5:
	.xword	0xbfed1bb48eee2c13              // double -0.90963199535451833
.LCPI104_6:
	.xword	0xbfe14cedf8bb580b              // double -0.54064081745559756
.LCPI104_7:
	.xword	0xbfefac9e043842ef              // double -0.98982144188093268
.LCPI104_8:
	.xword	0xbfe82f19bb3a28a1              // double -0.75574957435425827
.LCPI104_9:
	.xword	0xbfd207e7fd768dbf              // double -0.28173255684142967
.LCPI104_10:
	.xword	0x3fd207e7fd768dbf              // double 0.28173255684142967
.LCPI104_11:
	.xword	0x3fefac9e043842ef              // double 0.98982144188093268
.LCPI104_12:
	.xword	0x3fe14cedf8bb580b              // double 0.54064081745559756
.LCPI104_13:
	.xword	0x3fed1bb48eee2c13              // double 0.90963199535451833
	.section	.text._ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #688
	.cfi_def_cfa_offset 848
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #208]              // 16-byte Folded Spill
	b.ne	.LBB104_4
// %bb.1:
	cbz	x2, .LBB104_10
// %bb.2:
	adrp	x15, .LCPI104_0
	adrp	x16, .LCPI104_1
	adrp	x0, .LCPI104_2
	adrp	x1, .LCPI104_9
	add	x18, x2, x2, lsl #3
	mov	w11, #112
	ldr	d0, [x15, :lo12:.LCPI104_0]
	adrp	x15, .LCPI104_3
	ldr	x9, [sp, #208]                  // 8-byte Folded Reload
	add	x14, x2, x2, lsl #1
	add	x17, x2, x2, lsl #2
	mul	x11, x2, x11
	str	d0, [sp, #504]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI104_1]
	adrp	x16, .LCPI104_4
	lsl	x8, x14, #5
	add	x9, x9, #8
	lsl	x10, x17, #4
	str	d0, [sp, #496]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI104_2]
	adrp	x0, .LCPI104_5
	lsl	x12, x2, #6
	lsl	x13, x2, #7
	lsl	x14, x14, #4
	str	d0, [sp, #488]                  // 8-byte Folded Spill
	ldr	d0, [x15, :lo12:.LCPI104_3]
	adrp	x15, .LCPI104_6
	lsl	x17, x17, #5
	ldp	d31, d29, [sp, #488]            // 16-byte Folded Reload
	str	d0, [sp, #480]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI104_4]
	adrp	x16, .LCPI104_7
	str	d0, [sp, #472]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI104_5]
	adrp	x0, .LCPI104_8
	str	d0, [sp, #464]                  // 8-byte Folded Spill
	ldr	d0, [x15, :lo12:.LCPI104_6]
	lsl	x15, x18, #4
	adrp	x18, .LCPI104_12
	str	d0, [sp, #576]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI104_7]
	adrp	x16, .LCPI104_10
	str	d0, [sp, #568]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI104_8]
	adrp	x0, .LCPI104_11
	str	d0, [sp, #432]                  // 8-byte Folded Spill
	ldr	d0, [x1, :lo12:.LCPI104_9]
	adrp	x1, .LCPI104_13
	str	d0, [sp, #456]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI104_10]
	lsl	x16, x2, #5
	str	d0, [sp, #448]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI104_11]
	ldr	x0, [sp, #216]                  // 8-byte Folded Reload
	str	d0, [sp, #440]                  // 8-byte Folded Spill
	ldr	d0, [x18, :lo12:.LCPI104_12]
	lsl	x18, x2, #4
	add	x0, x0, #88
	str	d0, [sp, #424]                  // 8-byte Folded Spill
	ldr	d0, [x1, :lo12:.LCPI104_13]
	str	d0, [sp, #416]                  // 8-byte Folded Spill
.LBB104_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d5, d18, [x0, #-72]
	add	x1, x9, x18
	add	x3, x9, x15
	ldp	d20, d19, [x0, #72]
	subs	x2, x2, #1
	ldp	d27, d25, [x0, #56]
	ldp	d24, d26, [x0, #-56]
	fadd	d9, d5, d20
	fadd	d3, d18, d19
	fsub	d8, d5, d20
	fsub	d0, d18, d19
	ldp	d5, d18, [x0, #40]
	fadd	d4, d24, d27
	fsub	d23, d24, d27
	ldp	d19, d30, [x0, #-40]
	fadd	d16, d26, d25
	fsub	d17, d26, d25
	ldr	d26, [sp, #504]                 // 8-byte Folded Reload
	str	d0, [sp, #680]                  // 8-byte Folded Spill
	ldp	d11, d12, [x0, #24]
	fadd	d22, d19, d5
	fsub	d25, d19, d5
	fadd	d2, d30, d18
	fsub	d20, d30, d18
	ldp	d1, d24, [x0, #-88]
	fmul	d6, d3, d26
	str	d17, [sp, #608]                 // 8-byte Folded Spill
	ldp	d0, d18, [x0, #-24]
	fmul	d14, d9, d26
	fmov	d19, d16
	ldr	d28, [sp, #464]                 // 8-byte Folded Reload
	fmul	d21, d16, d29
	fadd	d6, d24, d6
	ldr	d27, [sp, #576]                 // 8-byte Folded Reload
	fadd	d5, d0, d11
	fsub	d11, d0, d11
	fmul	d17, d17, d28
	fmul	d0, d23, d28
	ldr	d16, [sp, #680]                 // 8-byte Folded Reload
	str	d8, [sp, #640]                  // 8-byte Folded Spill
	str	d23, [sp, #664]                 // 8-byte Folded Spill
	fadd	d14, d1, d14
	str	d1, [sp, #592]                  // 8-byte Folded Spill
	fmul	d7, d4, d29
	ldp	d10, d15, [x0, #8]
	fmadd	d17, d16, d27, d17
	fmadd	d0, d8, d27, d0
	ldp	d1, d23, [x0, #-8]
	str	d4, [sp, #600]                  // 8-byte Folded Spill
	fadd	d4, d18, d12
	ldp	d8, d16, [sp, #472]             // 16-byte Folded Reload
	fadd	d6, d6, d21
	fmul	d21, d2, d31
	ldr	d13, [sp, #568]                 // 8-byte Folded Reload
	str	d3, [sp, #584]                  // 8-byte Folded Spill
	str	d4, [sp, #512]                  // 8-byte Folded Spill
	fadd	d7, d14, d7
	fmov	d3, d22
	fmul	d22, d22, d31
	fsub	d6, d6, d21
	fmul	d21, d4, d16
	fadd	d4, d23, d15
	fmadd	d0, d25, d13, d0
	str	d25, [sp, #648]                 // 8-byte Folded Spill
	ldr	d25, [sp, #432]                 // 8-byte Folded Reload
	str	d20, [sp, #616]                 // 8-byte Folded Spill
	fsub	d18, d18, d12
	fsub	d7, d7, d22
	fmul	d22, d5, d16
	fadd	d12, d1, d10
	fmadd	d17, d20, d13, d17
	fsub	d20, d23, d15
	fsub	d15, d1, d10
	fsub	d6, d6, d21
	fmul	d21, d4, d8
	fmadd	d0, d11, d25, d0
	fmov	d30, d5
	ldr	d14, [sp, #456]                 // 8-byte Folded Reload
	fsub	d7, d7, d22
	ldr	d5, [sp, #584]                  // 8-byte Folded Reload
	fmul	d22, d12, d8
	fmadd	d17, d18, d25, d17
	fsub	d6, d6, d21
	fmadd	d0, d15, d14, d0
	str	d18, [sp, #656]                 // 8-byte Folded Spill
	fmul	d21, d5, d29
	fmul	d18, d19, d16
	fsub	d7, d7, d22
	fmul	d22, d9, d29
	fmadd	d17, d20, d14, d17
	str	d4, [sp, #624]                  // 8-byte Folded Spill
	fadd	d1, d0, d6
	str	d20, [sp, #672]                 // 8-byte Folded Spill
	fadd	d21, d24, d21
	ldr	d20, [sp, #592]                 // 8-byte Folded Reload
	ldr	d4, [sp, #600]                  // 8-byte Folded Reload
	str	d11, [sp, #632]                 // 8-byte Folded Spill
	fsub	d23, d7, d17
	fmov	d11, d30
	fadd	d22, d20, d22
	str	d1, [x1]
	fmul	d10, d4, d16
	fsub	d1, d21, d18
	fmul	d18, d2, d8
	fmul	d21, d30, d31
	ldr	d30, [sp, #512]                 // 8-byte Folded Reload
	stur	d23, [x1, #-8]
	fmul	d23, d3, d8
	fmov	d27, d2
	fsub	d22, d22, d10
	str	d2, [sp, #560]                  // 8-byte Folded Spill
	fsub	d0, d6, d0
	fmul	d6, d9, d31
	fsub	d1, d1, d18
	fmul	d2, d30, d31
	fadd	d7, d7, d17
	add	x1, x9, x17
	fsub	d17, d22, d23
	fmul	d22, d4, d8
	str	d0, [sp, #544]                  // 8-byte Folded Spill
	ldr	d0, [sp, #608]                  // 8-byte Folded Reload
	fsub	d6, d20, d6
	fsub	d20, d1, d2
	ldr	d1, [sp, #664]                  // 8-byte Folded Reload
	stur	d7, [x1, #-8]
	fmul	d7, d0, d25
	str	d3, [sp, #552]                  // 8-byte Folded Spill
	fsub	d17, d17, d21
	fmul	d21, d5, d31
	fmul	d2, d1, d25
	ldr	d5, [sp, #680]                  // 8-byte Folded Reload
	fsub	d6, d6, d22
	fmul	d22, d3, d29
	ldr	d3, [sp, #640]                  // 8-byte Folded Reload
	str	d9, [sp, #528]                  // 8-byte Folded Spill
	fmadd	d7, d5, d28, d7
	fmul	d23, d12, d26
	fsub	d21, d24, d21
	fmul	d10, d19, d8
	fmadd	d2, d3, d28, d2
	ldr	d18, [sp, #648]                 // 8-byte Folded Reload
	ldp	d9, d28, [sp, #440]             // 16-byte Folded Reload
	fadd	d17, d17, d23
	fadd	d6, d6, d22
	fsub	d21, d21, d10
	fmul	d22, d27, d29
	str	d19, [sp, #536]                 // 8-byte Folded Spill
	ldr	d19, [sp, #624]                 // 8-byte Folded Reload
	str	d24, [sp, #520]                 // 8-byte Folded Spill
	fmov	d27, d30
	fmul	d23, d1, d28
	fmul	d4, d0, d28
	ldr	d1, [sp, #616]                  // 8-byte Folded Reload
	fmadd	d2, d18, d28, d2
	ldr	d0, [sp, #632]                  // 8-byte Folded Reload
	fadd	d21, d21, d22
	fmul	d22, d30, d26
	fmul	d10, d19, d26
	fmadd	d23, d3, d13, d23
	fmadd	d7, d1, d28, d7
	ldp	d24, d30, [sp, #416]            // 16-byte Folded Reload
	fmadd	d4, d5, d13, d4
	fmul	d28, d11, d26
	ldr	d5, [sp, #656]                  // 8-byte Folded Reload
	fmadd	d2, d0, d9, d2
	ldr	d13, [sp, #576]                 // 8-byte Folded Reload
	fadd	d21, d21, d22
	fmadd	d23, d18, d24, d23
	fmul	d22, d12, d16
	fmadd	d7, d5, d9, d7
	fmadd	d3, d1, d24, d4
	fadd	d1, d20, d10
	fadd	d6, d6, d28
	ldr	d4, [sp, #672]                  // 8-byte Folded Reload
	fmadd	d2, d15, d30, d2
	fmadd	d23, d0, d13, d23
	ldr	d0, [sp, #544]                  // 8-byte Folded Reload
	fmadd	d3, d5, d13, d3
	fmul	d28, d19, d16
	fmadd	d7, d4, d30, d7
	fsub	d6, d6, d22
	fadd	d22, d2, d1
	str	d0, [x1]
	add	x1, x9, x16
	fmadd	d23, d15, d25, d23
	fmadd	d0, d4, d25, d3
	fsub	d21, d21, d28
	fsub	d10, d17, d7
	fadd	d7, d17, d7
	str	d22, [x1]
	ldr	d22, [sp, #528]                 // 8-byte Folded Reload
	fsub	d1, d1, d2
	ldr	d3, [sp, #592]                  // 8-byte Folded Reload
	fsub	d2, d6, d0
	ldr	d19, [sp, #600]                 // 8-byte Folded Reload
	stur	d10, [x1, #-8]
	ldr	d10, [sp, #584]                 // 8-byte Folded Reload
	stur	d7, [x3, #-8]
	fmul	d7, d22, d16
	add	x1, x9, x14
	fadd	d17, d23, d21
	str	d1, [x3]
	fmul	d1, d10, d16
	fadd	d0, d6, d0
	fadd	d6, d3, d22
	stur	d2, [x1, #-8]
	fsub	d2, d3, d7
	fmov	d20, d3
	ldr	d3, [sp, #520]                  // 8-byte Folded Reload
	ldr	d28, [sp, #536]                 // 8-byte Folded Reload
	fmul	d7, d19, d31
	ldr	d4, [sp, #552]                  // 8-byte Folded Reload
	str	d17, [x1]
	fsub	d17, d21, d23
	fsub	d1, d3, d1
	fmul	d21, d28, d31
	ldr	d18, [sp, #560]                 // 8-byte Folded Reload
	fsub	d2, d2, d7
	fmul	d7, d4, d26
	fmul	d22, d22, d8
	add	x1, x9, x13
	fmov	d23, d10
	fmov	d5, d3
	fsub	d1, d1, d21
	fmul	d21, d18, d26
	fadd	d2, d2, d7
	fmul	d7, d11, d8
	stur	d0, [x1, #-8]
	fadd	d0, d3, d10
	fsub	d20, d20, d22
	fmul	d22, d10, d8
	ldr	d10, [sp, #608]                 // 8-byte Folded Reload
	fadd	d6, d6, d19
	fmov	d3, d11
	fmul	d23, d19, d26
	fadd	d1, d1, d21
	fmov	d11, d27
	fmul	d21, d27, d8
	ldr	d27, [sp, #664]                 // 8-byte Folded Reload
	fsub	d2, d2, d7
	fmul	d7, d10, d9
	fadd	d0, d0, d28
	fsub	d19, d5, d22
	fmul	d22, d27, d9
	fmul	d28, d28, d26
	ldr	d26, [sp, #680]                 // 8-byte Folded Reload
	fadd	d6, d6, d4
	fadd	d20, d20, d23
	fmul	d4, d4, d16
	ldr	d5, [sp, #640]                  // 8-byte Folded Reload
	str	d17, [x1]
	fmadd	d7, d26, d25, d7
	fmul	d17, d10, d30
	fmul	d23, d12, d29
	fsub	d1, d1, d21
	fmadd	d21, d5, d25, d22
	fadd	d19, d19, d28
	ldr	d28, [sp, #616]                 // 8-byte Folded Reload
	fmul	d22, d27, d30
	fsub	d20, d20, d4
	ldr	d4, [sp, #624]                  // 8-byte Folded Reload
	ldr	d9, [sp, #648]                  // 8-byte Folded Reload
	fmadd	d17, d26, d14, d17
	fmadd	d7, d28, d13, d7
	fadd	d2, d2, d23
	fmul	d23, d4, d29
	fmul	d26, d18, d16
	fmadd	d21, d9, d13, d21
	fmadd	d22, d5, d14, d22
	ldr	d30, [sp, #656]                 // 8-byte Folded Reload
	fmul	d27, d3, d29
	ldr	d5, [sp, #632]                  // 8-byte Folded Reload
	fmadd	d17, d28, d25, d17
	fadd	d1, d1, d23
	fsub	d19, d19, d26
	fmadd	d7, d30, d14, d7
	fmul	d23, d11, d29
	fmadd	d21, d5, d14, d21
	fmadd	d22, d9, d25, d22
	ldr	d25, [sp, #672]                 // 8-byte Folded Reload
	fadd	d0, d0, d18
	fadd	d20, d20, d27
	fmul	d18, d12, d31
	fmadd	d17, d30, d24, d17
	fadd	d6, d6, d3
	fmadd	d7, d25, d24, d7
	fadd	d19, d19, d23
	fmadd	d21, d15, d24, d21
	fmul	d23, d4, d31
	fmadd	d22, d5, d24, d22
	ldr	d3, [sp, #568]                  // 8-byte Folded Reload
	add	x3, x9, x11
	add	x1, x9, x12
	fsub	d24, d2, d7
	fadd	d2, d2, d7
	fsub	d7, d20, d18
	fmadd	d17, d25, d3, d17
	fadd	d18, d21, d1
	fsub	d19, d19, d23
	fmadd	d5, d15, d3, d22
	fsub	d1, d1, d21
	fadd	d0, d0, d11
	stur	d2, [x3, #-8]
	fsub	d2, d7, d17
	stur	d24, [x1, #-8]
	str	d18, [x1]
	add	x1, x9, x10
	fadd	d18, d5, d19
	fadd	d6, d6, d12
	str	d1, [x3]
	fadd	d0, d0, d4
	stur	d2, [x1, #-8]
	fadd	d1, d7, d17
	fsub	d2, d19, d5
	add	x0, x0, #176
	str	d18, [x1]
	add	x1, x9, x8
	fmov	d16, d11
	stur	d6, [x9, #-8]
	str	d0, [x9], #16
	stur	d1, [x1, #-8]
	str	d2, [x1]
	b.ne	.LBB104_3
	b	.LBB104_10
.LBB104_4:
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	cbz	x2, .LBB104_10
// %bb.5:
	lsl	x9, x2, #2
	mov	w10, #176
	add	x14, x9, x2
	mul	x3, x2, x1
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	mul	x10, x1, x10
	str	x9, [sp, #192]                  // 8-byte Folded Spill
	mov	w8, #96
	ldp	x9, x25, [sp, #208]             // 16-byte Folded Reload
	mov	w11, #160
	add	x13, x27, x27, lsl #1
	str	x10, [sp, #176]                 // 8-byte Folded Spill
	lsl	x24, x13, #4
	lsl	x13, x13, #5
	lsl	x4, x27, #7
	madd	x18, x3, x8, x9
	lsl	x8, x27, #5
	add	x10, x8, x25
	madd	x12, x1, x11, x25
	add	x26, x10, #32
	add	x10, x27, x27, lsl #3
	lsl	x10, x10, #4
	add	x19, x13, x25
	add	x16, x10, x25
	add	x8, x5, x8
	stp	x12, x18, [sp, #264]            // 16-byte Folded Spill
	add	x12, x16, #144
	add	x18, x4, x25
	mov	x15, x1
	add	x10, x5, x10
	add	x7, x27, x27, lsl #2
	str	x12, [sp, #256]                 // 8-byte Folded Spill
	mov	w12, #112
	mov	w20, #80
	lsl	x21, x27, #6
	mul	x22, x27, x12
	lsl	x23, x7, #4
	madd	x12, x3, x12, x9
	str	x14, [sp, #184]                 // 8-byte Folded Spill
	add	x6, x22, x25
	add	x0, x21, x25
	add	x16, x6, #112
	add	x1, x18, #128
	add	x7, x23, x25
	madd	x20, x3, x20, x9
	add	x23, x5, x23
	str	x15, [sp, #200]                 // 8-byte Folded Spill
	str	x16, [sp, #248]                 // 8-byte Folded Spill
	add	x16, x19, #96
	add	x15, x5, x21
	add	x18, x9, x3, lsl #7
	str	x10, [sp, #104]                 // 8-byte Folded Spill
	madd	x21, x3, x11, x9
	stp	x12, x16, [sp, #232]            // 16-byte Folded Spill
	add	x12, x5, x13
	adrp	x13, .LCPI104_1
	add	x16, x9, x3, lsl #6
	add	x11, x9, x3, lsl #4
	stp	x15, x23, [sp, #160]            // 16-byte Folded Spill
	str	x12, [sp, #152]                 // 8-byte Folded Spill
	add	x12, x5, x24
	ldr	d11, [x13, :lo12:.LCPI104_1]
	adrp	x13, .LCPI104_4
	ldr	x15, [sp, #200]                 // 8-byte Folded Reload
	add	x17, x24, x25
	str	x12, [sp, #144]                 // 8-byte Folded Spill
	add	x12, x5, x22
	mov	x28, xzr
	add	x17, x17, #48
	add	x0, x0, #64
	add	x7, x7, #80
	stp	x8, x12, [sp, #128]             // 16-byte Folded Spill
	adrp	x8, .LCPI104_0
	add	x12, x5, x4
	adrp	x4, .LCPI104_2
	mov	x22, x25
	ldr	x29, [sp, #144]                 // 8-byte Folded Reload
	ldr	d16, [x8, :lo12:.LCPI104_0]
	adrp	x8, .LCPI104_3
	ldr	d0, [x4, :lo12:.LCPI104_2]
	adrp	x4, .LCPI104_5
	str	x12, [sp, #120]                 // 8-byte Folded Spill
	adrp	x12, .LCPI104_13
	str	d11, [sp, #24]                  // 8-byte Folded Spill
	str	d0, [sp, #680]                  // 8-byte Folded Spill
	ldr	d0, [x8, :lo12:.LCPI104_3]
	adrp	x8, .LCPI104_6
	str	d0, [sp, #280]                  // 8-byte Folded Spill
	ldr	d0, [x13, :lo12:.LCPI104_4]
	adrp	x13, .LCPI104_7
	str	d0, [sp, #112]                  // 8-byte Folded Spill
	ldr	d0, [x4, :lo12:.LCPI104_5]
	adrp	x4, .LCPI104_8
	str	d0, [sp, #312]                  // 8-byte Folded Spill
	ldr	d0, [x8, :lo12:.LCPI104_6]
	adrp	x8, .LCPI104_9
	str	d0, [sp, #504]                  // 8-byte Folded Spill
	ldr	d0, [x13, :lo12:.LCPI104_7]
	adrp	x13, .LCPI104_10
	str	d0, [sp, #512]                  // 8-byte Folded Spill
	ldr	d0, [x4, :lo12:.LCPI104_8]
	adrp	x4, .LCPI104_11
	str	d0, [sp, #304]                  // 8-byte Folded Spill
	ldr	d0, [x8, :lo12:.LCPI104_9]
	mov	w8, #48
	str	d0, [sp, #672]                  // 8-byte Folded Spill
	ldr	d0, [x13, :lo12:.LCPI104_10]
	adrp	x13, .LCPI104_12
	madd	x8, x3, x8, x9
	str	d0, [sp, #296]                  // 8-byte Folded Spill
	ldr	d0, [x4, :lo12:.LCPI104_11]
	mov	w4, #144
	str	d0, [sp, #288]                  // 8-byte Folded Spill
	ldr	d0, [x13, :lo12:.LCPI104_12]
	madd	x10, x3, x4, x9
	add	x13, x9, x3, lsl #5
	str	d0, [sp, #376]                  // 8-byte Folded Spill
	ldr	d0, [x12, :lo12:.LCPI104_13]
	lsl	x12, x14, #1
	lsl	x14, x2, #3
	add	x3, x14, x2
	str	d0, [sp, #664]                  // 8-byte Folded Spill
	str	x12, [sp, #96]                  // 8-byte Folded Spill
	lsl	x12, x2, #1
	stp	x3, x14, [sp, #72]              // 16-byte Folded Spill
	sub	x14, x14, x2
	str	x12, [sp, #88]                  // 8-byte Folded Spill
	add	x12, x12, x2
	stp	x14, x12, [sp, #56]             // 16-byte Folded Spill
	lsl	x14, x15, #4
	lsl	x12, x12, #1
	stp	x12, x14, [sp, #40]             // 16-byte Folded Spill
	add	x14, x25, x14
	add	x12, x5, x27, lsl #4
	str	x12, [sp, #32]                  // 8-byte Folded Spill
	b	.LBB104_7
.LBB104_6:                              //   in Loop: Header=BB104_7 Depth=1
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	fmov	d16, d8
	ldp	x15, x25, [sp, #320]            // 16-byte Folded Reload
	fmov	d11, d21
	add	x9, x9, x8
	ldr	x24, [sp, #344]                 // 8-byte Folded Reload
	ldp	x12, x11, [sp, #352]            // 16-byte Folded Reload
	add	x26, x26, x8
	add	x13, x13, x8
	str	x9, [sp, #272]                  // 8-byte Folded Spill
	ldr	x9, [sp, #176]                  // 8-byte Folded Reload
	ldr	x10, [sp, #224]                 // 8-byte Folded Reload
	add	x25, x25, x8
	add	x12, x12, x8
	add	x14, x14, x9
	add	x17, x17, x9
	add	x7, x7, x9
	add	x22, x22, x9
	add	x24, x24, x9
	add	x15, x15, x9
	stp	x17, x14, [sp, #256]            // 16-byte Folded Spill
	add	x17, x18, x9
	add	x1, x1, x9
	add	x0, x6, x9
	str	x7, [sp, #248]                  // 8-byte Folded Spill
	add	x7, x19, x9
	add	x20, x20, x9
	ldr	x9, [sp, #368]                  // 8-byte Folded Reload
	ldr	x14, [sp, #336]                 // 8-byte Folded Reload
	add	x10, x10, #1
	add	x16, x11, x8
	add	x11, x3, x8
	add	x9, x9, x8
	stp	x26, x20, [sp, #232]            // 16-byte Folded Spill
	add	x20, x23, x8
	add	x18, x14, x8
	add	x21, x4, x8
	mov	x28, x10
	cmp	x10, x2
	mov	x26, x15
	ldr	x15, [sp, #200]                 // 8-byte Folded Reload
	mov	x8, x13
	mov	x10, x9
	mov	x13, x12
	mov	x14, x24
	mov	x9, x25
	b.eq	.LBB104_10
.LBB104_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB104_9 Depth 2
	stp	x26, x9, [sp, #320]             // 16-byte Folded Spill
	mov	w9, #11
	stp	x18, x14, [sp, #336]            // 16-byte Folded Spill
	mov	x14, x28
	mul	x24, x28, x9
	ldr	x9, [sp, #216]                  // 8-byte Folded Reload
	str	x10, [sp, #368]                 // 8-byte Folded Spill
	ldr	d10, [sp, #504]                 // 8-byte Folded Reload
	add	x25, x24, #10
	add	x30, x24, #2
	mul	x27, x24, x15
	add	x10, x24, #9
	mul	x25, x25, x15
	stp	x13, x16, [sp, #352]            // 16-byte Folded Spill
	mul	x30, x30, x15
	ldr	x13, [sp, #96]                  // 8-byte Folded Reload
	add	x28, x9, x27, lsl #4
	add	x27, x15, x27
	add	x25, x9, x25, lsl #4
	mul	x10, x10, x15
	add	x27, x9, x27, lsl #4
	cmp	x15, #2
	ldp	d29, d5, [x28]
	add	x28, x24, #3
	add	x10, x9, x10, lsl #4
	ldp	d0, d1, [x27]
	add	x27, x9, x30, lsl #4
	mul	x28, x28, x15
	ldp	d2, d3, [x25]
	add	x25, x24, #8
	str	d5, [sp, #560]                  // 8-byte Folded Spill
	ldp	d6, d7, [x27]
	add	x27, x9, x28, lsl #4
	mul	x25, x25, x15
	add	x28, x24, #4
	fadd	d22, d0, d2
	ldp	d17, d18, [x10]
	mul	x10, x28, x15
	add	x25, x9, x25, lsl #4
	fadd	d15, d1, d3
	fsub	d31, d0, d2
	fsub	d14, d1, d3
	fadd	d20, d29, d22
	add	x10, x9, x10, lsl #4
	fadd	d23, d6, d17
	ldp	d0, d1, [x25]
	add	x25, x24, #7
	fadd	d8, d7, d18
	ldp	d2, d3, [x10]
	mul	x10, x25, x15
	add	x25, x24, #6
	ldp	d19, d21, [x27]
	add	x24, x24, #5
	mul	x25, x25, x15
	add	x10, x9, x10, lsl #4
	fsub	d25, d7, d18
	mul	x24, x24, x15
	fsub	d4, d6, d17
	fadd	d27, d19, d0
	fsub	d12, d19, d0
	ldp	d7, d0, [x10]
	add	x25, x9, x25, lsl #4
	fadd	d6, d20, d23
	add	x24, x9, x24, lsl #4
	fmov	d30, d22
	str	d22, [sp, #480]                 // 8-byte Folded Spill
	fmov	d26, d23
	fadd	d23, d21, d1
	fadd	d18, d2, d7
	fsub	d24, d21, d1
	fsub	d22, d2, d7
	ldp	d9, d1, [x24]
	fadd	d6, d6, d27
	fadd	d20, d3, d0
	ldp	d17, d2, [x25]
	fsub	d0, d3, d0
	fmul	d3, d15, d16
	fadd	d7, d5, d15
	str	d31, [sp, #552]                 // 8-byte Folded Spill
	fadd	d6, d6, d18
	str	d18, [sp, #528]                 // 8-byte Folded Spill
	fadd	d19, d9, d17
	mul	x10, x14, x15
	str	d0, [sp, #648]                  // 8-byte Folded Spill
	fmul	d0, d30, d16
	fadd	d13, d1, d2
	fsub	d1, d1, d2
	fadd	d3, d5, d3
	ldr	d5, [sp, #312]                  // 8-byte Folded Reload
	fsub	d30, d9, d17
	fadd	d2, d7, d8
	fadd	d0, d29, d0
	fmul	d7, d8, d11
	str	d1, [sp, #592]                  // 8-byte Folded Spill
	fadd	d1, d6, d19
	fmul	d6, d26, d11
	fmul	d17, d4, d5
	fmul	d21, d25, d5
	fadd	d2, d2, d23
	fadd	d3, d3, d7
	ldr	d7, [sp, #680]                  // 8-byte Folded Reload
	ldr	x9, [sp, #208]                  // 8-byte Folded Reload
	str	d8, [sp, #544]                  // 8-byte Folded Spill
	fadd	d0, d0, d6
	ldr	d6, [sp, #680]                  // 8-byte Folded Reload
	fmadd	d17, d31, d10, d17
	ldr	d31, [sp, #280]                 // 8-byte Folded Reload
	fmadd	d21, d14, d10, d21
	fmul	d7, d23, d7
	fmul	d6, d27, d6
	fadd	d2, d2, d20
	fmov	d8, d16
	add	x10, x9, x10, lsl #4
	fmov	d16, d24
	str	d24, [sp, #616]                 // 8-byte Folded Spill
	fsub	d3, d3, d7
	fmul	d7, d20, d31
	fsub	d0, d0, d6
	fmul	d6, d18, d31
	ldr	d18, [sp, #512]                 // 8-byte Folded Reload
	str	d4, [sp, #640]                  // 8-byte Folded Spill
	fmov	d4, d25
	str	d25, [sp, #488]                 // 8-byte Folded Spill
	str	d20, [sp, #600]                 // 8-byte Folded Spill
	ldr	d25, [sp, #304]                 // 8-byte Folded Reload
	fmadd	d17, d12, d18, d17
	ldr	d18, [sp, #512]                 // 8-byte Folded Reload
	str	d1, [x10]
	fadd	d1, d2, d13
	fsub	d0, d0, d6
	ldr	d20, [sp, #648]                 // 8-byte Folded Reload
	fmadd	d21, d24, d18, d21
	ldr	d24, [sp, #112]                 // 8-byte Folded Reload
	fmov	d9, d26
	str	d26, [sp, #632]                 // 8-byte Folded Spill
	ldr	d26, [sp, #480]                 // 8-byte Folded Reload
	str	d12, [sp, #576]                 // 8-byte Folded Spill
	fmul	d2, d19, d24
	fmov	d12, d13
	fsub	d3, d3, d7
	fmul	d6, d13, d24
	fmadd	d7, d22, d25, d17
	fmadd	d17, d20, d25, d21
	fmov	d13, d11
	str	d22, [sp, #568]                 // 8-byte Folded Spill
	str	d1, [x10, #8]
	fsub	d22, d0, d2
	fmul	d1, d26, d11
	ldr	d0, [sp, #672]                  // 8-byte Folded Reload
	ldr	d11, [sp, #592]                 // 8-byte Folded Reload
	fmov	d28, d29
	str	d23, [sp, #536]                 // 8-byte Folded Spill
	fsub	d23, d3, d6
	add	x10, x14, x2
	fmadd	d3, d30, d0, d7
	fmadd	d6, d11, d0, d17
	fmul	d7, d15, d13
	str	d19, [sp, #656]                 // 8-byte Folded Spill
	ldr	d19, [sp, #560]                 // 8-byte Folded Reload
	str	d29, [sp, #624]                 // 8-byte Folded Spill
	fmov	d29, d14
	str	d14, [sp, #608]                 // 8-byte Folded Spill
	ldr	d14, [sp, #544]                 // 8-byte Folded Reload
	mul	x10, x10, x15
	fadd	d18, d28, d1
	fmul	d17, d9, d31
	fsub	d2, d22, d6
	fadd	d7, d19, d7
	fmul	d0, d14, d31
	fmul	d21, d4, d25
	add	x10, x9, x10, lsl #4
	ldr	d28, [sp, #536]                 // 8-byte Folded Reload
	fadd	d1, d3, d23
	fsub	d17, d18, d17
	fmul	d18, d27, d24
	str	d2, [x10]
	fsub	d0, d7, d0
	fmul	d2, d28, d24
	fmadd	d21, d29, d5, d21
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	add	x24, x14, x13
	ldr	d29, [sp, #528]                 // 8-byte Folded Reload
	fsub	d7, d17, d18
	ldr	d18, [sp, #296]                 // 8-byte Folded Reload
	mul	x24, x24, x15
	fsub	d0, d0, d2
	ldr	d2, [sp, #680]                  // 8-byte Folded Reload
	fmul	d17, d29, d4
	ldr	d4, [sp, #600]                  // 8-byte Folded Reload
	str	d1, [x10, #8]
	fmadd	d1, d16, d18, d21
	fadd	d6, d22, d6
	ldr	d21, [sp, #288]                 // 8-byte Folded Reload
	fmul	d2, d4, d2
	ldr	d4, [sp, #656]                  // 8-byte Folded Reload
	fsub	d7, d7, d17
	add	x10, x9, x24, lsl #4
	fmadd	d1, d20, d21, d1
	fsub	d3, d23, d3
	fmul	d4, d4, d8
	ldr	d16, [sp, #640]                 // 8-byte Folded Reload
	str	d6, [x10]
	fsub	d0, d0, d2
	fmul	d2, d12, d8
	fmov	d23, d11
	str	d3, [x10, #8]
	ldr	d3, [sp, #680]                  // 8-byte Folded Reload
	fadd	d6, d7, d4
	ldr	d4, [sp, #376]                  // 8-byte Folded Reload
	fmul	d17, d16, d25
	ldr	d9, [sp, #552]                  // 8-byte Folded Reload
	ldr	x13, [sp, #88]                  // 8-byte Folded Reload
	fmul	d3, d15, d3
	fmadd	d1, d11, d4, d1
	fmov	d11, d4
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	fmov	d22, d26
	fmadd	d5, d9, d5, d17
	add	x24, x14, x13
	str	d15, [sp, #496]                 // 8-byte Folded Spill
	ldr	d15, [sp, #576]                 // 8-byte Folded Reload
	fmul	d7, d26, d4
	fadd	d26, d0, d2
	ldr	d0, [sp, #624]                  // 8-byte Folded Reload
	mul	x24, x24, x15
	fsub	d3, d19, d3
	fmul	d4, d14, d24
	ldr	d14, [sp, #488]                 // 8-byte Folded Reload
	fmadd	d2, d15, d18, d5
	fsub	d7, d0, d7
	ldr	d0, [sp, #632]                  // 8-byte Folded Reload
	fsub	d5, d6, d1
	add	x10, x9, x24, lsl #4
	fmul	d19, d14, d18
	fsub	d3, d3, d4
	fmul	d17, d0, d24
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	ldr	d4, [sp, #512]                  // 8-byte Folded Reload
	str	d30, [sp, #584]                 // 8-byte Folded Spill
	ldr	d20, [sp, #608]                 // 8-byte Folded Reload
	str	d5, [x10]
	fmul	d5, d16, d18
	fmadd	d2, d0, d21, d2
	fsub	d7, d7, d17
	fmul	d17, d27, d13
	fmadd	d19, d20, d4, d19
	ldr	d4, [sp, #512]                  // 8-byte Folded Reload
	ldr	d30, [sp, #584]                 // 8-byte Folded Reload
	fmul	d18, d28, d13
	fmov	d16, d28
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	fmadd	d5, d9, d4, d5
	fadd	d7, d7, d17
	fmadd	d2, d30, d11, d2
	fmul	d17, d29, d8
	fmov	d28, d29
	ldr	d29, [sp, #600]                 // 8-byte Folded Reload
	ldr	d9, [sp, #664]                  // 8-byte Folded Reload
	add	x24, x14, x13
	ldr	d4, [sp, #616]                  // 8-byte Folded Reload
	fadd	d3, d3, d18
	fmul	d18, d29, d8
	fadd	d1, d6, d1
	fmadd	d5, d15, d9, d5
	fadd	d6, d2, d26
	fmadd	d19, d4, d9, d19
	ldr	d20, [sp, #656]                 // 8-byte Folded Reload
	ldr	d4, [sp, #648]                  // 8-byte Folded Reload
	mul	x24, x24, x15
	fadd	d7, d7, d17
	fadd	d3, d3, d18
	fmul	d17, d20, d31
	fmadd	d5, d0, d10, d5
	fmadd	d18, d4, d10, d19
	fmul	d19, d12, d31
	fsub	d0, d26, d2
	add	x24, x9, x24, lsl #4
	fmov	d15, d12
	str	d12, [sp, #472]                 // 8-byte Folded Spill
	str	d6, [x10, #8]
	ldr	x10, [sp, #64]                  // 8-byte Folded Reload
	ldr	d12, [sp, #496]                 // 8-byte Folded Reload
	fmov	d26, d22
	fmul	d6, d22, d31
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	ldr	d22, [sp, #632]                 // 8-byte Folded Reload
	str	d1, [x24]
	fsub	d1, d7, d17
	fmadd	d2, d23, d25, d18
	add	x10, x14, x10
	fsub	d3, d3, d19
	fmadd	d5, d30, d25, d5
	str	d0, [x24, #8]
	fmul	d0, d12, d31
	ldr	d23, [sp, #624]                 // 8-byte Folded Reload
	fmul	d18, d22, d4
	ldr	d11, [sp, #560]                 // 8-byte Folded Reload
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	mul	x10, x10, x15
	ldr	d13, [sp, #544]                 // 8-byte Folded Reload
	fsub	d7, d1, d2
	fadd	d17, d5, d3
	fsub	d6, d23, d6
	fsub	d0, d11, d0
	add	x10, x9, x10, lsl #4
	fmul	d19, d13, d4
	ldr	d4, [sp, #640]                  // 8-byte Folded Reload
	ldr	x13, [sp, #80]                  // 8-byte Folded Reload
	fadd	d1, d1, d2
	str	d7, [x10]
	fsub	d6, d6, d18
	str	d17, [x10, #8]
	fmul	d7, d27, d8
	fsub	d0, d0, d19
	fmul	d17, d16, d8
	fmul	d18, d4, d21
	add	x24, x14, x13
	fmul	d2, d14, d21
	ldr	d21, [sp, #608]                 // 8-byte Folded Reload
	fadd	d6, d6, d7
	fmul	d7, d28, d24
	fadd	d0, d0, d17
	fmul	d17, d29, d24
	ldr	d28, [sp, #552]                 // 8-byte Folded Reload
	fmul	d19, d26, d24
	ldr	d26, [sp, #24]                  // 8-byte Folded Reload
	mul	x24, x24, x15
	fsub	d3, d3, d5
	fmadd	d2, d21, d25, d2
	fmadd	d5, d28, d25, d18
	fsub	d0, d0, d17
	fmul	d17, d15, d26
	ldr	d15, [sp, #576]                 // 8-byte Folded Reload
	fmov	d30, d14
	add	x10, x9, x24, lsl #4
	fmov	d14, d29
	ldr	d29, [sp, #616]                 // 8-byte Folded Reload
	fmadd	d5, d15, d10, d5
	fmul	d18, d12, d24
	str	d1, [x10]
	fsub	d1, d6, d7
	fmadd	d2, d29, d10, d2
	fsub	d7, d23, d19
	ldr	d10, [sp, #672]                 // 8-byte Folded Reload
	fmul	d19, d22, d8
	ldr	d22, [sp, #568]                 // 8-byte Folded Reload
	fmul	d6, d20, d26
	str	d3, [x10, #8]
	ldr	d16, [sp, #648]                 // 8-byte Folded Reload
	fadd	d0, d0, d17
	str	d27, [sp, #520]                 // 8-byte Folded Spill
	fmadd	d3, d22, d10, d5
	fsub	d5, d11, d18
	ldr	d18, [sp, #376]                 // 8-byte Folded Reload
	fadd	d1, d1, d6
	fadd	d6, d7, d19
	fmul	d7, d13, d8
	ldr	d19, [sp, #640]                 // 8-byte Folded Reload
	fmadd	d2, d16, d10, d2
	fmul	d17, d30, d18
	fmov	d27, d24
	fmov	d24, d25
	ldr	d30, [sp, #592]                 // 8-byte Folded Reload
	ldr	x10, [sp, #192]                 // 8-byte Folded Reload
	fmul	d18, d19, d18
	ldr	d25, [sp, #584]                 // 8-byte Folded Reload
	fadd	d5, d5, d7
	ldr	d19, [sp, #520]                 // 8-byte Folded Reload
	fmadd	d7, d21, d10, d17
	fmov	d20, d8
	fmadd	d2, d30, d9, d2
	add	x10, x14, x10
	fmadd	d3, d25, d9, d3
	fmul	d19, d19, d31
	ldr	d20, [sp, #536]                 // 8-byte Folded Reload
	mul	x10, x10, x15
	fmadd	d7, d29, d24, d7
	fsub	d17, d1, d2
	fmadd	d18, d28, d10, d18
	fmul	d21, d20, d31
	ldr	d20, [sp, #528]                 // 8-byte Folded Reload
	fsub	d6, d6, d19
	fadd	d19, d3, d0
	add	x10, x9, x10, lsl #4
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	fmadd	d7, d16, d9, d7
	ldr	d16, [sp, #656]                 // 8-byte Folded Reload
	fmul	d20, d20, d26
	fsub	d5, d5, d21
	str	d17, [x10]
	fmadd	d17, d15, d24, d18
	fmul	d18, d14, d26
	str	d19, [x10, #8]
	ldr	x10, [sp, #56]                  // 8-byte Folded Reload
	fmul	d19, d16, d4
	ldr	d16, [sp, #472]                 // 8-byte Folded Reload
	mov	x30, x14
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	fadd	d6, d6, d20
	add	x10, x14, x10
	ldr	x14, [sp, #184]                 // 8-byte Folded Reload
	fadd	d5, d5, d18
	fmadd	d17, d22, d9, d17
	fmul	d18, d16, d4
	ldr	d23, [sp, #512]                 // 8-byte Folded Reload
	mul	x10, x10, x15
	add	x24, x30, x14
	add	x25, x30, x13
	fadd	d1, d1, d2
	fsub	d0, d0, d3
	fsub	d2, d6, d19
	fmadd	d3, d30, d23, d7
	add	x10, x9, x10, lsl #4
	fsub	d5, d5, d18
	fmadd	d6, d25, d23, d17
	mul	x24, x24, x15
	str	x30, [sp, #224]                 // 8-byte Folded Spill
	mul	x25, x25, x15
	str	d1, [x10]
	str	d0, [x10, #8]
	mov	x18, x17
	add	x24, x9, x24, lsl #4
	mov	x19, x7
	add	x10, x9, x25, lsl #4
	mov	x23, x20
	ldp	x14, x9, [sp, #264]             // 16-byte Folded Reload
	mov	x13, x8
	fmov	d21, d26
	ldp	x15, x30, [sp, #160]            // 16-byte Folded Reload
	fsub	d1, d2, d3
	fadd	d7, d6, d5
	ldp	x7, x17, [sp, #248]             // 16-byte Folded Reload
	fadd	d0, d2, d3
	fsub	d2, d5, d6
	ldp	x26, x20, [sp, #232]            // 16-byte Folded Reload
	mov	x6, x0
	mov	x3, x11
	ldp	x8, x16, [sp, #128]             // 16-byte Folded Reload
	mov	x4, x21
	str	d1, [x24]
	ldr	x0, [sp, #152]                  // 8-byte Folded Reload
	str	d7, [x24, #8]
	ldr	x11, [sp, #120]                 // 8-byte Folded Reload
	str	d0, [x10]
	ldr	x21, [sp, #104]                 // 8-byte Folded Reload
	str	d2, [x10, #8]
	ldr	x12, [sp, #32]                  // 8-byte Folded Reload
	b.lo	.LBB104_6
// %bb.8:                               //   in Loop: Header=BB104_7 Depth=1
	mov	x24, xzr
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
.LBB104_9:                              //   Parent Loop BB104_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x10, [sp, #344]                 // 8-byte Folded Reload
	add	x27, x14, x24
	add	x28, x22, x24
	fmov	d29, d8
	fmov	d14, d21
	ldr	d24, [sp, #280]                 // 8-byte Folded Reload
	add	x10, x10, x24
	subs	x25, x25, #1
	ldp	d2, d3, [x27, #16]
	ldr	x27, [sp, #320]                 // 8-byte Folded Reload
	ldp	d0, d1, [x10, #16]
	add	x10, x17, x24
	add	x27, x27, x24
	ldp	d20, d4, [x28, #16]
	fadd	d25, d0, d2
	fsub	d13, d0, d2
	fadd	d18, d1, d3
	fsub	d16, d1, d3
	ldp	d2, d1, [x27, #16]
	add	x28, x18, x24
	add	x27, x6, x24
	ldp	d0, d3, [x10, #16]
	add	x10, x1, x24
	str	d18, [sp, #640]                 // 8-byte Folded Spill
	ldp	d5, d6, [x28, #16]
	fmul	d18, d18, d8
	fmov	d30, d25
	ldp	d7, d17, [x10, #16]
	fadd	d23, d1, d3
	add	x10, x7, x24
	fadd	d22, d2, d0
	fsub	d31, d2, d0
	fsub	d26, d1, d3
	str	d4, [sp, #616]                  // 8-byte Folded Spill
	ldp	d0, d1, [x27, #16]
	fadd	d10, d5, d7
	fadd	d12, d6, d17
	ldp	d2, d3, [x10, #16]
	fsub	d8, d5, d7
	fsub	d19, d6, d17
	fmul	d5, d25, d29
	fadd	d6, d4, d18
	fmul	d7, d23, d21
	add	x10, x19, x24
	add	x27, x20, x24
	ldr	d25, [sp, #312]                 // 8-byte Folded Reload
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	str	d20, [sp, #624]                 // 8-byte Folded Spill
	str	d26, [sp, #552]                 // 8-byte Folded Spill
	fadd	d15, d0, d2
	fadd	d11, d1, d3
	fsub	d9, d0, d2
	fsub	d28, d1, d3
	fadd	d0, d20, d5
	fmul	d1, d31, d25
	fmul	d2, d22, d21
	fadd	d3, d6, d7
	fmul	d17, d26, d25
	ldp	d6, d7, [x10, #16]
	fmul	d5, d12, d4
	str	d16, [sp, #544]                 // 8-byte Folded Spill
	ldp	d20, d26, [sp, #504]            // 16-byte Folded Reload
	fadd	d0, d0, d2
	fmul	d2, d10, d4
	ldp	d18, d21, [x27, #16]
	fsub	d3, d3, d5
	fmul	d4, d11, d24
	fmadd	d1, d13, d20, d1
	fmadd	d17, d16, d20, d17
	str	d13, [sp, #568]                 // 8-byte Folded Spill
	fsub	d0, d0, d2
	fadd	d13, d6, d18
	fmul	d2, d15, d24
	fadd	d16, d7, d21
	str	d31, [sp, #576]                 // 8-byte Folded Spill
	fmadd	d1, d8, d26, d1
	ldr	d31, [sp, #304]                 // 8-byte Folded Reload
	fsub	d5, d6, d18
	fsub	d3, d3, d4
	fmadd	d4, d19, d26, d17
	fsub	d0, d0, d2
	fmul	d6, d16, d27
	fmul	d2, d13, d27
	fmadd	d1, d9, d31, d1
	str	d19, [sp, #536]                 // 8-byte Folded Spill
	fsub	d7, d7, d21
	str	d5, [sp, #608]                  // 8-byte Folded Spill
	fmadd	d4, d28, d31, d4
	add	x10, x5, x24
	fsub	d19, d3, d6
	ldr	d3, [sp, #672]                  // 8-byte Folded Reload
	str	d16, [sp, #648]                 // 8-byte Folded Spill
	add	x27, x21, x24
	str	d8, [sp, #584]                  // 8-byte Folded Spill
	ldr	d8, [sp, #640]                  // 8-byte Folded Reload
	fmadd	d18, d5, d3, d1
	fsub	d5, d0, d2
	ldr	d0, [sp, #672]                  // 8-byte Folded Reload
	str	d23, [sp, #632]                 // 8-byte Folded Spill
	fmov	d23, d11
	fmul	d17, d8, d14
	fmov	d11, d24
	str	d9, [sp, #592]                  // 8-byte Folded Spill
	fmadd	d4, d7, d0, d4
	fadd	d20, d18, d19
	ldp	d0, d6, [x10]
	str	d28, [sp, #560]                 // 8-byte Folded Spill
	fmov	d9, d13
	fmov	d13, d27
	ldr	d27, [sp, #616]                 // 8-byte Folded Reload
	fsub	d21, d5, d4
	fadd	d4, d5, d4
	fsub	d5, d19, d18
	ldr	d28, [sp, #632]                 // 8-byte Folded Reload
	fmul	d16, d20, d6
	str	d7, [sp, #600]                  // 8-byte Folded Spill
	fmul	d7, d30, d14
	ldr	d24, [sp, #624]                 // 8-byte Folded Reload
	fneg	d2, d21
	fadd	d17, d27, d17
	fmul	d3, d28, d11
	fmul	d1, d22, d11
	fmadd	d16, d21, d0, d16
	fmul	d19, d12, d13
	fadd	d7, d24, d7
	ldr	d21, [sp, #552]                 // 8-byte Folded Reload
	fmul	d2, d6, d2
	stp	d30, d22, [sp, #400]            // 16-byte Folded Spill
	fsub	d3, d17, d3
	fneg	d17, d4
	str	d16, [sp, #480]                 // 8-byte Folded Spill
	add	x10, x12, x24
	ldp	d18, d16, [x27]
	fmadd	d0, d20, d0, d2
	fsub	d1, d7, d1
	fmul	d7, d10, d13
	fsub	d3, d3, d19
	ldr	d19, [sp, #544]                 // 8-byte Folded Reload
	str	d10, [sp, #656]                 // 8-byte Folded Spill
	ldr	d20, [sp, #576]                 // 8-byte Folded Reload
	str	d9, [sp, #392]                  // 8-byte Folded Spill
	fmul	d6, d5, d16
	str	d0, [sp, #496]                  // 8-byte Folded Spill
	fsub	d1, d1, d7
	ldr	d7, [sp, #680]                  // 8-byte Folded Reload
	fmul	d0, d21, d31
	ldr	d10, [sp, #648]                 // 8-byte Folded Reload
	str	d23, [sp, #528]                 // 8-byte Folded Spill
	add	x27, x11, x24
	fmadd	d2, d4, d18, d6
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	ldr	d6, [sp, #680]                  // 8-byte Folded Reload
	fmul	d7, d15, d7
	fmadd	d0, d19, d25, d0
	str	d12, [sp, #520]                 // 8-byte Folded Spill
	fmul	d4, d23, d4
	add	x28, x8, x24
	str	d2, [sp, #488]                  // 8-byte Folded Spill
	fmul	d2, d16, d17
	fmul	d6, d30, d6
	fsub	d1, d1, d7
	fmul	d7, d9, d29
	fmul	d16, d28, d13
	fsub	d3, d3, d4
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	fmadd	d2, d5, d18, d2
	ldp	d28, d18, [sp, #288]            // 16-byte Folded Reload
	fsub	d5, d24, d6
	fmul	d6, d22, d13
	ldr	d22, [sp, #536]                 // 8-byte Folded Reload
	fmul	d4, d8, d4
	ldr	d8, [sp, #568]                  // 8-byte Folded Reload
	fadd	d1, d1, d7
	str	d2, [sp, #472]                  // 8-byte Folded Spill
	fmul	d2, d20, d31
	fmadd	d0, d22, d18, d0
	fsub	d5, d5, d6
	fmul	d6, d21, d18
	ldr	d21, [sp, #560]                 // 8-byte Folded Reload
	fmul	d7, d10, d29
	fmadd	d2, d8, d25, d2
	fsub	d4, d27, d4
	ldr	d25, [sp, #584]                 // 8-byte Folded Reload
	fmov	d30, d9
	fmadd	d0, d21, d28, d0
	ldr	d17, [sp, #656]                 // 8-byte Folded Reload
	ldr	d9, [sp, #376]                  // 8-byte Folded Reload
	fadd	d3, d3, d7
	ldr	d27, [sp, #600]                 // 8-byte Folded Reload
	fmadd	d2, d25, d18, d2
	fmul	d17, d17, d14
	fsub	d4, d4, d16
	fmul	d7, d12, d14
	fmul	d16, d20, d18
	ldr	d24, [sp, #592]                 // 8-byte Folded Reload
	fmadd	d6, d19, d26, d6
	fmadd	d0, d27, d9, d0
	ldr	d18, [sp, #664]                 // 8-byte Folded Reload
	fadd	d5, d5, d17
	fmul	d17, d15, d29
	fmadd	d2, d24, d28, d2
	fadd	d4, d4, d7
	fmul	d7, d23, d29
	fmadd	d16, d8, d26, d16
	ldr	d23, [sp, #608]                 // 8-byte Folded Reload
	fmadd	d6, d22, d18, d6
	fsub	d18, d1, d0
	fadd	d20, d1, d0
	ldr	d0, [sp, #664]                  // 8-byte Folded Reload
	fadd	d1, d5, d17
	fmadd	d2, d23, d9, d2
	fadd	d4, d4, d7
	fmul	d7, d30, d11
	fmov	d12, d15
	fmadd	d5, d25, d0, d16
	ldr	d0, [sp, #504]                  // 8-byte Folded Reload
	fmul	d16, d10, d11
	fneg	d19, d18
	fadd	d17, d2, d3
	fsub	d3, d3, d2
	fmadd	d6, d21, d0, d6
	ldr	d2, [x10, #8]
	fmov	d15, d25
	fmadd	d5, d24, d0, d5
	fmov	d10, d0
	fsub	d25, d1, d7
	ldp	d0, d1, [x27]
	fsub	d22, d4, d16
	fmul	d16, d2, d19
	fmadd	d24, d27, d31, d6
	fneg	d6, d20
	fmul	d7, d17, d2
	ldr	d19, [x10]
	fmadd	d23, d23, d31, d5
	fmov	d8, d29
	fmul	d2, d3, d1
	ldr	d26, [sp, #576]                 // 8-byte Folded Reload
	fmul	d6, d1, d6
	fmadd	d1, d17, d19, d16
	fmadd	d5, d18, d19, d7
	fsub	d4, d25, d24
	fadd	d18, d23, d22
	ldr	d16, [x28, #8]
	ldp	d30, d29, [sp, #400]            // 16-byte Folded Reload
	add	x10, x16, x24
	str	d12, [sp, #384]                 // 8-byte Folded Spill
	stp	d5, d1, [sp, #424]              // 16-byte Folded Spill
	fmadd	d7, d20, d0, d2
	fmadd	d0, d3, d0, d6
	fmul	d19, d18, d16
	ldr	d20, [x28]
	fmul	d6, d30, d11
	ldr	d5, [sp, #640]                  // 8-byte Folded Reload
	add	x28, x30, x24
	fneg	d1, d4
	str	d0, [sp, #440]                  // 8-byte Folded Spill
	ldr	d0, [sp, #624]                  // 8-byte Folded Reload
	fmul	d2, d5, d11
	fmadd	d4, d4, d20, d19
	ldr	x27, [sp, #328]                 // 8-byte Folded Reload
	fmul	d16, d16, d1
	ldr	d1, [sp, #616]                  // 8-byte Folded Reload
	fadd	d3, d0, d30
	ldr	d27, [sp, #592]                 // 8-byte Folded Reload
	stp	d4, d7, [sp, #448]              // 16-byte Folded Spill
	ldr	d4, [sp, #680]                  // 8-byte Folded Reload
	fadd	d7, d1, d5
	fsub	d5, d0, d6
	fsub	d21, d1, d2
	ldr	d0, [sp, #632]                  // 8-byte Folded Reload
	fmadd	d1, d18, d20, d16
	ldr	d6, [sp, #680]                  // 8-byte Folded Reload
	fadd	d3, d3, d29
	ldr	d18, [sp, #568]                 // 8-byte Folded Reload
	fmul	d19, d0, d4
	fadd	d2, d7, d0
	fmul	d17, d29, d6
	ldr	d4, [sp, #520]                  // 8-byte Folded Reload
	str	d1, [sp, #464]                  // 8-byte Folded Spill
	ldr	d1, [sp, #656]                  // 8-byte Folded Reload
	ldr	d7, [sp, #544]                  // 8-byte Folded Reload
	add	x27, x27, x24
	fadd	d2, d2, d4
	ldr	d6, [sp, #536]                  // 8-byte Folded Reload
	fmul	d16, d1, d8
	fadd	d3, d3, d1
	fsub	d1, d21, d19
	fmul	d19, d4, d8
	fmov	d4, d12
	fsub	d0, d5, d17
	fadd	d17, d25, d24
	ldr	d24, [sp, #552]                 // 8-byte Folded Reload
	ldr	d4, [sp, #528]                  // 8-byte Folded Reload
	fadd	d3, d3, d12
	ldr	d25, [sp, #648]                 // 8-byte Folded Reload
	fadd	d1, d1, d19
	fmul	d20, d24, d28
	fadd	d0, d0, d16
	fadd	d2, d2, d4
	fmul	d16, d26, d28
	ldr	d28, [sp, #392]                 // 8-byte Folded Reload
	fmul	d19, d12, d13
	fmul	d21, d4, d13
	fsub	d5, d22, d23
	fmadd	d20, d7, d31, d20
	fneg	d22, d17
	fadd	d3, d3, d28
	fadd	d2, d2, d25
	fmadd	d16, d18, d31, d16
	fsub	d4, d0, d19
	ldr	d0, [sp, #672]                  // 8-byte Folded Reload
	fsub	d1, d1, d21
	ldr	d12, [sp, #608]                 // 8-byte Folded Reload
	fmul	d23, d28, d14
	stp	d3, d2, [x27, #16]
	fmadd	d3, d6, d10, d20
	ldp	d20, d19, [x10]
	fmadd	d16, d15, d10, d16
	add	x10, x3, x24
	ldr	d2, [sp, #672]                  // 8-byte Folded Reload
	fadd	d4, d4, d23
	add	x27, x29, x24
	fmov	d15, d28
	ldr	d23, [sp, #472]                 // 8-byte Folded Reload
	fmul	d21, d5, d19
	fmadd	d16, d27, d0, d16
	fmul	d0, d25, d14
	ldr	d25, [sp, #560]                 // 8-byte Folded Reload
	ldr	d10, [sp, #672]                 // 8-byte Folded Reload
	fmadd	d2, d25, d2, d3
	fmadd	d3, d17, d20, d21
	fadd	d0, d1, d0
	ldr	d1, [sp, #664]                  // 8-byte Folded Reload
	fmul	d17, d19, d22
	ldr	d21, [sp, #624]                 // 8-byte Folded Reload
	ldp	d19, d22, [sp, #480]            // 16-byte Folded Reload
	str	d3, [sp, #416]                  // 8-byte Folded Spill
	fmadd	d1, d12, d1, d16
	ldr	d16, [sp, #664]                 // 8-byte Folded Reload
	ldr	d3, [sp, #600]                  // 8-byte Folded Reload
	fmadd	d5, d5, d20, d17
	ldr	d17, [sp, #496]                 // 8-byte Folded Reload
	ldp	d28, d20, [x27]
	fmadd	d2, d3, d16, d2
	fmul	d16, d30, d13
	stp	d19, d17, [x10, #16]
	add	x10, x4, x24
	fadd	d17, d1, d0
	ldr	d30, [sp, #616]                 // 8-byte Folded Reload
	fsub	d0, d0, d1
	ldr	x27, [sp, #368]                 // 8-byte Folded Reload
	fsub	d19, d4, d2
	fsub	d16, d21, d16
	ldr	d21, [sp, #640]                 // 8-byte Folded Reload
	stp	d22, d23, [x10, #16]
	fmul	d22, d29, d8
	fmul	d23, d17, d20
	ldr	x10, [sp, #352]                 // 8-byte Folded Reload
	fneg	d29, d19
	fmul	d21, d21, d13
	fadd	d2, d4, d2
	add	x27, x27, x24
	fadd	d16, d16, d22
	ldr	d22, [sp, #656]                 // 8-byte Folded Reload
	add	x10, x10, x24
	fmadd	d19, d19, d28, d23
	fmul	d20, d20, d29
	fmul	d29, d24, d9
	fsub	d21, d30, d21
	ldr	d30, [sp, #632]                 // 8-byte Folded Reload
	fmul	d22, d22, d11
	fmul	d23, d26, d9
	ldr	d9, [sp, #664]                  // 8-byte Folded Reload
	fneg	d1, d2
	fmadd	d29, d7, d10, d29
	ldr	d4, [sp, #424]                  // 8-byte Folded Reload
	fmul	d30, d30, d8
	fmadd	d17, d17, d28, d20
	fsub	d16, d16, d22
	ldr	d22, [sp, #520]                 // 8-byte Folded Reload
	ldr	d7, [sp, #432]                  // 8-byte Folded Reload
	fmadd	d23, d18, d10, d23
	ldr	d18, [sp, #384]                 // 8-byte Folded Reload
	fadd	d21, d21, d30
	fmul	d22, d22, d11
	stp	d4, d7, [x10, #16]
	ldr	d7, [sp, #528]                  // 8-byte Folded Reload
	fmul	d30, d18, d14
	add	x10, x0, x24
	fsub	d18, d21, d22
	fmul	d20, d7, d14
	ldr	d7, [sp, #584]                  // 8-byte Folded Reload
	fmadd	d21, d6, d31, d29
	fadd	d4, d16, d30
	ldr	d22, [sp, #680]                 // 8-byte Folded Reload
	ldr	d6, [sp, #648]                  // 8-byte Folded Reload
	fmadd	d16, d7, d31, d23
	fadd	d18, d18, d20
	ldr	d20, [sp, #680]                 // 8-byte Folded Reload
	fmul	d22, d15, d22
	fmadd	d21, d25, d9, d21
	ldr	d23, [x10, #8]
	fmul	d20, d6, d20
	fmadd	d16, d27, d9, d16
	ldr	d6, [sp, #512]                  // 8-byte Folded Reload
	fsub	d4, d4, d22
	fmul	d1, d23, d1
	ldr	d22, [x10]
	add	x10, x15, x24
	fmov	d27, d13
	fsub	d18, d18, d20
	fmul	d20, d0, d23
	fmadd	d21, d3, d6, d21
	fmadd	d16, d12, d6, d16
	ldp	d7, d6, [sp, #448]              // 16-byte Folded Reload
	fmadd	d0, d0, d22, d1
	ldr	d3, [sp, #440]                  // 8-byte Folded Reload
	fmadd	d2, d2, d22, d20
	fsub	d1, d4, d21
	fadd	d4, d4, d21
	stp	d6, d3, [x27, #16]
	add	x27, x13, x24
	ldp	d22, d21, [x10]
	fadd	d20, d16, d18
	fsub	d16, d18, d16
	ldr	x10, [sp, #336]                 // 8-byte Folded Reload
	fneg	d6, d1
	ldr	d3, [sp, #464]                  // 8-byte Folded Reload
	fneg	d18, d4
	add	x10, x10, x24
	stp	d7, d3, [x27, #16]
	ldr	d3, [sp, #416]                  // 8-byte Folded Reload
	fmul	d7, d20, d21
	add	x27, x26, x24
	stp	d3, d5, [x10, #16]
	ldr	x10, [sp, #360]                 // 8-byte Folded Reload
	fmul	d5, d21, d6
	fmadd	d1, d1, d22, d7
	ldp	d7, d3, [x28]
	fmul	d6, d16, d3
	fmul	d3, d3, d18
	add	x10, x10, x24
	fmov	d21, d14
	fmadd	d5, d20, d22, d5
	stp	d19, d17, [x10, #16]
	fmadd	d4, d4, d7, d6
	stp	d2, d0, [x27, #16]
	fmadd	d2, d16, d7, d3
	add	x10, x23, x24
	add	x27, x9, x24
	add	x24, x24, #16
	stp	d1, d5, [x10, #16]
	stp	d4, d2, [x27, #16]
	b.ne	.LBB104_9
	b	.LBB104_6
.LBB104_10:
	add	sp, sp, #688
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end104:
	.size	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end104-_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
.LCPI105_0:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_,@function
_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_: // @_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #496
	stp	x29, x30, [sp, #400]            // 16-byte Folded Spill
	add	x29, sp, #400
	stp	x28, x27, [sp, #416]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #432]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #448]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #464]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #480]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #4
	mov	x26, x7
	add	x0, x8, #64
	stur	x6, [x29, #-136]                // 8-byte Folded Spill
	mov	x23, x2
	stur	x5, [x29, #-32]                 // 8-byte Folded Spill
	mov	x27, x4
	mov	x28, x3
	mov	x22, x1
	bl	malloc
	cbz	x0, .LBB105_154
// %bb.1:
	adrp	x8, .LCPI105_0
	add	x9, x0, #64
	add	x20, x23, #1
	mul	x24, x28, x22
	and	x14, x9, #0xffffffffffffffc0
	lsr	x5, x20, #1
	ldr	q0, [x8, :lo12:.LCPI105_0]
	subs	x15, x23, #2
	stur	x27, [x29, #-64]                // 8-byte Folded Spill
	stur	x0, [x14, #-8]
	str	q0, [x14]
	stur	x14, [x29, #-40]                // 8-byte Folded Spill
	stur	x24, [x29, #-16]                // 8-byte Folded Spill
	stp	x28, x22, [x29, #-104]          // 16-byte Folded Spill
	str	x5, [sp, #160]                  // 8-byte Folded Spill
	b.lo	.LBB105_4
// %bb.2:
	sub	x0, x23, #1
	cmp	x0, #4
	b.hs	.LBB105_6
// %bb.3:
	mov	w8, #1
	b	.LBB105_13
.LBB105_4:
	ldur	x26, [x29, #-32]                // 8-byte Folded Reload
	cbz	x28, .LBB105_124
// %bb.5:
	cbnz	x22, .LBB105_17
	b	.LBB105_124
.LBB105_6:
	cmp	xzr, x15, lsr #60
	add	x11, x14, #16
	lsl	x10, x15, #4
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB105_13
// %bb.7:
	tbnz	w9, #0, .LBB105_13
// %bb.8:
	add	x11, x14, #24
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB105_13
// %bb.9:
	tbnz	w9, #0, .LBB105_13
// %bb.10:
	and	x9, x0, #0xfffffffffffffffc
	add	x10, x14, #48
	orr	x8, x9, #0x1
	add	x11, x26, #48
	mov	x12, x9
.LBB105_11:                             // =>This Inner Loop Header: Depth=1
	ld2	{ v0.2d, v1.2d }, [x11]
	sub	x13, x11, #32
	add	x11, x11, #64
	subs	x12, x12, #4
	ld2	{ v2.2d, v3.2d }, [x13]
	sub	x13, x10, #32
	fneg	v1.2d, v1.2d
	fneg	v3.2d, v3.2d
	st2	{ v0.2d, v1.2d }, [x10]
	add	x10, x10, #64
	st2	{ v2.2d, v3.2d }, [x13]
	b.ne	.LBB105_11
// %bb.12:
	cmp	x0, x9
	b.eq	.LBB105_15
.LBB105_13:
	sub	x9, x23, x8
	lsl	x8, x8, #4
	add	x10, x26, x8
	add	x11, x14, x8
	add	x8, x10, #8
	add	x10, x11, #8
.LBB105_14:                             // =>This Inner Loop Header: Depth=1
	ldp	d1, d0, [x8, #-8]
	subs	x9, x9, #1
	add	x8, x8, #16
	fneg	d0, d0
	stp	d1, d0, [x10, #-8]
	add	x10, x10, #16
	b.ne	.LBB105_14
.LBB105_15:
	cbz	x28, .LBB105_77
// %bb.16:
	ldur	x26, [x29, #-32]                // 8-byte Folded Reload
	cbz	x22, .LBB105_79
.LBB105_17:
	mul	x8, x23, x22
	lsl	x2, x22, #4
	mov	x19, x28
	str	x15, [sp, #184]                 // 8-byte Folded Spill
	lsl	x21, x8, #4
	stur	x2, [x29, #-112]                // 8-byte Folded Spill
.LBB105_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	bl	memcpy
	ldur	x2, [x29, #-112]                // 8-byte Folded Reload
	add	x27, x27, x21
	subs	x19, x19, #1
	add	x26, x26, x2
	b.ne	.LBB105_18
// %bb.19:
	sub	x8, x23, #1
	str	x20, [sp, #176]                 // 8-byte Folded Spill
	cmp	x20, #3
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldur	x26, [x29, #-32]                // 8-byte Folded Reload
	b.ls	.LBB105_45
// %bb.20:
	cbz	x22, .LBB105_92
// %bb.21:
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	mov	w9, #2
	lsl	x11, x28, #4
	sub	x10, x22, #1
	add	x11, x11, #16
	lsl	x14, x10, #4
	cmp	x8, #2
	mov	x12, xzr
	csel	x8, x8, x9, hi
	mul	x11, x11, x22
	cmp	xzr, x10, lsr #60
	add	x18, x14, #16
	cset	w13, ne
	stur	x8, [x29, #-176]                // 8-byte Folded Spill
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	mul	x9, x8, x28
	mul	x15, x24, x8
	lsl	x9, x9, #4
	add	x9, x9, #16
	add	x0, x26, x15, lsl #4
	mul	x9, x9, x22
	stp	x9, x11, [x29, #-80]            // 16-byte Folded Spill
	and	x9, x22, #0xfffffffffffffffe
	add	x11, x26, x24, lsl #4
	stur	x9, [x29, #-88]                 // 8-byte Folded Spill
	mul	x9, x22, x8
	lsl	x8, x24, #4
	stp	x8, x15, [x29, #-192]           // 16-byte Folded Spill
	neg	x8, x8
	str	x8, [sp, #200]                  // 8-byte Folded Spill
	ldur	x8, [x29, #-64]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-112]               // 8-byte Folded Reload
	add	x3, x8, x9, lsl #4
	mov	w9, #1
	add	x2, x8, x10
	neg	x8, x10
	str	x8, [sp, #192]                  // 8-byte Folded Spill
	b	.LBB105_23
.LBB105_22:                             //   in Loop: Header=BB105_23 Depth=1
	ldp	x11, x12, [x29, #-128]          // 16-byte Folded Reload
	ldur	x8, [x29, #-192]                // 8-byte Folded Reload
	ldp	x2, x0, [x29, #-152]            // 16-byte Folded Reload
	add	x11, x11, x8
	ldr	x8, [sp, #200]                  // 8-byte Folded Reload
	ldp	x9, x3, [x29, #-168]            // 16-byte Folded Reload
	add	x12, x12, #1
	add	x2, x2, x18
	add	x0, x0, x8
	ldr	x8, [sp, #192]                  // 8-byte Folded Reload
	add	x9, x9, #1
	add	x3, x3, x8
	ldur	x8, [x29, #-176]                // 8-byte Folded Reload
	cmp	x9, x8
	b.eq	.LBB105_45
.LBB105_23:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_24 Depth 2
                                        //       Child Loop BB105_37 Depth 3
                                        //       Child Loop BB105_41 Depth 3
	ldur	x8, [x29, #-184]                // 8-byte Folded Reload
	stp	x9, x3, [x29, #-168]            // 16-byte Folded Spill
	mul	x9, x24, x12
	mov	x6, xzr
	madd	x25, x24, x12, x24
	stp	x11, x12, [x29, #-128]          // 16-byte Folded Spill
	msub	x7, x24, x12, x8
	add	x10, x24, x9
	sub	x8, x8, x9
	stp	x2, x0, [x29, #-152]            // 16-byte Folded Spill
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	stp	x8, x10, [x29, #-56]            // 16-byte Folded Spill
	mov	x10, x11
.LBB105_24:                             //   Parent Loop BB105_23 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB105_37 Depth 3
                                        //       Child Loop BB105_41 Depth 3
	cmp	x22, #2
	b.hs	.LBB105_26
// %bb.25:                              //   in Loop: Header=BB105_24 Depth=2
	mov	x19, xzr
	b	.LBB105_40
.LBB105_26:                             //   in Loop: Header=BB105_24 Depth=2
	mul	x20, x6, x22
	mov	x19, xzr
	add	x11, x7, x20
	add	x12, x25, x20
	add	x11, x26, x11, lsl #4
	add	x17, x26, x12, lsl #4
	add	x12, x11, #8
	add	x16, x11, x14
	add	x1, x17, #8
	cmp	x16, x11
	add	x11, x12, x14
	cset	w4, lo
	cmp	x11, x12
	add	x11, x1, x14
	cset	w12, lo
	cmp	x11, x1
	add	x11, x17, x14
	cset	w16, lo
	cmp	x11, x17
	orr	w17, w4, w13
	cset	w11, lo
	tbnz	w17, #0, .LBB105_40
// %bb.27:                              //   in Loop: Header=BB105_24 Depth=2
	orr	w12, w12, w13
	tbnz	w12, #0, .LBB105_40
// %bb.28:                              //   in Loop: Header=BB105_24 Depth=2
	orr	w12, w16, w13
	tbnz	w12, #0, .LBB105_40
// %bb.29:                              //   in Loop: Header=BB105_24 Depth=2
	orr	w11, w11, w13
	tbnz	w11, #0, .LBB105_40
// %bb.30:                              //   in Loop: Header=BB105_24 Depth=2
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	mov	x19, xzr
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x11, x8, x20
	sub	x17, x20, x8
	ldur	x8, [x29, #-72]                 // 8-byte Folded Reload
	add	x12, x9, x20
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	add	x11, x26, x11, lsl #4
	add	x12, x26, x12, lsl #4
	add	x17, x26, x17, lsl #4
	add	x11, x11, x8
	ldur	x8, [x29, #-80]                 // 8-byte Folded Reload
	add	x16, x9, x20
	sub	x1, x11, #8
	add	x5, x12, #8
	cmp	x11, x12
	add	x8, x17, x8
	add	x30, x26, x16, lsl #4
	sub	x9, x8, #8
	cset	w26, hi
	cmp	x1, x5
	add	x15, x30, #8
	cset	w27, hi
	cmp	x9, x12
	cset	w16, hi
	cmp	x1, x30
	cset	w22, hi
	cmp	x8, x12
	cset	w20, hi
	cmp	x1, x15
	cset	w17, hi
	cmp	x9, x5
	cset	w28, hi
	cmp	x11, x30
	cset	w4, hi
	cmp	x8, x5
	cset	w5, hi
	cmp	x11, x15
	cset	w11, hi
	cmp	x8, x30
	cset	w1, hi
	cmp	x9, x15
	and	w8, w26, w27
	cset	w12, hi
	tbnz	w8, #0, .LBB105_43
// %bb.31:                              //   in Loop: Header=BB105_24 Depth=2
	and	w8, w16, w22
	ldur	x26, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB105_44
// %bb.32:                              //   in Loop: Header=BB105_24 Depth=2
	and	w8, w20, w17
	ldur	x22, [x29, #-96]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB105_39
// %bb.33:                              //   in Loop: Header=BB105_24 Depth=2
	and	w8, w28, w4
	tbnz	w8, #0, .LBB105_39
// %bb.34:                              //   in Loop: Header=BB105_24 Depth=2
	and	w8, w5, w11
	ldur	x28, [x29, #-104]               // 8-byte Folded Reload
	tbnz	w8, #0, .LBB105_40
// %bb.35:                              //   in Loop: Header=BB105_24 Depth=2
	and	w8, w1, w12
	tbnz	w8, #0, .LBB105_40
// %bb.36:                              //   in Loop: Header=BB105_24 Depth=2
	ldur	x19, [x29, #-88]                // 8-byte Folded Reload
	mov	x20, x3
	mov	x22, x2
	mov	x28, x0
	mov	x16, x10
.LBB105_37:                             //   Parent Loop BB105_23 Depth=1
                                        //     Parent Loop BB105_24 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.2d, v1.2d }, [x22], #32
	subs	x19, x19, #2
	ld2	{ v2.2d, v3.2d }, [x20], #32
	fadd	v4.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x16], #32
	fsub	v4.2d, v0.2d, v2.2d
	fsub	v5.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x28], #32
	b.ne	.LBB105_37
// %bb.38:                              //   in Loop: Header=BB105_24 Depth=2
	ldp	x22, x8, [x29, #-96]            // 16-byte Folded Reload
	ldur	x28, [x29, #-104]               // 8-byte Folded Reload
	mov	x19, x8
	cmp	x8, x22
	b.ne	.LBB105_40
	b	.LBB105_42
.LBB105_39:                             //   in Loop: Header=BB105_24 Depth=2
	ldur	x28, [x29, #-104]               // 8-byte Folded Reload
.LBB105_40:                             //   in Loop: Header=BB105_24 Depth=2
	sub	x16, x22, x19
	lsl	x19, x19, #4
.LBB105_41:                             //   Parent Loop BB105_23 Depth=1
                                        //     Parent Loop BB105_24 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x8, x2, x19
	add	x9, x3, x19
	subs	x16, x16, #1
	ldp	d0, d1, [x8]
	add	x8, x10, x19
	ldp	d2, d3, [x9]
	add	x9, x0, x19
	add	x19, x19, #16
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stp	d4, d5, [x8]
	stp	d0, d1, [x9]
	b.ne	.LBB105_41
.LBB105_42:                             //   in Loop: Header=BB105_24 Depth=2
	add	x6, x6, #1
	add	x10, x10, x18
	add	x0, x0, x18
	add	x2, x2, x21
	add	x3, x3, x21
	cmp	x6, x28
	b.ne	.LBB105_24
	b	.LBB105_22
.LBB105_43:                             //   in Loop: Header=BB105_24 Depth=2
	ldp	x28, x22, [x29, #-104]          // 16-byte Folded Reload
	ldur	x26, [x29, #-32]                // 8-byte Folded Reload
	b	.LBB105_40
.LBB105_44:                             //   in Loop: Header=BB105_24 Depth=2
	ldp	x28, x22, [x29, #-104]          // 16-byte Folded Reload
	b	.LBB105_40
.LBB105_45:
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldr	x2, [sp, #176]                  // 8-byte Folded Reload
	ldur	x18, [x29, #-112]               // 8-byte Folded Reload
	cbz	x22, .LBB105_53
// %bb.46:
	cmp	x2, #3
	b.ls	.LBB105_81
// %bb.47:
	cmp	x5, #2
	mov	w9, #2
	csel	x9, x5, x9, hi
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x26, x24, lsl #4
	lsl	x11, x24, #4
.LBB105_48:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_49 Depth 2
                                        //       Child Loop BB105_50 Depth 3
	mul	x13, x8, x22
	mov	x12, xzr
	mov	x14, x10
.LBB105_49:                             //   Parent Loop BB105_48 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB105_50 Depth 3
	add	x15, x12, x13
	mov	x16, x14
	mov	x17, x9
	ldr	q0, [x26, x15, lsl #4]
.LBB105_50:                             //   Parent Loop BB105_48 Depth=1
                                        //     Parent Loop BB105_49 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q1, [x16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.2d, v0.2d, v1.2d
	b.ne	.LBB105_50
// %bb.51:                              //   in Loop: Header=BB105_49 Depth=2
	add	x12, x12, #1
	add	x14, x14, #16
	cmp	x12, x22
	str	q0, [x27, x15, lsl #4]
	b.ne	.LBB105_49
// %bb.52:                              //   in Loop: Header=BB105_48 Depth=1
	add	x8, x8, #1
	add	x10, x10, x18
	cmp	x8, x28
	b.ne	.LBB105_48
.LBB105_53:
	mov	w10, wzr
	mov	w9, wzr
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	cmp	x2, #4
	ldr	x15, [sp, #184]                 // 8-byte Folded Reload
	b.hs	.LBB105_93
// %bb.54:
	subs	x8, x22, #1
	b.ne	.LBB105_122
.LBB105_55:
	cmp	x24, #0
	eor	w9, w9, #0x1
	cset	w8, eq
	orr	w8, w9, w8
	tbnz	w8, #0, .LBB105_124
// %bb.56:
	mul	x10, x0, x28
	lsl	x11, x0, #4
	sub	x14, x24, #1
	add	x12, x11, #16
	cmp	x5, #2
	mov	w9, #2
	mul	x10, x10, x22
	csel	x9, x5, x9, hi
	mul	x12, x24, x12
	cmp	xzr, x14, lsr #60
	lsl	x14, x14, #4
	mov	x8, xzr
	lsl	x11, x24, #1
	cset	w13, ne
	and	x15, x24, #0xfffffffffffffffe
	add	x16, x27, x24, lsl #4
	add	x17, x14, #16
	add	x18, x27, x10, lsl #4
	neg	x0, x24, lsl #4
	mov	w1, #1
.LBB105_57:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_73 Depth 2
                                        //     Child Loop BB105_60 Depth 2
	cmp	x24, #2
	b.hs	.LBB105_62
// %bb.58:                              //   in Loop: Header=BB105_57 Depth=1
	mov	x2, xzr
.LBB105_59:                             //   in Loop: Header=BB105_57 Depth=1
	sub	x3, x24, x2
	lsl	x2, x2, #4
.LBB105_60:                             //   Parent Loop BB105_57 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x4, x16, x2
	add	x5, x18, x2
	subs	x3, x3, #1
	add	x2, x2, #16
	ldp	d0, d1, [x4]
	ldp	d2, d3, [x5]
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stp	d4, d5, [x4]
	stp	d0, d1, [x5]
	b.ne	.LBB105_60
.LBB105_61:                             //   in Loop: Header=BB105_57 Depth=1
	add	x1, x1, #1
	add	x8, x8, #1
	add	x16, x16, x17
	add	x18, x18, x0
	cmp	x1, x9
	b.ne	.LBB105_57
	b	.LBB105_124
.LBB105_62:                             //   in Loop: Header=BB105_57 Depth=1
	msub	x3, x24, x8, x10
	mov	x2, xzr
	madd	x4, x24, x8, x24
	add	x3, x27, x3, lsl #4
	add	x5, x3, #8
	add	x6, x27, x4, lsl #4
	add	x4, x5, x14
	add	x7, x6, #8
	cmp	x4, x5
	add	x4, x3, x14
	cset	w19, lo
	cmp	x4, x3
	add	x3, x7, x14
	cset	w4, lo
	cmp	x3, x7
	add	x3, x6, x14
	cset	w5, lo
	cmp	x3, x6
	orr	w6, w19, w13
	cset	w3, lo
	tbnz	w6, #0, .LBB105_59
// %bb.63:                              //   in Loop: Header=BB105_57 Depth=1
	orr	w4, w4, w13
	tbnz	w4, #0, .LBB105_59
// %bb.64:                              //   in Loop: Header=BB105_57 Depth=1
	orr	w4, w5, w13
	tbnz	w4, #0, .LBB105_59
// %bb.65:                              //   in Loop: Header=BB105_57 Depth=1
	orr	w3, w3, w13
	tbnz	w3, #0, .LBB105_59
// %bb.66:                              //   in Loop: Header=BB105_57 Depth=1
	mul	x3, x24, x8
	mov	x2, xzr
	add	x4, x24, x3
	add	x5, x11, x3
	sub	x6, x10, x3
	sub	x3, x27, x3, lsl #4
	add	x4, x27, x4, lsl #4
	add	x21, x27, x5, lsl #4
	add	x23, x27, x6, lsl #4
	add	x24, x3, x12
	sub	x6, x21, #8
	add	x19, x4, #8
	cmp	x4, x21
	sub	x25, x24, #8
	cset	w27, lo
	cmp	x19, x6
	cset	w28, lo
	cmp	x25, x4
	cset	w3, hi
	cmp	x23, x6
	add	x26, x23, #8
	cset	w5, lo
	cmp	x24, x4
	cset	w4, hi
	cmp	x26, x6
	cset	w7, lo
	cmp	x25, x19
	cset	w6, hi
	cmp	x23, x21
	cset	w20, lo
	cmp	x24, x19
	cset	w19, hi
	cmp	x26, x21
	cset	w22, lo
	cmp	x24, x23
	cset	w21, hi
	cmp	x25, x26
	and	w24, w27, w28
	cset	w23, hi
	tbnz	w24, #0, .LBB105_76
// %bb.67:                              //   in Loop: Header=BB105_57 Depth=1
	and	w3, w3, w5
	tbnz	w3, #0, .LBB105_76
// %bb.68:                              //   in Loop: Header=BB105_57 Depth=1
	and	w3, w4, w7
	ldur	x24, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w3, #0, .LBB105_75
// %bb.69:                              //   in Loop: Header=BB105_57 Depth=1
	and	w3, w6, w20
	tbnz	w3, #0, .LBB105_75
// %bb.70:                              //   in Loop: Header=BB105_57 Depth=1
	and	w3, w19, w22
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	tbnz	w3, #0, .LBB105_59
// %bb.71:                              //   in Loop: Header=BB105_57 Depth=1
	and	w3, w21, w23
	tbnz	w3, #0, .LBB105_59
// %bb.72:                              //   in Loop: Header=BB105_57 Depth=1
	mov	x2, x15
	mov	x3, x18
	mov	x4, x16
.LBB105_73:                             //   Parent Loop BB105_57 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v0.2d, v1.2d }, [x4]
	subs	x2, x2, #2
	ld2	{ v2.2d, v3.2d }, [x3]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v6.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v7.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x4], #32
	st2	{ v6.2d, v7.2d }, [x3], #32
	b.ne	.LBB105_73
// %bb.74:                              //   in Loop: Header=BB105_57 Depth=1
	mov	x2, x15
	cmp	x24, x15
	b.ne	.LBB105_59
	b	.LBB105_61
.LBB105_75:                             //   in Loop: Header=BB105_57 Depth=1
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	b	.LBB105_59
.LBB105_76:                             //   in Loop: Header=BB105_57 Depth=1
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	ldur	x24, [x29, #-16]                // 8-byte Folded Reload
	b	.LBB105_59
.LBB105_77:
	mov	w10, #1
	ldur	x26, [x29, #-32]                // 8-byte Folded Reload
	cmp	x20, #3
	b.hi	.LBB105_93
// %bb.78:
	mov	w9, wzr
	subs	x8, x22, #1
	b.ne	.LBB105_122
	b	.LBB105_55
.LBB105_79:
	cmp	x20, #3
	b.ls	.LBB105_124
// %bb.80:
	mov	w10, wzr
	b	.LBB105_93
.LBB105_81:
	sub	x12, x22, #1
	mov	x8, xzr
	mov	x9, xzr
	and	x10, x22, #0xfffffffffffffffc
	cmp	xzr, x12, lsr #60
	lsl	x12, x12, #4
	add	x11, x27, #32
	cset	w13, ne
	add	x14, x12, #16
	add	x15, x26, #32
	b	.LBB105_83
.LBB105_82:                             //   in Loop: Header=BB105_83 Depth=1
	add	x9, x9, #1
	add	x11, x11, x14
	add	x15, x15, x14
	add	x8, x8, x22
	cmp	x9, x28
	b.eq	.LBB105_53
.LBB105_83:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_90 Depth 2
                                        //     Child Loop BB105_86 Depth 2
	cmp	x22, #4
	b.hs	.LBB105_87
// %bb.84:                              //   in Loop: Header=BB105_83 Depth=1
	mov	x16, xzr
.LBB105_85:                             //   in Loop: Header=BB105_83 Depth=1
	add	x17, x16, x8
	sub	x16, x22, x16
	lsl	x18, x17, #4
	add	x17, x27, x18
	add	x18, x26, x18
.LBB105_86:                             //   Parent Loop BB105_83 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	q0, [x18], #16
	subs	x16, x16, #1
	str	q0, [x17], #16
	b.ne	.LBB105_86
	b	.LBB105_82
.LBB105_87:                             //   in Loop: Header=BB105_83 Depth=1
	mul	x17, x9, x22
	mov	x16, xzr
	add	x17, x27, x17, lsl #4
	add	x18, x17, x12
	add	x0, x17, #8
	cmp	x18, x17
	add	x18, x0, x12
	cset	w17, lo
	cmp	x18, x0
	orr	w1, w17, w13
	cset	w17, lo
	tbnz	w1, #0, .LBB105_85
// %bb.88:                              //   in Loop: Header=BB105_83 Depth=1
	orr	w17, w17, w13
	tbnz	w17, #0, .LBB105_85
// %bb.89:                              //   in Loop: Header=BB105_83 Depth=1
	mov	x16, x10
	mov	x17, x15
	mov	x18, x11
.LBB105_90:                             //   Parent Loop BB105_83 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x17, #-32]
	subs	x16, x16, #4
	ldp	q3, q2, [x17], #64
	stp	q1, q0, [x18, #-32]
	stp	q3, q2, [x18], #64
	b.ne	.LBB105_90
// %bb.91:                              //   in Loop: Header=BB105_83 Depth=1
	mov	x16, x10
	cmp	x10, x22
	b.eq	.LBB105_82
	b	.LBB105_85
.LBB105_92:
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	mov	w10, wzr
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldr	x15, [sp, #184]                 // 8-byte Folded Reload
.LBB105_93:
	sub	x9, x5, #1
	str	w10, [sp, #4]                   // 4-byte Folded Spill
	cmp	x5, #2
	mov	w10, #2
	lsl	x11, x0, #4
	csel	x10, x5, x10, hi
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	mul	x9, x0, x28
	add	x11, x11, #16
	str	x0, [sp, #8]                    // 8-byte Folded Spill
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	sub	x13, x24, #1
	mul	x9, x9, x22
	lsl	x6, x24, #4
	cmp	xzr, x13, lsr #60
	mul	x8, x24, x15
	mul	x14, x24, x0
	lsl	x12, x24, #1
	sub	x15, x23, #3
	add	x7, x27, x6
	stur	x9, [x29, #-120]                // 8-byte Folded Spill
	mul	x9, x24, x11
	add	x8, x26, x8, lsl #4
	lsl	x10, x14, #4
	add	x4, x27, x10
	lsl	x30, x24, #5
	mov	x19, xzr
	and	x1, x24, #0xfffffffffffffffe
	str	x9, [sp, #144]                  // 8-byte Folded Spill
	cset	w9, ne
	add	x11, x7, #8
	mov	w17, #1
	str	w9, [sp, #116]                  // 4-byte Folded Spill
	lsl	x9, x13, #4
	str	x9, [sp, #104]                  // 8-byte Folded Spill
	add	x9, x26, x6
	add	x21, x9, #8
	neg	x9, x6
	stur	x14, [x29, #-72]                // 8-byte Folded Spill
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x26, x24, lsl #5
	add	x9, x9, #8
	str	x15, [sp, #120]                 // 8-byte Folded Spill
	stp	x8, x9, [sp, #88]               // 16-byte Folded Spill
	add	x8, x26, x10
	add	x9, x12, x24
	add	x20, x8, #8
	sub	x8, x23, #4
	add	x18, x26, x9, lsl #4
	str	x9, [sp, #72]                   // 8-byte Folded Spill
	mul	x9, x24, x15
	mul	x10, x24, x8
	lsl	x8, x24, #2
	stp	x9, x18, [sp, #56]              // 16-byte Folded Spill
	add	x18, x26, x9, lsl #4
	stp	x8, x10, [sp, #40]              // 16-byte Folded Spill
	add	x8, x26, x24, lsl #6
	add	x9, x26, x10, lsl #4
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	neg	x8, x30
	stp	x9, x18, [sp, #16]              // 16-byte Folded Spill
	add	x9, x26, #8
	ldur	x3, [x29, #-40]                 // 8-byte Folded Reload
	stp	x9, x24, [x29, #-88]            // 16-byte Folded Spill
	stp	x21, x6, [sp, #128]             // 16-byte Folded Spill
	str	x20, [sp, #80]                  // 8-byte Folded Spill
	b	.LBB105_95
.LBB105_94:                             //   in Loop: Header=BB105_95 Depth=1
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x17, x17, #1
	ldur	x11, [x29, #-112]               // 8-byte Folded Reload
	add	x19, x19, #1
	add	x7, x7, x6
	add	x4, x4, x9
	ldur	x9, [x29, #-80]                 // 8-byte Folded Reload
	add	x11, x11, x6
	add	x9, x9, x24
	stur	x9, [x29, #-80]                 // 8-byte Folded Spill
	ldur	x9, [x29, #-72]                 // 8-byte Folded Reload
	sub	x9, x9, x24
	stur	x9, [x29, #-72]                 // 8-byte Folded Spill
	ldr	x9, [sp, #152]                  // 8-byte Folded Reload
	ldr	x21, [sp, #128]                 // 8-byte Folded Reload
	cmp	x17, x9
	b.eq	.LBB105_121
.LBB105_95:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_97 Depth 2
                                        //     Child Loop BB105_102 Depth 2
                                        //       Child Loop BB105_106 Depth 3
                                        //       Child Loop BB105_109 Depth 3
                                        //     Child Loop BB105_115 Depth 2
                                        //       Child Loop BB105_117 Depth 3
                                        //       Child Loop BB105_120 Depth 3
	mul	x13, x24, x19
	ldur	x9, [x29, #-120]                // 8-byte Folded Reload
	stur	x11, [x29, #-112]               // 8-byte Folded Spill
	sub	x25, x9, x13
	sub	x11, x27, x13, lsl #4
	cbz	x24, .LBB105_98
// %bb.96:                              //   in Loop: Header=BB105_95 Depth=1
	ldp	x28, x22, [sp, #88]             // 16-byte Folded Reload
	add	x15, x3, x17, lsl #4
	add	x18, x3, x17, lsl #5
	mov	x14, xzr
	lsl	x16, x17, #1
	add	x0, x15, #8
	add	x2, x18, #8
	mov	x3, x24
	ldur	x20, [x29, #-112]               // 8-byte Folded Reload
	ldr	x10, [sp, #80]                  // 8-byte Folded Reload
.LBB105_97:                             //   Parent Loop BB105_95 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x5, x26, x14
	add	x9, x21, x14
	ldr	d0, [x15]
	add	x6, x22, x14
	ldr	d3, [x18]
	subs	x3, x3, #1
	ldp	d2, d4, [x5]
	add	x5, x20, x14
	ldur	d1, [x9, #-8]
	fmadd	d0, d0, d1, d2
	ldp	d1, d2, [x6, #-8]
	fmadd	d0, d3, d1, d0
	ldr	d1, [x9]
	add	x9, x28, x14
	stur	d0, [x5, #-8]
	ldr	d0, [x15]
	fmadd	d0, d0, d1, d4
	ldr	d1, [x18]
	fmadd	d0, d1, d2, d0
	ldp	d3, d2, [x9]
	add	x9, x4, x14
	str	d0, [x5]
	add	x5, x10, x14
	ldr	d0, [x2]
	add	x14, x14, #16
	fneg	d1, d0
	fmul	d0, d0, d3
	ldp	d3, d4, [x5, #-8]
	fmul	d1, d2, d1
	ldr	d2, [x0]
	fmadd	d0, d2, d3, d0
	fmsub	d1, d2, d4, d1
	stp	d1, d0, [x9]
	b.ne	.LBB105_97
	b	.LBB105_99
.LBB105_98:                             //   in Loop: Header=BB105_95 Depth=1
	lsl	x16, x17, #1
.LBB105_99:                             //   in Loop: Header=BB105_95 Depth=1
	add	x9, x24, x13
	add	x15, x12, x13
	ldr	x13, [sp, #144]                 // 8-byte Folded Reload
	add	x5, x27, x25, lsl #4
	ldur	x10, [x29, #-120]               // 8-byte Folded Reload
	add	x14, x27, x15, lsl #4
	add	x6, x27, x9, lsl #4
	sub	x3, x14, #8
	add	x18, x11, x13
	madd	x13, x24, x19, x24
	msub	x11, x24, x19, x10
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	stur	x19, [x29, #-128]               // 8-byte Folded Spill
	sub	x19, x18, #8
	add	x14, x27, x13, lsl #4
	add	x2, x6, #8
	add	x11, x27, x11, lsl #4
	add	x0, x5, #8
	add	x21, x11, #8
	add	x20, x14, #8
	cmp	x9, #4
	stp	x18, x15, [x29, #-152]          // 16-byte Folded Spill
	stp	x2, x0, [x29, #-168]            // 16-byte Folded Spill
	stp	x5, x3, [x29, #-184]            // 16-byte Folded Spill
	stur	x6, [x29, #-192]                // 8-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	stp	x14, x21, [sp, #176]            // 16-byte Folded Spill
	str	x11, [sp, #168]                 // 8-byte Folded Spill
	b.lo	.LBB105_110
// %bb.100:                             //   in Loop: Header=BB105_95 Depth=1
	ldr	x13, [sp, #104]                 // 8-byte Folded Reload
	add	x15, x27, x15, lsl #4
	add	x9, x11, x13
	add	x10, x14, x13
	cmp	x9, x11
	add	x9, x21, x13
	cset	w11, lo
	cmp	x10, x14
	ldr	w14, [sp, #116]                 // 4-byte Folded Reload
	orr	w10, w11, w14
	cset	w11, lo
	cmp	x9, x21
	orr	w9, w11, w14
	add	x11, x20, x13
	cset	w13, lo
	cmp	x11, x20
	orr	w11, w13, w14
	cset	w13, lo
	cmp	x19, x6
	orr	w13, w13, w14
	cset	w14, hi
	cmp	x5, x3
	orr	w9, w10, w9
	cset	w10, lo
	cmp	x18, x2
	cset	w18, hi
	cmp	x0, x15
	orr	w9, w9, w11
	cset	w11, lo
	and	w10, w14, w10
	and	w11, w18, w11
	orr	w25, w9, w13
	orr	w9, w10, w11
	mov	w18, #3
	stur	w9, [x29, #-56]                 // 4-byte Folded Spill
	ldp	x28, x5, [sp, #48]              // 16-byte Folded Reload
	ldp	x15, x2, [sp, #32]              // 16-byte Folded Reload
	ldp	x14, x11, [sp, #64]             // 16-byte Folded Reload
	ldp	x19, x13, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp, #120]                 // 8-byte Folded Reload
	b	.LBB105_102
.LBB105_101:                            //   in Loop: Header=BB105_102 Depth=2
	ldp	x9, x24, [x29, #-24]            // 16-byte Folded Reload
	add	x18, x18, #2
	sub	x21, x21, #2
	add	x14, x14, x30
	add	x15, x15, x30
	add	x13, x13, x8
	add	x19, x19, x8
	add	x11, x11, x12
	add	x2, x2, x12
	sub	x5, x5, x12
	sub	x28, x28, x12
	cmp	x18, x9
	b.hs	.LBB105_111
.LBB105_102:                            //   Parent Loop BB105_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB105_106 Depth 3
                                        //       Child Loop BB105_109 Depth 3
	add	x9, x16, x17
	cmp	x9, x23
	csel	x16, x23, xzr, hi
	sub	x9, x9, x16
	add	x16, x9, x17
	cmp	x16, x23
	csel	x0, x23, xzr, hi
	sub	x16, x16, x0
	cbz	x24, .LBB105_101
// %bb.103:                             //   in Loop: Header=BB105_102 Depth=2
	ldur	x10, [x29, #-40]                // 8-byte Folded Reload
	add	x9, x10, x9, lsl #4
	add	x0, x10, x16, lsl #4
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	ldp	d3, d0, [x9]
	cmp	x10, #1
	ldur	w9, [x29, #-56]                 // 4-byte Folded Reload
	cset	w3, eq
	ldp	d1, d2, [x0]
	orr	w3, w3, w25
	orr	w9, w3, w9
	tbz	w9, #0, .LBB105_105
// %bb.104:                             //   in Loop: Header=BB105_102 Depth=2
	mov	x9, xzr
	b	.LBB105_108
.LBB105_105:                            //   in Loop: Header=BB105_102 Depth=2
	mov	x20, xzr
	mov	x22, x1
	dup	v4.2d, v3.d[0]
	dup	v5.2d, v0.d[0]
.LBB105_106:                            //   Parent Loop BB105_95 Depth=1
                                        //     Parent Loop BB105_102 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x15, x20
	add	x0, x19, x20
	subs	x22, x22, #2
	ld2	{ v6.2d, v7.2d }, [x9]
	add	x9, x14, x20
	ld2	{ v16.2d, v17.2d }, [x9]
	add	x9, x7, x20
	fmul	v18.2d, v6.2d, v1.d[0]
	fmul	v6.2d, v7.2d, v1.d[0]
	ld2	{ v19.2d, v20.2d }, [x9]
	fmla	v18.2d, v4.2d, v16.2d
	fmla	v6.2d, v4.2d, v17.2d
	ld2	{ v16.2d, v17.2d }, [x0]
	add	x0, x13, x20
	fadd	v21.2d, v19.2d, v18.2d
	fadd	v22.2d, v20.2d, v6.2d
	ld2	{ v6.2d, v7.2d }, [x0]
	add	x0, x4, x20
	add	x20, x20, #32
	fmul	v18.2d, v17.2d, v2.d[0]
	fmul	v16.2d, v16.2d, v2.d[0]
	st2	{ v21.2d, v22.2d }, [x9]
	ld2	{ v19.2d, v20.2d }, [x0]
	fmla	v18.2d, v5.2d, v7.2d
	fmla	v16.2d, v5.2d, v6.2d
	fsub	v6.2d, v19.2d, v18.2d
	fadd	v7.2d, v20.2d, v16.2d
	st2	{ v6.2d, v7.2d }, [x0]
	b.ne	.LBB105_106
// %bb.107:                             //   in Loop: Header=BB105_102 Depth=2
	mov	x9, x1
	cmp	x10, x1
	b.eq	.LBB105_101
.LBB105_108:                            //   in Loop: Header=BB105_102 Depth=2
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	add	x0, x9, x11
	add	x6, x9, x2
	add	x24, x9, x28
	mov	x20, xzr
	dup	v3.2d, v3.d[0]
	sub	x22, x10, x9
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x3, x10, x0, lsl #4
	add	x6, x10, x6, lsl #4
	ldur	x10, [x29, #-80]                // 8-byte Folded Reload
	add	x0, x10, x9
	ldur	x10, [x29, #-72]                // 8-byte Folded Reload
	add	x27, x10, x9
	add	x10, x9, x5
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	add	x26, x9, x0, lsl #4
	ldur	x0, [x29, #-88]                 // 8-byte Folded Reload
	add	x9, x9, x27, lsl #4
	add	x27, x0, x10, lsl #4
	add	x0, x0, x24, lsl #4
.LBB105_109:                            //   Parent Loop BB105_95 Depth=1
                                        //     Parent Loop BB105_102 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q4, [x6, x20]
	add	x10, x0, x20
	ldr	q5, [x3, x20]
	add	x24, x27, x20
	ldr	q6, [x26, x20]
	subs	x22, x22, #1
	ldp	d16, d7, [x10, #-8]
	fmul	v4.2d, v4.2d, v1.d[0]
	add	x10, x9, x20
	fmul	d16, d2, d16
	fmla	v4.2d, v3.2d, v5.2d
	fmul	d7, d2, d7
	fadd	v4.2d, v6.2d, v4.2d
	ldp	d6, d5, [x24, #-8]
	str	q4, [x26, x20]
	add	x20, x20, #16
	fmadd	d4, d6, d0, d16
	fmadd	d5, d5, d0, d7
	ldp	d6, d7, [x10]
	fsub	d5, d6, d5
	fadd	d4, d7, d4
	stp	d5, d4, [x10]
	b.ne	.LBB105_109
	b	.LBB105_101
.LBB105_110:                            //   in Loop: Header=BB105_95 Depth=1
	ldr	x21, [sp, #120]                 // 8-byte Folded Reload
	mov	w18, #3
.LBB105_111:                            //   in Loop: Header=BB105_95 Depth=1
	ldp	x3, x26, [x29, #-40]            // 16-byte Folded Reload
	ldp	x28, x22, [x29, #-104]          // 16-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	ldur	x19, [x29, #-128]               // 8-byte Folded Reload
	ldr	x6, [sp, #136]                  // 8-byte Folded Reload
	cmp	x18, x5
	b.hs	.LBB105_94
// %bb.112:                             //   in Loop: Header=BB105_95 Depth=1
	cbz	x24, .LBB105_94
// %bb.113:                             //   in Loop: Header=BB105_95 Depth=1
	ldp	x10, x11, [sp, #168]            // 16-byte Folded Reload
	mul	x2, x24, x21
	ldr	x13, [sp, #104]                 // 8-byte Folded Reload
	ldr	x15, [sp, #184]                 // 8-byte Folded Reload
	ldr	w14, [sp, #116]                 // 4-byte Folded Reload
	add	x9, x10, x13
	cmp	x9, x10
	add	x9, x11, x13
	cset	w10, lo
	cmp	x9, x11
	add	x9, x15, x13
	cset	w11, lo
	cmp	x9, x15
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	orr	w9, w11, w14
	orr	w10, w10, w14
	orr	w9, w10, w9
	add	x11, x15, x13
	cset	w13, lo
	cmp	x11, x15
	orr	w11, w13, w14
	cset	w13, lo
	orr	w9, w9, w11
	orr	w13, w13, w14
	ldr	x11, [sp, #200]                 // 8-byte Folded Reload
	ldp	x10, x14, [x29, #-192]          // 16-byte Folded Reload
	cmp	x11, x10
	ldp	x11, x15, [x29, #-176]          // 16-byte Folded Reload
	cset	w10, hi
	cmp	x14, x11
	ldp	x0, x14, [x29, #-160]           // 16-byte Folded Reload
	cset	w11, lo
	and	w11, w10, w11
	orr	w10, w9, w13
	cmp	x14, x15
	ldur	x15, [x29, #-144]               // 8-byte Folded Reload
	cset	w14, hi
	add	x15, x27, x15, lsl #4
	cmp	x0, x15
	mul	x15, x24, x18
	cset	w0, lo
	and	w14, w14, w0
	orr	w11, w11, w14
	add	x13, x26, x15, lsl #4
	add	x14, x26, x2, lsl #4
	b	.LBB105_115
.LBB105_114:                            //   in Loop: Header=BB105_115 Depth=2
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x18, x18, #1
	add	x13, x13, x6
	cmp	x18, x5
	add	x14, x14, x9
	b.eq	.LBB105_94
.LBB105_115:                            //   Parent Loop BB105_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB105_117 Depth 3
                                        //       Child Loop BB105_120 Depth 3
	cmp	x24, #2
	add	x9, x16, x17
	cset	w0, lo
	cmp	x9, x23
	csel	x16, x23, xzr, hi
	orr	w0, w0, w10
	sub	x16, x9, x16
	mov	x15, xzr
	orr	w0, w0, w11
	add	x9, x3, x16, lsl #4
	ldp	d1, d0, [x9]
	tbnz	w0, #0, .LBB105_119
// %bb.116:                             //   in Loop: Header=BB105_115 Depth=2
	mov	x15, xzr
	mov	x0, x1
	dup	v2.2d, v1.d[0]
	dup	v3.2d, v0.d[0]
.LBB105_117:                            //   Parent Loop BB105_95 Depth=1
                                        //     Parent Loop BB105_115 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x13, x15
	add	x2, x14, x15
	subs	x0, x0, #2
	ld2	{ v4.2d, v5.2d }, [x9]
	add	x9, x7, x15
	ld2	{ v6.2d, v7.2d }, [x9]
	fmla	v6.2d, v2.2d, v4.2d
	fmla	v7.2d, v2.2d, v5.2d
	ld2	{ v4.2d, v5.2d }, [x2]
	add	x2, x4, x15
	add	x15, x15, #32
	st2	{ v6.2d, v7.2d }, [x9]
	ld2	{ v6.2d, v7.2d }, [x2]
	fmls	v6.2d, v3.2d, v5.2d
	fmla	v7.2d, v3.2d, v4.2d
	st2	{ v6.2d, v7.2d }, [x2]
	b.ne	.LBB105_117
// %bb.118:                             //   in Loop: Header=BB105_115 Depth=2
	mov	x15, x1
	cmp	x24, x1
	b.eq	.LBB105_114
.LBB105_119:                            //   in Loop: Header=BB105_115 Depth=2
	sub	x9, x24, x15
	lsl	x15, x15, #4
	dup	v1.2d, v1.d[0]
.LBB105_120:                            //   Parent Loop BB105_95 Depth=1
                                        //     Parent Loop BB105_115 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q2, [x13, x15]
	add	x0, x14, x15
	ldr	q3, [x7, x15]
	add	x2, x4, x15
	subs	x9, x9, #1
	fmla	v3.2d, v1.2d, v2.2d
	ldp	d4, d2, [x0]
	str	q3, [x7, x15]
	add	x15, x15, #16
	ldp	d3, d5, [x2]
	fmsub	d2, d2, d0, d3
	fmadd	d3, d4, d0, d5
	str	d2, [x2]
	str	d3, [x2, #8]
	b.ne	.LBB105_120
	b	.LBB105_114
.LBB105_121:
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	mov	w9, #1
	ldr	w10, [sp, #4]                   // 4-byte Folded Reload
	subs	x8, x22, #1
	b.eq	.LBB105_55
.LBB105_122:
	cbz	w9, .LBB105_124
// %bb.123:
	tbz	w10, #0, .LBB105_127
.LBB105_124:
	ldur	x8, [x29, #-40]                 // 8-byte Folded Reload
	cbz	x8, .LBB105_126
// %bb.125:
	ldp	x20, x19, [sp, #480]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #464]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #448]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #432]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #416]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #400]            // 16-byte Folded Reload
	ldur	x0, [x8, #-8]
	add	sp, sp, #496
	b	free
.LBB105_126:
	ldp	x20, x19, [sp, #480]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #464]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #448]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #432]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #416]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #400]            // 16-byte Folded Reload
	add	sp, sp, #496
	ret
.LBB105_127:
	cmp	x5, #2
	mov	w11, #2
	mul	x10, x0, x28
	csel	x11, x5, x11, hi
	lsl	x13, x28, #4
	sub	x12, x22, #2
	add	x13, x13, #16
	lsl	x16, x12, #4
	stur	x11, [x29, #-176]               // 8-byte Folded Spill
	mul	x11, x10, x22
	lsl	x10, x10, #4
	mul	x13, x13, x22
	add	x10, x10, #16
	cmp	xzr, x12, lsr #60
	orr	x12, x8, #0x1
	add	x14, x11, #1
	mul	x10, x10, x22
	add	x3, x27, x11, lsl #4
	lsl	x2, x22, #4
	add	x18, x24, #1
	stur	x12, [x29, #-112]               // 8-byte Folded Spill
	add	x12, x27, x24, lsl #4
	add	x4, x12, #8
	lsl	x12, x24, #4
	stp	x10, x13, [x29, #-80]           // 16-byte Folded Spill
	and	x10, x8, #0xfffffffffffffffe
	neg	x11, x12
	mov	x9, xzr
	cset	w15, ne
	add	x23, x27, x18, lsl #4
	stur	x10, [x29, #-88]                // 8-byte Folded Spill
	sub	x10, x0, #1
	stp	x11, x12, [x29, #-192]          // 16-byte Folded Spill
	ldur	x11, [x29, #-136]               // 8-byte Folded Reload
	mul	x10, x10, x8
	add	x13, x27, x14, lsl #4
	add	x26, x3, #8
	str	x18, [sp, #176]                 // 8-byte Folded Spill
	add	x17, x11, x10, lsl #4
	mov	w10, #16
	sub	x10, x10, x2
	str	x10, [sp, #200]                 // 8-byte Folded Spill
	sub	x10, x2, #16
	stp	x14, x10, [sp, #184]            // 16-byte Folded Spill
	mov	w14, #1
	b	.LBB105_129
.LBB105_128:                            //   in Loop: Header=BB105_129 Depth=1
	ldp	x11, x10, [x29, #-192]          // 16-byte Folded Reload
	ldp	x23, x9, [x29, #-128]           // 16-byte Folded Reload
	ldr	x12, [sp, #200]                 // 8-byte Folded Reload
	add	x3, x3, x11
	ldp	x14, x26, [x29, #-160]          // 16-byte Folded Reload
	add	x4, x4, x10
	add	x23, x23, x10
	add	x17, x17, x12
	ldr	x12, [sp, #192]                 // 8-byte Folded Reload
	ldur	x13, [x29, #-144]               // 8-byte Folded Reload
	add	x9, x9, #1
	ldp	x10, x0, [x29, #-176]           // 16-byte Folded Reload
	add	x14, x14, #1
	add	x20, x20, x12
	add	x13, x13, x11
	add	x26, x26, x11
	ldur	x24, [x29, #-16]                // 8-byte Folded Reload
	cmp	x14, x10
	stur	x20, [x29, #-136]               // 8-byte Folded Spill
	b.eq	.LBB105_124
.LBB105_129:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_153 Depth 2
                                        //     Child Loop BB105_131 Depth 2
                                        //       Child Loop BB105_147 Depth 3
                                        //       Child Loop BB105_134 Depth 3
	sub	x10, x0, #1
	cmp	x22, #1
	stp	x23, x9, [x29, #-128]           // 16-byte Folded Spill
	stp	x26, x13, [x29, #-152]          // 16-byte Folded Spill
	stp	x10, x14, [x29, #-168]          // 16-byte Folded Spill
	b.ls	.LBB105_152
// %bb.130:                             //   in Loop: Header=BB105_129 Depth=1
	ldr	x11, [sp, #184]                 // 8-byte Folded Reload
	mul	x10, x24, x9
	mul	x18, x14, x28
	mov	x21, xzr
	mul	x30, x0, x28
	mov	x0, x4
	msub	x12, x24, x9, x11
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
	stur	x12, [x29, #-24]                // 8-byte Folded Spill
	ldr	x12, [sp, #176]                 // 8-byte Folded Reload
	madd	x9, x24, x9, x12
	mov	x24, x13
	stur	x9, [x29, #-32]                 // 8-byte Folded Spill
	add	x9, x12, x10
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	sub	x9, x11, x10
	stur	x9, [x29, #-56]                 // 8-byte Folded Spill
.LBB105_131:                            //   Parent Loop BB105_129 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB105_147 Depth 3
                                        //       Child Loop BB105_134 Depth 3
	add	x13, x21, x18
	add	x14, x21, x30
	cmp	x8, #2
	mul	x13, x13, x22
	mul	x14, x14, x22
	add	x13, x27, x13, lsl #4
	add	x14, x27, x14, lsl #4
	ldp	d0, d1, [x13]
	ldp	d2, d3, [x14]
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	str	d4, [x13]
	str	d5, [x13, #8]
	str	d0, [x14]
	str	d1, [x14, #8]
	b.hs	.LBB105_136
.LBB105_132:                            //   in Loop: Header=BB105_131 Depth=2
	mov	w19, #1
.LBB105_133:                            //   in Loop: Header=BB105_131 Depth=2
	sub	x5, x22, x19
	lsl	x19, x19, #4
.LBB105_134:                            //   Parent Loop BB105_129 Depth=1
                                        //     Parent Loop BB105_131 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x0, x19
	add	x11, x26, x19
	add	x12, x20, x19
	add	x13, x17, x19
	subs	x5, x5, #1
	add	x19, x19, #16
	ldp	d0, d2, [x9, #-8]
	ldp	d1, d3, [x11, #-8]
	ldp	d17, d5, [x12, #-16]
	fadd	d4, d0, d1
	fsub	d0, d0, d1
	fadd	d1, d2, d3
	fsub	d2, d2, d3
	ldp	d18, d3, [x13, #-16]
	fneg	d6, d4
	fneg	d7, d0
	fmul	d16, d1, d5
	fmul	d5, d5, d6
	fmul	d6, d2, d3
	fmul	d3, d3, d7
	fmadd	d4, d4, d17, d16
	fmadd	d1, d1, d17, d5
	fmadd	d0, d0, d18, d6
	fmadd	d2, d2, d18, d3
	stur	d4, [x9, #-8]
	str	d1, [x9]
	stur	d0, [x11, #-8]
	str	d2, [x11]
	b.ne	.LBB105_134
.LBB105_135:                            //   in Loop: Header=BB105_131 Depth=2
	add	x21, x21, #1
	add	x23, x23, x2
	add	x24, x24, x2
	add	x0, x0, x2
	add	x26, x26, x2
	cmp	x21, x28
	b.ne	.LBB105_131
	b	.LBB105_128
.LBB105_136:                            //   in Loop: Header=BB105_131 Depth=2
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	mul	x5, x21, x22
	add	x13, x9, x5
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #4
	add	x14, x9, x5
	add	x1, x13, #8
	add	x6, x27, x14, lsl #4
	add	x14, x1, x16
	add	x7, x6, #8
	cmp	x14, x1
	add	x14, x13, x16
	cset	w1, lo
	cmp	x14, x13
	add	x13, x7, x16
	cset	w14, lo
	cmp	x13, x7
	add	x13, x6, x16
	orr	w19, w1, w15
	cset	w1, lo
	cmp	x13, x6
	cset	w13, lo
	tbnz	w19, #0, .LBB105_132
// %bb.137:                             //   in Loop: Header=BB105_131 Depth=2
	orr	w14, w14, w15
	tbnz	w14, #0, .LBB105_132
// %bb.138:                             //   in Loop: Header=BB105_131 Depth=2
	orr	w14, w1, w15
	tbnz	w14, #0, .LBB105_132
// %bb.139:                             //   in Loop: Header=BB105_131 Depth=2
	orr	w13, w13, w15
	mov	w19, #1
	tbnz	w13, #0, .LBB105_133
// %bb.140:                             //   in Loop: Header=BB105_131 Depth=2
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x14, x10, x5
	add	x14, x27, x14, lsl #4
	add	x13, x9, x5
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #4
	add	x1, x9, x5
	ldur	x9, [x29, #-72]                 // 8-byte Folded Reload
	sub	x5, x5, x10
	add	x6, x13, #8
	add	x1, x27, x1, lsl #4
	add	x14, x14, x9
	ldur	x9, [x29, #-80]                 // 8-byte Folded Reload
	add	x5, x27, x5, lsl #4
	sub	x7, x14, #8
	cmp	x14, x13
	add	x11, x1, #8
	add	x9, x5, x9
	cset	w5, hi
	sub	x27, x9, #8
	cmp	x7, x6
	cset	w19, hi
	cmp	x27, x13
	and	w12, w5, w19
	cset	w5, hi
	cmp	x7, x1
	cset	w20, hi
	cmp	x9, x13
	cset	w19, hi
	cmp	x7, x11
	cset	w28, hi
	cmp	x27, x6
	cset	w22, hi
	cmp	x14, x1
	cset	w7, hi
	cmp	x9, x6
	cset	w6, hi
	cmp	x14, x11
	cset	w13, hi
	cmp	x9, x1
	cset	w14, hi
	cmp	x27, x11
	cset	w1, hi
	tbnz	w12, #0, .LBB105_150
// %bb.141:                             //   in Loop: Header=BB105_131 Depth=2
	and	w9, w5, w20
	tbnz	w9, #0, .LBB105_150
// %bb.142:                             //   in Loop: Header=BB105_131 Depth=2
	and	w9, w19, w28
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
	tbnz	w9, #0, .LBB105_151
// %bb.143:                             //   in Loop: Header=BB105_131 Depth=2
	and	w9, w22, w7
	ldur	x28, [x29, #-104]               // 8-byte Folded Reload
	tbnz	w9, #0, .LBB105_149
// %bb.144:                             //   in Loop: Header=BB105_131 Depth=2
	and	w9, w6, w13
	ldur	x22, [x29, #-96]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB105_132
// %bb.145:                             //   in Loop: Header=BB105_131 Depth=2
	and	w9, w14, w1
	mov	w19, #1
	tbnz	w9, #0, .LBB105_133
// %bb.146:                             //   in Loop: Header=BB105_131 Depth=2
	ldur	x19, [x29, #-88]                // 8-byte Folded Reload
	mov	x22, x20
	mov	x20, x24
	mov	x28, x23
	mov	x5, x17
.LBB105_147:                            //   Parent Loop BB105_129 Depth=1
                                        //     Parent Loop BB105_131 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.2d, v1.2d }, [x28]
	subs	x19, x19, #2
	ld2	{ v2.2d, v3.2d }, [x20]
	ld2	{ v6.2d, v7.2d }, [x22], #32
	fadd	v4.2d, v1.2d, v3.2d
	fadd	v5.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fmul	v16.2d, v4.2d, v7.2d
	fneg	v18.2d, v5.2d
	fmla	v16.2d, v6.2d, v5.2d
	fmul	v17.2d, v7.2d, v18.2d
	fmla	v17.2d, v6.2d, v4.2d
	fsub	v4.2d, v1.2d, v3.2d
	fneg	v3.2d, v0.2d
	st2	{ v16.2d, v17.2d }, [x28], #32
	ld2	{ v1.2d, v2.2d }, [x5], #32
	fmul	v5.2d, v4.2d, v2.2d
	fmla	v5.2d, v1.2d, v0.2d
	fmul	v6.2d, v2.2d, v3.2d
	fmla	v6.2d, v1.2d, v4.2d
	st2	{ v5.2d, v6.2d }, [x20], #32
	b.ne	.LBB105_147
// %bb.148:                             //   in Loop: Header=BB105_131 Depth=2
	ldp	x22, x9, [x29, #-96]            // 16-byte Folded Reload
	ldp	x19, x28, [x29, #-112]          // 16-byte Folded Reload
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
	cmp	x8, x9
	b.ne	.LBB105_133
	b	.LBB105_135
.LBB105_149:                            //   in Loop: Header=BB105_131 Depth=2
	ldur	x22, [x29, #-96]                // 8-byte Folded Reload
	b	.LBB105_132
.LBB105_150:                            //   in Loop: Header=BB105_131 Depth=2
	ldp	x28, x22, [x29, #-104]          // 16-byte Folded Reload
	mov	w19, #1
	ldur	x27, [x29, #-64]                // 8-byte Folded Reload
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
	b	.LBB105_133
.LBB105_151:                            //   in Loop: Header=BB105_131 Depth=2
	ldp	x28, x22, [x29, #-104]          // 16-byte Folded Reload
	b	.LBB105_132
.LBB105_152:                            //   in Loop: Header=BB105_129 Depth=1
	mov	x10, xzr
	mov	x11, x28
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
.LBB105_153:                            //   Parent Loop BB105_129 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x12, x4, x10
	add	x13, x3, x10
	subs	x11, x11, #1
	add	x10, x10, x2
	ldp	d0, d1, [x12, #-8]
	ldp	d2, d3, [x13]
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stur	d4, [x12, #-8]
	str	d5, [x12]
	str	d0, [x13]
	str	d1, [x13, #8]
	b.ne	.LBB105_153
	b	.LBB105_128
.LBB105_154:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end105:
	.size	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_, .Lfunc_end105-_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x22, x21, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	subs	x8, x1, #1
	b.ne	.LBB106_4
// %bb.1:
	cbz	x2, .LBB106_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #8
	lsl	x9, x2, #4
	lsl	x10, x10, #4
	lsl	x11, x2, #5
	add	x12, x3, #32
.LBB106_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d0, d1, [x12, #-32]
	add	x13, x8, x11
	add	x14, x8, x9
	ldp	d2, d3, [x12]
	subs	x2, x2, #1
	ldp	d4, d5, [x12, #-16]
	ldp	d6, d7, [x12, #16]
	fadd	d16, d0, d2
	fadd	d18, d1, d3
	fsub	d0, d0, d2
	fsub	d1, d1, d3
	add	x12, x12, #64
	fadd	d17, d4, d6
	fsub	d3, d4, d6
	fadd	d19, d5, d7
	fsub	d2, d5, d7
	fsub	d4, d16, d17
	fadd	d6, d16, d17
	fsub	d5, d18, d19
	fsub	d7, d0, d2
	fadd	d0, d0, d2
	stp	d4, d5, [x13, #-8]
	fadd	d5, d18, d19
	fadd	d4, d1, d3
	fsub	d1, d1, d3
	add	x13, x8, x10
	stp	d6, d5, [x8, #-8]
	add	x8, x8, #16
	stp	d7, d4, [x14, #-8]
	stp	d0, d1, [x13, #-8]
	b.ne	.LBB106_3
	b	.LBB106_10
.LBB106_4:
	cbz	x2, .LBB106_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #48
	lsl	x10, x2, #1
	mov	x9, xzr
	add	x11, x3, #16
	lsl	x12, x1, #6
	madd	x14, x0, x14, x4
	add	x13, x10, x2
	lsl	x15, x1, #4
	add	x16, x5, x8, lsl #5
	add	x17, x4, x0, lsl #5
	add	x18, x5, x8, lsl #4
	add	x0, x4, x0, lsl #4
	mov	x6, x4
	b	.LBB106_7
.LBB106_6:                              //   in Loop: Header=BB106_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x12
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB106_10
.LBB106_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB106_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #4
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #4
	ldp	d0, d1, [x7]
	add	x20, x3, x20, lsl #4
	add	x7, x3, x21, lsl #4
	ldp	d2, d3, [x19]
	mul	x19, x9, x1
	add	x21, x9, x13
	ldp	d4, d5, [x20]
	add	x20, x9, x2
	ldp	d6, d7, [x7]
	fadd	d16, d0, d2
	fadd	d17, d1, d3
	fsub	d0, d0, d2
	add	x7, x9, x10
	fsub	d1, d1, d3
	add	x19, x4, x19, lsl #4
	fadd	d2, d4, d6
	fsub	d3, d4, d6
	fadd	d18, d5, d7
	fsub	d4, d5, d7
	mul	x7, x7, x1
	mul	x20, x20, x1
	fadd	d5, d16, d2
	fsub	d2, d16, d2
	fadd	d6, d17, d18
	fsub	d7, d17, d18
	add	x7, x4, x7, lsl #4
	add	x20, x4, x20, lsl #4
	stp	d5, d6, [x19]
	mul	x19, x21, x1
	fsub	d5, d0, d4
	fadd	d6, d1, d3
	fadd	d0, d0, d4
	fsub	d1, d1, d3
	stp	d2, d7, [x7]
	add	x7, x4, x19, lsl #4
	stp	d5, d6, [x20]
	stp	d0, d1, [x7]
	b.lo	.LBB106_6
// %bb.8:                               //   in Loop: Header=BB106_7 Depth=1
	mov	x7, xzr
	mov	x19, x8
.LBB106_9:                              //   Parent Loop BB106_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x11, x7
	subs	x19, x19, #1
	add	x21, x20, x15
	add	x22, x21, x15
	ldp	d0, d1, [x20]
	add	x20, x22, x15
	ldp	d2, d3, [x22]
	ldp	d4, d7, [x20]
	add	x20, x5, x7
	ldp	d5, d6, [x21]
	fsub	d16, d1, d3
	fadd	d18, d0, d2
	fsub	d0, d0, d2
	fadd	d1, d1, d3
	add	x21, x18, x7
	fsub	d17, d5, d4
	fadd	d3, d5, d4
	fadd	d4, d6, d7
	fsub	d5, d6, d7
	ldp	d6, d7, [x20]
	add	x20, x16, x7
	fadd	d2, d16, d17
	fsub	d16, d16, d17
	fsub	d21, d1, d4
	fadd	d1, d1, d4
	fsub	d4, d0, d5
	fadd	d20, d18, d3
	fsub	d3, d18, d3
	fadd	d0, d0, d5
	fneg	d19, d2
	fmul	d2, d2, d6
	fneg	d18, d21
	fmul	d17, d7, d19
	fmadd	d2, d4, d7, d2
	ldp	d19, d22, [x21]
	fneg	d7, d16
	add	x21, x6, x7
	fmadd	d4, d4, d6, d17
	ldp	d6, d17, [x20]
	fmul	d18, d22, d18
	fmul	d5, d21, d19
	add	x20, x0, x7
	str	d1, [x21, #24]
	str	d20, [x21, #16]
	add	x21, x17, x7
	fmul	d16, d16, d6
	fmul	d7, d17, d7
	fmadd	d1, d3, d19, d18
	fmadd	d3, d3, d22, d5
	str	d2, [x20, #24]
	str	d4, [x20, #16]
	add	x20, x14, x7
	fmadd	d5, d0, d17, d16
	add	x7, x7, #16
	fmadd	d0, d0, d6, d7
	str	d1, [x21, #16]
	str	d3, [x21, #24]
	str	d5, [x20, #24]
	str	d0, [x20, #16]
	b.ne	.LBB106_9
	b	.LBB106_6
.LBB106_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x22, x21, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end106:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end106-_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI107_0:
	.xword	0x3fe6a09e667f3bcd              // double 0.70710678118654757
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #96]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #112]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #128]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 192
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	stp	x4, x3, [sp, #80]               // 16-byte Folded Spill
	b.ne	.LBB107_4
// %bb.1:
	cbz	x2, .LBB107_10
// %bb.2:
	ldp	x8, x16, [sp, #80]              // 16-byte Folded Reload
	mov	w11, #112
	adrp	x17, .LCPI107_0
	add	x13, x2, x2, lsl #1
	add	x12, x2, x2, lsl #2
	mul	x10, x2, x11
	lsl	x9, x13, #4
	add	x8, x8, #8
	lsl	x11, x12, #4
	lsl	x12, x2, #4
	lsl	x13, x13, #5
	lsl	x14, x2, #5
	lsl	x15, x2, #6
	add	x16, x16, #64
	ldr	d0, [x17, :lo12:.LCPI107_0]
.LBB107_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d1, d2, [x16, #-48]
	add	x17, x8, x15
	add	x18, x8, x13
	ldp	d3, d4, [x16, #16]
	subs	x2, x2, #1
	ldp	d5, d7, [x16, #-16]
	fadd	d6, d1, d3
	fsub	d1, d1, d3
	ldp	d17, d3, [x16, #48]
	fadd	d16, d2, d4
	fsub	d2, d2, d4
	ldp	d4, d19, [x16, #-64]
	fadd	d18, d5, d17
	fsub	d5, d5, d17
	fadd	d20, d7, d3
	fsub	d3, d7, d3
	ldp	d21, d7, [x16]
	ldp	d17, d23, [x16, #-32]
	fadd	d26, d1, d3
	fsub	d1, d1, d3
	ldp	d25, d27, [x16, #32]
	fadd	d28, d4, d21
	fadd	d3, d2, d5
	fadd	d30, d19, d7
	fadd	d22, d6, d18
	fadd	d24, d16, d20
	fsub	d16, d16, d20
	fadd	d29, d17, d25
	fsub	d2, d2, d5
	fadd	d31, d23, d27
	fneg	d5, d26
	fsub	d6, d6, d18
	fsub	d18, d1, d3
	fadd	d1, d3, d1
	fsub	d4, d4, d21
	fadd	d20, d28, d29
	fsub	d7, d19, d7
	fadd	d3, d30, d31
	fsub	d21, d28, d29
	fsub	d5, d5, d2
	fsub	d2, d26, d2
	fsub	d17, d17, d25
	fsub	d28, d30, d31
	fsub	d19, d20, d22
	fsub	d23, d23, d27
	fsub	d26, d3, d24
	fmul	d1, d1, d0
	fmul	d18, d18, d0
	fmul	d5, d5, d0
	fadd	d25, d6, d28
	fsub	d6, d28, d6
	stur	d19, [x17, #-8]
	fsub	d19, d21, d16
	str	d26, [x17]
	add	x17, x8, x14
	fadd	d16, d16, d21
	fsub	d21, d4, d23
	fmul	d2, d2, d0
	fadd	d4, d4, d23
	stur	d19, [x17, #-8]
	fadd	d19, d7, d17
	fsub	d7, d7, d17
	str	d25, [x17]
	stur	d16, [x18, #-8]
	add	x17, x8, x12
	str	d6, [x18]
	fadd	d6, d18, d21
	fadd	d16, d1, d19
	fsub	d1, d19, d1
	add	x18, x8, x11
	fadd	d17, d2, d7
	fsub	d18, d21, d18
	fsub	d2, d7, d2
	stur	d6, [x17, #-8]
	fadd	d6, d22, d20
	str	d16, [x17]
	fadd	d16, d5, d4
	add	x17, x8, x9
	str	d1, [x18]
	fadd	d1, d24, d3
	fsub	d3, d4, d5
	add	x16, x16, #128
	stur	d18, [x18, #-8]
	stur	d16, [x17, #-8]
	str	d17, [x17]
	add	x17, x8, x10
	stur	d6, [x8, #-8]
	str	d1, [x8], #16
	stur	d3, [x17, #-8]
	str	d2, [x17]
	b.ne	.LBB107_3
	b	.LBB107_10
.LBB107_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	cbz	x2, .LBB107_10
// %bb.5:
	lsl	x8, x2, #2
	lsl	x10, x2, #1
	ldr	x16, [sp]                       // 8-byte Folded Reload
	lsl	x13, x1, #7
	mul	x11, x2, x1
	mov	w12, #112
	stp	x10, x8, [sp, #56]              // 16-byte Folded Spill
	add	x10, x10, x2
	add	x8, x8, x2
	lsl	x18, x10, #1
	mov	w14, #48
	mov	x9, xzr
	str	x2, [sp, #72]                   // 8-byte Folded Spill
	stp	x8, x10, [sp, #40]              // 16-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	ldp	x4, x10, [sp, #80]              // 16-byte Folded Reload
	stp	x8, x18, [sp, #24]              // 16-byte Folded Spill
	lsl	x8, x1, #4
	madd	x17, x11, x12, x4
	add	x25, x4, x11, lsl #4
	stp	x13, x8, [sp, #8]               // 16-byte Folded Spill
	add	x8, x8, x10
	add	x18, x8, #24
	add	x8, x16, x16, lsl #2
	lsl	x8, x8, #4
	madd	x7, x11, x14, x4
	add	x13, x8, x10
	madd	x12, x1, x12, x10
	add	x6, x13, #104
	add	x13, x16, x16, lsl #1
	lsl	x15, x13, #4
	add	x20, x12, #24
	add	x14, x15, x10
	lsl	x12, x16, #6
	add	x19, x14, #72
	mov	w14, #80
	lsl	x13, x13, #5
	add	x29, x5, x12
	madd	x21, x11, x14, x4
	add	x14, x12, x10
	add	x22, x14, #64
	lsl	x14, x16, #5
	add	x3, x14, x10
	adrp	x12, .LCPI107_0
	add	x23, x3, #32
	add	x3, x13, x10
	add	x24, x3, #96
	mov	w3, #96
	add	x26, x5, x13
	add	x27, x5, x14
	madd	x28, x11, x3, x4
	add	x30, x4, x11, lsl #5
	add	x8, x5, x8
	add	x13, x5, x16, lsl #4
	add	x14, x4, x11, lsl #6
	add	x15, x5, x15
	ldr	d0, [x12, :lo12:.LCPI107_0]
	mov	x3, x10
	b	.LBB107_7
.LBB107_6:                              //   in Loop: Header=BB107_7 Depth=1
	ldp	x11, x10, [sp, #8]              // 16-byte Folded Reload
	add	x9, x9, #1
	ldr	x2, [sp, #72]                   // 8-byte Folded Reload
	add	x18, x18, x11
	add	x6, x6, x11
	add	x17, x17, x10
	add	x7, x7, x10
	add	x19, x19, x11
	add	x20, x20, x11
	add	x21, x21, x10
	add	x3, x3, x11
	add	x22, x22, x11
	add	x23, x23, x11
	add	x24, x24, x11
	add	x4, x4, x10
	add	x25, x25, x10
	add	x28, x28, x10
	add	x30, x30, x10
	add	x14, x14, x10
	cmp	x9, x2
	b.eq	.LBB107_10
.LBB107_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB107_9 Depth 2
	mov	w11, #1
	mov	w12, #5
	bfi	x11, x9, #3, #61
	mov	w10, #3
	mov	w16, #7
	ldr	x0, [sp, #88]                   // 8-byte Folded Reload
	mul	x11, x11, x1
	bfi	x12, x9, #3, #61
	bfi	x10, x9, #3, #61
	bfi	x16, x9, #3, #61
	mul	x12, x12, x1
	cmp	x1, #2
	add	x11, x0, x11, lsl #4
	mul	x10, x10, x1
	mul	x16, x16, x1
	add	x12, x0, x12, lsl #4
	ldp	d1, d2, [x11]
	add	x10, x0, x10, lsl #4
	add	x11, x0, x16, lsl #4
	ldp	d3, d4, [x12]
	mov	w12, #2
	mov	w16, #6
	ldp	d5, d6, [x10]
	lsl	x10, x9, #3
	bfi	x12, x9, #3, #61
	ldp	d7, d16, [x11]
	mov	w11, #4
	mul	x10, x10, x1
	bfi	x11, x9, #3, #61
	bfi	x16, x9, #3, #61
	fadd	d17, d1, d3
	fadd	d18, d2, d4
	mul	x11, x11, x1
	fsub	d1, d1, d3
	fsub	d3, d6, d16
	fsub	d2, d2, d4
	fsub	d4, d5, d7
	add	x10, x0, x10, lsl #4
	mul	x12, x12, x1
	add	x11, x0, x11, lsl #4
	mul	x16, x16, x1
	fadd	d19, d5, d7
	fadd	d20, d6, d16
	fsub	d7, d1, d3
	fadd	d16, d2, d4
	fadd	d1, d1, d3
	ldp	d3, d21, [x10]
	add	x10, x0, x12, lsl #4
	fsub	d2, d2, d4
	ldp	d4, d22, [x11]
	add	x11, x0, x16, lsl #4
	fadd	d5, d17, d19
	fadd	d6, d18, d20
	fsub	d17, d17, d19
	ldp	d24, d19, [x10]
	fsub	d18, d18, d20
	fneg	d23, d1
	ldp	d20, d26, [x11]
	fsub	d25, d7, d16
	fadd	d7, d16, d7
	fadd	d27, d21, d22
	mul	x11, x9, x1
	fsub	d16, d23, d2
	fadd	d23, d3, d4
	fadd	d28, d24, d20
	fsub	d3, d3, d4
	fadd	d29, d19, d26
	fsub	d4, d21, d22
	ldp	x12, x10, [sp, #56]             // 16-byte Folded Reload
	fsub	d1, d1, d2
	fmul	d2, d25, d0
	fadd	d21, d23, d28
	ldr	x0, [sp, #80]                   // 8-byte Folded Reload
	fadd	d22, d27, d29
	fsub	d20, d24, d20
	add	x12, x9, x12
	fsub	d19, d19, d26
	add	x10, x9, x10
	add	x11, x0, x11, lsl #4
	fadd	d24, d5, d21
	fsub	d5, d21, d5
	fadd	d25, d6, d22
	mul	x10, x10, x1
	fsub	d6, d22, d6
	fsub	d21, d23, d28
	fsub	d22, d27, d29
	mul	x12, x12, x1
	add	x10, x0, x10, lsl #4
	fmul	d7, d7, d0
	stp	d24, d25, [x11]
	ldp	x16, x11, [sp, #24]             // 16-byte Folded Reload
	fmul	d16, d16, d0
	stp	d5, d6, [x10]
	fsub	d5, d21, d18
	add	x11, x9, x11
	fadd	d6, d17, d22
	fadd	d18, d18, d21
	fsub	d17, d22, d17
	mul	x10, x11, x1
	add	x11, x0, x12, lsl #4
	add	x12, x9, x2
	fsub	d21, d3, d19
	fadd	d22, d4, d20
	fmul	d1, d1, d0
	stp	d5, d6, [x11]
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	add	x10, x0, x10, lsl #4
	mul	x12, x12, x1
	fadd	d5, d2, d21
	fsub	d2, d21, d2
	add	x11, x9, x11
	fadd	d6, d7, d22
	stp	d18, d17, [x10]
	fsub	d7, d22, d7
	mul	x10, x11, x1
	add	x11, x0, x12, lsl #4
	ldr	x12, [sp, #48]                  // 8-byte Folded Reload
	fadd	d3, d3, d19
	fsub	d4, d4, d20
	add	x16, x9, x16
	add	x10, x0, x10, lsl #4
	stp	d5, d6, [x11]
	add	x12, x9, x12
	mul	x11, x16, x1
	fadd	d5, d16, d3
	mul	x12, x12, x1
	fadd	d6, d1, d4
	stp	d2, d7, [x10]
	fsub	d2, d3, d16
	fsub	d1, d4, d1
	add	x10, x0, x11, lsl #4
	add	x12, x0, x12, lsl #4
	stp	d5, d6, [x12]
	stp	d2, d1, [x10]
	b.lo	.LBB107_6
// %bb.8:                               //   in Loop: Header=BB107_7 Depth=1
	mov	x12, xzr
	ldr	x11, [sp]                       // 8-byte Folded Reload
.LBB107_9:                              //   Parent Loop BB107_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x10, x18, x12
	add	x16, x6, x12
	add	x2, x19, x12
	subs	x11, x11, #1
	ldp	d1, d2, [x10, #-8]
	add	x10, x20, x12
	ldp	d3, d4, [x16, #-8]
	add	x16, x3, x12
	ldp	d5, d6, [x2, #-8]
	add	x2, x22, x12
	ldp	d7, d17, [x10, #-8]
	add	x10, x23, x12
	fadd	d16, d1, d3
	ldp	d19, d20, [x16, #16]
	add	x16, x24, x12
	fadd	d18, d2, d4
	fsub	d1, d1, d3
	fadd	d24, d5, d7
	ldp	d3, d21, [x2, #16]
	fsub	d22, d6, d17
	fadd	d6, d6, d17
	ldp	d23, d25, [x10, #16]
	fsub	d2, d2, d4
	fsub	d4, d5, d7
	ldp	d5, d17, [x16, #16]
	fadd	d7, d1, d22
	fadd	d26, d20, d21
	fadd	d28, d16, d24
	fadd	d29, d18, d6
	fsub	d1, d1, d22
	fadd	d22, d2, d4
	fsub	d2, d2, d4
	fsub	d16, d16, d24
	fadd	d27, d25, d17
	fneg	d4, d7
	fadd	d30, d19, d3
	fadd	d31, d23, d5
	add	x10, x15, x12
	fsub	d6, d18, d6
	fsub	d18, d1, d22
	fadd	d1, d22, d1
	fadd	d24, d26, d27
	fsub	d4, d4, d2
	fsub	d2, d7, d2
	fadd	d22, d30, d31
	fsub	d3, d19, d3
	fsub	d19, d20, d21
	fsub	d5, d23, d5
	fsub	d20, d26, d27
	fsub	d7, d24, d29
	fadd	d24, d29, d24
	ldp	d23, d27, [x10]
	fadd	d26, d28, d22
	add	x10, x4, x12
	fsub	d22, d22, d28
	fsub	d17, d25, d17
	fneg	d21, d7
	fadd	d25, d16, d20
	fmul	d7, d23, d7
	str	d24, [x10, #24]
	str	d26, [x10, #16]
	add	x10, x13, x12
	fsub	d16, d20, d16
	fsub	d26, d30, d31
	fmul	d21, d27, d21
	add	x2, x8, x12
	fmadd	d7, d22, d27, d7
	add	x16, x14, x12
	fmul	d1, d1, d0
	fadd	d29, d19, d5
	ldp	d27, d28, [x2]
	fmadd	d21, d22, d23, d21
	fneg	d23, d25
	ldp	d20, d22, [x10]
	fneg	d24, d16
	str	d7, [x16, #24]
	fmul	d16, d16, d27
	fmul	d18, d18, d0
	str	d21, [x16, #16]
	fsub	d21, d26, d6
	fmul	d25, d25, d20
	fadd	d6, d6, d26
	fmul	d23, d22, d23
	fmul	d7, d28, d24
	add	x16, x5, x12
	add	x10, x30, x12
	add	x2, x28, x12
	fmul	d2, d2, d0
	fsub	d5, d19, d5
	fmul	d4, d4, d0
	fmadd	d20, d21, d20, d23
	fmadd	d21, d21, d22, d25
	fadd	d22, d1, d29
	fmadd	d7, d6, d27, d7
	ldp	d24, d25, [x16]
	fmadd	d6, d6, d28, d16
	fsub	d16, d3, d17
	str	d20, [x10, #16]
	fsub	d1, d29, d1
	fneg	d23, d22
	str	d21, [x10, #24]
	str	d7, [x2, #16]
	add	x10, x29, x12
	fadd	d7, d18, d16
	str	d6, [x2, #24]
	fmul	d6, d22, d24
	fadd	d3, d3, d17
	fmul	d20, d25, d23
	fadd	d19, d2, d5
	add	x16, x25, x12
	fsub	d16, d16, d18
	fsub	d2, d5, d2
	fmadd	d6, d7, d25, d6
	fmadd	d17, d7, d24, d20
	fneg	d7, d1
	ldp	d20, d21, [x10]
	add	x10, x27, x12
	str	d6, [x16, #24]
	fadd	d6, d4, d3
	str	d17, [x16, #16]
	fneg	d17, d19
	ldp	d18, d22, [x10]
	fmul	d5, d21, d7
	add	x10, x26, x12
	fmul	d1, d1, d20
	fsub	d3, d3, d4
	add	x16, x7, x12
	fmadd	d5, d16, d20, d5
	fmul	d7, d22, d17
	ldp	d23, d20, [x10]
	fneg	d17, d2
	fmadd	d1, d16, d21, d1
	fmul	d16, d19, d18
	add	x10, x21, x12
	fmadd	d7, d6, d18, d7
	fmul	d2, d2, d23
	fmul	d4, d20, d17
	str	d5, [x10, #16]
	fmadd	d5, d6, d22, d16
	str	d1, [x10, #24]
	add	x10, x17, x12
	add	x12, x12, #16
	fmadd	d2, d3, d20, d2
	str	d7, [x16, #16]
	fmadd	d1, d3, d23, d4
	str	d5, [x16, #24]
	str	d2, [x10, #24]
	str	d1, [x10, #16]
	b.ne	.LBB107_9
	b	.LBB107_6
.LBB107_10:
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #96]             // 16-byte Folded Reload
	add	sp, sp, #192
	ret
.Lfunc_end107:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end107-_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 176
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	cmp	x1, #1
	str	x5, [sp, #56]                   // 8-byte Folded Spill
	b.ne	.LBB108_16
// %bb.1:
	cbz	x2, .LBB108_45
// %bb.2:
	mov	x8, xzr
	subs	x9, x2, #1
	b.eq	.LBB108_14
// %bb.3:
	cmp	xzr, x9, lsr #60
	add	x11, x4, x2, lsl #4
	lsl	x9, x9, #4
	cset	w10, ne
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB108_14
// %bb.4:
	tbnz	w10, #0, .LBB108_14
// %bb.5:
	add	x11, x11, #8
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB108_14
// %bb.6:
	tbnz	w10, #0, .LBB108_14
// %bb.7:
	add	x11, x4, #8
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB108_14
// %bb.8:
	tbnz	w10, #0, .LBB108_14
// %bb.9:
	add	x11, x4, x9
	cmp	x11, x4
	b.lo	.LBB108_14
// %bb.10:
	tbnz	w10, #0, .LBB108_14
// %bb.11:
	and	x8, x2, #0xfffffffffffffffe
	add	x9, x9, #16
	mov	x10, x8
	mov	x11, x4
	mov	x12, x3
.LBB108_12:                             // =>This Inner Loop Header: Depth=1
	ld4	{ v0.2d, v1.2d, v2.2d, v3.2d }, [x12], #64
	fadd	v4.2d, v0.2d, v2.2d
	add	x13, x11, x9
	fadd	v5.2d, v1.2d, v3.2d
	subs	x10, x10, #2
	st2	{ v4.2d, v5.2d }, [x11], #32
	fsub	v4.2d, v0.2d, v2.2d
	fsub	v5.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x13]
	b.ne	.LBB108_12
// %bb.13:
	cmp	x8, x2
	b.eq	.LBB108_45
.LBB108_14:
	add	x9, x8, x2
	add	x10, x4, x8, lsl #4
	add	x11, x3, x8, lsl #5
	sub	x8, x2, x8
	add	x12, x4, x9, lsl #4
	add	x9, x10, #8
	add	x10, x12, #8
	add	x11, x11, #16
.LBB108_15:                             // =>This Inner Loop Header: Depth=1
	ldp	d0, d1, [x11, #-16]
	subs	x8, x8, #1
	ldp	d2, d3, [x11], #32
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stur	d4, [x9, #-8]
	str	d5, [x9], #16
	stur	d0, [x10, #-8]
	str	d1, [x10], #16
	b.ne	.LBB108_15
	b	.LBB108_45
.LBB108_16:
	cbz	x2, .LBB108_45
// %bb.17:
	subs	x6, x1, #1
	b.ls	.LBB108_43
// %bb.18:
	lsl	x13, x2, #4
	sub	x14, x1, #2
	add	x13, x13, #16
	mul	x12, x2, x1
	cmp	xzr, x14, lsr #60
	lsl	x16, x14, #4
	mul	x8, x13, x1
	mov	x9, xzr
	mov	x10, xzr
	mov	x11, xzr
	add	x18, x12, #1
	cset	w21, ne
	add	x0, x3, #16
	lsl	x15, x1, #5
	stp	x8, x16, [sp, #40]              // 16-byte Folded Spill
	and	x8, x6, #0xfffffffffffffffe
	add	x7, x16, #32
	add	x19, x4, #16
	lsl	x20, x12, #4
	add	x24, x3, #8
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	orr	x8, x6, #0x1
	lsl	x22, x1, #1
	add	x23, x4, #8
	mov	x25, x1
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldr	x8, [sp, #56]                   // 8-byte Folded Reload
	stp	x23, x15, [sp, #16]             // 16-byte Folded Spill
	sub	x8, x8, #8
	stp	x18, x8, [sp, #64]              // 16-byte Folded Spill
.LBB108_19:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB108_31 Depth 2
                                        //     Child Loop BB108_35 Depth 2
	mov	w14, #1
	lsl	x13, x11, #1
	bfi	x14, x11, #1, #63
	mul	x26, x11, x1
	mul	x13, x13, x1
	cmp	x6, #2
	mul	x14, x14, x1
	add	x30, x4, x26, lsl #4
	add	x13, x3, x13, lsl #4
	add	x14, x3, x14, lsl #4
	ldp	d0, d1, [x13]
	add	x13, x11, x2
	ldp	d2, d3, [x14]
	mul	x13, x13, x1
	mov	w14, #1
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	add	x13, x4, x13, lsl #4
	stp	d4, d5, [x30]
	stp	d0, d1, [x13]
	b.lo	.LBB108_34
// %bb.20:                              //   in Loop: Header=BB108_19 Depth=1
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	add	x18, x30, #24
	add	x29, x30, #16
	add	x14, x18, x16
	add	x13, x8, x26
	add	x28, x4, x13, lsl #4
	add	x27, x28, #8
	add	x13, x28, x16
	cmp	x13, x28
	add	x13, x27, x16
	cset	w17, lo
	cmp	x13, x27
	orr	w5, w17, w21
	cset	w17, lo
	cmp	x14, x18
	add	x13, x29, x16
	cset	w14, lo
	cmp	x13, x29
	cset	w13, lo
	tbnz	w5, #0, .LBB108_33
// %bb.21:                              //   in Loop: Header=BB108_19 Depth=1
	orr	w17, w17, w21
	tbnz	w17, #0, .LBB108_33
// %bb.22:                              //   in Loop: Header=BB108_19 Depth=1
	orr	w14, w14, w21
	tbnz	w14, #0, .LBB108_33
// %bb.23:                              //   in Loop: Header=BB108_19 Depth=1
	orr	w13, w13, w21
	mov	w14, #1
	tbnz	w13, #0, .LBB108_34
// %bb.24:                              //   in Loop: Header=BB108_19 Depth=1
	add	x13, x26, x1
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	mov	x14, x4
	mov	x23, x22
	add	x5, x4, x13, lsl #4
	mov	x22, x24
	add	x24, x30, x8
	sub	x13, x5, #8
	cmp	x29, x5
	mov	x15, x6
	cset	w14, lo
	cmp	x18, x13
	sub	x6, x24, #8
	cset	w17, lo
	cmp	x6, x29
	and	w8, w14, w17
	cset	w14, hi
	cmp	x28, x13
	cset	w30, lo
	cmp	x24, x29
	cset	w26, hi
	cmp	x27, x13
	cset	w17, lo
	cmp	x6, x18
	cset	w29, hi
	cmp	x28, x5
	cset	w13, lo
	cmp	x24, x18
	cset	w18, hi
	cmp	x27, x5
	cset	w5, lo
	cmp	x24, x28
	cset	w28, hi
	cmp	x6, x27
	mov	w16, w21
	cset	w27, hi
	tbnz	w8, #0, .LBB108_40
// %bb.25:                              //   in Loop: Header=BB108_19 Depth=1
	and	w8, w14, w30
	mov	x6, x15
	mov	x24, x22
	tbnz	w8, #0, .LBB108_41
// %bb.26:                              //   in Loop: Header=BB108_19 Depth=1
	and	w8, w26, w17
	mov	x22, x23
	tbnz	w8, #0, .LBB108_39
// %bb.27:                              //   in Loop: Header=BB108_19 Depth=1
	and	w8, w29, w13
	mov	w21, w16
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB108_38
// %bb.28:                              //   in Loop: Header=BB108_19 Depth=1
	and	w8, w18, w5
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB108_37
// %bb.29:                              //   in Loop: Header=BB108_19 Depth=1
	and	w8, w28, w27
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB108_34
// %bb.30:                              //   in Loop: Header=BB108_19 Depth=1
	mov	x14, x19
	ldr	x18, [sp, #32]                  // 8-byte Folded Reload
	mov	x26, x0
	ldr	x27, [sp, #56]                  // 8-byte Folded Reload
	mov	x28, x19
.LBB108_31:                             //   Parent Loop BB108_19 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x26, x7
	subs	x18, x18, #2
	ld2	{ v0.2d, v1.2d }, [x26], #32
	ld2	{ v2.2d, v3.2d }, [x8]
	add	x8, x14, x20
	fsub	v6.2d, v1.2d, v3.2d
	fadd	v4.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v0.2d, v0.2d, v2.2d
	fneg	v7.2d, v6.2d
	st2	{ v4.2d, v5.2d }, [x28], #32
	ld2	{ v1.2d, v2.2d }, [x27], #32
	fmul	v3.2d, v2.2d, v7.2d
	mov	x14, x28
	fmla	v3.2d, v1.2d, v0.2d
	fmul	v4.2d, v6.2d, v1.2d
	fmla	v4.2d, v2.2d, v0.2d
	st2	{ v3.2d, v4.2d }, [x8]
	b.ne	.LBB108_31
// %bb.32:                              //   in Loop: Header=BB108_19 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cmp	x6, x8
	b.ne	.LBB108_34
	b	.LBB108_36
.LBB108_33:                             //   in Loop: Header=BB108_19 Depth=1
	mov	w14, #1
.LBB108_34:                             //   in Loop: Header=BB108_19 Depth=1
	add	x8, x14, x10
	add	x13, x14, x12
	add	x17, x14, x25
	add	x18, x14, x9
	add	x27, x24, x8, lsl #4
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	sub	x26, x1, x14
	add	x28, x23, x13, lsl #4
	add	x29, x24, x17, lsl #4
	add	x18, x23, x18, lsl #4
	add	x30, x8, x14, lsl #4
.LBB108_35:                             //   Parent Loop BB108_19 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	d3, d0, [x27, #-8]
	subs	x26, x26, #1
	add	x27, x27, #16
	ldp	d4, d1, [x29, #-8]
	add	x29, x29, #16
	ldp	d5, d7, [x30, #-8]
	add	x30, x30, #16
	fsub	d16, d3, d4
	fadd	d3, d3, d4
	fsub	d2, d0, d1
	fadd	d0, d0, d1
	stur	d3, [x18, #-8]
	fneg	d6, d2
	fmul	d2, d2, d5
	str	d0, [x18], #16
	fmul	d6, d7, d6
	fmadd	d1, d16, d7, d2
	fmadd	d2, d16, d5, d6
	str	d1, [x28]
	stur	d2, [x28, #-8]
	add	x28, x28, #16
	b.ne	.LBB108_35
.LBB108_36:                             //   in Loop: Header=BB108_19 Depth=1
	add	x11, x11, #1
	add	x0, x0, x15
	add	x19, x19, x7
	add	x10, x10, x22
	add	x12, x12, x1
	add	x25, x25, x22
	add	x9, x9, x1
	cmp	x11, x2
	b.ne	.LBB108_19
	b	.LBB108_45
.LBB108_37:                             //   in Loop: Header=BB108_19 Depth=1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	mov	w14, #1
	b	.LBB108_34
.LBB108_38:                             //   in Loop: Header=BB108_19 Depth=1
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB108_34
.LBB108_39:                             //   in Loop: Header=BB108_19 Depth=1
	ldp	x23, x15, [sp, #16]             // 16-byte Folded Reload
	mov	w21, w16
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB108_34
.LBB108_40:                             //   in Loop: Header=BB108_19 Depth=1
	mov	x6, x15
	mov	w21, w16
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	mov	x24, x22
	b	.LBB108_42
.LBB108_41:                             //   in Loop: Header=BB108_19 Depth=1
	mov	w14, #1
	mov	w21, w16
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
.LBB108_42:                             //   in Loop: Header=BB108_19 Depth=1
	mov	x22, x23
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	b	.LBB108_34
.LBB108_43:
	mul	x10, x2, x1
	add	x8, x4, #8
	lsl	x9, x1, #4
	add	x11, x3, #8
	lsl	x10, x10, #4
	lsl	x12, x1, #5
.LBB108_44:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	d0, d1, [x11, #-8]
	add	x11, x11, x12
	ldp	d2, d3, [x13, #-8]
	add	x13, x8, x10
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stur	d4, [x8, #-8]
	str	d5, [x8]
	add	x8, x8, x9
	stur	d0, [x13, #-8]
	str	d1, [x13]
	b.ne	.LBB108_44
.LBB108_45:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end108:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end108-_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI109_0:
	.xword	0x3febb67ae8584caa              // double 0.8660254037844386
	.xword	0xbfebb67ae8584caa              // double -0.8660254037844386
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3
.LCPI109_1:
	.xword	0xbfebb67ae8584caa              // double -0.8660254037844386
.LCPI109_2:
	.xword	0x3febb67ae8584caa              // double 0.8660254037844386
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x20, x19, [sp, #-16]!           // 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	subs	x8, x1, #1
	b.ne	.LBB109_4
// %bb.1:
	cbz	x2, .LBB109_10
// %bb.2:
	adrp	x10, .LCPI109_0
	lsl	x8, x2, #5
	fmov	v0.2d, #-0.50000000
	add	x9, x3, #16
	ldr	q1, [x10, :lo12:.LCPI109_0]
	mov	x10, x2
.LBB109_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q2, q3, [x9]
	subs	x10, x10, #1
	fadd	v4.2d, v2.2d, v3.2d
	fsub	v2.2d, v2.2d, v3.2d
	ldur	q3, [x9, #-16]
	add	x9, x9, #48
	fmul	v5.2d, v4.2d, v0.2d
	fmul	v2.2d, v2.2d, v1.2d
	fadd	v5.2d, v3.2d, v5.2d
	ext	v2.16b, v2.16b, v2.16b, #8
	fadd	v3.2d, v3.2d, v4.2d
	fadd	v4.2d, v2.2d, v5.2d
	fsub	v2.2d, v5.2d, v2.2d
	str	q3, [x4]
	str	q4, [x4, x2, lsl #4]
	str	q2, [x4, x8]
	add	x4, x4, #16
	b.ne	.LBB109_3
	b	.LBB109_10
.LBB109_4:
	cbz	x2, .LBB109_10
// %bb.5:
	mul	x16, x2, x1
	adrp	x17, .LCPI109_0
	adrp	x18, .LCPI109_1
	adrp	x0, .LCPI109_2
	lsl	x11, x1, #4
	add	x12, x1, x1, lsl #1
	fmov	v1.2d, #-0.50000000
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #4
	add	x13, x3, x11
	add	x14, x4, x16, lsl #5
	add	x15, x3, x1, lsl #5
	add	x16, x4, x16, lsl #4
	ldr	q0, [x17, :lo12:.LCPI109_0]
	add	x17, x5, x8, lsl #4
	ldr	d2, [x18, :lo12:.LCPI109_1]
	fmov	d3, #0.50000000
	ldr	d4, [x0, :lo12:.LCPI109_2]
	mov	x18, x4
	mov	x0, x3
	b	.LBB109_7
.LBB109_6:                              //   in Loop: Header=BB109_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x0, x0, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x18, x18, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB109_10
.LBB109_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB109_9 Depth 2
	add	x6, x9, x9, lsl #1
	cmp	x1, #2
	add	x7, x6, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	ldr	q5, [x3, x6, lsl #4]
	mul	x6, x9, x1
	ldr	q6, [x3, x19, lsl #4]
	add	x19, x9, x10
	ldr	q7, [x3, x7, lsl #4]
	add	x7, x9, x2
	mul	x19, x19, x1
	mul	x7, x7, x1
	fadd	v16.2d, v6.2d, v7.2d
	fsub	v6.2d, v6.2d, v7.2d
	fmul	v7.2d, v16.2d, v1.2d
	fmul	v6.2d, v6.2d, v0.2d
	fadd	v7.2d, v5.2d, v7.2d
	ext	v6.16b, v6.16b, v6.16b, #8
	fadd	v5.2d, v5.2d, v16.2d
	fadd	v16.2d, v6.2d, v7.2d
	str	q5, [x4, x6, lsl #4]
	fsub	v6.2d, v7.2d, v6.2d
	str	q16, [x4, x7, lsl #4]
	str	q6, [x4, x19, lsl #4]
	b.lo	.LBB109_6
// %bb.8:                               //   in Loop: Header=BB109_7 Depth=1
	mov	x6, xzr
	mov	x7, x8
.LBB109_9:                              //   Parent Loop BB109_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x19, x13, x6
	add	x20, x15, x6
	subs	x7, x7, #1
	ldp	d7, d5, [x19, #16]
	add	x19, x0, x6
	ldp	d17, d6, [x20, #16]
	add	x20, x17, x6
	ldr	d20, [x19, #24]
	fsub	d18, d7, d17
	fadd	d7, d7, d17
	fadd	d16, d5, d6
	fsub	d5, d5, d6
	ldp	d26, d27, [x20]
	add	x20, x16, x6
	fmul	d17, d18, d4
	fmul	d6, d7, d3
	fmul	d19, d16, d3
	fmul	d5, d5, d2
	fadd	d16, d20, d16
	fsub	d18, d20, d19
	ldr	d19, [x19, #16]
	add	x19, x5, x6
	fsub	d6, d19, d6
	fadd	d7, d19, d7
	fadd	d21, d17, d18
	fsub	d17, d18, d17
	ldp	d18, d23, [x19]
	add	x19, x18, x6
	fadd	d24, d6, d5
	fsub	d5, d6, d5
	fneg	d22, d21
	fneg	d25, d17
	fmul	d21, d18, d21
	fmul	d17, d17, d26
	stp	d7, d16, [x19, #16]
	add	x19, x14, x6
	add	x6, x6, #16
	fmul	d22, d23, d22
	fmul	d19, d27, d25
	fmadd	d6, d24, d23, d21
	fmadd	d18, d24, d18, d22
	fmadd	d7, d5, d26, d19
	fmadd	d5, d5, d27, d17
	stp	d18, d6, [x20, #16]
	stp	d7, d5, [x19, #16]
	b.ne	.LBB109_9
	b	.LBB109_6
.LBB109_10:
	ldp	x20, x19, [sp], #16             // 16-byte Folded Reload
	ret
.Lfunc_end109:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end109-_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI110_0:
	.xword	0x3fd3c6ef372fe950              // double 0.30901699437494745
.LCPI110_1:
	.xword	0xbfe9e3779b97f4a8              // double -0.80901699437494745
.LCPI110_2:
	.xword	0x3fe2cf2304755a5e              // double 0.58778525229247314
.LCPI110_3:
	.xword	0x3fee6f0e134454ff              // double 0.95105651629515353
.LCPI110_4:
	.xword	0xbfee6f0e134454ff              // double -0.95105651629515353
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	b.ne	.LBB110_4
// %bb.1:
	cbz	x2, .LBB110_10
// %bb.2:
	adrp	x11, .LCPI110_0
	adrp	x12, .LCPI110_1
	adrp	x13, .LCPI110_2
	adrp	x14, .LCPI110_3
	adrp	x15, .LCPI110_4
	add	x10, x2, x2, lsl #1
	add	x8, x4, #8
	lsl	x9, x2, #5
	lsl	x10, x10, #4
	ldr	d0, [x11, :lo12:.LCPI110_0]
	ldr	d1, [x12, :lo12:.LCPI110_1]
	lsl	x11, x2, #6
	ldr	d2, [x13, :lo12:.LCPI110_2]
	lsl	x12, x2, #4
	ldr	d3, [x14, :lo12:.LCPI110_3]
	add	x13, x3, #40
	ldr	d4, [x15, :lo12:.LCPI110_4]
.LBB110_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d5, d6, [x13, #-24]
	add	x14, x8, x12
	add	x15, x8, x11
	ldp	d17, d7, [x13, #24]
	subs	x2, x2, #1
	ldp	d16, d19, [x13, #-8]
	ldp	d20, d18, [x13, #8]
	fadd	d22, d6, d7
	fsub	d6, d6, d7
	ldp	d24, d7, [x13, #-40]
	fadd	d21, d5, d17
	fsub	d5, d5, d17
	fsub	d23, d16, d20
	fadd	d16, d16, d20
	fsub	d17, d19, d18
	fadd	d18, d19, d18
	add	x13, x13, #80
	fmadd	d19, d21, d0, d24
	fmadd	d25, d22, d0, d7
	fmul	d26, d23, d2
	fadd	d27, d24, d21
	fmul	d20, d17, d2
	fmadd	d21, d21, d1, d24
	fmadd	d24, d22, d1, d7
	fmul	d17, d17, d4
	fmadd	d19, d16, d1, d19
	fmadd	d25, d18, d1, d25
	fmadd	d26, d5, d3, d26
	fmul	d23, d23, d4
	fmadd	d20, d6, d3, d20
	fadd	d27, d27, d16
	fmadd	d16, d16, d0, d21
	fmadd	d6, d6, d2, d17
	fmadd	d17, d18, d0, d24
	fadd	d7, d7, d22
	fmadd	d5, d5, d2, d23
	fsub	d21, d25, d26
	fsub	d28, d19, d20
	fadd	d19, d19, d20
	fadd	d20, d25, d26
	fadd	d7, d7, d18
	stp	d19, d21, [x15, #-8]
	fsub	d19, d16, d6
	stp	d28, d20, [x14, #-8]
	fadd	d20, d17, d5
	add	x14, x8, x9
	fadd	d6, d16, d6
	fsub	d5, d17, d5
	stp	d27, d7, [x8, #-8]
	stp	d19, d20, [x14, #-8]
	add	x14, x8, x10
	add	x8, x8, #16
	stp	d6, d5, [x14, #-8]
	b.ne	.LBB110_3
	b	.LBB110_10
.LBB110_4:
	cbz	x2, .LBB110_10
// %bb.5:
	adrp	x23, .LCPI110_1
	mul	x22, x2, x1
	mov	w14, #48
	add	x18, x8, x8, lsl #1
	adrp	x20, .LCPI110_0
	adrp	x24, .LCPI110_2
	adrp	x25, .LCPI110_3
	ldr	d1, [x23, :lo12:.LCPI110_1]
	adrp	x23, .LCPI110_4
	lsl	x7, x8, #5
	lsl	x21, x18, #4
	lsl	x11, x2, #1
	lsl	x13, x1, #4
	madd	x14, x22, x14, x4
	add	x15, x1, x1, lsl #2
	add	x18, x7, x3
	add	x0, x21, x3
	mov	x9, xzr
	lsl	x10, x2, #2
	add	x12, x11, x2
	lsl	x15, x15, #4
	add	x16, x3, x13
	add	x17, x3, x1, lsl #6
	add	x18, x18, #32
	add	x0, x0, #48
	add	x6, x4, x22, lsl #5
	add	x7, x5, x7
	add	x19, x5, x8, lsl #4
	ldr	d0, [x20, :lo12:.LCPI110_0]
	add	x20, x4, x22, lsl #6
	ldr	d2, [x24, :lo12:.LCPI110_2]
	add	x21, x5, x21
	ldr	d3, [x25, :lo12:.LCPI110_3]
	add	x22, x4, x22, lsl #4
	ldr	d4, [x23, :lo12:.LCPI110_4]
	mov	x23, x4
	mov	x24, x3
	b	.LBB110_7
.LBB110_6:                              //   in Loop: Header=BB110_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x13
	add	x24, x24, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x23, x23, x13
	add	x6, x6, x13
	add	x20, x20, x13
	add	x22, x22, x13
	cmp	x9, x2
	b.eq	.LBB110_10
.LBB110_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB110_9 Depth 2
	add	x25, x9, x9, lsl #2
	cmp	x1, #2
	add	x27, x25, #4
	add	x29, x25, #2
	mul	x26, x25, x1
	add	x25, x25, #3
	mul	x27, x27, x1
	add	x28, x1, x26
	mul	x29, x29, x1
	mul	x25, x25, x1
	add	x26, x3, x26, lsl #4
	add	x28, x3, x28, lsl #4
	add	x27, x3, x27, lsl #4
	add	x25, x3, x25, lsl #4
	ldp	d5, d6, [x28]
	add	x28, x3, x29, lsl #4
	ldp	d7, d16, [x27]
	add	x27, x9, x10
	ldp	d17, d18, [x28]
	ldp	d19, d20, [x25]
	fadd	d23, d5, d7
	fadd	d25, d6, d16
	ldp	d21, d22, [x26]
	fsub	d5, d5, d7
	fsub	d6, d6, d16
	fsub	d26, d17, d19
	fadd	d7, d17, d19
	fsub	d24, d18, d20
	fadd	d16, d18, d20
	fmadd	d17, d23, d0, d21
	fadd	d27, d21, d23
	fmadd	d19, d25, d0, d22
	fadd	d28, d22, d25
	fmul	d20, d26, d2
	mul	x25, x9, x1
	fmul	d18, d24, d2
	add	x26, x9, x2
	fmadd	d17, d7, d1, d17
	fadd	d27, d27, d7
	fmadd	d19, d16, d1, d19
	mul	x26, x26, x1
	fmadd	d20, d5, d3, d20
	fadd	d28, d28, d16
	fmadd	d18, d6, d3, d18
	add	x25, x4, x25, lsl #4
	fmadd	d21, d23, d1, d21
	fmul	d23, d24, d4
	fmadd	d22, d25, d1, d22
	fmul	d24, d26, d4
	fadd	d30, d19, d20
	add	x26, x4, x26, lsl #4
	fsub	d29, d17, d18
	str	d27, [x25]
	str	d28, [x25, #8]
	mul	x25, x27, x1
	fadd	d17, d17, d18
	fmadd	d7, d7, d0, d21
	str	d30, [x26, #8]
	fmadd	d6, d6, d2, d23
	str	d29, [x26]
	add	x26, x9, x11
	fmadd	d16, d16, d0, d22
	fmadd	d5, d5, d2, d24
	add	x27, x9, x12
	fsub	d18, d19, d20
	add	x25, x4, x25, lsl #4
	mul	x26, x26, x1
	mul	x27, x27, x1
	fadd	d19, d16, d5
	fsub	d5, d16, d5
	str	d17, [x25]
	fsub	d17, d7, d6
	fadd	d6, d7, d6
	add	x26, x4, x26, lsl #4
	str	d18, [x25, #8]
	add	x25, x4, x27, lsl #4
	str	d17, [x26]
	str	d19, [x26, #8]
	str	d6, [x25]
	str	d5, [x25, #8]
	b.lo	.LBB110_6
// %bb.8:                               //   in Loop: Header=BB110_7 Depth=1
	mov	x25, xzr
	mov	x26, x8
.LBB110_9:                              //   Parent Loop BB110_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x27, x16, x25
	add	x28, x17, x25
	add	x29, x0, x25
	add	x30, x18, x25
	subs	x26, x26, #1
	ldp	d5, d6, [x27, #16]
	add	x27, x24, x25
	ldp	d23, d7, [x28, #16]
	add	x28, x23, x25
	ldp	d16, d19, [x29, #16]
	ldp	d17, d18, [x30, #16]
	fadd	d20, d6, d7
	fsub	d26, d5, d23
	ldp	d28, d21, [x27, #16]
	fadd	d5, d5, d23
	add	x27, x5, x25
	fsub	d22, d17, d16
	fsub	d6, d6, d7
	fadd	d24, d18, d19
	fsub	d18, d18, d19
	fadd	d7, d17, d16
	fmadd	d25, d20, d0, d21
	fmadd	d17, d5, d0, d28
	fmul	d27, d22, d2
	fadd	d16, d21, d20
	fmul	d29, d18, d2
	fadd	d31, d28, d5
	fmadd	d20, d20, d1, d21
	fmadd	d5, d5, d1, d28
	fmadd	d19, d24, d1, d25
	fmul	d21, d22, d4
	fmadd	d23, d26, d3, d27
	fmadd	d17, d7, d1, d17
	ldp	d25, d27, [x27]
	fmadd	d22, d6, d3, d29
	add	x27, x21, x25
	fmadd	d21, d26, d2, d21
	fadd	d16, d16, d24
	fadd	d30, d19, d23
	fmadd	d20, d24, d0, d20
	ldp	d24, d29, [x27]
	fsub	d26, d17, d22
	add	x27, x19, x25
	fadd	d31, d31, d7
	fsub	d19, d19, d23
	fneg	d28, d30
	fmul	d30, d25, d30
	fmadd	d5, d7, d0, d5
	fmul	d18, d18, d4
	ldp	d7, d23, [x27]
	add	x27, x22, x25
	stp	d31, d16, [x28, #16]
	fmul	d28, d27, d28
	fneg	d16, d19
	fmadd	d6, d6, d2, d18
	fadd	d17, d17, d22
	fmul	d19, d19, d24
	add	x28, x6, x25
	fmadd	d25, d26, d25, d28
	fmadd	d26, d26, d27, d30
	fadd	d28, d20, d21
	fsub	d20, d20, d21
	fmul	d16, d29, d16
	fsub	d21, d5, d6
	fadd	d5, d5, d6
	stp	d25, d26, [x27, #16]
	add	x27, x7, x25
	fneg	d18, d28
	fneg	d22, d20
	fmul	d26, d28, d7
	fmadd	d16, d17, d24, d16
	ldp	d25, d27, [x27]
	fmadd	d17, d17, d29, d19
	add	x27, x20, x25
	fmul	d18, d23, d18
	fmul	d19, d20, d25
	fmul	d6, d27, d22
	stp	d16, d17, [x27, #16]
	fmadd	d7, d21, d7, d18
	fmadd	d18, d21, d23, d26
	add	x27, x14, x25
	add	x25, x25, #16
	fmadd	d6, d5, d25, d6
	fmadd	d5, d5, d27, d19
	stp	d7, d18, [x28, #16]
	stp	d6, d5, [x27, #16]
	b.ne	.LBB110_9
	b	.LBB110_6
.LBB110_10:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end110:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end110-_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI111_0:
	.xword	0x3fe3f3a0e28bedd1              // double 0.62348980185873348
.LCPI111_1:
	.xword	0xbfcc7b90e3024582              // double -0.22252093395631439
.LCPI111_2:
	.xword	0xbfecd4bca9cb5c71              // double -0.90096886790241915
.LCPI111_3:
	.xword	0x3fef329c0558e969              // double 0.97492791218182361
.LCPI111_4:
	.xword	0x3fe904c37505de4b              // double 0.7818314824680298
.LCPI111_5:
	.xword	0x3fdbc4c04d71abc1              // double 0.43388373911755812
.LCPI111_6:
	.xword	0xbfdbc4c04d71abc1              // double -0.43388373911755812
.LCPI111_7:
	.xword	0xbfe904c37505de4b              // double -0.7818314824680298
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #256
	stp	d15, d14, [sp, #96]             // 16-byte Folded Spill
	stp	d13, d12, [sp, #112]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #128]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #144]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #176]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #192]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 256
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #64]               // 16-byte Folded Spill
	str	x2, [sp, #56]                   // 8-byte Folded Spill
	b.ne	.LBB111_4
// %bb.1:
	cbz	x2, .LBB111_10
// %bb.2:
	adrp	x16, .LCPI111_2
	adrp	x11, .LCPI111_0
	adrp	x12, .LCPI111_1
	adrp	x17, .LCPI111_3
	add	x15, x2, x2, lsl #2
	ldr	d2, [x16, :lo12:.LCPI111_2]
	adrp	x16, .LCPI111_5
	ldr	d0, [x11, :lo12:.LCPI111_0]
	lsl	x11, x15, #4
	ldr	d1, [x12, :lo12:.LCPI111_1]
	adrp	x12, .LCPI111_4
	ldr	d3, [x17, :lo12:.LCPI111_3]
	adrp	x15, .LCPI111_6
	ldp	x17, x8, [sp, #56]              // 16-byte Folded Reload
	add	x14, x2, x2, lsl #1
	ldr	d5, [x16, :lo12:.LCPI111_5]
	adrp	x16, .LCPI111_7
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	lsl	x9, x2, #6
	add	x8, x8, #8
	lsl	x10, x14, #4
	ldr	d4, [x12, :lo12:.LCPI111_4]
	lsl	x12, x17, #5
	lsl	x14, x14, #5
	ldr	d6, [x15, :lo12:.LCPI111_6]
	lsl	x15, x17, #4
	add	x13, x13, #56
	ldr	d7, [x16, :lo12:.LCPI111_7]
.LBB111_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d27, d24, [x13, #24]
	add	x16, x8, x15
	mov	x18, x17
	ldp	d21, d26, [x13, #-24]
	add	x17, x8, x14
	ldp	d22, d16, [x13, #-40]
	ldp	d23, d18, [x13, #40]
	fsub	d19, d26, d24
	ldp	d29, d20, [x13, #-56]
	fadd	d25, d22, d23
	fsub	d22, d22, d23
	fadd	d17, d16, d18
	fsub	d16, d16, d18
	ldp	d9, d28, [x13, #8]
	fadd	d18, d21, d27
	fsub	d21, d21, d27
	ldp	d27, d31, [x13, #-8]
	fmadd	d30, d25, d0, d29
	fmul	d8, d19, d3
	fadd	d23, d26, d24
	fmadd	d24, d17, d0, d20
	fmul	d26, d21, d3
	fmadd	d12, d25, d1, d29
	fadd	d10, d27, d9
	fsub	d27, d27, d9
	fsub	d11, d31, d28
	fmadd	d30, d18, d1, d30
	fmadd	d8, d16, d4, d8
	fadd	d28, d31, d28
	fmadd	d24, d23, d1, d24
	fmadd	d26, d22, d4, d26
	fmul	d14, d19, d6
	fmul	d19, d19, d7
	fmadd	d30, d10, d2, d30
	add	x13, x13, #112
	fmadd	d31, d11, d5, d8
	fadd	d8, d29, d25
	fmadd	d24, d28, d2, d24
	fmadd	d26, d27, d5, d26
	fmadd	d25, d25, d2, d29
	fadd	d29, d20, d17
	fsub	d9, d30, d31
	fadd	d8, d8, d18
	fadd	d13, d26, d24
	fadd	d30, d30, d31
	fmadd	d31, d18, d2, d12
	fmul	d12, d21, d6
	fsub	d24, d24, d26
	fmadd	d18, d18, d0, d25
	stur	d9, [x16, #-8]
	fmadd	d9, d17, d1, d20
	str	d13, [x16]
	fmadd	d13, d16, d3, d14
	stur	d30, [x17, #-8]
	fadd	d26, d8, d10
	fmadd	d30, d10, d0, d31
	fmadd	d8, d22, d3, d12
	fmadd	d31, d23, d2, d9
	fmadd	d17, d17, d2, d20
	fmul	d20, d21, d7
	fmadd	d9, d11, d7, d13
	fmadd	d16, d16, d5, d19
	fmadd	d18, d10, d1, d18
	str	d24, [x17]
	add	x16, x8, x12
	fmadd	d21, d28, d0, d31
	fmadd	d31, d27, d7, d8
	fmadd	d17, d23, d0, d17
	fmadd	d19, d22, d5, d20
	fadd	d22, d30, d9
	fmadd	d16, d11, d3, d16
	fsub	d24, d30, d9
	add	x17, x8, x11
	fadd	d20, d31, d21
	fsub	d21, d21, d31
	fmadd	d17, d28, d1, d17
	fmadd	d19, d27, d3, d19
	fadd	d23, d29, d23
	stur	d22, [x17, #-8]
	stur	d24, [x16, #-8]
	str	d20, [x16]
	fsub	d20, d18, d16
	fadd	d22, d19, d17
	add	x16, x8, x10
	str	d21, [x17]
	mov	x17, x18
	fadd	d21, d23, d28
	fadd	d16, d18, d16
	fsub	d17, d17, d19
	stur	d20, [x16, #-8]
	str	d22, [x16]
	add	x16, x8, x9
	subs	x17, x18, #1
	stur	d26, [x8, #-8]
	str	d21, [x8], #16
	stur	d16, [x16, #-8]
	str	d17, [x16]
	b.ne	.LBB111_3
	b	.LBB111_10
.LBB111_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	cbz	x2, .LBB111_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x11, x2, #2
	ldr	x12, [sp, #8]                   // 8-byte Folded Reload
	adrp	x27, .LCPI111_2
	mov	w14, #112
	mul	x10, x2, x1
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	lsl	x3, x12, #5
	add	x23, x5, x3
	mov	w30, #96
	stp	x11, x8, [sp, #32]              // 16-byte Folded Spill
	add	x8, x11, x2
	mul	x2, x1, x14
	add	x7, x12, x12, lsl #1
	mov	w21, #48
	mov	w24, #80
	stp	x8, x18, [sp, #16]              // 16-byte Folded Spill
	adrp	x26, .LCPI111_1
	ldp	x11, x8, [sp, #64]              // 16-byte Folded Reload
	adrp	x28, .LCPI111_4
	adrp	x14, .LCPI111_7
	ldr	d2, [x27, :lo12:.LCPI111_2]
	adrp	x27, .LCPI111_5
	lsl	x22, x7, #4
	lsl	x25, x12, #6
	lsl	x16, x1, #4
	madd	x21, x10, x21, x11
	add	x4, x3, x8
	adrp	x3, .LCPI111_0
	add	x6, x4, #32
	add	x4, x12, x12, lsl #2
	lsl	x4, x4, #4
	madd	x0, x1, x30, x8
	ldr	d0, [x3, :lo12:.LCPI111_0]
	adrp	x3, .LCPI111_3
	add	x19, x4, x8
	add	x20, x25, x8
	add	x7, x19, #80
	add	x19, x22, x8
	ldr	d3, [x3, :lo12:.LCPI111_3]
	adrp	x3, .LCPI111_6
	madd	x24, x10, x24, x11
	mov	x9, xzr
	madd	x30, x10, x30, x11
	add	x15, x11, x10, lsl #6
	add	x18, x8, x16
	add	x19, x19, #48
	add	x20, x20, #64
	add	x22, x5, x22
	add	x25, x5, x25
	ldr	d1, [x26, :lo12:.LCPI111_1]
	add	x26, x5, x12, lsl #4
	ldr	d4, [x28, :lo12:.LCPI111_4]
	ldr	d5, [x27, :lo12:.LCPI111_5]
	add	x27, x11, x10, lsl #5
	add	x28, x5, x4
	ldr	d6, [x3, :lo12:.LCPI111_6]
	add	x29, x11, x10, lsl #4
	ldr	d7, [x14, :lo12:.LCPI111_7]
	mov	x4, x11
	mov	x3, x8
	ldr	x17, [sp, #72]                  // 8-byte Folded Reload
	stp	d4, d6, [sp, #80]               // 16-byte Folded Spill
	b	.LBB111_7
.LBB111_6:                              //   in Loop: Header=BB111_7 Depth=1
	add	x9, x9, #1
	add	x15, x15, x16
	add	x3, x3, x2
	add	x18, x18, x2
	add	x0, x0, x2
	add	x6, x6, x2
	add	x7, x7, x2
	add	x19, x19, x2
	add	x20, x20, x2
	add	x4, x4, x16
	add	x21, x21, x16
	add	x24, x24, x16
	add	x27, x27, x16
	add	x29, x29, x16
	add	x30, x30, x16
	ldr	d6, [sp, #88]                   // 8-byte Folded Reload
	cmp	x9, x13
	b.eq	.LBB111_10
.LBB111_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB111_9 Depth 2
	lsl	x10, x9, #3
	cmp	x1, #2
	sub	x10, x10, x9
	add	x14, x10, #6
	add	x13, x10, #2
	mul	x11, x10, x1
	add	x8, x10, #5
	mul	x14, x14, x1
	add	x12, x1, x11
	mul	x13, x13, x1
	mul	x8, x8, x1
	add	x11, x17, x11, lsl #4
	add	x12, x17, x12, lsl #4
	add	x14, x17, x14, lsl #4
	add	x8, x17, x8, lsl #4
	ldp	d20, d22, [x12]
	add	x12, x17, x13, lsl #4
	add	x13, x10, #3
	ldp	d21, d25, [x14]
	add	x10, x10, #4
	ldp	d26, d27, [x12]
	mul	x12, x13, x1
	ldp	d28, d29, [x8]
	mul	x8, x10, x1
	fadd	d23, d20, d21
	ldp	d24, d18, [x11]
	add	x10, x17, x12, lsl #4
	fadd	d19, d22, d25
	add	x8, x17, x8, lsl #4
	fadd	d17, d26, d28
	fadd	d16, d27, d29
	fsub	d25, d22, d25
	ldp	d30, d31, [x10]
	fadd	d8, d24, d23
	fadd	d9, d18, d19
	ldp	d10, d11, [x8]
	fsub	d27, d27, d29
	mul	x8, x9, x1
	ldp	x13, x12, [sp, #56]             // 16-byte Folded Reload
	fsub	d21, d20, d21
	fadd	d29, d8, d17
	fadd	d8, d9, d16
	fadd	d22, d30, d10
	fmadd	d9, d23, d0, d24
	fadd	d20, d31, d11
	fmadd	d12, d19, d0, d18
	fmul	d13, d27, d3
	fsub	d26, d26, d28
	add	x8, x12, x8, lsl #4
	fsub	d31, d31, d11
	fadd	d28, d29, d22
	fadd	d29, d8, d20
	fmadd	d8, d17, d1, d9
	fmadd	d9, d16, d1, d12
	fmadd	d11, d25, d4, d13
	fsub	d30, d30, d10
	fmadd	d10, d23, d1, d24
	str	d28, [x8]
	fmul	d28, d26, d3
	str	d29, [x8, #8]
	fmadd	d29, d22, d2, d8
	add	x8, x9, x13
	fmadd	d8, d20, d2, d9
	fmadd	d9, d31, d5, d11
	fmadd	d11, d19, d1, d18
	fmadd	d28, d21, d4, d28
	mul	x8, x8, x1
	fmul	d12, d27, d6
	fmul	d14, d26, d6
	ldr	x10, [sp, #24]                  // 8-byte Folded Reload
	fmadd	d10, d17, d2, d10
	fsub	d13, d29, d9
	add	x8, x12, x8, lsl #4
	fmadd	d28, d30, d5, d28
	ldr	x11, [sp, #48]                  // 8-byte Folded Reload
	add	x10, x9, x10
	fmadd	d11, d16, d2, d11
	fmadd	d12, d25, d3, d12
	fadd	d29, d29, d9
	str	d13, [x8]
	fmadd	d13, d21, d3, d14
	fadd	d9, d28, d8
	mul	x10, x10, x1
	add	x11, x9, x11
	fmadd	d10, d22, d0, d10
	fmadd	d11, d20, d0, d11
	fmadd	d12, d31, d7, d12
	fmadd	d13, d30, d7, d13
	add	x10, x12, x10, lsl #4
	str	d9, [x8, #8]
	mul	x8, x11, x1
	ldr	x11, [sp, #16]                  // 8-byte Folded Reload
	fsub	d28, d8, d28
	str	d29, [x10]
	fsub	d29, d10, d12
	fmadd	d23, d23, d2, d24
	fadd	d24, d13, d11
	add	x11, x9, x11
	add	x8, x12, x8, lsl #4
	fmul	d27, d27, d7
	fmadd	d18, d19, d2, d18
	fmul	d19, d26, d7
	str	d28, [x10, #8]
	mul	x10, x11, x1
	str	d29, [x8]
	str	d24, [x8, #8]
	fmadd	d17, d17, d0, d23
	fmadd	d23, d25, d5, d27
	fmadd	d16, d16, d0, d18
	add	x8, x12, x10, lsl #4
	fmadd	d18, d21, d5, d19
	ldp	x11, x10, [sp, #32]             // 16-byte Folded Reload
	fadd	d19, d10, d12
	fmadd	d17, d22, d1, d17
	fmadd	d22, d31, d3, d23
	fmadd	d16, d20, d1, d16
	fmadd	d18, d30, d3, d18
	fsub	d21, d11, d13
	add	x11, x9, x11
	add	x10, x9, x10
	str	d19, [x8]
	mul	x11, x11, x1
	fsub	d19, d17, d22
	mul	x10, x10, x1
	fadd	d20, d18, d16
	fadd	d17, d17, d22
	fsub	d16, d16, d18
	str	d21, [x8, #8]
	add	x8, x12, x11, lsl #4
	add	x10, x12, x10, lsl #4
	str	d19, [x10]
	str	d20, [x10, #8]
	str	d17, [x8]
	str	d16, [x8, #8]
	b.lo	.LBB111_6
// %bb.8:                               //   in Loop: Header=BB111_7 Depth=1
	mov	x14, xzr
	ldr	x10, [sp, #8]                   // 8-byte Folded Reload
.LBB111_9:                              //   Parent Loop BB111_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x18, x14
	add	x11, x0, x14
	add	x12, x7, x14
	fmov	d6, d0
	subs	x10, x10, #1
	ldp	d21, d22, [x8, #16]
	add	x8, x6, x14
	ldp	d23, d24, [x11, #16]
	add	x11, x3, x14
	ldp	d30, d26, [x12, #16]
	add	x12, x20, x14
	ldp	d31, d25, [x8, #16]
	add	x8, x19, x14
	fadd	d19, d22, d24
	ldp	d28, d20, [x11, #16]
	fsub	d16, d21, d23
	fadd	d29, d21, d23
	fsub	d17, d31, d30
	fsub	d23, d22, d24
	ldp	d8, d9, [x8, #16]
	fadd	d18, d25, d26
	fsub	d25, d25, d26
	ldp	d11, d12, [x12, #16]
	fmadd	d10, d19, d0, d20
	fmul	d13, d17, d3
	fadd	d24, d31, d30
	fmadd	d30, d29, d0, d28
	fmul	d31, d25, d3
	add	x8, x5, x14
	fsub	d27, d8, d11
	fadd	d21, d8, d11
	fadd	d26, d9, d12
	fmadd	d10, d18, d1, d10
	fmadd	d13, d16, d4, d13
	fadd	d8, d28, d29
	fsub	d22, d9, d12
	fadd	d9, d20, d19
	fmadd	d30, d24, d1, d30
	fmadd	d31, d23, d4, d31
	fmadd	d10, d26, d2, d10
	add	x11, x4, x14
	fmadd	d11, d27, d5, d13
	fadd	d8, d8, d24
	fadd	d9, d9, d18
	fmov	d0, d7
	ldp	d14, d15, [x8]
	fmadd	d30, d21, d2, d30
	fmadd	d31, d22, d5, d31
	fadd	d12, d11, d10
	fadd	d8, d8, d21
	fadd	d9, d9, d26
	fmov	d7, d5
	ldr	d5, [sp, #88]                   // 8-byte Folded Reload
	add	x8, x28, x14
	fsub	d4, d30, d31
	fsub	d10, d10, d11
	fneg	d13, d12
	fmadd	d11, d19, d1, d20
	stp	d8, d9, [x11, #16]
	fmul	d8, d17, d5
	fadd	d30, d30, d31
	fmul	d31, d14, d12
	fneg	d9, d10
	add	x11, x26, x14
	fmul	d13, d15, d13
	fmadd	d11, d18, d2, d11
	fmadd	d8, d16, d3, d8
	fmadd	d19, d19, d2, d20
	fmadd	d13, d4, d14, d13
	fmadd	d4, d4, d15, d31
	ldp	d12, d14, [x8]
	fmul	d15, d25, d5
	fmov	d5, d7
	fmov	d7, d0
	fmadd	d11, d26, d6, d11
	add	x8, x29, x14
	fmadd	d18, d18, d6, d19
	fmul	d10, d10, d12
	fmov	d0, d6
	fmul	d31, d14, d9
	fmadd	d9, d29, d1, d28
	fmadd	d8, d27, d7, d8
	stp	d13, d4, [x8, #16]
	fmul	d17, d17, d7
	add	x8, x30, x14
	fmadd	d28, d29, d2, d28
	fmul	d25, d25, d7
	fmadd	d4, d24, d2, d9
	fmadd	d31, d30, d12, d31
	fmadd	d9, d23, d3, d15
	fmadd	d30, d30, d14, d10
	fadd	d10, d8, d11
	fmadd	d16, d16, d5, d17
	ldp	d12, d13, [x11]
	fmadd	d4, d21, d6, d4
	fsub	d29, d11, d8
	fmadd	d20, d22, d7, d9
	stp	d31, d30, [x8, #16]
	fneg	d9, d10
	add	x8, x25, x14
	fmadd	d18, d26, d1, d18
	fmadd	d16, d27, d3, d16
	fmadd	d23, d23, d5, d25
	add	x11, x27, x14
	fsub	d19, d4, d20
	fadd	d4, d4, d20
	fmul	d17, d13, d9
	fmul	d20, d10, d12
	ldp	d25, d26, [x8]
	add	x8, x23, x14
	fneg	d27, d29
	fmadd	d17, d19, d12, d17
	fmadd	d19, d19, d13, d20
	fmadd	d20, d24, d6, d28
	fadd	d24, d16, d18
	fsub	d16, d18, d16
	stp	d17, d19, [x11, #16]
	fmul	d19, d29, d25
	fmadd	d20, d21, d1, d20
	fmadd	d21, d22, d3, d23
	ldp	d22, d23, [x8]
	add	x8, x22, x14
	fneg	d18, d24
	fmul	d17, d26, d27
	fneg	d28, d16
	fsub	d27, d20, d21
	add	x11, x21, x14
	ldp	d29, d30, [x8]
	fmul	d18, d23, d18
	fmul	d24, d24, d22
	fmadd	d17, d4, d25, d17
	fmadd	d4, d4, d26, d19
	fadd	d19, d20, d21
	add	x8, x24, x14
	fmul	d16, d16, d29
	fmul	d20, d30, d28
	fmadd	d18, d27, d22, d18
	fmadd	d21, d27, d23, d24
	stp	d17, d4, [x8, #16]
	add	x8, x15, x14
	add	x14, x14, #16
	fmadd	d16, d19, d30, d16
	fmadd	d4, d19, d29, d20
	stp	d18, d21, [x11, #16]
	stp	d4, d16, [x8, #16]
	ldr	d4, [sp, #80]                   // 8-byte Folded Reload
	b.ne	.LBB111_9
	b	.LBB111_6
.LBB111_10:
	ldp	x20, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #144]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #128]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #112]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #96]             // 16-byte Folded Reload
	add	sp, sp, #256
	ret
.Lfunc_end111:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end111-_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
.LCPI112_0:
	.xword	0x3feaeb8c8764f0ba              // double 0.84125353283118121
.LCPI112_1:
	.xword	0x3fda9628d9c712b6              // double 0.41541501300188644
.LCPI112_2:
	.xword	0x3fc2375f640f44db              // double 0.14231483827328514
.LCPI112_3:
	.xword	0x3fe4f49e7f775887              // double 0.6548607339452851
.LCPI112_4:
	.xword	0x3feeb42a9bcd5057              // double 0.95949297361449736
.LCPI112_5:
	.xword	0x3fed1bb48eee2c13              // double 0.90963199535451833
.LCPI112_6:
	.xword	0x3fe14cedf8bb580b              // double 0.54064081745559756
.LCPI112_7:
	.xword	0x3fefac9e043842ef              // double 0.98982144188093268
.LCPI112_8:
	.xword	0x3fe82f19bb3a28a1              // double 0.75574957435425827
.LCPI112_9:
	.xword	0x3fd207e7fd768dbf              // double 0.28173255684142967
.LCPI112_10:
	.xword	0xbfd207e7fd768dbf              // double -0.28173255684142967
.LCPI112_11:
	.xword	0xbfefac9e043842ef              // double -0.98982144188093268
.LCPI112_12:
	.xword	0xbfe14cedf8bb580b              // double -0.54064081745559756
.LCPI112_13:
	.xword	0xbfed1bb48eee2c13              // double -0.90963199535451833
	.section	.text._ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #592
	.cfi_def_cfa_offset 752
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #168]              // 16-byte Folded Spill
	b.ne	.LBB112_4
// %bb.1:
	cbz	x2, .LBB112_10
// %bb.2:
	adrp	x15, .LCPI112_0
	adrp	x16, .LCPI112_1
	adrp	x0, .LCPI112_2
	adrp	x1, .LCPI112_9
	add	x18, x2, x2, lsl #3
	mov	w11, #112
	ldr	d0, [x15, :lo12:.LCPI112_0]
	adrp	x15, .LCPI112_3
	ldr	x9, [sp, #168]                  // 8-byte Folded Reload
	add	x14, x2, x2, lsl #1
	add	x17, x2, x2, lsl #2
	mul	x11, x2, x11
	str	d0, [sp, #408]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI112_1]
	adrp	x16, .LCPI112_4
	lsl	x8, x14, #5
	add	x9, x9, #8
	lsl	x10, x17, #4
	str	d0, [sp, #400]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI112_2]
	adrp	x0, .LCPI112_5
	lsl	x12, x2, #6
	lsl	x13, x2, #7
	lsl	x14, x14, #4
	str	d0, [sp, #392]                  // 8-byte Folded Spill
	ldr	d0, [x15, :lo12:.LCPI112_3]
	adrp	x15, .LCPI112_6
	lsl	x17, x17, #5
	ldp	d31, d29, [sp, #392]            // 16-byte Folded Reload
	str	d0, [sp, #384]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI112_4]
	adrp	x16, .LCPI112_7
	str	d0, [sp, #376]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI112_5]
	adrp	x0, .LCPI112_8
	str	d0, [sp, #368]                  // 8-byte Folded Spill
	ldr	d0, [x15, :lo12:.LCPI112_6]
	lsl	x15, x18, #4
	adrp	x18, .LCPI112_12
	str	d0, [sp, #480]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI112_7]
	adrp	x16, .LCPI112_10
	str	d0, [sp, #472]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI112_8]
	adrp	x0, .LCPI112_11
	str	d0, [sp, #336]                  // 8-byte Folded Spill
	ldr	d0, [x1, :lo12:.LCPI112_9]
	adrp	x1, .LCPI112_13
	str	d0, [sp, #360]                  // 8-byte Folded Spill
	ldr	d0, [x16, :lo12:.LCPI112_10]
	lsl	x16, x2, #5
	str	d0, [sp, #352]                  // 8-byte Folded Spill
	ldr	d0, [x0, :lo12:.LCPI112_11]
	ldr	x0, [sp, #176]                  // 8-byte Folded Reload
	str	d0, [sp, #344]                  // 8-byte Folded Spill
	ldr	d0, [x18, :lo12:.LCPI112_12]
	lsl	x18, x2, #4
	add	x0, x0, #88
	str	d0, [sp, #328]                  // 8-byte Folded Spill
	ldr	d0, [x1, :lo12:.LCPI112_13]
	str	d0, [sp, #320]                  // 8-byte Folded Spill
.LBB112_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d5, d18, [x0, #-72]
	add	x1, x9, x18
	add	x3, x9, x15
	ldp	d20, d19, [x0, #72]
	subs	x2, x2, #1
	ldp	d27, d25, [x0, #56]
	ldp	d24, d26, [x0, #-56]
	fadd	d9, d5, d20
	fadd	d3, d18, d19
	fsub	d8, d5, d20
	fsub	d0, d18, d19
	ldp	d5, d18, [x0, #40]
	fadd	d4, d24, d27
	fsub	d23, d24, d27
	ldp	d19, d30, [x0, #-40]
	fsub	d17, d26, d25
	str	d0, [sp, #584]                  // 8-byte Folded Spill
	fadd	d16, d26, d25
	ldr	d26, [sp, #408]                 // 8-byte Folded Reload
	ldp	d11, d12, [x0, #24]
	fadd	d22, d19, d5
	fsub	d25, d19, d5
	fadd	d2, d30, d18
	fsub	d20, d30, d18
	ldp	d0, d18, [x0, #-24]
	stp	d4, d17, [sp, #504]             // 16-byte Folded Spill
	fmul	d6, d3, d26
	ldr	d28, [sp, #368]                 // 8-byte Folded Reload
	fmov	d19, d16
	ldp	d1, d24, [x0, #-88]
	fadd	d5, d0, d11
	fsub	d11, d0, d11
	ldp	d13, d27, [sp, #472]            // 16-byte Folded Reload
	fmul	d17, d17, d28
	fmul	d21, d16, d29
	fmul	d0, d23, d28
	ldr	d16, [sp, #584]                 // 8-byte Folded Reload
	fmul	d14, d9, d26
	fadd	d6, d24, d6
	str	d8, [sp, #544]                  // 8-byte Folded Spill
	fmul	d7, d4, d29
	fmadd	d17, d16, d27, d17
	str	d23, [sp, #568]                 // 8-byte Folded Spill
	fmadd	d0, d8, d27, d0
	stp	d3, d1, [sp, #488]              // 16-byte Folded Spill
	ldp	d10, d15, [x0, #8]
	fadd	d14, d1, d14
	fadd	d4, d18, d12
	ldp	d1, d23, [x0, #-8]
	fadd	d6, d6, d21
	fmul	d21, d2, d31
	ldp	d8, d16, [sp, #376]             // 16-byte Folded Reload
	fsub	d18, d18, d12
	fmadd	d17, d20, d13, d17
	str	d25, [sp, #552]                 // 8-byte Folded Spill
	fmadd	d0, d25, d13, d0
	ldr	d25, [sp, #336]                 // 8-byte Folded Reload
	str	d20, [sp, #520]                 // 8-byte Folded Spill
	fadd	d7, d14, d7
	str	d4, [sp, #416]                  // 8-byte Folded Spill
	fmov	d3, d22
	fmul	d22, d22, d31
	fsub	d6, d6, d21
	fmul	d21, d4, d16
	fadd	d4, d23, d15
	fsub	d20, d23, d15
	fmadd	d17, d18, d25, d17
	ldr	d14, [sp, #360]                 // 8-byte Folded Reload
	fmov	d30, d5
	fsub	d7, d7, d22
	fmul	d22, d5, d16
	fadd	d12, d1, d10
	fsub	d15, d1, d10
	str	d20, [sp, #576]                 // 8-byte Folded Spill
	fsub	d6, d6, d21
	fmul	d21, d4, d8
	fmadd	d0, d11, d25, d0
	fmadd	d17, d20, d14, d17
	fsub	d7, d7, d22
	ldp	d5, d20, [sp, #488]             // 16-byte Folded Reload
	fmul	d22, d12, d8
	str	d18, [sp, #560]                 // 8-byte Folded Spill
	fsub	d6, d6, d21
	fmadd	d0, d15, d14, d0
	fmul	d18, d19, d16
	str	d4, [sp, #528]                  // 8-byte Folded Spill
	fmul	d21, d5, d29
	ldr	d4, [sp, #504]                  // 8-byte Folded Reload
	fsub	d7, d7, d22
	fmul	d22, d9, d29
	fadd	d1, d0, d6
	str	d11, [sp, #536]                 // 8-byte Folded Spill
	fmul	d10, d4, d16
	fmov	d11, d30
	fadd	d21, d24, d21
	stp	d3, d2, [sp, #456]              // 16-byte Folded Spill
	fsub	d23, d7, d17
	fadd	d22, d20, d22
	str	d1, [x1]
	fmov	d27, d2
	fsub	d0, d6, d0
	fmul	d6, d9, d31
	fsub	d1, d21, d18
	fmul	d18, d2, d8
	fmul	d21, d30, d31
	ldr	d30, [sp, #416]                 // 8-byte Folded Reload
	stur	d23, [x1, #-8]
	fsub	d22, d22, d10
	fmul	d23, d3, d8
	fadd	d7, d7, d17
	fsub	d1, d1, d18
	fmul	d2, d30, d31
	add	x1, x9, x17
	stp	d19, d0, [sp, #440]             // 16-byte Folded Spill
	ldr	d0, [sp, #512]                  // 8-byte Folded Reload
	fsub	d6, d20, d6
	fsub	d17, d22, d23
	fmul	d22, d4, d8
	fsub	d20, d1, d2
	ldr	d1, [sp, #568]                  // 8-byte Folded Reload
	stur	d7, [x1, #-8]
	fmul	d7, d0, d25
	stp	d24, d9, [sp, #424]             // 16-byte Folded Spill
	fmul	d23, d12, d26
	fmul	d2, d1, d25
	fsub	d17, d17, d21
	fmul	d21, d5, d31
	ldr	d5, [sp, #584]                  // 8-byte Folded Reload
	fsub	d6, d6, d22
	fmul	d22, d3, d29
	ldr	d3, [sp, #544]                  // 8-byte Folded Reload
	fmul	d10, d19, d8
	fmadd	d7, d5, d28, d7
	ldr	d18, [sp, #552]                 // 8-byte Folded Reload
	fsub	d21, d24, d21
	fadd	d17, d17, d23
	fmadd	d2, d3, d28, d2
	fadd	d6, d6, d22
	ldp	d9, d28, [sp, #344]             // 16-byte Folded Reload
	fmul	d22, d27, d29
	fmov	d27, d30
	fsub	d21, d21, d10
	ldr	d19, [sp, #528]                 // 8-byte Folded Reload
	add	x0, x0, #176
	fmul	d23, d1, d28
	fmul	d4, d0, d28
	ldr	d1, [sp, #520]                  // 8-byte Folded Reload
	fmadd	d2, d18, d28, d2
	ldr	d0, [sp, #536]                  // 8-byte Folded Reload
	fadd	d21, d21, d22
	fmul	d22, d30, d26
	fmul	d10, d19, d26
	fmadd	d23, d3, d13, d23
	fmadd	d7, d1, d28, d7
	ldp	d24, d30, [sp, #320]            // 16-byte Folded Reload
	fmadd	d4, d5, d13, d4
	fmul	d28, d11, d26
	ldr	d5, [sp, #560]                  // 8-byte Folded Reload
	fmadd	d2, d0, d9, d2
	ldr	d13, [sp, #480]                 // 8-byte Folded Reload
	fadd	d21, d21, d22
	fmadd	d23, d18, d24, d23
	fmul	d22, d12, d16
	fmadd	d7, d5, d9, d7
	fmadd	d3, d1, d24, d4
	fadd	d1, d20, d10
	fadd	d6, d6, d28
	ldr	d4, [sp, #576]                  // 8-byte Folded Reload
	fmadd	d2, d15, d30, d2
	fmadd	d23, d0, d13, d23
	ldr	d0, [sp, #448]                  // 8-byte Folded Reload
	fmadd	d3, d5, d13, d3
	fmul	d28, d19, d16
	fmadd	d7, d4, d30, d7
	fsub	d6, d6, d22
	fadd	d22, d2, d1
	str	d0, [x1]
	add	x1, x9, x16
	fmadd	d23, d15, d25, d23
	fmadd	d0, d4, d25, d3
	fsub	d21, d21, d28
	fsub	d10, d17, d7
	fadd	d7, d17, d7
	str	d22, [x1]
	fsub	d1, d1, d2
	ldp	d22, d28, [sp, #432]            // 16-byte Folded Reload
	fsub	d2, d6, d0
	fadd	d17, d23, d21
	stur	d10, [x1, #-8]
	add	x1, x9, x14
	ldp	d10, d3, [sp, #488]             // 16-byte Folded Reload
	stur	d7, [x3, #-8]
	fmul	d7, d22, d16
	ldr	d19, [sp, #504]                 // 8-byte Folded Reload
	str	d1, [x3]
	stur	d2, [x1, #-8]
	fadd	d0, d6, d0
	fmul	d1, d10, d16
	str	d17, [x1]
	fsub	d2, d3, d7
	fadd	d6, d3, d22
	fmov	d20, d3
	ldr	d3, [sp, #424]                  // 8-byte Folded Reload
	fmul	d7, d19, d31
	fsub	d17, d21, d23
	ldp	d4, d18, [sp, #456]             // 16-byte Folded Reload
	fsub	d1, d3, d1
	fmul	d21, d28, d31
	fmul	d22, d22, d8
	add	x1, x9, x13
	fsub	d2, d2, d7
	fmov	d23, d10
	fmul	d7, d4, d26
	fmov	d5, d3
	fsub	d1, d1, d21
	fmul	d21, d18, d26
	stur	d0, [x1, #-8]
	fadd	d0, d3, d10
	fsub	d20, d20, d22
	fmul	d22, d10, d8
	fadd	d2, d2, d7
	fmul	d7, d11, d8
	ldr	d10, [sp, #512]                 // 8-byte Folded Reload
	fadd	d6, d6, d19
	fmov	d3, d11
	fmul	d23, d19, d26
	fadd	d1, d1, d21
	fmov	d11, d27
	fmul	d21, d27, d8
	ldr	d27, [sp, #568]                 // 8-byte Folded Reload
	fsub	d2, d2, d7
	fmul	d7, d10, d9
	fadd	d0, d0, d28
	fsub	d19, d5, d22
	fmul	d22, d27, d9
	fmul	d28, d28, d26
	ldr	d26, [sp, #584]                 // 8-byte Folded Reload
	fadd	d6, d6, d4
	fadd	d20, d20, d23
	fmul	d4, d4, d16
	ldr	d5, [sp, #544]                  // 8-byte Folded Reload
	str	d17, [x1]
	fmadd	d7, d26, d25, d7
	fmul	d17, d10, d30
	fmul	d23, d12, d29
	fsub	d1, d1, d21
	fmadd	d21, d5, d25, d22
	fadd	d19, d19, d28
	ldr	d28, [sp, #520]                 // 8-byte Folded Reload
	fmul	d22, d27, d30
	fsub	d20, d20, d4
	ldr	d4, [sp, #528]                  // 8-byte Folded Reload
	ldr	d9, [sp, #552]                  // 8-byte Folded Reload
	fmadd	d17, d26, d14, d17
	fmadd	d7, d28, d13, d7
	fadd	d2, d2, d23
	fmul	d23, d4, d29
	fmul	d26, d18, d16
	fmadd	d21, d9, d13, d21
	fmadd	d22, d5, d14, d22
	ldr	d30, [sp, #560]                 // 8-byte Folded Reload
	fmul	d27, d3, d29
	ldr	d5, [sp, #536]                  // 8-byte Folded Reload
	fmadd	d17, d28, d25, d17
	fadd	d1, d1, d23
	fsub	d19, d19, d26
	fmadd	d7, d30, d14, d7
	fmul	d23, d11, d29
	fmadd	d21, d5, d14, d21
	fmadd	d22, d9, d25, d22
	ldr	d25, [sp, #576]                 // 8-byte Folded Reload
	fadd	d0, d0, d18
	fadd	d20, d20, d27
	fmul	d18, d12, d31
	fmadd	d17, d30, d24, d17
	fadd	d6, d6, d3
	fmadd	d7, d25, d24, d7
	fadd	d19, d19, d23
	fmadd	d21, d15, d24, d21
	fmul	d23, d4, d31
	fmadd	d22, d5, d24, d22
	ldr	d3, [sp, #472]                  // 8-byte Folded Reload
	add	x3, x9, x11
	add	x1, x9, x12
	fsub	d24, d2, d7
	fadd	d2, d2, d7
	fsub	d7, d20, d18
	fmadd	d17, d25, d3, d17
	fadd	d18, d21, d1
	fsub	d19, d19, d23
	fmadd	d5, d15, d3, d22
	fsub	d1, d1, d21
	fadd	d0, d0, d11
	stur	d2, [x3, #-8]
	fsub	d2, d7, d17
	stur	d24, [x1, #-8]
	str	d18, [x1]
	add	x1, x9, x10
	fadd	d18, d5, d19
	fadd	d6, d6, d12
	str	d1, [x3]
	fadd	d0, d0, d4
	stur	d2, [x1, #-8]
	fadd	d1, d7, d17
	fsub	d2, d19, d5
	fmov	d16, d11
	str	d18, [x1]
	add	x1, x9, x8
	stur	d6, [x9, #-8]
	str	d0, [x9], #16
	stur	d1, [x1, #-8]
	str	d2, [x1]
	b.ne	.LBB112_3
	b	.LBB112_10
.LBB112_4:
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	cbz	x2, .LBB112_10
// %bb.5:
	lsl	x9, x2, #2
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	add	x14, x9, x2
	mul	x3, x2, x1
	mov	w12, #112
	mov	w10, #176
	str	x9, [sp, #160]                  // 8-byte Folded Spill
	add	x13, x27, x27, lsl #1
	ldp	x9, x25, [sp, #168]             // 16-byte Folded Reload
	lsl	x24, x13, #4
	lsl	x13, x13, #5
	mul	x22, x27, x12
	mov	w8, #96
	mul	x10, x1, x10
	lsl	x4, x27, #7
	madd	x29, x3, x12, x9
	add	x12, x5, x13
	madd	x30, x3, x8, x9
	lsl	x8, x27, #5
	add	x18, x4, x25
	add	x19, x13, x25
	stp	x12, x10, [sp, #136]            // 16-byte Folded Spill
	add	x12, x5, x24
	add	x10, x8, x25
	add	x8, x5, x8
	adrp	x13, .LCPI112_1
	str	x12, [sp, #128]                 // 8-byte Folded Spill
	add	x12, x5, x22
	add	x10, x10, #32
	str	x14, [sp, #152]                 // 8-byte Folded Spill
	ldr	d11, [x13, :lo12:.LCPI112_1]
	adrp	x13, .LCPI112_4
	stp	x8, x12, [sp, #112]             // 16-byte Folded Spill
	adrp	x8, .LCPI112_0
	add	x12, x5, x4
	adrp	x4, .LCPI112_2
	stp	x10, x1, [sp, #192]             // 16-byte Folded Spill
	add	x10, x27, x27, lsl #3
	ldr	d0, [x8, :lo12:.LCPI112_0]
	adrp	x8, .LCPI112_3
	lsl	x10, x10, #4
	str	x12, [sp, #104]                 // 8-byte Folded Spill
	add	x16, x10, x25
	add	x10, x5, x10
	str	d0, [sp, #568]                  // 8-byte Folded Spill
	ldr	d0, [x4, :lo12:.LCPI112_2]
	adrp	x4, .LCPI112_5
	adrp	x12, .LCPI112_13
	str	x10, [sp, #96]                  // 8-byte Folded Spill
	lsl	x10, x14, #1
	str	d0, [sp, #552]                  // 8-byte Folded Spill
	ldr	d0, [x8, :lo12:.LCPI112_3]
	adrp	x8, .LCPI112_6
	mov	w11, #160
	str	x10, [sp, #88]                  // 8-byte Folded Spill
	lsl	x10, x2, #1
	str	d0, [sp, #584]                  // 8-byte Folded Spill
	ldr	d0, [x13, :lo12:.LCPI112_4]
	adrp	x13, .LCPI112_7
	madd	x15, x1, x11, x25
	add	x1, x18, #128
	ldr	x18, [sp, #200]                 // 8-byte Folded Reload
	str	d0, [sp, #576]                  // 8-byte Folded Spill
	ldr	d0, [x4, :lo12:.LCPI112_5]
	adrp	x4, .LCPI112_8
	str	x10, [sp, #80]                  // 8-byte Folded Spill
	add	x10, x10, x2
	add	x7, x27, x27, lsl #2
	str	d0, [sp, #360]                  // 8-byte Folded Spill
	ldr	d0, [x8, :lo12:.LCPI112_6]
	adrp	x8, .LCPI112_9
	lsl	x21, x27, #6
	lsl	x23, x7, #4
	add	x0, x21, x25
	str	d0, [sp, #560]                  // 8-byte Folded Spill
	ldr	d0, [x13, :lo12:.LCPI112_7]
	adrp	x13, .LCPI112_10
	add	x7, x23, x25
	mov	w20, #80
	add	x23, x5, x23
	str	d0, [sp, #544]                  // 8-byte Folded Spill
	ldr	d0, [x4, :lo12:.LCPI112_8]
	ldr	d5, [x13, :lo12:.LCPI112_10]
	adrp	x4, .LCPI112_11
	adrp	x13, .LCPI112_12
	add	x21, x5, x21
	ldr	d1, [x8, :lo12:.LCPI112_9]
	mov	w8, #48
	str	d5, [sp, #240]                  // 8-byte Folded Spill
	ldr	d5, [x12, :lo12:.LCPI112_13]
	lsl	x12, x2, #3
	ldr	d4, [x4, :lo12:.LCPI112_11]
	add	x14, x12, x2
	mov	w4, #144
	add	x17, x24, x25
	add	x6, x22, x25
	madd	x20, x3, x20, x9
	str	d4, [sp, #496]                  // 8-byte Folded Spill
	stp	x14, x12, [sp, #64]             // 16-byte Folded Spill
	sub	x12, x12, x2
	madd	x8, x3, x8, x9
	ldr	d4, [x13, :lo12:.LCPI112_12]
	madd	x13, x3, x11, x9
	mov	x26, xzr
	stp	x12, x10, [sp, #48]             // 16-byte Folded Spill
	lsl	x12, x18, #4
	lsl	x10, x10, #1
	madd	x11, x3, x4, x9
	add	x16, x16, #144
	add	x17, x17, #48
	add	x0, x0, #64
	add	x6, x6, #112
	add	x7, x7, #80
	add	x19, x19, #96
	stp	x21, x23, [sp, #208]            // 16-byte Folded Spill
	add	x24, x9, x3, lsl #6
	add	x23, x9, x3, lsl #7
	add	x21, x9, x3, lsl #4
	add	x3, x9, x3, lsl #5
	stp	x10, x12, [sp, #32]             // 16-byte Folded Spill
	add	x4, x25, x12
	add	x10, x5, x27, lsl #4
	mov	x12, x9
	mov	x22, x25
	stp	d4, d11, [sp, #368]             // 16-byte Folded Spill
	stp	d0, d5, [sp, #224]              // 16-byte Folded Spill
	str	x10, [sp, #24]                  // 8-byte Folded Spill
	str	d1, [sp, #280]                  // 8-byte Folded Spill
	b	.LBB112_7
.LBB112_6:                              //   in Loop: Header=BB112_7 Depth=1
	ldr	x9, [sp, #144]                  // 8-byte Folded Reload
	ldp	x18, x11, [sp, #248]            // 16-byte Folded Reload
	add	x14, x14, x9
	add	x22, x22, x9
	add	x4, x4, x9
	add	x15, x15, x9
	add	x16, x16, x9
	add	x17, x17, x9
	str	x14, [sp, #192]                 // 8-byte Folded Spill
	add	x1, x1, x9
	add	x0, x0, x9
	add	x6, x6, x9
	add	x7, x7, x9
	add	x19, x19, x9
	ldp	x14, x9, [sp, #264]             // 16-byte Folded Reload
	ldr	x8, [sp, #184]                  // 8-byte Folded Reload
	ldr	x10, [sp, #40]                  // 8-byte Folded Reload
	add	x8, x8, #1
	add	x11, x11, x10
	add	x14, x14, x10
	add	x3, x3, x10
	add	x30, x30, x10
	add	x12, x12, x10
	add	x20, x20, x10
	add	x29, x29, x10
	add	x24, x9, x10
	add	x23, x18, x10
	add	x21, x21, x10
	add	x13, x13, x10
	mov	x26, x8
	cmp	x8, x2
	ldr	x18, [sp, #200]                 // 8-byte Folded Reload
	mov	x8, x11
	mov	x11, x3
	mov	x3, x14
	b.eq	.LBB112_10
.LBB112_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB112_9 Depth 2
	mov	w9, #11
	stp	x3, x24, [sp, #264]             // 16-byte Folded Spill
	stp	x23, x8, [sp, #248]             // 16-byte Folded Spill
	mov	x23, x20
	mul	x24, x26, x9
	mov	x20, x19
	mov	x19, x7
	mov	x7, x6
	mov	x6, x0
	mov	x0, x1
	ldr	x1, [sp, #200]                  // 8-byte Folded Reload
	add	x25, x24, #10
	mul	x27, x24, x18
	ldr	x9, [sp, #176]                  // 8-byte Folded Reload
	ldr	x10, [sp, #200]                 // 8-byte Folded Reload
	mov	x18, x17
	mul	x25, x25, x1
	ldr	x1, [sp, #200]                  // 8-byte Folded Reload
	mov	x17, x16
	mov	x16, x15
	mov	x15, x30
	add	x30, x24, #2
	add	x28, x9, x27, lsl #4
	add	x27, x10, x27
	mov	x8, x29
	mul	x30, x30, x1
	ldr	x1, [sp, #200]                  // 8-byte Folded Reload
	add	x10, x24, #9
	add	x27, x9, x27, lsl #4
	ldr	x8, [sp, #200]                  // 8-byte Folded Reload
	ldp	d28, d25, [x28]
	add	x28, x24, #3
	add	x25, x9, x25, lsl #4
	mul	x10, x10, x1
	ldr	d22, [sp, #568]                 // 8-byte Folded Reload
	ldp	d6, d7, [x27]
	add	x27, x9, x30, lsl #4
	mul	x28, x28, x8
	ldp	d18, d19, [x25]
	add	x25, x24, #8
	add	x10, x9, x10, lsl #4
	ldp	d20, d26, [x27]
	add	x27, x9, x28, lsl #4
	mul	x25, x25, x8
	add	x28, x24, #4
	fadd	d0, d6, d18
	ldp	d27, d30, [x10]
	mul	x10, x28, x8
	add	x25, x9, x25, lsl #4
	fadd	d23, d7, d19
	fsub	d1, d6, d18
	fsub	d3, d7, d19
	fadd	d18, d28, d0
	add	x10, x9, x10, lsl #4
	fadd	d16, d20, d27
	ldp	d6, d7, [x25]
	add	x25, x24, #7
	fsub	d12, d20, d27
	ldp	d19, d13, [x10]
	mul	x10, x25, x8
	add	x25, x24, #6
	add	x24, x24, #5
	fadd	d20, d18, d16
	ldp	d10, d11, [x27]
	mul	x25, x25, x8
	add	x10, x9, x10, lsl #4
	mul	x24, x24, x8
	fadd	d29, d26, d30
	fmov	d9, d0
	fsub	d17, d26, d30
	fadd	d2, d10, d6
	add	x25, x9, x25, lsl #4
	add	x24, x9, x24, lsl #4
	fsub	d21, d10, d6
	ldp	d27, d6, [x10]
	fadd	d0, d11, d7
	fsub	d26, d11, d7
	ldp	d10, d5, [x25]
	fadd	d20, d20, d2
	stp	d12, d1, [sp, #456]             // 16-byte Folded Spill
	ldp	d14, d7, [x24]
	fadd	d18, d19, d27
	fsub	d24, d19, d27
	fadd	d30, d13, d6
	fsub	d13, d13, d6
	fmul	d6, d9, d22
	fmov	d27, d9
	fadd	d1, d14, d10
	stp	d0, d16, [sp, #424]             // 16-byte Folded Spill
	fadd	d19, d20, d18
	fsub	d4, d7, d5
	fmov	d8, d18
	str	d18, [sp, #520]                 // 8-byte Folded Spill
	fadd	d20, d25, d23
	fmul	d18, d23, d22
	fmov	d9, d1
	fadd	d11, d7, d5
	str	d4, [sp, #472]                  // 8-byte Folded Spill
	fadd	d4, d19, d1
	ldr	d1, [sp, #376]                  // 8-byte Folded Reload
	fmov	d31, d2
	fadd	d7, d20, d29
	fadd	d18, d25, d18
	ldr	d15, [sp, #552]                 // 8-byte Folded Reload
	fadd	d22, d28, d6
	fmul	d19, d16, d1
	fmul	d20, d29, d1
	ldr	d16, [sp, #360]                 // 8-byte Folded Reload
	fadd	d7, d7, d0
	mul	x10, x26, x8
	ldr	x9, [sp, #168]                  // 8-byte Folded Reload
	str	d2, [sp, #536]                  // 8-byte Folded Spill
	fmul	d5, d17, d16
	fadd	d18, d18, d20
	fmul	d20, d0, d15
	ldr	d0, [sp, #560]                  // 8-byte Folded Reload
	fmul	d6, d12, d16
	fadd	d19, d22, d19
	fmul	d22, d31, d15
	fmov	d2, d23
	fsub	d23, d14, d10
	ldr	d14, [sp, #464]                 // 8-byte Folded Reload
	fmov	d31, d3
	str	d3, [sp, #384]                  // 8-byte Folded Spill
	fmadd	d5, d3, d0, d5
	ldr	d3, [sp, #584]                  // 8-byte Folded Reload
	add	x10, x9, x10, lsl #4
	fmadd	d6, d14, d0, d6
	fadd	d7, d7, d30
	fsub	d19, d19, d22
	fmul	d22, d8, d3
	ldr	d0, [sp, #544]                  // 8-byte Folded Reload
	str	d4, [x10]
	ldr	d4, [sp, #576]                  // 8-byte Folded Reload
	fsub	d18, d18, d20
	fmul	d20, d30, d3
	fmadd	d5, d26, d0, d5
	stp	d21, d24, [sp, #480]            // 16-byte Folded Spill
	fmadd	d6, d21, d0, d6
	fadd	d7, d7, d11
	fsub	d19, d19, d22
	fmul	d22, d9, d4
	ldr	d21, [sp, #224]                 // 8-byte Folded Reload
	fsub	d18, d18, d20
	fmul	d20, d11, d4
	fmov	d12, d26
	str	d26, [sp, #512]                 // 8-byte Folded Spill
	ldr	d8, [sp, #472]                  // 8-byte Folded Reload
	fmadd	d5, d13, d21, d5
	str	d7, [x10, #8]
	fsub	d26, d19, d22
	fmul	d19, d27, d1
	ldr	d7, [sp, #280]                  // 8-byte Folded Reload
	str	d25, [sp, #392]                 // 8-byte Folded Spill
	ldr	d0, [sp, #376]                  // 8-byte Folded Reload
	str	d29, [sp, #528]                 // 8-byte Folded Spill
	fmov	d25, d1
	fmadd	d6, d24, d21, d6
	fsub	d24, d18, d20
	add	x10, x26, x2
	fmadd	d18, d8, d7, d5
	fmul	d20, d2, d0
	str	d28, [sp, #352]                 // 8-byte Folded Spill
	fadd	d25, d28, d19
	ldr	d1, [sp, #392]                  // 8-byte Folded Reload
	mul	x10, x10, x8
	ldr	d28, [sp, #528]                 // 8-byte Folded Reload
	fmadd	d22, d23, d7, d6
	ldr	d29, [sp, #432]                 // 8-byte Folded Reload
	fsub	d7, d26, d18
	fadd	d20, d1, d20
	str	d23, [sp, #504]                 // 8-byte Folded Spill
	fmul	d5, d28, d3
	fmov	d10, d30
	stp	d30, d13, [sp, #440]            // 16-byte Folded Spill
	fmov	d30, d21
	fmul	d19, d29, d3
	fmul	d23, d17, d21
	add	x10, x9, x10, lsl #4
	ldr	d21, [sp, #424]                 // 8-byte Folded Reload
	ldr	d0, [sp, #536]                  // 8-byte Folded Reload
	fsub	d5, d20, d5
	mov	x14, x26
	fadd	d6, d22, d24
	str	d7, [x10]
	fmul	d7, d21, d4
	fsub	d19, d25, d19
	fmul	d25, d0, d4
	ldr	d0, [sp, #520]                  // 8-byte Folded Reload
	fmadd	d23, d31, d16, d23
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	stp	d11, d17, [sp, #400]            // 16-byte Folded Spill
	fmov	d17, d16
	ldr	d16, [sp, #240]                 // 8-byte Folded Reload
	fmul	d20, d0, d15
	fsub	d5, d5, d7
	fmul	d7, d10, d15
	ldp	d31, d10, [sp, #448]            // 16-byte Folded Reload
	add	x24, x26, x14
	fsub	d19, d19, d25
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	str	d6, [x10, #8]
	fmadd	d6, d12, d16, d23
	mul	x24, x24, x8
	fadd	d18, d26, d18
	fmul	d23, d9, d0
	ldr	d0, [sp, #496]                  // 8-byte Folded Reload
	fsub	d19, d19, d20
	fmul	d20, d10, d30
	fmov	d11, d27
	add	x10, x9, x24, lsl #4
	fmov	d27, d30
	fmov	d30, d3
	fmadd	d6, d31, d0, d6
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	ldr	d3, [sp, #400]                  // 8-byte Folded Reload
	fsub	d22, d24, d22
	str	d18, [x10]
	fsub	d5, d5, d7
	fmadd	d18, d14, d17, d20
	ldr	d17, [sp, #480]                 // 8-byte Folded Reload
	fmul	d7, d3, d0
	ldr	d0, [sp, #368]                  // 8-byte Folded Reload
	fadd	d19, d19, d23
	fmul	d23, d29, d4
	fmul	d24, d28, d4
	fmul	d20, d11, d15
	fmadd	d6, d8, d0, d6
	str	d22, [x10, #8]
	ldp	d4, d0, [sp, #488]              // 16-byte Folded Reload
	fmul	d22, d2, d15
	fadd	d5, d5, d7
	fmadd	d7, d17, d16, d18
	ldr	d26, [sp, #352]                 // 8-byte Folded Reload
	fmov	d29, d1
	fmov	d13, d15
	ldr	x14, [sp, #80]                  // 8-byte Folded Reload
	fmov	d12, d11
	fsub	d20, d26, d20
	fsub	d22, d1, d22
	fmadd	d7, d4, d0, d7
	ldr	d15, [sp, #536]                 // 8-byte Folded Reload
	ldp	d0, d1, [sp, #376]              // 16-byte Folded Reload
	add	x24, x26, x14
	fsub	d18, d19, d6
	fsub	d20, d20, d23
	fsub	d22, d22, d24
	mul	x24, x24, x8
	ldr	d28, [sp, #504]                 // 8-byte Folded Reload
	fmul	d23, d15, d0
	ldr	d0, [sp, #376]                  // 8-byte Folded Reload
	ldr	d11, [sp, #408]                 // 8-byte Folded Reload
	str	d9, [sp, #416]                  // 8-byte Folded Spill
	add	x10, x9, x24, lsl #4
	ldr	d9, [sp, #520]                  // 8-byte Folded Reload
	fmul	d24, d21, d0
	ldr	d0, [sp, #368]                  // 8-byte Folded Reload
	fmul	d25, d11, d16
	fadd	d20, d20, d23
	str	d18, [x10]
	fmul	d18, d10, d16
	fmadd	d7, d28, d0, d7
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	ldr	d16, [sp, #544]                 // 8-byte Folded Reload
	fadd	d22, d22, d24
	ldr	d21, [sp, #440]                 // 8-byte Folded Reload
	fadd	d6, d19, d6
	fmul	d23, d9, d0
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	fmadd	d25, d1, d16, d25
	ldr	x14, [sp, #64]                  // 8-byte Folded Reload
	fmadd	d18, d14, d16, d18
	ldr	d16, [sp, #232]                 // 8-byte Folded Reload
	fmul	d24, d21, d0
	ldr	d0, [sp, #512]                  // 8-byte Folded Reload
	add	x24, x26, x14
	fadd	d19, d7, d5
	fadd	d20, d20, d23
	fsub	d5, d5, d7
	fmadd	d25, d0, d16, d25
	fmadd	d18, d17, d16, d18
	ldr	d17, [sp, #416]                 // 8-byte Folded Reload
	mul	x24, x24, x8
	ldr	d0, [sp, #560]                  // 8-byte Folded Reload
	fadd	d22, d22, d24
	str	d19, [x10, #8]
	ldr	x10, [sp, #56]                  // 8-byte Folded Reload
	fmul	d23, d17, d30
	add	x24, x9, x24, lsl #4
	fmadd	d24, d31, d0, d25
	fmul	d25, d3, d30
	fmadd	d18, d4, d0, d18
	add	x10, x26, x10
	str	d6, [x24]
	ldr	d0, [sp, #528]                  // 8-byte Folded Reload
	fsub	d6, d20, d23
	mul	x10, x10, x8
	fmadd	d7, d8, d27, d24
	fsub	d19, d22, d25
	fmadd	d18, d28, d27, d18
	fmul	d25, d0, d13
	add	x10, x9, x10, lsl #4
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	fmul	d20, d12, d30
	ldr	d8, [sp, #432]                  // 8-byte Folded Reload
	fsub	d22, d6, d7
	str	d5, [x24, #8]
	fadd	d23, d18, d19
	fmul	d5, d2, d30
	fmul	d24, d8, d13
	ldr	x14, [sp, #72]                  // 8-byte Folded Reload
	fsub	d20, d26, d20
	fmov	d31, d12
	str	d22, [x10]
	fmul	d22, d15, d0
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	str	d23, [x10, #8]
	ldr	d15, [sp, #424]                 // 8-byte Folded Reload
	fsub	d5, d29, d5
	fadd	d6, d6, d7
	fmov	d12, d11
	add	x24, x26, x14
	fsub	d20, d20, d24
	fmul	d23, d15, d0
	ldr	d0, [sp, #496]                  // 8-byte Folded Reload
	ldr	d14, [sp, #576]                 // 8-byte Folded Reload
	mul	x24, x24, x8
	fmov	d10, d26
	fsub	d5, d5, d25
	fmul	d7, d11, d0
	ldr	d0, [sp, #496]                  // 8-byte Folded Reload
	ldp	d28, d11, [sp, #456]            // 16-byte Folded Reload
	fadd	d20, d20, d22
	fmul	d22, d9, d14
	add	x10, x9, x24, lsl #4
	fadd	d5, d5, d23
	fmul	d23, d21, d14
	fmul	d25, d31, d14
	fmul	d24, d28, d0
	fmadd	d7, d1, d27, d7
	ldp	d26, d0, [sp, #368]             // 16-byte Folded Reload
	str	d6, [x10]
	fsub	d6, d20, d22
	fsub	d18, d19, d18
	fmov	d21, d1
	fmadd	d19, d11, d27, d24
	fsub	d5, d5, d23
	ldr	d1, [sp, #512]                  // 8-byte Folded Reload
	fsub	d22, d10, d25
	fmul	d20, d17, d0
	ldr	d0, [sp, #376]                  // 8-byte Folded Reload
	ldr	d4, [sp, #560]                  // 8-byte Folded Reload
	fmov	d10, d3
	fmov	d31, d17
	ldr	d17, [sp, #448]                 // 8-byte Folded Reload
	fmul	d23, d3, d0
	ldr	d3, [sp, #480]                  // 8-byte Folded Reload
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	fmadd	d7, d1, d4, d7
	fmul	d24, d2, d14
	str	d18, [x10, #8]
	fmadd	d19, d3, d4, d19
	ldr	d4, [sp, #488]                  // 8-byte Folded Reload
	fmul	d25, d8, d0
	ldr	d0, [sp, #280]                  // 8-byte Folded Reload
	fadd	d6, d6, d20
	fadd	d5, d5, d23
	fmul	d23, d12, d26
	ldr	d8, [sp, #472]                  // 8-byte Folded Reload
	fmadd	d7, d17, d0, d7
	fmadd	d18, d4, d0, d19
	fmov	d2, d0
	fadd	d20, d22, d25
	ldr	d0, [sp, #568]                  // 8-byte Folded Reload
	fsub	d19, d29, d24
	ldr	d22, [sp, #528]                 // 8-byte Folded Reload
	fmul	d24, d28, d26
	ldp	x14, x10, [sp, #152]            // 16-byte Folded Reload
	fmadd	d7, d8, d16, d7
	ldr	d12, [sp, #504]                 // 8-byte Folded Reload
	fmul	d26, d15, d30
	fmul	d22, d22, d0
	ldr	d0, [sp, #536]                  // 8-byte Folded Reload
	add	x10, x26, x10
	fmadd	d24, d11, d2, d24
	fmadd	d18, d12, d16, d18
	mul	x10, x10, x8
	fmul	d25, d0, d30
	fadd	d19, d19, d22
	fmadd	d22, d21, d2, d23
	ldr	d0, [sp, #376]                  // 8-byte Folded Reload
	fsub	d23, d6, d7
	fadd	d29, d18, d5
	add	x10, x9, x10, lsl #4
	fsub	d20, d20, d25
	add	x24, x26, x14
	fmadd	d22, d1, d27, d22
	fmul	d28, d9, d0
	ldr	d0, [sp, #376]                  // 8-byte Folded Reload
	str	d23, [x10]
	ldr	d1, [sp, #440]                  // 8-byte Folded Reload
	fsub	d19, d19, d26
	fmadd	d23, d3, d27, d24
	str	d29, [x10, #8]
	ldr	x10, [sp, #48]                  // 8-byte Folded Reload
	fadd	d20, d20, d28
	fmul	d24, d1, d0
	ldr	x14, [sp, #32]                  // 8-byte Folded Reload
	fmadd	d22, d17, d16, d22
	fmul	d0, d31, d13
	add	x10, x26, x10
	fmadd	d23, d4, d16, d23
	ldr	d9, [sp, #544]                  // 8-byte Folded Reload
	add	x25, x26, x14
	fadd	d19, d19, d24
	fmul	d24, d10, d13
	mul	x10, x10, x8
	fadd	d6, d6, d7
	fsub	d5, d5, d18
	fsub	d7, d20, d0
	fmadd	d18, d8, d9, d22
	fmadd	d20, d12, d9, d23
	add	x10, x9, x10, lsl #4
	fsub	d19, d19, d24
	mul	x24, x24, x8
	mov	x30, x15
	mul	x25, x25, x8
	mov	x15, x16
	mov	x16, x17
	mov	x17, x18
	mov	x18, x26
	mov	x1, x0
	mov	x0, x6
	mov	x6, x7
	mov	x7, x19
	mov	x19, x20
	mov	x20, x23
	str	x26, [sp, #184]                 // 8-byte Folded Spill
	str	d6, [x10]
	add	x24, x9, x24, lsl #4
	str	d5, [x10, #8]
	add	x10, x9, x25, lsl #4
	cmp	x8, #2
	fsub	d6, d7, d18
	ldp	x9, x8, [sp, #128]              // 16-byte Folded Reload
	fadd	d22, d20, d19
	fadd	d5, d7, d18
	ldp	x26, x23, [sp, #112]            // 16-byte Folded Reload
	fsub	d7, d19, d20
	mov	x3, x11
	ldp	x28, x18, [sp, #96]             // 16-byte Folded Reload
	str	d6, [x24]
	ldr	d11, [sp, #376]                 // 8-byte Folded Reload
	str	d22, [x24, #8]
	ldr	x14, [sp, #192]                 // 8-byte Folded Reload
	str	d5, [x10]
	ldr	d23, [sp, #360]                 // 8-byte Folded Reload
	str	d7, [x10, #8]
	ldr	d4, [sp, #560]                  // 8-byte Folded Reload
	ldr	x11, [sp, #24]                  // 8-byte Folded Reload
	b.lo	.LBB112_6
// %bb.8:                               //   in Loop: Header=BB112_7 Depth=1
	fmov	d28, d13
	fmov	d31, d30
	fmov	d26, d14
	mov	x24, xzr
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
.LBB112_9:                              //   Parent Loop BB112_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x10, x4, x24
	add	x27, x15, x24
	fmov	d30, d11
	subs	x25, x25, #1
	ldp	d5, d6, [x10, #16]
	add	x10, x14, x24
	ldp	d7, d18, [x27, #16]
	add	x27, x16, x24
	ldp	d19, d20, [x10, #16]
	add	x10, x22, x24
	fadd	d3, d5, d7
	fsub	d24, d5, d7
	ldp	d27, d5, [x27, #16]
	fadd	d17, d6, d18
	add	x27, x1, x24
	ldp	d22, d2, [x10, #16]
	add	x10, x17, x24
	fsub	d0, d6, d18
	fadd	d10, d19, d27
	str	d3, [sp, #504]                  // 8-byte Folded Spill
	fadd	d1, d20, d5
	fsub	d16, d20, d5
	ldr	d20, [sp, #568]                 // 8-byte Folded Reload
	str	d17, [sp, #392]                 // 8-byte Folded Spill
	ldp	d7, d18, [x10, #16]
	str	d0, [sp, #408]                  // 8-byte Folded Spill
	fsub	d0, d19, d27
	ldp	d6, d5, [x27, #16]
	add	x10, x0, x24
	add	x27, x6, x24
	fmul	d19, d17, d20
	fmov	d21, d20
	fmul	d11, d1, d11
	stp	d1, d2, [sp, #456]              // 16-byte Folded Spill
	fadd	d29, d7, d6
	fsub	d25, d7, d6
	ldp	d20, d13, [x10, #16]
	fadd	d27, d18, d5
	add	x10, x7, x24
	ldp	d15, d6, [x27, #16]
	add	x27, x19, x24
	fadd	d7, d2, d19
	str	d0, [sp, #424]                  // 8-byte Folded Spill
	fmul	d12, d0, d23
	ldp	d17, d8, [x10, #16]
	fmul	d2, d3, d21
	fmov	d21, d3
	ldp	d0, d1, [x27, #16]
	fadd	d19, d13, d6
	fadd	d7, d7, d11
	fmul	d3, d27, d28
	fsub	d14, d18, d5
	fmadd	d5, d24, d4, d12
	fsub	d18, d20, d15
	str	d8, [sp, #448]                  // 8-byte Folded Spill
	fadd	d2, d22, d2
	fadd	d11, d8, d1
	fmov	d8, d16
	fsub	d3, d7, d3
	fmul	d7, d19, d31
	fmadd	d5, d25, d9, d5
	str	d16, [sp, #472]                 // 8-byte Folded Spill
	fmul	d16, d16, d23
	fadd	d23, d20, d15
	fmov	d15, d26
	fsub	d9, d17, d0
	fsub	d12, d3, d7
	fmul	d7, d11, d26
	ldr	d26, [sp, #224]                 // 8-byte Folded Reload
	str	d11, [sp, #528]                 // 8-byte Folded Spill
	ldr	d20, [sp, #408]                 // 8-byte Folded Reload
	fmul	d4, d10, d30
	ldr	d11, [sp, #280]                 // 8-byte Folded Reload
	str	d18, [sp, #536]                 // 8-byte Folded Spill
	fmadd	d3, d18, d26, d5
	ldr	d5, [sp, #560]                  // 8-byte Folded Reload
	str	d19, [sp, #520]                 // 8-byte Folded Spill
	ldr	d31, [sp, #392]                 // 8-byte Folded Reload
	fadd	d2, d2, d4
	fmul	d4, d29, d28
	fmadd	d16, d20, d5, d16
	fsub	d5, d13, d6
	fmadd	d18, d9, d11, d3
	ldr	d3, [sp, #544]                  // 8-byte Folded Reload
	fsub	d19, d12, d7
	str	d27, [sp, #304]                 // 8-byte Folded Spill
	fmov	d27, d10
	str	d10, [sp, #440]                 // 8-byte Folded Spill
	fmadd	d6, d14, d3, d16
	fadd	d10, d17, d0
	ldp	d3, d7, [sp, #448]              // 16-byte Folded Reload
	fsub	d0, d2, d4
	fmul	d2, d31, d30
	ldr	d4, [sp, #584]                  // 8-byte Folded Reload
	fadd	d16, d18, d19
	str	d10, [sp, #512]                 // 8-byte Folded Spill
	fmadd	d6, d5, d26, d6
	fsub	d17, d3, d1
	ldr	d3, [sp, #464]                  // 8-byte Folded Reload
	fmul	d4, d23, d4
	fmul	d1, d21, d30
	add	x10, x5, x24
	str	d5, [sp, #416]                  // 8-byte Folded Spill
	fadd	d2, d3, d2
	ldr	d3, [sp, #584]                  // 8-byte Folded Reload
	str	d22, [sp, #400]                 // 8-byte Folded Spill
	fmov	d12, d31
	fadd	d1, d22, d1
	str	d17, [sp, #448]                 // 8-byte Folded Spill
	fmul	d7, d7, d3
	fsub	d3, d0, d4
	fmul	d4, d10, d15
	ldr	d0, [sp, #584]                  // 8-byte Folded Reload
	ldr	d10, [sp, #304]                 // 8-byte Folded Reload
	fmadd	d22, d17, d11, d6
	str	d14, [sp, #384]                 // 8-byte Folded Spill
	ldr	d14, [sp, #424]                 // 8-byte Folded Reload
	fmul	d21, d27, d0
	fsub	d2, d2, d7
	fmul	d0, d10, d15
	fsub	d27, d3, d4
	fneg	d6, d16
	fmul	d7, d14, d26
	str	d9, [sp, #296]                  // 8-byte Folded Spill
	ldr	d9, [sp, #360]                  // 8-byte Folded Reload
	fsub	d17, d1, d21
	fmov	d15, d26
	fsub	d5, d2, d0
	ldr	d0, [sp, #576]                  // 8-byte Folded Reload
	ldp	d2, d21, [x10]
	fmadd	d7, d24, d9, d7
	str	d23, [sp, #432]                 // 8-byte Folded Spill
	fmul	d3, d29, d0
	ldr	d0, [sp, #520]                  // 8-byte Folded Reload
	ldr	d26, [sp, #240]                 // 8-byte Folded Reload
	fmul	d1, d8, d15
	fmul	d16, d2, d16
	ldr	d8, [sp, #296]                  // 8-byte Folded Reload
	fmul	d4, d0, d28
	fmul	d6, d21, d6
	fsub	d0, d27, d22
	fmadd	d7, d25, d26, d7
	fsub	d3, d17, d3
	ldr	d17, [sp, #528]                 // 8-byte Folded Reload
	str	d29, [sp, #328]                 // 8-byte Folded Spill
	add	x10, x28, x24
	fsub	d4, d5, d4
	fmul	d5, d23, d28
	fmadd	d2, d0, d2, d6
	fmadd	d0, d0, d21, d16
	ldr	d6, [sp, #536]                  // 8-byte Folded Reload
	fmul	d16, d31, d28
	ldr	d23, [sp, #568]                 // 8-byte Folded Reload
	stp	d24, d25, [sp, #480]            // 16-byte Folded Spill
	fsub	d3, d3, d5
	fsub	d24, d19, d18
	stp	d0, d2, [sp, #344]              // 16-byte Folded Spill
	ldr	d2, [sp, #496]                  // 8-byte Folded Reload
	fmadd	d0, d20, d9, d1
	ldr	d1, [sp, #384]                  // 8-byte Folded Reload
	fmul	d17, d17, d23
	fmadd	d2, d6, d2, d7
	ldr	d7, [sp, #368]                  // 8-byte Folded Reload
	ldp	d31, d29, [sp, #456]            // 16-byte Folded Reload
	fmadd	d0, d1, d26, d0
	fneg	d19, d24
	ldr	d1, [sp, #568]                  // 8-byte Folded Reload
	fadd	d9, d4, d17
	fmadd	d28, d8, d7, d2
	ldr	d2, [sp, #512]                  // 8-byte Folded Reload
	ldr	d25, [sp, #416]                 // 8-byte Folded Reload
	fadd	d18, d27, d22
	fsub	d16, d29, d16
	ldr	d20, [x10, #8]
	fmul	d5, d2, d1
	ldr	d1, [sp, #576]                  // 8-byte Folded Reload
	fmul	d22, d10, d30
	ldr	d30, [sp, #448]                 // 8-byte Folded Reload
	fadd	d21, d28, d9
	add	x27, x11, x24
	fmul	d17, d31, d1
	ldr	d13, [sp, #232]                 // 8-byte Folded Reload
	fadd	d23, d3, d5
	ldp	d1, d5, [sp, #496]              // 16-byte Folded Reload
	fsub	d4, d16, d17
	fmul	d16, d20, d19
	ldr	d17, [x10]
	fneg	d19, d21
	fmadd	d0, d25, d1, d0
	add	x10, x18, x24
	ldp	d1, d2, [x27]
	fmul	d24, d24, d17
	fadd	d27, d4, d22
	fmul	d4, d14, d26
	fmov	d14, d29
	fmadd	d6, d30, d7, d0
	ldr	d0, [sp, #552]                  // 8-byte Folded Reload
	fmul	d21, d21, d1
	add	x27, x12, x24
	fmul	d19, d2, d19
	fmul	d3, d5, d0
	fmadd	d0, d18, d17, d16
	fsub	d22, d23, d6
	fmadd	d18, d18, d20, d24
	fsub	d20, d9, d28
	str	d0, [sp, #312]                  // 8-byte Folded Spill
	ldr	d0, [sp, #400]                  // 8-byte Folded Reload
	fmadd	d1, d22, d1, d19
	str	d18, [sp, #288]                 // 8-byte Folded Spill
	ldr	d28, [sp, #312]                 // 8-byte Folded Reload
	fsub	d17, d0, d3
	fadd	d16, d0, d5
	ldr	d0, [sp, #440]                  // 8-byte Folded Reload
	fadd	d5, d29, d12
	ldr	d3, [sp, #576]                  // 8-byte Folded Reload
	str	d1, [sp, #320]                  // 8-byte Folded Spill
	ldr	d12, [sp, #520]                 // 8-byte Folded Reload
	fmadd	d1, d22, d2, d21
	fadd	d18, d16, d0
	fmov	d24, d0
	fmul	d7, d0, d3
	ldr	d3, [sp, #568]                  // 8-byte Folded Reload
	ldr	d16, [sp, #544]                 // 8-byte Folded Reload
	fadd	d5, d5, d31
	ldr	d0, [sp, #480]                  // 8-byte Folded Reload
	str	d1, [sp, #336]                  // 8-byte Folded Spill
	fmul	d3, d12, d3
	ldr	d22, [sp, #528]                 // 8-byte Folded Reload
	fsub	d7, d17, d7
	fmov	d17, d31
	fmadd	d4, d0, d16, d4
	ldr	d16, [sp, #376]                 // 8-byte Folded Reload
	ldr	d31, [sp, #328]                 // 8-byte Folded Reload
	fadd	d5, d5, d10
	ldr	d2, [sp, #584]                  // 8-byte Folded Reload
	fadd	d3, d27, d3
	ldr	d0, [sp, #488]                  // 8-byte Folded Reload
	fmov	d29, d11
	fmul	d16, d31, d16
	ldr	d1, [sp, #432]                  // 8-byte Folded Reload
	fmul	d19, d22, d2
	fadd	d2, d23, d6
	fadd	d6, d18, d31
	fmadd	d4, d0, d13, d4
	ldr	d0, [sp, #472]                  // 8-byte Folded Reload
	fadd	d5, d5, d12
	fadd	d7, d7, d16
	ldr	d16, [sp, #560]                 // 8-byte Folded Reload
	fsub	d3, d3, d19
	ldr	d19, [sp, #536]                 // 8-byte Folded Reload
	fmul	d18, d0, d26
	fadd	d6, d6, d1
	ldr	d11, [sp, #408]                 // 8-byte Folded Reload
	fadd	d5, d5, d22
	fmadd	d4, d19, d16, d4
	ldr	d16, [sp, #544]                 // 8-byte Folded Reload
	ldr	d23, [sp, #512]                 // 8-byte Folded Reload
	fmov	d0, d10
	ldr	d21, [sp, #568]                 // 8-byte Folded Reload
	fmov	d12, d8
	fmadd	d16, d11, d16, d18
	fneg	d18, d20
	fadd	d6, d6, d23
	ldr	d26, [sp, #384]                 // 8-byte Folded Reload
	ldr	d19, [x10, #8]
	fmul	d21, d1, d21
	fmadd	d4, d8, d15, d4
	ldr	d22, [sp, #560]                 // 8-byte Folded Reload
	fmadd	d16, d26, d13, d16
	ldr	d8, [sp, #472]                  // 8-byte Folded Reload
	fmul	d18, d19, d18
	stp	d6, d5, [x27, #16]
	ldr	d6, [sp, #584]                  // 8-byte Folded Reload
	fadd	d7, d7, d21
	ldr	d21, [x10]
	add	x10, x26, x24
	fmadd	d16, d25, d22, d16
	fadd	d22, d4, d3
	fmul	d6, d23, d6
	ldr	d23, [sp, #504]                 // 8-byte Folded Reload
	fmadd	d5, d2, d21, d18
	fmul	d18, d20, d21
	ldr	d21, [sp, #584]                 // 8-byte Folded Reload
	fsub	d3, d3, d4
	ldp	d9, d10, [sp, #392]             // 16-byte Folded Reload
	fsub	d6, d7, d6
	fmadd	d7, d30, d15, d16
	fneg	d16, d22
	fmul	d21, d23, d21
	ldr	d20, [x10, #8]
	add	x27, x21, x24
	fmadd	d2, d2, d19, d18
	ldp	d18, d19, [sp, #344]            // 16-byte Folded Reload
	fneg	d23, d3
	fmul	d4, d20, d16
	fsub	d16, d10, d21
	ldr	d21, [sp, #552]                 // 8-byte Folded Reload
	fmov	d30, d14
	stp	d19, d18, [x27, #16]
	add	x27, x23, x24
	fsub	d18, d6, d7
	ldr	d19, [x10]
	fmul	d21, d24, d21
	ldr	d24, [sp, #584]                 // 8-byte Folded Reload
	fadd	d6, d6, d7
	ldr	d7, [x27, #8]
	add	x10, x13, x24
	ldr	d25, [sp, #568]                 // 8-byte Folded Reload
	fmul	d24, d9, d24
	fmadd	d4, d18, d19, d4
	fmul	d19, d22, d19
	fsub	d16, d16, d21
	fmul	d21, d7, d23
	ldr	d23, [x27]
	fmul	d25, d31, d25
	ldr	x27, [sp, #256]                 // 8-byte Folded Reload
	fsub	d22, d14, d24
	ldr	d24, [sp, #552]                 // 8-byte Folded Reload
	fmov	d14, d17
	fmul	d3, d3, d23
	fmadd	d18, d18, d20, d19
	add	x27, x27, x24
	fmul	d24, d17, d24
	ldr	d17, [sp, #288]                 // 8-byte Folded Reload
	fadd	d16, d16, d25
	ldr	d25, [sp, #424]                 // 8-byte Folded Reload
	stp	d28, d17, [x10, #16]
	fmadd	d17, d6, d23, d21
	ldr	d23, [sp, #568]                 // 8-byte Folded Reload
	fsub	d19, d22, d24
	ldr	x10, [sp, #264]                 // 8-byte Folded Reload
	ldr	d24, [sp, #496]                 // 8-byte Folded Reload
	str	d17, [sp, #344]                 // 8-byte Folded Spill
	fmul	d21, d0, d23
	fmov	d17, d0
	ldr	d0, [sp, #576]                  // 8-byte Folded Reload
	add	x10, x10, x24
	fmul	d20, d8, d24
	ldp	d27, d28, [sp, #368]            // 16-byte Folded Reload
	fmul	d22, d1, d0
	fmadd	d1, d6, d7, d3
	ldr	d0, [sp, #320]                  // 8-byte Folded Reload
	fadd	d3, d19, d21
	ldr	d21, [sp, #520]                 // 8-byte Folded Reload
	ldr	d6, [sp, #512]                  // 8-byte Folded Reload
	str	d1, [sp, #352]                  // 8-byte Folded Spill
	ldr	d1, [sp, #336]                  // 8-byte Folded Reload
	stp	d0, d1, [x10, #16]
	fmul	d0, d25, d24
	fsub	d7, d16, d22
	ldr	d16, [sp, #560]                 // 8-byte Folded Reload
	add	x10, x3, x24
	fmadd	d1, d11, d15, d20
	ldr	d22, [sp, #536]                 // 8-byte Folded Reload
	ldp	d19, d20, [sp, #480]            // 16-byte Folded Reload
	stp	d5, d2, [x10, #16]
	ldr	d5, [sp, #576]                  // 8-byte Folded Reload
	stp	d4, d18, [x27, #16]
	ldr	d2, [sp, #576]                  // 8-byte Folded Reload
	fmadd	d1, d26, d16, d1
	fmadd	d0, d19, d15, d0
	fmul	d16, d6, d28
	fmul	d5, d21, d5
	ldr	d4, [sp, #560]                  // 8-byte Folded Reload
	fmul	d2, d9, d2
	ldr	d9, [sp, #528]                  // 8-byte Folded Reload
	ldr	d18, [sp, #504]                 // 8-byte Folded Reload
	add	x27, x9, x24
	fmadd	d0, d20, d4, d0
	fadd	d4, d7, d16
	fsub	d3, d3, d5
	fmul	d7, d9, d28
	fmul	d16, d25, d27
	ldr	d25, [sp, #576]                 // 8-byte Folded Reload
	ldr	x10, [sp, #248]                 // 8-byte Folded Reload
	fsub	d2, d30, d2
	fmul	d5, d14, d23
	fmadd	d0, d22, d29, d0
	fmul	d18, d18, d25
	fadd	d3, d3, d7
	add	x10, x10, x24
	ldr	d7, [sp, #344]                  // 8-byte Folded Reload
	ldr	d24, [sp, #416]                 // 8-byte Folded Reload
	fmov	d25, d12
	fadd	d2, d2, d5
	ldr	d5, [sp, #584]                  // 8-byte Folded Reload
	str	d7, [x10, #16]
	fmadd	d7, d19, d29, d16
	fsub	d16, d10, d18
	ldp	d18, d14, [sp, #440]            // 16-byte Folded Reload
	fmul	d5, d17, d5
	fmadd	d1, d24, d29, d1
	fmadd	d0, d12, d13, d0
	fmul	d18, d18, d23
	fmul	d19, d21, d28
	ldr	d21, [sp, #552]                 // 8-byte Folded Reload
	fsub	d2, d2, d5
	fmadd	d1, d14, d13, d1
	fadd	d5, d0, d3
	ldr	d12, [sp, #552]                 // 8-byte Folded Reload
	fadd	d16, d16, d18
	ldr	d18, [sp, #584]                 // 8-byte Folded Reload
	fmul	d21, d9, d21
	ldr	d9, [sp, #544]                  // 8-byte Folded Reload
	fadd	d2, d2, d19
	fsub	d17, d4, d1
	fmul	d18, d31, d18
	fadd	d1, d4, d1
	fmadd	d4, d20, d15, d7
	fmul	d7, d8, d27
	fneg	d20, d5
	fsub	d0, d3, d0
	fsub	d2, d2, d21
	ldr	d23, [sp, #360]                 // 8-byte Folded Reload
	fsub	d16, d16, d18
	ldr	d31, [sp, #584]                 // 8-byte Folded Reload
	ldp	d18, d19, [x27]
	fmadd	d4, d22, d13, d4
	fmadd	d7, d11, d29, d7
	add	x27, x8, x24
	ldr	d22, [sp, #432]                 // 8-byte Folded Reload
	fmov	d11, d28
	fmul	d5, d5, d18
	fmul	d20, d19, d20
	fmadd	d3, d25, d9, d4
	fmadd	d4, d26, d15, d7
	fmul	d22, d22, d28
	fmov	d28, d12
	ldr	d26, [sp, #576]                 // 8-byte Folded Reload
	fmadd	d5, d17, d19, d5
	fmadd	d7, d17, d18, d20
	fmul	d20, d6, d12
	ldp	d19, d21, [x27]
	fneg	d18, d0
	fadd	d16, d16, d22
	ldr	d6, [sp, #352]                  // 8-byte Folded Reload
	fmadd	d4, d24, d13, d4
	fadd	d17, d3, d2
	fmul	d0, d0, d19
	fsub	d2, d2, d3
	str	d6, [x10, #24]
	ldp	x27, x10, [sp, #208]            // 16-byte Folded Reload
	fmul	d18, d21, d18
	add	x27, x27, x24
	fsub	d16, d16, d20
	fmadd	d4, d14, d9, d4
	add	x10, x10, x24
	fmadd	d0, d1, d21, d0
	ldp	d20, d22, [x27]
	fmadd	d6, d1, d19, d18
	fneg	d3, d17
	ldp	d21, d1, [x10]
	fneg	d19, d2
	fsub	d18, d16, d4
	ldr	x10, [sp, #272]                 // 8-byte Folded Reload
	fmul	d17, d17, d20
	fmul	d3, d22, d3
	fadd	d4, d16, d4
	fmul	d2, d2, d21
	add	x27, x29, x24
	fmul	d16, d1, d19
	add	x10, x10, x24
	fmadd	d17, d18, d22, d17
	fmadd	d3, d18, d20, d3
	stp	d7, d5, [x10, #16]
	fmadd	d1, d4, d1, d2
	fmadd	d5, d4, d21, d16
	add	x10, x20, x24
	stp	d6, d0, [x27, #16]
	ldr	d4, [sp, #560]                  // 8-byte Folded Reload
	add	x27, x30, x24
	add	x24, x24, #16
	stp	d3, d17, [x10, #16]
	stp	d5, d1, [x27, #16]
	b.ne	.LBB112_9
	b	.LBB112_6
.LBB112_10:
	add	sp, sp, #592
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end112:
	.size	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end112-_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIdEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
.LCPI113_0:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_,@function
_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_: // @_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #496
	stp	x29, x30, [sp, #400]            // 16-byte Folded Spill
	add	x29, sp, #400
	stp	x28, x27, [sp, #416]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #432]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #448]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #464]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #480]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #4
	mov	x26, x7
	add	x0, x8, #64
	stur	x6, [x29, #-128]                // 8-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x27, x4
	mov	x28, x3
	mov	x22, x1
	bl	malloc
	cbz	x0, .LBB113_155
// %bb.1:
	adrp	x8, .LCPI113_0
	add	x9, x0, #64
	add	x20, x23, #1
	and	x13, x9, #0xffffffffffffffc0
	mul	x9, x28, x22
	lsr	x3, x20, #1
	ldr	q0, [x8, :lo12:.LCPI113_0]
	subs	x15, x23, #2
	stur	x0, [x13, #-8]
	stur	x27, [x29, #-56]                // 8-byte Folded Spill
	stur	x9, [x29, #-16]                 // 8-byte Folded Spill
	str	q0, [x13]
	stur	x13, [x29, #-32]                // 8-byte Folded Spill
	stp	x28, x22, [x29, #-96]           // 16-byte Folded Spill
	str	x3, [sp, #160]                  // 8-byte Folded Spill
	b.lo	.LBB113_4
// %bb.2:
	sub	x14, x23, #1
	cmp	x14, #4
	b.hs	.LBB113_6
// %bb.3:
	mov	w8, #1
	b	.LBB113_13
.LBB113_4:
	cbz	x28, .LBB113_125
// %bb.5:
	cbnz	x22, .LBB113_17
	b	.LBB113_125
.LBB113_6:
	cmp	xzr, x15, lsr #60
	add	x11, x13, #16
	lsl	x10, x15, #4
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB113_13
// %bb.7:
	tbnz	w9, #0, .LBB113_13
// %bb.8:
	add	x11, x13, #24
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB113_13
// %bb.9:
	tbnz	w9, #0, .LBB113_13
// %bb.10:
	and	x9, x14, #0xfffffffffffffffc
	add	x10, x13, #48
	orr	x8, x9, #0x1
	add	x11, x26, #48
	mov	x12, x9
.LBB113_11:                             // =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x11, #-32]
	subs	x12, x12, #4
	ldp	q3, q2, [x11], #64
	stp	q1, q0, [x10, #-32]
	stp	q3, q2, [x10], #64
	b.ne	.LBB113_11
// %bb.12:
	cmp	x14, x9
	b.eq	.LBB113_15
.LBB113_13:
	lsl	x10, x8, #4
	sub	x9, x23, x8
	add	x8, x26, x10
	add	x10, x13, x10
.LBB113_14:                             // =>This Inner Loop Header: Depth=1
	ldr	q0, [x8], #16
	subs	x9, x9, #1
	str	q0, [x10], #16
	b.ne	.LBB113_14
.LBB113_15:
	cbz	x28, .LBB113_77
// %bb.16:
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cbz	x22, .LBB113_79
.LBB113_17:
	mul	x8, x23, x22
	lsl	x2, x22, #4
	mov	x19, x28
	mov	x26, x24
	lsl	x21, x8, #4
	str	x15, [sp, #192]                 // 8-byte Folded Spill
	stur	x2, [x29, #-104]                // 8-byte Folded Spill
.LBB113_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	bl	memcpy
	ldur	x2, [x29, #-104]                // 8-byte Folded Reload
	add	x27, x27, x21
	subs	x19, x19, #1
	add	x26, x26, x2
	b.ne	.LBB113_18
// %bb.19:
	sub	x8, x23, #1
	str	x20, [sp, #184]                 // 8-byte Folded Spill
	cmp	x20, #3
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	b.ls	.LBB113_45
// %bb.20:
	cbz	x22, .LBB113_92
// %bb.21:
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	mov	w9, #2
	lsl	x11, x28, #4
	sub	x10, x22, #1
	add	x11, x11, #16
	lsl	x14, x10, #4
	cmp	x8, #2
	mov	x12, xzr
	csel	x8, x8, x9, hi
	mul	x11, x11, x22
	cmp	xzr, x10, lsr #60
	ldur	x10, [x29, #-104]               // 8-byte Folded Reload
	cset	w13, ne
	add	x18, x14, #16
	stur	x8, [x29, #-168]                // 8-byte Folded Spill
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	mul	x9, x8, x28
	mul	x15, x26, x8
	lsl	x9, x9, #4
	add	x9, x9, #16
	add	x0, x24, x15, lsl #4
	mul	x9, x9, x22
	stp	x9, x11, [x29, #-72]            // 16-byte Folded Spill
	and	x9, x22, #0xfffffffffffffffe
	add	x11, x24, x26, lsl #4
	stur	x9, [x29, #-80]                 // 8-byte Folded Spill
	mul	x9, x22, x8
	lsl	x8, x26, #4
	stp	x8, x15, [x29, #-184]           // 16-byte Folded Spill
	neg	x8, x8
	stur	x8, [x29, #-192]                // 8-byte Folded Spill
	ldur	x8, [x29, #-56]                 // 8-byte Folded Reload
	add	x2, x8, x10
	add	x3, x8, x9, lsl #4
	neg	x8, x10
	mov	w9, #1
	str	x8, [sp, #200]                  // 8-byte Folded Spill
.LBB113_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB113_23 Depth 2
                                        //       Child Loop BB113_36 Depth 3
                                        //       Child Loop BB113_42 Depth 3
	ldur	x8, [x29, #-176]                // 8-byte Folded Reload
	stp	x9, x3, [x29, #-160]            // 16-byte Folded Spill
	mul	x9, x26, x12
	mov	x6, xzr
	madd	x25, x26, x12, x26
	stp	x11, x12, [x29, #-120]          // 16-byte Folded Spill
	msub	x7, x26, x12, x8
	add	x10, x26, x9
	sub	x8, x8, x9
	stp	x2, x0, [x29, #-144]            // 16-byte Folded Spill
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	stp	x8, x10, [x29, #-48]            // 16-byte Folded Spill
	mov	x10, x11
.LBB113_23:                             //   Parent Loop BB113_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB113_36 Depth 3
                                        //       Child Loop BB113_42 Depth 3
	cmp	x22, #2
	b.hs	.LBB113_25
// %bb.24:                              //   in Loop: Header=BB113_23 Depth=2
	mov	x19, xzr
	b	.LBB113_41
.LBB113_25:                             //   in Loop: Header=BB113_23 Depth=2
	mul	x20, x6, x22
	mov	x19, xzr
	add	x11, x7, x20
	add	x12, x25, x20
	add	x11, x24, x11, lsl #4
	add	x17, x24, x12, lsl #4
	add	x12, x11, #8
	add	x16, x11, x14
	add	x1, x17, #8
	cmp	x16, x11
	add	x11, x12, x14
	cset	w4, lo
	cmp	x11, x12
	add	x11, x1, x14
	cset	w12, lo
	cmp	x11, x1
	add	x11, x17, x14
	cset	w16, lo
	cmp	x11, x17
	orr	w17, w4, w13
	cset	w11, lo
	tbnz	w17, #0, .LBB113_41
// %bb.26:                              //   in Loop: Header=BB113_23 Depth=2
	orr	w12, w12, w13
	tbnz	w12, #0, .LBB113_41
// %bb.27:                              //   in Loop: Header=BB113_23 Depth=2
	orr	w12, w16, w13
	tbnz	w12, #0, .LBB113_41
// %bb.28:                              //   in Loop: Header=BB113_23 Depth=2
	orr	w11, w11, w13
	tbnz	w11, #0, .LBB113_41
// %bb.29:                              //   in Loop: Header=BB113_23 Depth=2
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	mov	x9, x24
	ldp	x15, x12, [x29, #-48]           // 16-byte Folded Reload
	mov	x19, xzr
	add	x11, x8, x20
	sub	x17, x20, x8
	ldur	x8, [x29, #-64]                 // 8-byte Folded Reload
	add	x11, x24, x11, lsl #4
	add	x17, x24, x17, lsl #4
	add	x12, x12, x20
	add	x16, x15, x20
	add	x11, x11, x8
	ldur	x8, [x29, #-72]                 // 8-byte Folded Reload
	add	x12, x24, x12, lsl #4
	sub	x1, x11, #8
	add	x5, x12, #8
	cmp	x11, x12
	add	x8, x17, x8
	cset	w26, hi
	sub	x9, x8, #8
	cmp	x1, x5
	add	x30, x24, x16, lsl #4
	cset	w27, hi
	cmp	x9, x12
	add	x15, x30, #8
	cset	w16, hi
	cmp	x1, x30
	cset	w22, hi
	cmp	x8, x12
	cset	w20, hi
	cmp	x1, x15
	cset	w17, hi
	cmp	x9, x5
	cset	w28, hi
	cmp	x11, x30
	cset	w4, hi
	cmp	x8, x5
	cset	w5, hi
	cmp	x11, x15
	cset	w11, hi
	cmp	x8, x30
	cset	w1, hi
	cmp	x9, x15
	and	w8, w26, w27
	cset	w12, hi
	tbnz	w8, #0, .LBB113_39
// %bb.30:                              //   in Loop: Header=BB113_23 Depth=2
	and	w8, w16, w22
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB113_40
// %bb.31:                              //   in Loop: Header=BB113_23 Depth=2
	and	w8, w20, w17
	ldur	x22, [x29, #-88]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB113_38
// %bb.32:                              //   in Loop: Header=BB113_23 Depth=2
	and	w8, w28, w4
	tbnz	w8, #0, .LBB113_38
// %bb.33:                              //   in Loop: Header=BB113_23 Depth=2
	and	w8, w5, w11
	ldur	x28, [x29, #-96]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB113_41
// %bb.34:                              //   in Loop: Header=BB113_23 Depth=2
	and	w8, w1, w12
	tbnz	w8, #0, .LBB113_41
// %bb.35:                              //   in Loop: Header=BB113_23 Depth=2
	ldur	x19, [x29, #-80]                // 8-byte Folded Reload
	mov	x20, x3
	mov	x22, x2
	mov	x28, x0
	mov	x16, x10
.LBB113_36:                             //   Parent Loop BB113_22 Depth=1
                                        //     Parent Loop BB113_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.2d, v1.2d }, [x22], #32
	subs	x19, x19, #2
	ld2	{ v2.2d, v3.2d }, [x20], #32
	fadd	v4.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x16], #32
	fsub	v4.2d, v0.2d, v2.2d
	fsub	v5.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x28], #32
	b.ne	.LBB113_36
// %bb.37:                              //   in Loop: Header=BB113_23 Depth=2
	ldp	x22, x8, [x29, #-88]            // 16-byte Folded Reload
	ldur	x28, [x29, #-96]                // 8-byte Folded Reload
	mov	x19, x8
	cmp	x8, x22
	b.ne	.LBB113_41
	b	.LBB113_43
.LBB113_38:                             //   in Loop: Header=BB113_23 Depth=2
	ldur	x28, [x29, #-96]                // 8-byte Folded Reload
	b	.LBB113_41
.LBB113_39:                             //   in Loop: Header=BB113_23 Depth=2
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
.LBB113_40:                             //   in Loop: Header=BB113_23 Depth=2
	ldp	x28, x22, [x29, #-96]           // 16-byte Folded Reload
.LBB113_41:                             //   in Loop: Header=BB113_23 Depth=2
	sub	x16, x22, x19
	lsl	x19, x19, #4
.LBB113_42:                             //   Parent Loop BB113_22 Depth=1
                                        //     Parent Loop BB113_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x8, x2, x19
	add	x9, x3, x19
	subs	x16, x16, #1
	ldp	d0, d1, [x8]
	add	x8, x10, x19
	ldp	d2, d3, [x9]
	add	x9, x0, x19
	add	x19, x19, #16
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stp	d4, d5, [x8]
	stp	d0, d1, [x9]
	b.ne	.LBB113_42
.LBB113_43:                             //   in Loop: Header=BB113_23 Depth=2
	add	x6, x6, #1
	add	x10, x10, x18
	add	x0, x0, x18
	add	x2, x2, x21
	add	x3, x3, x21
	cmp	x6, x28
	b.ne	.LBB113_23
// %bb.44:                              //   in Loop: Header=BB113_22 Depth=1
	ldp	x11, x12, [x29, #-120]          // 16-byte Folded Reload
	ldur	x8, [x29, #-184]                // 8-byte Folded Reload
	ldp	x2, x0, [x29, #-144]            // 16-byte Folded Reload
	add	x11, x11, x8
	ldur	x8, [x29, #-192]                // 8-byte Folded Reload
	ldp	x9, x3, [x29, #-160]            // 16-byte Folded Reload
	add	x12, x12, #1
	add	x2, x2, x18
	add	x0, x0, x8
	ldr	x8, [sp, #200]                  // 8-byte Folded Reload
	add	x9, x9, #1
	add	x3, x3, x8
	ldur	x8, [x29, #-168]                // 8-byte Folded Reload
	cmp	x9, x8
	b.ne	.LBB113_22
.LBB113_45:
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	ldr	x3, [sp, #160]                  // 8-byte Folded Reload
	ldr	x2, [sp, #184]                  // 8-byte Folded Reload
	ldur	x18, [x29, #-104]               // 8-byte Folded Reload
	cbz	x22, .LBB113_53
// %bb.46:
	cmp	x2, #3
	b.ls	.LBB113_81
// %bb.47:
	cmp	x3, #2
	mov	w9, #2
	csel	x9, x3, x9, hi
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x24, x26, lsl #4
	lsl	x11, x26, #4
.LBB113_48:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB113_49 Depth 2
                                        //       Child Loop BB113_50 Depth 3
	mul	x13, x8, x22
	mov	x12, xzr
	mov	x14, x10
.LBB113_49:                             //   Parent Loop BB113_48 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB113_50 Depth 3
	add	x15, x12, x13
	mov	x16, x14
	mov	x17, x9
	ldr	q0, [x24, x15, lsl #4]
.LBB113_50:                             //   Parent Loop BB113_48 Depth=1
                                        //     Parent Loop BB113_49 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q1, [x16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.2d, v0.2d, v1.2d
	b.ne	.LBB113_50
// %bb.51:                              //   in Loop: Header=BB113_49 Depth=2
	add	x12, x12, #1
	add	x14, x14, #16
	cmp	x12, x22
	str	q0, [x27, x15, lsl #4]
	b.ne	.LBB113_49
// %bb.52:                              //   in Loop: Header=BB113_48 Depth=1
	add	x8, x8, #1
	add	x10, x10, x18
	cmp	x8, x28
	b.ne	.LBB113_48
.LBB113_53:
	mov	w10, wzr
	mov	w9, wzr
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cmp	x2, #4
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	b.hs	.LBB113_93
// %bb.54:
	subs	x8, x22, #1
	b.ne	.LBB113_123
.LBB113_55:
	cmp	x26, #0
	eor	w9, w9, #0x1
	cset	w8, eq
	orr	w8, w9, w8
	tbnz	w8, #0, .LBB113_125
// %bb.56:
	mul	x10, x14, x28
	lsl	x11, x14, #4
	sub	x14, x26, #1
	add	x12, x11, #16
	cmp	x3, #2
	mov	w9, #2
	mul	x10, x10, x22
	csel	x9, x3, x9, hi
	mul	x12, x26, x12
	cmp	xzr, x14, lsr #60
	lsl	x14, x14, #4
	mov	x8, xzr
	lsl	x11, x26, #1
	cset	w13, ne
	and	x15, x26, #0xfffffffffffffffe
	add	x16, x27, x26, lsl #4
	add	x17, x14, #16
	add	x18, x27, x10, lsl #4
	neg	x0, x26, lsl #4
	mov	w1, #1
.LBB113_57:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB113_73 Depth 2
                                        //     Child Loop BB113_60 Depth 2
	cmp	x26, #2
	b.hs	.LBB113_62
// %bb.58:                              //   in Loop: Header=BB113_57 Depth=1
	mov	x2, xzr
.LBB113_59:                             //   in Loop: Header=BB113_57 Depth=1
	sub	x3, x26, x2
	lsl	x2, x2, #4
.LBB113_60:                             //   Parent Loop BB113_57 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x4, x16, x2
	add	x5, x18, x2
	subs	x3, x3, #1
	add	x2, x2, #16
	ldp	d0, d1, [x4]
	ldp	d2, d3, [x5]
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stp	d4, d5, [x4]
	stp	d0, d1, [x5]
	b.ne	.LBB113_60
.LBB113_61:                             //   in Loop: Header=BB113_57 Depth=1
	add	x1, x1, #1
	add	x8, x8, #1
	add	x16, x16, x17
	add	x18, x18, x0
	cmp	x1, x9
	b.ne	.LBB113_57
	b	.LBB113_125
.LBB113_62:                             //   in Loop: Header=BB113_57 Depth=1
	msub	x3, x26, x8, x10
	mov	x2, xzr
	madd	x4, x26, x8, x26
	add	x3, x27, x3, lsl #4
	add	x5, x3, #8
	add	x6, x27, x4, lsl #4
	add	x4, x5, x14
	add	x7, x6, #8
	cmp	x4, x5
	add	x4, x3, x14
	cset	w19, lo
	cmp	x4, x3
	add	x3, x7, x14
	cset	w4, lo
	cmp	x3, x7
	add	x3, x6, x14
	cset	w5, lo
	cmp	x3, x6
	orr	w6, w19, w13
	cset	w3, lo
	tbnz	w6, #0, .LBB113_59
// %bb.63:                              //   in Loop: Header=BB113_57 Depth=1
	orr	w4, w4, w13
	tbnz	w4, #0, .LBB113_59
// %bb.64:                              //   in Loop: Header=BB113_57 Depth=1
	orr	w4, w5, w13
	tbnz	w4, #0, .LBB113_59
// %bb.65:                              //   in Loop: Header=BB113_57 Depth=1
	orr	w3, w3, w13
	tbnz	w3, #0, .LBB113_59
// %bb.66:                              //   in Loop: Header=BB113_57 Depth=1
	mul	x3, x26, x8
	mov	x2, xzr
	add	x4, x26, x3
	add	x5, x11, x3
	sub	x6, x10, x3
	sub	x3, x27, x3, lsl #4
	add	x4, x27, x4, lsl #4
	add	x21, x27, x5, lsl #4
	add	x23, x27, x6, lsl #4
	add	x24, x3, x12
	sub	x6, x21, #8
	add	x19, x4, #8
	cmp	x4, x21
	sub	x25, x24, #8
	cset	w27, lo
	cmp	x19, x6
	cset	w28, lo
	cmp	x25, x4
	cset	w3, hi
	cmp	x23, x6
	add	x26, x23, #8
	cset	w5, lo
	cmp	x24, x4
	cset	w4, hi
	cmp	x26, x6
	cset	w7, lo
	cmp	x25, x19
	cset	w6, hi
	cmp	x23, x21
	cset	w20, lo
	cmp	x24, x19
	cset	w19, hi
	cmp	x26, x21
	cset	w22, lo
	cmp	x24, x23
	cset	w21, hi
	cmp	x25, x26
	and	w24, w27, w28
	cset	w23, hi
	tbnz	w24, #0, .LBB113_76
// %bb.67:                              //   in Loop: Header=BB113_57 Depth=1
	and	w3, w3, w5
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w3, #0, .LBB113_75
// %bb.68:                              //   in Loop: Header=BB113_57 Depth=1
	and	w3, w4, w7
	tbnz	w3, #0, .LBB113_75
// %bb.69:                              //   in Loop: Header=BB113_57 Depth=1
	and	w3, w6, w20
	tbnz	w3, #0, .LBB113_75
// %bb.70:                              //   in Loop: Header=BB113_57 Depth=1
	and	w3, w19, w22
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	tbnz	w3, #0, .LBB113_59
// %bb.71:                              //   in Loop: Header=BB113_57 Depth=1
	and	w3, w21, w23
	tbnz	w3, #0, .LBB113_59
// %bb.72:                              //   in Loop: Header=BB113_57 Depth=1
	mov	x2, x15
	mov	x3, x18
	mov	x4, x16
.LBB113_73:                             //   Parent Loop BB113_57 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v0.2d, v1.2d }, [x4]
	subs	x2, x2, #2
	ld2	{ v2.2d, v3.2d }, [x3]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v6.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v7.2d, v1.2d, v3.2d
	st2	{ v4.2d, v5.2d }, [x4], #32
	st2	{ v6.2d, v7.2d }, [x3], #32
	b.ne	.LBB113_73
// %bb.74:                              //   in Loop: Header=BB113_57 Depth=1
	mov	x2, x15
	cmp	x26, x15
	b.ne	.LBB113_59
	b	.LBB113_61
.LBB113_75:                             //   in Loop: Header=BB113_57 Depth=1
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	b	.LBB113_59
.LBB113_76:                             //   in Loop: Header=BB113_57 Depth=1
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	b	.LBB113_59
.LBB113_77:
	mov	w10, #1
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cmp	x20, #3
	b.hi	.LBB113_93
// %bb.78:
	mov	w9, wzr
	subs	x8, x22, #1
	b.ne	.LBB113_123
	b	.LBB113_55
.LBB113_79:
	cmp	x20, #3
	b.ls	.LBB113_125
// %bb.80:
	mov	w10, wzr
	b	.LBB113_93
.LBB113_81:
	sub	x12, x22, #1
	mov	x8, xzr
	mov	x9, xzr
	and	x10, x22, #0xfffffffffffffffc
	cmp	xzr, x12, lsr #60
	lsl	x12, x12, #4
	add	x11, x27, #32
	cset	w13, ne
	add	x14, x12, #16
	add	x15, x24, #32
	b	.LBB113_83
.LBB113_82:                             //   in Loop: Header=BB113_83 Depth=1
	add	x9, x9, #1
	add	x11, x11, x14
	add	x15, x15, x14
	add	x8, x8, x22
	cmp	x9, x28
	b.eq	.LBB113_53
.LBB113_83:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB113_90 Depth 2
                                        //     Child Loop BB113_86 Depth 2
	cmp	x22, #4
	b.hs	.LBB113_87
// %bb.84:                              //   in Loop: Header=BB113_83 Depth=1
	mov	x16, xzr
.LBB113_85:                             //   in Loop: Header=BB113_83 Depth=1
	add	x17, x16, x8
	sub	x16, x22, x16
	lsl	x18, x17, #4
	add	x17, x27, x18
	add	x18, x24, x18
.LBB113_86:                             //   Parent Loop BB113_83 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	q0, [x18], #16
	subs	x16, x16, #1
	str	q0, [x17], #16
	b.ne	.LBB113_86
	b	.LBB113_82
.LBB113_87:                             //   in Loop: Header=BB113_83 Depth=1
	mul	x17, x9, x22
	mov	x16, xzr
	add	x17, x27, x17, lsl #4
	add	x18, x17, x12
	add	x0, x17, #8
	cmp	x18, x17
	add	x18, x0, x12
	cset	w17, lo
	cmp	x18, x0
	orr	w1, w17, w13
	cset	w17, lo
	tbnz	w1, #0, .LBB113_85
// %bb.88:                              //   in Loop: Header=BB113_83 Depth=1
	orr	w17, w17, w13
	tbnz	w17, #0, .LBB113_85
// %bb.89:                              //   in Loop: Header=BB113_83 Depth=1
	mov	x16, x10
	mov	x17, x15
	mov	x18, x11
.LBB113_90:                             //   Parent Loop BB113_83 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x17, #-32]
	subs	x16, x16, #4
	ldp	q3, q2, [x17], #64
	stp	q1, q0, [x18, #-32]
	stp	q3, q2, [x18], #64
	b.ne	.LBB113_90
// %bb.91:                              //   in Loop: Header=BB113_83 Depth=1
	mov	x16, x10
	cmp	x10, x22
	b.eq	.LBB113_82
	b	.LBB113_85
.LBB113_92:
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	mov	w10, wzr
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	ldr	x3, [sp, #160]                  // 8-byte Folded Reload
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
.LBB113_93:
	sub	x9, x3, #1
	str	w10, [sp, #4]                   // 4-byte Folded Spill
	lsl	x11, x14, #4
	cmp	x3, #2
	add	x11, x11, #16
	mov	w10, #2
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	mul	x9, x14, x28
	sub	x13, x26, #1
	csel	x10, x3, x10, hi
	lsl	x6, x26, #4
	mul	x8, x26, x15
	mul	x20, x9, x22
	cmp	xzr, x13, lsr #60
	mul	x9, x26, x11
	str	x14, [sp, #8]                   // 8-byte Folded Spill
	mul	x16, x26, x14
	add	x8, x24, x8, lsl #4
	add	x7, x27, x6
	lsl	x12, x26, #1
	sub	x15, x23, #3
	lsl	x18, x26, #2
	stp	x9, x10, [sp, #144]             // 16-byte Folded Spill
	cset	w9, ne
	lsl	x10, x16, #4
	lsl	x30, x26, #5
	add	x4, x27, x10
	mov	x19, xzr
	str	w9, [sp, #116]                  // 4-byte Folded Spill
	lsl	x9, x13, #4
	and	x5, x26, #0xfffffffffffffffe
	mov	w17, #1
	str	x9, [sp, #104]                  // 8-byte Folded Spill
	add	x9, x24, x6
	add	x21, x9, #8
	neg	x9, x6
	stur	x16, [x29, #-64]                // 8-byte Folded Spill
	stur	x9, [x29, #-40]                 // 8-byte Folded Spill
	add	x9, x24, x26, lsl #5
	add	x9, x9, #8
	stp	x8, x9, [sp, #88]               // 16-byte Folded Spill
	add	x8, x7, #8
	add	x9, x12, x26
	stur	x8, [x29, #-112]                // 8-byte Folded Spill
	add	x8, x24, x10
	add	x8, x8, #8
	add	x11, x24, x9, lsl #4
	str	x15, [sp, #120]                 // 8-byte Folded Spill
	stp	x9, x8, [sp, #72]               // 16-byte Folded Spill
	sub	x8, x23, #4
	mul	x9, x26, x15
	mul	x10, x26, x8
	add	x8, x24, x26, lsl #6
	stp	x9, x11, [sp, #56]              // 16-byte Folded Spill
	add	x11, x24, x9, lsl #4
	add	x9, x24, x10, lsl #4
	stp	x8, x18, [sp, #32]              // 16-byte Folded Spill
	str	x10, [sp, #48]                  // 8-byte Folded Spill
	neg	x8, x30
	stp	x9, x11, [sp, #16]              // 16-byte Folded Spill
	add	x9, x24, #8
	ldur	x1, [x29, #-32]                 // 8-byte Folded Reload
	stur	x20, [x29, #-136]               // 8-byte Folded Spill
	stur	x5, [x29, #-104]                // 8-byte Folded Spill
	stp	x9, x26, [x29, #-80]            // 16-byte Folded Spill
	stp	x21, x6, [sp, #128]             // 16-byte Folded Spill
	b	.LBB113_95
.LBB113_94:                             //   in Loop: Header=BB113_95 Depth=1
	ldur	x9, [x29, #-40]                 // 8-byte Folded Reload
	add	x17, x17, #1
	add	x19, x19, #1
	add	x7, x7, x6
	add	x4, x4, x9
	ldur	x9, [x29, #-112]                // 8-byte Folded Reload
	add	x9, x9, x6
	stur	x9, [x29, #-112]                // 8-byte Folded Spill
	ldur	x9, [x29, #-72]                 // 8-byte Folded Reload
	add	x9, x9, x26
	stur	x9, [x29, #-72]                 // 8-byte Folded Spill
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	sub	x9, x9, x26
	stur	x9, [x29, #-64]                 // 8-byte Folded Spill
	ldr	x9, [sp, #152]                  // 8-byte Folded Reload
	ldr	x21, [sp, #128]                 // 8-byte Folded Reload
	cmp	x17, x9
	b.eq	.LBB113_122
.LBB113_95:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB113_97 Depth 2
                                        //     Child Loop BB113_103 Depth 2
                                        //       Child Loop BB113_107 Depth 3
                                        //       Child Loop BB113_110 Depth 3
                                        //     Child Loop BB113_116 Depth 2
                                        //       Child Loop BB113_118 Depth 3
                                        //       Child Loop BB113_121 Depth 3
	mul	x13, x26, x19
	sub	x10, x20, x13
	sub	x11, x27, x13, lsl #4
	cbz	x26, .LBB113_99
// %bb.96:                              //   in Loop: Header=BB113_95 Depth=1
	add	x15, x1, x17, lsl #4
	add	x18, x1, x17, lsl #5
	ldp	x22, x1, [sp, #88]              // 16-byte Folded Reload
	mov	x14, xzr
	lsl	x16, x17, #1
	add	x0, x15, #8
	add	x2, x18, #8
	mov	x3, x26
	ldur	x28, [x29, #-112]               // 8-byte Folded Reload
	ldr	x20, [sp, #80]                  // 8-byte Folded Reload
.LBB113_97:                             //   Parent Loop BB113_95 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x5, x24, x14
	add	x9, x21, x14
	ldr	d0, [x15]
	add	x6, x1, x14
	ldr	d3, [x18]
	subs	x3, x3, #1
	ldp	d2, d4, [x5]
	add	x5, x28, x14
	ldur	d1, [x9, #-8]
	fmadd	d0, d0, d1, d2
	ldp	d1, d2, [x6, #-8]
	fmadd	d0, d3, d1, d0
	ldr	d1, [x9]
	add	x9, x22, x14
	stur	d0, [x5, #-8]
	ldr	d0, [x15]
	fmadd	d0, d0, d1, d4
	ldr	d1, [x18]
	fmadd	d0, d1, d2, d0
	ldp	d3, d2, [x9]
	add	x9, x4, x14
	str	d0, [x5]
	add	x5, x20, x14
	ldr	d0, [x2]
	add	x14, x14, #16
	fneg	d1, d0
	fmul	d0, d0, d3
	ldp	d3, d4, [x5, #-8]
	fmul	d1, d2, d1
	ldr	d2, [x0]
	fmadd	d0, d2, d3, d0
	fmsub	d1, d2, d4, d1
	str	d0, [x9, #8]
	str	d1, [x9]
	b.ne	.LBB113_97
// %bb.98:                              //   in Loop: Header=BB113_95 Depth=1
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
	b	.LBB113_100
.LBB113_99:                             //   in Loop: Header=BB113_95 Depth=1
	lsl	x16, x17, #1
.LBB113_100:                            //   in Loop: Header=BB113_95 Depth=1
	add	x9, x26, x13
	add	x15, x12, x13
	ldr	x13, [sp, #144]                 // 8-byte Folded Reload
	add	x3, x27, x10, lsl #4
	add	x14, x27, x15, lsl #4
	add	x5, x27, x9, lsl #4
	sub	x2, x14, #8
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	add	x18, x11, x13
	msub	x11, x26, x19, x20
	madd	x13, x26, x19, x26
	stur	x19, [x29, #-120]               // 8-byte Folded Spill
	sub	x6, x18, #8
	add	x1, x5, #8
	add	x11, x27, x11, lsl #4
	add	x0, x3, #8
	add	x14, x27, x13, lsl #4
	add	x20, x11, #8
	add	x19, x14, #8
	cmp	x9, #4
	stp	x18, x15, [x29, #-152]          // 16-byte Folded Spill
	stp	x1, x0, [x29, #-168]            // 16-byte Folded Spill
	stp	x3, x2, [x29, #-184]            // 16-byte Folded Spill
	stur	x5, [x29, #-192]                // 8-byte Folded Spill
	stp	x19, x6, [sp, #192]             // 16-byte Folded Spill
	stp	x14, x20, [sp, #176]            // 16-byte Folded Spill
	str	x11, [sp, #168]                 // 8-byte Folded Spill
	b.lo	.LBB113_111
// %bb.101:                             //   in Loop: Header=BB113_95 Depth=1
	ldr	x13, [sp, #104]                 // 8-byte Folded Reload
	add	x15, x27, x15, lsl #4
	add	x9, x11, x13
	add	x10, x14, x13
	cmp	x9, x11
	add	x9, x20, x13
	cset	w11, lo
	cmp	x10, x14
	ldr	w14, [sp, #116]                 // 4-byte Folded Reload
	orr	w10, w11, w14
	cset	w11, lo
	cmp	x9, x20
	orr	w9, w11, w14
	add	x11, x19, x13
	cset	w13, lo
	cmp	x11, x19
	orr	w11, w13, w14
	cset	w13, lo
	cmp	x6, x5
	orr	w13, w13, w14
	cset	w14, hi
	cmp	x3, x2
	orr	w9, w10, w9
	cset	w10, lo
	cmp	x18, x1
	cset	w18, hi
	cmp	x0, x15
	orr	w9, w9, w11
	cset	w11, lo
	and	w10, w14, w10
	and	w11, w18, w11
	orr	w25, w9, w13
	orr	w9, w10, w11
	mov	w18, #3
	stur	w9, [x29, #-48]                 // 4-byte Folded Spill
	ldp	x28, x5, [sp, #48]              // 16-byte Folded Reload
	ldp	x15, x2, [sp, #32]              // 16-byte Folded Reload
	ldp	x14, x11, [sp, #64]             // 16-byte Folded Reload
	ldp	x19, x13, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp, #120]                 // 8-byte Folded Reload
	b	.LBB113_103
.LBB113_102:                            //   in Loop: Header=BB113_103 Depth=2
	ldp	x9, x26, [x29, #-24]            // 16-byte Folded Reload
	add	x18, x18, #2
	sub	x21, x21, #2
	add	x14, x14, x30
	add	x15, x15, x30
	add	x13, x13, x8
	add	x19, x19, x8
	add	x11, x11, x12
	add	x2, x2, x12
	sub	x5, x5, x12
	sub	x28, x28, x12
	cmp	x18, x9
	b.hs	.LBB113_112
.LBB113_103:                            //   Parent Loop BB113_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB113_107 Depth 3
                                        //       Child Loop BB113_110 Depth 3
	add	x9, x16, x17
	cmp	x9, x23
	csel	x16, x23, xzr, hi
	sub	x9, x9, x16
	add	x16, x9, x17
	cmp	x16, x23
	csel	x0, x23, xzr, hi
	sub	x16, x16, x0
	cbz	x26, .LBB113_102
// %bb.104:                             //   in Loop: Header=BB113_103 Depth=2
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	add	x9, x10, x9, lsl #4
	add	x0, x10, x16, lsl #4
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	ldp	d3, d0, [x9]
	cmp	x10, #1
	ldur	w9, [x29, #-48]                 // 4-byte Folded Reload
	cset	w3, eq
	ldp	d1, d2, [x0]
	orr	w3, w3, w25
	orr	w9, w3, w9
	tbz	w9, #0, .LBB113_106
// %bb.105:                             //   in Loop: Header=BB113_103 Depth=2
	mov	x9, xzr
	b	.LBB113_109
.LBB113_106:                            //   in Loop: Header=BB113_103 Depth=2
	ldur	x1, [x29, #-104]                // 8-byte Folded Reload
	mov	x20, xzr
	dup	v4.2d, v3.d[0]
	dup	v5.2d, v0.d[0]
	mov	x22, x1
.LBB113_107:                            //   Parent Loop BB113_95 Depth=1
                                        //     Parent Loop BB113_103 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x15, x20
	add	x0, x19, x20
	subs	x22, x22, #2
	ld2	{ v6.2d, v7.2d }, [x9]
	add	x9, x14, x20
	ld2	{ v16.2d, v17.2d }, [x9]
	add	x9, x7, x20
	fmul	v18.2d, v6.2d, v1.d[0]
	fmul	v6.2d, v7.2d, v1.d[0]
	ld2	{ v19.2d, v20.2d }, [x9]
	fmla	v18.2d, v4.2d, v16.2d
	fmla	v6.2d, v4.2d, v17.2d
	ld2	{ v16.2d, v17.2d }, [x0]
	add	x0, x13, x20
	fadd	v21.2d, v19.2d, v18.2d
	fadd	v22.2d, v20.2d, v6.2d
	ld2	{ v6.2d, v7.2d }, [x0]
	add	x0, x4, x20
	add	x20, x20, #32
	fmul	v18.2d, v17.2d, v2.d[0]
	fmul	v16.2d, v16.2d, v2.d[0]
	st2	{ v21.2d, v22.2d }, [x9]
	ld2	{ v19.2d, v20.2d }, [x0]
	fmla	v18.2d, v5.2d, v7.2d
	fmla	v16.2d, v5.2d, v6.2d
	fsub	v6.2d, v19.2d, v18.2d
	fadd	v7.2d, v20.2d, v16.2d
	st2	{ v6.2d, v7.2d }, [x0]
	b.ne	.LBB113_107
// %bb.108:                             //   in Loop: Header=BB113_103 Depth=2
	mov	x9, x1
	cmp	x10, x1
	b.eq	.LBB113_102
.LBB113_109:                            //   in Loop: Header=BB113_103 Depth=2
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	add	x0, x9, x11
	add	x6, x9, x2
	add	x1, x9, x28
	add	x3, x24, x0, lsl #4
	mov	x20, xzr
	sub	x22, x10, x9
	ldur	x10, [x29, #-72]                // 8-byte Folded Reload
	add	x6, x24, x6, lsl #4
	dup	v3.2d, v3.d[0]
	add	x0, x10, x9
	ldur	x10, [x29, #-64]                // 8-byte Folded Reload
	add	x27, x10, x9
	add	x10, x9, x5
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	add	x26, x9, x0, lsl #4
	ldur	x0, [x29, #-80]                 // 8-byte Folded Reload
	add	x9, x9, x27, lsl #4
	add	x27, x0, x10, lsl #4
	add	x0, x0, x1, lsl #4
.LBB113_110:                            //   Parent Loop BB113_95 Depth=1
                                        //     Parent Loop BB113_103 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q4, [x6, x20]
	add	x10, x0, x20
	ldr	q5, [x3, x20]
	add	x1, x27, x20
	ldr	q6, [x26, x20]
	subs	x22, x22, #1
	ldp	d16, d7, [x10, #-8]
	fmul	v4.2d, v4.2d, v1.d[0]
	add	x10, x9, x20
	fmul	d16, d2, d16
	fmla	v4.2d, v3.2d, v5.2d
	fmul	d7, d2, d7
	fadd	v4.2d, v6.2d, v4.2d
	ldp	d6, d5, [x1, #-8]
	str	q4, [x26, x20]
	add	x20, x20, #16
	fmadd	d4, d6, d0, d16
	fmadd	d5, d5, d0, d7
	ldp	d6, d7, [x10]
	fsub	d5, d6, d5
	fadd	d4, d7, d4
	str	d5, [x10]
	str	d4, [x10, #8]
	b.ne	.LBB113_110
	b	.LBB113_102
.LBB113_111:                            //   in Loop: Header=BB113_95 Depth=1
	ldr	x21, [sp, #120]                 // 8-byte Folded Reload
	mov	w18, #3
.LBB113_112:                            //   in Loop: Header=BB113_95 Depth=1
	ldp	x28, x22, [x29, #-96]           // 16-byte Folded Reload
	ldr	x3, [sp, #160]                  // 8-byte Folded Reload
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	ldur	x1, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x19, [x29, #-120]               // 8-byte Folded Reload
	cmp	x18, x3
	ldur	x20, [x29, #-136]               // 8-byte Folded Reload
	ldur	x5, [x29, #-104]                // 8-byte Folded Reload
	ldr	x6, [sp, #136]                  // 8-byte Folded Reload
	b.hs	.LBB113_94
// %bb.113:                             //   in Loop: Header=BB113_95 Depth=1
	cbz	x26, .LBB113_94
// %bb.114:                             //   in Loop: Header=BB113_95 Depth=1
	ldp	x10, x11, [sp, #168]            // 16-byte Folded Reload
	mul	x2, x26, x21
	ldr	x13, [sp, #104]                 // 8-byte Folded Reload
	ldr	x15, [sp, #184]                 // 8-byte Folded Reload
	ldr	w14, [sp, #116]                 // 4-byte Folded Reload
	add	x9, x10, x13
	cmp	x9, x10
	add	x9, x11, x13
	cset	w10, lo
	cmp	x9, x11
	add	x9, x15, x13
	cset	w11, lo
	cmp	x9, x15
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	orr	w9, w11, w14
	orr	w10, w10, w14
	orr	w9, w10, w9
	add	x11, x15, x13
	cset	w13, lo
	cmp	x11, x15
	orr	w11, w13, w14
	cset	w13, lo
	orr	w9, w9, w11
	orr	w13, w13, w14
	ldr	x11, [sp, #200]                 // 8-byte Folded Reload
	ldp	x10, x14, [x29, #-192]          // 16-byte Folded Reload
	cmp	x11, x10
	ldp	x11, x15, [x29, #-176]          // 16-byte Folded Reload
	cset	w10, hi
	cmp	x14, x11
	ldp	x0, x14, [x29, #-160]           // 16-byte Folded Reload
	cset	w11, lo
	and	w11, w10, w11
	orr	w10, w9, w13
	cmp	x14, x15
	ldur	x15, [x29, #-144]               // 8-byte Folded Reload
	cset	w14, hi
	add	x15, x27, x15, lsl #4
	cmp	x0, x15
	mul	x15, x26, x18
	cset	w0, lo
	and	w14, w14, w0
	orr	w11, w11, w14
	add	x13, x24, x15, lsl #4
	add	x14, x24, x2, lsl #4
	b	.LBB113_116
.LBB113_115:                            //   in Loop: Header=BB113_116 Depth=2
	ldur	x9, [x29, #-40]                 // 8-byte Folded Reload
	add	x18, x18, #1
	add	x13, x13, x6
	cmp	x18, x3
	add	x14, x14, x9
	b.eq	.LBB113_94
.LBB113_116:                            //   Parent Loop BB113_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB113_118 Depth 3
                                        //       Child Loop BB113_121 Depth 3
	cmp	x26, #2
	add	x9, x16, x17
	cset	w0, lo
	cmp	x9, x23
	csel	x16, x23, xzr, hi
	orr	w0, w0, w10
	sub	x16, x9, x16
	mov	x15, xzr
	orr	w0, w0, w11
	add	x9, x1, x16, lsl #4
	ldp	d1, d0, [x9]
	tbnz	w0, #0, .LBB113_120
// %bb.117:                             //   in Loop: Header=BB113_116 Depth=2
	mov	x15, xzr
	mov	x0, x5
	dup	v2.2d, v1.d[0]
	dup	v3.2d, v0.d[0]
.LBB113_118:                            //   Parent Loop BB113_95 Depth=1
                                        //     Parent Loop BB113_116 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x13, x15
	add	x2, x14, x15
	subs	x0, x0, #2
	ld2	{ v4.2d, v5.2d }, [x9]
	add	x9, x7, x15
	ld2	{ v6.2d, v7.2d }, [x9]
	fmla	v6.2d, v2.2d, v4.2d
	fmla	v7.2d, v2.2d, v5.2d
	ld2	{ v4.2d, v5.2d }, [x2]
	add	x2, x4, x15
	add	x15, x15, #32
	st2	{ v6.2d, v7.2d }, [x9]
	ld2	{ v6.2d, v7.2d }, [x2]
	fmls	v6.2d, v3.2d, v5.2d
	fmla	v7.2d, v3.2d, v4.2d
	st2	{ v6.2d, v7.2d }, [x2]
	b.ne	.LBB113_118
// %bb.119:                             //   in Loop: Header=BB113_116 Depth=2
	mov	x15, x5
	cmp	x26, x5
	b.eq	.LBB113_115
.LBB113_120:                            //   in Loop: Header=BB113_116 Depth=2
	sub	x9, x26, x15
	lsl	x15, x15, #4
	dup	v1.2d, v1.d[0]
.LBB113_121:                            //   Parent Loop BB113_95 Depth=1
                                        //     Parent Loop BB113_116 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q2, [x13, x15]
	add	x0, x14, x15
	ldr	q3, [x7, x15]
	add	x2, x4, x15
	subs	x9, x9, #1
	fmla	v3.2d, v1.2d, v2.2d
	ldp	d4, d2, [x0]
	str	q3, [x7, x15]
	add	x15, x15, #16
	ldp	d3, d5, [x2]
	fmsub	d2, d2, d0, d3
	fmadd	d3, d4, d0, d5
	stp	d2, d3, [x2]
	b.ne	.LBB113_121
	b	.LBB113_115
.LBB113_122:
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	mov	w9, #1
	ldr	w10, [sp, #4]                   // 4-byte Folded Reload
	subs	x8, x22, #1
	b.eq	.LBB113_55
.LBB113_123:
	cbz	w9, .LBB113_125
// %bb.124:
	tbz	w10, #0, .LBB113_128
.LBB113_125:
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	cbz	x8, .LBB113_127
// %bb.126:
	ldp	x20, x19, [sp, #480]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #464]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #448]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #432]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #416]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #400]            // 16-byte Folded Reload
	ldur	x0, [x8, #-8]
	add	sp, sp, #496
	b	free
.LBB113_127:
	ldp	x20, x19, [sp, #480]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #464]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #448]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #432]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #416]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #400]            // 16-byte Folded Reload
	add	sp, sp, #496
	ret
.LBB113_128:
	cmp	x3, #2
	mov	w11, #2
	mul	x10, x14, x28
	csel	x11, x3, x11, hi
	lsl	x13, x28, #4
	sub	x12, x22, #2
	add	x13, x13, #16
	lsl	x16, x12, #4
	stur	x11, [x29, #-176]               // 8-byte Folded Spill
	mul	x11, x10, x22
	lsl	x10, x10, #4
	mul	x13, x13, x22
	add	x10, x10, #16
	cmp	xzr, x12, lsr #60
	orr	x12, x8, #0x1
	add	x18, x11, #1
	mul	x10, x10, x22
	add	x3, x27, x11, lsl #4
	lsl	x2, x22, #4
	add	x0, x26, #1
	stur	x12, [x29, #-112]               // 8-byte Folded Spill
	add	x12, x27, x26, lsl #4
	add	x4, x12, #8
	lsl	x12, x26, #4
	stp	x10, x13, [x29, #-80]           // 16-byte Folded Spill
	and	x10, x8, #0xfffffffffffffffe
	neg	x11, x12
	mov	x9, xzr
	cset	w15, ne
	add	x23, x27, x0, lsl #4
	stur	x10, [x29, #-104]               // 8-byte Folded Spill
	sub	x10, x14, #1
	stp	x11, x12, [x29, #-192]          // 16-byte Folded Spill
	ldur	x11, [x29, #-128]               // 8-byte Folded Reload
	mul	x10, x10, x8
	add	x24, x27, x18, lsl #4
	add	x13, x3, #8
	str	x0, [sp, #176]                  // 8-byte Folded Spill
	add	x17, x11, x10, lsl #4
	mov	w10, #16
	sub	x10, x10, x2
	str	x10, [sp, #200]                 // 8-byte Folded Spill
	sub	x10, x2, #16
	stp	x18, x10, [sp, #184]            // 16-byte Folded Spill
	mov	w18, #1
	b	.LBB113_130
.LBB113_129:                            //   in Loop: Header=BB113_130 Depth=1
	ldp	x11, x10, [x29, #-192]          // 16-byte Folded Reload
	ldp	x24, x23, [x29, #-144]          // 16-byte Folded Reload
	ldr	x12, [sp, #200]                 // 8-byte Folded Reload
	add	x3, x3, x11
	ldp	x18, x13, [x29, #-160]          // 16-byte Folded Reload
	add	x4, x4, x10
	add	x24, x24, x11
	ldur	x9, [x29, #-120]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	x12, [sp, #192]                 // 8-byte Folded Reload
	add	x23, x23, x10
	ldp	x10, x14, [x29, #-176]          // 16-byte Folded Reload
	add	x18, x18, #1
	add	x9, x9, #1
	add	x20, x20, x12
	add	x13, x13, x11
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cmp	x18, x10
	stur	x20, [x29, #-128]               // 8-byte Folded Spill
	b.eq	.LBB113_125
.LBB113_130:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB113_154 Depth 2
                                        //     Child Loop BB113_132 Depth 2
                                        //       Child Loop BB113_148 Depth 3
                                        //       Child Loop BB113_135 Depth 3
	sub	x10, x14, #1
	cmp	x22, #1
	stur	x9, [x29, #-120]                // 8-byte Folded Spill
	stp	x24, x23, [x29, #-144]          // 16-byte Folded Spill
	stp	x10, x18, [x29, #-168]          // 16-byte Folded Spill
	stur	x13, [x29, #-152]               // 8-byte Folded Spill
	b.ls	.LBB113_153
// %bb.131:                             //   in Loop: Header=BB113_130 Depth=1
	ldr	x11, [sp, #184]                 // 8-byte Folded Reload
	mul	x10, x26, x9
	mul	x18, x18, x28
	mov	x21, xzr
	mul	x30, x14, x28
	mov	x0, x4
	msub	x12, x26, x9, x11
	ldur	x20, [x29, #-128]               // 8-byte Folded Reload
	stur	x12, [x29, #-24]                // 8-byte Folded Spill
	ldr	x12, [sp, #176]                 // 8-byte Folded Reload
	madd	x9, x26, x9, x12
	mov	x26, x13
	stur	x9, [x29, #-40]                 // 8-byte Folded Spill
	add	x9, x12, x10
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	sub	x9, x11, x10
	stur	x9, [x29, #-64]                 // 8-byte Folded Spill
.LBB113_132:                            //   Parent Loop BB113_130 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB113_148 Depth 3
                                        //       Child Loop BB113_135 Depth 3
	add	x13, x21, x18
	add	x14, x21, x30
	cmp	x8, #2
	mul	x13, x13, x22
	mul	x14, x14, x22
	add	x13, x27, x13, lsl #4
	add	x14, x27, x14, lsl #4
	ldp	d0, d1, [x13]
	ldp	d2, d3, [x14]
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	str	d4, [x13]
	str	d5, [x13, #8]
	str	d0, [x14]
	str	d1, [x14, #8]
	b.hs	.LBB113_137
.LBB113_133:                            //   in Loop: Header=BB113_132 Depth=2
	mov	w19, #1
.LBB113_134:                            //   in Loop: Header=BB113_132 Depth=2
	sub	x5, x22, x19
	lsl	x19, x19, #4
.LBB113_135:                            //   Parent Loop BB113_130 Depth=1
                                        //     Parent Loop BB113_132 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x0, x19
	add	x11, x26, x19
	add	x12, x20, x19
	subs	x5, x5, #1
	ldp	d4, d0, [x9, #-8]
	ldp	d5, d1, [x11, #-8]
	fadd	d18, d4, d5
	fsub	d4, d4, d5
	fadd	d2, d0, d1
	fsub	d0, d0, d1
	ldp	d1, d3, [x12, #-16]
	add	x12, x17, x19
	add	x19, x19, #16
	fneg	d6, d2
	fneg	d7, d0
	ldp	d16, d17, [x12, #-16]
	fmul	d2, d1, d2
	fmul	d6, d3, d6
	fmul	d0, d0, d16
	fmul	d5, d17, d7
	fmadd	d2, d18, d3, d2
	fmadd	d1, d18, d1, d6
	fmadd	d0, d4, d17, d0
	fmadd	d3, d4, d16, d5
	str	d2, [x9]
	stur	d1, [x9, #-8]
	str	d0, [x11]
	stur	d3, [x11, #-8]
	b.ne	.LBB113_135
.LBB113_136:                            //   in Loop: Header=BB113_132 Depth=2
	add	x21, x21, #1
	add	x23, x23, x2
	add	x24, x24, x2
	add	x0, x0, x2
	add	x26, x26, x2
	cmp	x21, x28
	b.ne	.LBB113_132
	b	.LBB113_129
.LBB113_137:                            //   in Loop: Header=BB113_132 Depth=2
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	mul	x5, x21, x22
	add	x13, x9, x5
	ldur	x9, [x29, #-40]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #4
	add	x14, x9, x5
	add	x1, x13, #8
	add	x6, x27, x14, lsl #4
	add	x14, x1, x16
	add	x7, x6, #8
	cmp	x14, x1
	add	x14, x13, x16
	cset	w1, lo
	cmp	x14, x13
	add	x13, x7, x16
	cset	w14, lo
	cmp	x13, x7
	add	x13, x6, x16
	orr	w19, w1, w15
	cset	w1, lo
	cmp	x13, x6
	cset	w13, lo
	tbnz	w19, #0, .LBB113_133
// %bb.138:                             //   in Loop: Header=BB113_132 Depth=2
	orr	w14, w14, w15
	tbnz	w14, #0, .LBB113_133
// %bb.139:                             //   in Loop: Header=BB113_132 Depth=2
	orr	w14, w1, w15
	tbnz	w14, #0, .LBB113_133
// %bb.140:                             //   in Loop: Header=BB113_132 Depth=2
	orr	w13, w13, w15
	mov	w19, #1
	tbnz	w13, #0, .LBB113_134
// %bb.141:                             //   in Loop: Header=BB113_132 Depth=2
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x14, x10, x5
	add	x14, x27, x14, lsl #4
	add	x13, x9, x5
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #4
	add	x1, x9, x5
	ldur	x9, [x29, #-72]                 // 8-byte Folded Reload
	sub	x5, x5, x10
	add	x6, x13, #8
	add	x1, x27, x1, lsl #4
	add	x14, x14, x9
	ldur	x9, [x29, #-80]                 // 8-byte Folded Reload
	add	x5, x27, x5, lsl #4
	sub	x7, x14, #8
	cmp	x14, x13
	add	x11, x1, #8
	add	x9, x5, x9
	cset	w5, hi
	sub	x27, x9, #8
	cmp	x7, x6
	cset	w19, hi
	cmp	x27, x13
	and	w12, w5, w19
	cset	w5, hi
	cmp	x7, x1
	cset	w20, hi
	cmp	x9, x13
	cset	w19, hi
	cmp	x7, x11
	cset	w28, hi
	cmp	x27, x6
	cset	w22, hi
	cmp	x14, x1
	cset	w7, hi
	cmp	x9, x6
	cset	w6, hi
	cmp	x14, x11
	cset	w13, hi
	cmp	x9, x1
	cset	w14, hi
	cmp	x27, x11
	cset	w1, hi
	tbnz	w12, #0, .LBB113_151
// %bb.142:                             //   in Loop: Header=BB113_132 Depth=2
	and	w9, w5, w20
	tbnz	w9, #0, .LBB113_151
// %bb.143:                             //   in Loop: Header=BB113_132 Depth=2
	and	w9, w19, w28
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	ldur	x20, [x29, #-128]               // 8-byte Folded Reload
	tbnz	w9, #0, .LBB113_152
// %bb.144:                             //   in Loop: Header=BB113_132 Depth=2
	and	w9, w22, w7
	ldur	x28, [x29, #-96]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB113_150
// %bb.145:                             //   in Loop: Header=BB113_132 Depth=2
	and	w9, w6, w13
	ldur	x22, [x29, #-88]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB113_133
// %bb.146:                             //   in Loop: Header=BB113_132 Depth=2
	and	w9, w14, w1
	mov	w19, #1
	tbnz	w9, #0, .LBB113_134
// %bb.147:                             //   in Loop: Header=BB113_132 Depth=2
	ldur	x19, [x29, #-104]               // 8-byte Folded Reload
	mov	x22, x20
	mov	x20, x24
	mov	x28, x23
	mov	x5, x17
.LBB113_148:                            //   Parent Loop BB113_130 Depth=1
                                        //     Parent Loop BB113_132 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.2d, v1.2d }, [x28]
	subs	x19, x19, #2
	ld2	{ v2.2d, v3.2d }, [x20]
	ld2	{ v6.2d, v7.2d }, [x22], #32
	fadd	v4.2d, v1.2d, v3.2d
	fadd	v16.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fneg	v5.2d, v4.2d
	fmul	v17.2d, v7.2d, v5.2d
	fmla	v17.2d, v6.2d, v16.2d
	fmul	v18.2d, v6.2d, v4.2d
	fsub	v4.2d, v1.2d, v3.2d
	fmla	v18.2d, v7.2d, v16.2d
	fneg	v5.2d, v4.2d
	st2	{ v17.2d, v18.2d }, [x28], #32
	ld2	{ v1.2d, v2.2d }, [x5], #32
	fmul	v5.2d, v2.2d, v5.2d
	fmla	v5.2d, v1.2d, v0.2d
	fmul	v6.2d, v4.2d, v1.2d
	fmla	v6.2d, v2.2d, v0.2d
	st2	{ v5.2d, v6.2d }, [x20], #32
	b.ne	.LBB113_148
// %bb.149:                             //   in Loop: Header=BB113_132 Depth=2
	ldp	x19, x9, [x29, #-112]           // 16-byte Folded Reload
	ldp	x28, x22, [x29, #-96]           // 16-byte Folded Reload
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	ldur	x20, [x29, #-128]               // 8-byte Folded Reload
	cmp	x8, x9
	b.ne	.LBB113_134
	b	.LBB113_136
.LBB113_150:                            //   in Loop: Header=BB113_132 Depth=2
	ldur	x22, [x29, #-88]                // 8-byte Folded Reload
	b	.LBB113_133
.LBB113_151:                            //   in Loop: Header=BB113_132 Depth=2
	ldp	x28, x22, [x29, #-96]           // 16-byte Folded Reload
	mov	w19, #1
	ldur	x27, [x29, #-56]                // 8-byte Folded Reload
	ldur	x20, [x29, #-128]               // 8-byte Folded Reload
	b	.LBB113_134
.LBB113_152:                            //   in Loop: Header=BB113_132 Depth=2
	ldp	x28, x22, [x29, #-96]           // 16-byte Folded Reload
	b	.LBB113_133
.LBB113_153:                            //   in Loop: Header=BB113_130 Depth=1
	mov	x10, xzr
	mov	x11, x28
	ldur	x20, [x29, #-128]               // 8-byte Folded Reload
.LBB113_154:                            //   Parent Loop BB113_130 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x12, x4, x10
	add	x13, x3, x10
	subs	x11, x11, #1
	add	x10, x10, x2
	ldp	d0, d1, [x12, #-8]
	ldp	d2, d3, [x13]
	fadd	d4, d0, d2
	fsub	d0, d0, d2
	fadd	d5, d1, d3
	fsub	d1, d1, d3
	stur	d4, [x12, #-8]
	str	d5, [x12]
	str	d0, [x13]
	str	d1, [x13, #8]
	b.ne	.LBB113_154
	b	.LBB113_129
.LBB113_155:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end113:
	.size	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_, .Lfunc_end113-_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIdEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail11pocketfft_cIdED2Ev,"axG",@progbits,_ZN9pocketfft6detail11pocketfft_cIdED2Ev,comdat
	.weak	_ZN9pocketfft6detail11pocketfft_cIdED2Ev // -- Begin function _ZN9pocketfft6detail11pocketfft_cIdED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail11pocketfft_cIdED2Ev,@function
_ZN9pocketfft6detail11pocketfft_cIdED2Ev: // @_ZN9pocketfft6detail11pocketfft_cIdED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0, #8]
	cbz	x20, .LBB114_8
// %bb.1:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB114_3
// %bb.2:
	ldur	x0, [x8, #-8]
	bl	free
.LBB114_3:
	ldr	x0, [x20, #40]
	cbz	x0, .LBB114_5
// %bb.4:
	bl	_ZdlPv
.LBB114_5:
	ldr	x8, [x20, #24]
	cbz	x8, .LBB114_7
// %bb.6:
	ldur	x0, [x8, #-8]
	bl	free
.LBB114_7:
	mov	x0, x20
	bl	_ZdlPv
.LBB114_8:
	ldr	x20, [x19]
	str	xzr, [x19, #8]
	cbz	x20, .LBB114_14
// %bb.9:
	ldr	x0, [x20, #24]
	cbz	x0, .LBB114_11
// %bb.10:
	bl	_ZdlPv
.LBB114_11:
	ldr	x8, [x20, #8]
	cbz	x8, .LBB114_13
// %bb.12:
	ldur	x0, [x8, #-8]
	bl	free
.LBB114_13:
	mov	x0, x20
	bl	_ZdlPv
.LBB114_14:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end114:
	.size	_ZN9pocketfft6detail11pocketfft_cIdED2Ev, .Lfunc_end114-_ZN9pocketfft6detail11pocketfft_cIdED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,"axG",@progbits,_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,comdat
	.weak	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv // -- Begin function _ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
	.p2align	2
	.type	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,@function
_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv: // @_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.Lfunc_begin39:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception39
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #128]            // 16-byte Folded Spill
	add	x29, sp, #128
	str	x23, [sp, #144]                 // 8-byte Folded Spill
	stp	x22, x21, [sp, #160]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x8, x9, [x0]
	mov	x19, x0
	ldp	x15, x10, [x8]
	ldr	x9, [x9]
	cmp	x15, x10
	b.eq	.LBB115_3
// %bb.1:
	sub	x11, x10, x15
	sub	x11, x11, #8
	cmp	x11, #8
	b.hs	.LBB115_4
// %bb.2:
	mov	w12, #1
	mov	x11, x15
	b	.LBB115_7
.LBB115_3:
	mov	w12, #1
	b	.LBB115_8
.LBB115_4:
	lsr	x11, x11, #3
	mov	w12, #1
	add	x13, x11, #1
	mov	w17, #1
	and	x14, x13, #0x3ffffffffffffffe
	mov	x16, x14
	add	x11, x15, x14, lsl #3
	add	x15, x15, #8
.LBB115_5:                              // =>This Inner Loop Header: Depth=1
	ldp	x18, x0, [x15, #-8]
	add	x15, x15, #16
	subs	x16, x16, #2
	mul	x12, x18, x12
	mul	x17, x0, x17
	b.ne	.LBB115_5
// %bb.6:
	mul	x12, x17, x12
	cmp	x13, x14
	b.eq	.LBB115_8
.LBB115_7:                              // =>This Inner Loop Header: Depth=1
	ldr	x13, [x11], #8
	cmp	x11, x10
	mul	x12, x13, x12
	b.ne	.LBB115_7
.LBB115_8:
	udiv	x10, x12, x9
	cmp	x10, #1
	mov	w10, #1
	cinc	x10, x10, hi
	mul	x9, x9, x10
	lsl	x9, x9, #4
	cbz	x9, .LBB115_11
// %bb.9:
	add	x0, x9, #64
	bl	malloc
	cbz	x0, .LBB115_45
// %bb.10:
	add	x8, x0, #64
	and	x20, x8, #0xffffffffffffffc0
	stur	x0, [x20, #-8]
	ldr	x8, [x19]
	b	.LBB115_12
.LBB115_11:
	mov	x20, xzr
.LBB115_12:
	ldp	x9, x2, [x19, #16]
	ldr	x10, [x19, #32]
	ldr	x9, [x9]
	ldr	x10, [x10]
	cmp	x9, #0
	ldr	x3, [x10, x9, lsl #3]
	csel	x21, x8, x2, eq
.Ltmp565:
	add	x0, sp, #8
	mov	x1, x21
	bl	_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m
.Ltmp566:
// %bb.13:
	ldr	x8, [sp, #120]
	cmp	x8, #2
	b.lo	.LBB115_24
// %bb.14:
	add	x22, x20, #16
	b	.LBB115_16
.LBB115_15:                             //   in Loop: Header=BB115_16 Depth=1
	ldr	x8, [sp, #120]
	cmp	x8, #1
	b.ls	.LBB115_24
.LBB115_16:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB115_19 Depth 2
                                        //     Child Loop BB115_23 Depth 2
.Ltmp568:
	add	x0, sp, #8
	mov	w1, #2
	bl	_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm
.Ltmp569:
// %bb.17:                              //   in Loop: Header=BB115_16 Depth=1
	ldr	x9, [sp, #32]
	ldp	x8, x10, [x19, #40]
	ldr	x11, [sp, #112]
	ldr	x9, [x9]
	ldr	x12, [x19, #56]
	ldr	x9, [x9, x11, lsl #3]
	ldr	x23, [x19, #24]
	ldr	x0, [x10]
	ldr	d0, [x12]
	cbz	x9, .LBB115_20
// %bb.18:                              //   in Loop: Header=BB115_16 Depth=1
	ldr	x13, [sp, #56]
	mov	x14, x22
	ldp	x12, x10, [sp, #64]
	ldr	x11, [x21, #48]
	add	x13, x13, #8
.LBB115_19:                             //   Parent Loop BB115_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x15, x11, x13
	add	x16, x11, x12
	subs	x9, x9, #1
	add	x11, x11, x10
	ldp	d1, d2, [x15, #-8]
	ld1	{ v1.d }[1], [x16], #8
	ld1	{ v2.d }[1], [x16]
	stp	q1, q2, [x14, #-16]
	add	x14, x14, #32
	b.ne	.LBB115_19
.LBB115_20:                             //   in Loop: Header=BB115_16 Depth=1
	ldrb	w2, [x8]
.Ltmp571:
	mov	x1, x20
	bl	_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb
.Ltmp572:
// %bb.21:                              //   in Loop: Header=BB115_16 Depth=1
	ldr	x8, [sp, #40]
	ldr	x9, [sp, #112]
	ldr	x8, [x8]
	ldr	x8, [x8, x9, lsl #3]
	cbz	x8, .LBB115_15
// %bb.22:                              //   in Loop: Header=BB115_16 Depth=1
	ldp	x13, x9, [sp, #96]
	mov	x12, x22
	ldr	x10, [x23, #48]
	ldr	x11, [sp, #88]
.LBB115_23:                             //   Parent Loop BB115_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x12, #-16]
	subs	x8, x8, #1
	add	x12, x12, #32
	zip1	v2.2d, v0.2d, v1.2d
	zip2	v0.2d, v0.2d, v1.2d
	str	q2, [x10, x11]
	str	q0, [x10, x13]
	add	x10, x10, x9
	b.ne	.LBB115_23
	b	.LBB115_15
.LBB115_24:
	cbnz	x8, .LBB115_31
.LBB115_25:
	ldr	x0, [sp, #8]
	cbz	x0, .LBB115_27
// %bb.26:
	bl	_ZdlPv
.LBB115_27:
	cbz	x20, .LBB115_29
// %bb.28:
	ldur	x0, [x20, #-8]
	bl	free
.LBB115_29:
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #128]            // 16-byte Folded Reload
	ldr	x23, [sp, #144]                 // 8-byte Folded Reload
	add	sp, sp, #192
	ret
.LBB115_30:                             //   in Loop: Header=BB115_31 Depth=1
	ldr	x8, [sp, #120]
	cbz	x8, .LBB115_25
.LBB115_31:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB115_38 Depth 2
                                        //     Child Loop BB115_44 Depth 2
.Ltmp574:
	add	x0, sp, #8
	mov	w1, #1
	bl	_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm
.Ltmp575:
// %bb.32:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	x8, [x19, #64]
	mov	x22, x20
	ldr	x23, [x19, #24]
	ldrb	w8, [x8]
	cbz	w8, .LBB115_35
// %bb.33:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	x8, [sp, #104]
	mov	x22, x20
	cmp	x8, #16
	b.ne	.LBB115_35
// %bb.34:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	x8, [sp, #88]
	ldr	x9, [x23, #48]
	add	x22, x9, x8
.LBB115_35:                             //   in Loop: Header=BB115_31 Depth=1
	ldp	x9, x10, [x19, #48]
	ldr	x13, [sp, #56]
	ldr	x14, [x21, #48]
	ldr	x8, [x19, #40]
	ldr	x0, [x9]
	ldr	d0, [x10]
	add	x9, x14, x13
	cmp	x9, x22
	b.eq	.LBB115_39
// %bb.36:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	x9, [sp, #32]
	ldr	x10, [sp, #112]
	ldr	x11, [x9]
	ldr	x11, [x11, x10, lsl #3]
	cbz	x11, .LBB115_39
// %bb.37:                              //   in Loop: Header=BB115_31 Depth=1
	mov	x11, xzr
	ldr	x12, [sp, #72]
	add	x13, x14, x13
	mov	x14, x22
.LBB115_38:                             //   Parent Loop BB115_31 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	q1, [x13]
	add	x11, x11, #1
	add	x13, x13, x12
	str	q1, [x14], #16
	ldr	x15, [x9]
	ldr	x15, [x15, x10, lsl #3]
	cmp	x11, x15
	b.lo	.LBB115_38
.LBB115_39:                             //   in Loop: Header=BB115_31 Depth=1
	ldrb	w2, [x8]
.Ltmp577:
	mov	x1, x22
	bl	_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb
.Ltmp578:
// %bb.40:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	x8, [sp, #88]
	ldr	x9, [x23, #48]
	add	x8, x9, x8
	cmp	x8, x22
	b.eq	.LBB115_30
// %bb.41:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	x9, [sp, #40]
	ldr	x10, [sp, #112]
	ldr	x9, [x9]
	ldr	x9, [x9, x10, lsl #3]
	cbz	x9, .LBB115_30
// %bb.42:                              //   in Loop: Header=BB115_31 Depth=1
	ldr	q0, [x22]
	str	q0, [x8]
	ldr	x8, [sp, #40]
	ldr	x9, [sp, #112]
	ldr	x8, [x8]
	ldr	x8, [x8, x9, lsl #3]
	cmp	x8, #2
	b.lo	.LBB115_30
// %bb.43:                              //   in Loop: Header=BB115_31 Depth=1
	add	x8, x22, #16
	mov	w9, #1
.LBB115_44:                             //   Parent Loop BB115_31 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x10, [sp, #88]
	ldr	x11, [sp, #104]
	ldr	q0, [x8], #16
	madd	x10, x11, x9, x10
	ldr	x11, [x23, #48]
	add	x9, x9, #1
	str	q0, [x11, x10]
	ldr	x10, [sp, #40]
	ldr	x11, [sp, #112]
	ldr	x10, [x10]
	ldr	x10, [x10, x11, lsl #3]
	cmp	x9, x10
	b.lo	.LBB115_44
	b	.LBB115_30
.LBB115_45:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB115_46:
.Ltmp567:
	mov	x19, x0
	cbz	x20, .LBB115_53
	b	.LBB115_55
.LBB115_47:
.Ltmp573:
	b	.LBB115_51
.LBB115_48:
.Ltmp570:
	b	.LBB115_51
.LBB115_49:
.Ltmp579:
	b	.LBB115_51
.LBB115_50:
.Ltmp576:
.LBB115_51:
	mov	x19, x0
	ldr	x0, [sp, #8]
	cbnz	x0, .LBB115_54
// %bb.52:
	cbnz	x20, .LBB115_55
.LBB115_53:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB115_54:
	bl	_ZdlPv
	cbz	x20, .LBB115_53
.LBB115_55:
	ldur	x0, [x20, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end115:
	.size	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv, .Lfunc_end115-_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
	.cfi_endproc
	.section	.gcc_except_table._ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,"aG",@progbits,_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,comdat
	.p2align	2
GCC_except_table115:
.Lexception39:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end39-.Lcst_begin39
.Lcst_begin39:
	.uleb128 .Ltmp565-.Lfunc_begin39        // >> Call Site 1 <<
	.uleb128 .Ltmp566-.Ltmp565              //   Call between .Ltmp565 and .Ltmp566
	.uleb128 .Ltmp567-.Lfunc_begin39        //     jumps to .Ltmp567
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp568-.Lfunc_begin39        // >> Call Site 2 <<
	.uleb128 .Ltmp569-.Ltmp568              //   Call between .Ltmp568 and .Ltmp569
	.uleb128 .Ltmp570-.Lfunc_begin39        //     jumps to .Ltmp570
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp571-.Lfunc_begin39        // >> Call Site 3 <<
	.uleb128 .Ltmp572-.Ltmp571              //   Call between .Ltmp571 and .Ltmp572
	.uleb128 .Ltmp573-.Lfunc_begin39        //     jumps to .Ltmp573
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp574-.Lfunc_begin39        // >> Call Site 4 <<
	.uleb128 .Ltmp575-.Ltmp574              //   Call between .Ltmp574 and .Ltmp575
	.uleb128 .Ltmp576-.Lfunc_begin39        //     jumps to .Ltmp576
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp577-.Lfunc_begin39        // >> Call Site 5 <<
	.uleb128 .Ltmp578-.Ltmp577              //   Call between .Ltmp577 and .Ltmp578
	.uleb128 .Ltmp579-.Lfunc_begin39        //     jumps to .Ltmp579
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp578-.Lfunc_begin39        // >> Call Site 6 <<
	.uleb128 .Lfunc_end115-.Ltmp578         //   Call between .Ltmp578 and .Lfunc_end115
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end39:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m,"axG",@progbits,_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m,comdat
	.weak	_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m // -- Begin function _ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m
	.p2align	2
	.type	_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m,@function
_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m: // @_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m
.Lfunc_begin40:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception40
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x10, x9, [x1]
	mov	x8, #-7
	movk	x8, #32767, lsl #48
	sub	x24, x9, x10
	cmp	x24, x8
	b.hs	.LBB116_22
// %bb.1:
	mov	x20, x3
	mov	x23, x2
	mov	x22, x1
	mov	x19, x0
	stp	xzr, xzr, [x0]
	str	xzr, [x0, #16]
	cbz	x24, .LBB116_3
// %bb.2:
	mov	x0, x24
	asr	x25, x24, #3
	bl	_Znwm
	and	x2, x24, #0xfffffffffffffff8
	add	x24, x0, x25, lsl #3
	mov	w1, wzr
	mov	x21, x0
	str	x0, [x19]
	str	x24, [x19, #16]
	bl	memset
	b	.LBB116_4
.LBB116_3:
	mov	x21, xzr
	stp	xzr, xzr, [x19]
	str	xzr, [x19, #16]
.LBB116_4:
	stp	x22, x23, [x19, #24]
	lsl	x10, x20, #3
	ldr	x8, [x22, #24]
	str	xzr, [x19, #40]
	ldr	x9, [x23, #24]
	str	x24, [x19, #8]
	ldr	x11, [x8, x10]
	stp	x11, xzr, [x19, #64]
	ldr	x12, [x9, x10]
	ldp	x10, x11, [x22]
	stp	x12, x20, [x19, #96]
	cmp	x10, x11
	b.eq	.LBB116_7
// %bb.5:
	sub	x12, x11, x10
	sub	x12, x12, #8
	cmp	x12, #8
	b.hs	.LBB116_8
// %bb.6:
	mov	w13, #1
	mov	x12, x10
	b	.LBB116_11
.LBB116_7:
	mov	w13, #1
	b	.LBB116_12
.LBB116_8:
	lsr	x12, x12, #3
	add	x16, x10, #8
	add	x14, x12, #1
	mov	w13, #1
	and	x15, x14, #0x3ffffffffffffffe
	mov	w18, #1
	mov	x17, x15
	add	x12, x10, x15, lsl #3
.LBB116_9:                              // =>This Inner Loop Header: Depth=1
	ldp	x0, x1, [x16, #-8]
	add	x16, x16, #16
	subs	x17, x17, #2
	mul	x13, x0, x13
	mul	x18, x1, x18
	b.ne	.LBB116_9
// %bb.10:
	mul	x13, x18, x13
	cmp	x14, x15
	b.eq	.LBB116_12
.LBB116_11:                             // =>This Inner Loop Header: Depth=1
	ldr	x14, [x12], #8
	cmp	x12, x11
	mul	x13, x14, x13
	b.ne	.LBB116_11
.LBB116_12:
	ldr	x11, [x10, x20, lsl #3]
	mrs	x14, TPIDR_EL0
	add	x12, x14, :tprel_hi12:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	add	x12, x12, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	udiv	x11, x13, x11
	ldr	x12, [x12]
	cmp	x12, #1
	str	x11, [x19, #112]
	b.eq	.LBB116_21
// %bb.13:
	cbz	x12, .LBB116_23
// %bb.14:
	add	x13, x14, :tprel_hi12:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x13, x13, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	ldr	x15, [x13]
	cmp	x15, x12
	b.hs	.LBB116_25
// %bb.15:
	udiv	x16, x11, x12
	msub	x17, x16, x12, x11
	cmp	x15, x17
	cinc	x12, x16, lo
	subs	x18, x24, x21
	b.eq	.LBB116_20
// %bb.16:
	cmp	x15, x17
	asr	x18, x18, #3
	csel	x17, x15, x17, lo
	cmp	x18, #1
	madd	x15, x16, x15, x17
	mov	x13, xzr
	mov	x14, xzr
	csinc	x16, x18, xzr, hi
	b	.LBB116_18
.LBB116_17:                             //   in Loop: Header=BB116_18 Depth=1
	sub	x16, x16, #1
	sub	x20, x20, #1
	add	x10, x10, #8
	add	x21, x21, #8
	add	x8, x8, #8
	add	x9, x9, #8
	cbz	x16, .LBB116_20
.LBB116_18:                             // =>This Inner Loop Header: Depth=1
	cbz	x20, .LBB116_17
// %bb.19:                              //   in Loop: Header=BB116_18 Depth=1
	ldr	x17, [x10]
	ldr	x18, [x21]
	udiv	x11, x11, x17
	udiv	x17, x15, x11
	add	x18, x18, x17
	msub	x15, x17, x11, x15
	str	x18, [x21]
	ldr	x18, [x8]
	madd	x14, x18, x17, x14
	str	x14, [x19, #40]
	ldr	x18, [x9]
	madd	x13, x18, x17, x13
	str	x13, [x19, #72]
	b	.LBB116_17
.LBB116_20:
	str	x12, [x19, #112]
.LBB116_21:
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB116_22:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.LBB116_23:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp580:
	adrp	x1, .L.str.9
	add	x1, x1, :lo12:.L.str.9
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp581:
// %bb.24:
.Ltmp583:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp584:
	b	.LBB116_27
.LBB116_25:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp586:
	adrp	x1, .L.str.10
	add	x1, x1, :lo12:.L.str.10
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp587:
// %bb.26:
.Ltmp589:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp590:
.LBB116_27:
.LBB116_28:
.Ltmp591:
	b	.LBB116_31
.LBB116_29:
.Ltmp588:
	b	.LBB116_33
.LBB116_30:
.Ltmp585:
.LBB116_31:
	mov	x20, x0
	b	.LBB116_34
.LBB116_32:
.Ltmp582:
.LBB116_33:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
.LBB116_34:
	ldr	x0, [x19]
	cbz	x0, .LBB116_36
// %bb.35:
	bl	_ZdlPv
.LBB116_36:
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end116:
	.size	_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m, .Lfunc_end116-_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m,"aG",@progbits,_ZN9pocketfft6detail10multi_iterILm2EEC2ERKNS0_8arr_infoES5_m,comdat
	.p2align	2
GCC_except_table116:
.Lexception40:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end40-.Lcst_begin40
.Lcst_begin40:
	.uleb128 .Lfunc_begin40-.Lfunc_begin40  // >> Call Site 1 <<
	.uleb128 .Ltmp580-.Lfunc_begin40        //   Call between .Lfunc_begin40 and .Ltmp580
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp580-.Lfunc_begin40        // >> Call Site 2 <<
	.uleb128 .Ltmp581-.Ltmp580              //   Call between .Ltmp580 and .Ltmp581
	.uleb128 .Ltmp582-.Lfunc_begin40        //     jumps to .Ltmp582
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp583-.Lfunc_begin40        // >> Call Site 3 <<
	.uleb128 .Ltmp584-.Ltmp583              //   Call between .Ltmp583 and .Ltmp584
	.uleb128 .Ltmp585-.Lfunc_begin40        //     jumps to .Ltmp585
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp584-.Lfunc_begin40        // >> Call Site 4 <<
	.uleb128 .Ltmp586-.Ltmp584              //   Call between .Ltmp584 and .Ltmp586
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp586-.Lfunc_begin40        // >> Call Site 5 <<
	.uleb128 .Ltmp587-.Ltmp586              //   Call between .Ltmp586 and .Ltmp587
	.uleb128 .Ltmp588-.Lfunc_begin40        //     jumps to .Ltmp588
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp589-.Lfunc_begin40        // >> Call Site 6 <<
	.uleb128 .Ltmp590-.Ltmp589              //   Call between .Ltmp589 and .Ltmp590
	.uleb128 .Ltmp591-.Lfunc_begin40        //     jumps to .Ltmp591
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp590-.Lfunc_begin40        // >> Call Site 7 <<
	.uleb128 .Lfunc_end116-.Ltmp590         //   Call between .Ltmp590 and .Lfunc_end116
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end40:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10multi_iterILm2EE7advanceEm,"axG",@progbits,_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm,comdat
	.weak	_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm // -- Begin function _ZN9pocketfft6detail10multi_iterILm2EE7advanceEm
	.p2align	2
	.type	_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm,@function
_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm: // @_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm
.Lfunc_begin41:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception41
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x8, [x0, #112]
	cmp	x8, x1
	b.lo	.LBB117_13
// %bb.1:
	cbz	x1, .LBB117_12
// %bb.2:
	ldp	x8, x9, [x0]
	sub	x10, x9, x8
	lsr	x9, x10, #3
	cmp	w9, #0
	b.le	.LBB117_10
// %bb.3:
	ubfx	x10, x10, #3, #32
	mov	x9, xzr
	add	x10, x10, #1
	b	.LBB117_5
.LBB117_4:                              //   in Loop: Header=BB117_5 Depth=1
	add	x9, x9, #1
	cmp	x9, x1
	b.eq	.LBB117_12
.LBB117_5:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB117_8 Depth 2
	ldr	x11, [x0, #40]
	add	x12, x0, x9, lsl #3
	mov	x13, x10
	str	x11, [x12, #48]
	ldr	x11, [x0, #72]
	str	x11, [x12, #80]
	ldp	x11, x12, [x0, #24]
	b	.LBB117_8
.LBB117_6:                              //   in Loop: Header=BB117_8 Depth=2
	str	xzr, [x8, x14]
	ldr	x17, [x17, x14]
	ldr	x16, [x16, x14]
	ldr	x18, [x0, #40]
	msub	x16, x16, x17, x18
	ldr	x17, [x12]
	str	x16, [x0, #40]
	ldr	x16, [x17, x14]
	ldr	x14, [x15, x14]
	ldr	x15, [x0, #72]
	msub	x14, x14, x16, x15
	str	x14, [x0, #72]
.LBB117_7:                              //   in Loop: Header=BB117_8 Depth=2
	sub	x13, x13, #1
	cmp	x13, #1
	b.ls	.LBB117_4
.LBB117_8:                              //   Parent Loop BB117_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x15, [x0, #104]
	sub	w14, w13, #2
	cmp	x15, x14
	b.eq	.LBB117_7
// %bb.9:                               //   in Loop: Header=BB117_8 Depth=2
	lsl	x14, x14, #3
	ldr	x16, [x11, #24]
	ldr	x17, [x0, #40]
	ldr	x18, [x0, #72]
	ldr	x15, [x16, x14]
	add	x17, x17, x15
	ldr	x15, [x12, #24]
	str	x17, [x0, #40]
	ldr	x17, [x15, x14]
	add	x17, x18, x17
	str	x17, [x0, #72]
	ldr	x17, [x8, x14]
	add	x18, x17, #1
	ldr	x17, [x11]
	str	x18, [x8, x14]
	ldr	x2, [x17, x14]
	cmp	x18, x2
	b.hs	.LBB117_6
	b	.LBB117_4
.LBB117_10:
	add	x8, x0, #80
	mov	x9, x1
.LBB117_11:                             // =>This Inner Loop Header: Depth=1
	ldr	x10, [x0, #40]
	subs	x9, x9, #1
	stur	x10, [x8, #-32]
	ldr	x10, [x0, #72]
	str	x10, [x8], #8
	b.ne	.LBB117_11
.LBB117_12:
	ldr	x8, [x0, #112]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	sub	x8, x8, x1
	str	x8, [x0, #112]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB117_13:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x19, x0
.Ltmp592:
	adrp	x1, .L.str.11
	add	x1, x1, :lo12:.L.str.11
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp593:
// %bb.14:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x19
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.LBB117_15:
.Ltmp594:
	mov	x20, x0
	mov	x0, x19
	bl	__cxa_free_exception
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end117:
	.size	_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm, .Lfunc_end117-_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10multi_iterILm2EE7advanceEm,"aG",@progbits,_ZN9pocketfft6detail10multi_iterILm2EE7advanceEm,comdat
	.p2align	2
GCC_except_table117:
.Lexception41:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end41-.Lcst_begin41
.Lcst_begin41:
	.uleb128 .Lfunc_begin41-.Lfunc_begin41  // >> Call Site 1 <<
	.uleb128 .Ltmp592-.Lfunc_begin41        //   Call between .Lfunc_begin41 and .Ltmp592
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp592-.Lfunc_begin41        // >> Call Site 2 <<
	.uleb128 .Ltmp593-.Ltmp592              //   Call between .Ltmp592 and .Ltmp593
	.uleb128 .Ltmp594-.Lfunc_begin41        //     jumps to .Ltmp594
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp593-.Lfunc_begin41        // >> Call Site 3 <<
	.uleb128 .Lfunc_end117-.Ltmp593         //   Call between .Ltmp593 and .Lfunc_end117
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end41:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb,"axG",@progbits,_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb,comdat
	.weak	_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb // -- Begin function _ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb
	.p2align	2
	.type	_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb,@function
_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb: // @_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	ldr	x0, [x0]
	cbz	x0, .LBB118_3
// %bb.1:
	tbz	w2, #0, .LBB118_5
// %bb.2:
	b	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d
.LBB118_3:
	ldr	x0, [x8, #8]
	tbz	w2, #0, .LBB118_6
// %bb.4:
	b	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd
.LBB118_5:
	b	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d
.LBB118_6:
	b	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd
.Lfunc_end118:
	.size	_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb, .Lfunc_end118-_ZNK9pocketfft6detail11pocketfft_cIdE4execIDv2_dEEvPNS0_5cmplxIT_EEdb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d // -- Begin function _ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,@function
_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d: // @_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d
.Lfunc_begin42:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception42
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	ldr	x23, [x0]
	mov	x20, x1
                                        // kill: def $d0 killed $d0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB119_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB119_4
// %bb.2:
	ldp	q0, q1, [x20]
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.2d, v0.2d, v2.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	stp	q0, q1, [x20]
	b	.LBB119_31
.LBB119_3:
	mov	x22, xzr
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.ne	.LBB119_6
	b	.LBB119_23
.LBB119_4:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB119_32
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.eq	.LBB119_23
.LBB119_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI119_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x20
	add	x27, x27, :lo12:.LJTI119_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB119_12
.LBB119_7:
	adr	x10, .LBB119_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB119_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp603:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp604:
	mov	x0, x21
	mov	x21, x22
	b	.LBB119_16
.LBB119_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp601:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp602:
	mov	x0, x21
	mov	x21, x22
	b	.LBB119_16
.LBB119_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp607:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp608:
	mov	x0, x21
	mov	x21, x22
	b	.LBB119_16
.LBB119_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp599:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp600:
	mov	x0, x21
	mov	x21, x22
	b	.LBB119_16
.LBB119_12:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp609:
	mov	x0, x19
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
.Ltmp610:
	mov	x0, x22
	b	.LBB119_16
.LBB119_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp597:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp598:
	mov	x0, x21
	mov	x21, x22
	b	.LBB119_16
.LBB119_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp605:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp606:
	mov	x0, x21
	mov	x21, x22
	b	.LBB119_16
.LBB119_15:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp595:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp596:
	mov	x0, x21
	mov	x21, x22
.LBB119_16:
	ldp	x8, x9, [x19, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB119_18
// %bb.17:
	ldr	x23, [x19]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB119_7
	b	.LBB119_12
.LBB119_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x20
	b.eq	.LBB119_23
// %bb.19:
	fmov	d0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x19]
	fcmp	d2, d0
	b.eq	.LBB119_27
// %bb.20:
	cbz	x8, .LBB119_29
// %bb.21:
	mov	x8, xzr
	add	x9, x20, #16
	add	x10, x22, #16
.LBB119_22:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-16]
	add	x8, x8, #1
	add	x10, x10, #32
	fmul	v0.2d, v0.2d, v2.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x11, [x19]
	cmp	x8, x11
	b.lo	.LBB119_22
	b	.LBB119_30
.LBB119_23:
	fmov	d0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fcmp	d2, d0
	b.eq	.LBB119_29
// %bb.24:
	ldr	x8, [x19]
	cbz	x8, .LBB119_29
// %bb.25:
	mov	x8, xzr
	add	x9, x20, #16
.LBB119_26:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	fmul	v0.2d, v0.2d, v2.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x10, [x19]
	cmp	x8, x10
	b.lo	.LBB119_26
	b	.LBB119_29
.LBB119_27:
	cbz	x8, .LBB119_29
// %bb.28:
	lsl	x2, x8, #5
	mov	x0, x20
	mov	x1, x21
	bl	memmove
.LBB119_29:
	cbz	x22, .LBB119_31
.LBB119_30:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB119_31:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB119_32:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB119_33:
.Ltmp611:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB119_35
// %bb.34:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB119_35:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end119:
	.size	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d, .Lfunc_end119-_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,comdat
.LJTI119_0:
	.byte	(.LBB119_8-.LBB119_8)>>2
	.byte	(.LBB119_9-.LBB119_8)>>2
	.byte	(.LBB119_10-.LBB119_8)>>2
	.byte	(.LBB119_11-.LBB119_8)>>2
	.byte	(.LBB119_12-.LBB119_8)>>2
	.byte	(.LBB119_13-.LBB119_8)>>2
	.byte	(.LBB119_14-.LBB119_8)>>2
	.byte	(.LBB119_12-.LBB119_8)>>2
	.byte	(.LBB119_12-.LBB119_8)>>2
	.byte	(.LBB119_15-.LBB119_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d,comdat
	.p2align	2
GCC_except_table119:
.Lexception42:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end42-.Lcst_begin42
.Lcst_begin42:
	.uleb128 .Ltmp603-.Lfunc_begin42        // >> Call Site 1 <<
	.uleb128 .Ltmp596-.Ltmp603              //   Call between .Ltmp603 and .Ltmp596
	.uleb128 .Ltmp611-.Lfunc_begin42        //     jumps to .Ltmp611
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp596-.Lfunc_begin42        // >> Call Site 2 <<
	.uleb128 .Lfunc_end119-.Ltmp596         //   Call between .Ltmp596 and .Lfunc_end119
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end42:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d // -- Begin function _ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,@function
_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d: // @_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d
.Lfunc_begin43:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception43
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	ldr	x23, [x0]
	mov	x20, x1
                                        // kill: def $d0 killed $d0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB120_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB120_4
// %bb.2:
	ldp	q0, q1, [x20]
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.2d, v0.2d, v2.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	stp	q0, q1, [x20]
	b	.LBB120_31
.LBB120_3:
	mov	x22, xzr
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.ne	.LBB120_6
	b	.LBB120_23
.LBB120_4:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB120_32
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.eq	.LBB120_23
.LBB120_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI120_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x20
	add	x27, x27, :lo12:.LJTI120_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB120_12
.LBB120_7:
	adr	x10, .LBB120_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB120_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp620:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp621:
	mov	x0, x21
	mov	x21, x22
	b	.LBB120_16
.LBB120_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp618:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp619:
	mov	x0, x21
	mov	x21, x22
	b	.LBB120_16
.LBB120_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp624:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp625:
	mov	x0, x21
	mov	x21, x22
	b	.LBB120_16
.LBB120_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp616:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp617:
	mov	x0, x21
	mov	x21, x22
	b	.LBB120_16
.LBB120_12:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp626:
	mov	x0, x19
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
.Ltmp627:
	mov	x0, x22
	b	.LBB120_16
.LBB120_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp614:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp615:
	mov	x0, x21
	mov	x21, x22
	b	.LBB120_16
.LBB120_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp622:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp623:
	mov	x0, x21
	mov	x21, x22
	b	.LBB120_16
.LBB120_15:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp612:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
.Ltmp613:
	mov	x0, x21
	mov	x21, x22
.LBB120_16:
	ldp	x8, x9, [x19, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB120_18
// %bb.17:
	ldr	x23, [x19]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB120_7
	b	.LBB120_12
.LBB120_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x20
	b.eq	.LBB120_23
// %bb.19:
	fmov	d0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x19]
	fcmp	d2, d0
	b.eq	.LBB120_27
// %bb.20:
	cbz	x8, .LBB120_29
// %bb.21:
	mov	x8, xzr
	add	x9, x20, #16
	add	x10, x22, #16
.LBB120_22:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-16]
	add	x8, x8, #1
	add	x10, x10, #32
	fmul	v0.2d, v0.2d, v2.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x11, [x19]
	cmp	x8, x11
	b.lo	.LBB120_22
	b	.LBB120_30
.LBB120_23:
	fmov	d0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fcmp	d2, d0
	b.eq	.LBB120_29
// %bb.24:
	ldr	x8, [x19]
	cbz	x8, .LBB120_29
// %bb.25:
	mov	x8, xzr
	add	x9, x20, #16
.LBB120_26:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	fmul	v0.2d, v0.2d, v2.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x10, [x19]
	cmp	x8, x10
	b.lo	.LBB120_26
	b	.LBB120_29
.LBB120_27:
	cbz	x8, .LBB120_29
// %bb.28:
	lsl	x2, x8, #5
	mov	x0, x20
	mov	x1, x21
	bl	memmove
.LBB120_29:
	cbz	x22, .LBB120_31
.LBB120_30:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB120_31:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB120_32:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB120_33:
.Ltmp628:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB120_35
// %bb.34:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB120_35:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end120:
	.size	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d, .Lfunc_end120-_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,comdat
.LJTI120_0:
	.byte	(.LBB120_8-.LBB120_8)>>2
	.byte	(.LBB120_9-.LBB120_8)>>2
	.byte	(.LBB120_10-.LBB120_8)>>2
	.byte	(.LBB120_11-.LBB120_8)>>2
	.byte	(.LBB120_12-.LBB120_8)>>2
	.byte	(.LBB120_13-.LBB120_8)>>2
	.byte	(.LBB120_14-.LBB120_8)>>2
	.byte	(.LBB120_12-.LBB120_8)>>2
	.byte	(.LBB120_12-.LBB120_8)>>2
	.byte	(.LBB120_15-.LBB120_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d,comdat
	.p2align	2
GCC_except_table120:
.Lexception43:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end43-.Lcst_begin43
.Lcst_begin43:
	.uleb128 .Ltmp620-.Lfunc_begin43        // >> Call Site 1 <<
	.uleb128 .Ltmp613-.Ltmp620              //   Call between .Ltmp620 and .Ltmp613
	.uleb128 .Ltmp628-.Lfunc_begin43        //     jumps to .Ltmp628
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp613-.Lfunc_begin43        // >> Call Site 2 <<
	.uleb128 .Lfunc_end120-.Ltmp613         //   Call between .Ltmp613 and .Lfunc_end120
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end43:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	str	x23, [sp, #-48]!                // 8-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	subs	x8, x1, #1
	b.ne	.LBB121_4
// %bb.1:
	cbz	x2, .LBB121_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #5
	lsl	x10, x10, #5
	lsl	x11, x2, #6
	add	x12, x3, #64
.LBB121_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x12, #-64]
	add	x13, x8, x11
	add	x14, x8, x9
	subs	x2, x2, #1
	ldp	q2, q3, [x12]
	fadd	v5.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	ldp	q6, q16, [x12, #-32]
	fadd	v7.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	ldp	q4, q2, [x12, #32]
	add	x12, x12, #128
	fadd	v17.2d, v6.2d, v4.2d
	fsub	v4.2d, v6.2d, v4.2d
	fadd	v3.2d, v16.2d, v2.2d
	fsub	v2.2d, v16.2d, v2.2d
	fsub	v16.2d, v5.2d, v17.2d
	fadd	v5.2d, v5.2d, v17.2d
	fsub	v6.2d, v7.2d, v3.2d
	fadd	v3.2d, v7.2d, v3.2d
	fadd	v17.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	stp	q16, q6, [x13, #-16]
	add	x13, x8, x10
	fsub	v16.2d, v1.2d, v4.2d
	stp	q5, q3, [x8, #-16]
	fadd	v1.2d, v1.2d, v4.2d
	add	x8, x8, #32
	stp	q17, q16, [x14, #-16]
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB121_3
	b	.LBB121_10
.LBB121_4:
	cbz	x2, .LBB121_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #96
	lsl	x10, x2, #1
	lsl	x15, x1, #5
	lsl	x18, x1, #4
	mov	x9, xzr
	madd	x14, x0, x14, x4
	add	x11, x3, #32
	add	x12, x10, x2
	lsl	x13, x1, #7
	sub	x16, x15, #32
	add	x17, x4, x0, lsl #6
	sub	x18, x18, #16
	add	x0, x4, x0, lsl #5
	mov	x6, x4
	b	.LBB121_7
.LBB121_6:                              //   in Loop: Header=BB121_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x13
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB121_10
.LBB121_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB121_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #5
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #5
	ldp	q0, q1, [x7]
	add	x7, x3, x20, lsl #5
	add	x20, x3, x21, lsl #5
	ldp	q2, q3, [x19]
	mul	x19, x9, x1
	fadd	v16.2d, v0.2d, v2.2d
	add	x19, x4, x19, lsl #5
	fsub	v0.2d, v0.2d, v2.2d
	ldp	q4, q5, [x7]
	fadd	v17.2d, v1.2d, v3.2d
	add	x7, x9, x10
	fsub	v1.2d, v1.2d, v3.2d
	mul	x7, x7, x1
	ldp	q6, q7, [x20]
	add	x7, x4, x7, lsl #5
	add	x20, x9, x2
	mul	x20, x20, x1
	fadd	v2.2d, v4.2d, v6.2d
	fsub	v4.2d, v4.2d, v6.2d
	fadd	v3.2d, v5.2d, v7.2d
	fsub	v5.2d, v5.2d, v7.2d
	fadd	v6.2d, v16.2d, v2.2d
	fsub	v2.2d, v16.2d, v2.2d
	fadd	v16.2d, v17.2d, v3.2d
	fsub	v3.2d, v17.2d, v3.2d
	stp	q6, q16, [x19]
	add	x19, x9, x12
	stp	q2, q3, [x7]
	mul	x7, x19, x1
	add	x19, x4, x20, lsl #5
	fadd	v2.2d, v0.2d, v5.2d
	fsub	v3.2d, v1.2d, v4.2d
	fsub	v0.2d, v0.2d, v5.2d
	add	x7, x4, x7, lsl #5
	fadd	v1.2d, v1.2d, v4.2d
	stp	q2, q3, [x19]
	stp	q0, q1, [x7]
	b.lo	.LBB121_6
// %bb.8:                               //   in Loop: Header=BB121_7 Depth=1
	mov	x7, xzr
	mov	x19, x5
	mov	x20, x8
.LBB121_9:                              //   Parent Loop BB121_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x21, x11, x7
	ldr	d16, [x19, #8]
	add	x22, x21, x15
	subs	x20, x20, #1
	add	x23, x22, x15
	ldp	q0, q1, [x21]
	add	x21, x23, x15
	ldp	q2, q3, [x22]
	mov	x22, x19
	ldp	q6, q7, [x21]
	add	x21, x6, x7
	ldp	q4, q5, [x23]
	add	x23, x19, x18
	add	x19, x19, #16
	fadd	v17.2d, v0.2d, v4.2d
	fsub	v0.2d, v0.2d, v4.2d
	fsub	v4.2d, v3.2d, v7.2d
	fadd	v18.2d, v1.2d, v5.2d
	fsub	v1.2d, v1.2d, v5.2d
	fadd	v5.2d, v2.2d, v6.2d
	fsub	v2.2d, v2.2d, v6.2d
	fadd	v6.2d, v0.2d, v4.2d
	fadd	v3.2d, v3.2d, v7.2d
	fadd	v7.2d, v17.2d, v5.2d
	fsub	v19.2d, v1.2d, v2.2d
	fneg	v20.2d, v6.2d
	fadd	v21.2d, v18.2d, v3.2d
	fsub	v5.2d, v17.2d, v5.2d
	fmul	v22.2d, v19.2d, v16.d[0]
	fmul	v16.2d, v20.2d, v16.d[0]
	stp	q7, q21, [x21, #32]
	add	x21, x0, x7
	ld1r	{ v7.2d }, [x22], x16
	fmla	v22.2d, v7.2d, v6.2d
	fmla	v16.2d, v7.2d, v19.2d
	fsub	v3.2d, v18.2d, v3.2d
	fneg	v7.2d, v5.2d
	fsub	v0.2d, v0.2d, v4.2d
	stp	q22, q16, [x21, #32]
	add	x21, x17, x7
	ld1r	{ v6.2d }, [x23], #8
	fadd	v1.2d, v1.2d, v2.2d
	fneg	v2.2d, v0.2d
	ldr	d16, [x23]
	fmul	v17.2d, v3.2d, v16.d[0]
	fmul	v7.2d, v7.2d, v16.d[0]
	fmla	v17.2d, v6.2d, v5.2d
	fmla	v7.2d, v6.2d, v3.2d
	stp	q17, q7, [x21, #32]
	add	x21, x14, x7
	ld1r	{ v3.2d }, [x22], #8
	add	x7, x7, #32
	ldr	d4, [x22]
	fmul	v5.2d, v1.2d, v4.d[0]
	fmul	v2.2d, v2.2d, v4.d[0]
	fmla	v5.2d, v3.2d, v0.2d
	fmla	v2.2d, v3.2d, v1.2d
	stp	q5, q2, [x21, #32]
	b.ne	.LBB121_9
	b	.LBB121_6
.LBB121_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp], #48                  // 8-byte Folded Reload
	ret
.Lfunc_end121:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end121-_ZNK9pocketfft6detail5cfftpIdE5pass4ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	str	d14, [sp, #80]                  // 8-byte Folded Spill
	stp	d13, d12, [sp, #96]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #112]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 240
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -160
	subs	x8, x1, #1
	str	x4, [sp, #72]                   // 8-byte Folded Spill
	str	x3, [sp, #88]                   // 8-byte Folded Spill
	b.ne	.LBB122_4
// %bb.1:
	cbz	x2, .LBB122_10
// %bb.2:
	mov	x17, #15309
	mov	w10, #224
	movk	x17, #26239, lsl #16
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	movk	x17, #41118, lsl #32
	ldr	x15, [sp, #88]                  // 8-byte Folded Reload
	movk	x17, #16358, lsl #48
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	mul	x10, x2, x10
	add	x8, x8, #16
	lsl	x9, x13, #5
	lsl	x11, x11, #5
	lsl	x12, x2, #5
	lsl	x13, x13, #6
	lsl	x14, x2, #6
	lsl	x16, x2, #7
	add	x15, x15, #128
	dup	v0.2d, x17
.LBB122_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q1, q2, [x15, #-96]
	add	x17, x8, x16
	add	x18, x8, x13
	subs	x2, x2, #1
	ldp	q3, q4, [x15, #32]
	fadd	v6.2d, v1.2d, v3.2d
	fsub	v3.2d, v1.2d, v3.2d
	ldp	q5, q7, [x15, #-32]
	fadd	v16.2d, v2.2d, v4.2d
	fsub	v1.2d, v2.2d, v4.2d
	ldp	q17, q18, [x15, #96]
	fadd	v2.2d, v5.2d, v17.2d
	fsub	v5.2d, v5.2d, v17.2d
	fadd	v4.2d, v7.2d, v18.2d
	ldp	q19, q17, [x15, #-128]
	fsub	v7.2d, v7.2d, v18.2d
	fadd	v20.2d, v6.2d, v2.2d
	fadd	v22.2d, v16.2d, v4.2d
	fsub	v2.2d, v6.2d, v2.2d
	fsub	v4.2d, v16.2d, v4.2d
	ldp	q18, q21, [x15]
	fadd	v27.2d, v3.2d, v7.2d
	fsub	v28.2d, v1.2d, v5.2d
	fsub	v3.2d, v3.2d, v7.2d
	fadd	v24.2d, v19.2d, v18.2d
	fsub	v18.2d, v19.2d, v18.2d
	ldp	q23, q25, [x15, #64]
	fadd	v29.2d, v17.2d, v21.2d
	fadd	v7.2d, v28.2d, v27.2d
	fsub	v17.2d, v17.2d, v21.2d
	fsub	v27.2d, v28.2d, v27.2d
	fadd	v1.2d, v1.2d, v5.2d
	ldp	q6, q16, [x15, #-64]
	fmul	v7.2d, v7.2d, v0.2d
	add	x15, x15, #256
	fneg	v5.2d, v3.2d
	fsub	v3.2d, v1.2d, v3.2d
	fadd	v26.2d, v6.2d, v23.2d
	fsub	v6.2d, v6.2d, v23.2d
	fadd	v31.2d, v16.2d, v25.2d
	fsub	v16.2d, v16.2d, v25.2d
	fadd	v30.2d, v24.2d, v26.2d
	fsub	v21.2d, v24.2d, v26.2d
	fadd	v9.2d, v29.2d, v31.2d
	fsub	v24.2d, v29.2d, v31.2d
	fsub	v8.2d, v30.2d, v20.2d
	fsub	v23.2d, v17.2d, v6.2d
	fsub	v19.2d, v9.2d, v22.2d
	fsub	v25.2d, v24.2d, v2.2d
	fadd	v2.2d, v2.2d, v24.2d
	fsub	v1.2d, v5.2d, v1.2d
	stp	q8, q19, [x17, #-16]
	add	x17, x8, x14
	fadd	v19.2d, v4.2d, v21.2d
	fsub	v4.2d, v21.2d, v4.2d
	fadd	v21.2d, v18.2d, v16.2d
	fmul	v1.2d, v1.2d, v0.2d
	stp	q19, q25, [x17, #-16]
	add	x17, x8, x12
	fmul	v19.2d, v27.2d, v0.2d
	stp	q4, q2, [x18, #-16]
	fadd	v4.2d, v7.2d, v21.2d
	add	x18, x8, x11
	fadd	v5.2d, v17.2d, v6.2d
	fadd	v6.2d, v20.2d, v30.2d
	fadd	v2.2d, v19.2d, v23.2d
	stp	q4, q2, [x17, #-16]
	fsub	v4.2d, v21.2d, v7.2d
	stur	q6, [x8, #-16]
	add	x17, x8, x9
	fmul	v2.2d, v3.2d, v0.2d
	stur	q4, [x18, #-16]
	fsub	v3.2d, v18.2d, v16.2d
	fsub	v4.2d, v23.2d, v19.2d
	fadd	v6.2d, v22.2d, v9.2d
	fadd	v7.2d, v2.2d, v3.2d
	str	q4, [x18]
	fadd	v4.2d, v1.2d, v5.2d
	fsub	v2.2d, v3.2d, v2.2d
	fsub	v1.2d, v5.2d, v1.2d
	stp	q7, q4, [x17, #-16]
	add	x17, x8, x10
	str	q6, [x8], #32
	stp	q2, q1, [x17, #-16]
	b.ne	.LBB122_3
	b	.LBB122_10
.LBB122_4:
	stp	x5, x8, [sp, #8]                // 16-byte Folded Spill
	cbz	x2, .LBB122_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x10, x2, #2
	add	x11, x8, x2
	ldr	x3, [sp, #88]                   // 8-byte Folded Reload
	ldr	x14, [sp, #16]                  // 8-byte Folded Reload
	lsl	x16, x1, #5
	stp	x10, x8, [sp, #56]              // 16-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	str	x11, [sp, #48]                  // 8-byte Folded Spill
	lsl	x11, x11, #1
	add	x10, x10, x2
	add	x12, x16, x3
	ldr	x4, [sp, #72]                   // 8-byte Folded Reload
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	mov	w8, #160
	stp	x10, x11, [sp, #32]             // 16-byte Folded Spill
	mul	x10, x2, x1
	madd	x13, x14, x8, x3
	mov	w11, #224
	add	x18, x12, #48
	mov	w12, #96
	add	x6, x13, #208
	add	x13, x1, x1, lsl #1
	lsl	x7, x13, #5
	madd	x17, x10, x11, x4
	madd	x11, x1, x11, x3
	mov	x9, xzr
	madd	x19, x10, x12, x4
	add	x12, x7, x3
	add	x20, x12, #48
	mov	w12, #192
	add	x21, x11, #48
	add	x11, x3, x14, lsl #7
	madd	x22, x10, x8, x4
	add	x23, x11, #128
	add	x8, x3, x14, lsl #6
	madd	x11, x14, x12, x3
	add	x24, x8, #64
	mov	w8, #80
	madd	x26, x10, x12, x4
	mov	x12, #15309
	add	x25, x11, #192
	mov	w11, #48
	movk	x12, #26239, lsl #16
	mul	x8, x1, x8
	movk	x12, #41118, lsl #32
	mul	x11, x1, x11
	movk	x12, #16358, lsl #48
	sub	x30, x8, #80
	lsl	x8, x1, #4
	lsl	x0, x1, #8
	add	x27, x4, x10, lsl #5
	lsl	x28, x1, #6
	add	x29, x4, x10, lsl #6
	sub	x8, x8, #16
	add	x5, x4, x10, lsl #7
	sub	x13, x11, #48
	dup	v0.2d, x12
	b	.LBB122_7
.LBB122_6:                              //   in Loop: Header=BB122_7 Depth=1
	add	x9, x9, #1
	add	x17, x17, x16
	add	x18, x18, x0
	add	x6, x6, x0
	add	x19, x19, x16
	add	x20, x20, x0
	add	x21, x21, x0
	add	x22, x22, x16
	add	x3, x3, x0
	add	x23, x23, x0
	add	x24, x24, x0
	add	x25, x25, x0
	add	x4, x4, x16
	add	x27, x27, x16
	add	x26, x26, x16
	add	x29, x29, x16
	add	x5, x5, x16
	cmp	x9, x2
	b.eq	.LBB122_10
.LBB122_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB122_9 Depth 2
	mov	w10, #1
	mov	w11, #5
	bfi	x10, x9, #3, #61
	bfi	x11, x9, #3, #61
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	mov	w12, #3
	mul	x10, x10, x1
	mov	w15, #7
	mul	x11, x11, x1
	bfi	x12, x9, #3, #61
	bfi	x15, x9, #3, #61
	cmp	x1, #2
	add	x10, x14, x10, lsl #5
	mul	x12, x12, x1
	add	x11, x14, x11, lsl #5
	ldp	q1, q2, [x10]
	mul	x10, x15, x1
	add	x12, x14, x12, lsl #5
	add	x10, x14, x10, lsl #5
	ldp	q3, q4, [x11]
	lsl	x11, x9, #3
	fadd	v7.2d, v1.2d, v3.2d
	fsub	v18.2d, v1.2d, v3.2d
	ldp	q5, q6, [x12]
	mov	w12, #2
	fadd	v16.2d, v2.2d, v4.2d
	bfi	x12, x9, #3, #61
	fsub	v4.2d, v2.2d, v4.2d
	mul	x12, x12, x1
	ldp	q17, q1, [x10]
	mul	x10, x11, x1
	mov	w11, #4
	bfi	x11, x9, #3, #61
	add	x12, x14, x12, lsl #5
	fadd	v19.2d, v5.2d, v17.2d
	add	x10, x14, x10, lsl #5
	fsub	v5.2d, v5.2d, v17.2d
	mul	x11, x11, x1
	fadd	v20.2d, v6.2d, v1.2d
	fsub	v6.2d, v6.2d, v1.2d
	fadd	v3.2d, v7.2d, v19.2d
	add	x11, x14, x11, lsl #5
	fsub	v1.2d, v7.2d, v19.2d
	ldp	q19, q21, [x10]
	mov	w10, #6
	bfi	x10, x9, #3, #61
	fadd	v7.2d, v18.2d, v6.2d
	mul	x10, x10, x1
	fsub	v17.2d, v4.2d, v5.2d
	fadd	v2.2d, v16.2d, v20.2d
	add	x10, x14, x10, lsl #5
	ldr	x14, [sp, #72]                  // 8-byte Folded Reload
	fsub	v16.2d, v16.2d, v20.2d
	fsub	v6.2d, v18.2d, v6.2d
	fadd	v4.2d, v4.2d, v5.2d
	fadd	v5.2d, v17.2d, v7.2d
	ldp	q18, q20, [x11]
	fsub	v7.2d, v17.2d, v7.2d
	fsub	v22.2d, v4.2d, v6.2d
	fneg	v6.2d, v6.2d
	fadd	v25.2d, v19.2d, v18.2d
	fmul	v5.2d, v5.2d, v0.2d
	ldp	q17, q23, [x12]
	fadd	v27.2d, v21.2d, v20.2d
	fsub	v4.2d, v6.2d, v4.2d
	fsub	v6.2d, v19.2d, v18.2d
	fsub	v20.2d, v21.2d, v20.2d
	fmul	v7.2d, v7.2d, v0.2d
	ldp	q24, q26, [x10]
	mul	x10, x9, x1
	fadd	v28.2d, v17.2d, v24.2d
	add	x10, x14, x10, lsl #5
	fadd	v29.2d, v23.2d, v26.2d
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	fsub	v21.2d, v23.2d, v26.2d
	ldr	x12, [sp, #40]                  // 8-byte Folded Reload
	fadd	v18.2d, v25.2d, v28.2d
	add	x11, x9, x11
	fadd	v19.2d, v27.2d, v29.2d
	add	x12, x9, x12
	mul	x11, x11, x1
	fadd	v23.2d, v3.2d, v18.2d
	fsub	v3.2d, v18.2d, v3.2d
	fadd	v26.2d, v2.2d, v19.2d
	add	x11, x14, x11, lsl #5
	fsub	v2.2d, v19.2d, v2.2d
	stp	q23, q26, [x10]
	ldr	x10, [sp, #64]                  // 8-byte Folded Reload
	fsub	v23.2d, v25.2d, v28.2d
	stp	q3, q2, [x11]
	fsub	v25.2d, v27.2d, v29.2d
	mul	x11, x12, x1
	add	x10, x9, x10
	ldr	x12, [sp, #32]                  // 8-byte Folded Reload
	fsub	v3.2d, v17.2d, v24.2d
	mul	x10, x10, x1
	add	x11, x14, x11, lsl #5
	fadd	v18.2d, v16.2d, v23.2d
	add	x12, x9, x12
	fsub	v19.2d, v25.2d, v1.2d
	add	x10, x14, x10, lsl #5
	fadd	v2.2d, v6.2d, v21.2d
	fsub	v17.2d, v20.2d, v3.2d
	stp	q18, q19, [x10]
	add	x10, x9, x2
	fsub	v16.2d, v23.2d, v16.2d
	fadd	v1.2d, v1.2d, v25.2d
	mul	x10, x10, x1
	fadd	v18.2d, v5.2d, v2.2d
	fadd	v19.2d, v7.2d, v17.2d
	add	x10, x14, x10, lsl #5
	stp	q16, q1, [x11]
	mul	x11, x12, x1
	ldr	x12, [sp, #24]                  // 8-byte Folded Reload
	stp	q18, q19, [x10]
	add	x10, x14, x11, lsl #5
	ldr	x11, [sp, #48]                  // 8-byte Folded Reload
	fmul	v1.2d, v4.2d, v0.2d
	add	x12, x9, x12
	fsub	v2.2d, v2.2d, v5.2d
	fsub	v4.2d, v17.2d, v7.2d
	add	x11, x9, x11
	fmul	v16.2d, v22.2d, v0.2d
	fsub	v5.2d, v6.2d, v21.2d
	mul	x11, x11, x1
	fadd	v3.2d, v20.2d, v3.2d
	stp	q2, q4, [x10]
	mul	x10, x12, x1
	add	x11, x14, x11, lsl #5
	fadd	v2.2d, v16.2d, v5.2d
	fadd	v4.2d, v1.2d, v3.2d
	add	x10, x14, x10, lsl #5
	fsub	v5.2d, v5.2d, v16.2d
	fsub	v1.2d, v3.2d, v1.2d
	stp	q2, q4, [x11]
	stp	q5, q1, [x10]
	b.lo	.LBB122_6
// %bb.8:                               //   in Loop: Header=BB122_7 Depth=1
	ldp	x15, x12, [sp, #8]              // 16-byte Folded Reload
	mov	x10, xzr
.LBB122_9:                              //   Parent Loop BB122_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x11, x18, x10
	add	x14, x6, x10
	subs	x12, x12, #1
	ldp	q4, q3, [x11, #-16]
	add	x11, x20, x10
	ldp	q6, q5, [x14, #-16]
	add	x14, x21, x10
	fadd	v25.2d, v4.2d, v6.2d
	fsub	v4.2d, v4.2d, v6.2d
	ldp	q1, q2, [x11, #-16]
	add	x11, x3, x10
	fadd	v26.2d, v3.2d, v5.2d
	fsub	v3.2d, v3.2d, v5.2d
	ldp	q7, q16, [x14, #-16]
	add	x14, x23, x10
	fadd	v27.2d, v1.2d, v7.2d
	fsub	v1.2d, v1.2d, v7.2d
	ldp	q18, q17, [x11, #32]
	add	x11, x24, x10
	fadd	v28.2d, v2.2d, v16.2d
	fadd	v9.2d, v25.2d, v27.2d
	fsub	v25.2d, v25.2d, v27.2d
	fsub	v2.2d, v2.2d, v16.2d
	ldp	q19, q20, [x14, #32]
	add	x14, x25, x10
	fadd	v10.2d, v26.2d, v28.2d
	fsub	v26.2d, v26.2d, v28.2d
	fadd	v29.2d, v18.2d, v19.2d
	fsub	v7.2d, v18.2d, v19.2d
	ldp	q21, q22, [x11, #32]
	fadd	v30.2d, v17.2d, v20.2d
	add	x11, x4, x10
	fsub	v16.2d, v17.2d, v20.2d
	fadd	v19.2d, v4.2d, v2.2d
	fsub	v20.2d, v3.2d, v1.2d
	fsub	v2.2d, v4.2d, v2.2d
	ldp	q23, q24, [x14, #32]
	add	x14, x15, x13
	fadd	v1.2d, v3.2d, v1.2d
	fadd	v31.2d, v21.2d, v23.2d
	fsub	v17.2d, v21.2d, v23.2d
	fadd	v8.2d, v22.2d, v24.2d
	fsub	v18.2d, v22.2d, v24.2d
	fadd	v11.2d, v29.2d, v31.2d
	fsub	v28.2d, v29.2d, v31.2d
	fadd	v12.2d, v30.2d, v8.2d
	fsub	v27.2d, v30.2d, v8.2d
	fadd	v13.2d, v9.2d, v11.2d
	fsub	v9.2d, v11.2d, v9.2d
	fadd	v14.2d, v10.2d, v12.2d
	fsub	v10.2d, v12.2d, v10.2d
	fadd	v29.2d, v26.2d, v28.2d
	fneg	v12.2d, v9.2d
	stp	q13, q14, [x11, #32]
	add	x11, x5, x10
	ld1r	{ v11.2d }, [x14], #8
	fsub	v31.2d, v27.2d, v25.2d
	fneg	v8.2d, v29.2d
	fsub	v26.2d, v28.2d, v26.2d
	ldr	d13, [x14]
	add	x14, x15, x8
	fadd	v25.2d, v25.2d, v27.2d
	fadd	v3.2d, v7.2d, v18.2d
	fmul	v14.2d, v10.2d, v13.d[0]
	fmul	v12.2d, v12.2d, v13.d[0]
	fneg	v27.2d, v26.2d
	fsub	v4.2d, v16.2d, v17.2d
	fmla	v14.2d, v11.2d, v9.2d
	fmla	v12.2d, v11.2d, v10.2d
	fsub	v7.2d, v7.2d, v18.2d
	fadd	v16.2d, v16.2d, v17.2d
	fneg	v17.2d, v2.2d
	stp	q14, q12, [x11, #32]
	add	x11, x29, x10
	ld1r	{ v30.2d }, [x14], #8
	fadd	v18.2d, v20.2d, v19.2d
	fsub	v19.2d, v20.2d, v19.2d
	fsub	v2.2d, v1.2d, v2.2d
	ldr	d9, [x14]
	add	x14, x15, x30
	fsub	v1.2d, v17.2d, v1.2d
	fmul	v17.2d, v18.2d, v0.2d
	fmul	v10.2d, v31.2d, v9.d[0]
	fmul	v8.2d, v8.2d, v9.d[0]
	fmul	v18.2d, v19.2d, v0.2d
	fmul	v2.2d, v2.2d, v0.2d
	fmla	v10.2d, v30.2d, v29.2d
	fmla	v8.2d, v30.2d, v31.2d
	fadd	v19.2d, v17.2d, v3.2d
	fadd	v20.2d, v18.2d, v4.2d
	fsub	v3.2d, v3.2d, v17.2d
	stp	q10, q8, [x11, #32]
	mov	x11, x15
	ld1r	{ v28.2d }, [x14], #8
	fadd	v17.2d, v2.2d, v7.2d
	ldr	d6, [x15, #8]
	fsub	v2.2d, v7.2d, v2.2d
	fneg	v7.2d, v19.2d
	ldr	d29, [x14]
	add	x14, x26, x10
	fmul	v1.2d, v1.2d, v0.2d
	fmul	v23.2d, v20.2d, v6.d[0]
	fsub	v4.2d, v4.2d, v18.2d
	fmul	v30.2d, v25.2d, v29.d[0]
	fmul	v27.2d, v27.2d, v29.d[0]
	fmul	v6.2d, v7.2d, v6.d[0]
	fneg	v18.2d, v3.2d
	fadd	v21.2d, v1.2d, v16.2d
	fmla	v30.2d, v28.2d, v26.2d
	fmla	v27.2d, v28.2d, v25.2d
	fsub	v1.2d, v16.2d, v1.2d
	fneg	v22.2d, v17.2d
	fneg	v7.2d, v2.2d
	stp	q30, q27, [x14, #32]
	add	x14, x15, x28
	ld1r	{ v25.2d }, [x11], x7
	fmla	v23.2d, v25.2d, v19.2d
	fmla	v6.2d, v25.2d, v20.2d
	ldp	d5, d26, [x14, #-64]
	add	x14, x15, x16
	add	x15, x15, #16
	ldp	d24, d16, [x14, #-32]
	fmul	v19.2d, v4.2d, v26.d[0]
	fmul	v18.2d, v18.2d, v26.d[0]
	ldp	d26, d20, [x11, #-96]
	add	x14, x27, x10
	add	x11, x22, x10
	fmul	v25.2d, v21.2d, v16.d[0]
	fmul	v16.2d, v22.2d, v16.d[0]
	fmla	v19.2d, v3.2d, v5.d[0]
	fmla	v18.2d, v4.2d, v5.d[0]
	fmul	v3.2d, v1.2d, v20.d[0]
	fmul	v4.2d, v7.2d, v20.d[0]
	stp	q23, q6, [x14, #32]
	add	x14, x19, x10
	fmla	v25.2d, v17.2d, v24.d[0]
	fmla	v16.2d, v21.2d, v24.d[0]
	stp	q19, q18, [x11, #32]
	add	x11, x17, x10
	fmla	v3.2d, v2.2d, v26.d[0]
	fmla	v4.2d, v1.2d, v26.d[0]
	add	x10, x10, #32
	stp	q25, q16, [x14, #32]
	stp	q3, q4, [x11, #32]
	b.ne	.LBB122_9
	b	.LBB122_6
.LBB122_10:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #112]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #96]             // 16-byte Folded Reload
	ldr	d14, [sp, #80]                  // 8-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end122:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end122-_ZNK9pocketfft6detail5cfftpIdE5pass8ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	cmp	x1, #1
	b.ne	.LBB123_4
// %bb.1:
	cbz	x2, .LBB123_12
// %bb.2:
	lsl	x8, x2, #5
	add	x9, x4, #16
	add	x10, x3, #32
.LBB123_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-32]
	add	x11, x9, x8
	subs	x2, x2, #1
	ldp	q2, q3, [x10], #64
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x9, #-16]
	add	x9, x9, #32
	stp	q0, q1, [x11, #-16]
	b.ne	.LBB123_3
	b	.LBB123_12
.LBB123_4:
	cbz	x2, .LBB123_12
// %bb.5:
	subs	x8, x1, #1
	b.ls	.LBB123_10
// %bb.6:
	mul	x13, x2, x1
	mov	x9, xzr
	add	x10, x4, #32
	lsl	x11, x1, #5
	add	x12, x3, #48
	lsl	x13, x13, #5
	lsl	x14, x1, #6
	add	x15, x5, #8
.LBB123_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB123_8 Depth 2
	mov	w17, #1
	lsl	x16, x9, #1
	bfi	x17, x9, #1, #63
	mul	x5, x9, x1
	mul	x16, x16, x1
	add	x18, x9, x2
	mul	x17, x17, x1
	mul	x18, x18, x1
	add	x16, x3, x16, lsl #5
	add	x0, x3, x17, lsl #5
	mov	x17, x12
	ldp	q0, q1, [x16]
	mov	x16, x15
	ldp	q2, q3, [x0]
	add	x0, x4, x5, lsl #5
	add	x5, x4, x18, lsl #5
	mov	x18, x10
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x0]
	mov	x0, x8
	stp	q0, q1, [x5]
.LBB123_8:                              //   Parent Loop BB123_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x5, x17, x11
	ldr	d6, [x16]
	ldp	q0, q2, [x17, #-16]
	subs	x0, x0, #1
	add	x17, x17, #32
	ldp	q1, q3, [x5, #-16]
	add	x5, x18, x13
	fsub	v4.2d, v0.2d, v1.2d
	fadd	v0.2d, v0.2d, v1.2d
	fsub	v5.2d, v2.2d, v3.2d
	fadd	v1.2d, v2.2d, v3.2d
	fneg	v7.2d, v4.2d
	fmul	v2.2d, v5.2d, v6.d[0]
	stp	q0, q1, [x18], #32
	fmul	v3.2d, v7.2d, v6.d[0]
	ldur	d6, [x16, #-8]
	add	x16, x16, #16
	fmla	v2.2d, v4.2d, v6.d[0]
	fmla	v3.2d, v5.2d, v6.d[0]
	stp	q2, q3, [x5]
	b.ne	.LBB123_8
// %bb.9:                               //   in Loop: Header=BB123_7 Depth=1
	add	x9, x9, #1
	add	x10, x10, x11
	add	x12, x12, x14
	cmp	x9, x2
	b.ne	.LBB123_7
	b	.LBB123_12
.LBB123_10:
	mul	x10, x2, x1
	add	x8, x4, #16
	lsl	x9, x1, #5
	add	x11, x3, #16
	lsl	x10, x10, #5
	lsl	x12, x1, #6
.LBB123_11:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	q0, q1, [x11, #-16]
	add	x11, x11, x12
	ldp	q2, q3, [x13, #-16]
	add	x13, x8, x10
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x8, #-16]
	add	x8, x8, x9
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB123_11
.LBB123_12:
	ret
.Lfunc_end123:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end123-_ZNK9pocketfft6detail5cfftpIdE5pass2ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	stp	x22, x21, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	subs	x8, x1, #1
	b.ne	.LBB124_4
// %bb.1:
	cbz	x2, .LBB124_10
// %bb.2:
	mov	x12, #19626
	mov	x13, #19626
	movk	x12, #59480, lsl #16
	movk	x13, #59480, lsl #16
	movk	x12, #46714, lsl #32
	movk	x13, #46714, lsl #32
	movk	x12, #16363, lsl #48
	movk	x13, #49131, lsl #48
	fmov	v0.2d, #0.50000000
	lsl	x8, x2, #6
	add	x9, x4, #16
	lsl	x10, x2, #5
	add	x11, x3, #48
	dup	v1.2d, x12
	dup	v2.2d, x13
.LBB124_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q3, q4, [x11, #-16]
	add	x12, x9, x10
	subs	x2, x2, #1
	ldp	q5, q6, [x11, #16]
	fadd	v7.2d, v3.2d, v5.2d
	fsub	v3.2d, v3.2d, v5.2d
	fadd	v17.2d, v4.2d, v6.2d
	ldp	q16, q18, [x11, #-48]
	fsub	v4.2d, v4.2d, v6.2d
	add	x11, x11, #96
	fmul	v5.2d, v7.2d, v0.2d
	fmul	v6.2d, v17.2d, v0.2d
	fmul	v3.2d, v3.2d, v2.2d
	fmul	v4.2d, v4.2d, v1.2d
	fsub	v5.2d, v16.2d, v5.2d
	fsub	v6.2d, v18.2d, v6.2d
	fadd	v7.2d, v16.2d, v7.2d
	fadd	v16.2d, v18.2d, v17.2d
	fadd	v19.2d, v5.2d, v4.2d
	fadd	v20.2d, v3.2d, v6.2d
	fsub	v4.2d, v5.2d, v4.2d
	fsub	v3.2d, v6.2d, v3.2d
	stp	q7, q16, [x9, #-16]
	stp	q19, q20, [x12, #-16]
	add	x12, x9, x8
	add	x9, x9, #32
	stp	q4, q3, [x12, #-16]
	b.ne	.LBB124_3
	b	.LBB124_10
.LBB124_4:
	cbz	x2, .LBB124_10
// %bb.5:
	mov	x6, #19626
	mov	x7, #19626
	movk	x6, #59480, lsl #16
	movk	x7, #59480, lsl #16
	mul	x16, x2, x1
	movk	x6, #46714, lsl #32
	movk	x7, #46714, lsl #32
	movk	x6, #16363, lsl #48
	movk	x7, #49131, lsl #48
	add	x12, x1, x1, lsl #1
	lsl	x11, x1, #5
	lsl	x17, x1, #4
	fmov	v0.2d, #0.50000000
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #5
	add	x13, x3, x11
	add	x14, x4, x16, lsl #6
	add	x15, x3, x1, lsl #6
	add	x16, x4, x16, lsl #5
	sub	x17, x17, #16
	mov	x18, x4
	mov	x0, x3
	dup	v1.2d, x6
	dup	v2.2d, x7
	b	.LBB124_7
.LBB124_6:                              //   in Loop: Header=BB124_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x0, x0, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x18, x18, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB124_10
.LBB124_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB124_9 Depth 2
	add	x6, x9, x9, lsl #1
	add	x20, x9, x2
	add	x7, x6, #2
	cmp	x1, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	add	x6, x3, x6, lsl #5
	add	x19, x3, x19, lsl #5
	add	x7, x3, x7, lsl #5
	ldp	q3, q4, [x6]
	mul	x6, x9, x1
	add	x6, x4, x6, lsl #5
	ldp	q5, q6, [x19]
	add	x19, x9, x10
	mul	x19, x19, x1
	ldp	q7, q16, [x7]
	mul	x7, x20, x1
	add	x19, x4, x19, lsl #5
	fadd	v17.2d, v5.2d, v7.2d
	add	x7, x4, x7, lsl #5
	fsub	v5.2d, v5.2d, v7.2d
	fadd	v18.2d, v6.2d, v16.2d
	fsub	v6.2d, v6.2d, v16.2d
	fadd	v7.2d, v3.2d, v17.2d
	fmul	v17.2d, v17.2d, v0.2d
	fadd	v16.2d, v4.2d, v18.2d
	fmul	v18.2d, v18.2d, v0.2d
	fmul	v6.2d, v6.2d, v1.2d
	fmul	v5.2d, v5.2d, v2.2d
	fsub	v3.2d, v3.2d, v17.2d
	stp	q7, q16, [x6]
	fsub	v4.2d, v4.2d, v18.2d
	fadd	v7.2d, v3.2d, v6.2d
	fadd	v16.2d, v5.2d, v4.2d
	fsub	v3.2d, v3.2d, v6.2d
	fsub	v4.2d, v4.2d, v5.2d
	stp	q7, q16, [x7]
	stp	q3, q4, [x19]
	b.lo	.LBB124_6
// %bb.8:                               //   in Loop: Header=BB124_7 Depth=1
	mov	x6, xzr
	mov	x7, x5
	mov	x19, x8
.LBB124_9:                              //   Parent Loop BB124_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x15, x6
	add	x21, x13, x6
	add	x22, x0, x6
	ldr	d20, [x7, #8]
	subs	x19, x19, #1
	ldp	q3, q6, [x20, #32]
	add	x20, x18, x6
	ldp	q4, q5, [x21, #32]
	mov	x21, x7
	add	x7, x7, #16
	fadd	v7.2d, v4.2d, v3.2d
	fsub	v3.2d, v4.2d, v3.2d
	ldp	q16, q17, [x22, #32]
	fadd	v18.2d, v5.2d, v6.2d
	fsub	v5.2d, v5.2d, v6.2d
	fmul	v6.2d, v7.2d, v0.2d
	fmul	v3.2d, v3.2d, v2.2d
	fmul	v4.2d, v18.2d, v0.2d
	fmul	v5.2d, v5.2d, v1.2d
	fsub	v6.2d, v16.2d, v6.2d
	fadd	v7.2d, v16.2d, v7.2d
	fsub	v4.2d, v17.2d, v4.2d
	fadd	v17.2d, v17.2d, v18.2d
	fadd	v19.2d, v6.2d, v5.2d
	fsub	v5.2d, v6.2d, v5.2d
	fadd	v16.2d, v3.2d, v4.2d
	stp	q7, q17, [x20, #32]
	add	x20, x16, x6
	fneg	v21.2d, v19.2d
	ld1r	{ v7.2d }, [x21], x17
	fmul	v18.2d, v16.2d, v20.d[0]
	fsub	v3.2d, v4.2d, v3.2d
	fmul	v20.2d, v21.2d, v20.d[0]
	fneg	v4.2d, v5.2d
	fmla	v18.2d, v7.2d, v19.2d
	fmla	v20.2d, v7.2d, v16.2d
	stp	q18, q20, [x20, #32]
	add	x20, x14, x6
	ld1r	{ v6.2d }, [x21], #8
	add	x6, x6, #32
	ldr	d7, [x21]
	fmul	v16.2d, v3.2d, v7.d[0]
	fmul	v4.2d, v4.2d, v7.d[0]
	fmla	v16.2d, v6.2d, v5.2d
	fmla	v4.2d, v6.2d, v3.2d
	stp	q16, q4, [x20, #32]
	b.ne	.LBB124_9
	b	.LBB124_6
.LBB124_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x22, x21, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end124:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end124-_ZNK9pocketfft6detail5cfftpIdE5pass3ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	stp	d9, d8, [sp, #-112]!            // 16-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #32]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 112
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	subs	x8, x1, #1
	b.ne	.LBB125_4
// %bb.1:
	cbz	x2, .LBB125_10
// %bb.2:
	mov	x11, #59728
	mov	x12, #62632
	mov	x13, #23134
	movk	x11, #14127, lsl #16
	movk	x12, #39831, lsl #16
	movk	x13, #1141, lsl #16
	mov	x14, #21759
	mov	x15, #21759
	movk	x11, #50927, lsl #32
	movk	x12, #58231, lsl #32
	movk	x13, #53027, lsl #32
	movk	x14, #4932, lsl #16
	movk	x15, #4932, lsl #16
	movk	x11, #16339, lsl #48
	movk	x12, #49129, lsl #48
	movk	x13, #49122, lsl #48
	movk	x14, #28430, lsl #32
	movk	x15, #28430, lsl #32
	movk	x14, #49134, lsl #48
	movk	x15, #16366, lsl #48
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #6
	lsl	x10, x10, #5
	dup	v0.2d, x11
	dup	v1.2d, x12
	lsl	x11, x2, #7
	dup	v2.2d, x13
	lsl	x12, x2, #5
	add	x13, x3, #80
	dup	v3.2d, x14
	dup	v4.2d, x15
.LBB125_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x13, #-48]
	add	x14, x8, x12
	add	x15, x8, x9
	subs	x2, x2, #1
	ldp	q16, q7, [x13, #48]
	fadd	v19.2d, v5.2d, v16.2d
	fsub	v5.2d, v5.2d, v16.2d
	ldp	q17, q20, [x13, #-16]
	fadd	v21.2d, v6.2d, v7.2d
	fsub	v6.2d, v6.2d, v7.2d
	ldp	q22, q18, [x13, #16]
	fadd	v23.2d, v17.2d, v22.2d
	fsub	v17.2d, v17.2d, v22.2d
	ldp	q16, q7, [x13, #-80]
	fsub	v24.2d, v20.2d, v18.2d
	add	x13, x13, #160
	fadd	v18.2d, v20.2d, v18.2d
	fmul	v22.2d, v17.2d, v2.2d
	mov	v25.16b, v16.16b
	fmul	v20.2d, v24.2d, v2.2d
	mov	v26.16b, v7.16b
	fmla	v22.2d, v3.2d, v5.2d
	fmla	v25.2d, v0.2d, v19.2d
	fmla	v20.2d, v3.2d, v6.2d
	fmla	v26.2d, v0.2d, v21.2d
	fadd	v27.2d, v16.2d, v19.2d
	fmla	v16.2d, v1.2d, v19.2d
	fmla	v25.2d, v1.2d, v23.2d
	fadd	v28.2d, v7.2d, v21.2d
	fmla	v7.2d, v1.2d, v21.2d
	fmla	v26.2d, v1.2d, v18.2d
	fmul	v24.2d, v24.2d, v4.2d
	fmla	v16.2d, v0.2d, v23.2d
	fmul	v17.2d, v17.2d, v4.2d
	fsub	v19.2d, v25.2d, v20.2d
	fmla	v7.2d, v0.2d, v18.2d
	fadd	v21.2d, v26.2d, v22.2d
	fadd	v20.2d, v25.2d, v20.2d
	fmla	v24.2d, v2.2d, v6.2d
	fmla	v17.2d, v2.2d, v5.2d
	fsub	v5.2d, v26.2d, v22.2d
	fadd	v6.2d, v27.2d, v23.2d
	stp	q19, q21, [x14, #-16]
	add	x14, x8, x11
	fsub	v19.2d, v16.2d, v24.2d
	stp	q20, q5, [x14, #-16]
	add	x14, x8, x10
	fadd	v20.2d, v7.2d, v17.2d
	stur	q6, [x8, #-16]
	fadd	v5.2d, v28.2d, v18.2d
	fadd	v6.2d, v16.2d, v24.2d
	fsub	v7.2d, v7.2d, v17.2d
	stp	q19, q20, [x15, #-16]
	str	q5, [x8], #32
	stp	q6, q7, [x14, #-16]
	b.ne	.LBB125_3
	b	.LBB125_10
.LBB125_4:
	cbz	x2, .LBB125_10
// %bb.5:
	mov	x23, #59728
	mov	x24, #62632
	movk	x23, #14127, lsl #16
	movk	x24, #39831, lsl #16
	mov	x25, #23134
	mov	x26, #21759
	mov	x27, #21759
	mul	x22, x2, x1
	mov	w17, #96
	mov	w19, #48
	movk	x23, #50927, lsl #32
	movk	x24, #58231, lsl #32
	movk	x25, #1141, lsl #16
	movk	x26, #4932, lsl #16
	movk	x27, #4932, lsl #16
	movk	x23, #16339, lsl #48
	movk	x24, #49129, lsl #48
	movk	x25, #53027, lsl #32
	movk	x26, #28430, lsl #32
	movk	x27, #28430, lsl #32
	madd	x0, x8, x17, x3
	movk	x25, #49122, lsl #48
	mul	x21, x1, x19
	movk	x26, #49134, lsl #48
	movk	x27, #16366, lsl #48
	lsl	x11, x2, #1
	lsl	x13, x1, #5
	madd	x14, x22, x17, x4
	add	x15, x1, x1, lsl #2
	add	x18, x3, x8, lsl #6
	lsl	x20, x1, #4
	mov	x9, xzr
	lsl	x10, x2, #2
	add	x12, x11, x2
	lsl	x15, x15, #5
	add	x16, x3, x13
	add	x17, x3, x1, lsl #7
	add	x18, x18, #64
	add	x0, x0, #96
	add	x6, x4, x22, lsl #6
	sub	x7, x13, #32
	sub	x19, x20, #16
	add	x20, x4, x22, lsl #7
	sub	x21, x21, #48
	add	x22, x4, x22, lsl #5
	dup	v0.2d, x23
	dup	v1.2d, x24
	mov	x23, x4
	mov	x24, x3
	dup	v2.2d, x25
	dup	v3.2d, x26
	dup	v4.2d, x27
	b	.LBB125_7
.LBB125_6:                              //   in Loop: Header=BB125_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x13
	add	x24, x24, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x23, x23, x13
	add	x6, x6, x13
	add	x20, x20, x13
	add	x22, x22, x13
	cmp	x9, x2
	b.eq	.LBB125_10
.LBB125_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB125_9 Depth 2
	add	x25, x9, x9, lsl #2
	cmp	x1, #2
	add	x26, x25, #4
	add	x29, x25, #2
	mul	x27, x25, x1
	add	x25, x25, #3
	mul	x26, x26, x1
	mul	x25, x25, x1
	add	x28, x3, x27, lsl #5
	add	x27, x1, x27
	add	x26, x3, x26, lsl #5
	add	x27, x3, x27, lsl #5
	add	x25, x3, x25, lsl #5
	ldp	q6, q5, [x28]
	mul	x28, x29, x1
	ldp	q7, q16, [x27]
	add	x27, x3, x28, lsl #5
	mov	v25.16b, v5.16b
	ldp	q17, q18, [x26]
	add	x26, x9, x2
	mul	x26, x26, x1
	fadd	v21.2d, v7.2d, v17.2d
	fsub	v7.2d, v7.2d, v17.2d
	ldp	q19, q20, [x27]
	fadd	v22.2d, v16.2d, v18.2d
	add	x26, x4, x26, lsl #5
	fsub	v16.2d, v16.2d, v18.2d
	add	x27, x9, x12
	fadd	v28.2d, v5.2d, v22.2d
	fmla	v25.2d, v0.2d, v22.2d
	ldp	q23, q17, [x25]
	mul	x25, x9, x1
	fmla	v5.2d, v1.2d, v22.2d
	fadd	v18.2d, v19.2d, v23.2d
	add	x25, x4, x25, lsl #5
	fsub	v19.2d, v19.2d, v23.2d
	fadd	v24.2d, v20.2d, v17.2d
	fsub	v17.2d, v20.2d, v17.2d
	mov	v20.16b, v6.16b
	fadd	v23.2d, v6.2d, v21.2d
	fmla	v6.2d, v1.2d, v21.2d
	fmul	v27.2d, v19.2d, v2.2d
	fmla	v25.2d, v1.2d, v24.2d
	fmul	v26.2d, v17.2d, v2.2d
	fmla	v5.2d, v0.2d, v24.2d
	fmla	v20.2d, v0.2d, v21.2d
	fadd	v23.2d, v23.2d, v18.2d
	fmla	v6.2d, v0.2d, v18.2d
	fadd	v28.2d, v28.2d, v24.2d
	fmla	v27.2d, v3.2d, v7.2d
	fmla	v26.2d, v3.2d, v16.2d
	fmla	v20.2d, v1.2d, v18.2d
	fmul	v17.2d, v17.2d, v4.2d
	stp	q23, q28, [x25]
	add	x25, x9, x10
	fadd	v30.2d, v25.2d, v27.2d
	fsub	v29.2d, v20.2d, v26.2d
	mul	x25, x25, x1
	fmul	v19.2d, v19.2d, v4.2d
	fmla	v17.2d, v2.2d, v16.2d
	fadd	v20.2d, v20.2d, v26.2d
	fsub	v21.2d, v25.2d, v27.2d
	add	x25, x4, x25, lsl #5
	stp	q29, q30, [x26]
	add	x26, x9, x11
	fmla	v19.2d, v2.2d, v7.2d
	mul	x26, x26, x1
	stp	q20, q21, [x25]
	mul	x25, x27, x1
	fsub	v7.2d, v6.2d, v17.2d
	fadd	v16.2d, v5.2d, v19.2d
	add	x26, x4, x26, lsl #5
	fadd	v6.2d, v6.2d, v17.2d
	add	x25, x4, x25, lsl #5
	fsub	v5.2d, v5.2d, v19.2d
	stp	q7, q16, [x26]
	stp	q6, q5, [x25]
	b.lo	.LBB125_6
// %bb.8:                               //   in Loop: Header=BB125_7 Depth=1
	mov	x25, xzr
	mov	x26, x5
	mov	x27, x8
.LBB125_9:                              //   Parent Loop BB125_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x28, x16, x25
	add	x29, x17, x25
	add	x30, x18, x25
	subs	x27, x27, #1
	ldp	q18, q5, [x28, #32]
	add	x28, x0, x25
	ldp	q19, q7, [x29, #32]
	add	x29, x24, x25
	fadd	v23.2d, v18.2d, v19.2d
	fsub	v18.2d, v18.2d, v19.2d
	ldp	q20, q21, [x30, #32]
	fadd	v16.2d, v5.2d, v7.2d
	add	x30, x26, x21
	fsub	v7.2d, v5.2d, v7.2d
	ldp	q22, q24, [x28, #32]
	add	x28, x23, x25
	fadd	v26.2d, v20.2d, v22.2d
	fsub	v20.2d, v20.2d, v22.2d
	ldp	q6, q5, [x29, #32]
	fsub	v17.2d, v21.2d, v24.2d
	mov	x29, x26
	fadd	v19.2d, v21.2d, v24.2d
	fmul	v21.2d, v20.2d, v2.2d
	mov	v25.16b, v6.16b
	fmul	v27.2d, v17.2d, v2.2d
	mov	v22.16b, v5.16b
	ldr	d24, [x26, #8]
	fmla	v21.2d, v3.2d, v18.2d
	fmla	v25.2d, v0.2d, v23.2d
	fmla	v27.2d, v3.2d, v7.2d
	fmla	v22.2d, v0.2d, v16.2d
	fadd	v28.2d, v6.2d, v23.2d
	fmla	v6.2d, v1.2d, v23.2d
	fmla	v25.2d, v1.2d, v26.2d
	fadd	v30.2d, v5.2d, v16.2d
	fmla	v5.2d, v1.2d, v16.2d
	fmla	v22.2d, v1.2d, v19.2d
	fadd	v28.2d, v28.2d, v26.2d
	fmla	v6.2d, v0.2d, v26.2d
	fsub	v29.2d, v25.2d, v27.2d
	fadd	v30.2d, v30.2d, v19.2d
	fmla	v5.2d, v0.2d, v19.2d
	fadd	v31.2d, v22.2d, v21.2d
	fsub	v21.2d, v22.2d, v21.2d
	fneg	v8.2d, v29.2d
	stp	q28, q30, [x28, #32]
	add	x28, x22, x25
	fmul	v9.2d, v31.2d, v24.d[0]
	ld1r	{ v28.2d }, [x29], x7
	fmul	v24.2d, v8.2d, v24.d[0]
	fmul	v17.2d, v17.2d, v4.2d
	fmla	v9.2d, v28.2d, v29.2d
	fmul	v16.2d, v20.2d, v4.2d
	fmla	v24.2d, v28.2d, v31.2d
	fmla	v17.2d, v2.2d, v7.2d
	fmla	v16.2d, v2.2d, v18.2d
	stp	q9, q24, [x28, #32]
	add	x28, x20, x25
	fadd	v24.2d, v25.2d, v27.2d
	ld1r	{ v25.2d }, [x30], #8
	fsub	v7.2d, v6.2d, v17.2d
	fadd	v19.2d, v5.2d, v16.2d
	fneg	v22.2d, v24.2d
	ldr	d27, [x30]
	fneg	v20.2d, v7.2d
	fadd	v6.2d, v6.2d, v17.2d
	fmul	v28.2d, v21.2d, v27.d[0]
	fmul	v22.2d, v22.2d, v27.d[0]
	fsub	v5.2d, v5.2d, v16.2d
	fneg	v16.2d, v6.2d
	fmla	v28.2d, v25.2d, v24.2d
	fmla	v22.2d, v25.2d, v21.2d
	stp	q28, q22, [x28, #32]
	add	x28, x26, x19
	add	x26, x26, #16
	ld1r	{ v18.2d }, [x28], #8
	ldr	d21, [x28]
	add	x28, x6, x25
	fmul	v22.2d, v19.2d, v21.d[0]
	fmul	v20.2d, v20.2d, v21.d[0]
	fmla	v22.2d, v18.2d, v7.2d
	fmla	v20.2d, v18.2d, v19.2d
	stp	q22, q20, [x28, #32]
	add	x28, x14, x25
	ld1r	{ v7.2d }, [x29], #8
	add	x25, x25, #32
	ldr	d17, [x29]
	fmul	v18.2d, v5.2d, v17.d[0]
	fmul	v16.2d, v16.2d, v17.d[0]
	fmla	v18.2d, v7.2d, v6.2d
	fmla	v16.2d, v7.2d, v5.2d
	stp	q18, q16, [x28, #32]
	b.ne	.LBB125_9
	b	.LBB125_6
.LBB125_10:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldp	d9, d8, [sp], #112              // 16-byte Folded Reload
	ret
.Lfunc_end125:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end125-_ZNK9pocketfft6detail5cfftpIdE5pass5ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #304
	stp	d15, d14, [sp, #144]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #160]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #176]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #192]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #224]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #240]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #256]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #272]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #288]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 304
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	mov	x8, x4
	subs	x9, x1, #1
	str	x3, [sp, #72]                   // 8-byte Folded Spill
	b.ne	.LBB126_4
// %bb.1:
	cbz	x2, .LBB126_10
// %bb.2:
	mov	x15, #17794
	mov	x16, #23665
	movk	x15, #58114, lsl #16
	mov	x17, #59753
	movk	x15, #31632, lsl #32
	movk	x16, #43467, lsl #16
	movk	x17, #1368, lsl #16
	movk	x15, #49100, lsl #48
	movk	x16, #54460, lsl #32
	movk	x17, #12956, lsl #32
	movk	x16, #49132, lsl #48
	movk	x17, #49135, lsl #48
	mov	x12, #60881
	dup	v1.2d, x15
	mov	x15, #43969
	movk	x12, #57995, lsl #16
	mov	x18, #56907
	dup	v2.2d, x16
	movk	x15, #19825, lsl #16
	dup	v3.2d, x17
	mov	x16, #43969
	mov	x17, #56907
	movk	x12, #62368, lsl #32
	movk	x18, #29957, lsl #16
	movk	x15, #50368, lsl #32
	movk	x16, #19825, lsl #16
	movk	x17, #29957, lsl #16
	movk	x12, #16355, lsl #48
	movk	x18, #1219, lsl #32
	movk	x15, #49115, lsl #48
	movk	x16, #50368, lsl #32
	movk	x17, #1219, lsl #32
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	movk	x18, #49129, lsl #48
	movk	x16, #16347, lsl #48
	movk	x17, #16361, lsl #48
	add	x14, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	lsl	x9, x2, #7
	add	x8, x8, #16
	lsl	x10, x14, #5
	lsl	x11, x11, #5
	dup	v0.2d, x12
	lsl	x12, x2, #6
	lsl	x14, x14, #6
	dup	v5.2d, x15
	lsl	x15, x2, #5
	add	x13, x13, #112
	dup	v4.2d, x18
	dup	v6.2d, x16
	dup	v7.2d, x17
.LBB126_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q16, q17, [x13, #-80]
	add	x16, x8, x15
	add	x17, x8, x14
	subs	x2, x2, #1
	ldp	q18, q19, [x13, #80]
	fadd	v24.2d, v16.2d, v18.2d
	fsub	v18.2d, v16.2d, v18.2d
	ldp	q27, q23, [x13, #48]
	fadd	v22.2d, v17.2d, v19.2d
	fsub	v19.2d, v17.2d, v19.2d
	ldp	q25, q26, [x13, #-48]
	fadd	v20.2d, v25.2d, v27.2d
	fsub	v25.2d, v25.2d, v27.2d
	ldp	q16, q17, [x13, #-112]
	fsub	v21.2d, v26.2d, v23.2d
	fadd	v23.2d, v26.2d, v23.2d
	fmul	v11.2d, v25.2d, v3.2d
	mov	v30.16b, v16.16b
	fmul	v10.2d, v21.2d, v3.2d
	mov	v9.16b, v17.16b
	ldp	q8, q29, [x13, #16]
	fmla	v30.2d, v0.2d, v24.2d
	fmla	v11.2d, v4.2d, v18.2d
	fmla	v10.2d, v4.2d, v19.2d
	fmla	v9.2d, v0.2d, v22.2d
	mov	v12.16b, v17.16b
	fmla	v30.2d, v1.2d, v20.2d
	ldp	q31, q26, [x13, #-16]
	fmla	v9.2d, v1.2d, v23.2d
	add	x13, x13, #224
	fmla	v12.2d, v1.2d, v22.2d
	fadd	v28.2d, v31.2d, v8.2d
	fsub	v27.2d, v26.2d, v29.2d
	fmla	v12.2d, v2.2d, v23.2d
	fadd	v26.2d, v26.2d, v29.2d
	fsub	v29.2d, v31.2d, v8.2d
	fmla	v30.2d, v2.2d, v28.2d
	mov	v31.16b, v16.16b
	fmla	v10.2d, v5.2d, v27.2d
	fmla	v9.2d, v2.2d, v26.2d
	fmla	v12.2d, v0.2d, v26.2d
	fmla	v11.2d, v5.2d, v29.2d
	fmla	v31.2d, v1.2d, v24.2d
	fsub	v8.2d, v30.2d, v10.2d
	fadd	v30.2d, v30.2d, v10.2d
	fadd	v13.2d, v11.2d, v9.2d
	fmul	v10.2d, v25.2d, v6.2d
	fmla	v31.2d, v2.2d, v20.2d
	fsub	v9.2d, v9.2d, v11.2d
	fadd	v11.2d, v16.2d, v24.2d
	fmla	v16.2d, v2.2d, v24.2d
	stp	q8, q13, [x16, #-16]
	add	x16, x8, x12
	fmul	v8.2d, v21.2d, v6.2d
	fmla	v10.2d, v3.2d, v18.2d
	stp	q30, q9, [x17, #-16]
	fmla	v31.2d, v0.2d, v28.2d
	fadd	v9.2d, v17.2d, v22.2d
	fmla	v17.2d, v2.2d, v22.2d
	fmul	v21.2d, v21.2d, v7.2d
	fmla	v16.2d, v0.2d, v20.2d
	fmla	v8.2d, v3.2d, v19.2d
	fmla	v10.2d, v7.2d, v29.2d
	fmul	v22.2d, v25.2d, v7.2d
	add	x17, x8, x10
	fadd	v30.2d, v11.2d, v20.2d
	fmla	v17.2d, v0.2d, v23.2d
	fmla	v21.2d, v5.2d, v19.2d
	fmla	v16.2d, v1.2d, v28.2d
	fmla	v8.2d, v7.2d, v27.2d
	fmla	v22.2d, v5.2d, v18.2d
	fadd	v25.2d, v10.2d, v12.2d
	fmla	v17.2d, v1.2d, v26.2d
	fadd	v18.2d, v30.2d, v28.2d
	fmla	v21.2d, v3.2d, v27.2d
	fsub	v24.2d, v31.2d, v8.2d
	fadd	v19.2d, v31.2d, v8.2d
	fmla	v22.2d, v3.2d, v29.2d
	fsub	v20.2d, v12.2d, v10.2d
	fadd	v23.2d, v9.2d, v23.2d
	stur	q18, [x8, #-16]
	stp	q24, q25, [x16, #-16]
	add	x16, x8, x11
	fadd	v24.2d, v22.2d, v17.2d
	fsub	v17.2d, v17.2d, v22.2d
	stp	q19, q20, [x16, #-16]
	add	x16, x8, x9
	fsub	v19.2d, v16.2d, v21.2d
	fadd	v18.2d, v23.2d, v26.2d
	fadd	v16.2d, v16.2d, v21.2d
	stp	q19, q24, [x17, #-16]
	str	q18, [x8], #32
	stp	q16, q17, [x16, #-16]
	b.ne	.LBB126_3
	b	.LBB126_10
.LBB126_4:
	str	x9, [sp, #24]                   // 8-byte Folded Spill
	cbz	x2, .LBB126_10
// %bb.5:
	lsl	x11, x2, #1
	lsl	x12, x2, #2
	mul	x10, x2, x1
	ldr	x13, [sp, #24]                  // 8-byte Folded Reload
	mov	w3, #96
	mov	x23, x5
	str	x11, [sp, #64]                  // 8-byte Folded Spill
	add	x11, x11, x2
	lsl	x18, x11, #1
	madd	x21, x10, x3, x8
	mov	w14, #192
	add	x15, x8, x10, lsl #7
	stp	x12, x11, [sp, #48]             // 16-byte Folded Spill
	add	x11, x12, x2
	ldr	x12, [sp, #72]                  // 8-byte Folded Reload
	add	x27, x8, x10, lsl #6
	add	x29, x8, x10, lsl #5
	madd	x30, x10, x14, x8
	stp	x11, x18, [sp, #32]             // 16-byte Folded Spill
	mov	w11, #224
	madd	x19, x13, x3, x12
	mov	w3, #80
	mul	x17, x1, x11
	mov	w11, #160
	add	x5, x12, x13, lsl #6
	madd	x18, x1, x14, x12
	madd	x4, x13, x11, x12
	mov	x14, #59753
	movk	x14, #1368, lsl #16
	add	x6, x5, #64
	add	x7, x4, #160
	add	x4, x12, x13, lsl #7
	add	x13, x23, #8
	madd	x23, x10, x11, x8
	mul	x11, x1, x3
	mov	x3, #17794
	movk	x3, #58114, lsl #16
	mov	x10, #23665
	sub	x28, x11, #80
	mov	x11, #60881
	movk	x11, #57995, lsl #16
	movk	x3, #31632, lsl #32
	movk	x10, #43467, lsl #16
	movk	x11, #62368, lsl #32
	movk	x3, #49100, lsl #48
	movk	x10, #54460, lsl #32
	movk	x14, #12956, lsl #32
	movk	x11, #16355, lsl #48
	movk	x10, #49132, lsl #48
	movk	x14, #49135, lsl #48
	dup	v1.2d, x3
	mov	x3, #43969
	dup	v11.2d, x11
	mov	x11, #56907
	movk	x3, #19825, lsl #16
	dup	v2.2d, x10
	dup	v3.2d, x14
	mov	x10, #43969
	mov	x14, #56907
	mov	w5, #48
	movk	x11, #29957, lsl #16
	movk	x3, #50368, lsl #32
	movk	x10, #19825, lsl #16
	movk	x14, #29957, lsl #16
	movk	x11, #1219, lsl #32
	movk	x3, #49115, lsl #48
	movk	x10, #50368, lsl #32
	movk	x14, #1219, lsl #32
	mul	x5, x1, x5
	movk	x11, #49129, lsl #48
	movk	x10, #16347, lsl #48
	movk	x14, #16361, lsl #48
	lsl	x16, x1, #5
	mov	x9, xzr
	add	x0, x12, x16
	add	x19, x19, #96
	add	x20, x4, #128
	sub	x22, x5, #48
	sub	x24, x16, #32
	lsl	x25, x1, #6
	lsl	x26, x1, #4
	dup	v15.2d, x3
	mov	x4, x8
	mov	x3, x12
	dup	v0.2d, x11
	dup	v6.2d, x10
	dup	v7.2d, x14
	str	x13, [sp, #16]                  // 8-byte Folded Spill
	stp	q0, q15, [sp, #80]              // 32-byte Folded Spill
	stp	q6, q11, [sp, #112]             // 32-byte Folded Spill
	b	.LBB126_7
.LBB126_6:                              //   in Loop: Header=BB126_7 Depth=1
	add	x9, x9, #1
	add	x15, x15, x16
	add	x3, x3, x17
	add	x0, x0, x17
	add	x18, x18, x17
	add	x6, x6, x17
	add	x7, x7, x17
	add	x19, x19, x17
	add	x20, x20, x17
	add	x4, x4, x16
	add	x21, x21, x16
	add	x23, x23, x16
	add	x27, x27, x16
	add	x29, x29, x16
	add	x30, x30, x16
	cmp	x9, x2
	b.eq	.LBB126_10
.LBB126_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB126_9 Depth 2
	lsl	x10, x9, #3
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	sub	x10, x10, x9
	ldr	q5, [sp, #96]                   // 16-byte Folded Reload
	add	x11, x10, #6
	add	x12, x10, #2
	mul	x14, x10, x1
	cmp	x1, #2
	mul	x11, x11, x1
	mul	x12, x12, x1
	add	x5, x13, x14, lsl #5
	add	x14, x1, x14
	add	x11, x13, x11, lsl #5
	add	x14, x13, x14, lsl #5
	add	x12, x13, x12, lsl #5
	ldp	q16, q17, [x5]
	ldp	q18, q19, [x14]
	add	x14, x10, #5
	mul	x14, x14, x1
	ldp	q20, q21, [x11]
	add	x11, x10, #3
	add	x10, x10, #4
	mul	x11, x11, x1
	mul	x10, x10, x1
	fadd	v28.2d, v18.2d, v20.2d
	ldp	q24, q26, [x12]
	add	x12, x13, x14, lsl #5
	add	x11, x13, x11, lsl #5
	add	x10, x13, x10, lsl #5
	fsub	v18.2d, v18.2d, v20.2d
	fadd	v27.2d, v19.2d, v21.2d
	fsub	v19.2d, v19.2d, v21.2d
	ldp	q20, q29, [x12]
	fadd	v10.2d, v17.2d, v27.2d
	fadd	v22.2d, v24.2d, v20.2d
	fsub	v25.2d, v24.2d, v20.2d
	ldp	q30, q31, [x11]
	fadd	v23.2d, v26.2d, v29.2d
	fsub	v26.2d, v26.2d, v29.2d
	fadd	v29.2d, v16.2d, v28.2d
	fmul	v12.2d, v25.2d, v3.2d
	fadd	v10.2d, v10.2d, v23.2d
	ldp	q8, q9, [x10]
	fadd	v29.2d, v29.2d, v22.2d
	mul	x10, x9, x1
	fmla	v12.2d, v0.2d, v18.2d
	fmul	v14.2d, v25.2d, v6.2d
	fadd	v20.2d, v30.2d, v8.2d
	add	x10, x8, x10, lsl #5
	fsub	v24.2d, v30.2d, v8.2d
	mov	v30.16b, v16.16b
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	mov	v8.16b, v17.16b
	fmla	v14.2d, v3.2d, v18.2d
	fadd	v21.2d, v31.2d, v9.2d
	fadd	v13.2d, v29.2d, v20.2d
	fmla	v12.2d, v15.2d, v24.2d
	fmla	v30.2d, v11.2d, v28.2d
	add	x11, x9, x11
	fmla	v8.2d, v11.2d, v27.2d
	fmla	v14.2d, v7.2d, v24.2d
	fmul	v11.2d, v26.2d, v3.2d
	fadd	v10.2d, v10.2d, v21.2d
	fmla	v30.2d, v1.2d, v22.2d
	fsub	v29.2d, v31.2d, v9.2d
	fmla	v8.2d, v1.2d, v23.2d
	fmla	v11.2d, v0.2d, v19.2d
	stp	q13, q10, [x10]
	add	x10, x9, x2
	fmla	v30.2d, v2.2d, v20.2d
	fmla	v8.2d, v2.2d, v21.2d
	mul	x10, x10, x1
	fmla	v11.2d, v15.2d, v29.2d
	mov	v31.16b, v16.16b
	fmla	v16.2d, v2.2d, v28.2d
	mov	v9.16b, v17.16b
	add	x10, x8, x10, lsl #5
	fadd	v13.2d, v12.2d, v8.2d
	fmla	v17.2d, v2.2d, v27.2d
	fsub	v10.2d, v30.2d, v11.2d
	fmla	v31.2d, v1.2d, v28.2d
	fmla	v9.2d, v1.2d, v27.2d
	fmul	v15.2d, v26.2d, v6.2d
	stp	q10, q13, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
	fmla	v31.2d, v2.2d, v22.2d
	fmla	v9.2d, v2.2d, v23.2d
	fmla	v15.2d, v3.2d, v19.2d
	add	x10, x8, x10, lsl #5
	fadd	v30.2d, v30.2d, v11.2d
	ldr	q11, [sp, #128]                 // 16-byte Folded Reload
	fsub	v8.2d, v8.2d, v12.2d
	add	x11, x9, x11
	fmul	v26.2d, v26.2d, v7.2d
	fmla	v31.2d, v11.2d, v20.2d
	fmla	v9.2d, v11.2d, v21.2d
	fmla	v15.2d, v7.2d, v29.2d
	fmla	v16.2d, v11.2d, v22.2d
	stp	q30, q8, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #32]                  // 8-byte Folded Reload
	fmla	v26.2d, v5.2d, v19.2d
	fadd	v8.2d, v14.2d, v9.2d
	fmla	v17.2d, v11.2d, v23.2d
	fsub	v30.2d, v31.2d, v15.2d
	add	x10, x8, x10, lsl #5
	add	x11, x9, x11
	fmla	v16.2d, v1.2d, v20.2d
	fmul	v25.2d, v25.2d, v7.2d
	fmla	v26.2d, v3.2d, v29.2d
	mul	x11, x11, x1
	fmla	v17.2d, v1.2d, v21.2d
	fadd	v19.2d, v31.2d, v15.2d
	ldr	q15, [sp, #96]                  // 16-byte Folded Reload
	stp	q30, q8, [x10]
	add	x10, x8, x11, lsl #5
	ldp	x12, x11, [sp, #48]             // 16-byte Folded Reload
	fmla	v25.2d, v15.2d, v18.2d
	fsub	v18.2d, v9.2d, v14.2d
	add	x12, x9, x12
	add	x11, x9, x11
	fmla	v25.2d, v3.2d, v24.2d
	stp	q19, q18, [x10]
	mul	x10, x12, x1
	mul	x11, x11, x1
	fsub	v18.2d, v16.2d, v26.2d
	fadd	v19.2d, v25.2d, v17.2d
	add	x10, x8, x10, lsl #5
	fadd	v16.2d, v16.2d, v26.2d
	add	x11, x8, x11, lsl #5
	fsub	v17.2d, v17.2d, v25.2d
	stp	q18, q19, [x11]
	stp	q16, q17, [x10]
	b.lo	.LBB126_6
// %bb.8:                               //   in Loop: Header=BB126_7 Depth=1
	ldp	x14, x10, [sp, #16]             // 16-byte Folded Reload
	mov	x5, xzr
.LBB126_9:                              //   Parent Loop BB126_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x11, x0, x5
	add	x12, x18, x5
	add	x13, x3, x5
	subs	x10, x10, #1
	ldp	q19, q20, [x11, #32]
	add	x11, x6, x5
	ldp	q21, q22, [x12, #32]
	add	x12, x7, x5
	fadd	v27.2d, v19.2d, v21.2d
	fsub	v19.2d, v19.2d, v21.2d
	ldp	q17, q16, [x13, #32]
	fadd	v18.2d, v20.2d, v22.2d
	add	x13, x14, x26
	fsub	v22.2d, v20.2d, v22.2d
	ldp	q23, q26, [x11, #32]
	add	x11, x19, x5
	mov	v9.16b, v16.16b
	fadd	v10.2d, v16.2d, v18.2d
	ldp	q25, q28, [x12, #32]
	add	x12, x20, x5
	fmla	v9.2d, v11.2d, v18.2d
	fadd	v24.2d, v23.2d, v25.2d
	fsub	v25.2d, v23.2d, v25.2d
	ldp	q29, q30, [x11, #32]
	fadd	v21.2d, v26.2d, v28.2d
	mov	x11, x14
	fsub	v26.2d, v26.2d, v28.2d
	fmla	v9.2d, v1.2d, v21.2d
	ldp	q31, q8, [x12, #32]
	fadd	v10.2d, v10.2d, v21.2d
	add	x12, x4, x5
	fadd	v23.2d, v29.2d, v31.2d
	fsub	v28.2d, v29.2d, v31.2d
	fadd	v20.2d, v30.2d, v8.2d
	fsub	v29.2d, v30.2d, v8.2d
	mov	v30.16b, v17.16b
	fmul	v31.2d, v25.2d, v3.2d
	fadd	v8.2d, v17.2d, v27.2d
	fmla	v9.2d, v2.2d, v20.2d
	fadd	v10.2d, v10.2d, v20.2d
	fmla	v30.2d, v11.2d, v27.2d
	fmul	v11.2d, v26.2d, v3.2d
	fmla	v31.2d, v0.2d, v19.2d
	fadd	v8.2d, v8.2d, v24.2d
	fmla	v30.2d, v1.2d, v24.2d
	fmla	v11.2d, v0.2d, v22.2d
	fmla	v31.2d, v15.2d, v28.2d
	fadd	v8.2d, v8.2d, v23.2d
	fmla	v30.2d, v2.2d, v23.2d
	fmla	v11.2d, v15.2d, v29.2d
	fadd	v12.2d, v31.2d, v9.2d
	stp	q8, q10, [x12, #32]
	ldur	d10, [x14, #-8]
	add	x12, x14, x28
	ld1r	{ v13.2d }, [x11], x22
	fsub	v8.2d, v30.2d, v11.2d
	ldr	q0, [sp, #112]                  // 16-byte Folded Reload
	fmul	v14.2d, v12.2d, v13.2d
	fadd	v30.2d, v30.2d, v11.2d
	mov	v11.16b, v17.16b
	fsub	v9.2d, v9.2d, v31.2d
	mov	v31.16b, v16.16b
	fmla	v14.2d, v8.2d, v10.d[0]
	fneg	v8.2d, v8.2d
	fmla	v11.2d, v1.2d, v27.2d
	fmul	v15.2d, v26.2d, v6.2d
	fmla	v31.2d, v1.2d, v18.2d
	fmul	v6.2d, v25.2d, v0.2d
	fmul	v8.2d, v13.2d, v8.2d
	fmla	v11.2d, v2.2d, v24.2d
	ldp	d13, d4, [x12, #-8]
	fneg	v5.2d, v30.2d
	fmla	v15.2d, v3.2d, v22.2d
	fmla	v31.2d, v2.2d, v21.2d
	fmla	v6.2d, v3.2d, v19.2d
	mov	v0.16b, v3.16b
	fmla	v8.2d, v12.2d, v10.d[0]
	mov	v3.16b, v2.16b
	add	x12, x29, x5
	mov	v2.16b, v1.16b
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	fmul	v5.2d, v5.2d, v4.d[0]
	fmla	v15.2d, v7.2d, v29.2d
	fmul	v4.2d, v9.2d, v4.d[0]
	fmla	v6.2d, v7.2d, v28.2d
	fmla	v11.2d, v1.2d, v23.2d
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	stp	q14, q8, [x12, #32]
	add	x12, x30, x5
	fmla	v5.2d, v9.2d, v13.d[0]
	fmla	v31.2d, v1.2d, v20.2d
	fmla	v4.2d, v30.2d, v13.d[0]
	mov	v1.16b, v2.16b
	mov	v2.16b, v3.16b
	fsub	v9.2d, v11.2d, v15.2d
	stp	q4, q5, [x12, #32]
	add	x12, x14, x25
	fadd	v8.2d, v6.2d, v31.2d
	fmla	v17.2d, v2.2d, v27.2d
	fmla	v16.2d, v2.2d, v18.2d
	ldp	d4, d27, [x13, #-24]
	fneg	v10.2d, v9.2d
	fmul	v26.2d, v26.2d, v7.2d
	fadd	v30.2d, v11.2d, v15.2d
	ldr	q11, [sp, #128]                 // 16-byte Folded Reload
	ldr	q15, [sp, #96]                  // 16-byte Folded Reload
	fmul	v18.2d, v25.2d, v7.2d
	fmul	v5.2d, v10.2d, v27.d[0]
	fmul	v27.2d, v8.2d, v27.d[0]
	fmla	v17.2d, v11.2d, v24.2d
	fmla	v26.2d, v15.2d, v22.2d
	fmla	v16.2d, v11.2d, v21.2d
	fsub	v6.2d, v31.2d, v6.2d
	fmla	v18.2d, v15.2d, v19.2d
	fmla	v5.2d, v8.2d, v4.d[0]
	fmla	v27.2d, v9.2d, v4.d[0]
	fmla	v17.2d, v1.2d, v23.2d
	fmla	v26.2d, v0.2d, v29.2d
	fmla	v16.2d, v1.2d, v20.2d
	ldp	d4, d19, [x12, #-72]
	add	x12, x27, x5
	fmla	v18.2d, v0.2d, v28.2d
	fneg	v21.2d, v30.2d
	fsub	v20.2d, v17.2d, v26.2d
	stp	q27, q5, [x12, #32]
	add	x12, x14, x24
	fmul	v5.2d, v6.2d, v19.d[0]
	add	x14, x14, #16
	fmul	v19.2d, v21.2d, v19.d[0]
	fadd	v21.2d, v18.2d, v16.2d
	fadd	v17.2d, v17.2d, v26.2d
	fsub	v16.2d, v16.2d, v18.2d
	fmla	v5.2d, v30.2d, v4.d[0]
	ldp	d18, d22, [x12, #-8]
	fneg	v23.2d, v20.2d
	fmla	v19.2d, v6.2d, v4.d[0]
	fneg	v25.2d, v17.2d
	add	x12, x23, x5
	mov	v3.16b, v0.16b
	ldr	q0, [sp, #80]                   // 16-byte Folded Reload
	fmul	v24.2d, v21.2d, v22.d[0]
	fmul	v22.2d, v23.2d, v22.d[0]
	ldr	d23, [x11]
	stp	q5, q19, [x12, #32]
	add	x12, x15, x5
	fmul	v4.2d, v16.2d, v23.d[0]
	fmul	v6.2d, v25.2d, v23.d[0]
	fmla	v24.2d, v20.2d, v18.d[0]
	fmla	v22.2d, v21.2d, v18.d[0]
	ldur	d18, [x11, #-8]
	add	x11, x21, x5
	add	x5, x5, #32
	fmla	v4.2d, v17.2d, v18.d[0]
	fmla	v6.2d, v16.2d, v18.d[0]
	stp	q24, q22, [x11, #32]
	stp	q4, q6, [x12, #32]
	ldr	q6, [sp, #112]                  // 16-byte Folded Reload
	b.ne	.LBB126_9
	b	.LBB126_6
.LBB126_10:
	ldp	x20, x19, [sp, #288]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #272]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #256]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #192]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #176]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #160]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #144]            // 16-byte Folded Reload
	add	sp, sp, #304
	ret
.Lfunc_end126:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end126-_ZNK9pocketfft6detail5cfftpIdE5pass7ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #960
	.cfi_def_cfa_offset 1120
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #176]              // 16-byte Folded Spill
	b.ne	.LBB127_4
// %bb.1:
	cbz	x2, .LBB127_10
// %bb.2:
	mov	x16, #61626
	mov	x0, #4790
	movk	x16, #34660, lsl #16
	movk	x0, #55751, lsl #16
	movk	x16, #60300, lsl #32
	movk	x0, #38440, lsl #32
	movk	x16, #16362, lsl #48
	mov	x1, #17627
	movk	x0, #16346, lsl #48
	movk	x1, #25615, lsl #16
	movk	x1, #14175, lsl #32
	mov	x3, #22663
	dup	v1.2d, x16
	mov	x16, #20567
	movk	x1, #16322, lsl #48
	movk	x3, #32631, lsl #16
	movk	x16, #39885, lsl #16
	movk	x3, #62622, lsl #32
	movk	x16, #46122, lsl #32
	dup	v0.2d, x0
	mov	x0, #11283
	movk	x3, #16356, lsl #48
	movk	x16, #16366, lsl #48
	movk	x0, #36590, lsl #16
	str	q0, [sp, #896]                  // 16-byte Folded Spill
	movk	x0, #7092, lsl #32
	dup	v0.2d, x1
	movk	x0, #49133, lsl #48
	mov	x1, #10401
	mov	x4, #36287
	stp	q0, q1, [sp, #432]              // 32-byte Folded Spill
	dup	v1.2d, x3
	dup	v0.2d, x16
	movk	x1, #47930, lsl #16
	mov	x16, #22539
	movk	x1, #12057, lsl #32
	stp	q0, q1, [sp, #400]              // 32-byte Folded Spill
	dup	v0.2d, x0
	mov	x0, #17135
	movk	x16, #63675, lsl #16
	movk	x0, #1080, lsl #16
	movk	x1, #49128, lsl #48
	movk	x0, #44190, lsl #32
	movk	x4, #64886, lsl #16
	movk	x0, #49135, lsl #48
	movk	x16, #19693, lsl #32
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	movk	x4, #2023, lsl #32
	mov	x3, #36287
	movk	x16, #49121, lsl #48
	dup	v0.2d, x0
	movk	x4, #49106, lsl #48
	movk	x3, #64886, lsl #16
	mov	x0, #17135
	movk	x3, #2023, lsl #32
	str	q0, [sp, #912]                  // 16-byte Folded Spill
	dup	v0.2d, x1
	movk	x3, #16338, lsl #48
	movk	x0, #1080, lsl #16
	dup	v1.2d, x16
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	dup	v0.2d, x4
	movk	x0, #44190, lsl #32
	mov	x1, #22539
	movk	x0, #16367, lsl #48
	movk	x1, #63675, lsl #16
	ldp	x9, x14, [sp, #176]             // 16-byte Folded Reload
	stp	q0, q1, [sp, #592]              // 32-byte Folded Spill
	dup	v1.2d, x3
	movk	x1, #19693, lsl #32
	mov	x3, #11283
	movk	x1, #16353, lsl #48
	movk	x3, #36590, lsl #16
	mov	w11, #224
	movk	x3, #7092, lsl #32
	dup	v0.2d, x0
	movk	x3, #16365, lsl #48
	ldp	q8, q30, [sp, #432]             // 32-byte Folded Reload
	add	x15, x2, x2, lsl #1
	add	x18, x2, x2, lsl #2
	mul	x11, x2, x11
	add	x17, x2, x2, lsl #3
	stp	q0, q1, [sp, #464]              // 32-byte Folded Spill
	dup	v0.2d, x1
	lsl	x8, x15, #6
	add	x9, x9, #16
	lsl	x10, x18, #5
	lsl	x12, x2, #7
	lsl	x13, x2, #8
	add	x14, x14, #176
	lsl	x15, x15, #5
	lsl	x16, x17, #5
	lsl	x17, x2, #6
	lsl	x18, x18, #6
	lsl	x0, x2, #5
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	dup	v0.2d, x3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
.LBB127_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x14, #-144]
	add	x1, x9, x0
	add	x3, x9, x17
	subs	x2, x2, #1
	ldp	q18, q19, [x14, #144]
	fadd	v3.2d, v5.2d, v18.2d
	fsub	v28.2d, v5.2d, v18.2d
	ldp	q25, q20, [x14, #112]
	fadd	v10.2d, v6.2d, v19.2d
	fsub	v1.2d, v6.2d, v19.2d
	stp	q3, q10, [sp, #704]             // 32-byte Folded Spill
	fmul	v14.2d, v3.2d, v30.2d
	ldp	q26, q5, [x14, #-112]
	fadd	v29.2d, v26.2d, v25.2d
	fsub	v25.2d, v26.2d, v25.2d
	ldp	q18, q6, [x14, #80]
	fadd	v11.2d, v5.2d, v20.2d
	fsub	v22.2d, v5.2d, v20.2d
	stp	q29, q28, [sp, #624]            // 32-byte Folded Spill
	str	q25, [sp, #736]                 // 16-byte Folded Spill
	stp	q1, q11, [sp, #672]             // 32-byte Folded Spill
	ldp	q19, q26, [x14, #-80]
	fadd	v2.2d, v19.2d, v18.2d
	fsub	v16.2d, v19.2d, v18.2d
	ldp	q20, q5, [x14, #48]
	fadd	v23.2d, v26.2d, v6.2d
	fsub	v6.2d, v26.2d, v6.2d
	str	q2, [sp, #656]                  // 16-byte Folded Spill
	stp	q16, q22, [sp, #928]            // 32-byte Folded Spill
	ldp	q12, q13, [x14, #-48]
	fadd	v19.2d, v12.2d, v20.2d
	fsub	v17.2d, v12.2d, v20.2d
	ldp	q3, q0, [x14, #-176]
	fmul	v20.2d, v10.2d, v30.2d
	fadd	v16.2d, v13.2d, v5.2d
	stp	q19, q23, [sp, #816]            // 32-byte Folded Spill
	fsub	v12.2d, v13.2d, v5.2d
	fadd	v14.2d, v3.2d, v14.2d
	mov	v5.16b, v2.16b
	ldr	q9, [sp, #896]                  // 16-byte Folded Reload
	stp	q0, q3, [sp, #864]              // 32-byte Folded Spill
	ldr	q24, [sp, #496]                 // 16-byte Folded Reload
	stp	q17, q16, [sp, #784]            // 32-byte Folded Spill
	fadd	v3.2d, v0.2d, v20.2d
	ldr	q18, [sp, #608]                 // 16-byte Folded Reload
	fmul	v15.2d, v29.2d, v9.2d
	ldp	q20, q31, [x14, #16]
	fmul	v0.2d, v22.2d, v24.2d
	ldr	q26, [sp, #416]                 // 16-byte Folded Reload
	fmul	v21.2d, v11.2d, v9.2d
	fmul	v27.2d, v25.2d, v24.2d
	str	q12, [sp, #848]                 // 16-byte Folded Spill
	ldp	q7, q17, [x14, #-16]
	fadd	v15.2d, v14.2d, v15.2d
	fmla	v0.2d, v18.2d, v1.2d
	fmul	v22.2d, v2.2d, v8.2d
	add	x14, x14, #352
	fadd	v21.2d, v3.2d, v21.2d
	fmla	v27.2d, v18.2d, v28.2d
	fadd	v4.2d, v7.2d, v20.2d
	fmul	v2.2d, v23.2d, v8.2d
	ldr	q3, [sp, #912]                  // 16-byte Folded Reload
	ldp	q25, q18, [sp, #384]            // 32-byte Folded Reload
	fsub	v15.2d, v15.2d, v22.2d
	stp	q4, q6, [sp, #752]              // 32-byte Folded Spill
	fmul	v23.2d, v19.2d, v26.2d
	fmla	v0.2d, v3.2d, v6.2d
	fsub	v14.2d, v17.2d, v31.2d
	mov	v22.16b, v6.16b
	fsub	v6.2d, v21.2d, v2.2d
	fmul	v21.2d, v16.2d, v26.2d
	fmla	v0.2d, v25.2d, v12.2d
	fsub	v23.2d, v15.2d, v23.2d
	ldr	q12, [sp, #704]                 // 16-byte Folded Reload
	mov	v16.16b, v28.16b
	fmul	v28.2d, v4.2d, v18.2d
	fsub	v19.2d, v7.2d, v20.2d
	ldr	q7, [sp, #592]                  // 16-byte Folded Reload
	ldr	q20, [sp, #928]                 // 16-byte Folded Reload
	fadd	v2.2d, v17.2d, v31.2d
	ldr	q31, [sp, #880]                 // 16-byte Folded Reload
	fsub	v15.2d, v23.2d, v28.2d
	fmla	v0.2d, v7.2d, v14.2d
	fmul	v28.2d, v12.2d, v9.2d
	fmla	v27.2d, v3.2d, v20.2d
	fmul	v17.2d, v10.2d, v9.2d
	stp	q14, q19, [sp, #544]            // 32-byte Folded Spill
	mov	v13.16b, v1.16b
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	fsub	v23.2d, v15.2d, v0.2d
	fadd	v31.2d, v31.2d, v28.2d
	ldr	q28, [sp, #864]                 // 16-byte Folded Reload
	fsub	v6.2d, v6.2d, v21.2d
	fmla	v27.2d, v25.2d, v1.2d
	fmul	v21.2d, v2.2d, v18.2d
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #736]                  // 16-byte Folded Reload
	fadd	v17.2d, v28.2d, v17.2d
	stur	q23, [x1, #-16]
	fmul	v28.2d, v29.2d, v26.2d
	fmla	v27.2d, v7.2d, v19.2d
	fmul	v23.2d, v2.2d, v25.2d
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fmul	v29.2d, v11.2d, v26.2d
	str	q9, [sp, #528]                  // 16-byte Folded Spill
	fsub	v3.2d, v6.2d, v21.2d
	fsub	v7.2d, v31.2d, v28.2d
	fmul	v28.2d, v2.2d, v25.2d
	fmla	v23.2d, v24.2d, v16.2d
	ldp	q31, q4, [sp, #816]             // 32-byte Folded Reload
	fsub	v17.2d, v17.2d, v29.2d
	fmul	v21.2d, v5.2d, v18.2d
	fmla	v28.2d, v24.2d, v13.2d
	fadd	v0.2d, v15.2d, v0.2d
	fsub	v5.2d, v3.2d, v27.2d
	ldp	q10, q24, [sp, #464]            // 32-byte Folded Reload
	fmul	v29.2d, v4.2d, v18.2d
	fsub	v7.2d, v7.2d, v21.2d
	fmul	v21.2d, v31.2d, v8.2d
	mov	v11.16b, v19.16b
	fsub	v17.2d, v17.2d, v29.2d
	ldr	q13, [sp, #800]                 // 16-byte Folded Reload
	fmla	v23.2d, v24.2d, v20.2d
	fmla	v28.2d, v24.2d, v22.2d
	ldr	q2, [sp, #752]                  // 16-byte Folded Reload
	fsub	v7.2d, v7.2d, v21.2d
	fmul	v29.2d, v13.2d, v8.2d
	fmla	v23.2d, v10.2d, v1.2d
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	fmul	v20.2d, v9.2d, v30.2d
	fadd	v21.2d, v27.2d, v3.2d
	ldr	q27, [sp, #624]                 // 16-byte Folded Reload
	fsub	v17.2d, v17.2d, v29.2d
	fmla	v28.2d, v10.2d, v1.2d
	fmul	v29.2d, v2.2d, v30.2d
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	ldp	q16, q11, [sp, #864]            // 32-byte Folded Reload
	str	q21, [x1]
	add	x1, x9, x18
	fmla	v28.2d, v1.2d, v14.2d
	fmla	v23.2d, v1.2d, v19.2d
	fadd	v6.2d, v7.2d, v29.2d
	fadd	v7.2d, v17.2d, v20.2d
	stp	q0, q5, [x1, #-16]
	fmul	v5.2d, v12.2d, v8.2d
	add	x1, x9, x16
	ldp	q19, q29, [sp, #720]            // 32-byte Folded Reload
	fsub	v0.2d, v6.2d, v28.2d
	ldr	q1, [sp, #896]                  // 16-byte Folded Reload
	fadd	v17.2d, v23.2d, v7.2d
	fsub	v5.2d, v11.2d, v5.2d
	ldr	q20, [sp, #368]                 // 16-byte Folded Reload
	mov	v3.16b, v12.16b
	ldr	q12, [sp, #688]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v28.2d
	ldr	q28, [sp, #656]                 // 16-byte Folded Reload
	stp	q0, q17, [x3, #-16]
	fmul	v0.2d, v19.2d, v8.2d
	fmul	v17.2d, v27.2d, v18.2d
	fmul	v21.2d, v12.2d, v18.2d
	fsub	v7.2d, v7.2d, v23.2d
	fsub	v0.2d, v16.2d, v0.2d
	fsub	v5.2d, v5.2d, v17.2d
	fmul	v17.2d, v28.2d, v1.2d
	stp	q6, q7, [x1, #-16]
	add	x1, x9, x15
	fsub	v0.2d, v0.2d, v21.2d
	fmul	v6.2d, v4.2d, v1.2d
	fadd	v5.2d, v5.2d, v17.2d
	fmul	v17.2d, v31.2d, v30.2d
	ldr	q31, [sp, #672]                 // 16-byte Folded Reload
	mov	v22.16b, v4.16b
	ldr	q4, [sp, #944]                  // 16-byte Folded Reload
	fadd	v1.2d, v0.2d, v6.2d
	ldr	q0, [sp, #912]                  // 16-byte Folded Reload
	fmul	v6.2d, v29.2d, v24.2d
	fadd	v5.2d, v5.2d, v17.2d
	fmul	v17.2d, v4.2d, v24.2d
	ldr	q24, [sp, #640]                 // 16-byte Folded Reload
	fmul	v21.2d, v2.2d, v26.2d
	fmul	v7.2d, v13.2d, v30.2d
	fmla	v6.2d, v0.2d, v24.2d
	fmla	v17.2d, v0.2d, v31.2d
	fsub	v0.2d, v5.2d, v21.2d
	ldr	q5, [sp, #848]                  // 16-byte Folded Reload
	fmul	v21.2d, v3.2d, v26.2d
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fadd	v1.2d, v1.2d, v7.2d
	fmul	v7.2d, v9.2d, v26.2d
	fmul	v23.2d, v27.2d, v8.2d
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	fsub	v21.2d, v11.2d, v21.2d
	ldr	q0, [sp, #768]                  // 16-byte Folded Reload
	fmla	v6.2d, v20.2d, v3.2d
	fsub	v9.2d, v1.2d, v7.2d
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	fmla	v17.2d, v20.2d, v0.2d
	fmul	v7.2d, v19.2d, v26.2d
	ldr	q19, [sp, #784]                 // 16-byte Folded Reload
	fsub	v21.2d, v21.2d, v23.2d
	fmul	v23.2d, v28.2d, v30.2d
	mov	v15.16b, v2.16b
	fmla	v6.2d, v1.2d, v19.2d
	ldp	q2, q13, [sp, #544]             // 32-byte Folded Reload
	fmla	v17.2d, v1.2d, v5.2d
	fsub	v7.2d, v16.2d, v7.2d
	fmul	v27.2d, v12.2d, v8.2d
	fadd	v21.2d, v21.2d, v23.2d
	fmul	v23.2d, v4.2d, v10.2d
	fmla	v17.2d, v25.2d, v2.2d
	fmul	v28.2d, v29.2d, v10.2d
	fmla	v6.2d, v25.2d, v13.2d
	ldp	q10, q4, [sp, #800]             // 32-byte Folded Reload
	mov	v14.16b, v1.16b
	fsub	v7.2d, v7.2d, v27.2d
	fmla	v23.2d, v25.2d, v31.2d
	fmul	v27.2d, v22.2d, v30.2d
	fmla	v28.2d, v25.2d, v24.2d
	mov	v12.16b, v29.16b
	fmul	v24.2d, v10.2d, v18.2d
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	fmla	v23.2d, v14.2d, v0.2d
	fadd	v7.2d, v7.2d, v27.2d
	fmla	v28.2d, v14.2d, v3.2d
	fadd	v27.2d, v6.2d, v9.2d
	ldr	q22, [sp, #896]                 // 16-byte Folded Reload
	fsub	v29.2d, v1.2d, v17.2d
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	fmul	v31.2d, v4.2d, v18.2d
	ldr	q14, [sp, #528]                 // 16-byte Folded Reload
	fsub	v7.2d, v7.2d, v24.2d
	ldr	q3, [sp, #656]                  // 16-byte Folded Reload
	fmul	v24.2d, v15.2d, v22.2d
	fmla	v23.2d, v0.2d, v5.2d
	stp	q29, q27, [x1, #-16]
	fmla	v28.2d, v0.2d, v19.2d
	fsub	v21.2d, v21.2d, v31.2d
	add	x1, x9, x13
	fmul	v27.2d, v14.2d, v22.2d
	mov	v31.16b, v5.16b
	fmla	v23.2d, v20.2d, v2.2d
	mov	v15.16b, v0.16b
	fmla	v28.2d, v20.2d, v13.2d
	fadd	v5.2d, v1.2d, v17.2d
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	fsub	v0.2d, v9.2d, v6.2d
	fadd	v6.2d, v21.2d, v24.2d
	ldr	q21, [sp, #704]                 // 16-byte Folded Reload
	fadd	v7.2d, v7.2d, v27.2d
	ldr	q24, [sp, #624]                 // 16-byte Folded Reload
	mov	v29.16b, v19.16b
	stp	q5, q0, [x1, #-16]
	add	x1, x9, x12
	fsub	v0.2d, v6.2d, v23.2d
	fadd	v5.2d, v28.2d, v7.2d
	fadd	v17.2d, v11.2d, v21.2d
	fmul	v21.2d, v21.2d, v18.2d
	fmul	v19.2d, v24.2d, v30.2d
	stp	q0, q5, [x1, #-16]
	add	x1, x9, x11
	fadd	v0.2d, v17.2d, v24.2d
	fsub	v5.2d, v11.2d, v21.2d
	ldr	q21, [sp, #720]                 // 16-byte Folded Reload
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v23.2d
	fmul	v17.2d, v21.2d, v18.2d
	fadd	v21.2d, v16.2d, v21.2d
	fadd	v5.2d, v5.2d, v19.2d
	fmul	v19.2d, v12.2d, v1.2d
	fsub	v17.2d, v16.2d, v17.2d
	ldr	q16, [sp, #688]                 // 16-byte Folded Reload
	fmul	v23.2d, v2.2d, v1.2d
	ldr	q1, [sp, #640]                  // 16-byte Folded Reload
	fadd	v0.2d, v0.2d, v3.2d
	fmul	v18.2d, v16.2d, v30.2d
	fmla	v19.2d, v15.2d, v1.2d
	ldr	q1, [sp, #672]                  // 16-byte Folded Reload
	fsub	v7.2d, v7.2d, v28.2d
	fadd	v21.2d, v21.2d, v16.2d
	fadd	v17.2d, v17.2d, v18.2d
	fmla	v23.2d, v15.2d, v1.2d
	fmul	v18.2d, v3.2d, v26.2d
	ldr	q3, [sp, #832]                  // 16-byte Folded Reload
	ldp	q16, q1, [sp, #912]             // 32-byte Folded Reload
	stp	q6, q7, [x1, #-16]
	fadd	v0.2d, v0.2d, v4.2d
	add	x1, x9, x10
	fmul	v24.2d, v3.2d, v26.2d
	fmla	v19.2d, v25.2d, v1.2d
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	fsub	v5.2d, v5.2d, v18.2d
	fmul	v18.2d, v10.2d, v22.2d
	fsub	v6.2d, v17.2d, v24.2d
	fmla	v23.2d, v25.2d, v1.2d
	fmul	v17.2d, v4.2d, v22.2d
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	fmla	v19.2d, v20.2d, v29.2d
	mov	v2.16b, v4.16b
	fmul	v7.2d, v1.2d, v8.2d
	fmla	v23.2d, v20.2d, v31.2d
	fadd	v5.2d, v5.2d, v17.2d
	fadd	v6.2d, v6.2d, v18.2d
	fmla	v19.2d, v16.2d, v13.2d
	fmul	v17.2d, v14.2d, v8.2d
	fmla	v23.2d, v16.2d, v9.2d
	fsub	v5.2d, v5.2d, v7.2d
	fadd	v7.2d, v21.2d, v3.2d
	fsub	v6.2d, v6.2d, v17.2d
	fadd	v3.2d, v0.2d, v1.2d
	fsub	v17.2d, v5.2d, v23.2d
	fadd	v7.2d, v7.2d, v10.2d
	fadd	v18.2d, v19.2d, v6.2d
	fadd	v5.2d, v5.2d, v23.2d
	fsub	v6.2d, v6.2d, v19.2d
	fadd	v0.2d, v7.2d, v14.2d
	stp	q17, q18, [x1, #-16]
	add	x1, x9, x8
	mov	v16.16b, v14.16b
	stp	q3, q0, [x9, #-16]
	add	x9, x9, #32
	stp	q5, q6, [x1, #-16]
	b.ne	.LBB127_3
	b	.LBB127_10
.LBB127_4:
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	cbz	x2, .LBB127_10
// %bb.5:
	lsl	x8, x2, #2
	mul	x11, x2, x1
	ldp	x6, x24, [sp, #176]             // 16-byte Folded Reload
	mov	w12, #352
	mov	w17, #288
	stp	x8, x2, [sp, #160]              // 16-byte Folded Spill
	add	x8, x8, x2
	mov	w3, #80
	mov	w16, #160
	mov	w10, #320
	lsl	x28, x2, #3
	str	x8, [sp, #144]                  // 8-byte Folded Spill
	lsl	x8, x8, #1
	madd	x25, x11, x16, x6
	add	x30, x6, x11, lsl #8
	madd	x18, x1, x10, x24
	lsl	x26, x2, #1
	stp	x28, x8, [sp, #128]             // 16-byte Folded Spill
	mov	w8, #192
	madd	x10, x11, x10, x6
	mov	x15, xzr
	madd	x9, x11, x8, x6
	str	x26, [sp, #152]                 // 8-byte Folded Spill
	str	x1, [sp, #104]                  // 8-byte Folded Spill
	str	x9, [sp, #208]                  // 8-byte Folded Spill
	mul	x9, x1, x12
	str	x9, [sp, #120]                  // 8-byte Folded Spill
	ldr	x9, [sp, #16]                   // 8-byte Folded Reload
	add	x13, x24, x9, lsl #6
	madd	x14, x9, x17, x24
	add	x0, x13, #64
	add	x13, x1, x1, lsl #1
	lsl	x12, x13, #5
	add	x13, x24, x9, lsl #8
	add	x19, x13, #256
	mov	w13, #224
	madd	x8, x9, x8, x24
	add	x7, x14, #288
	add	x14, x24, x9, lsl #7
	madd	x4, x9, x16, x24
	add	x20, x14, #128
	madd	x14, x9, x13, x24
	add	x23, x8, #192
	mov	w8, #48
	add	x21, x14, #224
	mul	x14, x1, x3
	mul	x8, x1, x8
	mov	x16, #17627
	sub	x9, x14, #80
	mov	w14, #112
	sub	x8, x8, #48
	movk	x16, #25615, lsl #16
	movk	x16, #14175, lsl #32
	lsl	x3, x1, #5
	stp	x8, x9, [sp, #224]              // 16-byte Folded Spill
	add	x9, x5, #8
	mul	x8, x1, x14
	movk	x16, #16322, lsl #48
	mov	w14, #96
	sub	x8, x8, #112
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	madd	x9, x11, x13, x6
	mov	x13, #61626
	movk	x13, #34660, lsl #16
	dup	v2.2d, x16
	movk	x13, #60300, lsl #32
	str	x8, [sp, #216]                  // 8-byte Folded Spill
	mov	x8, #4790
	movk	x13, #16362, lsl #48
	movk	x8, #55751, lsl #16
	mov	x16, #11283
	movk	x8, #38440, lsl #32
	movk	x16, #36590, lsl #16
	movk	x8, #16346, lsl #48
	dup	v9.2d, x13
	mov	x13, #22663
	movk	x16, #7092, lsl #32
	movk	x13, #32631, lsl #16
	movk	x16, #49133, lsl #48
	movk	x13, #62622, lsl #32
	dup	v1.2d, x8
	mov	x8, #20567
	movk	x13, #16356, lsl #48
	movk	x8, #39885, lsl #16
	str	x9, [sp, #200]                  // 8-byte Folded Spill
	movk	x8, #46122, lsl #32
	add	x9, x6, x11, lsl #7
	movk	x8, #16366, lsl #48
	dup	v0.2d, x13
	mov	x13, #22539
	str	x12, [sp, #112]                 // 8-byte Folded Spill
	movk	x13, #63675, lsl #16
	stp	q1, q0, [sp, #896]              // 32-byte Folded Spill
	movk	x13, #19693, lsl #32
	dup	v0.2d, x8
	mov	x8, #17135
	movk	x13, #49121, lsl #48
	movk	x8, #1080, lsl #16
	dup	v1.2d, x16
	movk	x8, #44190, lsl #32
	mov	x16, #10401
	movk	x8, #49135, lsl #48
	movk	x16, #47930, lsl #16
	stp	q2, q0, [sp, #928]              // 32-byte Folded Spill
	movk	x16, #12057, lsl #32
	dup	v0.2d, x13
	mov	x13, #36287
	movk	x16, #49128, lsl #48
	movk	x13, #64886, lsl #16
	str	q0, [sp, #880]                  // 16-byte Folded Spill
	movk	x13, #2023, lsl #32
	dup	v0.2d, x8
	movk	x13, #49106, lsl #48
	mov	x8, #36287
	mov	x5, #11283
	str	q0, [sp, #832]                  // 16-byte Folded Spill
	movk	x8, #64886, lsl #16
	dup	v0.2d, x16
	movk	x8, #2023, lsl #32
	mov	w16, #144
	movk	x8, #16338, lsl #48
	stp	q0, q1, [sp, #304]              // 32-byte Folded Spill
	dup	v0.2d, x13
	mov	x13, #17135
	mul	x16, x1, x16
	movk	x13, #1080, lsl #16
	dup	v1.2d, x8
	movk	x13, #44190, lsl #32
	madd	x8, x11, x14, x6
	movk	x13, #16367, lsl #48
	sub	x14, x16, #144
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	add	x16, x6, x11, lsl #6
	movk	x5, #36590, lsl #16
	add	x22, x4, #160
	str	x14, [sp, #96]                  // 8-byte Folded Spill
	dup	v0.2d, x13
	add	x13, x6, x11, lsl #5
	madd	x14, x11, x17, x6
	add	x11, x28, x2
	sub	x17, x28, x2
	movk	x5, #7092, lsl #32
	stp	q0, q1, [sp, #272]              // 32-byte Folded Spill
	movk	x5, #16365, lsl #48
	str	x11, [sp, #88]                  // 8-byte Folded Spill
	add	x11, x26, x2
	dup	v0.2d, x5
	stp	x17, x11, [sp, #72]             // 16-byte Folded Spill
	lsl	x11, x11, #1
	add	x17, x24, x3
	stp	x11, x3, [sp, #56]              // 16-byte Folded Spill
	add	x11, x12, x24
	lsl	x12, x1, #6
	str	x12, [sp, #48]                  // 8-byte Folded Spill
	sub	x12, x3, #32
	lsl	x3, x1, #4
	str	x12, [sp, #40]                  // 8-byte Folded Spill
	lsl	x12, x1, #7
	ldr	x29, [sp, #40]                  // 8-byte Folded Reload
	stp	x3, x12, [sp, #24]              // 16-byte Folded Spill
	mov	x12, #22539
	movk	x12, #63675, lsl #16
	movk	x12, #19693, lsl #32
	movk	x12, #16353, lsl #48
	dup	v1.2d, x12
	stp	q0, q1, [sp, #240]              // 32-byte Folded Spill
	b	.LBB127_7
.LBB127_6:                              //   in Loop: Header=BB127_7 Depth=1
	ldr	x10, [sp, #64]                  // 8-byte Folded Reload
	ldp	x4, x3, [sp, #336]              // 16-byte Folded Reload
	mov	v9.16b, v31.16b
	add	x9, x9, x10
	ldr	x12, [sp, #360]                 // 8-byte Folded Reload
	ldr	x15, [sp, #192]                 // 8-byte Folded Reload
	add	x1, x1, x10
	add	x11, x11, x10
	ldr	x2, [sp, #168]                  // 8-byte Folded Reload
	stp	x1, x9, [sp, #200]              // 16-byte Folded Spill
	ldr	x9, [sp, #120]                  // 8-byte Folded Reload
	add	x15, x15, #1
	add	x25, x25, x10
	add	x30, x30, x10
	add	x24, x4, x9
	add	x17, x6, x9
	add	x18, x18, x9
	add	x0, x0, x9
	add	x7, x7, x9
	add	x12, x12, x9
	add	x19, x19, x9
	add	x20, x20, x9
	add	x21, x21, x9
	add	x22, x22, x9
	add	x23, x23, x9
	ldr	x9, [sp, #352]                  // 8-byte Folded Reload
	add	x6, x3, x10
	add	x8, x8, x10
	add	x13, x13, x10
	add	x16, x16, x10
	add	x9, x9, x10
	add	x14, x14, x10
	ldr	x1, [sp, #104]                  // 8-byte Folded Reload
	mov	x10, x11
	mov	x11, x12
	cmp	x15, x2
	b.eq	.LBB127_10
.LBB127_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB127_9 Depth 2
	stp	x9, x11, [sp, #352]             // 16-byte Folded Spill
	mov	w11, #11
	ldr	x9, [sp, #184]                  // 8-byte Folded Reload
	add	x2, x15, x2
	mul	x4, x15, x11
	ldr	x11, [sp, #88]                  // 8-byte Folded Reload
	mul	x2, x2, x1
	str	x15, [sp, #192]                 // 8-byte Folded Spill
	add	x5, x4, #10
	add	x12, x4, #9
	mul	x26, x4, x1
	add	x3, x4, #2
	mul	x5, x5, x1
	cmp	x1, #2
	mul	x12, x12, x1
	stp	x24, x6, [sp, #336]             // 16-byte Folded Spill
	add	x28, x9, x26, lsl #5
	add	x26, x1, x26
	mul	x3, x3, x1
	add	x5, x9, x5, lsl #5
	add	x26, x9, x26, lsl #5
	add	x12, x9, x12, lsl #5
	ldp	q19, q5, [x28]
	add	x28, x4, #3
	add	x3, x9, x3, lsl #5
	mov	x6, x17
	mov	v31.16b, v19.16b
	ldp	q0, q1, [x26]
	mul	x26, x28, x1
	ldp	q2, q3, [x5]
	fadd	v30.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	ldp	q7, q16, [x12]
	add	x12, x4, #8
	fadd	v26.2d, v1.2d, v3.2d
	str	q30, [sp, #656]                 // 16-byte Folded Spill
	mul	x12, x12, x1
	fsub	v20.2d, v1.2d, v3.2d
	ldp	q4, q6, [x3]
	add	x3, x9, x26, lsl #5
	add	x12, x9, x12, lsl #5
	fadd	v22.2d, v4.2d, v7.2d
	fsub	v25.2d, v4.2d, v7.2d
	ldp	q17, q21, [x3]
	add	x3, x4, #4
	fadd	v4.2d, v19.2d, v30.2d
	stp	q22, q0, [sp, #784]             // 32-byte Folded Spill
	mul	x3, x3, x1
	fadd	v11.2d, v6.2d, v16.2d
	fsub	v27.2d, v6.2d, v16.2d
	ldp	q0, q1, [x12]
	add	x12, x4, #7
	add	x3, x9, x3, lsl #5
	fadd	v4.2d, v4.2d, v22.2d
	mul	x12, x12, x1
	stp	q26, q27, [sp, #624]            // 32-byte Folded Spill
	fadd	v28.2d, v17.2d, v0.2d
	fsub	v8.2d, v17.2d, v0.2d
	ldp	q2, q3, [x3]
	add	x3, x4, #5
	add	x4, x4, #6
	add	x12, x9, x12, lsl #5
	str	q28, [sp, #816]                 // 16-byte Folded Spill
	mul	x3, x3, x1
	mul	x4, x4, x1
	fadd	v10.2d, v21.2d, v1.2d
	fsub	v15.2d, v21.2d, v1.2d
	add	x3, x9, x3, lsl #5
	ldp	q0, q1, [x12]
	add	x12, x9, x4, lsl #5
	mov	v17.16b, v22.16b
	str	q15, [sp, #864]                 // 16-byte Folded Spill
	fadd	v18.2d, v2.2d, v0.2d
	fsub	v22.2d, v2.2d, v0.2d
	ldp	q6, q7, [x3]
	fadd	v2.2d, v4.2d, v28.2d
	fadd	v29.2d, v3.2d, v1.2d
	stp	q25, q18, [sp, #592]            // 32-byte Folded Spill
	fsub	v13.2d, v3.2d, v1.2d
	str	q22, [sp, #768]                 // 16-byte Folded Spill
	fadd	v4.2d, v5.2d, v26.2d
	fadd	v1.2d, v2.2d, v18.2d
	ldp	q16, q0, [x12]
	fmul	v2.2d, v30.2d, v9.2d
	mul	x12, x15, x1
	fadd	v4.2d, v4.2d, v11.2d
	stp	q5, q13, [sp, #672]             // 32-byte Folded Spill
	str	q29, [sp, #560]                 // 16-byte Folded Spill
	fadd	v3.2d, v6.2d, v16.2d
	fsub	v12.2d, v6.2d, v16.2d
	fadd	v24.2d, v7.2d, v0.2d
	ldr	q21, [sp, #320]                 // 16-byte Folded Reload
	fsub	v14.2d, v7.2d, v0.2d
	ldr	x9, [sp, #176]                  // 8-byte Folded Reload
	fadd	v0.2d, v1.2d, v3.2d
	ldr	x4, [sp, #112]                  // 8-byte Folded Reload
	mov	v23.16b, v3.16b
	ldr	q3, [sp, #896]                  // 16-byte Folded Reload
	fadd	v2.2d, v19.2d, v2.2d
	add	x12, x9, x12, lsl #5
	fmul	v1.2d, v26.2d, v9.2d
	add	x2, x9, x2, lsl #5
	fmul	v3.2d, v17.2d, v3.2d
	str	q14, [sp, #848]                 // 16-byte Folded Spill
	ldp	q17, q6, [sp, #880]             // 32-byte Folded Reload
	fmul	v7.2d, v27.2d, v21.2d
	stp	q23, q8, [sp, #736]             // 32-byte Folded Spill
	fadd	v1.2d, v5.2d, v1.2d
	fadd	v2.2d, v2.2d, v3.2d
	fmul	v16.2d, v25.2d, v21.2d
	mov	v19.16b, v20.16b
	fmla	v7.2d, v17.2d, v20.2d
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fmul	v6.2d, v11.2d, v6.2d
	ldr	q20, [sp, #800]                 // 16-byte Folded Reload
	fadd	v4.2d, v4.2d, v10.2d
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	fmul	v3.2d, v28.2d, v3.2d
	ldr	q28, [sp, #832]                 // 16-byte Folded Reload
	mov	v17.16b, v10.16b
	fadd	v1.2d, v1.2d, v6.2d
	ldr	q6, [sp, #928]                  // 16-byte Folded Reload
	fmla	v7.2d, v28.2d, v15.2d
	fsub	v2.2d, v2.2d, v3.2d
	ldr	q3, [sp, #880]                  // 16-byte Folded Reload
	fmul	v6.2d, v10.2d, v6.2d
	fadd	v4.2d, v4.2d, v29.2d
	fmla	v16.2d, v3.2d, v20.2d
	ldr	q3, [sp, #912]                  // 16-byte Folded Reload
	mov	v10.16b, v30.16b
	fsub	v1.2d, v1.2d, v6.2d
	ldr	q6, [sp, #912]                  // 16-byte Folded Reload
	fmul	v3.2d, v18.2d, v3.2d
	fmla	v16.2d, v28.2d, v8.2d
	ldr	q28, [sp, #304]                 // 16-byte Folded Reload
	fmul	v6.2d, v29.2d, v6.2d
	mov	v15.16b, v12.16b
	fsub	v2.2d, v2.2d, v3.2d
	ldr	q3, [sp, #944]                  // 16-byte Folded Reload
	fmla	v7.2d, v28.2d, v13.2d
	fmla	v16.2d, v28.2d, v22.2d
	fsub	v1.2d, v1.2d, v6.2d
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	fmul	v3.2d, v23.2d, v3.2d
	ldr	q13, [sp, #816]                 // 16-byte Folded Reload
	mov	v5.16b, v24.16b
	stp	q19, q15, [sp, #704]            // 32-byte Folded Spill
	fmul	v6.2d, v24.2d, v6.2d
	fsub	v2.2d, v2.2d, v3.2d
	ldr	q3, [sp, #576]                  // 16-byte Folded Reload
	fsub	v1.2d, v1.2d, v6.2d
	fmla	v7.2d, v3.2d, v14.2d
	fmla	v16.2d, v3.2d, v12.2d
	fadd	v3.2d, v4.2d, v24.2d
	mov	v12.16b, v26.16b
	mov	v14.16b, v17.16b
	fsub	v4.2d, v2.2d, v7.2d
	fadd	v6.2d, v16.2d, v1.2d
	stp	q0, q3, [x12]
	ldr	x12, [sp, #136]                 // 8-byte Folded Reload
	fadd	v2.2d, v2.2d, v7.2d
	stp	q4, q6, [x2]
	ldp	q0, q6, [sp, #896]              // 32-byte Folded Reload
	ldp	q3, q4, [sp, #896]              // 32-byte Folded Reload
	fmul	v0.2d, v30.2d, v0.2d
	add	x12, x15, x12
	fmul	v6.2d, v11.2d, v6.2d
	add	x2, x15, x11
	mul	x12, x12, x1
	fmul	v3.2d, v26.2d, v3.2d
	fadd	v0.2d, v31.2d, v0.2d
	ldr	q30, [sp, #784]                 // 16-byte Folded Reload
	add	x12, x9, x12, lsl #5
	ldr	q26, [sp, #672]                 // 16-byte Folded Reload
	fsub	v1.2d, v1.2d, v16.2d
	ldr	x11, [sp, #80]                  // 8-byte Folded Reload
	fmul	v4.2d, v30.2d, v4.2d
	fadd	v3.2d, v26.2d, v3.2d
	stp	q2, q1, [x12]
	fsub	v4.2d, v0.2d, v4.2d
	ldp	q1, q0, [sp, #928]              // 32-byte Folded Reload
	fsub	v3.2d, v3.2d, v6.2d
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	ldr	x12, [sp, #152]                 // 8-byte Folded Reload
	fmul	v7.2d, v13.2d, v0.2d
	fmul	v6.2d, v17.2d, v6.2d
	fmul	v0.2d, v25.2d, v28.2d
	ldr	q25, [sp, #256]                 // 16-byte Folded Reload
	add	x12, x15, x12
	fsub	v4.2d, v4.2d, v7.2d
	ldr	q7, [sp, #928]                  // 16-byte Folded Reload
	fsub	v2.2d, v3.2d, v6.2d
	mul	x12, x12, x1
	fmul	v6.2d, v23.2d, v9.2d
	fmla	v0.2d, v21.2d, v20.2d
	fmul	v7.2d, v18.2d, v7.2d
	fmul	v3.2d, v29.2d, v1.2d
	add	x12, x9, x12, lsl #5
	fmul	v1.2d, v27.2d, v28.2d
	ldp	q18, q17, [sp, #272]            // 32-byte Folded Reload
	fsub	v4.2d, v4.2d, v7.2d
	fsub	v2.2d, v2.2d, v3.2d
	fmul	v3.2d, v24.2d, v9.2d
	fmla	v1.2d, v21.2d, v19.2d
	mov	v20.16b, v23.16b
	fadd	v4.2d, v4.2d, v6.2d
	fmla	v0.2d, v17.2d, v8.2d
	mov	v29.16b, v9.16b
	ldr	q9, [sp, #592]                  // 16-byte Folded Reload
	mov	v24.16b, v14.16b
	str	q4, [sp, #544]                  // 16-byte Folded Spill
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	fmla	v0.2d, v18.2d, v22.2d
	fmul	v6.2d, v10.2d, v4.2d
	ldr	q10, [sp, #800]                 // 16-byte Folded Reload
	fadd	v4.2d, v2.2d, v3.2d
	ldr	q2, [sp, #928]                  // 16-byte Folded Reload
	ldr	q3, [sp, #864]                  // 16-byte Folded Reload
	fmla	v0.2d, v25.2d, v15.2d
	fmul	v16.2d, v12.2d, v2.2d
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fsub	v6.2d, v31.2d, v6.2d
	fmla	v1.2d, v17.2d, v3.2d
	ldr	q12, [sp, #688]                 // 16-byte Folded Reload
	fmul	v7.2d, v30.2d, v2.2d
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fsub	v21.2d, v26.2d, v16.2d
	ldr	q30, [sp, #848]                 // 16-byte Folded Reload
	fmla	v1.2d, v18.2d, v12.2d
	fmul	v16.2d, v11.2d, v2.2d
	ldr	q2, [sp, #896]                  // 16-byte Folded Reload
	fsub	v6.2d, v6.2d, v7.2d
	fmul	v7.2d, v13.2d, v2.2d
	ldr	q2, [sp, #896]                  // 16-byte Folded Reload
	fsub	v23.2d, v21.2d, v16.2d
	fmla	v1.2d, v25.2d, v30.2d
	fmul	v16.2d, v14.2d, v2.2d
	ldr	q14, [sp, #560]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v7.2d
	fmul	v7.2d, v9.2d, v17.2d
	fmul	v17.2d, v27.2d, v17.2d
	ldr	q27, [sp, #608]                 // 16-byte Folded Reload
	fadd	v2.2d, v23.2d, v16.2d
	ldr	q23, [sp, #832]                 // 16-byte Folded Reload
	fmul	v16.2d, v14.2d, v29.2d
	fmul	v21.2d, v27.2d, v29.2d
	fmla	v17.2d, v23.2d, v19.2d
	fmla	v7.2d, v23.2d, v10.2d
	ldr	q19, [sp, #544]                 // 16-byte Folded Reload
	ldr	q23, [sp, #240]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v21.2d
	fsub	v21.2d, v19.2d, v1.2d
	fmla	v17.2d, v23.2d, v3.2d
	fmla	v7.2d, v23.2d, v8.2d
	fadd	v3.2d, v2.2d, v16.2d
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	fadd	v16.2d, v0.2d, v4.2d
	fadd	v1.2d, v19.2d, v1.2d
	fsub	v0.2d, v4.2d, v0.2d
	mov	v8.16b, v27.16b
	stp	q21, q16, [x12]
	mul	x12, x2, x1
	fmul	v21.2d, v20.2d, v2.2d
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	add	x2, x15, x11
	ldr	x11, [sp, #72]                  // 8-byte Folded Reload
	add	x12, x9, x12, lsl #5
	fmla	v7.2d, v2.2d, v22.2d
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	fsub	v6.2d, v6.2d, v21.2d
	mul	x2, x2, x1
	stp	q1, q0, [x12]
	ldr	x12, [sp, #128]                 // 8-byte Folded Reload
	fmla	v17.2d, v2.2d, v12.2d
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	fmla	v7.2d, v28.2d, v15.2d
	add	x2, x9, x2, lsl #5
	mov	v16.16b, v18.16b
	ldr	q18, [sp, #656]                 // 16-byte Folded Reload
	fmul	v2.2d, v5.2d, v2.2d
	add	x12, x15, x12
	fmla	v17.2d, v28.2d, v30.2d
	mov	v22.16b, v5.16b
	mul	x12, x12, x1
	mov	v30.16b, v31.16b
	fsub	v2.2d, v3.2d, v2.2d
	fsub	v3.2d, v6.2d, v17.2d
	add	x12, x9, x12, lsl #5
	fadd	v1.2d, v6.2d, v17.2d
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	ldp	q19, q17, [sp, #624]            // 32-byte Folded Reload
	fadd	v4.2d, v7.2d, v2.2d
	fsub	v2.2d, v2.2d, v7.2d
	fmul	v6.2d, v14.2d, v6.2d
	stp	q3, q4, [x2]
	ldp	q0, q4, [sp, #912]              // 32-byte Folded Reload
	stp	q1, q2, [x12]
	fmul	v2.2d, v13.2d, v29.2d
	fmul	v1.2d, v17.2d, v16.2d
	fmul	v0.2d, v18.2d, v0.2d
	fmul	v7.2d, v17.2d, v25.2d
	ldp	q3, q5, [sp, #912]              // 32-byte Folded Reload
	fsub	v0.2d, v31.2d, v0.2d
	fmul	v3.2d, v19.2d, v3.2d
	ldr	q31, [sp, #784]                 // 16-byte Folded Reload
	fmul	v5.2d, v11.2d, v5.2d
	ldr	q13, [sp, #576]                 // 16-byte Folded Reload
	fsub	v3.2d, v26.2d, v3.2d
	ldr	x12, [sp, #160]                 // 8-byte Folded Reload
	fmul	v4.2d, v31.2d, v4.2d
	ldr	x2, [sp, #144]                  // 8-byte Folded Reload
	ldp	q15, q17, [sp, #736]            // 32-byte Folded Reload
	add	x12, x15, x12
	fsub	v3.2d, v3.2d, v5.2d
	add	x2, x15, x2
	fsub	v0.2d, v0.2d, v4.2d
	mul	x12, x12, x1
	fmul	v4.2d, v24.2d, v29.2d
	mul	x2, x2, x1
	mov	v5.16b, v9.16b
	fmul	v5.2d, v9.2d, v25.2d
	fadd	v2.2d, v0.2d, v2.2d
	add	x12, x9, x12, lsl #5
	fadd	v3.2d, v3.2d, v4.2d
	add	x2, x9, x2, lsl #5
	ldp	q20, q4, [sp, #928]             // 32-byte Folded Reload
	fmul	v0.2d, v9.2d, v16.2d
	fmla	v5.2d, v13.2d, v10.2d
	fsub	v3.2d, v3.2d, v6.2d
	fmla	v0.2d, v28.2d, v10.2d
	fmla	v5.2d, v28.2d, v17.2d
	fmul	v4.2d, v27.2d, v4.2d
	ldp	q16, q25, [sp, #704]            // 32-byte Folded Reload
	ldr	q6, [sp, #880]                  // 16-byte Folded Reload
	ldr	q10, [sp, #768]                 // 16-byte Folded Reload
	fmla	v1.2d, v28.2d, v16.2d
	fmla	v7.2d, v13.2d, v16.2d
	fsub	v2.2d, v2.2d, v4.2d
	fmla	v0.2d, v6.2d, v17.2d
	ldp	q27, q4, [sp, #864]             // 32-byte Folded Reload
	fmla	v5.2d, v23.2d, v10.2d
	fmla	v0.2d, v13.2d, v10.2d
	fmla	v7.2d, v28.2d, v27.2d
	ldr	q6, [sp, #896]                  // 16-byte Folded Reload
	fmla	v1.2d, v4.2d, v27.2d
	ldr	q16, [sp, #944]                 // 16-byte Folded Reload
	fmla	v0.2d, v23.2d, v25.2d
	ldp	q4, q21, [sp, #896]             // 32-byte Folded Reload
	fmul	v6.2d, v22.2d, v6.2d
	fmla	v7.2d, v23.2d, v12.2d
	fmul	v16.2d, v18.2d, v16.2d
	fmla	v1.2d, v13.2d, v12.2d
	fmul	v18.2d, v11.2d, v29.2d
	fmul	v4.2d, v15.2d, v4.2d
	fadd	v3.2d, v3.2d, v6.2d
	fsub	v6.2d, v30.2d, v16.2d
	ldr	q30, [sp, #848]                 // 16-byte Folded Reload
	fmul	v16.2d, v31.2d, v29.2d
	fadd	v2.2d, v2.2d, v4.2d
	ldr	q4, [sp, #944]                  // 16-byte Folded Reload
	fmla	v1.2d, v23.2d, v30.2d
	mov	v31.16b, v29.16b
	fmul	v4.2d, v19.2d, v4.2d
	ldr	q19, [sp, #896]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v16.2d
	fsub	v17.2d, v2.2d, v1.2d
	fadd	v16.2d, v0.2d, v3.2d
	fsub	v4.2d, v26.2d, v4.2d
	fadd	v1.2d, v2.2d, v1.2d
	fsub	v0.2d, v3.2d, v0.2d
	stp	q17, q16, [x12]
	ldr	q17, [sp, #816]                 // 16-byte Folded Reload
	fadd	v4.2d, v4.2d, v18.2d
	add	x12, x15, x11
	fmul	v18.2d, v24.2d, v21.2d
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	fmul	v17.2d, v17.2d, v21.2d
	mul	x12, x12, x1
	fmul	v16.2d, v8.2d, v19.2d
	add	x3, x15, x11
	mov	x11, x10
	fsub	v4.2d, v4.2d, v18.2d
	ldr	q18, [sp, #832]                 // 16-byte Folded Reload
	fsub	v6.2d, v6.2d, v17.2d
	add	x12, x9, x12, lsl #5
	fmul	v17.2d, v14.2d, v19.2d
	ldr	x10, [sp, #96]                  // 8-byte Folded Reload
	fmla	v5.2d, v18.2d, v25.2d
	fmla	v7.2d, v18.2d, v30.2d
	stp	q1, q0, [x12]
	mul	x12, x3, x1
	fadd	v2.2d, v6.2d, v16.2d
	fadd	v4.2d, v4.2d, v17.2d
	fmul	v6.2d, v15.2d, v20.2d
	add	x12, x9, x12, lsl #5
	fmul	v16.2d, v22.2d, v20.2d
	ldp	x1, x9, [sp, #200]              // 16-byte Folded Reload
	fsub	v2.2d, v2.2d, v6.2d
	fsub	v3.2d, v4.2d, v16.2d
	ldp	x15, x27, [sp, #24]             // 16-byte Folded Reload
	fsub	v0.2d, v2.2d, v7.2d
	fadd	v1.2d, v5.2d, v3.2d
	fadd	v2.2d, v2.2d, v7.2d
	fsub	v3.2d, v3.2d, v5.2d
	stp	q0, q1, [x2]
	stp	q2, q3, [x12]
	b.lo	.LBB127_6
// %bb.8:                               //   in Loop: Header=BB127_7 Depth=1
	ldp	x28, x5, [sp, #8]               // 16-byte Folded Reload
	mov	v11.16b, v18.16b
	mov	x26, xzr
.LBB127_9:                              //   Parent Loop BB127_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x12, x6, x26
	add	x2, x18, x26
	ldr	x3, [sp, #336]                  // 8-byte Folded Reload
	mov	x24, x27
	subs	x5, x5, #1
	ldp	q0, q1, [x12, #32]
	add	x12, x0, x26
	add	x3, x3, x26
	ldp	q2, q3, [x2, #32]
	add	x2, x7, x26
	fadd	v24.2d, v0.2d, v2.2d
	fsub	v13.2d, v0.2d, v2.2d
	ldp	q4, q5, [x12, #32]
	fadd	v18.2d, v1.2d, v3.2d
	fsub	v26.2d, v1.2d, v3.2d
	ldr	x12, [sp, #360]                 // 8-byte Folded Reload
	str	q26, [sp, #640]                 // 16-byte Folded Spill
	ldp	q0, q2, [x2, #32]
	add	x2, x19, x26
	add	x12, x12, x26
	fadd	v22.2d, v4.2d, v0.2d
	fsub	v12.2d, v4.2d, v0.2d
	ldp	q1, q3, [x12, #32]
	add	x12, x20, x26
	fadd	v23.2d, v5.2d, v2.2d
	str	q22, [sp, #608]                 // 16-byte Folded Spill
	fsub	v25.2d, v5.2d, v2.2d
	stp	q13, q12, [sp, #688]            // 32-byte Folded Spill
	ldp	q6, q0, [x2, #32]
	add	x2, x21, x26
	fadd	v21.2d, v1.2d, v6.2d
	fsub	v9.2d, v1.2d, v6.2d
	fadd	v27.2d, v3.2d, v0.2d
	ldp	q1, q2, [x12, #32]
	fsub	v8.2d, v3.2d, v0.2d
	add	x12, x22, x26
	stp	q8, q9, [sp, #656]              // 32-byte Folded Spill
	ldp	q0, q3, [x2, #32]
	add	x2, x23, x26
	fadd	v28.2d, v1.2d, v0.2d
	fsub	v20.2d, v1.2d, v0.2d
	ldp	q5, q6, [x12, #32]
	fadd	v15.2d, v2.2d, v3.2d
	fsub	v19.2d, v2.2d, v3.2d
	ldp	q7, q0, [x2, #32]
	mov	x2, x28
	fadd	v14.2d, v5.2d, v7.2d
	fsub	v29.2d, v5.2d, v7.2d
	ldp	q16, q17, [x3, #32]
	fadd	v2.2d, v6.2d, v0.2d
	add	x3, x28, x27
	fsub	v10.2d, v6.2d, v0.2d
	mov	x27, x17
	fmul	v0.2d, v24.2d, v31.2d
	stp	q20, q29, [sp, #752]            // 32-byte Folded Spill
	stp	q16, q24, [sp, #848]            // 32-byte Folded Spill
	mov	x17, x10
	fadd	v4.2d, v16.2d, v24.2d
	str	q2, [sp, #592]                  // 16-byte Folded Spill
	fmul	v2.2d, v18.2d, v31.2d
	ldr	x12, [sp, #344]                 // 8-byte Folded Reload
	fadd	v0.2d, v16.2d, v0.2d
	stp	q19, q10, [sp, #720]            // 32-byte Folded Spill
	ldp	q16, q30, [sp, #880]            // 32-byte Folded Reload
	mov	v24.16b, v18.16b
	add	x12, x12, x26
	fadd	v3.2d, v17.2d, v18.2d
	fadd	v1.2d, v4.2d, v22.2d
	fadd	v2.2d, v17.2d, v2.2d
	ldr	q18, [sp, #320]                 // 16-byte Folded Reload
	fmul	v4.2d, v22.2d, v30.2d
	mov	v22.16b, v17.16b
	mov	v17.16b, v25.16b
	fmul	v6.2d, v25.2d, v18.2d
	ldr	q25, [sp, #928]                 // 16-byte Folded Reload
	fadd	v0.2d, v0.2d, v4.2d
	fmul	v7.2d, v12.2d, v18.2d
	fmul	v4.2d, v21.2d, v25.2d
	fmla	v6.2d, v16.2d, v26.2d
	ldr	q26, [sp, #912]                 // 16-byte Folded Reload
	fmul	v5.2d, v23.2d, v30.2d
	fadd	v1.2d, v1.2d, v21.2d
	fmla	v7.2d, v16.2d, v13.2d
	fsub	v0.2d, v0.2d, v4.2d
	ldr	q16, [sp, #944]                 // 16-byte Folded Reload
	fmul	v4.2d, v28.2d, v26.2d
	fmla	v6.2d, v11.2d, v8.2d
	fadd	v2.2d, v2.2d, v5.2d
	fmul	v5.2d, v27.2d, v25.2d
	fmla	v7.2d, v11.2d, v9.2d
	fadd	v1.2d, v1.2d, v28.2d
	mov	v12.16b, v28.16b
	ldr	q28, [sp, #304]                 // 16-byte Folded Reload
	fadd	v3.2d, v3.2d, v23.2d
	fsub	v0.2d, v0.2d, v4.2d
	fmul	v4.2d, v14.2d, v16.2d
	fmla	v6.2d, v28.2d, v19.2d
	fsub	v2.2d, v2.2d, v5.2d
	fmla	v7.2d, v28.2d, v20.2d
	fmul	v5.2d, v15.2d, v26.2d
	fadd	v3.2d, v3.2d, v27.2d
	fsub	v0.2d, v0.2d, v4.2d
	ldp	q4, q13, [sp, #576]             // 32-byte Folded Reload
	fadd	v1.2d, v1.2d, v14.2d
	fsub	v2.2d, v2.2d, v5.2d
	fmul	v5.2d, v13.2d, v16.2d
	fmla	v6.2d, v4.2d, v10.2d
	fadd	v3.2d, v3.2d, v15.2d
	fmla	v7.2d, v4.2d, v29.2d
	mov	v19.16b, v24.16b
	mov	v10.16b, v23.16b
	fsub	v2.2d, v2.2d, v5.2d
	fsub	v4.2d, v0.2d, v6.2d
	fadd	v3.2d, v3.2d, v13.2d
	fadd	v6.2d, v0.2d, v6.2d
	fadd	v5.2d, v7.2d, v2.2d
	fneg	v16.2d, v4.2d
	stp	q1, q3, [x12, #32]
	ldr	x12, [sp, #232]                 // 8-byte Folded Reload
	ldur	d1, [x28, #-8]
	fsub	v7.2d, v2.2d, v7.2d
	ld1r	{ v3.2d }, [x2], x12
	fmul	v9.2d, v5.2d, v3.2d
	fmul	v20.2d, v3.2d, v16.2d
	str	q24, [sp, #416]                 // 16-byte Folded Spill
	fmul	v16.2d, v24.2d, v30.2d
	ldp	q24, q25, [sp, #848]            // 32-byte Folded Reload
	fmul	v3.2d, v25.2d, v30.2d
	add	x12, x28, x10
	fmla	v9.2d, v4.2d, v1.d[0]
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fmla	v20.2d, v5.2d, v1.d[0]
	stp	q22, q21, [sp, #784]            // 32-byte Folded Spill
	fmul	v5.2d, v23.2d, v26.2d
	str	q14, [sp, #512]                 // 16-byte Folded Spill
	fadd	v1.2d, v24.2d, v3.2d
	str	q17, [sp, #368]                 // 16-byte Folded Spill
	fadd	v3.2d, v22.2d, v16.2d
	str	q23, [sp, #624]                 // 16-byte Folded Spill
	stp	q9, q20, [sp, #528]             // 32-byte Folded Spill
	ldr	q9, [sp, #608]                  // 16-byte Folded Reload
	ldp	d20, d16, [x12, #-8]
	mov	v8.16b, v14.16b
	add	x12, x28, x15
	fmul	v4.2d, v9.2d, v26.2d
	mov	x10, x4
	fsub	v3.2d, v3.2d, v5.2d
	add	x4, x28, x29
	fneg	v5.2d, v6.2d
	stp	q20, q7, [sp, #480]             // 32-byte Folded Spill
	mov	v26.16b, v21.16b
	str	q27, [sp, #816]                 // 16-byte Folded Spill
	fsub	v2.2d, v1.2d, v4.2d
	fmul	v4.2d, v21.2d, v0.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fmul	v1.2d, v7.2d, v16.d[0]
	mov	v29.16b, v13.16b
	fmul	v7.2d, v27.2d, v0.2d
	ldr	q0, [sp, #928]                  // 16-byte Folded Reload
	fsub	v2.2d, v2.2d, v4.2d
	fmla	v1.2d, v6.2d, v20.d[0]
	fmul	v4.2d, v12.2d, v0.2d
	fmul	v0.2d, v5.2d, v16.d[0]
	fsub	v3.2d, v3.2d, v7.2d
	fmul	v6.2d, v14.2d, v31.2d
	ldp	q20, q11, [sp, #640]            // 32-byte Folded Reload
	str	q0, [sp, #464]                  // 16-byte Folded Spill
	fsub	v4.2d, v2.2d, v4.2d
	str	q1, [sp, #560]                  // 16-byte Folded Spill
	fmul	v2.2d, v17.2d, v28.2d
	mov	v14.16b, v17.16b
	mov	v23.16b, v12.16b
	ldr	q0, [sp, #928]                  // 16-byte Folded Reload
	fadd	v4.2d, v4.2d, v6.2d
	fmla	v2.2d, v18.2d, v20.2d
	mov	v12.16b, v13.16b
	fmul	v5.2d, v15.2d, v0.2d
	ldr	q0, [sp, #928]                  // 16-byte Folded Reload
	stp	q15, q23, [sp, #384]            // 32-byte Folded Spill
	mov	v29.16b, v31.16b
	fmul	v7.2d, v25.2d, v0.2d
	ldr	q0, [sp, #928]                  // 16-byte Folded Reload
	fsub	v3.2d, v3.2d, v5.2d
	ldr	q25, [sp, #720]                 // 16-byte Folded Reload
	fmul	v16.2d, v19.2d, v0.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fsub	v5.2d, v24.2d, v7.2d
	mov	v24.16b, v23.16b
	fmul	v17.2d, v9.2d, v0.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fsub	v6.2d, v22.2d, v16.2d
	ldp	q19, q22, [sp, #688]            // 32-byte Folded Reload
	fmul	v0.2d, v10.2d, v0.2d
	fmul	v16.2d, v13.2d, v31.2d
	fsub	v5.2d, v5.2d, v17.2d
	fsub	v1.2d, v6.2d, v0.2d
	fmul	v7.2d, v22.2d, v28.2d
	ldr	q10, [sp, #672]                 // 16-byte Folded Reload
	fmul	v6.2d, v26.2d, v30.2d
	ldr	q26, [sp, #768]                 // 16-byte Folded Reload
	fadd	v3.2d, v3.2d, v16.2d
	fmul	v16.2d, v27.2d, v30.2d
	fmla	v7.2d, v18.2d, v19.2d
	ldp	q21, q18, [sp, #272]            // 32-byte Folded Reload
	fadd	v5.2d, v5.2d, v6.2d
	fadd	v1.2d, v1.2d, v16.2d
	fmul	v16.2d, v15.2d, v31.2d
	fmla	v2.2d, v18.2d, v11.2d
	fmla	v7.2d, v18.2d, v10.2d
	ldp	q30, q13, [sp, #240]            // 32-byte Folded Reload
	fmul	v17.2d, v22.2d, v18.2d
	fmul	v0.2d, v14.2d, v18.2d
	fmla	v2.2d, v21.2d, v25.2d
	fadd	v1.2d, v1.2d, v16.2d
	ldp	q18, q22, [sp, #736]            // 32-byte Folded Reload
	fmla	v2.2d, v13.2d, v18.2d
	ldr	q6, [sp, #832]                  // 16-byte Folded Reload
	fmla	v7.2d, v21.2d, v22.2d
	fmla	v17.2d, v6.2d, v19.2d
	ldr	q6, [sp, #832]                  // 16-byte Folded Reload
	fsub	v19.2d, v4.2d, v2.2d
	fmla	v7.2d, v13.2d, v26.2d
	fmla	v0.2d, v6.2d, v20.2d
	fmul	v6.2d, v23.2d, v31.2d
	fmla	v17.2d, v30.2d, v10.2d
	fadd	v20.2d, v4.2d, v2.2d
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	ldp	q27, q31, [sp, #464]            // 32-byte Folded Reload
	fmla	v0.2d, v30.2d, v11.2d
	fadd	v4.2d, v5.2d, v6.2d
	fmul	v5.2d, v8.2d, v2.2d
	fadd	v6.2d, v7.2d, v3.2d
	mov	v8.16b, v21.16b
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	fsub	v23.2d, v4.2d, v5.2d
	fsub	v21.2d, v3.2d, v7.2d
	fmul	v16.2d, v12.2d, v2.2d
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	ldp	d3, d7, [x12, #-24]
	fneg	v5.2d, v19.2d
	fmla	v17.2d, v2.2d, v22.2d
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	fsub	v22.2d, v1.2d, v16.2d
	ldr	d1, [x4]
	ldr	x12, [sp, #216]                 // 8-byte Folded Reload
	fmla	v0.2d, v2.2d, v25.2d
	fmul	v14.2d, v5.2d, v7.d[0]
	fmla	v17.2d, v28.2d, v26.2d
	fmul	v10.2d, v6.2d, v7.d[0]
	fneg	v7.2d, v20.2d
	add	x12, x28, x12
	ldr	q26, [sp, #496]                 // 16-byte Folded Reload
	fmla	v0.2d, v28.2d, v18.2d
	fmla	v14.2d, v6.2d, v3.d[0]
	ldp	d18, d2, [x3, #-136]
	fadd	v5.2d, v17.2d, v22.2d
	fmla	v10.2d, v19.2d, v3.d[0]
	ldr	q3, [sp, #864]                  // 16-byte Folded Reload
	fmla	v27.2d, v26.2d, v31.d[0]
	fsub	v16.2d, v23.2d, v0.2d
	mov	v11.16b, v12.16b
	add	x3, x16, x26
	fmul	v25.2d, v21.2d, v2.d[0]
	fmul	v19.2d, v7.2d, v2.d[0]
	fmul	v6.2d, v5.2d, v1.d[0]
	fneg	v4.2d, v16.2d
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	mov	v12.16b, v28.16b
	fmla	v25.2d, v20.2d, v18.d[0]
	fmul	v2.2d, v3.2d, v2.2d
	ldp	q3, q26, [sp, #624]             // 32-byte Folded Reload
	fmul	v7.2d, v4.2d, v1.d[0]
	ldur	d1, [x4, #-8]
	ldr	q4, [sp, #912]                  // 16-byte Folded Reload
	fmla	v19.2d, v21.2d, v18.d[0]
	str	q25, [sp, #464]                 // 16-byte Folded Spill
	ldr	q25, [sp, #416]                 // 16-byte Folded Reload
	fmla	v6.2d, v16.2d, v1.d[0]
	mov	x4, x10
	fmla	v7.2d, v5.2d, v1.d[0]
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	fmul	v4.2d, v25.2d, v4.2d
	ldr	q5, [sp, #928]                  // 16-byte Folded Reload
	ldp	d20, d18, [x12, #-8]
	fsub	v1.2d, v1.2d, v2.2d
	add	x12, x13, x26
	ldr	q2, [sp, #784]                  // 16-byte Folded Reload
	stp	q7, q6, [sp, #480]              // 32-byte Folded Spill
	fmul	v5.2d, v3.2d, v5.2d
	ldr	q3, [sp, #704]                  // 16-byte Folded Reload
	fsub	v16.2d, v22.2d, v17.2d
	str	q19, [sp, #432]                 // 16-byte Folded Spill
	fsub	v2.2d, v2.2d, v4.2d
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	fadd	v17.2d, v23.2d, v0.2d
	ldr	q0, [sp, #800]                  // 16-byte Folded Reload
	ldr	q23, [sp, #368]                 // 16-byte Folded Reload
	mov	x10, x17
	fmul	v6.2d, v16.2d, v18.d[0]
	mov	x17, x27
	fsub	v5.2d, v2.2d, v5.2d
	mov	x27, x24
	fneg	v2.2d, v17.2d
	fmul	v4.2d, v9.2d, v4.2d
	fmul	v21.2d, v0.2d, v29.2d
	ldp	q0, q9, [sp, #816]              // 32-byte Folded Reload
	fmla	v6.2d, v17.2d, v20.d[0]
	ldr	q17, [sp, #944]                 // 16-byte Folded Reload
	fmul	v31.2d, v2.2d, v18.d[0]
	ldr	q18, [sp, #944]                 // 16-byte Folded Reload
	fsub	v4.2d, v1.2d, v4.2d
	fmul	v22.2d, v0.2d, v29.2d
	fmul	v1.2d, v3.2d, v8.2d
	str	q6, [sp, #448]                  // 16-byte Folded Spill
	fmul	v0.2d, v23.2d, v8.2d
	ldr	q6, [sp, #688]                  // 16-byte Folded Reload
	fmla	v31.2d, v16.2d, v20.d[0]
	ldr	q8, [sp, #576]                  // 16-byte Folded Reload
	ldp	q16, q20, [sp, #528]            // 32-byte Folded Reload
	fmla	v1.2d, v28.2d, v6.2d
	fmla	v0.2d, v28.2d, v26.2d
	fmul	v18.2d, v15.2d, v18.2d
	fadd	v5.2d, v5.2d, v22.2d
	fadd	v4.2d, v4.2d, v21.2d
	ldp	q15, q28, [sp, #656]            // 32-byte Folded Reload
	stp	q16, q20, [x12, #32]
	add	x12, x11, x26
	fmul	v17.2d, v24.2d, v17.2d
	fsub	v5.2d, v5.2d, v18.2d
	fmul	v22.2d, v23.2d, v13.2d
	ldp	q16, q18, [sp, #880]            // 32-byte Folded Reload
	fsub	v4.2d, v4.2d, v17.2d
	ldr	q21, [sp, #944]                 // 16-byte Folded Reload
	fmla	v1.2d, v16.2d, v28.2d
	fmla	v0.2d, v16.2d, v15.2d
	ldr	q16, [sp, #896]                 // 16-byte Folded Reload
	fmla	v22.2d, v8.2d, v26.2d
	ldp	q7, q2, [sp, #752]              // 32-byte Folded Reload
	fmul	v17.2d, v3.2d, v13.2d
	fmul	v16.2d, v11.2d, v16.2d
	fmla	v22.2d, v12.2d, v15.2d
	fmla	v1.2d, v8.2d, v7.2d
	fmla	v17.2d, v8.2d, v6.2d
	ldr	q11, [sp, #512]                 // 16-byte Folded Reload
	fadd	v19.2d, v5.2d, v16.2d
	ldr	q16, [sp, #560]                 // 16-byte Folded Reload
	ldp	q5, q6, [sp, #720]              // 32-byte Folded Reload
	fmla	v1.2d, v30.2d, v2.2d
	fmul	v18.2d, v11.2d, v18.2d
	stp	q16, q27, [x12, #32]
	ldr	x12, [sp, #224]                 // 8-byte Folded Reload
	fmla	v0.2d, v8.2d, v5.2d
	fmla	v17.2d, v12.2d, v28.2d
	fadd	v16.2d, v1.2d, v19.2d
	stp	q10, q14, [x3, #32]
	fadd	v4.2d, v4.2d, v18.2d
	add	x12, x28, x12
	ldp	q3, q18, [sp, #848]             // 32-byte Folded Reload
	fmla	v0.2d, v30.2d, v6.2d
	fmla	v17.2d, v30.2d, v7.2d
	fmla	v22.2d, v30.2d, v5.2d
	add	x3, x8, x26
	fsub	v1.2d, v19.2d, v1.2d
	fsub	v24.2d, v4.2d, v0.2d
	fmla	v17.2d, v9.2d, v2.2d
	fmul	v18.2d, v18.2d, v21.2d
	fmul	v21.2d, v25.2d, v21.2d
	ldp	d25, d20, [x12, #-8]
	add	x12, x14, x26
	ldr	q7, [sp, #464]                  // 16-byte Folded Reload
	fmul	v23.2d, v16.2d, v20.d[0]
	ldr	q2, [sp, #400]                  // 16-byte Folded Reload
	fsub	v18.2d, v3.2d, v18.2d
	ldr	q3, [sp, #784]                  // 16-byte Folded Reload
	fadd	v0.2d, v4.2d, v0.2d
	fmla	v22.2d, v9.2d, v6.2d
	ldr	d6, [x2]
	fsub	v21.2d, v3.2d, v21.2d
	ldr	q3, [sp, #608]                  // 16-byte Folded Reload
	fmla	v23.2d, v24.2d, v25.d[0]
	fneg	v24.2d, v24.2d
	fmul	v27.2d, v3.2d, v29.2d
	ldr	q3, [sp, #624]                  // 16-byte Folded Reload
	fmul	v28.2d, v3.2d, v29.2d
	ldr	q3, [sp, #800]                  // 16-byte Folded Reload
	fadd	v18.2d, v18.2d, v27.2d
	ldp	q26, q27, [sp, #912]            // 32-byte Folded Reload
	fmul	v20.2d, v24.2d, v20.d[0]
	fadd	v21.2d, v21.2d, v28.2d
	fmul	v24.2d, v3.2d, v26.2d
	fmla	v20.2d, v16.2d, v25.d[0]
	ldr	q3, [sp, #816]                  // 16-byte Folded Reload
	fneg	v25.2d, v0.2d
	fmul	v26.2d, v3.2d, v26.2d
	ldr	q3, [sp, #432]                  // 16-byte Folded Reload
	stp	q7, q3, [x12, #32]
	add	x12, x28, x4
	fsub	v16.2d, v21.2d, v26.2d
	ldr	q21, [sp, #896]                 // 16-byte Folded Reload
	fsub	v7.2d, v18.2d, v24.2d
	fmul	v18.2d, v2.2d, v21.2d
	ldr	q2, [sp, #384]                  // 16-byte Folded Reload
	fmul	v21.2d, v2.2d, v21.2d
	ldr	q2, [sp, #592]                  // 16-byte Folded Reload
	fadd	v5.2d, v7.2d, v18.2d
	ldp	d4, d7, [x12, #-104]
	fmul	v18.2d, v2.2d, v27.2d
	add	x12, x28, x17
	fadd	v16.2d, v16.2d, v21.2d
	ldp	q2, q3, [sp, #480]              // 32-byte Folded Reload
	fmul	v21.2d, v11.2d, v27.2d
	add	x28, x28, #16
	mov	v11.16b, v9.16b
	fmul	v24.2d, v1.2d, v7.d[0]
	stp	q3, q2, [x3, #32]
	fsub	v16.2d, v16.2d, v18.2d
	fmul	v3.2d, v25.2d, v7.d[0]
	fsub	v5.2d, v5.2d, v21.2d
	ldr	q2, [sp, #448]                  // 16-byte Folded Reload
	fmla	v24.2d, v0.2d, v4.d[0]
	ldp	d19, d0, [x12, #-72]
	fsub	v18.2d, v5.2d, v22.2d
	add	x12, x30, x26
	fadd	v5.2d, v5.2d, v22.2d
	fmla	v3.2d, v1.2d, v4.d[0]
	fadd	v7.2d, v17.2d, v16.2d
	fsub	v16.2d, v16.2d, v17.2d
	stp	q2, q31, [x12, #32]
	fneg	v4.2d, v18.2d
	ldr	x12, [sp, #352]                 // 8-byte Folded Reload
	fneg	v17.2d, v5.2d
	fmul	v1.2d, v7.2d, v0.d[0]
	fmul	v2.2d, v16.2d, v6.d[0]
	add	x12, x12, x26
	fmul	v0.2d, v4.2d, v0.d[0]
	fmul	v4.2d, v17.2d, v6.d[0]
	ldur	d6, [x2, #-8]
	add	x2, x1, x26
	fmla	v1.2d, v18.2d, v19.d[0]
	mov	v31.16b, v29.16b
	stp	q23, q20, [x12, #32]
	fmla	v0.2d, v7.2d, v19.d[0]
	fmla	v2.2d, v5.2d, v6.d[0]
	fmla	v4.2d, v16.2d, v6.d[0]
	add	x12, x25, x26
	stp	q24, q3, [x2, #32]
	add	x2, x9, x26
	add	x26, x26, #32
	stp	q1, q0, [x12, #32]
	stp	q2, q4, [x2, #32]
	b.ne	.LBB127_9
	b	.LBB127_6
.LBB127_10:
	add	sp, sp, #960
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end127:
	.size	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end127-_ZNK9pocketfft6detail5cfftpIdE6pass11ILb1ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
.LCPI128_0:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_,@function
_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_: // @_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #4
	mov	x25, x7
	add	x0, x8, #64
	stp	x6, x4, [sp, #24]               // 16-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x22, x3
	mov	x21, x1
	bl	malloc
	cbz	x0, .LBB128_85
// %bb.1:
	adrp	x8, .LCPI128_0
	add	x9, x0, #64
	add	x14, x23, #1
	mul	x19, x22, x21
	and	x28, x9, #0xffffffffffffffc0
	lsr	x26, x14, #1
	ldr	q0, [x8, :lo12:.LCPI128_0]
	subs	x18, x23, #2
	stur	x0, [x28, #-8]
	str	q0, [x28]
	stp	x26, x22, [x29, #-16]           // 16-byte Folded Spill
	b.lo	.LBB128_4
// %bb.2:
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cmp	x27, #4
	b.hs	.LBB128_6
// %bb.3:
	mov	w8, #1
	b	.LBB128_13
.LBB128_4:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cbz	x22, .LBB128_73
// %bb.5:
	cbnz	x21, .LBB128_17
	b	.LBB128_73
.LBB128_6:
	cmp	xzr, x18, lsr #60
	add	x11, x28, #16
	lsl	x10, x18, #4
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB128_13
// %bb.7:
	tbnz	w9, #0, .LBB128_13
// %bb.8:
	add	x11, x28, #24
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB128_13
// %bb.9:
	tbnz	w9, #0, .LBB128_13
// %bb.10:
	and	x9, x27, #0xfffffffffffffffc
	add	x10, x28, #48
	orr	x8, x9, #0x1
	add	x11, x25, #48
	mov	x12, x9
.LBB128_11:                             // =>This Inner Loop Header: Depth=1
	ld2	{ v0.2d, v1.2d }, [x11]
	sub	x13, x11, #32
	add	x11, x11, #64
	subs	x12, x12, #4
	ld2	{ v2.2d, v3.2d }, [x13]
	sub	x13, x10, #32
	fneg	v1.2d, v1.2d
	fneg	v3.2d, v3.2d
	st2	{ v0.2d, v1.2d }, [x10]
	add	x10, x10, #64
	st2	{ v2.2d, v3.2d }, [x13]
	b.ne	.LBB128_11
// %bb.12:
	cmp	x27, x9
	b.eq	.LBB128_15
.LBB128_13:
	sub	x9, x23, x8
	lsl	x8, x8, #4
	add	x10, x25, x8
	add	x11, x28, x8
	add	x8, x10, #8
	add	x10, x11, #8
.LBB128_14:                             // =>This Inner Loop Header: Depth=1
	ldp	d1, d0, [x8, #-8]
	subs	x9, x9, #1
	add	x8, x8, #16
	fneg	d0, d0
	stp	d1, d0, [x10, #-8]
	add	x10, x10, #16
	b.ne	.LBB128_14
.LBB128_15:
	cbz	x22, .LBB128_35
// %bb.16:
	cbz	x21, .LBB128_37
.LBB128_17:
	mul	x8, x23, x21
	lsl	x25, x21, #5
	mov	x26, x24
	mov	x27, x30
	lsl	x20, x8, #5
	stp	x18, x14, [x29, #-32]           // 16-byte Folded Spill
.LBB128_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	mov	x2, x25
	bl	memcpy
	add	x27, x27, x20
	add	x26, x26, x25
	subs	x22, x22, #1
	b.ne	.LBB128_18
// %bb.19:
	ldp	x8, x26, [x29, #-24]            // 16-byte Folded Reload
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	cmp	x8, #3
	b.ls	.LBB128_27
// %bb.20:
	cbz	x21, .LBB128_49
// %bb.21:
	mul	x10, x21, x27
	add	x11, x24, x19, lsl #5
	mul	x13, x19, x27
	cmp	x26, #2
	mov	w8, #2
	add	x14, x30, x25
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	lsl	x12, x19, #5
	add	x15, x24, x13, lsl #5
	neg	x9, x25
	csel	x8, x26, x8, hi
	add	x13, x14, #16
	add	x14, x15, #16
	neg	x15, x12
	mov	w16, #1
.LBB128_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB128_23 Depth 2
                                        //       Child Loop BB128_24 Depth 3
	mov	x17, xzr
	mov	x18, x14
	mov	x0, x13
	mov	x1, x10
	mov	x2, x11
.LBB128_23:                             //   Parent Loop BB128_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB128_24 Depth 3
	mov	x3, x18
	mov	x4, x0
	mov	x5, x1
	mov	x6, x2
	mov	x7, x21
.LBB128_24:                             //   Parent Loop BB128_22 Depth=1
                                        //     Parent Loop BB128_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x4, #-16]
	subs	x7, x7, #1
	add	x4, x4, #32
	ldp	q2, q3, [x6, #-16]
	add	x6, x6, #32
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x5, #-16]
	add	x5, x5, #32
	stp	q0, q1, [x3, #-16]
	add	x3, x3, #32
	b.ne	.LBB128_24
// %bb.25:                              //   in Loop: Header=BB128_23 Depth=2
	add	x17, x17, #1
	add	x2, x2, x20
	add	x1, x1, x25
	add	x0, x0, x20
	add	x18, x18, x25
	cmp	x17, x22
	b.ne	.LBB128_23
// %bb.26:                              //   in Loop: Header=BB128_22 Depth=1
	add	x16, x16, #1
	add	x11, x11, x9
	add	x10, x10, x12
	add	x13, x13, x25
	add	x14, x14, x15
	cmp	x16, x8
	b.ne	.LBB128_22
.LBB128_27:
	ldp	x18, x0, [x29, #-32]            // 16-byte Folded Reload
	cbz	x21, .LBB128_42
// %bb.28:
	cmp	x0, #3
	b.ls	.LBB128_38
// %bb.29:
	cmp	x26, #2
	mov	w9, #2
	csel	x9, x26, x9, hi
	add	x10, x24, x19, lsl #5
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x10, #16
	lsl	x11, x19, #5
.LBB128_30:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB128_31 Depth 2
                                        //       Child Loop BB128_32 Depth 3
	mul	x13, x8, x21
	mov	x12, xzr
	mov	x14, x10
.LBB128_31:                             //   Parent Loop BB128_30 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB128_32 Depth 3
	add	x15, x12, x13
	mov	x17, x9
	add	x16, x24, x15, lsl #5
	ldp	q0, q1, [x16]
	mov	x16, x14
.LBB128_32:                             //   Parent Loop BB128_30 Depth=1
                                        //     Parent Loop BB128_31 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q3, [x16, #-16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.2d, v0.2d, v2.2d
	fadd	v1.2d, v1.2d, v3.2d
	b.ne	.LBB128_32
// %bb.33:                              //   in Loop: Header=BB128_31 Depth=2
	add	x15, x30, x15, lsl #5
	add	x12, x12, #1
	add	x14, x14, #32
	cmp	x12, x21
	stp	q0, q1, [x15]
	b.ne	.LBB128_31
// %bb.34:                              //   in Loop: Header=BB128_30 Depth=1
	add	x8, x8, #1
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB128_30
	b	.LBB128_42
.LBB128_35:
	mov	w9, #1
	cmp	x14, #3
	b.hi	.LBB128_51
// %bb.36:
	mov	w8, wzr
	subs	x10, x21, #1
	b.eq	.LBB128_44
	b	.LBB128_71
.LBB128_37:
	cmp	x14, #3
	b.hi	.LBB128_50
	b	.LBB128_73
.LBB128_38:
	mov	x8, xzr
	add	x9, x30, #16
	add	x10, x24, #16
.LBB128_39:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB128_40 Depth 2
	mov	x11, x10
	mov	x12, x9
	mov	x13, x21
.LBB128_40:                             //   Parent Loop BB128_39 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x13, x13, #1
	add	x11, x11, #32
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB128_40
// %bb.41:                              //   in Loop: Header=BB128_39 Depth=1
	add	x8, x8, #1
	add	x9, x9, x25
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB128_39
.LBB128_42:
	mov	w9, wzr
	mov	w8, wzr
	cmp	x0, #4
	b.hs	.LBB128_51
// %bb.43:
	subs	x10, x21, #1
	b.ne	.LBB128_71
.LBB128_44:
	cmp	x19, #0
	eor	w8, w8, #0x1
	cset	w9, eq
	orr	w8, w8, w9
	tbnz	w8, #0, .LBB128_73
// %bb.45:
	mul	x8, x27, x22
	cmp	x26, #2
	mov	w9, #2
	add	x11, x30, x19, lsl #5
	csel	x9, x26, x9, hi
	mov	w13, #1
	mul	x10, x8, x21
	lsl	x8, x19, #5
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	neg	x12, x8
.LBB128_46:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB128_47 Depth 2
	mov	x14, x11
	mov	x15, x10
	mov	x16, x19
.LBB128_47:                             //   Parent Loop BB128_46 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x15, #-16]
	subs	x16, x16, #1
	ldp	q2, q3, [x14, #-16]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x15, #-16]
	add	x15, x15, #32
	stp	q0, q1, [x14, #-16]
	add	x14, x14, #32
	b.ne	.LBB128_47
// %bb.48:                              //   in Loop: Header=BB128_46 Depth=1
	add	x13, x13, #1
	add	x10, x10, x8
	add	x11, x11, x12
	cmp	x13, x9
	b.ne	.LBB128_46
	b	.LBB128_73
.LBB128_49:
	ldur	x18, [x29, #-32]                // 8-byte Folded Reload
.LBB128_50:
	mov	w9, wzr
.LBB128_51:
	str	w9, [sp, #12]                   // 4-byte Folded Spill
	mul	x9, x19, x18
	sub	x1, x23, #4
	mul	x8, x19, x27
	cmp	x26, #2
	mov	w13, #2
	add	x18, x24, x9, lsl #5
	mov	w9, #96
	mul	x2, x19, x1
	lsl	x8, x8, #5
	madd	x9, x19, x9, x24
	add	x15, x30, x8
	add	x8, x24, x8
	csel	x13, x26, x13, hi
	add	x1, x8, #16
	add	x8, x9, #16
	add	x9, x24, x2, lsl #5
	sub	x10, x23, #3
	str	x27, [sp, #16]                  // 8-byte Folded Spill
	lsl	x12, x19, #5
	stp	x8, x13, [x29, #-32]            // 16-byte Folded Spill
	mul	x8, x19, x10
	stur	x9, [x29, #-40]                 // 8-byte Folded Spill
	add	x9, x24, x19, lsl #7
	add	x9, x9, #16
	add	x14, x24, x12
	add	x17, x24, x19, lsl #6
	add	x0, x30, x12
	lsl	x3, x19, #6
	sub	x11, x26, #1
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x24, x8, lsl #5
	add	x8, x24, #16
	add	x14, x14, #16
	neg	x16, x12
	add	x17, x17, #16
	add	x0, x0, #16
	neg	x5, x3
	stp	x8, x9, [sp, #48]               // 16-byte Folded Spill
	lsl	x8, x19, #1
	mov	w27, #1
	str	x8, [sp, #40]                   // 8-byte Folded Spill
	b	.LBB128_53
.LBB128_52:                             //   in Loop: Header=BB128_53 Depth=1
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	add	x27, x27, #1
	add	x15, x15, x16
	add	x0, x0, x12
	cmp	x27, x8
	b.eq	.LBB128_70
.LBB128_53:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB128_55 Depth 2
                                        //     Child Loop BB128_59 Depth 2
                                        //       Child Loop BB128_61 Depth 3
                                        //     Child Loop BB128_67 Depth 2
                                        //       Child Loop BB128_68 Depth 3
	cbz	x19, .LBB128_62
// %bb.54:                              //   in Loop: Header=BB128_53 Depth=1
	add	x2, x28, x27, lsl #4
	add	x4, x28, x27, lsl #5
	mov	x9, xzr
	lsl	x30, x27, #1
	add	x6, x2, #8
	add	x7, x4, #8
	mov	x20, x19
.LBB128_55:                             //   Parent Loop BB128_53 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x14, x9
	add	x25, x24, x9
	ldr	d0, [x2]
	add	x22, x17, x9
	ld1r	{ v7.2d }, [x7]
	subs	x20, x20, #1
	ldp	q2, q16, [x8, #-16]
	add	x8, x18, x9
	fneg	v7.2d, v7.2d
	ldp	q4, q5, [x25]
	fmla	v4.2d, v2.2d, v0.d[0]
	ldp	q0, q20, [x8]
	add	x8, x0, x9
	ldp	q3, q18, [x22, #-16]
	add	x22, x1, x9
	ldr	d1, [x4]
	ldr	d6, [x2]
	ldr	d19, [x7]
	fmla	v4.2d, v3.2d, v1.d[0]
	ldr	d17, [x4]
	fmla	v5.2d, v16.2d, v6.d[0]
	ldr	d2, [x6]
	fmul	v6.2d, v20.2d, v7.2d
	fmul	v0.2d, v0.2d, v19.d[0]
	ldp	q1, q7, [x22, #-16]
	add	x22, x15, x9
	add	x9, x9, #32
	fmla	v5.2d, v18.2d, v17.d[0]
	ldr	d16, [x6]
	fmls	v6.2d, v7.2d, v2.d[0]
	stp	q4, q5, [x8, #-16]
	fmla	v0.2d, v1.2d, v16.d[0]
	stp	q6, q0, [x22]
	b.ne	.LBB128_55
// %bb.56:                              //   in Loop: Header=BB128_53 Depth=1
	cmp	x11, #4
	b.lo	.LBB128_63
.LBB128_57:                             //   in Loop: Header=BB128_53 Depth=1
	ldp	x6, x4, [x29, #-48]             // 16-byte Folded Reload
	mov	w9, #3
	mov	x20, x10
	ldr	x7, [sp, #56]                   // 8-byte Folded Reload
	ldur	x2, [x29, #-32]                 // 8-byte Folded Reload
	b	.LBB128_59
.LBB128_58:                             //   in Loop: Header=BB128_59 Depth=2
	add	x9, x9, #2
	sub	x20, x20, #2
	add	x2, x2, x3
	add	x4, x4, x5
	add	x6, x6, x3
	add	x7, x7, x5
	cmp	x9, x11
	b.hs	.LBB128_64
.LBB128_59:                             //   Parent Loop BB128_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB128_61 Depth 3
	add	x8, x30, x27
	cmp	x8, x23
	csel	x22, x23, xzr, hi
	sub	x22, x8, x22
	add	x8, x22, x27
	cmp	x8, x23
	csel	x25, x23, xzr, hi
	sub	x30, x8, x25
	cbz	x19, .LBB128_58
// %bb.60:                              //   in Loop: Header=BB128_59 Depth=2
	add	x22, x28, x22, lsl #4
	add	x25, x28, x30, lsl #4
	mov	x8, xzr
	ld1r	{ v0.2d }, [x22], #8
	ld1r	{ v1.2d }, [x25], #8
	ld1r	{ v2.2d }, [x22]
	mov	x22, x19
	ld1r	{ v3.2d }, [x25]
.LBB128_61:                             //   Parent Loop BB128_53 Depth=1
                                        //     Parent Loop BB128_59 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x25, x6, x8
	add	x26, x2, x8
	add	x13, x0, x8
	subs	x22, x22, #1
	ldp	q4, q5, [x25, #-16]
	add	x25, x4, x8
	fmul	v4.2d, v1.2d, v4.2d
	ldp	q6, q7, [x26, #-16]
	fmul	v5.2d, v1.2d, v5.2d
	add	x26, x7, x8
	fmla	v4.2d, v0.2d, v6.2d
	ldp	q16, q17, [x13, #-16]
	fmla	v5.2d, v0.2d, v7.2d
	fadd	v4.2d, v16.2d, v4.2d
	ldp	q7, q6, [x25]
	fadd	v5.2d, v17.2d, v5.2d
	add	x25, x15, x8
	add	x8, x8, #32
	fmul	v7.2d, v3.2d, v7.2d
	stp	q4, q5, [x13, #-16]
	ldp	q17, q16, [x26]
	fmul	v6.2d, v3.2d, v6.2d
	fmla	v7.2d, v2.2d, v17.2d
	ldp	q4, q5, [x25]
	fmla	v6.2d, v2.2d, v16.2d
	fsub	v4.2d, v4.2d, v6.2d
	fadd	v5.2d, v5.2d, v7.2d
	stp	q4, q5, [x25]
	b.ne	.LBB128_61
	b	.LBB128_58
.LBB128_62:                             //   in Loop: Header=BB128_53 Depth=1
	lsl	x30, x27, #1
	cmp	x11, #4
	b.hs	.LBB128_57
.LBB128_63:                             //   in Loop: Header=BB128_53 Depth=1
	mov	x20, x10
	mov	w9, #3
.LBB128_64:                             //   in Loop: Header=BB128_53 Depth=1
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cmp	x9, x26
	b.hs	.LBB128_52
// %bb.65:                              //   in Loop: Header=BB128_53 Depth=1
	cbz	x19, .LBB128_52
// %bb.66:                              //   in Loop: Header=BB128_53 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	mul	x8, x13, x9
	mul	x4, x13, x20
	ldr	x13, [sp, #48]                  // 8-byte Folded Reload
	add	x2, x13, x8, lsl #4
	add	x4, x13, x4, lsl #4
.LBB128_67:                             //   Parent Loop BB128_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB128_68 Depth 3
	add	x6, x30, x27
	mov	x8, xzr
	cmp	x6, x23
	csel	x7, x23, xzr, hi
	sub	x30, x6, x7
	add	x6, x28, x30, lsl #4
	ld1r	{ v0.2d }, [x6], #8
	ld1r	{ v1.2d }, [x6]
	mov	x6, x19
.LBB128_68:                             //   Parent Loop BB128_53 Depth=1
                                        //     Parent Loop BB128_67 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x7, x2, x8
	add	x20, x0, x8
	add	x22, x15, x8
	subs	x6, x6, #1
	ldp	q2, q4, [x7, #-16]
	add	x7, x4, x8
	add	x8, x8, #32
	ldp	q3, q5, [x20, #-16]
	fmla	v3.2d, v0.2d, v2.2d
	fmla	v5.2d, v0.2d, v4.2d
	stp	q3, q5, [x20, #-16]
	ldp	q3, q2, [x7, #-16]
	ldp	q4, q5, [x22]
	fmls	v4.2d, v1.2d, v2.2d
	fmla	v5.2d, v1.2d, v3.2d
	stp	q4, q5, [x22]
	b.ne	.LBB128_68
// %bb.69:                              //   in Loop: Header=BB128_67 Depth=2
	add	x9, x9, #1
	add	x2, x2, x12
	add	x4, x4, x16
	cmp	x9, x26
	b.ne	.LBB128_67
	b	.LBB128_52
.LBB128_70:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	mov	w8, #1
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	ldr	w9, [sp, #12]                   // 4-byte Folded Reload
	subs	x10, x21, #1
	b.eq	.LBB128_44
.LBB128_71:
	cbz	w8, .LBB128_73
// %bb.72:
	tbz	w9, #0, .LBB128_76
.LBB128_73:
	cbz	x28, .LBB128_75
// %bb.74:
	ldur	x0, [x28, #-8]
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	b	free
.LBB128_75:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB128_76:
	mul	x8, x27, x22
	sub	x11, x27, #1
	ldr	x0, [sp, #24]                   // 8-byte Folded Reload
	cmp	x26, #2
	mul	x15, x11, x10
	mov	w12, #2
	mul	x8, x8, x21
	add	x18, x30, x19, lsl #5
	lsl	x9, x19, #5
	mov	w17, #16
	add	x16, x0, x15, lsl #4
	csel	x11, x26, x12, hi
	add	x15, x30, x8, lsl #5
	lsl	x8, x21, #4
	add	x12, x18, #16
	lsl	x13, x21, #5
	neg	x14, x9
	add	x16, x16, #8
	sub	x17, x17, x8
	add	x18, x18, #48
	add	x0, x0, #8
	sub	x1, x8, #16
	add	x2, x15, #48
	mov	w3, #1
	b	.LBB128_78
.LBB128_77:                             //   in Loop: Header=BB128_78 Depth=1
	add	x3, x3, #1
	add	x12, x12, x9
	add	x15, x15, x14
	add	x16, x16, x17
	add	x18, x18, x9
	add	x0, x0, x1
	add	x2, x2, x14
	mov	x27, x4
	cmp	x3, x11
	b.eq	.LBB128_73
.LBB128_78:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB128_84 Depth 2
                                        //     Child Loop BB128_80 Depth 2
                                        //       Child Loop BB128_81 Depth 3
	sub	x4, x27, #1
	cmp	x21, #1
	b.ls	.LBB128_83
// %bb.79:                              //   in Loop: Header=BB128_78 Depth=1
	mul	x5, x3, x22
	mov	x8, xzr
	mul	x6, x27, x22
	mov	x7, x2
	mov	x20, x18
.LBB128_80:                             //   Parent Loop BB128_78 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB128_81 Depth 3
	add	x19, x8, x5
	add	x22, x8, x6
	mov	x23, x0
	mov	x24, x20
	mul	x19, x19, x21
	mov	x25, x16
	mul	x22, x22, x21
	mov	x26, x10
	add	x19, x30, x19, lsl #5
	add	x27, x30, x22, lsl #5
	mov	x22, x7
	ldp	q0, q1, [x19]
	ldp	q2, q3, [x27]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x19]
	stp	q0, q1, [x27]
.LBB128_81:                             //   Parent Loop BB128_78 Depth=1
                                        //     Parent Loop BB128_80 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q2, [x24, #-16]
	subs	x26, x26, #1
	ldp	q1, q3, [x22, #-16]
	fadd	v4.2d, v0.2d, v1.2d
	fsub	v0.2d, v0.2d, v1.2d
	ldp	d17, d5, [x23, #-8]
	fadd	v1.2d, v2.2d, v3.2d
	add	x23, x23, #16
	fneg	v7.2d, v4.2d
	ldr	d6, [x25]
	fsub	v2.2d, v2.2d, v3.2d
	fneg	v3.2d, v0.2d
	fmul	v16.2d, v1.2d, v5.d[0]
	fmul	v5.2d, v7.2d, v5.d[0]
	fmul	v7.2d, v2.2d, v6.d[0]
	fmul	v3.2d, v3.2d, v6.d[0]
	ldur	d6, [x25, #-8]
	fmla	v16.2d, v4.2d, v17.d[0]
	add	x25, x25, #16
	fmla	v5.2d, v1.2d, v17.d[0]
	fmla	v7.2d, v0.2d, v6.d[0]
	fmla	v3.2d, v2.2d, v6.d[0]
	stp	q16, q5, [x24, #-16]
	add	x24, x24, #32
	stp	q7, q3, [x22, #-16]
	add	x22, x22, #32
	b.ne	.LBB128_81
// %bb.82:                              //   in Loop: Header=BB128_80 Depth=2
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	add	x8, x8, #1
	add	x20, x20, x13
	add	x7, x7, x13
	cmp	x8, x22
	b.ne	.LBB128_80
	b	.LBB128_77
.LBB128_83:                             //   in Loop: Header=BB128_78 Depth=1
	mov	x8, xzr
	mov	x5, x22
.LBB128_84:                             //   Parent Loop BB128_78 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x6, x12, x8
	add	x7, x15, x8
	subs	x5, x5, #1
	add	x8, x8, x13
	ldp	q0, q1, [x6, #-16]
	ldp	q2, q3, [x7]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x6, #-16]
	stp	q0, q1, [x7]
	b.ne	.LBB128_84
	b	.LBB128_77
.LBB128_85:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end128:
	.size	_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_, .Lfunc_end128-_ZNK9pocketfft6detail5cfftpIdE5passgILb1ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	str	x23, [sp, #-48]!                // 8-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	subs	x8, x1, #1
	b.ne	.LBB129_4
// %bb.1:
	cbz	x2, .LBB129_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #5
	lsl	x10, x10, #5
	lsl	x11, x2, #6
	add	x12, x3, #64
.LBB129_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x12, #-64]
	add	x13, x8, x11
	add	x14, x8, x9
	subs	x2, x2, #1
	ldp	q2, q3, [x12]
	fadd	v5.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	ldp	q6, q16, [x12, #-32]
	fadd	v7.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	ldp	q4, q2, [x12, #32]
	add	x12, x12, #128
	fadd	v17.2d, v6.2d, v4.2d
	fsub	v4.2d, v6.2d, v4.2d
	fadd	v3.2d, v16.2d, v2.2d
	fsub	v2.2d, v16.2d, v2.2d
	fsub	v16.2d, v5.2d, v17.2d
	fadd	v5.2d, v5.2d, v17.2d
	fsub	v6.2d, v7.2d, v3.2d
	fadd	v3.2d, v7.2d, v3.2d
	fsub	v17.2d, v0.2d, v2.2d
	fadd	v0.2d, v0.2d, v2.2d
	stp	q16, q6, [x13, #-16]
	add	x13, x8, x10
	fadd	v16.2d, v1.2d, v4.2d
	stp	q5, q3, [x8, #-16]
	fsub	v1.2d, v1.2d, v4.2d
	add	x8, x8, #32
	stp	q17, q16, [x14, #-16]
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB129_3
	b	.LBB129_10
.LBB129_4:
	cbz	x2, .LBB129_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #96
	lsl	x10, x2, #1
	lsl	x15, x1, #5
	lsl	x18, x1, #4
	mov	x9, xzr
	madd	x14, x0, x14, x4
	add	x11, x3, #32
	add	x12, x10, x2
	lsl	x13, x1, #7
	sub	x16, x15, #32
	add	x17, x4, x0, lsl #6
	sub	x18, x18, #16
	add	x0, x4, x0, lsl #5
	mov	x6, x4
	b	.LBB129_7
.LBB129_6:                              //   in Loop: Header=BB129_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x13
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB129_10
.LBB129_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB129_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #5
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #5
	ldp	q0, q1, [x7]
	add	x7, x3, x20, lsl #5
	add	x20, x3, x21, lsl #5
	ldp	q2, q3, [x19]
	mul	x19, x9, x1
	fadd	v16.2d, v0.2d, v2.2d
	add	x19, x4, x19, lsl #5
	fsub	v0.2d, v0.2d, v2.2d
	ldp	q4, q5, [x7]
	fadd	v17.2d, v1.2d, v3.2d
	add	x7, x9, x10
	fsub	v1.2d, v1.2d, v3.2d
	mul	x7, x7, x1
	ldp	q6, q7, [x20]
	add	x7, x4, x7, lsl #5
	add	x20, x9, x2
	mul	x20, x20, x1
	fadd	v2.2d, v4.2d, v6.2d
	fsub	v4.2d, v4.2d, v6.2d
	fadd	v3.2d, v5.2d, v7.2d
	fsub	v5.2d, v5.2d, v7.2d
	fadd	v6.2d, v16.2d, v2.2d
	fsub	v2.2d, v16.2d, v2.2d
	fadd	v16.2d, v17.2d, v3.2d
	fsub	v3.2d, v17.2d, v3.2d
	stp	q6, q16, [x19]
	add	x19, x9, x12
	stp	q2, q3, [x7]
	mul	x7, x19, x1
	add	x19, x4, x20, lsl #5
	fsub	v2.2d, v0.2d, v5.2d
	fadd	v3.2d, v1.2d, v4.2d
	fadd	v0.2d, v0.2d, v5.2d
	add	x7, x4, x7, lsl #5
	fsub	v1.2d, v1.2d, v4.2d
	stp	q2, q3, [x19]
	stp	q0, q1, [x7]
	b.lo	.LBB129_6
// %bb.8:                               //   in Loop: Header=BB129_7 Depth=1
	mov	x7, xzr
	mov	x19, x5
	mov	x20, x8
.LBB129_9:                              //   Parent Loop BB129_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x21, x11, x7
	ldr	d20, [x19, #8]
	add	x22, x21, x15
	subs	x20, x20, #1
	add	x23, x22, x15
	ldp	q0, q1, [x21]
	add	x21, x23, x15
	ldp	q4, q5, [x23]
	add	x23, x19, x18
	fadd	v16.2d, v0.2d, v4.2d
	fsub	v0.2d, v0.2d, v4.2d
	ldp	q2, q3, [x22]
	fadd	v17.2d, v1.2d, v5.2d
	add	x22, x6, x7
	fsub	v1.2d, v1.2d, v5.2d
	ldp	q6, q7, [x21]
	mov	x21, x19
	add	x19, x19, #16
	fsub	v4.2d, v2.2d, v6.2d
	fadd	v2.2d, v2.2d, v6.2d
	fadd	v5.2d, v3.2d, v7.2d
	fsub	v3.2d, v3.2d, v7.2d
	fadd	v6.2d, v1.2d, v4.2d
	fadd	v7.2d, v16.2d, v2.2d
	fadd	v18.2d, v17.2d, v5.2d
	fsub	v5.2d, v17.2d, v5.2d
	fneg	v19.2d, v6.2d
	fsub	v2.2d, v16.2d, v2.2d
	stp	q7, q18, [x22, #32]
	add	x22, x0, x7
	fsub	v7.2d, v0.2d, v3.2d
	ld1r	{ v18.2d }, [x21], x16
	fmul	v19.2d, v19.2d, v20.d[0]
	fmul	v6.2d, v6.2d, v18.2d
	fsub	v1.2d, v1.2d, v4.2d
	fadd	v0.2d, v0.2d, v3.2d
	fmla	v19.2d, v18.2d, v7.2d
	fmla	v6.2d, v7.2d, v20.d[0]
	fneg	v7.2d, v5.2d
	fneg	v4.2d, v1.2d
	stp	q19, q6, [x22, #32]
	add	x22, x17, x7
	ld1r	{ v6.2d }, [x23], #8
	fmul	v5.2d, v5.2d, v6.2d
	ldr	d17, [x23]
	fmul	v7.2d, v7.2d, v17.d[0]
	fmla	v5.2d, v2.2d, v17.d[0]
	fmla	v7.2d, v6.2d, v2.2d
	stp	q7, q5, [x22, #32]
	ld1r	{ v2.2d }, [x21], #8
	fmul	v1.2d, v1.2d, v2.2d
	ldr	d5, [x21]
	add	x21, x14, x7
	add	x7, x7, #32
	fmul	v3.2d, v4.2d, v5.d[0]
	fmla	v1.2d, v0.2d, v5.d[0]
	fmla	v3.2d, v2.2d, v0.2d
	stp	q3, q1, [x21, #32]
	b.ne	.LBB129_9
	b	.LBB129_6
.LBB129_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp], #48                  // 8-byte Folded Reload
	ret
.Lfunc_end129:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end129-_ZNK9pocketfft6detail5cfftpIdE5pass4ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	str	d14, [sp, #80]                  // 8-byte Folded Spill
	stp	d13, d12, [sp, #96]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #112]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 240
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -160
	subs	x8, x1, #1
	str	x4, [sp, #72]                   // 8-byte Folded Spill
	str	x3, [sp, #88]                   // 8-byte Folded Spill
	b.ne	.LBB130_4
// %bb.1:
	cbz	x2, .LBB130_10
// %bb.2:
	mov	x17, #15309
	mov	w10, #224
	movk	x17, #26239, lsl #16
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	movk	x17, #41118, lsl #32
	ldr	x15, [sp, #88]                  // 8-byte Folded Reload
	movk	x17, #16358, lsl #48
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	mul	x10, x2, x10
	add	x8, x8, #16
	lsl	x9, x13, #5
	lsl	x11, x11, #5
	lsl	x12, x2, #5
	lsl	x13, x13, #6
	lsl	x14, x2, #6
	lsl	x16, x2, #7
	add	x15, x15, #128
	dup	v0.2d, x17
.LBB130_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q1, q2, [x15, #-96]
	add	x17, x8, x16
	add	x18, x8, x13
	subs	x2, x2, #1
	ldp	q3, q4, [x15, #32]
	fadd	v6.2d, v1.2d, v3.2d
	fsub	v3.2d, v1.2d, v3.2d
	ldp	q5, q7, [x15, #-32]
	fadd	v16.2d, v2.2d, v4.2d
	fsub	v1.2d, v2.2d, v4.2d
	ldp	q17, q18, [x15, #96]
	fadd	v2.2d, v5.2d, v17.2d
	fsub	v5.2d, v5.2d, v17.2d
	fadd	v4.2d, v7.2d, v18.2d
	ldp	q19, q17, [x15, #-128]
	fsub	v7.2d, v7.2d, v18.2d
	fadd	v20.2d, v6.2d, v2.2d
	fadd	v22.2d, v16.2d, v4.2d
	fsub	v2.2d, v6.2d, v2.2d
	fsub	v4.2d, v16.2d, v4.2d
	ldp	q18, q21, [x15]
	fsub	v27.2d, v3.2d, v7.2d
	fadd	v28.2d, v1.2d, v5.2d
	fadd	v3.2d, v3.2d, v7.2d
	fadd	v24.2d, v19.2d, v18.2d
	fsub	v18.2d, v19.2d, v18.2d
	ldp	q23, q25, [x15, #64]
	fadd	v29.2d, v17.2d, v21.2d
	fsub	v7.2d, v27.2d, v28.2d
	fsub	v17.2d, v17.2d, v21.2d
	fadd	v27.2d, v28.2d, v27.2d
	fsub	v1.2d, v1.2d, v5.2d
	ldp	q6, q16, [x15, #-64]
	fmul	v7.2d, v7.2d, v0.2d
	add	x15, x15, #256
	fneg	v5.2d, v3.2d
	fadd	v26.2d, v6.2d, v23.2d
	fsub	v6.2d, v6.2d, v23.2d
	fadd	v31.2d, v16.2d, v25.2d
	fsub	v16.2d, v16.2d, v25.2d
	fadd	v30.2d, v24.2d, v26.2d
	fsub	v21.2d, v24.2d, v26.2d
	fadd	v9.2d, v29.2d, v31.2d
	fsub	v24.2d, v29.2d, v31.2d
	fsub	v8.2d, v30.2d, v20.2d
	fadd	v23.2d, v17.2d, v6.2d
	fsub	v19.2d, v9.2d, v22.2d
	fadd	v25.2d, v2.2d, v24.2d
	fsub	v2.2d, v24.2d, v2.2d
	fsub	v5.2d, v5.2d, v1.2d
	stp	q8, q19, [x17, #-16]
	add	x17, x8, x14
	fsub	v19.2d, v21.2d, v4.2d
	fadd	v4.2d, v4.2d, v21.2d
	fsub	v21.2d, v18.2d, v16.2d
	fsub	v1.2d, v3.2d, v1.2d
	stp	q19, q25, [x17, #-16]
	add	x17, x8, x12
	fmul	v19.2d, v27.2d, v0.2d
	stp	q4, q2, [x18, #-16]
	fadd	v4.2d, v7.2d, v21.2d
	add	x18, x8, x11
	fmul	v1.2d, v1.2d, v0.2d
	fadd	v3.2d, v18.2d, v16.2d
	fadd	v2.2d, v19.2d, v23.2d
	stp	q4, q2, [x17, #-16]
	fsub	v4.2d, v21.2d, v7.2d
	add	x17, x8, x9
	fmul	v2.2d, v5.2d, v0.2d
	stur	q4, [x18, #-16]
	fsub	v4.2d, v23.2d, v19.2d
	fsub	v5.2d, v17.2d, v6.2d
	fadd	v6.2d, v20.2d, v30.2d
	fadd	v7.2d, v2.2d, v3.2d
	str	q4, [x18]
	fadd	v4.2d, v1.2d, v5.2d
	stur	q6, [x8, #-16]
	fadd	v6.2d, v22.2d, v9.2d
	fsub	v2.2d, v3.2d, v2.2d
	fsub	v1.2d, v5.2d, v1.2d
	stp	q7, q4, [x17, #-16]
	add	x17, x8, x10
	str	q6, [x8], #32
	stp	q2, q1, [x17, #-16]
	b.ne	.LBB130_3
	b	.LBB130_10
.LBB130_4:
	stp	x5, x8, [sp, #8]                // 16-byte Folded Spill
	cbz	x2, .LBB130_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x10, x2, #2
	add	x11, x8, x2
	ldr	x3, [sp, #88]                   // 8-byte Folded Reload
	ldr	x14, [sp, #16]                  // 8-byte Folded Reload
	lsl	x16, x1, #5
	stp	x10, x8, [sp, #56]              // 16-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	str	x11, [sp, #48]                  // 8-byte Folded Spill
	lsl	x11, x11, #1
	add	x10, x10, x2
	add	x12, x16, x3
	ldr	x4, [sp, #72]                   // 8-byte Folded Reload
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	mov	w8, #160
	stp	x10, x11, [sp, #32]             // 16-byte Folded Spill
	mul	x10, x2, x1
	madd	x13, x14, x8, x3
	mov	w11, #224
	add	x18, x12, #48
	mov	w12, #96
	add	x6, x13, #208
	add	x13, x1, x1, lsl #1
	lsl	x7, x13, #5
	madd	x17, x10, x11, x4
	madd	x11, x1, x11, x3
	mov	x9, xzr
	madd	x19, x10, x12, x4
	add	x12, x7, x3
	add	x20, x12, #48
	mov	w12, #192
	add	x21, x11, #48
	add	x11, x3, x14, lsl #7
	madd	x22, x10, x8, x4
	add	x23, x11, #128
	add	x8, x3, x14, lsl #6
	madd	x11, x14, x12, x3
	add	x24, x8, #64
	mov	w8, #80
	madd	x26, x10, x12, x4
	mov	x12, #15309
	add	x25, x11, #192
	mov	w11, #48
	movk	x12, #26239, lsl #16
	mul	x8, x1, x8
	movk	x12, #41118, lsl #32
	mul	x11, x1, x11
	movk	x12, #16358, lsl #48
	sub	x30, x8, #80
	lsl	x8, x1, #4
	lsl	x0, x1, #8
	add	x27, x4, x10, lsl #5
	lsl	x28, x1, #6
	add	x29, x4, x10, lsl #6
	sub	x8, x8, #16
	add	x5, x4, x10, lsl #7
	sub	x13, x11, #48
	dup	v0.2d, x12
	b	.LBB130_7
.LBB130_6:                              //   in Loop: Header=BB130_7 Depth=1
	add	x9, x9, #1
	add	x17, x17, x16
	add	x18, x18, x0
	add	x6, x6, x0
	add	x19, x19, x16
	add	x20, x20, x0
	add	x21, x21, x0
	add	x22, x22, x16
	add	x3, x3, x0
	add	x23, x23, x0
	add	x24, x24, x0
	add	x25, x25, x0
	add	x4, x4, x16
	add	x27, x27, x16
	add	x26, x26, x16
	add	x29, x29, x16
	add	x5, x5, x16
	cmp	x9, x2
	b.eq	.LBB130_10
.LBB130_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB130_9 Depth 2
	mov	w10, #1
	mov	w11, #5
	bfi	x10, x9, #3, #61
	bfi	x11, x9, #3, #61
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	mov	w12, #3
	mul	x10, x10, x1
	mov	w15, #7
	mul	x11, x11, x1
	bfi	x12, x9, #3, #61
	bfi	x15, x9, #3, #61
	cmp	x1, #2
	add	x10, x14, x10, lsl #5
	mul	x12, x12, x1
	add	x11, x14, x11, lsl #5
	ldp	q1, q2, [x10]
	mul	x10, x15, x1
	add	x12, x14, x12, lsl #5
	add	x10, x14, x10, lsl #5
	ldp	q3, q4, [x11]
	lsl	x11, x9, #3
	fadd	v7.2d, v1.2d, v3.2d
	fsub	v18.2d, v1.2d, v3.2d
	ldp	q5, q6, [x12]
	fadd	v16.2d, v2.2d, v4.2d
	mov	w12, #2
	fsub	v19.2d, v2.2d, v4.2d
	bfi	x12, x9, #3, #61
	mul	x12, x12, x1
	ldp	q17, q1, [x10]
	mul	x10, x11, x1
	mov	w11, #4
	bfi	x11, x9, #3, #61
	add	x12, x14, x12, lsl #5
	fadd	v2.2d, v5.2d, v17.2d
	add	x10, x14, x10, lsl #5
	fsub	v5.2d, v5.2d, v17.2d
	mul	x11, x11, x1
	fadd	v20.2d, v6.2d, v1.2d
	fsub	v6.2d, v6.2d, v1.2d
	fadd	v4.2d, v7.2d, v2.2d
	add	x11, x14, x11, lsl #5
	fsub	v1.2d, v7.2d, v2.2d
	fadd	v3.2d, v16.2d, v20.2d
	fsub	v2.2d, v16.2d, v20.2d
	ldp	q16, q17, [x10]
	mov	w10, #6
	bfi	x10, x9, #3, #61
	fadd	v7.2d, v18.2d, v6.2d
	mul	x10, x10, x1
	fsub	v6.2d, v18.2d, v6.2d
	fadd	v18.2d, v19.2d, v5.2d
	add	x10, x14, x10, lsl #5
	ldr	x14, [sp, #72]                  // 8-byte Folded Reload
	ldp	q20, q21, [x11]
	fsub	v5.2d, v19.2d, v5.2d
	fsub	v22.2d, v6.2d, v18.2d
	fadd	v6.2d, v18.2d, v6.2d
	fneg	v19.2d, v7.2d
	fadd	v25.2d, v16.2d, v20.2d
	ldp	q23, q18, [x12]
	fadd	v27.2d, v17.2d, v21.2d
	fsub	v19.2d, v19.2d, v5.2d
	fsub	v5.2d, v7.2d, v5.2d
	fsub	v7.2d, v16.2d, v20.2d
	fsub	v17.2d, v17.2d, v21.2d
	ldp	q24, q26, [x10]
	mul	x10, x9, x1
	fmul	v22.2d, v22.2d, v0.2d
	fmul	v6.2d, v6.2d, v0.2d
	fadd	v28.2d, v23.2d, v24.2d
	add	x10, x14, x10, lsl #5
	fadd	v29.2d, v18.2d, v26.2d
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	fsub	v18.2d, v18.2d, v26.2d
	ldr	x12, [sp, #40]                  // 8-byte Folded Reload
	fadd	v16.2d, v25.2d, v28.2d
	add	x11, x9, x11
	fadd	v20.2d, v27.2d, v29.2d
	add	x12, x9, x12
	mul	x11, x11, x1
	fadd	v21.2d, v4.2d, v16.2d
	fsub	v4.2d, v16.2d, v4.2d
	fadd	v26.2d, v3.2d, v20.2d
	add	x11, x14, x11, lsl #5
	fsub	v3.2d, v20.2d, v3.2d
	stp	q21, q26, [x10]
	ldr	x10, [sp, #64]                  // 8-byte Folded Reload
	fsub	v21.2d, v25.2d, v28.2d
	stp	q4, q3, [x11]
	fsub	v25.2d, v27.2d, v29.2d
	mul	x11, x12, x1
	add	x10, x9, x10
	ldr	x12, [sp, #32]                  // 8-byte Folded Reload
	fsub	v4.2d, v23.2d, v24.2d
	mul	x10, x10, x1
	add	x11, x14, x11, lsl #5
	fsub	v16.2d, v21.2d, v2.2d
	add	x12, x9, x12
	fadd	v20.2d, v1.2d, v25.2d
	add	x10, x14, x10, lsl #5
	fsub	v3.2d, v7.2d, v18.2d
	fadd	v2.2d, v2.2d, v21.2d
	stp	q16, q20, [x10]
	add	x10, x9, x2
	fadd	v16.2d, v17.2d, v4.2d
	fsub	v1.2d, v25.2d, v1.2d
	mul	x10, x10, x1
	fadd	v20.2d, v22.2d, v3.2d
	fsub	v3.2d, v3.2d, v22.2d
	fadd	v21.2d, v6.2d, v16.2d
	add	x10, x14, x10, lsl #5
	stp	q2, q1, [x11]
	mul	x11, x12, x1
	ldr	x12, [sp, #24]                  // 8-byte Folded Reload
	fmul	v1.2d, v5.2d, v0.2d
	stp	q20, q21, [x10]
	add	x10, x14, x11, lsl #5
	ldr	x11, [sp, #48]                  // 8-byte Folded Reload
	add	x12, x9, x12
	fsub	v5.2d, v16.2d, v6.2d
	fmul	v2.2d, v19.2d, v0.2d
	add	x11, x9, x11
	fadd	v6.2d, v7.2d, v18.2d
	fsub	v4.2d, v17.2d, v4.2d
	mul	x11, x11, x1
	stp	q3, q5, [x10]
	mul	x10, x12, x1
	fadd	v3.2d, v2.2d, v6.2d
	add	x11, x14, x11, lsl #5
	fadd	v5.2d, v1.2d, v4.2d
	add	x10, x14, x10, lsl #5
	fsub	v2.2d, v6.2d, v2.2d
	fsub	v1.2d, v4.2d, v1.2d
	stp	q3, q5, [x11]
	stp	q2, q1, [x10]
	b.lo	.LBB130_6
// %bb.8:                               //   in Loop: Header=BB130_7 Depth=1
	ldp	x15, x12, [sp, #8]              // 16-byte Folded Reload
	mov	x10, xzr
.LBB130_9:                              //   Parent Loop BB130_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x11, x18, x10
	add	x14, x6, x10
	subs	x12, x12, #1
	ldp	q4, q3, [x11, #-16]
	add	x11, x20, x10
	ldp	q6, q5, [x14, #-16]
	add	x14, x21, x10
	fadd	v25.2d, v4.2d, v6.2d
	fsub	v4.2d, v4.2d, v6.2d
	ldp	q1, q2, [x11, #-16]
	add	x11, x3, x10
	fadd	v26.2d, v3.2d, v5.2d
	fsub	v3.2d, v3.2d, v5.2d
	ldp	q7, q16, [x14, #-16]
	add	x14, x23, x10
	fadd	v27.2d, v1.2d, v7.2d
	fsub	v1.2d, v1.2d, v7.2d
	ldp	q18, q17, [x11, #32]
	add	x11, x24, x10
	fadd	v28.2d, v2.2d, v16.2d
	fadd	v9.2d, v25.2d, v27.2d
	fsub	v25.2d, v25.2d, v27.2d
	fsub	v2.2d, v2.2d, v16.2d
	ldp	q19, q20, [x14, #32]
	add	x14, x25, x10
	fadd	v10.2d, v26.2d, v28.2d
	fsub	v26.2d, v26.2d, v28.2d
	fadd	v29.2d, v18.2d, v19.2d
	fsub	v7.2d, v18.2d, v19.2d
	ldp	q21, q22, [x11, #32]
	fadd	v30.2d, v17.2d, v20.2d
	add	x11, x4, x10
	fsub	v16.2d, v17.2d, v20.2d
	fsub	v19.2d, v4.2d, v2.2d
	fadd	v20.2d, v3.2d, v1.2d
	fadd	v2.2d, v4.2d, v2.2d
	ldp	q23, q24, [x14, #32]
	add	x14, x15, x13
	fsub	v1.2d, v3.2d, v1.2d
	fadd	v31.2d, v21.2d, v23.2d
	fsub	v17.2d, v21.2d, v23.2d
	fadd	v8.2d, v22.2d, v24.2d
	fsub	v18.2d, v22.2d, v24.2d
	fadd	v11.2d, v29.2d, v31.2d
	fsub	v28.2d, v29.2d, v31.2d
	fadd	v12.2d, v30.2d, v8.2d
	fsub	v27.2d, v30.2d, v8.2d
	fadd	v13.2d, v9.2d, v11.2d
	fsub	v9.2d, v11.2d, v9.2d
	fadd	v14.2d, v10.2d, v12.2d
	fsub	v10.2d, v12.2d, v10.2d
	fadd	v30.2d, v25.2d, v27.2d
	fsub	v25.2d, v27.2d, v25.2d
	stp	q13, q14, [x11, #32]
	add	x11, x5, x10
	ld1r	{ v12.2d }, [x14], #8
	fneg	v13.2d, v10.2d
	fmul	v10.2d, v10.2d, v12.2d
	fneg	v29.2d, v30.2d
	ldr	d14, [x14]
	add	x14, x15, x8
	fsub	v3.2d, v7.2d, v18.2d
	fadd	v4.2d, v16.2d, v17.2d
	fmul	v11.2d, v13.2d, v14.d[0]
	fmla	v10.2d, v9.2d, v14.d[0]
	fadd	v7.2d, v7.2d, v18.2d
	fsub	v16.2d, v16.2d, v17.2d
	fneg	v17.2d, v2.2d
	fmla	v11.2d, v12.2d, v9.2d
	fsub	v9.2d, v28.2d, v26.2d
	fsub	v18.2d, v19.2d, v20.2d
	fadd	v19.2d, v20.2d, v19.2d
	stp	q11, q10, [x11, #32]
	add	x11, x29, x10
	ld1r	{ v8.2d }, [x14], #8
	fmul	v30.2d, v30.2d, v8.2d
	fsub	v2.2d, v2.2d, v1.2d
	fsub	v1.2d, v17.2d, v1.2d
	ldr	d31, [x14]
	add	x14, x15, x30
	fmul	v17.2d, v18.2d, v0.2d
	fmul	v18.2d, v19.2d, v0.2d
	fmul	v29.2d, v29.2d, v31.d[0]
	fmla	v30.2d, v9.2d, v31.d[0]
	fadd	v26.2d, v26.2d, v28.2d
	fmul	v2.2d, v2.2d, v0.2d
	fadd	v20.2d, v18.2d, v4.2d
	fmla	v29.2d, v8.2d, v9.2d
	fmul	v1.2d, v1.2d, v0.2d
	fadd	v19.2d, v17.2d, v3.2d
	fsub	v3.2d, v3.2d, v17.2d
	stp	q29, q30, [x11, #32]
	mov	x11, x15
	ld1r	{ v27.2d }, [x14], #8
	fneg	v29.2d, v25.2d
	ldr	d6, [x15, #8]
	fmul	v25.2d, v25.2d, v27.2d
	fadd	v17.2d, v2.2d, v16.2d
	ldr	d30, [x14]
	add	x14, x26, x10
	fsub	v2.2d, v16.2d, v2.2d
	fneg	v16.2d, v20.2d
	fmul	v28.2d, v29.2d, v30.d[0]
	fmla	v25.2d, v26.2d, v30.d[0]
	fsub	v4.2d, v4.2d, v18.2d
	fadd	v21.2d, v1.2d, v7.2d
	fmul	v16.2d, v16.2d, v6.d[0]
	fmla	v28.2d, v27.2d, v26.2d
	fsub	v1.2d, v7.2d, v1.2d
	fneg	v18.2d, v4.2d
	fneg	v23.2d, v17.2d
	stp	q28, q25, [x14, #32]
	add	x14, x15, x28
	ld1r	{ v25.2d }, [x11], x7
	fmul	v7.2d, v20.2d, v25.2d
	fmla	v16.2d, v25.2d, v19.2d
	ldp	d5, d26, [x14, #-64]
	add	x14, x15, x16
	add	x15, x15, #16
	fneg	v20.2d, v2.2d
	fmla	v7.2d, v19.2d, v6.d[0]
	ldp	d22, d24, [x14, #-32]
	fmul	v18.2d, v18.2d, v26.d[0]
	fmul	v4.2d, v4.2d, v5.d[0]
	ldp	d25, d6, [x11, #-96]
	add	x14, x27, x10
	add	x11, x22, x10
	fmul	v17.2d, v17.2d, v22.d[0]
	fmul	v19.2d, v23.2d, v24.d[0]
	fmla	v18.2d, v3.2d, v5.d[0]
	fmla	v4.2d, v3.2d, v26.d[0]
	fmul	v2.2d, v2.2d, v25.d[0]
	fmul	v3.2d, v20.2d, v6.d[0]
	stp	q16, q7, [x14, #32]
	fmla	v17.2d, v21.2d, v24.d[0]
	add	x14, x19, x10
	fmla	v19.2d, v21.2d, v22.d[0]
	fmla	v2.2d, v1.2d, v6.d[0]
	stp	q18, q4, [x11, #32]
	fmla	v3.2d, v1.2d, v25.d[0]
	add	x11, x17, x10
	add	x10, x10, #32
	stp	q19, q17, [x14, #32]
	stp	q3, q2, [x11, #32]
	b.ne	.LBB130_9
	b	.LBB130_6
.LBB130_10:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #112]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #96]             // 16-byte Folded Reload
	ldr	d14, [sp, #80]                  // 8-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end130:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end130-_ZNK9pocketfft6detail5cfftpIdE5pass8ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	cmp	x1, #1
	b.ne	.LBB131_4
// %bb.1:
	cbz	x2, .LBB131_12
// %bb.2:
	lsl	x8, x2, #5
	add	x9, x4, #16
	add	x10, x3, #32
.LBB131_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-32]
	add	x11, x9, x8
	subs	x2, x2, #1
	ldp	q2, q3, [x10], #64
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x9, #-16]
	add	x9, x9, #32
	stp	q0, q1, [x11, #-16]
	b.ne	.LBB131_3
	b	.LBB131_12
.LBB131_4:
	cbz	x2, .LBB131_12
// %bb.5:
	subs	x8, x1, #1
	b.ls	.LBB131_10
// %bb.6:
	mul	x13, x2, x1
	mov	x9, xzr
	add	x10, x4, #32
	lsl	x11, x1, #5
	add	x12, x3, #48
	lsl	x13, x13, #5
	lsl	x14, x1, #6
	add	x15, x5, #8
.LBB131_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB131_8 Depth 2
	mov	w17, #1
	lsl	x16, x9, #1
	bfi	x17, x9, #1, #63
	mul	x5, x9, x1
	mul	x16, x16, x1
	add	x18, x9, x2
	mul	x17, x17, x1
	mul	x18, x18, x1
	add	x16, x3, x16, lsl #5
	add	x0, x3, x17, lsl #5
	mov	x17, x12
	ldp	q0, q1, [x16]
	mov	x16, x15
	ldp	q2, q3, [x0]
	add	x0, x4, x5, lsl #5
	add	x5, x4, x18, lsl #5
	mov	x18, x10
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x0]
	mov	x0, x8
	stp	q0, q1, [x5]
.LBB131_8:                              //   Parent Loop BB131_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x5, x17, x11
	subs	x0, x0, #1
	ldp	q3, q0, [x17, #-16]
	add	x17, x17, #32
	ldp	q6, q1, [x5, #-16]
	add	x5, x18, x13
	fsub	v16.2d, v3.2d, v6.2d
	fadd	v3.2d, v3.2d, v6.2d
	fsub	v2.2d, v0.2d, v1.2d
	ldp	d7, d4, [x16, #-8]
	fadd	v0.2d, v0.2d, v1.2d
	add	x16, x16, #16
	fneg	v5.2d, v2.2d
	fmul	v2.2d, v2.2d, v7.d[0]
	stp	q3, q0, [x18], #32
	fmul	v5.2d, v5.2d, v4.d[0]
	fmla	v2.2d, v16.2d, v4.d[0]
	fmla	v5.2d, v16.2d, v7.d[0]
	stp	q5, q2, [x5]
	b.ne	.LBB131_8
// %bb.9:                               //   in Loop: Header=BB131_7 Depth=1
	add	x9, x9, #1
	add	x10, x10, x11
	add	x12, x12, x14
	cmp	x9, x2
	b.ne	.LBB131_7
	b	.LBB131_12
.LBB131_10:
	mul	x10, x2, x1
	add	x8, x4, #16
	lsl	x9, x1, #5
	add	x11, x3, #16
	lsl	x10, x10, #5
	lsl	x12, x1, #6
.LBB131_11:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	q0, q1, [x11, #-16]
	add	x11, x11, x12
	ldp	q2, q3, [x13, #-16]
	add	x13, x8, x10
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x8, #-16]
	add	x8, x8, x9
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB131_11
.LBB131_12:
	ret
.Lfunc_end131:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end131-_ZNK9pocketfft6detail5cfftpIdE5pass2ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	str	x21, [sp, #-32]!                // 8-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	subs	x8, x1, #1
	b.ne	.LBB132_4
// %bb.1:
	cbz	x2, .LBB132_10
// %bb.2:
	mov	x12, #19626
	mov	x13, #19626
	movk	x12, #59480, lsl #16
	movk	x13, #59480, lsl #16
	movk	x12, #46714, lsl #32
	movk	x13, #46714, lsl #32
	movk	x12, #49131, lsl #48
	movk	x13, #16363, lsl #48
	fmov	v0.2d, #0.50000000
	lsl	x8, x2, #6
	add	x9, x4, #16
	lsl	x10, x2, #5
	add	x11, x3, #48
	dup	v1.2d, x12
	dup	v2.2d, x13
.LBB132_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q3, q4, [x11, #-16]
	add	x12, x9, x10
	subs	x2, x2, #1
	ldp	q5, q6, [x11, #16]
	fadd	v7.2d, v3.2d, v5.2d
	fsub	v3.2d, v3.2d, v5.2d
	fadd	v17.2d, v4.2d, v6.2d
	ldp	q16, q18, [x11, #-48]
	fsub	v4.2d, v4.2d, v6.2d
	add	x11, x11, #96
	fmul	v5.2d, v7.2d, v0.2d
	fmul	v6.2d, v17.2d, v0.2d
	fmul	v3.2d, v3.2d, v2.2d
	fmul	v4.2d, v4.2d, v1.2d
	fsub	v5.2d, v16.2d, v5.2d
	fsub	v6.2d, v18.2d, v6.2d
	fadd	v7.2d, v16.2d, v7.2d
	fadd	v16.2d, v18.2d, v17.2d
	fadd	v19.2d, v5.2d, v4.2d
	fadd	v20.2d, v3.2d, v6.2d
	fsub	v4.2d, v5.2d, v4.2d
	fsub	v3.2d, v6.2d, v3.2d
	stp	q7, q16, [x9, #-16]
	stp	q19, q20, [x12, #-16]
	add	x12, x9, x8
	add	x9, x9, #32
	stp	q4, q3, [x12, #-16]
	b.ne	.LBB132_3
	b	.LBB132_10
.LBB132_4:
	cbz	x2, .LBB132_10
// %bb.5:
	mov	x6, #19626
	mov	x7, #19626
	movk	x6, #59480, lsl #16
	movk	x7, #59480, lsl #16
	mul	x16, x2, x1
	movk	x6, #46714, lsl #32
	movk	x7, #46714, lsl #32
	movk	x6, #49131, lsl #48
	movk	x7, #16363, lsl #48
	add	x12, x1, x1, lsl #1
	lsl	x11, x1, #5
	lsl	x17, x1, #4
	fmov	v0.2d, #0.50000000
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #5
	add	x13, x3, x11
	add	x14, x4, x16, lsl #6
	add	x15, x3, x1, lsl #6
	add	x16, x4, x16, lsl #5
	sub	x17, x17, #16
	mov	x18, x4
	mov	x0, x3
	dup	v1.2d, x6
	dup	v2.2d, x7
	b	.LBB132_7
.LBB132_6:                              //   in Loop: Header=BB132_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x0, x0, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x18, x18, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB132_10
.LBB132_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB132_9 Depth 2
	add	x6, x9, x9, lsl #1
	add	x20, x9, x2
	add	x7, x6, #2
	cmp	x1, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	add	x6, x3, x6, lsl #5
	add	x19, x3, x19, lsl #5
	add	x7, x3, x7, lsl #5
	ldp	q3, q4, [x6]
	mul	x6, x9, x1
	add	x6, x4, x6, lsl #5
	ldp	q5, q6, [x19]
	add	x19, x9, x10
	mul	x19, x19, x1
	ldp	q7, q16, [x7]
	mul	x7, x20, x1
	add	x19, x4, x19, lsl #5
	fadd	v17.2d, v5.2d, v7.2d
	add	x7, x4, x7, lsl #5
	fsub	v5.2d, v5.2d, v7.2d
	fadd	v18.2d, v6.2d, v16.2d
	fsub	v6.2d, v6.2d, v16.2d
	fadd	v7.2d, v3.2d, v17.2d
	fmul	v17.2d, v17.2d, v0.2d
	fadd	v16.2d, v4.2d, v18.2d
	fmul	v18.2d, v18.2d, v0.2d
	fmul	v6.2d, v6.2d, v1.2d
	fmul	v5.2d, v5.2d, v2.2d
	fsub	v3.2d, v3.2d, v17.2d
	stp	q7, q16, [x6]
	fsub	v4.2d, v4.2d, v18.2d
	fadd	v7.2d, v3.2d, v6.2d
	fadd	v16.2d, v5.2d, v4.2d
	fsub	v3.2d, v3.2d, v6.2d
	fsub	v4.2d, v4.2d, v5.2d
	stp	q7, q16, [x7]
	stp	q3, q4, [x19]
	b.lo	.LBB132_6
// %bb.8:                               //   in Loop: Header=BB132_7 Depth=1
	mov	x6, xzr
	mov	x7, x5
	mov	x19, x8
.LBB132_9:                              //   Parent Loop BB132_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x13, x6
	add	x21, x15, x6
	subs	x19, x19, #1
	ldp	q5, q3, [x20, #32]
	add	x20, x0, x6
	ldp	q6, q4, [x21, #32]
	add	x21, x18, x6
	fsub	v16.2d, v5.2d, v6.2d
	fadd	v5.2d, v5.2d, v6.2d
	fadd	v7.2d, v3.2d, v4.2d
	ldp	q18, q19, [x20, #32]
	fmul	v6.2d, v16.2d, v2.2d
	mov	x20, x7
	fsub	v3.2d, v3.2d, v4.2d
	fmul	v17.2d, v7.2d, v0.2d
	fadd	v4.2d, v18.2d, v5.2d
	fmul	v5.2d, v5.2d, v0.2d
	fadd	v7.2d, v19.2d, v7.2d
	fsub	v16.2d, v19.2d, v17.2d
	fmul	v3.2d, v3.2d, v1.2d
	fsub	v5.2d, v18.2d, v5.2d
	stp	q4, q7, [x21, #32]
	ldr	d4, [x7, #8]
	fadd	v17.2d, v6.2d, v16.2d
	add	x21, x16, x6
	ld1r	{ v7.2d }, [x20], x17
	fadd	v19.2d, v5.2d, v3.2d
	add	x7, x7, #16
	fsub	v3.2d, v5.2d, v3.2d
	fneg	v18.2d, v17.2d
	fmul	v17.2d, v17.2d, v7.2d
	fmul	v18.2d, v18.2d, v4.d[0]
	fmla	v17.2d, v19.2d, v4.d[0]
	fsub	v4.2d, v16.2d, v6.2d
	fmla	v18.2d, v7.2d, v19.2d
	fneg	v7.2d, v4.2d
	stp	q18, q17, [x21, #32]
	ld1r	{ v6.2d }, [x20], #8
	fmul	v4.2d, v4.2d, v6.2d
	ldr	d16, [x20]
	add	x20, x14, x6
	add	x6, x6, #32
	fmul	v5.2d, v7.2d, v16.d[0]
	fmla	v4.2d, v3.2d, v16.d[0]
	fmla	v5.2d, v6.2d, v3.2d
	stp	q5, q4, [x20, #32]
	b.ne	.LBB132_9
	b	.LBB132_6
.LBB132_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp], #32                  // 8-byte Folded Reload
	ret
.Lfunc_end132:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end132-_ZNK9pocketfft6detail5cfftpIdE5pass3ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	b.ne	.LBB133_4
// %bb.1:
	cbz	x2, .LBB133_10
// %bb.2:
	mov	x11, #59728
	mov	x12, #62632
	mov	x13, #23134
	movk	x11, #14127, lsl #16
	movk	x12, #39831, lsl #16
	movk	x13, #1141, lsl #16
	mov	x14, #21759
	mov	x15, #21759
	movk	x11, #50927, lsl #32
	movk	x12, #58231, lsl #32
	movk	x13, #53027, lsl #32
	movk	x14, #4932, lsl #16
	movk	x15, #4932, lsl #16
	movk	x11, #16339, lsl #48
	movk	x12, #49129, lsl #48
	movk	x13, #16354, lsl #48
	movk	x14, #28430, lsl #32
	movk	x15, #28430, lsl #32
	movk	x14, #16366, lsl #48
	movk	x15, #49134, lsl #48
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #6
	lsl	x10, x10, #5
	dup	v0.2d, x11
	dup	v1.2d, x12
	lsl	x11, x2, #7
	dup	v2.2d, x13
	lsl	x12, x2, #5
	add	x13, x3, #80
	dup	v3.2d, x14
	dup	v4.2d, x15
.LBB133_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x13, #-48]
	add	x14, x8, x12
	add	x15, x8, x9
	subs	x2, x2, #1
	ldp	q16, q7, [x13, #48]
	fadd	v19.2d, v5.2d, v16.2d
	fsub	v5.2d, v5.2d, v16.2d
	ldp	q17, q20, [x13, #-16]
	fadd	v21.2d, v6.2d, v7.2d
	fsub	v6.2d, v6.2d, v7.2d
	ldp	q22, q18, [x13, #16]
	fadd	v23.2d, v17.2d, v22.2d
	fsub	v17.2d, v17.2d, v22.2d
	ldp	q16, q7, [x13, #-80]
	fsub	v24.2d, v20.2d, v18.2d
	add	x13, x13, #160
	fadd	v18.2d, v20.2d, v18.2d
	fmul	v22.2d, v17.2d, v2.2d
	mov	v25.16b, v16.16b
	fmul	v20.2d, v24.2d, v2.2d
	mov	v26.16b, v7.16b
	fmla	v22.2d, v3.2d, v5.2d
	fmla	v25.2d, v0.2d, v19.2d
	fmla	v20.2d, v3.2d, v6.2d
	fmla	v26.2d, v0.2d, v21.2d
	fadd	v27.2d, v16.2d, v19.2d
	fmla	v16.2d, v1.2d, v19.2d
	fmla	v25.2d, v1.2d, v23.2d
	fadd	v28.2d, v7.2d, v21.2d
	fmla	v7.2d, v1.2d, v21.2d
	fmla	v26.2d, v1.2d, v18.2d
	fmul	v24.2d, v24.2d, v4.2d
	fmla	v16.2d, v0.2d, v23.2d
	fmul	v17.2d, v17.2d, v4.2d
	fsub	v19.2d, v25.2d, v20.2d
	fmla	v7.2d, v0.2d, v18.2d
	fadd	v21.2d, v26.2d, v22.2d
	fadd	v20.2d, v25.2d, v20.2d
	fmla	v24.2d, v2.2d, v6.2d
	fmla	v17.2d, v2.2d, v5.2d
	fsub	v5.2d, v26.2d, v22.2d
	fadd	v6.2d, v27.2d, v23.2d
	stp	q19, q21, [x14, #-16]
	add	x14, x8, x11
	fsub	v19.2d, v16.2d, v24.2d
	stp	q20, q5, [x14, #-16]
	add	x14, x8, x10
	fadd	v20.2d, v7.2d, v17.2d
	stur	q6, [x8, #-16]
	fadd	v5.2d, v28.2d, v18.2d
	fadd	v6.2d, v16.2d, v24.2d
	fsub	v7.2d, v7.2d, v17.2d
	stp	q19, q20, [x15, #-16]
	str	q5, [x8], #32
	stp	q6, q7, [x14, #-16]
	b.ne	.LBB133_3
	b	.LBB133_10
.LBB133_4:
	cbz	x2, .LBB133_10
// %bb.5:
	mov	x23, #59728
	mov	x24, #62632
	movk	x23, #14127, lsl #16
	movk	x24, #39831, lsl #16
	mov	x25, #23134
	mov	x26, #21759
	mov	x27, #21759
	mul	x22, x2, x1
	mov	w17, #96
	mov	w19, #48
	movk	x23, #50927, lsl #32
	movk	x24, #58231, lsl #32
	movk	x25, #1141, lsl #16
	movk	x26, #4932, lsl #16
	movk	x27, #4932, lsl #16
	movk	x23, #16339, lsl #48
	movk	x24, #49129, lsl #48
	movk	x25, #53027, lsl #32
	movk	x26, #28430, lsl #32
	movk	x27, #28430, lsl #32
	madd	x0, x8, x17, x3
	movk	x25, #16354, lsl #48
	mul	x21, x1, x19
	movk	x26, #16366, lsl #48
	movk	x27, #49134, lsl #48
	lsl	x11, x2, #1
	lsl	x13, x1, #5
	madd	x14, x22, x17, x4
	add	x15, x1, x1, lsl #2
	add	x18, x3, x8, lsl #6
	lsl	x20, x1, #4
	mov	x9, xzr
	lsl	x10, x2, #2
	add	x12, x11, x2
	lsl	x15, x15, #5
	add	x16, x3, x13
	add	x17, x3, x1, lsl #7
	add	x18, x18, #64
	add	x0, x0, #96
	add	x6, x4, x22, lsl #6
	sub	x7, x13, #32
	sub	x19, x20, #16
	add	x20, x4, x22, lsl #7
	sub	x21, x21, #48
	add	x22, x4, x22, lsl #5
	dup	v0.2d, x23
	dup	v1.2d, x24
	mov	x23, x4
	mov	x24, x3
	dup	v2.2d, x25
	dup	v3.2d, x26
	dup	v4.2d, x27
	b	.LBB133_7
.LBB133_6:                              //   in Loop: Header=BB133_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x13
	add	x24, x24, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x23, x23, x13
	add	x6, x6, x13
	add	x20, x20, x13
	add	x22, x22, x13
	cmp	x9, x2
	b.eq	.LBB133_10
.LBB133_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB133_9 Depth 2
	add	x25, x9, x9, lsl #2
	cmp	x1, #2
	add	x26, x25, #4
	add	x29, x25, #2
	mul	x27, x25, x1
	add	x25, x25, #3
	mul	x26, x26, x1
	mul	x25, x25, x1
	add	x28, x3, x27, lsl #5
	add	x27, x1, x27
	add	x26, x3, x26, lsl #5
	add	x27, x3, x27, lsl #5
	add	x25, x3, x25, lsl #5
	ldp	q6, q5, [x28]
	mul	x28, x29, x1
	ldp	q7, q16, [x27]
	add	x27, x3, x28, lsl #5
	mov	v25.16b, v5.16b
	ldp	q17, q18, [x26]
	add	x26, x9, x2
	mul	x26, x26, x1
	fadd	v21.2d, v7.2d, v17.2d
	fsub	v7.2d, v7.2d, v17.2d
	ldp	q19, q20, [x27]
	fadd	v22.2d, v16.2d, v18.2d
	add	x26, x4, x26, lsl #5
	fsub	v16.2d, v16.2d, v18.2d
	add	x27, x9, x12
	fadd	v28.2d, v5.2d, v22.2d
	fmla	v25.2d, v0.2d, v22.2d
	ldp	q23, q17, [x25]
	mul	x25, x9, x1
	fmla	v5.2d, v1.2d, v22.2d
	fadd	v18.2d, v19.2d, v23.2d
	add	x25, x4, x25, lsl #5
	fsub	v19.2d, v19.2d, v23.2d
	fadd	v24.2d, v20.2d, v17.2d
	fsub	v17.2d, v20.2d, v17.2d
	mov	v20.16b, v6.16b
	fadd	v23.2d, v6.2d, v21.2d
	fmla	v6.2d, v1.2d, v21.2d
	fmul	v27.2d, v19.2d, v2.2d
	fmla	v25.2d, v1.2d, v24.2d
	fmul	v26.2d, v17.2d, v2.2d
	fmla	v5.2d, v0.2d, v24.2d
	fmla	v20.2d, v0.2d, v21.2d
	fadd	v23.2d, v23.2d, v18.2d
	fmla	v6.2d, v0.2d, v18.2d
	fadd	v28.2d, v28.2d, v24.2d
	fmla	v27.2d, v3.2d, v7.2d
	fmla	v26.2d, v3.2d, v16.2d
	fmla	v20.2d, v1.2d, v18.2d
	fmul	v17.2d, v17.2d, v4.2d
	stp	q23, q28, [x25]
	add	x25, x9, x10
	fadd	v30.2d, v25.2d, v27.2d
	fsub	v29.2d, v20.2d, v26.2d
	mul	x25, x25, x1
	fmul	v19.2d, v19.2d, v4.2d
	fmla	v17.2d, v2.2d, v16.2d
	fadd	v20.2d, v20.2d, v26.2d
	fsub	v21.2d, v25.2d, v27.2d
	add	x25, x4, x25, lsl #5
	stp	q29, q30, [x26]
	add	x26, x9, x11
	fmla	v19.2d, v2.2d, v7.2d
	mul	x26, x26, x1
	stp	q20, q21, [x25]
	mul	x25, x27, x1
	fsub	v7.2d, v6.2d, v17.2d
	fadd	v16.2d, v5.2d, v19.2d
	add	x26, x4, x26, lsl #5
	fadd	v6.2d, v6.2d, v17.2d
	add	x25, x4, x25, lsl #5
	fsub	v5.2d, v5.2d, v19.2d
	stp	q7, q16, [x26]
	stp	q6, q5, [x25]
	b.lo	.LBB133_6
// %bb.8:                               //   in Loop: Header=BB133_7 Depth=1
	mov	x25, xzr
	mov	x26, x5
	mov	x27, x8
.LBB133_9:                              //   Parent Loop BB133_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x28, x24, x25
	add	x29, x16, x25
	add	x30, x17, x25
	subs	x27, x27, #1
	ldp	q5, q6, [x28, #32]
	add	x28, x0, x25
	ldp	q17, q18, [x29, #32]
	add	x29, x18, x25
	mov	v26.16b, v6.16b
	ldp	q19, q20, [x30, #32]
	add	x30, x26, x21
	fadd	v7.2d, v17.2d, v19.2d
	fsub	v17.2d, v17.2d, v19.2d
	ldp	q21, q25, [x28, #32]
	fadd	v24.2d, v18.2d, v20.2d
	mov	x28, x26
	fsub	v18.2d, v18.2d, v20.2d
	fmla	v26.2d, v0.2d, v24.2d
	ldp	q22, q23, [x29, #32]
	fadd	v27.2d, v6.2d, v24.2d
	add	x29, x23, x25
	fmla	v6.2d, v1.2d, v24.2d
	fsub	v16.2d, v22.2d, v21.2d
	fadd	v21.2d, v22.2d, v21.2d
	fadd	v19.2d, v23.2d, v25.2d
	fsub	v22.2d, v23.2d, v25.2d
	fmul	v20.2d, v16.2d, v2.2d
	mov	v23.16b, v5.16b
	fmla	v26.2d, v1.2d, v19.2d
	fmla	v6.2d, v0.2d, v19.2d
	fadd	v25.2d, v5.2d, v7.2d
	fmla	v5.2d, v1.2d, v7.2d
	fmla	v20.2d, v3.2d, v17.2d
	fmla	v23.2d, v0.2d, v7.2d
	fmul	v28.2d, v22.2d, v2.2d
	fadd	v25.2d, v25.2d, v21.2d
	fmla	v5.2d, v0.2d, v21.2d
	fadd	v29.2d, v26.2d, v20.2d
	fadd	v27.2d, v27.2d, v19.2d
	fmla	v23.2d, v1.2d, v21.2d
	fmla	v28.2d, v3.2d, v18.2d
	fsub	v20.2d, v26.2d, v20.2d
	fneg	v30.2d, v29.2d
	stp	q25, q27, [x29, #32]
	ldr	d25, [x26, #8]
	fsub	v27.2d, v23.2d, v28.2d
	add	x29, x22, x25
	ld1r	{ v31.2d }, [x28], x7
	fmul	v30.2d, v30.2d, v25.d[0]
	fmul	v29.2d, v29.2d, v31.2d
	fneg	v26.2d, v20.2d
	fadd	v23.2d, v23.2d, v28.2d
	fmla	v30.2d, v31.2d, v27.2d
	fmla	v29.2d, v27.2d, v25.d[0]
	fmul	v16.2d, v16.2d, v4.2d
	fmul	v7.2d, v22.2d, v4.2d
	stp	q30, q29, [x29, #32]
	add	x29, x20, x25
	ld1r	{ v25.2d }, [x30], #8
	fmul	v20.2d, v20.2d, v25.2d
	fmla	v16.2d, v2.2d, v17.2d
	fmla	v7.2d, v2.2d, v18.2d
	ldr	d27, [x30]
	fadd	v17.2d, v6.2d, v16.2d
	fsub	v21.2d, v5.2d, v7.2d
	fmul	v26.2d, v26.2d, v27.d[0]
	fmla	v20.2d, v23.2d, v27.d[0]
	fsub	v6.2d, v6.2d, v16.2d
	fneg	v18.2d, v17.2d
	fadd	v5.2d, v5.2d, v7.2d
	fmla	v26.2d, v25.2d, v23.2d
	stp	q26, q20, [x29, #32]
	add	x29, x26, x19
	add	x26, x26, #16
	ld1r	{ v19.2d }, [x29], #8
	fmul	v17.2d, v17.2d, v19.2d
	ldr	d20, [x29]
	add	x29, x6, x25
	fmul	v18.2d, v18.2d, v20.d[0]
	fmla	v17.2d, v21.2d, v20.d[0]
	fmla	v18.2d, v19.2d, v21.2d
	stp	q18, q17, [x29, #32]
	ld1r	{ v16.2d }, [x28], #8
	fneg	v17.2d, v6.2d
	fmul	v6.2d, v6.2d, v16.2d
	ldr	d18, [x28]
	add	x28, x14, x25
	add	x25, x25, #32
	fmul	v7.2d, v17.2d, v18.d[0]
	fmla	v6.2d, v5.2d, v18.d[0]
	fmla	v7.2d, v16.2d, v5.2d
	stp	q7, q6, [x28, #32]
	b.ne	.LBB133_9
	b	.LBB133_6
.LBB133_10:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end133:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end133-_ZNK9pocketfft6detail5cfftpIdE5pass5ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #304
	stp	d15, d14, [sp, #144]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #160]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #176]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #192]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #224]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #240]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #256]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #272]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #288]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 304
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	mov	x8, x4
	subs	x9, x1, #1
	str	x3, [sp, #72]                   // 8-byte Folded Spill
	b.ne	.LBB134_4
// %bb.1:
	cbz	x2, .LBB134_10
// %bb.2:
	mov	x15, #17794
	mov	x16, #23665
	movk	x15, #58114, lsl #16
	mov	x17, #59753
	movk	x15, #31632, lsl #32
	movk	x16, #43467, lsl #16
	movk	x17, #1368, lsl #16
	movk	x15, #49100, lsl #48
	movk	x16, #54460, lsl #32
	movk	x17, #12956, lsl #32
	movk	x16, #49132, lsl #48
	movk	x17, #16367, lsl #48
	mov	x12, #60881
	dup	v1.2d, x15
	mov	x15, #43969
	movk	x12, #57995, lsl #16
	mov	x18, #56907
	dup	v2.2d, x16
	movk	x15, #19825, lsl #16
	dup	v3.2d, x17
	mov	x16, #43969
	mov	x17, #56907
	movk	x12, #62368, lsl #32
	movk	x18, #29957, lsl #16
	movk	x15, #50368, lsl #32
	movk	x16, #19825, lsl #16
	movk	x17, #29957, lsl #16
	movk	x12, #16355, lsl #48
	movk	x18, #1219, lsl #32
	movk	x15, #16347, lsl #48
	movk	x16, #50368, lsl #32
	movk	x17, #1219, lsl #32
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	movk	x18, #16361, lsl #48
	movk	x16, #49115, lsl #48
	movk	x17, #49129, lsl #48
	add	x14, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	lsl	x9, x2, #7
	add	x8, x8, #16
	lsl	x10, x14, #5
	lsl	x11, x11, #5
	dup	v0.2d, x12
	lsl	x12, x2, #6
	lsl	x14, x14, #6
	dup	v5.2d, x15
	lsl	x15, x2, #5
	add	x13, x13, #112
	dup	v4.2d, x18
	dup	v6.2d, x16
	dup	v7.2d, x17
.LBB134_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q16, q17, [x13, #-80]
	add	x16, x8, x15
	add	x17, x8, x14
	subs	x2, x2, #1
	ldp	q18, q19, [x13, #80]
	fadd	v24.2d, v16.2d, v18.2d
	fsub	v18.2d, v16.2d, v18.2d
	ldp	q27, q23, [x13, #48]
	fadd	v22.2d, v17.2d, v19.2d
	fsub	v19.2d, v17.2d, v19.2d
	ldp	q25, q26, [x13, #-48]
	fadd	v20.2d, v25.2d, v27.2d
	fsub	v25.2d, v25.2d, v27.2d
	ldp	q16, q17, [x13, #-112]
	fsub	v21.2d, v26.2d, v23.2d
	fadd	v23.2d, v26.2d, v23.2d
	fmul	v11.2d, v25.2d, v3.2d
	mov	v30.16b, v16.16b
	fmul	v10.2d, v21.2d, v3.2d
	mov	v9.16b, v17.16b
	ldp	q8, q29, [x13, #16]
	fmla	v30.2d, v0.2d, v24.2d
	fmla	v11.2d, v4.2d, v18.2d
	fmla	v10.2d, v4.2d, v19.2d
	fmla	v9.2d, v0.2d, v22.2d
	mov	v12.16b, v17.16b
	fmla	v30.2d, v1.2d, v20.2d
	ldp	q31, q26, [x13, #-16]
	fmla	v9.2d, v1.2d, v23.2d
	add	x13, x13, #224
	fmla	v12.2d, v1.2d, v22.2d
	fadd	v28.2d, v31.2d, v8.2d
	fsub	v27.2d, v26.2d, v29.2d
	fmla	v12.2d, v2.2d, v23.2d
	fadd	v26.2d, v26.2d, v29.2d
	fsub	v29.2d, v31.2d, v8.2d
	fmla	v30.2d, v2.2d, v28.2d
	mov	v31.16b, v16.16b
	fmla	v10.2d, v5.2d, v27.2d
	fmla	v9.2d, v2.2d, v26.2d
	fmla	v12.2d, v0.2d, v26.2d
	fmla	v11.2d, v5.2d, v29.2d
	fmla	v31.2d, v1.2d, v24.2d
	fsub	v8.2d, v30.2d, v10.2d
	fadd	v30.2d, v30.2d, v10.2d
	fadd	v13.2d, v11.2d, v9.2d
	fmul	v10.2d, v25.2d, v6.2d
	fmla	v31.2d, v2.2d, v20.2d
	fsub	v9.2d, v9.2d, v11.2d
	fadd	v11.2d, v16.2d, v24.2d
	fmla	v16.2d, v2.2d, v24.2d
	stp	q8, q13, [x16, #-16]
	add	x16, x8, x12
	fmul	v8.2d, v21.2d, v6.2d
	fmla	v10.2d, v3.2d, v18.2d
	stp	q30, q9, [x17, #-16]
	fmla	v31.2d, v0.2d, v28.2d
	fadd	v9.2d, v17.2d, v22.2d
	fmla	v17.2d, v2.2d, v22.2d
	fmul	v21.2d, v21.2d, v7.2d
	fmla	v16.2d, v0.2d, v20.2d
	fmla	v8.2d, v3.2d, v19.2d
	fmla	v10.2d, v7.2d, v29.2d
	fmul	v22.2d, v25.2d, v7.2d
	add	x17, x8, x10
	fadd	v30.2d, v11.2d, v20.2d
	fmla	v17.2d, v0.2d, v23.2d
	fmla	v21.2d, v5.2d, v19.2d
	fmla	v16.2d, v1.2d, v28.2d
	fmla	v8.2d, v7.2d, v27.2d
	fmla	v22.2d, v5.2d, v18.2d
	fadd	v25.2d, v10.2d, v12.2d
	fmla	v17.2d, v1.2d, v26.2d
	fadd	v18.2d, v30.2d, v28.2d
	fmla	v21.2d, v3.2d, v27.2d
	fsub	v24.2d, v31.2d, v8.2d
	fadd	v19.2d, v31.2d, v8.2d
	fmla	v22.2d, v3.2d, v29.2d
	fsub	v20.2d, v12.2d, v10.2d
	fadd	v23.2d, v9.2d, v23.2d
	stur	q18, [x8, #-16]
	stp	q24, q25, [x16, #-16]
	add	x16, x8, x11
	fadd	v24.2d, v22.2d, v17.2d
	fsub	v17.2d, v17.2d, v22.2d
	stp	q19, q20, [x16, #-16]
	add	x16, x8, x9
	fsub	v19.2d, v16.2d, v21.2d
	fadd	v18.2d, v23.2d, v26.2d
	fadd	v16.2d, v16.2d, v21.2d
	stp	q19, q24, [x17, #-16]
	str	q18, [x8], #32
	stp	q16, q17, [x16, #-16]
	b.ne	.LBB134_3
	b	.LBB134_10
.LBB134_4:
	str	x9, [sp, #24]                   // 8-byte Folded Spill
	cbz	x2, .LBB134_10
// %bb.5:
	lsl	x11, x2, #1
	lsl	x12, x2, #2
	mul	x10, x2, x1
	ldr	x13, [sp, #24]                  // 8-byte Folded Reload
	mov	w3, #96
	mov	x23, x5
	str	x11, [sp, #64]                  // 8-byte Folded Spill
	add	x11, x11, x2
	lsl	x18, x11, #1
	madd	x21, x10, x3, x8
	mov	w14, #192
	add	x15, x8, x10, lsl #7
	stp	x12, x11, [sp, #48]             // 16-byte Folded Spill
	add	x11, x12, x2
	ldr	x12, [sp, #72]                  // 8-byte Folded Reload
	add	x27, x8, x10, lsl #6
	add	x29, x8, x10, lsl #5
	madd	x30, x10, x14, x8
	stp	x11, x18, [sp, #32]             // 16-byte Folded Spill
	mov	w11, #224
	madd	x19, x13, x3, x12
	mov	w3, #80
	mul	x17, x1, x11
	mov	w11, #160
	add	x5, x12, x13, lsl #6
	madd	x18, x1, x14, x12
	madd	x4, x13, x11, x12
	mov	x14, #59753
	movk	x14, #1368, lsl #16
	add	x6, x5, #64
	add	x7, x4, #160
	add	x4, x12, x13, lsl #7
	add	x13, x23, #8
	madd	x23, x10, x11, x8
	mul	x11, x1, x3
	mov	x3, #17794
	movk	x3, #58114, lsl #16
	mov	x10, #23665
	sub	x28, x11, #80
	mov	x11, #60881
	movk	x11, #57995, lsl #16
	movk	x3, #31632, lsl #32
	movk	x10, #43467, lsl #16
	movk	x11, #62368, lsl #32
	movk	x3, #49100, lsl #48
	movk	x10, #54460, lsl #32
	movk	x14, #12956, lsl #32
	movk	x11, #16355, lsl #48
	movk	x10, #49132, lsl #48
	movk	x14, #16367, lsl #48
	dup	v1.2d, x3
	mov	x3, #43969
	dup	v11.2d, x11
	mov	x11, #56907
	movk	x3, #19825, lsl #16
	dup	v2.2d, x10
	dup	v3.2d, x14
	mov	x10, #43969
	mov	x14, #56907
	mov	w5, #48
	movk	x11, #29957, lsl #16
	movk	x3, #50368, lsl #32
	movk	x10, #19825, lsl #16
	movk	x14, #29957, lsl #16
	movk	x11, #1219, lsl #32
	movk	x3, #16347, lsl #48
	movk	x10, #50368, lsl #32
	movk	x14, #1219, lsl #32
	mul	x5, x1, x5
	movk	x11, #16361, lsl #48
	movk	x10, #49115, lsl #48
	movk	x14, #49129, lsl #48
	lsl	x16, x1, #5
	mov	x9, xzr
	add	x0, x12, x16
	add	x19, x19, #96
	add	x20, x4, #128
	sub	x22, x5, #48
	sub	x24, x16, #32
	lsl	x25, x1, #6
	lsl	x26, x1, #4
	dup	v15.2d, x3
	mov	x4, x8
	mov	x3, x12
	dup	v0.2d, x11
	dup	v6.2d, x10
	dup	v7.2d, x14
	str	x13, [sp, #16]                  // 8-byte Folded Spill
	stp	q0, q15, [sp, #80]              // 32-byte Folded Spill
	stp	q6, q11, [sp, #112]             // 32-byte Folded Spill
	b	.LBB134_7
.LBB134_6:                              //   in Loop: Header=BB134_7 Depth=1
	add	x9, x9, #1
	add	x15, x15, x16
	add	x3, x3, x17
	add	x0, x0, x17
	add	x18, x18, x17
	add	x6, x6, x17
	add	x7, x7, x17
	add	x19, x19, x17
	add	x20, x20, x17
	add	x4, x4, x16
	add	x21, x21, x16
	add	x23, x23, x16
	add	x27, x27, x16
	add	x29, x29, x16
	add	x30, x30, x16
	cmp	x9, x2
	b.eq	.LBB134_10
.LBB134_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB134_9 Depth 2
	lsl	x10, x9, #3
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	sub	x10, x10, x9
	ldr	q5, [sp, #96]                   // 16-byte Folded Reload
	add	x11, x10, #6
	add	x12, x10, #2
	mul	x14, x10, x1
	cmp	x1, #2
	mul	x11, x11, x1
	mul	x12, x12, x1
	add	x5, x13, x14, lsl #5
	add	x14, x1, x14
	add	x11, x13, x11, lsl #5
	add	x14, x13, x14, lsl #5
	add	x12, x13, x12, lsl #5
	ldp	q16, q17, [x5]
	ldp	q18, q19, [x14]
	add	x14, x10, #5
	mul	x14, x14, x1
	ldp	q20, q21, [x11]
	add	x11, x10, #3
	add	x10, x10, #4
	mul	x11, x11, x1
	mul	x10, x10, x1
	fadd	v28.2d, v18.2d, v20.2d
	ldp	q24, q26, [x12]
	add	x12, x13, x14, lsl #5
	add	x11, x13, x11, lsl #5
	add	x10, x13, x10, lsl #5
	fsub	v18.2d, v18.2d, v20.2d
	fadd	v27.2d, v19.2d, v21.2d
	fsub	v19.2d, v19.2d, v21.2d
	ldp	q20, q29, [x12]
	fadd	v10.2d, v17.2d, v27.2d
	fadd	v22.2d, v24.2d, v20.2d
	fsub	v25.2d, v24.2d, v20.2d
	ldp	q30, q31, [x11]
	fadd	v23.2d, v26.2d, v29.2d
	fsub	v26.2d, v26.2d, v29.2d
	fadd	v29.2d, v16.2d, v28.2d
	fmul	v12.2d, v25.2d, v3.2d
	fadd	v10.2d, v10.2d, v23.2d
	ldp	q8, q9, [x10]
	fadd	v29.2d, v29.2d, v22.2d
	mul	x10, x9, x1
	fmla	v12.2d, v0.2d, v18.2d
	fmul	v14.2d, v25.2d, v6.2d
	fadd	v20.2d, v30.2d, v8.2d
	add	x10, x8, x10, lsl #5
	fsub	v24.2d, v30.2d, v8.2d
	mov	v30.16b, v16.16b
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	mov	v8.16b, v17.16b
	fmla	v14.2d, v3.2d, v18.2d
	fadd	v21.2d, v31.2d, v9.2d
	fadd	v13.2d, v29.2d, v20.2d
	fmla	v12.2d, v15.2d, v24.2d
	fmla	v30.2d, v11.2d, v28.2d
	add	x11, x9, x11
	fmla	v8.2d, v11.2d, v27.2d
	fmla	v14.2d, v7.2d, v24.2d
	fmul	v11.2d, v26.2d, v3.2d
	fadd	v10.2d, v10.2d, v21.2d
	fmla	v30.2d, v1.2d, v22.2d
	fsub	v29.2d, v31.2d, v9.2d
	fmla	v8.2d, v1.2d, v23.2d
	fmla	v11.2d, v0.2d, v19.2d
	stp	q13, q10, [x10]
	add	x10, x9, x2
	fmla	v30.2d, v2.2d, v20.2d
	fmla	v8.2d, v2.2d, v21.2d
	mul	x10, x10, x1
	fmla	v11.2d, v15.2d, v29.2d
	mov	v31.16b, v16.16b
	fmla	v16.2d, v2.2d, v28.2d
	mov	v9.16b, v17.16b
	add	x10, x8, x10, lsl #5
	fadd	v13.2d, v12.2d, v8.2d
	fmla	v17.2d, v2.2d, v27.2d
	fsub	v10.2d, v30.2d, v11.2d
	fmla	v31.2d, v1.2d, v28.2d
	fmla	v9.2d, v1.2d, v27.2d
	fmul	v15.2d, v26.2d, v6.2d
	stp	q10, q13, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
	fmla	v31.2d, v2.2d, v22.2d
	fmla	v9.2d, v2.2d, v23.2d
	fmla	v15.2d, v3.2d, v19.2d
	add	x10, x8, x10, lsl #5
	fadd	v30.2d, v30.2d, v11.2d
	ldr	q11, [sp, #128]                 // 16-byte Folded Reload
	fsub	v8.2d, v8.2d, v12.2d
	add	x11, x9, x11
	fmul	v26.2d, v26.2d, v7.2d
	fmla	v31.2d, v11.2d, v20.2d
	fmla	v9.2d, v11.2d, v21.2d
	fmla	v15.2d, v7.2d, v29.2d
	fmla	v16.2d, v11.2d, v22.2d
	stp	q30, q8, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #32]                  // 8-byte Folded Reload
	fmla	v26.2d, v5.2d, v19.2d
	fadd	v8.2d, v14.2d, v9.2d
	fmla	v17.2d, v11.2d, v23.2d
	fsub	v30.2d, v31.2d, v15.2d
	add	x10, x8, x10, lsl #5
	add	x11, x9, x11
	fmla	v16.2d, v1.2d, v20.2d
	fmul	v25.2d, v25.2d, v7.2d
	fmla	v26.2d, v3.2d, v29.2d
	mul	x11, x11, x1
	fmla	v17.2d, v1.2d, v21.2d
	fadd	v19.2d, v31.2d, v15.2d
	ldr	q15, [sp, #96]                  // 16-byte Folded Reload
	stp	q30, q8, [x10]
	add	x10, x8, x11, lsl #5
	ldp	x12, x11, [sp, #48]             // 16-byte Folded Reload
	fmla	v25.2d, v15.2d, v18.2d
	fsub	v18.2d, v9.2d, v14.2d
	add	x12, x9, x12
	add	x11, x9, x11
	fmla	v25.2d, v3.2d, v24.2d
	stp	q19, q18, [x10]
	mul	x10, x12, x1
	mul	x11, x11, x1
	fsub	v18.2d, v16.2d, v26.2d
	fadd	v19.2d, v25.2d, v17.2d
	add	x10, x8, x10, lsl #5
	fadd	v16.2d, v16.2d, v26.2d
	add	x11, x8, x11, lsl #5
	fsub	v17.2d, v17.2d, v25.2d
	stp	q18, q19, [x11]
	stp	q16, q17, [x10]
	b.lo	.LBB134_6
// %bb.8:                               //   in Loop: Header=BB134_7 Depth=1
	ldp	x14, x10, [sp, #16]             // 16-byte Folded Reload
	mov	x5, xzr
.LBB134_9:                              //   Parent Loop BB134_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x11, x0, x5
	add	x12, x18, x5
	add	x13, x3, x5
	ldur	d13, [x14, #-8]
	subs	x10, x10, #1
	ldp	q19, q20, [x11, #32]
	add	x11, x6, x5
	ldp	q21, q22, [x12, #32]
	add	x12, x7, x5
	fadd	v18.2d, v19.2d, v21.2d
	fsub	v23.2d, v19.2d, v21.2d
	ldp	q25, q26, [x11, #32]
	add	x11, x19, x5
	fadd	v24.2d, v20.2d, v22.2d
	fsub	v21.2d, v20.2d, v22.2d
	ldp	q19, q27, [x12, #32]
	add	x12, x20, x5
	fadd	v22.2d, v25.2d, v19.2d
	fsub	v29.2d, v25.2d, v19.2d
	ldp	q16, q17, [x13, #32]
	fadd	v28.2d, v26.2d, v27.2d
	add	x13, x29, x5
	fsub	v25.2d, v26.2d, v27.2d
	fmul	v10.2d, v29.2d, v3.2d
	fmul	v14.2d, v29.2d, v6.2d
	fmul	v29.2d, v29.2d, v7.2d
	ldp	q20, q30, [x11, #32]
	fadd	v9.2d, v17.2d, v24.2d
	fmla	v10.2d, v0.2d, v23.2d
	add	x11, x4, x5
	fmla	v14.2d, v3.2d, v23.2d
	fadd	v9.2d, v9.2d, v28.2d
	ldp	q31, q8, [x12, #32]
	add	x12, x14, x28
	fadd	v19.2d, v20.2d, v31.2d
	fsub	v26.2d, v20.2d, v31.2d
	fadd	v27.2d, v30.2d, v8.2d
	fsub	v20.2d, v30.2d, v8.2d
	mov	v8.16b, v17.16b
	mov	v30.16b, v16.16b
	fmla	v10.2d, v15.2d, v26.2d
	fadd	v31.2d, v16.2d, v18.2d
	fmla	v14.2d, v7.2d, v26.2d
	fadd	v9.2d, v9.2d, v27.2d
	fmla	v8.2d, v11.2d, v24.2d
	fmla	v30.2d, v11.2d, v18.2d
	fmul	v11.2d, v25.2d, v3.2d
	fadd	v31.2d, v31.2d, v22.2d
	fmla	v8.2d, v1.2d, v28.2d
	fmla	v30.2d, v1.2d, v22.2d
	fmla	v11.2d, v0.2d, v21.2d
	fadd	v31.2d, v31.2d, v19.2d
	fmla	v8.2d, v2.2d, v27.2d
	fmla	v30.2d, v2.2d, v19.2d
	fmla	v11.2d, v15.2d, v20.2d
	stp	q31, q9, [x11, #32]
	mov	x11, x14
	fadd	v9.2d, v10.2d, v8.2d
	mov	v31.16b, v17.16b
	fsub	v12.2d, v30.2d, v11.2d
	fadd	v11.2d, v30.2d, v11.2d
	fneg	v30.2d, v9.2d
	fmla	v31.2d, v1.2d, v24.2d
	fmul	v9.2d, v9.2d, v13.d[0]
	ld1r	{ v15.2d }, [x11], x22
	fsub	v10.2d, v8.2d, v10.2d
	ldr	q0, [sp, #112]                  // 16-byte Folded Reload
	fmul	v4.2d, v15.2d, v30.2d
	mov	v30.16b, v16.16b
	fmla	v31.2d, v2.2d, v28.2d
	fmul	v8.2d, v25.2d, v0.2d
	fmla	v9.2d, v15.2d, v12.2d
	mov	v0.16b, v3.16b
	mov	v3.16b, v2.16b
	fmla	v4.2d, v12.2d, v13.d[0]
	mov	v2.16b, v1.16b
	fmla	v30.2d, v1.2d, v18.2d
	ldp	d12, d6, [x12, #-8]
	fneg	v5.2d, v10.2d
	fmla	v8.2d, v0.2d, v21.2d
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	add	x12, x14, x26
	stp	q4, q9, [x13, #32]
	fmul	v10.2d, v10.2d, v12.d[0]
	fmla	v31.2d, v1.2d, v27.2d
	fmul	v5.2d, v5.2d, v6.d[0]
	mov	v1.16b, v2.16b
	fmla	v8.2d, v7.2d, v20.2d
	mov	v2.16b, v3.16b
	fmla	v10.2d, v11.2d, v6.d[0]
	fadd	v13.2d, v14.2d, v31.2d
	fmla	v5.2d, v11.2d, v12.d[0]
	ldr	q12, [sp, #128]                 // 16-byte Folded Reload
	fmla	v30.2d, v2.2d, v22.2d
	fmla	v17.2d, v2.2d, v24.2d
	ldp	d15, d6, [x12, #-24]
	add	x12, x30, x5
	fmla	v16.2d, v2.2d, v18.2d
	ldr	q11, [sp, #128]                 // 16-byte Folded Reload
	fmla	v30.2d, v12.2d, v19.2d
	fneg	v12.2d, v13.2d
	fmul	v9.2d, v13.2d, v15.d[0]
	fmla	v17.2d, v11.2d, v28.2d
	stp	q5, q10, [x12, #32]
	add	x12, x14, x25
	fmla	v16.2d, v11.2d, v22.2d
	fsub	v24.2d, v30.2d, v8.2d
	fmul	v4.2d, v12.2d, v6.d[0]
	fsub	v5.2d, v31.2d, v14.2d
	fmla	v17.2d, v1.2d, v27.2d
	fmla	v16.2d, v1.2d, v19.2d
	fmla	v9.2d, v24.2d, v6.d[0]
	fmla	v4.2d, v24.2d, v15.d[0]
	ldr	q15, [sp, #96]                  // 16-byte Folded Reload
	fmul	v6.2d, v25.2d, v7.2d
	fneg	v24.2d, v5.2d
	fmla	v29.2d, v15.2d, v23.2d
	ldp	d18, d23, [x12, #-72]
	add	x12, x27, x5
	fmla	v6.2d, v15.2d, v21.2d
	ldp	d25, d27, [x11, #-8]
	fmla	v29.2d, v0.2d, v26.2d
	add	x11, x23, x5
	stp	q4, q9, [x12, #32]
	add	x12, x14, x24
	fmul	v22.2d, v24.2d, v23.d[0]
	fmla	v6.2d, v0.2d, v20.2d
	fadd	v4.2d, v30.2d, v8.2d
	fmul	v5.2d, v5.2d, v18.d[0]
	fadd	v21.2d, v29.2d, v17.2d
	add	x14, x14, #16
	fsub	v17.2d, v17.2d, v29.2d
	ldp	d24, d20, [x12, #-8]
	fmla	v22.2d, v4.2d, v18.d[0]
	fmla	v5.2d, v4.2d, v23.d[0]
	fneg	v19.2d, v21.2d
	add	x12, x21, x5
	fneg	v26.2d, v17.2d
	fsub	v18.2d, v16.2d, v6.2d
	fmul	v21.2d, v21.2d, v24.d[0]
	stp	q22, q5, [x11, #32]
	fmul	v19.2d, v19.2d, v20.d[0]
	add	x11, x15, x5
	fadd	v6.2d, v16.2d, v6.2d
	fmul	v4.2d, v26.2d, v27.d[0]
	fmul	v16.2d, v17.2d, v25.d[0]
	add	x5, x5, #32
	mov	v3.16b, v0.16b
	fmla	v21.2d, v18.2d, v20.d[0]
	fmla	v19.2d, v18.2d, v24.d[0]
	ldr	q0, [sp, #80]                   // 16-byte Folded Reload
	fmla	v4.2d, v6.2d, v25.d[0]
	fmla	v16.2d, v6.2d, v27.d[0]
	ldr	q6, [sp, #112]                  // 16-byte Folded Reload
	stp	q19, q21, [x12, #32]
	stp	q4, q16, [x11, #32]
	b.ne	.LBB134_9
	b	.LBB134_6
.LBB134_10:
	ldp	x20, x19, [sp, #288]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #272]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #256]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #192]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #176]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #160]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #144]            // 16-byte Folded Reload
	add	sp, sp, #304
	ret
.Lfunc_end134:
	.size	_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end134-_ZNK9pocketfft6detail5cfftpIdE5pass7ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE // -- Begin function _ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE,@function
_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE: // @_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #960
	.cfi_def_cfa_offset 1120
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #184]              // 16-byte Folded Spill
	b.ne	.LBB135_4
// %bb.1:
	cbz	x2, .LBB135_10
// %bb.2:
	mov	x16, #61626
	mov	x0, #4790
	movk	x16, #34660, lsl #16
	movk	x0, #55751, lsl #16
	movk	x16, #60300, lsl #32
	movk	x0, #38440, lsl #32
	movk	x16, #16362, lsl #48
	mov	x1, #17627
	movk	x0, #16346, lsl #48
	movk	x1, #25615, lsl #16
	movk	x1, #14175, lsl #32
	mov	x3, #22663
	dup	v1.2d, x16
	mov	x16, #20567
	movk	x1, #16322, lsl #48
	movk	x3, #32631, lsl #16
	movk	x16, #39885, lsl #16
	movk	x3, #62622, lsl #32
	movk	x16, #46122, lsl #32
	dup	v0.2d, x0
	mov	x0, #11283
	movk	x3, #16356, lsl #48
	movk	x16, #16366, lsl #48
	movk	x0, #36590, lsl #16
	str	q0, [sp, #896]                  // 16-byte Folded Spill
	movk	x0, #7092, lsl #32
	dup	v0.2d, x1
	movk	x0, #16365, lsl #48
	mov	x1, #10401
	mov	x4, #36287
	stp	q0, q1, [sp, #432]              // 32-byte Folded Spill
	dup	v1.2d, x3
	dup	v0.2d, x16
	movk	x1, #47930, lsl #16
	mov	x16, #22539
	movk	x1, #12057, lsl #32
	stp	q0, q1, [sp, #400]              // 32-byte Folded Spill
	dup	v0.2d, x0
	mov	x0, #17135
	movk	x16, #63675, lsl #16
	movk	x0, #1080, lsl #16
	movk	x1, #16360, lsl #48
	movk	x0, #44190, lsl #32
	movk	x4, #64886, lsl #16
	movk	x0, #16367, lsl #48
	movk	x16, #19693, lsl #32
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	movk	x4, #2023, lsl #32
	mov	x3, #36287
	movk	x16, #16353, lsl #48
	dup	v0.2d, x0
	movk	x4, #16338, lsl #48
	movk	x3, #64886, lsl #16
	mov	x0, #17135
	movk	x3, #2023, lsl #32
	str	q0, [sp, #912]                  // 16-byte Folded Spill
	dup	v0.2d, x1
	movk	x3, #49106, lsl #48
	movk	x0, #1080, lsl #16
	dup	v1.2d, x16
	str	q0, [sp, #384]                  // 16-byte Folded Spill
	dup	v0.2d, x4
	movk	x0, #44190, lsl #32
	mov	x1, #22539
	movk	x0, #49135, lsl #48
	movk	x1, #63675, lsl #16
	ldp	x9, x14, [sp, #184]             // 16-byte Folded Reload
	stp	q0, q1, [sp, #592]              // 32-byte Folded Spill
	dup	v1.2d, x3
	movk	x1, #19693, lsl #32
	mov	x3, #11283
	movk	x1, #49121, lsl #48
	movk	x3, #36590, lsl #16
	mov	w11, #224
	movk	x3, #7092, lsl #32
	dup	v0.2d, x0
	movk	x3, #49133, lsl #48
	ldp	q8, q30, [sp, #432]             // 32-byte Folded Reload
	add	x15, x2, x2, lsl #1
	add	x18, x2, x2, lsl #2
	mul	x11, x2, x11
	add	x17, x2, x2, lsl #3
	stp	q0, q1, [sp, #464]              // 32-byte Folded Spill
	dup	v0.2d, x1
	lsl	x8, x15, #6
	add	x9, x9, #16
	lsl	x10, x18, #5
	lsl	x12, x2, #7
	lsl	x13, x2, #8
	add	x14, x14, #176
	lsl	x15, x15, #5
	lsl	x16, x17, #5
	lsl	x17, x2, #6
	lsl	x18, x18, #6
	lsl	x0, x2, #5
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	dup	v0.2d, x3
	str	q0, [sp, #368]                  // 16-byte Folded Spill
.LBB135_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x14, #-144]
	add	x1, x9, x0
	add	x3, x9, x17
	subs	x2, x2, #1
	ldp	q18, q19, [x14, #144]
	fadd	v3.2d, v5.2d, v18.2d
	fsub	v28.2d, v5.2d, v18.2d
	ldp	q25, q20, [x14, #112]
	fadd	v10.2d, v6.2d, v19.2d
	fsub	v1.2d, v6.2d, v19.2d
	stp	q3, q10, [sp, #704]             // 32-byte Folded Spill
	fmul	v14.2d, v3.2d, v30.2d
	ldp	q26, q5, [x14, #-112]
	fadd	v29.2d, v26.2d, v25.2d
	fsub	v25.2d, v26.2d, v25.2d
	ldp	q18, q6, [x14, #80]
	fadd	v11.2d, v5.2d, v20.2d
	fsub	v22.2d, v5.2d, v20.2d
	stp	q29, q28, [sp, #624]            // 32-byte Folded Spill
	str	q25, [sp, #736]                 // 16-byte Folded Spill
	stp	q1, q11, [sp, #672]             // 32-byte Folded Spill
	ldp	q19, q26, [x14, #-80]
	fadd	v2.2d, v19.2d, v18.2d
	fsub	v16.2d, v19.2d, v18.2d
	ldp	q20, q5, [x14, #48]
	fadd	v23.2d, v26.2d, v6.2d
	fsub	v6.2d, v26.2d, v6.2d
	str	q2, [sp, #656]                  // 16-byte Folded Spill
	stp	q16, q22, [sp, #928]            // 32-byte Folded Spill
	ldp	q12, q13, [x14, #-48]
	fadd	v19.2d, v12.2d, v20.2d
	fsub	v17.2d, v12.2d, v20.2d
	ldp	q3, q0, [x14, #-176]
	fmul	v20.2d, v10.2d, v30.2d
	fadd	v16.2d, v13.2d, v5.2d
	stp	q19, q23, [sp, #816]            // 32-byte Folded Spill
	fsub	v12.2d, v13.2d, v5.2d
	fadd	v14.2d, v3.2d, v14.2d
	mov	v5.16b, v2.16b
	ldr	q9, [sp, #896]                  // 16-byte Folded Reload
	stp	q0, q3, [sp, #864]              // 32-byte Folded Spill
	ldr	q24, [sp, #496]                 // 16-byte Folded Reload
	stp	q17, q16, [sp, #784]            // 32-byte Folded Spill
	fadd	v3.2d, v0.2d, v20.2d
	ldr	q18, [sp, #608]                 // 16-byte Folded Reload
	fmul	v15.2d, v29.2d, v9.2d
	ldp	q20, q31, [x14, #16]
	fmul	v0.2d, v22.2d, v24.2d
	ldr	q26, [sp, #416]                 // 16-byte Folded Reload
	fmul	v21.2d, v11.2d, v9.2d
	fmul	v27.2d, v25.2d, v24.2d
	str	q12, [sp, #848]                 // 16-byte Folded Spill
	ldp	q7, q17, [x14, #-16]
	fadd	v15.2d, v14.2d, v15.2d
	fmla	v0.2d, v18.2d, v1.2d
	fmul	v22.2d, v2.2d, v8.2d
	add	x14, x14, #352
	fadd	v21.2d, v3.2d, v21.2d
	fmla	v27.2d, v18.2d, v28.2d
	fadd	v4.2d, v7.2d, v20.2d
	fmul	v2.2d, v23.2d, v8.2d
	ldr	q3, [sp, #912]                  // 16-byte Folded Reload
	ldp	q25, q18, [sp, #384]            // 32-byte Folded Reload
	fsub	v15.2d, v15.2d, v22.2d
	stp	q4, q6, [sp, #752]              // 32-byte Folded Spill
	fmul	v23.2d, v19.2d, v26.2d
	fmla	v0.2d, v3.2d, v6.2d
	fsub	v14.2d, v17.2d, v31.2d
	mov	v22.16b, v6.16b
	fsub	v6.2d, v21.2d, v2.2d
	fmul	v21.2d, v16.2d, v26.2d
	fmla	v0.2d, v25.2d, v12.2d
	fsub	v23.2d, v15.2d, v23.2d
	ldr	q12, [sp, #704]                 // 16-byte Folded Reload
	mov	v16.16b, v28.16b
	fmul	v28.2d, v4.2d, v18.2d
	fsub	v19.2d, v7.2d, v20.2d
	ldr	q7, [sp, #592]                  // 16-byte Folded Reload
	ldr	q20, [sp, #928]                 // 16-byte Folded Reload
	fadd	v2.2d, v17.2d, v31.2d
	ldr	q31, [sp, #880]                 // 16-byte Folded Reload
	fsub	v15.2d, v23.2d, v28.2d
	fmla	v0.2d, v7.2d, v14.2d
	fmul	v28.2d, v12.2d, v9.2d
	fmla	v27.2d, v3.2d, v20.2d
	fmul	v17.2d, v10.2d, v9.2d
	stp	q14, q19, [sp, #544]            // 32-byte Folded Spill
	mov	v13.16b, v1.16b
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	fsub	v23.2d, v15.2d, v0.2d
	fadd	v31.2d, v31.2d, v28.2d
	ldr	q28, [sp, #864]                 // 16-byte Folded Reload
	fsub	v6.2d, v6.2d, v21.2d
	fmla	v27.2d, v25.2d, v1.2d
	fmul	v21.2d, v2.2d, v18.2d
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #736]                  // 16-byte Folded Reload
	fadd	v17.2d, v28.2d, v17.2d
	stur	q23, [x1, #-16]
	fmul	v28.2d, v29.2d, v26.2d
	fmla	v27.2d, v7.2d, v19.2d
	fmul	v23.2d, v2.2d, v25.2d
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fmul	v29.2d, v11.2d, v26.2d
	str	q9, [sp, #528]                  // 16-byte Folded Spill
	fsub	v3.2d, v6.2d, v21.2d
	fsub	v7.2d, v31.2d, v28.2d
	fmul	v28.2d, v2.2d, v25.2d
	fmla	v23.2d, v24.2d, v16.2d
	ldp	q31, q4, [sp, #816]             // 32-byte Folded Reload
	fsub	v17.2d, v17.2d, v29.2d
	fmul	v21.2d, v5.2d, v18.2d
	fmla	v28.2d, v24.2d, v13.2d
	fadd	v0.2d, v15.2d, v0.2d
	fsub	v5.2d, v3.2d, v27.2d
	ldp	q10, q24, [sp, #464]            // 32-byte Folded Reload
	fmul	v29.2d, v4.2d, v18.2d
	fsub	v7.2d, v7.2d, v21.2d
	fmul	v21.2d, v31.2d, v8.2d
	mov	v11.16b, v19.16b
	fsub	v17.2d, v17.2d, v29.2d
	ldr	q13, [sp, #800]                 // 16-byte Folded Reload
	fmla	v23.2d, v24.2d, v20.2d
	fmla	v28.2d, v24.2d, v22.2d
	ldr	q2, [sp, #752]                  // 16-byte Folded Reload
	fsub	v7.2d, v7.2d, v21.2d
	fmul	v29.2d, v13.2d, v8.2d
	fmla	v23.2d, v10.2d, v1.2d
	ldr	q1, [sp, #848]                  // 16-byte Folded Reload
	fmul	v20.2d, v9.2d, v30.2d
	fadd	v21.2d, v27.2d, v3.2d
	ldr	q27, [sp, #624]                 // 16-byte Folded Reload
	fsub	v17.2d, v17.2d, v29.2d
	fmla	v28.2d, v10.2d, v1.2d
	fmul	v29.2d, v2.2d, v30.2d
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	ldp	q16, q11, [sp, #864]            // 32-byte Folded Reload
	str	q21, [x1]
	add	x1, x9, x18
	fmla	v28.2d, v1.2d, v14.2d
	fmla	v23.2d, v1.2d, v19.2d
	fadd	v6.2d, v7.2d, v29.2d
	fadd	v7.2d, v17.2d, v20.2d
	stp	q0, q5, [x1, #-16]
	fmul	v5.2d, v12.2d, v8.2d
	add	x1, x9, x16
	ldp	q19, q29, [sp, #720]            // 32-byte Folded Reload
	fsub	v0.2d, v6.2d, v28.2d
	ldr	q1, [sp, #896]                  // 16-byte Folded Reload
	fadd	v17.2d, v23.2d, v7.2d
	fsub	v5.2d, v11.2d, v5.2d
	ldr	q20, [sp, #368]                 // 16-byte Folded Reload
	mov	v3.16b, v12.16b
	ldr	q12, [sp, #688]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v28.2d
	ldr	q28, [sp, #656]                 // 16-byte Folded Reload
	stp	q0, q17, [x3, #-16]
	fmul	v0.2d, v19.2d, v8.2d
	fmul	v17.2d, v27.2d, v18.2d
	fmul	v21.2d, v12.2d, v18.2d
	fsub	v7.2d, v7.2d, v23.2d
	fsub	v0.2d, v16.2d, v0.2d
	fsub	v5.2d, v5.2d, v17.2d
	fmul	v17.2d, v28.2d, v1.2d
	stp	q6, q7, [x1, #-16]
	add	x1, x9, x15
	fsub	v0.2d, v0.2d, v21.2d
	fmul	v6.2d, v4.2d, v1.2d
	fadd	v5.2d, v5.2d, v17.2d
	fmul	v17.2d, v31.2d, v30.2d
	ldr	q31, [sp, #672]                 // 16-byte Folded Reload
	mov	v22.16b, v4.16b
	ldr	q4, [sp, #944]                  // 16-byte Folded Reload
	fadd	v1.2d, v0.2d, v6.2d
	ldr	q0, [sp, #912]                  // 16-byte Folded Reload
	fmul	v6.2d, v29.2d, v24.2d
	fadd	v5.2d, v5.2d, v17.2d
	fmul	v17.2d, v4.2d, v24.2d
	ldr	q24, [sp, #640]                 // 16-byte Folded Reload
	fmul	v21.2d, v2.2d, v26.2d
	fmul	v7.2d, v13.2d, v30.2d
	fmla	v6.2d, v0.2d, v24.2d
	fmla	v17.2d, v0.2d, v31.2d
	fsub	v0.2d, v5.2d, v21.2d
	ldr	q5, [sp, #848]                  // 16-byte Folded Reload
	fmul	v21.2d, v3.2d, v26.2d
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fadd	v1.2d, v1.2d, v7.2d
	fmul	v7.2d, v9.2d, v26.2d
	fmul	v23.2d, v27.2d, v8.2d
	str	q0, [sp, #512]                  // 16-byte Folded Spill
	fsub	v21.2d, v11.2d, v21.2d
	ldr	q0, [sp, #768]                  // 16-byte Folded Reload
	fmla	v6.2d, v20.2d, v3.2d
	fsub	v9.2d, v1.2d, v7.2d
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	fmla	v17.2d, v20.2d, v0.2d
	fmul	v7.2d, v19.2d, v26.2d
	ldr	q19, [sp, #784]                 // 16-byte Folded Reload
	fsub	v21.2d, v21.2d, v23.2d
	fmul	v23.2d, v28.2d, v30.2d
	mov	v15.16b, v2.16b
	fmla	v6.2d, v1.2d, v19.2d
	ldp	q2, q13, [sp, #544]             // 32-byte Folded Reload
	fmla	v17.2d, v1.2d, v5.2d
	fsub	v7.2d, v16.2d, v7.2d
	fmul	v27.2d, v12.2d, v8.2d
	fadd	v21.2d, v21.2d, v23.2d
	fmul	v23.2d, v4.2d, v10.2d
	fmla	v17.2d, v25.2d, v2.2d
	fmul	v28.2d, v29.2d, v10.2d
	fmla	v6.2d, v25.2d, v13.2d
	ldp	q10, q4, [sp, #800]             // 32-byte Folded Reload
	mov	v14.16b, v1.16b
	fsub	v7.2d, v7.2d, v27.2d
	fmla	v23.2d, v25.2d, v31.2d
	fmul	v27.2d, v22.2d, v30.2d
	fmla	v28.2d, v25.2d, v24.2d
	mov	v12.16b, v29.16b
	fmul	v24.2d, v10.2d, v18.2d
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	fmla	v23.2d, v14.2d, v0.2d
	fadd	v7.2d, v7.2d, v27.2d
	fmla	v28.2d, v14.2d, v3.2d
	fadd	v27.2d, v6.2d, v9.2d
	ldr	q22, [sp, #896]                 // 16-byte Folded Reload
	fsub	v29.2d, v1.2d, v17.2d
	ldr	q0, [sp, #592]                  // 16-byte Folded Reload
	fmul	v31.2d, v4.2d, v18.2d
	ldr	q14, [sp, #528]                 // 16-byte Folded Reload
	fsub	v7.2d, v7.2d, v24.2d
	ldr	q3, [sp, #656]                  // 16-byte Folded Reload
	fmul	v24.2d, v15.2d, v22.2d
	fmla	v23.2d, v0.2d, v5.2d
	stp	q29, q27, [x1, #-16]
	fmla	v28.2d, v0.2d, v19.2d
	fsub	v21.2d, v21.2d, v31.2d
	add	x1, x9, x13
	fmul	v27.2d, v14.2d, v22.2d
	mov	v31.16b, v5.16b
	fmla	v23.2d, v20.2d, v2.2d
	mov	v15.16b, v0.16b
	fmla	v28.2d, v20.2d, v13.2d
	fadd	v5.2d, v1.2d, v17.2d
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	fsub	v0.2d, v9.2d, v6.2d
	fadd	v6.2d, v21.2d, v24.2d
	ldr	q21, [sp, #704]                 // 16-byte Folded Reload
	fadd	v7.2d, v7.2d, v27.2d
	ldr	q24, [sp, #624]                 // 16-byte Folded Reload
	mov	v29.16b, v19.16b
	stp	q5, q0, [x1, #-16]
	add	x1, x9, x12
	fsub	v0.2d, v6.2d, v23.2d
	fadd	v5.2d, v28.2d, v7.2d
	fadd	v17.2d, v11.2d, v21.2d
	fmul	v21.2d, v21.2d, v18.2d
	fmul	v19.2d, v24.2d, v30.2d
	stp	q0, q5, [x1, #-16]
	add	x1, x9, x11
	fadd	v0.2d, v17.2d, v24.2d
	fsub	v5.2d, v11.2d, v21.2d
	ldr	q21, [sp, #720]                 // 16-byte Folded Reload
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v23.2d
	fmul	v17.2d, v21.2d, v18.2d
	fadd	v21.2d, v16.2d, v21.2d
	fadd	v5.2d, v5.2d, v19.2d
	fmul	v19.2d, v12.2d, v1.2d
	fsub	v17.2d, v16.2d, v17.2d
	ldr	q16, [sp, #688]                 // 16-byte Folded Reload
	fmul	v23.2d, v2.2d, v1.2d
	ldr	q1, [sp, #640]                  // 16-byte Folded Reload
	fadd	v0.2d, v0.2d, v3.2d
	fmul	v18.2d, v16.2d, v30.2d
	fmla	v19.2d, v15.2d, v1.2d
	ldr	q1, [sp, #672]                  // 16-byte Folded Reload
	fsub	v7.2d, v7.2d, v28.2d
	fadd	v21.2d, v21.2d, v16.2d
	fadd	v17.2d, v17.2d, v18.2d
	fmla	v23.2d, v15.2d, v1.2d
	fmul	v18.2d, v3.2d, v26.2d
	ldr	q3, [sp, #832]                  // 16-byte Folded Reload
	ldp	q16, q1, [sp, #912]             // 32-byte Folded Reload
	stp	q6, q7, [x1, #-16]
	fadd	v0.2d, v0.2d, v4.2d
	add	x1, x9, x10
	fmul	v24.2d, v3.2d, v26.2d
	fmla	v19.2d, v25.2d, v1.2d
	ldr	q1, [sp, #768]                  // 16-byte Folded Reload
	fsub	v5.2d, v5.2d, v18.2d
	fmul	v18.2d, v10.2d, v22.2d
	fsub	v6.2d, v17.2d, v24.2d
	fmla	v23.2d, v25.2d, v1.2d
	fmul	v17.2d, v4.2d, v22.2d
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	fmla	v19.2d, v20.2d, v29.2d
	mov	v2.16b, v4.16b
	fmul	v7.2d, v1.2d, v8.2d
	fmla	v23.2d, v20.2d, v31.2d
	fadd	v5.2d, v5.2d, v17.2d
	fadd	v6.2d, v6.2d, v18.2d
	fmla	v19.2d, v16.2d, v13.2d
	fmul	v17.2d, v14.2d, v8.2d
	fmla	v23.2d, v16.2d, v9.2d
	fsub	v5.2d, v5.2d, v7.2d
	fadd	v7.2d, v21.2d, v3.2d
	fsub	v6.2d, v6.2d, v17.2d
	fadd	v3.2d, v0.2d, v1.2d
	fsub	v17.2d, v5.2d, v23.2d
	fadd	v7.2d, v7.2d, v10.2d
	fadd	v18.2d, v19.2d, v6.2d
	fadd	v5.2d, v5.2d, v23.2d
	fsub	v6.2d, v6.2d, v19.2d
	fadd	v0.2d, v7.2d, v14.2d
	stp	q17, q18, [x1, #-16]
	add	x1, x9, x8
	mov	v16.16b, v14.16b
	stp	q3, q0, [x9, #-16]
	add	x9, x9, #32
	stp	q5, q6, [x1, #-16]
	b.ne	.LBB135_3
	b	.LBB135_10
.LBB135_4:
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	cbz	x2, .LBB135_10
// %bb.5:
	lsl	x8, x2, #2
	mov	w12, #352
	ldp	x6, x7, [sp, #184]              // 16-byte Folded Reload
	mul	x9, x1, x12
	mov	w12, #320
	str	x8, [sp, #168]                  // 8-byte Folded Spill
	add	x8, x8, x2
	mul	x11, x2, x1
	mov	w10, #288
	mov	w3, #80
	lsl	x28, x2, #3
	str	x8, [sp, #152]                  // 8-byte Folded Spill
	lsl	x8, x8, #1
	str	x9, [sp, #128]                  // 8-byte Folded Spill
	ldr	x9, [sp, #24]                   // 8-byte Folded Reload
	madd	x16, x1, x12, x7
	lsl	x15, x2, #1
	str	x8, [sp, #144]                  // 8-byte Folded Spill
	mov	w8, #192
	add	x13, x7, x9, lsl #6
	madd	x14, x9, x10, x7
	madd	x18, x11, x8, x6
	add	x0, x13, #64
	add	x13, x1, x1, lsl #1
	madd	x8, x9, x8, x7
	lsl	x22, x13, #5
	add	x13, x7, x9, lsl #8
	add	x19, x13, #256
	mov	w13, #224
	stp	x16, x18, [sp, #208]            // 16-byte Folded Spill
	add	x18, x14, #288
	add	x14, x7, x9, lsl #7
	add	x23, x8, #192
	add	x20, x14, #128
	madd	x14, x9, x13, x7
	mov	w8, #48
	madd	x13, x11, x13, x6
	add	x21, x14, #224
	mul	x14, x1, x3
	mul	x8, x1, x8
	mov	w16, #160
	sub	x14, x14, #80
	mov	x3, #11283
	sub	x8, x8, #48
	madd	x4, x9, x16, x7
	madd	x25, x11, x16, x6
	add	x16, x5, #8
	stp	x8, x14, [sp, #232]             // 16-byte Folded Spill
	mov	w14, #112
	mov	x9, x22
	mul	x8, x1, x14
	str	x13, [sp, #200]                 // 8-byte Folded Spill
	mov	x13, #61626
	str	x16, [sp, #16]                  // 8-byte Folded Spill
	sub	x8, x8, #112
	movk	x13, #34660, lsl #16
	movk	x13, #60300, lsl #32
	mov	x16, #17627
	movk	x13, #16362, lsl #48
	movk	x16, #25615, lsl #16
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	mov	x8, #4790
	movk	x8, #55751, lsl #16
	movk	x16, #14175, lsl #32
	movk	x8, #38440, lsl #32
	movk	x16, #16322, lsl #48
	movk	x8, #16346, lsl #48
	dup	v5.2d, x13
	mov	x13, #22663
	mov	w14, #96
	movk	x13, #32631, lsl #16
	dup	v0.2d, x16
	dup	v13.2d, x8
	mov	x8, #20567
	movk	x8, #39885, lsl #16
	movk	x13, #62622, lsl #32
	movk	x8, #46122, lsl #32
	mov	x16, #11283
	movk	x13, #16356, lsl #48
	movk	x8, #16366, lsl #48
	movk	x16, #36590, lsl #16
	str	q0, [sp, #880]                  // 16-byte Folded Spill
	movk	x16, #7092, lsl #32
	madd	x24, x11, x14, x6
	movk	x16, #16365, lsl #48
	dup	v1.2d, x13
	dup	v0.2d, x8
	mov	x8, #17135
	movk	x8, #1080, lsl #16
	mov	x13, #22539
	stp	q1, q0, [sp, #928]              // 32-byte Folded Spill
	movk	x8, #44190, lsl #32
	dup	v0.2d, x16
	mov	x16, #10401
	movk	x8, #16367, lsl #48
	movk	x16, #47930, lsl #16
	movk	x16, #12057, lsl #32
	movk	x13, #63675, lsl #16
	movk	x16, #16360, lsl #48
	movk	x13, #19693, lsl #32
	str	q0, [sp, #576]                  // 16-byte Folded Spill
	dup	v0.2d, x8
	mov	x8, #36287
	movk	x13, #16353, lsl #48
	movk	x8, #64886, lsl #16
	str	q0, [sp, #864]                  // 16-byte Folded Spill
	movk	x8, #2023, lsl #32
	dup	v0.2d, x16
	mov	w16, #144
	movk	x8, #49106, lsl #48
	dup	v1.2d, x13
	mov	x13, #36287
	mul	x16, x1, x16
	movk	x13, #64886, lsl #16
	stp	q1, q0, [sp, #896]              // 32-byte Folded Spill
	dup	v1.2d, x8
	sub	x8, x16, #144
	movk	x13, #2023, lsl #32
	sub	x14, x28, x2
	movk	x13, #16338, lsl #48
	str	x9, [sp, #248]                  // 8-byte Folded Spill
	movk	x3, #36590, lsl #16
	str	x8, [sp, #104]                  // 8-byte Folded Spill
	madd	x8, x11, x12, x6
	add	x12, x28, x2
	dup	v0.2d, x13
	mov	x13, #17135
	str	x15, [sp, #160]                 // 8-byte Folded Spill
	movk	x13, #1080, lsl #16
	madd	x27, x11, x10, x6
	str	x12, [sp, #96]                  // 8-byte Folded Spill
	add	x12, x15, x2
	movk	x13, #44190, lsl #32
	lsl	x15, x1, #5
	movk	x13, #49135, lsl #48
	sub	x10, x15, #32
	stp	x14, x12, [sp, #80]             // 16-byte Folded Spill
	lsl	x12, x12, #1
	add	x14, x9, x7
	lsl	x9, x1, #6
	movk	x3, #7092, lsl #32
	str	q0, [sp, #592]                  // 16-byte Folded Spill
	movk	x3, #49133, lsl #48
	dup	v0.2d, x13
	stp	x9, x12, [sp, #56]              // 16-byte Folded Spill
	mov	x12, #22539
	movk	x12, #63675, lsl #16
	lsl	x9, x1, #7
	movk	x12, #19693, lsl #32
	mov	x26, xzr
	movk	x12, #49121, lsl #48
	add	x4, x4, #160
	add	x5, x6, x11, lsl #7
	add	x30, x6, x11, lsl #8
	add	x13, x6, x11, lsl #5
	add	x22, x6, x11, lsl #6
	add	x16, x7, x15
	stp	x9, x10, [sp, #40]              // 16-byte Folded Spill
	lsl	x9, x1, #4
	ldr	x29, [sp, #104]                 // 8-byte Folded Reload
	stp	q0, q1, [sp, #288]              // 32-byte Folded Spill
	dup	v1.2d, x12
	dup	v0.2d, x3
	str	x28, [sp, #136]                 // 8-byte Folded Spill
	str	x15, [sp, #72]                  // 8-byte Folded Spill
	str	x9, [sp, #32]                   // 8-byte Folded Spill
	stp	q0, q1, [sp, #256]              // 32-byte Folded Spill
	str	x2, [sp, #176]                  // 8-byte Folded Spill
	str	x1, [sp, #120]                  // 8-byte Folded Spill
	str	q13, [sp, #832]                 // 16-byte Folded Spill
	b	.LBB135_7
.LBB135_6:                              //   in Loop: Header=BB135_7 Depth=1
	ldr	x2, [sp, #72]                   // 8-byte Folded Reload
	ldp	x3, x17, [sp, #328]             // 16-byte Folded Reload
	mov	v5.16b, v15.16b
	add	x9, x9, x2
	ldr	x12, [sp, #224]                 // 8-byte Folded Reload
	add	x1, x1, x2
	add	x25, x25, x2
	add	x30, x30, x2
	add	x24, x8, x2
	str	x9, [sp, #216]                  // 8-byte Folded Spill
	ldr	x9, [sp, #128]                  // 8-byte Folded Reload
	add	x12, x12, #1
	add	x5, x17, x2
	add	x13, x13, x2
	add	x8, x10, x2
	add	x18, x18, x9
	add	x7, x7, x9
	add	x16, x16, x9
	add	x0, x0, x9
	add	x6, x6, x9
	add	x19, x19, x9
	stp	x1, x18, [sp, #200]             // 16-byte Folded Spill
	add	x18, x15, x9
	add	x20, x20, x9
	add	x21, x21, x9
	add	x4, x3, x9
	add	x23, x23, x9
	ldr	x9, [sp, #344]                  // 8-byte Folded Reload
	add	x22, x14, x2
	add	x27, x11, x2
	mov	x26, x12
	ldr	x1, [sp, #120]                  // 8-byte Folded Reload
	add	x9, x9, x2
	ldr	x2, [sp, #176]                  // 8-byte Folded Reload
	mov	x14, x6
	mov	x6, x9
	cmp	x12, x2
	b.eq	.LBB135_10
.LBB135_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB135_9 Depth 2
	mov	w9, #11
	stp	x4, x5, [sp, #328]              // 16-byte Folded Spill
	mov	x4, x2
	mul	x12, x26, x9
	str	x26, [sp, #224]                 // 8-byte Folded Spill
	str	x6, [sp, #344]                  // 8-byte Folded Spill
	mov	x10, x8
	add	x9, x12, #10
	add	x28, x12, #9
	mul	x3, x12, x1
	add	x26, x12, #2
	mul	x2, x9, x1
	ldp	x9, x15, [sp, #184]             // 16-byte Folded Reload
	mul	x28, x28, x1
	mov	x11, x27
	add	x5, x15, x3, lsl #5
	add	x3, x1, x3
	add	x2, x15, x2, lsl #5
	mul	x26, x26, x1
	add	x3, x15, x3, lsl #5
	mov	x6, x14
	ldp	q12, q19, [x5]
	add	x5, x12, #3
	mov	x14, x22
	mov	x8, x24
	cmp	x1, #2
	mul	x5, x5, x1
	ldp	q2, q3, [x2]
	add	x2, x15, x28, lsl #5
	str	q19, [sp, #608]                 // 16-byte Folded Spill
	mov	v14.16b, v19.16b
	ldp	q0, q1, [x3]
	add	x3, x15, x26, lsl #5
	fadd	v13.2d, v0.2d, v2.2d
	fsub	v18.2d, v0.2d, v2.2d
	ldp	q7, q16, [x2]
	add	x2, x12, #8
	fadd	v26.2d, v1.2d, v3.2d
	stp	q12, q13, [sp, #656]            // 32-byte Folded Spill
	mul	x2, x2, x1
	fsub	v23.2d, v1.2d, v3.2d
	ldp	q4, q6, [x3]
	add	x3, x15, x5, lsl #5
	add	x2, x15, x2, lsl #5
	fadd	v28.2d, v4.2d, v7.2d
	fsub	v22.2d, v4.2d, v7.2d
	ldp	q17, q21, [x3]
	add	x3, x12, #4
	fadd	v4.2d, v12.2d, v13.2d
	mul	x3, x3, x1
	str	q22, [sp, #688]                 // 16-byte Folded Spill
	fadd	v8.2d, v6.2d, v16.2d
	fsub	v20.2d, v6.2d, v16.2d
	ldp	q0, q1, [x2]
	add	x2, x12, #7
	add	x3, x15, x3, lsl #5
	fadd	v4.2d, v4.2d, v28.2d
	mul	x2, x2, x1
	str	q20, [sp, #560]                 // 16-byte Folded Spill
	fadd	v25.2d, v17.2d, v0.2d
	fsub	v9.2d, v17.2d, v0.2d
	ldp	q2, q3, [x3]
	add	x3, x12, #5
	add	x12, x12, #6
	add	x2, x15, x2, lsl #5
	mul	x3, x3, x1
	mul	x12, x12, x1
	fadd	v11.2d, v21.2d, v1.2d
	fsub	v15.2d, v21.2d, v1.2d
	add	x3, x15, x3, lsl #5
	ldp	q0, q1, [x2]
	add	x12, x15, x12, lsl #5
	mov	v17.16b, v25.16b
	str	q15, [sp, #720]                 // 16-byte Folded Spill
	fadd	v30.2d, v2.2d, v0.2d
	fsub	v24.2d, v2.2d, v0.2d
	ldp	q6, q7, [x3]
	fadd	v2.2d, v4.2d, v25.2d
	fadd	v31.2d, v3.2d, v1.2d
	stp	q30, q18, [sp, #752]            // 32-byte Folded Spill
	fsub	v25.2d, v3.2d, v1.2d
	str	q24, [sp, #816]                 // 16-byte Folded Spill
	fadd	v4.2d, v19.2d, v26.2d
	fadd	v1.2d, v2.2d, v30.2d
	ldp	q16, q0, [x12]
	fmul	v2.2d, v13.2d, v5.2d
	str	q25, [sp, #848]                 // 16-byte Folded Spill
	mov	v10.16b, v17.16b
	fadd	v4.2d, v4.2d, v8.2d
	fadd	v3.2d, v6.2d, v16.2d
	fadd	v2.2d, v12.2d, v2.2d
	fsub	v21.2d, v6.2d, v16.2d
	ldr	q6, [sp, #832]                  // 16-byte Folded Reload
	fadd	v29.2d, v7.2d, v0.2d
	ldr	x15, [sp, #224]                 // 8-byte Folded Reload
	fadd	v1.2d, v1.2d, v3.2d
	ldr	x3, [sp, #64]                   // 8-byte Folded Reload
	mov	v27.16b, v3.16b
	ldr	q3, [sp, #832]                  // 16-byte Folded Reload
	fmul	v6.2d, v8.2d, v6.2d
	mul	x12, x15, x1
	fsub	v0.2d, v7.2d, v0.2d
	add	x2, x15, x4
	fmul	v3.2d, v28.2d, v3.2d
	stp	q31, q1, [sp, #624]             // 32-byte Folded Spill
	fmul	v1.2d, v26.2d, v5.2d
	add	x12, x9, x12, lsl #5
	fadd	v4.2d, v4.2d, v11.2d
	mul	x2, x2, x1
	str	q0, [sp, #704]                  // 16-byte Folded Spill
	add	x3, x15, x3
	fadd	v2.2d, v2.2d, v3.2d
	ldr	q3, [sp, #880]                  // 16-byte Folded Reload
	fadd	v1.2d, v19.2d, v1.2d
	ldr	q19, [sp, #576]                 // 16-byte Folded Reload
	fadd	v4.2d, v4.2d, v31.2d
	add	x2, x9, x2, lsl #5
	fmul	v3.2d, v17.2d, v3.2d
	str	q21, [sp, #736]                 // 16-byte Folded Spill
	fmul	v16.2d, v22.2d, v19.2d
	stp	q27, q9, [sp, #784]             // 32-byte Folded Spill
	fadd	v1.2d, v1.2d, v6.2d
	ldr	x17, [sp, #112]                 // 8-byte Folded Reload
	ldp	q6, q17, [sp, #880]             // 32-byte Folded Reload
	fsub	v2.2d, v2.2d, v3.2d
	fmul	v7.2d, v20.2d, v19.2d
	fmul	v6.2d, v11.2d, v6.2d
	ldr	q3, [sp, #896]                  // 16-byte Folded Reload
	fmla	v7.2d, v17.2d, v23.2d
	ldr	q17, [sp, #864]                 // 16-byte Folded Reload
	fsub	v1.2d, v1.2d, v6.2d
	ldr	q6, [sp, #928]                  // 16-byte Folded Reload
	fmla	v16.2d, v3.2d, v18.2d
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fmla	v7.2d, v17.2d, v15.2d
	ldr	q17, [sp, #864]                 // 16-byte Folded Reload
	fmul	v6.2d, v31.2d, v6.2d
	fmul	v3.2d, v30.2d, v3.2d
	fmla	v16.2d, v17.2d, v9.2d
	ldr	q17, [sp, #912]                 // 16-byte Folded Reload
	ldp	x27, x22, [sp, #48]             // 16-byte Folded Reload
	fsub	v1.2d, v1.2d, v6.2d
	fsub	v2.2d, v2.2d, v3.2d
	ldr	q3, [sp, #944]                  // 16-byte Folded Reload
	ldr	q6, [sp, #912]                  // 16-byte Folded Reload
	fmla	v16.2d, v17.2d, v24.2d
	ldr	q17, [sp, #304]                 // 16-byte Folded Reload
	fmul	v3.2d, v27.2d, v3.2d
	fmla	v7.2d, v6.2d, v25.2d
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	mov	v25.16b, v29.16b
	ldp	x4, x24, [sp, #32]              // 16-byte Folded Reload
	fsub	v2.2d, v2.2d, v3.2d
	ldr	q3, [sp, #592]                  // 16-byte Folded Reload
	fmul	v6.2d, v29.2d, v6.2d
	fmla	v7.2d, v3.2d, v0.2d
	ldr	q3, [sp, #592]                  // 16-byte Folded Reload
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	fsub	v1.2d, v1.2d, v6.2d
	fmla	v16.2d, v3.2d, v21.2d
	fadd	v3.2d, v4.2d, v29.2d
	fsub	v4.2d, v2.2d, v7.2d
	fadd	v2.2d, v2.2d, v7.2d
	fadd	v6.2d, v16.2d, v1.2d
	stp	q0, q3, [x12]
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldr	q3, [sp, #832]                  // 16-byte Folded Reload
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	fmul	v0.2d, v13.2d, v0.2d
	stp	q4, q6, [x2]
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	fmul	v3.2d, v26.2d, v3.2d
	ldr	q6, [sp, #928]                  // 16-byte Folded Reload
	add	x12, x15, x12
	ldr	x2, [sp, #96]                   // 8-byte Folded Reload
	fadd	v0.2d, v12.2d, v0.2d
	fmul	v4.2d, v28.2d, v4.2d
	mul	x12, x12, x1
	fadd	v3.2d, v14.2d, v3.2d
	add	x2, x15, x2
	fmul	v6.2d, v8.2d, v6.2d
	fsub	v1.2d, v1.2d, v16.2d
	add	x12, x9, x12, lsl #5
	fsub	v4.2d, v0.2d, v4.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	mov	v29.16b, v18.16b
	fsub	v3.2d, v3.2d, v6.2d
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	fmul	v7.2d, v10.2d, v0.2d
	stp	q2, q1, [x12]
	ldr	q1, [sp, #880]                  // 16-byte Folded Reload
	fmul	v6.2d, v11.2d, v6.2d
	ldr	q0, [sp, #912]                  // 16-byte Folded Reload
	ldr	x12, [sp, #160]                 // 8-byte Folded Reload
	fsub	v4.2d, v4.2d, v7.2d
	ldr	q7, [sp, #880]                  // 16-byte Folded Reload
	fmul	v0.2d, v22.2d, v0.2d
	fsub	v2.2d, v3.2d, v6.2d
	add	x12, x15, x12
	fmul	v3.2d, v31.2d, v1.2d
	ldr	q1, [sp, #912]                  // 16-byte Folded Reload
	fmul	v7.2d, v30.2d, v7.2d
	mul	x12, x12, x1
	fmla	v0.2d, v19.2d, v18.2d
	ldr	q18, [sp, #608]                 // 16-byte Folded Reload
	fmul	v1.2d, v20.2d, v1.2d
	fsub	v2.2d, v2.2d, v3.2d
	add	x12, x9, x12, lsl #5
	fmul	v3.2d, v25.2d, v5.2d
	fsub	v4.2d, v4.2d, v7.2d
	fmla	v0.2d, v17.2d, v9.2d
	fmul	v6.2d, v27.2d, v5.2d
	fmla	v1.2d, v19.2d, v23.2d
	ldp	q14, q20, [sp, #272]            // 32-byte Folded Reload
	fadd	v19.2d, v2.2d, v3.2d
	mov	v31.16b, v25.16b
	fadd	v15.2d, v4.2d, v6.2d
	mov	v25.16b, v5.16b
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	fmla	v0.2d, v20.2d, v24.2d
	ldr	q4, [sp, #880]                  // 16-byte Folded Reload
	fmul	v16.2d, v26.2d, v2.2d
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fmul	v6.2d, v13.2d, v4.2d
	fmla	v0.2d, v14.2d, v21.2d
	mov	v4.16b, v21.16b
	fmul	v7.2d, v28.2d, v2.2d
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	ldp	q13, q3, [sp, #704]             // 32-byte Folded Reload
	fsub	v6.2d, v12.2d, v6.2d
	fsub	v21.2d, v18.2d, v16.2d
	fmul	v16.2d, v8.2d, v2.2d
	fsub	v6.2d, v6.2d, v7.2d
	ldp	q2, q12, [sp, #832]             // 32-byte Folded Reload
	fmla	v1.2d, v17.2d, v3.2d
	fsub	v5.2d, v21.2d, v16.2d
	fmul	v7.2d, v10.2d, v2.2d
	ldr	q2, [sp, #832]                  // 16-byte Folded Reload
	fmla	v1.2d, v20.2d, v12.2d
	fmul	v21.2d, v30.2d, v25.2d
	ldr	q30, [sp, #624]                 // 16-byte Folded Reload
	fmul	v16.2d, v11.2d, v2.2d
	ldr	q2, [sp, #864]                  // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v7.2d
	fmul	v7.2d, v22.2d, v17.2d
	ldr	q22, [sp, #560]                 // 16-byte Folded Reload
	fmla	v1.2d, v14.2d, v13.2d
	fadd	v5.2d, v5.2d, v16.2d
	fmul	v17.2d, v22.2d, v17.2d
	fmla	v7.2d, v2.2d, v29.2d
	ldr	q2, [sp, #864]                  // 16-byte Folded Reload
	fmul	v16.2d, v30.2d, v25.2d
	mov	v29.16b, v23.16b
	fmla	v17.2d, v2.2d, v23.2d
	ldr	q23, [sp, #256]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v21.2d
	fsub	v21.2d, v15.2d, v1.2d
	fmla	v7.2d, v23.2d, v9.2d
	fmla	v17.2d, v23.2d, v3.2d
	mov	v9.16b, v3.16b
	fadd	v3.2d, v5.2d, v16.2d
	ldr	q5, [sp, #880]                  // 16-byte Folded Reload
	fadd	v16.2d, v0.2d, v19.2d
	fadd	v1.2d, v15.2d, v1.2d
	fsub	v0.2d, v19.2d, v0.2d
	fmul	v5.2d, v8.2d, v5.2d
	stp	q21, q16, [x12]
	mul	x12, x2, x1
	ldp	q16, q2, [sp, #912]             // 32-byte Folded Reload
	mov	v15.16b, v25.16b
	add	x12, x9, x12, lsl #5
	stp	q1, q0, [x12]
	fmul	v21.2d, v27.2d, v2.2d
	ldr	q2, [sp, #896]                  // 16-byte Folded Reload
	ldr	x2, [sp, #88]                   // 8-byte Folded Reload
	fmla	v7.2d, v2.2d, v24.2d
	ldr	q2, [sp, #896]                  // 16-byte Folded Reload
	fsub	v6.2d, v6.2d, v21.2d
	add	x2, x15, x2
	ldr	x12, [sp, #136]                 // 8-byte Folded Reload
	fmla	v17.2d, v2.2d, v12.2d
	ldr	q2, [sp, #928]                  // 16-byte Folded Reload
	mul	x2, x2, x1
	mov	v12.16b, v13.16b
	add	x12, x15, x12
	fmul	v2.2d, v31.2d, v2.2d
	fmla	v17.2d, v16.2d, v13.2d
	add	x2, x9, x2, lsl #5
	ldp	q13, q27, [sp, #656]            // 32-byte Folded Reload
	mul	x12, x12, x1
	fsub	v2.2d, v3.2d, v2.2d
	fadd	v1.2d, v6.2d, v17.2d
	add	x12, x9, x12, lsl #5
	mov	v24.16b, v18.16b
	ldp	q3, q0, [sp, #912]              // 32-byte Folded Reload
	fmul	v0.2d, v27.2d, v0.2d
	fmla	v7.2d, v3.2d, v4.2d
	fsub	v3.2d, v6.2d, v17.2d
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	fsub	v0.2d, v13.2d, v0.2d
	fadd	v4.2d, v7.2d, v2.2d
	fsub	v2.2d, v2.2d, v7.2d
	ldr	q7, [sp, #912]                  // 16-byte Folded Reload
	fmul	v6.2d, v30.2d, v6.2d
	stp	q3, q4, [x2]
	ldp	q3, q17, [sp, #928]             // 32-byte Folded Reload
	ldr	q4, [sp, #880]                  // 16-byte Folded Reload
	stp	q1, q2, [x12]
	fmul	v1.2d, v22.2d, v20.2d
	ldr	x12, [sp, #168]                 // 8-byte Folded Reload
	fmul	v3.2d, v26.2d, v3.2d
	ldr	x2, [sp, #152]                  // 8-byte Folded Reload
	fmul	v4.2d, v28.2d, v4.2d
	fmul	v2.2d, v10.2d, v25.2d
	add	x12, x15, x12
	add	x2, x15, x2
	fsub	v3.2d, v18.2d, v3.2d
	mul	x12, x12, x1
	fsub	v0.2d, v0.2d, v4.2d
	mul	x2, x2, x1
	fmul	v4.2d, v11.2d, v25.2d
	mov	v18.16b, v29.16b
	add	x12, x9, x12, lsl #5
	fsub	v3.2d, v3.2d, v5.2d
	ldr	q5, [sp, #688]                  // 16-byte Folded Reload
	fadd	v2.2d, v0.2d, v2.2d
	add	x2, x9, x2, lsl #5
	fmul	v0.2d, v5.2d, v20.2d
	fadd	v3.2d, v3.2d, v4.2d
	ldr	q4, [sp, #912]                  // 16-byte Folded Reload
	fmul	v5.2d, v5.2d, v14.2d
	mov	v20.16b, v31.16b
	fmla	v1.2d, v4.2d, v29.2d
	ldr	q4, [sp, #944]                  // 16-byte Folded Reload
	ldp	q29, q16, [sp, #752]            // 32-byte Folded Reload
	fsub	v3.2d, v3.2d, v6.2d
	fmul	v4.2d, v29.2d, v4.2d
	fmla	v0.2d, v7.2d, v16.2d
	ldr	q7, [sp, #592]                  // 16-byte Folded Reload
	fsub	v2.2d, v2.2d, v4.2d
	fmla	v5.2d, v7.2d, v16.2d
	ldp	q16, q6, [sp, #896]             // 32-byte Folded Reload
	fmul	v7.2d, v22.2d, v14.2d
	mov	v14.16b, v9.16b
	fmla	v1.2d, v16.2d, v9.2d
	ldp	q9, q19, [sp, #784]             // 32-byte Folded Reload
	ldp	q22, q4, [sp, #816]             // 32-byte Folded Reload
	fmla	v5.2d, v6.2d, v19.2d
	fmla	v0.2d, v16.2d, v19.2d
	fmla	v5.2d, v23.2d, v22.2d
	ldr	q6, [sp, #592]                  // 16-byte Folded Reload
	fmul	v4.2d, v9.2d, v4.2d
	ldr	q16, [sp, #592]                 // 16-byte Folded Reload
	ldr	q19, [sp, #912]                 // 16-byte Folded Reload
	fmla	v7.2d, v6.2d, v18.2d
	ldr	q6, [sp, #832]                  // 16-byte Folded Reload
	fmul	v18.2d, v8.2d, v25.2d
	fadd	v2.2d, v2.2d, v4.2d
	ldr	q4, [sp, #592]                  // 16-byte Folded Reload
	fmul	v6.2d, v31.2d, v6.2d
	ldp	q21, q31, [sp, #832]            // 32-byte Folded Reload
	fmla	v0.2d, v4.2d, v22.2d
	fmla	v7.2d, v19.2d, v14.2d
	fmul	v4.2d, v26.2d, v17.2d
	fadd	v3.2d, v3.2d, v6.2d
	fmla	v1.2d, v16.2d, v31.2d
	fmla	v7.2d, v23.2d, v31.2d
	fmul	v16.2d, v27.2d, v17.2d
	ldr	q27, [sp, #736]                 // 16-byte Folded Reload
	fsub	v4.2d, v24.2d, v4.2d
	ldp	q19, q26, [sp, #864]            // 32-byte Folded Reload
	fmla	v1.2d, v23.2d, v12.2d
	fmla	v0.2d, v23.2d, v27.2d
	fsub	v6.2d, v13.2d, v16.2d
	fmul	v16.2d, v28.2d, v25.2d
	fadd	v4.2d, v4.2d, v18.2d
	fmla	v5.2d, v19.2d, v27.2d
	fsub	v17.2d, v2.2d, v1.2d
	fmla	v7.2d, v19.2d, v12.2d
	ldr	q18, [sp, #928]                 // 16-byte Folded Reload
	fadd	v6.2d, v6.2d, v16.2d
	fadd	v16.2d, v0.2d, v3.2d
	fmul	v18.2d, v11.2d, v18.2d
	fadd	v1.2d, v2.2d, v1.2d
	fsub	v0.2d, v3.2d, v0.2d
	stp	q17, q16, [x12]
	ldr	q17, [sp, #928]                 // 16-byte Folded Reload
	ldr	x12, [sp, #80]                  // 8-byte Folded Reload
	fsub	v4.2d, v4.2d, v18.2d
	fmul	v17.2d, v10.2d, v17.2d
	fmul	v16.2d, v29.2d, v21.2d
	add	x12, x15, x12
	mov	x15, x18
	mul	x12, x12, x1
	fsub	v6.2d, v6.2d, v17.2d
	fmul	v17.2d, v30.2d, v21.2d
	add	x12, x9, x12, lsl #5
	fadd	v2.2d, v6.2d, v16.2d
	fadd	v4.2d, v4.2d, v17.2d
	stp	q1, q0, [x12]
	fmul	v6.2d, v9.2d, v26.2d
	mul	x12, x3, x1
	fmul	v16.2d, v20.2d, v26.2d
	ldr	x1, [sp, #200]                  // 8-byte Folded Reload
	add	x12, x9, x12, lsl #5
	fsub	v2.2d, v2.2d, v6.2d
	fsub	v3.2d, v4.2d, v16.2d
	ldp	x18, x9, [sp, #208]             // 16-byte Folded Reload
	fsub	v0.2d, v2.2d, v7.2d
	fadd	v1.2d, v5.2d, v3.2d
	fadd	v2.2d, v2.2d, v7.2d
	fsub	v3.2d, v3.2d, v5.2d
	stp	q0, q1, [x2]
	stp	q2, q3, [x12]
	b.lo	.LBB135_6
// %bb.8:                               //   in Loop: Header=BB135_7 Depth=1
	ldp	x28, x5, [sp, #16]              // 16-byte Folded Reload
	mov	v13.16b, v21.16b
	mov	x26, xzr
.LBB135_9:                              //   Parent Loop BB135_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x12, x16, x26
	add	x2, x18, x26
	add	x3, x7, x26
	subs	x5, x5, #1
	mov	v24.16b, v13.16b
	ldp	q0, q1, [x12, #32]
	add	x12, x0, x26
	ldp	q2, q3, [x2, #32]
	add	x2, x15, x26
	fadd	v16.2d, v0.2d, v2.2d
	fsub	v23.2d, v0.2d, v2.2d
	ldp	q4, q5, [x12, #32]
	add	x12, x6, x26
	fadd	v19.2d, v1.2d, v3.2d
	fsub	v27.2d, v1.2d, v3.2d
	str	q23, [sp, #688]                 // 16-byte Folded Spill
	ldp	q6, q0, [x2, #32]
	add	x2, x19, x26
	str	q27, [sp, #480]                 // 16-byte Folded Spill
	fadd	v18.2d, v4.2d, v6.2d
	fsub	v14.2d, v4.2d, v6.2d
	ldp	q1, q2, [x12, #32]
	add	x12, x20, x26
	fadd	v21.2d, v5.2d, v0.2d
	fsub	v30.2d, v5.2d, v0.2d
	ldp	q3, q4, [x2, #32]
	add	x2, x21, x26
	str	q30, [sp, #352]                 // 16-byte Folded Spill
	fadd	v25.2d, v1.2d, v3.2d
	fsub	v10.2d, v1.2d, v3.2d
	ldp	q0, q5, [x12, #32]
	fadd	v28.2d, v2.2d, v4.2d
	fsub	v29.2d, v2.2d, v4.2d
	stp	q10, q14, [sp, #704]            // 32-byte Folded Spill
	ldr	x12, [sp, #328]                 // 8-byte Folded Reload
	ldp	q1, q3, [x2, #32]
	add	x2, x23, x26
	add	x12, x12, x26
	fadd	v8.2d, v0.2d, v1.2d
	fsub	v20.2d, v0.2d, v1.2d
	ldp	q7, q17, [x3, #32]
	fsub	v31.2d, v5.2d, v3.2d
	add	x3, x28, x24
	fadd	v12.2d, v5.2d, v3.2d
	fmul	v3.2d, v21.2d, v13.2d
	fadd	v1.2d, v7.2d, v16.2d
	stp	q16, q31, [sp, #640]            // 32-byte Folded Spill
	ldp	q2, q4, [x12, #32]
	mov	v13.16b, v19.16b
	str	q17, [sp, #848]                 // 16-byte Folded Spill
	fmul	v5.2d, v18.2d, v24.2d
	str	q12, [sp, #624]                 // 16-byte Folded Spill
	ldp	q6, q0, [x2, #32]
	mov	x2, x28
	fadd	v9.2d, v2.2d, v6.2d
	fsub	v26.2d, v2.2d, v6.2d
	fmul	v2.2d, v19.2d, v15.2d
	ldr	q6, [sp, #576]                  // 16-byte Folded Reload
	fadd	v11.2d, v4.2d, v0.2d
	ldr	x12, [sp, #344]                 // 8-byte Folded Reload
	fsub	v22.2d, v4.2d, v0.2d
	fadd	v0.2d, v1.2d, v18.2d
	stp	q20, q26, [sp, #736]            // 32-byte Folded Spill
	fmul	v1.2d, v16.2d, v15.2d
	add	x12, x12, x26
	fadd	v2.2d, v17.2d, v2.2d
	str	q11, [sp, #512]                 // 16-byte Folded Spill
	mov	v16.16b, v21.16b
	str	q22, [sp, #672]                 // 16-byte Folded Spill
	fadd	v4.2d, v17.2d, v19.2d
	fadd	v1.2d, v7.2d, v1.2d
	mov	v19.16b, v7.16b
	ldp	q21, q7, [sp, #880]             // 32-byte Folded Reload
	fadd	v2.2d, v2.2d, v3.2d
	fmul	v3.2d, v14.2d, v6.2d
	mov	v17.16b, v6.16b
	fmul	v6.2d, v28.2d, v21.2d
	fadd	v4.2d, v4.2d, v16.2d
	fmla	v3.2d, v7.2d, v23.2d
	mov	v14.16b, v16.16b
	fmul	v16.2d, v30.2d, v17.2d
	ldr	q30, [sp, #928]                 // 16-byte Folded Reload
	ldr	q17, [sp, #864]                 // 16-byte Folded Reload
	fadd	v1.2d, v1.2d, v5.2d
	fmul	v5.2d, v25.2d, v21.2d
	fsub	v2.2d, v2.2d, v6.2d
	fmla	v3.2d, v17.2d, v10.2d
	fmul	v6.2d, v12.2d, v30.2d
	fmla	v16.2d, v7.2d, v27.2d
	ldr	q7, [sp, #944]                  // 16-byte Folded Reload
	ldr	q10, [sp, #912]                 // 16-byte Folded Reload
	fsub	v1.2d, v1.2d, v5.2d
	fsub	v2.2d, v2.2d, v6.2d
	fmla	v16.2d, v17.2d, v29.2d
	fmul	v5.2d, v11.2d, v7.2d
	fmla	v3.2d, v10.2d, v20.2d
	fadd	v0.2d, v0.2d, v25.2d
	ldr	q17, [sp, #592]                 // 16-byte Folded Reload
	fadd	v4.2d, v4.2d, v28.2d
	fmul	v6.2d, v8.2d, v30.2d
	fmla	v16.2d, v10.2d, v31.2d
	fsub	v2.2d, v2.2d, v5.2d
	fmla	v3.2d, v17.2d, v26.2d
	fadd	v0.2d, v0.2d, v8.2d
	fadd	v4.2d, v4.2d, v12.2d
	fsub	v1.2d, v1.2d, v6.2d
	fmla	v16.2d, v17.2d, v22.2d
	fmul	v5.2d, v9.2d, v7.2d
	fadd	v7.2d, v3.2d, v2.2d
	fadd	v0.2d, v0.2d, v9.2d
	fadd	v4.2d, v4.2d, v11.2d
	fsub	v1.2d, v1.2d, v5.2d
	fneg	v5.2d, v7.2d
	fsub	v2.2d, v2.2d, v3.2d
	stp	q0, q4, [x12, #32]
	ldur	d4, [x28, #-8]
	ldr	x12, [sp, #240]                 // 8-byte Folded Reload
	fsub	v0.2d, v1.2d, v16.2d
	fmul	v7.2d, v7.2d, v4.d[0]
	ld1r	{ v17.2d }, [x2], x12
	fmul	v5.2d, v17.2d, v5.2d
	ldr	q6, [sp, #640]                  // 16-byte Folded Reload
	add	x12, x28, x29
	ldr	q23, [sp, #848]                 // 16-byte Folded Reload
	fmla	v7.2d, v17.2d, v0.2d
	stp	q14, q19, [sp, #800]            // 32-byte Folded Spill
	fmul	v3.2d, v6.2d, v24.2d
	str	q18, [sp, #608]                 // 16-byte Folded Spill
	fmla	v5.2d, v0.2d, v4.d[0]
	ldr	d0, [x12]
	fmul	v4.2d, v13.2d, v24.2d
	stp	q25, q28, [sp, #768]            // 32-byte Folded Spill
	fneg	v17.2d, v2.2d
	ldr	q31, [sp, #480]                 // 16-byte Folded Reload
	fadd	v3.2d, v19.2d, v3.2d
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	stp	q7, q5, [sp, #544]              // 32-byte Folded Spill
	mov	v7.16b, v19.16b
	stp	q9, q29, [sp, #368]             // 32-byte Folded Spill
	fmul	v5.2d, v18.2d, v30.2d
	str	q8, [sp, #400]                  // 16-byte Folded Spill
	mov	v11.16b, v18.16b
	fadd	v18.2d, v23.2d, v4.2d
	ldur	d4, [x12, #-8]
	fmul	v19.2d, v14.2d, v30.2d
	add	x12, x28, x4
	fadd	v30.2d, v1.2d, v16.2d
	fmul	v1.2d, v17.2d, v0.d[0]
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	mov	v12.16b, v13.16b
	ldr	q13, [sp, #352]                 // 16-byte Folded Reload
	fsub	v16.2d, v18.2d, v19.2d
	fmul	v18.2d, v25.2d, v0.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fsub	v5.2d, v3.2d, v5.2d
	fmla	v1.2d, v30.2d, v4.d[0]
	mov	v27.16b, v28.16b
	str	q30, [sp, #464]                 // 16-byte Folded Spill
	fmul	v19.2d, v28.2d, v0.2d
	ldr	q0, [sp, #912]                  // 16-byte Folded Reload
	fmul	v28.2d, v2.2d, v4.d[0]
	ldr	q4, [sp, #624]                  // 16-byte Folded Reload
	fmul	v20.2d, v12.2d, v21.2d
	str	q1, [sp, #528]                  // 16-byte Folded Spill
	fmul	v3.2d, v13.2d, v0.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fsub	v2.2d, v5.2d, v18.2d
	ldr	q30, [sp, #576]                 // 16-byte Folded Reload
	fsub	v5.2d, v16.2d, v19.2d
	str	q12, [sp, #432]                 // 16-byte Folded Spill
	fmul	v18.2d, v8.2d, v21.2d
	fmul	v19.2d, v4.2d, v21.2d
	fmla	v3.2d, v30.2d, v31.2d
	fmul	v21.2d, v6.2d, v21.2d
	fsub	v16.2d, v23.2d, v20.2d
	fmul	v20.2d, v14.2d, v0.2d
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fsub	v2.2d, v2.2d, v18.2d
	fsub	v18.2d, v7.2d, v21.2d
	ldp	q7, q1, [sp, #704]              // 32-byte Folded Reload
	mov	v26.16b, v6.16b
	fsub	v16.2d, v16.2d, v20.2d
	fmul	v20.2d, v11.2d, v0.2d
	fsub	v17.2d, v5.2d, v19.2d
	fmul	v19.2d, v9.2d, v15.2d
	ldp	q23, q6, [sp, #288]             // 32-byte Folded Reload
	fmul	v21.2d, v27.2d, v24.2d
	mov	v10.16b, v9.16b
	fadd	v19.2d, v2.2d, v19.2d
	fsub	v2.2d, v18.2d, v20.2d
	fadd	v18.2d, v16.2d, v21.2d
	ldr	q0, [sp, #912]                  // 16-byte Folded Reload
	fmla	v3.2d, v6.2d, v29.2d
	ldr	q27, [sp, #688]                 // 16-byte Folded Reload
	ldr	q9, [sp, #656]                  // 16-byte Folded Reload
	fmul	v0.2d, v1.2d, v0.2d
	ldr	q11, [sp, #512]                 // 16-byte Folded Reload
	fmul	v16.2d, v1.2d, v6.2d
	mov	v5.16b, v29.16b
	fmla	v3.2d, v23.2d, v9.2d
	fmul	v1.2d, v4.2d, v15.2d
	ldr	q4, [sp, #864]                  // 16-byte Folded Reload
	fmla	v0.2d, v30.2d, v27.2d
	ldp	q30, q29, [sp, #256]            // 32-byte Folded Reload
	fmla	v16.2d, v4.2d, v27.2d
	mov	v22.16b, v25.16b
	fmul	v20.2d, v11.2d, v15.2d
	fmla	v0.2d, v6.2d, v7.2d
	mov	v25.16b, v15.16b
	fmla	v16.2d, v30.2d, v7.2d
	ldr	q27, [sp, #672]                 // 16-byte Folded Reload
	fmul	v21.2d, v22.2d, v24.2d
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	fadd	v20.2d, v17.2d, v20.2d
	ldr	q22, [sp, #736]                 // 16-byte Folded Reload
	fmla	v3.2d, v29.2d, v27.2d
	fadd	v1.2d, v18.2d, v1.2d
	fadd	v24.2d, v2.2d, v21.2d
	fmla	v0.2d, v23.2d, v22.2d
	fmul	v2.2d, v13.2d, v6.2d
	fsub	v14.2d, v19.2d, v3.2d
	fadd	v17.2d, v19.2d, v3.2d
	ldr	q3, [sp, #896]                  // 16-byte Folded Reload
	fmul	v18.2d, v8.2d, v25.2d
	fmul	v21.2d, v11.2d, v4.2d
	ldr	q4, [sp, #752]                  // 16-byte Folded Reload
	fmla	v16.2d, v3.2d, v22.2d
	ldr	q3, [sp, #864]                  // 16-byte Folded Reload
	mov	v15.16b, v13.16b
	fadd	v18.2d, v24.2d, v18.2d
	fmla	v0.2d, v29.2d, v4.2d
	fmla	v2.2d, v3.2d, v31.2d
	fsub	v24.2d, v1.2d, v21.2d
	ldp	q3, q1, [sp, #912]              // 32-byte Folded Reload
	fadd	v19.2d, v0.2d, v20.2d
	fmla	v2.2d, v30.2d, v5.2d
	fsub	v20.2d, v20.2d, v0.2d
	fmla	v16.2d, v3.2d, v4.2d
	mov	v13.16b, v11.16b
	fmul	v1.2d, v10.2d, v1.2d
	ldp	d0, d5, [x12, #-24]
	fadd	v7.2d, v16.2d, v24.2d
	add	x12, x28, x27
	ldp	d4, d22, [x3, #-136]
	fsub	v21.2d, v18.2d, v1.2d
	add	x3, x10, x26
	ldp	q1, q6, [sp, #896]              // 32-byte Folded Reload
	fneg	v18.2d, v19.2d
	fmul	v10.2d, v19.2d, v0.d[0]
	fneg	v3.2d, v7.2d
	fmul	v19.2d, v20.2d, v4.d[0]
	fmla	v2.2d, v1.2d, v9.2d
	fneg	v1.2d, v20.2d
	fmla	v10.2d, v14.2d, v5.d[0]
	ldr	q9, [sp, #464]                  // 16-byte Folded Reload
	fmla	v19.2d, v17.2d, v22.d[0]
	fmla	v2.2d, v6.2d, v27.2d
	ldr	d6, [x12]
	ldr	q27, [sp, #496]                 // 16-byte Folded Reload
	str	q10, [sp, #416]                 // 16-byte Folded Spill
	fmla	v28.2d, v9.2d, v27.d[0]
	fmul	v27.2d, v18.2d, v5.d[0]
	fmul	v18.2d, v3.2d, v6.d[0]
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fmul	v9.2d, v1.2d, v22.d[0]
	ldr	q5, [sp, #848]                  // 16-byte Folded Reload
	fsub	v1.2d, v21.2d, v2.2d
	fmul	v3.2d, v12.2d, v3.2d
	fmla	v27.2d, v14.2d, v0.d[0]
	ldur	d0, [x12, #-8]
	add	x12, x13, x26
	fmla	v9.2d, v17.2d, v4.d[0]
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	fsub	v5.2d, v5.2d, v3.2d
	ldr	q3, [sp, #880]                  // 16-byte Folded Reload
	fmul	v4.2d, v26.2d, v4.2d
	fmla	v18.2d, v1.2d, v0.d[0]
	fmul	v11.2d, v7.2d, v0.d[0]
	ldp	q17, q0, [sp, #800]             // 32-byte Folded Reload
	fmul	v17.2d, v17.2d, v3.2d
	ldr	q7, [sp, #560]                  // 16-byte Folded Reload
	ldp	q10, q3, [sp, #592]             // 32-byte Folded Reload
	fsub	v0.2d, v0.2d, v4.2d
	str	q18, [sp, #496]                 // 16-byte Folded Spill
	str	q7, [x12, #32]
	fmla	v11.2d, v1.2d, v6.d[0]
	fsub	v5.2d, v5.2d, v17.2d
	stp	q9, q19, [sp, #448]             // 32-byte Folded Spill
	fadd	v19.2d, v21.2d, v2.2d
	ldp	q4, q21, [sp, #880]             // 32-byte Folded Reload
	ldp	q20, q18, [sp, #704]            // 32-byte Folded Reload
	fmul	v4.2d, v3.2d, v4.2d
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	fsub	v0.2d, v0.2d, v4.2d
	ldp	q4, q3, [sp, #768]              // 32-byte Folded Reload
	fmul	v7.2d, v3.2d, v25.2d
	ldr	q14, [sp, #624]                 // 16-byte Folded Reload
	str	q1, [x12, #48]
	ldr	q12, [sp, #912]                 // 16-byte Folded Reload
	fmul	v6.2d, v18.2d, v23.2d
	ldr	q2, [sp, #688]                  // 16-byte Folded Reload
	fmul	v4.2d, v4.2d, v25.2d
	add	x12, x28, x17
	fadd	v1.2d, v5.2d, v7.2d
	ldr	q5, [sp, #944]                  // 16-byte Folded Reload
	fsub	v7.2d, v24.2d, v16.2d
	ldr	q3, [sp, #528]                  // 16-byte Folded Reload
	fmla	v6.2d, v12.2d, v2.2d
	fmul	v5.2d, v14.2d, v5.2d
	fadd	v0.2d, v0.2d, v4.2d
	stp	q3, q28, [x3, #32]
	fmul	v16.2d, v15.2d, v23.2d
	ldr	x3, [sp, #232]                  // 8-byte Folded Reload
	fneg	v17.2d, v7.2d
	fsub	v4.2d, v1.2d, v5.2d
	ldr	q1, [sp, #896]                  // 16-byte Folded Reload
	ldr	q5, [sp, #832]                  // 16-byte Folded Reload
	add	x3, x28, x3
	mov	v24.16b, v15.16b
	fmla	v16.2d, v12.2d, v31.2d
	fmla	v6.2d, v1.2d, v20.2d
	ldr	q1, [sp, #944]                  // 16-byte Folded Reload
	fmul	v5.2d, v13.2d, v5.2d
	mov	v15.16b, v31.16b
	fmul	v1.2d, v8.2d, v1.2d
	ldp	q8, q3, [sp, #368]              // 32-byte Folded Reload
	fadd	v23.2d, v4.2d, v5.2d
	fsub	v0.2d, v0.2d, v1.2d
	str	q23, [sp, #560]                 // 16-byte Folded Spill
	ldp	q5, q22, [sp, #736]             // 32-byte Folded Reload
	fmla	v16.2d, v21.2d, v3.2d
	fmul	v21.2d, v24.2d, v29.2d
	fmla	v6.2d, v10.2d, v5.2d
	ldp	d4, d1, [x12, #-8]
	fmla	v21.2d, v10.2d, v15.2d
	add	x12, x14, x26
	fmla	v6.2d, v30.2d, v22.2d
	ldr	d24, [x3]
	fmul	v31.2d, v17.2d, v1.d[0]
	ldr	q17, [sp, #832]                 // 16-byte Folded Reload
	fmul	v26.2d, v7.2d, v4.d[0]
	fmul	v7.2d, v18.2d, v29.2d
	fmla	v21.2d, v12.2d, v3.2d
	fmul	v17.2d, v8.2d, v17.2d
	ldr	q3, [sp, #496]                  // 16-byte Folded Reload
	fmla	v31.2d, v19.2d, v4.d[0]
	ldp	q4, q28, [sp, #656]             // 32-byte Folded Reload
	fmla	v26.2d, v19.2d, v1.d[0]
	fmla	v7.2d, v10.2d, v2.2d
	fadd	v17.2d, v0.2d, v17.2d
	fadd	v0.2d, v6.2d, v23.2d
	fmla	v16.2d, v10.2d, v4.2d
	fmla	v7.2d, v12.2d, v20.2d
	ldp	q1, q19, [sp, #416]             // 32-byte Folded Reload
	fneg	v23.2d, v0.2d
	fmla	v16.2d, v30.2d, v28.2d
	mov	v15.16b, v25.16b
	stp	q27, q1, [x12, #32]
	add	x12, x11, x26
	fmul	v1.2d, v23.2d, v24.d[0]
	mov	v23.16b, v30.16b
	ldp	q18, q30, [sp, #448]            // 32-byte Folded Reload
	fsub	v2.2d, v17.2d, v16.2d
	fadd	v16.2d, v17.2d, v16.2d
	fmla	v7.2d, v23.2d, v5.2d
	fmla	v21.2d, v23.2d, v4.2d
	ldp	q9, q27, [sp, #928]             // 32-byte Folded Reload
	stp	q18, q30, [x12, #32]
	add	x12, x8, x26
	stp	q3, q11, [x12, #32]
	ldur	d18, [x3, #-8]
	add	x3, x28, x22
	fmul	v19.2d, v19.2d, v27.2d
	ldp	q5, q3, [sp, #784]              // 32-byte Folded Reload
	fmla	v1.2d, v2.2d, v18.d[0]
	fmul	v0.2d, v0.2d, v18.d[0]
	ldp	q29, q18, [sp, #832]            // 32-byte Folded Reload
	fmla	v0.2d, v2.2d, v24.d[0]
	fsub	v18.2d, v18.2d, v19.2d
	ldr	q2, [sp, #640]                  // 16-byte Folded Reload
	fmul	v19.2d, v3.2d, v25.2d
	ldr	q4, [sp, #608]                  // 16-byte Folded Reload
	ldp	q20, q24, [sp, #864]            // 32-byte Folded Reload
	fmul	v2.2d, v2.2d, v27.2d
	fadd	v3.2d, v18.2d, v19.2d
	fmul	v18.2d, v5.2d, v9.2d
	fmla	v7.2d, v20.2d, v22.2d
	fmla	v21.2d, v20.2d, v28.2d
	ldr	q19, [sp, #816]                 // 16-byte Folded Reload
	ldr	q5, [sp, #768]                  // 16-byte Folded Reload
	fsub	v3.2d, v3.2d, v18.2d
	ldr	x12, [sp, #248]                 // 8-byte Folded Reload
	fsub	v2.2d, v19.2d, v2.2d
	fmul	v19.2d, v4.2d, v25.2d
	ldr	q4, [sp, #560]                  // 16-byte Folded Reload
	fmul	v18.2d, v14.2d, v29.2d
	add	x12, x28, x12
	fmul	v17.2d, v8.2d, v24.2d
	add	x28, x28, #16
	fadd	v2.2d, v2.2d, v19.2d
	fmul	v19.2d, v5.2d, v9.2d
	fsub	v5.2d, v4.2d, v6.2d
	ldr	q4, [sp, #400]                  // 16-byte Folded Reload
	fadd	v3.2d, v3.2d, v18.2d
	fmul	v6.2d, v13.2d, v24.2d
	ldp	d20, d18, [x12, #-104]
	fsub	v2.2d, v2.2d, v19.2d
	add	x12, x30, x26
	fmul	v19.2d, v4.2d, v29.2d
	fsub	v3.2d, v3.2d, v6.2d
	fneg	v6.2d, v5.2d
	stp	q31, q26, [x12, #32]
	fmul	v4.2d, v5.2d, v20.d[0]
	ldr	x12, [sp, #336]                 // 8-byte Folded Reload
	fadd	v2.2d, v2.2d, v19.2d
	fadd	v19.2d, v7.2d, v3.2d
	fmul	v6.2d, v6.2d, v18.d[0]
	add	x12, x12, x26
	fsub	v3.2d, v3.2d, v7.2d
	fmla	v4.2d, v16.2d, v18.d[0]
	ldp	d22, d7, [x3, #-72]
	fsub	v2.2d, v2.2d, v17.2d
	stp	q1, q0, [x12, #32]
	fmla	v6.2d, v16.2d, v20.d[0]
	add	x12, x25, x26
	ldp	d18, d16, [x2, #-8]
	fneg	v17.2d, v19.2d
	fmul	v19.2d, v19.2d, v22.d[0]
	fneg	v20.2d, v3.2d
	add	x2, x1, x26
	mov	v13.16b, v29.16b
	fmul	v3.2d, v3.2d, v18.d[0]
	fmul	v5.2d, v17.2d, v7.d[0]
	stp	q6, q4, [x2, #32]
	fsub	v17.2d, v2.2d, v21.2d
	fmul	v20.2d, v20.2d, v16.d[0]
	fadd	v2.2d, v2.2d, v21.2d
	add	x2, x9, x26
	add	x26, x26, #32
	fmla	v5.2d, v17.2d, v22.d[0]
	fmla	v19.2d, v17.2d, v7.d[0]
	fmla	v20.2d, v2.2d, v18.d[0]
	fmla	v3.2d, v2.2d, v16.d[0]
	stp	q5, q19, [x12, #32]
	stp	q20, q3, [x2, #32]
	b.ne	.LBB135_9
	b	.LBB135_6
.LBB135_10:
	add	sp, sp, #960
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end135:
	.size	_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE, .Lfunc_end135-_ZNK9pocketfft6detail5cfftpIdE6pass11ILb0ENS0_5cmplxIDv2_dEEEEvmmPKT0_PS7_PKNS4_IdEE
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
.LCPI136_0:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_,@function
_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_: // @_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #4
	mov	x25, x7
	add	x0, x8, #64
	stp	x6, x4, [sp, #24]               // 16-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x22, x3
	mov	x21, x1
	bl	malloc
	cbz	x0, .LBB136_85
// %bb.1:
	adrp	x8, .LCPI136_0
	add	x9, x0, #64
	add	x14, x23, #1
	mul	x19, x22, x21
	and	x28, x9, #0xffffffffffffffc0
	lsr	x26, x14, #1
	ldr	q0, [x8, :lo12:.LCPI136_0]
	subs	x13, x23, #2
	stur	x0, [x28, #-8]
	str	q0, [x28]
	stp	x26, x22, [x29, #-16]           // 16-byte Folded Spill
	b.lo	.LBB136_4
// %bb.2:
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cmp	x27, #4
	b.hs	.LBB136_6
// %bb.3:
	mov	w8, #1
	b	.LBB136_13
.LBB136_4:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cbz	x22, .LBB136_73
// %bb.5:
	cbnz	x21, .LBB136_17
	b	.LBB136_73
.LBB136_6:
	cmp	xzr, x13, lsr #60
	add	x11, x28, #16
	lsl	x10, x13, #4
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB136_13
// %bb.7:
	tbnz	w9, #0, .LBB136_13
// %bb.8:
	add	x11, x28, #24
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB136_13
// %bb.9:
	tbnz	w9, #0, .LBB136_13
// %bb.10:
	and	x9, x27, #0xfffffffffffffffc
	add	x10, x28, #48
	orr	x8, x9, #0x1
	add	x11, x25, #48
	mov	x12, x9
.LBB136_11:                             // =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x11, #-32]
	subs	x12, x12, #4
	ldp	q3, q2, [x11], #64
	stp	q1, q0, [x10, #-32]
	stp	q3, q2, [x10], #64
	b.ne	.LBB136_11
// %bb.12:
	cmp	x27, x9
	b.eq	.LBB136_15
.LBB136_13:
	lsl	x10, x8, #4
	sub	x9, x23, x8
	add	x8, x25, x10
	add	x10, x28, x10
.LBB136_14:                             // =>This Inner Loop Header: Depth=1
	ldr	q0, [x8], #16
	subs	x9, x9, #1
	str	q0, [x10], #16
	b.ne	.LBB136_14
.LBB136_15:
	cbz	x22, .LBB136_35
// %bb.16:
	cbz	x21, .LBB136_37
.LBB136_17:
	mul	x8, x23, x21
	lsl	x25, x21, #5
	mov	x26, x24
	mov	x27, x30
	lsl	x20, x8, #5
	stp	x13, x14, [x29, #-32]           // 16-byte Folded Spill
.LBB136_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	mov	x2, x25
	bl	memcpy
	add	x27, x27, x20
	add	x26, x26, x25
	subs	x22, x22, #1
	b.ne	.LBB136_18
// %bb.19:
	ldp	x8, x26, [x29, #-24]            // 16-byte Folded Reload
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	cmp	x8, #3
	b.ls	.LBB136_27
// %bb.20:
	cbz	x21, .LBB136_49
// %bb.21:
	mul	x10, x21, x27
	add	x11, x24, x19, lsl #5
	mul	x13, x19, x27
	cmp	x26, #2
	mov	w8, #2
	add	x14, x30, x25
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	lsl	x12, x19, #5
	add	x15, x24, x13, lsl #5
	neg	x9, x25
	csel	x8, x26, x8, hi
	add	x13, x14, #16
	add	x14, x15, #16
	neg	x15, x12
	mov	w16, #1
.LBB136_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB136_23 Depth 2
                                        //       Child Loop BB136_24 Depth 3
	mov	x17, xzr
	mov	x18, x14
	mov	x0, x13
	mov	x1, x10
	mov	x2, x11
.LBB136_23:                             //   Parent Loop BB136_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB136_24 Depth 3
	mov	x3, x18
	mov	x4, x0
	mov	x5, x1
	mov	x6, x2
	mov	x7, x21
.LBB136_24:                             //   Parent Loop BB136_22 Depth=1
                                        //     Parent Loop BB136_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x4, #-16]
	subs	x7, x7, #1
	add	x4, x4, #32
	ldp	q2, q3, [x6, #-16]
	add	x6, x6, #32
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x5, #-16]
	add	x5, x5, #32
	stp	q0, q1, [x3, #-16]
	add	x3, x3, #32
	b.ne	.LBB136_24
// %bb.25:                              //   in Loop: Header=BB136_23 Depth=2
	add	x17, x17, #1
	add	x2, x2, x20
	add	x1, x1, x25
	add	x0, x0, x20
	add	x18, x18, x25
	cmp	x17, x22
	b.ne	.LBB136_23
// %bb.26:                              //   in Loop: Header=BB136_22 Depth=1
	add	x16, x16, #1
	add	x11, x11, x9
	add	x10, x10, x12
	add	x13, x13, x25
	add	x14, x14, x15
	cmp	x16, x8
	b.ne	.LBB136_22
.LBB136_27:
	ldur	x18, [x29, #-24]                // 8-byte Folded Reload
	cbz	x21, .LBB136_42
// %bb.28:
	cmp	x18, #3
	b.ls	.LBB136_38
// %bb.29:
	cmp	x26, #2
	mov	w9, #2
	csel	x9, x26, x9, hi
	add	x10, x24, x19, lsl #5
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x10, #16
	lsl	x11, x19, #5
.LBB136_30:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB136_31 Depth 2
                                        //       Child Loop BB136_32 Depth 3
	mul	x13, x8, x21
	mov	x12, xzr
	mov	x14, x10
.LBB136_31:                             //   Parent Loop BB136_30 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB136_32 Depth 3
	add	x15, x12, x13
	mov	x17, x9
	add	x16, x24, x15, lsl #5
	ldp	q0, q1, [x16]
	mov	x16, x14
.LBB136_32:                             //   Parent Loop BB136_30 Depth=1
                                        //     Parent Loop BB136_31 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q3, [x16, #-16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.2d, v0.2d, v2.2d
	fadd	v1.2d, v1.2d, v3.2d
	b.ne	.LBB136_32
// %bb.33:                              //   in Loop: Header=BB136_31 Depth=2
	add	x15, x30, x15, lsl #5
	add	x12, x12, #1
	add	x14, x14, #32
	cmp	x12, x21
	stp	q0, q1, [x15]
	b.ne	.LBB136_31
// %bb.34:                              //   in Loop: Header=BB136_30 Depth=1
	add	x8, x8, #1
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB136_30
	b	.LBB136_42
.LBB136_35:
	mov	w9, #1
	cmp	x14, #3
	b.hi	.LBB136_51
// %bb.36:
	mov	w8, wzr
	subs	x10, x21, #1
	b.eq	.LBB136_44
	b	.LBB136_71
.LBB136_37:
	cmp	x14, #3
	b.hi	.LBB136_50
	b	.LBB136_73
.LBB136_38:
	mov	x8, xzr
	add	x9, x30, #16
	add	x10, x24, #16
.LBB136_39:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB136_40 Depth 2
	mov	x11, x10
	mov	x12, x9
	mov	x13, x21
.LBB136_40:                             //   Parent Loop BB136_39 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x13, x13, #1
	add	x11, x11, #32
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB136_40
// %bb.41:                              //   in Loop: Header=BB136_39 Depth=1
	add	x8, x8, #1
	add	x9, x9, x25
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB136_39
.LBB136_42:
	mov	w9, wzr
	mov	w8, wzr
	ldur	x13, [x29, #-32]                // 8-byte Folded Reload
	cmp	x18, #4
	b.hs	.LBB136_51
// %bb.43:
	subs	x10, x21, #1
	b.ne	.LBB136_71
.LBB136_44:
	cmp	x19, #0
	eor	w8, w8, #0x1
	cset	w9, eq
	orr	w8, w8, w9
	tbnz	w8, #0, .LBB136_73
// %bb.45:
	mul	x8, x27, x22
	cmp	x26, #2
	mov	w9, #2
	add	x11, x30, x19, lsl #5
	csel	x9, x26, x9, hi
	mov	w13, #1
	mul	x10, x8, x21
	lsl	x8, x19, #5
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	neg	x12, x8
.LBB136_46:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB136_47 Depth 2
	mov	x14, x11
	mov	x15, x10
	mov	x16, x19
.LBB136_47:                             //   Parent Loop BB136_46 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x15, #-16]
	subs	x16, x16, #1
	ldp	q2, q3, [x14, #-16]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x15, #-16]
	add	x15, x15, #32
	stp	q0, q1, [x14, #-16]
	add	x14, x14, #32
	b.ne	.LBB136_47
// %bb.48:                              //   in Loop: Header=BB136_46 Depth=1
	add	x13, x13, #1
	add	x10, x10, x8
	add	x11, x11, x12
	cmp	x13, x9
	b.ne	.LBB136_46
	b	.LBB136_73
.LBB136_49:
	ldur	x13, [x29, #-32]                // 8-byte Folded Reload
.LBB136_50:
	mov	w9, wzr
.LBB136_51:
	str	w9, [sp, #12]                   // 4-byte Folded Spill
	mul	x9, x19, x13
	sub	x1, x23, #4
	mul	x8, x19, x27
	cmp	x26, #2
	mov	w13, #2
	add	x18, x24, x9, lsl #5
	mov	w9, #96
	mul	x2, x19, x1
	lsl	x8, x8, #5
	madd	x9, x19, x9, x24
	add	x15, x30, x8
	add	x8, x24, x8
	csel	x13, x26, x13, hi
	add	x1, x8, #16
	add	x8, x9, #16
	add	x9, x24, x2, lsl #5
	sub	x10, x23, #3
	str	x27, [sp, #16]                  // 8-byte Folded Spill
	lsl	x12, x19, #5
	stp	x8, x13, [x29, #-32]            // 16-byte Folded Spill
	mul	x8, x19, x10
	stur	x9, [x29, #-40]                 // 8-byte Folded Spill
	add	x9, x24, x19, lsl #7
	add	x9, x9, #16
	add	x14, x24, x12
	add	x17, x24, x19, lsl #6
	add	x0, x30, x12
	lsl	x3, x19, #6
	sub	x11, x26, #1
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x24, x8, lsl #5
	add	x8, x24, #16
	add	x14, x14, #16
	neg	x16, x12
	add	x17, x17, #16
	add	x0, x0, #16
	neg	x5, x3
	stp	x8, x9, [sp, #48]               // 16-byte Folded Spill
	lsl	x8, x19, #1
	mov	w27, #1
	str	x8, [sp, #40]                   // 8-byte Folded Spill
	b	.LBB136_53
.LBB136_52:                             //   in Loop: Header=BB136_53 Depth=1
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	add	x27, x27, #1
	add	x15, x15, x16
	add	x0, x0, x12
	cmp	x27, x8
	b.eq	.LBB136_70
.LBB136_53:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB136_55 Depth 2
                                        //     Child Loop BB136_59 Depth 2
                                        //       Child Loop BB136_61 Depth 3
                                        //     Child Loop BB136_67 Depth 2
                                        //       Child Loop BB136_68 Depth 3
	cbz	x19, .LBB136_62
// %bb.54:                              //   in Loop: Header=BB136_53 Depth=1
	add	x2, x28, x27, lsl #4
	add	x4, x28, x27, lsl #5
	mov	x9, xzr
	lsl	x30, x27, #1
	add	x6, x2, #8
	add	x7, x4, #8
	mov	x20, x19
.LBB136_55:                             //   Parent Loop BB136_53 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x14, x9
	add	x25, x24, x9
	ldr	d0, [x2]
	add	x22, x17, x9
	ld1r	{ v7.2d }, [x7]
	subs	x20, x20, #1
	ldp	q2, q16, [x8, #-16]
	add	x8, x18, x9
	fneg	v7.2d, v7.2d
	ldp	q4, q5, [x25]
	fmla	v4.2d, v2.2d, v0.d[0]
	ldp	q0, q20, [x8]
	add	x8, x0, x9
	ldp	q3, q18, [x22, #-16]
	add	x22, x1, x9
	ldr	d1, [x4]
	ldr	d6, [x2]
	ldr	d19, [x7]
	fmla	v4.2d, v3.2d, v1.d[0]
	ldr	d17, [x4]
	fmla	v5.2d, v16.2d, v6.d[0]
	ldr	d2, [x6]
	fmul	v6.2d, v20.2d, v7.2d
	fmul	v0.2d, v0.2d, v19.d[0]
	ldp	q1, q7, [x22, #-16]
	add	x22, x15, x9
	add	x9, x9, #32
	fmla	v5.2d, v18.2d, v17.d[0]
	ldr	d16, [x6]
	fmls	v6.2d, v7.2d, v2.d[0]
	stp	q4, q5, [x8, #-16]
	fmla	v0.2d, v1.2d, v16.d[0]
	stp	q6, q0, [x22]
	b.ne	.LBB136_55
// %bb.56:                              //   in Loop: Header=BB136_53 Depth=1
	cmp	x11, #4
	b.lo	.LBB136_63
.LBB136_57:                             //   in Loop: Header=BB136_53 Depth=1
	ldp	x6, x4, [x29, #-48]             // 16-byte Folded Reload
	mov	w9, #3
	mov	x20, x10
	ldr	x7, [sp, #56]                   // 8-byte Folded Reload
	ldur	x2, [x29, #-32]                 // 8-byte Folded Reload
	b	.LBB136_59
.LBB136_58:                             //   in Loop: Header=BB136_59 Depth=2
	add	x9, x9, #2
	sub	x20, x20, #2
	add	x2, x2, x3
	add	x4, x4, x5
	add	x6, x6, x3
	add	x7, x7, x5
	cmp	x9, x11
	b.hs	.LBB136_64
.LBB136_59:                             //   Parent Loop BB136_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB136_61 Depth 3
	add	x8, x30, x27
	cmp	x8, x23
	csel	x22, x23, xzr, hi
	sub	x22, x8, x22
	add	x8, x22, x27
	cmp	x8, x23
	csel	x25, x23, xzr, hi
	sub	x30, x8, x25
	cbz	x19, .LBB136_58
// %bb.60:                              //   in Loop: Header=BB136_59 Depth=2
	add	x22, x28, x22, lsl #4
	add	x25, x28, x30, lsl #4
	mov	x8, xzr
	ld1r	{ v0.2d }, [x22], #8
	ld1r	{ v1.2d }, [x25], #8
	ld1r	{ v2.2d }, [x22]
	mov	x22, x19
	ld1r	{ v3.2d }, [x25]
.LBB136_61:                             //   Parent Loop BB136_53 Depth=1
                                        //     Parent Loop BB136_59 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x25, x6, x8
	add	x26, x2, x8
	add	x13, x0, x8
	subs	x22, x22, #1
	ldp	q4, q5, [x25, #-16]
	add	x25, x4, x8
	fmul	v4.2d, v1.2d, v4.2d
	ldp	q6, q7, [x26, #-16]
	fmul	v5.2d, v1.2d, v5.2d
	add	x26, x7, x8
	fmla	v4.2d, v0.2d, v6.2d
	ldp	q16, q17, [x13, #-16]
	fmla	v5.2d, v0.2d, v7.2d
	fadd	v4.2d, v16.2d, v4.2d
	ldp	q7, q6, [x25]
	fadd	v5.2d, v17.2d, v5.2d
	add	x25, x15, x8
	add	x8, x8, #32
	fmul	v7.2d, v3.2d, v7.2d
	stp	q4, q5, [x13, #-16]
	ldp	q17, q16, [x26]
	fmul	v6.2d, v3.2d, v6.2d
	fmla	v7.2d, v2.2d, v17.2d
	ldp	q4, q5, [x25]
	fmla	v6.2d, v2.2d, v16.2d
	fsub	v4.2d, v4.2d, v6.2d
	fadd	v5.2d, v5.2d, v7.2d
	stp	q4, q5, [x25]
	b.ne	.LBB136_61
	b	.LBB136_58
.LBB136_62:                             //   in Loop: Header=BB136_53 Depth=1
	lsl	x30, x27, #1
	cmp	x11, #4
	b.hs	.LBB136_57
.LBB136_63:                             //   in Loop: Header=BB136_53 Depth=1
	mov	x20, x10
	mov	w9, #3
.LBB136_64:                             //   in Loop: Header=BB136_53 Depth=1
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cmp	x9, x26
	b.hs	.LBB136_52
// %bb.65:                              //   in Loop: Header=BB136_53 Depth=1
	cbz	x19, .LBB136_52
// %bb.66:                              //   in Loop: Header=BB136_53 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	mul	x8, x13, x9
	mul	x4, x13, x20
	ldr	x13, [sp, #48]                  // 8-byte Folded Reload
	add	x2, x13, x8, lsl #4
	add	x4, x13, x4, lsl #4
.LBB136_67:                             //   Parent Loop BB136_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB136_68 Depth 3
	add	x6, x30, x27
	mov	x8, xzr
	cmp	x6, x23
	csel	x7, x23, xzr, hi
	sub	x30, x6, x7
	add	x6, x28, x30, lsl #4
	ld1r	{ v0.2d }, [x6], #8
	ld1r	{ v1.2d }, [x6]
	mov	x6, x19
.LBB136_68:                             //   Parent Loop BB136_53 Depth=1
                                        //     Parent Loop BB136_67 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x7, x2, x8
	add	x20, x0, x8
	add	x22, x15, x8
	subs	x6, x6, #1
	ldp	q2, q4, [x7, #-16]
	add	x7, x4, x8
	add	x8, x8, #32
	ldp	q3, q5, [x20, #-16]
	fmla	v3.2d, v0.2d, v2.2d
	fmla	v5.2d, v0.2d, v4.2d
	stp	q3, q5, [x20, #-16]
	ldp	q3, q2, [x7, #-16]
	ldp	q4, q5, [x22]
	fmls	v4.2d, v1.2d, v2.2d
	fmla	v5.2d, v1.2d, v3.2d
	stp	q4, q5, [x22]
	b.ne	.LBB136_68
// %bb.69:                              //   in Loop: Header=BB136_67 Depth=2
	add	x9, x9, #1
	add	x2, x2, x12
	add	x4, x4, x16
	cmp	x9, x26
	b.ne	.LBB136_67
	b	.LBB136_52
.LBB136_70:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	mov	w8, #1
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	ldr	w9, [sp, #12]                   // 4-byte Folded Reload
	subs	x10, x21, #1
	b.eq	.LBB136_44
.LBB136_71:
	cbz	w8, .LBB136_73
// %bb.72:
	tbz	w9, #0, .LBB136_76
.LBB136_73:
	cbz	x28, .LBB136_75
// %bb.74:
	ldur	x0, [x28, #-8]
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	b	free
.LBB136_75:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB136_76:
	mul	x8, x27, x22
	sub	x11, x27, #1
	ldr	x0, [sp, #24]                   // 8-byte Folded Reload
	cmp	x26, #2
	mul	x15, x11, x10
	mov	w12, #2
	mul	x8, x8, x21
	add	x18, x30, x19, lsl #5
	lsl	x9, x19, #5
	mov	w17, #16
	add	x16, x0, x15, lsl #4
	csel	x11, x26, x12, hi
	add	x15, x30, x8, lsl #5
	lsl	x8, x21, #4
	add	x12, x18, #16
	lsl	x13, x21, #5
	neg	x14, x9
	add	x16, x16, #8
	sub	x17, x17, x8
	add	x18, x18, #48
	add	x0, x0, #8
	sub	x1, x8, #16
	add	x2, x15, #48
	mov	w3, #1
	b	.LBB136_78
.LBB136_77:                             //   in Loop: Header=BB136_78 Depth=1
	add	x3, x3, #1
	add	x12, x12, x9
	add	x15, x15, x14
	add	x16, x16, x17
	add	x18, x18, x9
	add	x0, x0, x1
	add	x2, x2, x14
	mov	x27, x4
	cmp	x3, x11
	b.eq	.LBB136_73
.LBB136_78:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB136_84 Depth 2
                                        //     Child Loop BB136_80 Depth 2
                                        //       Child Loop BB136_81 Depth 3
	sub	x4, x27, #1
	cmp	x21, #1
	b.ls	.LBB136_83
// %bb.79:                              //   in Loop: Header=BB136_78 Depth=1
	mul	x5, x3, x22
	mov	x8, xzr
	mul	x6, x27, x22
	mov	x7, x2
	mov	x20, x18
.LBB136_80:                             //   Parent Loop BB136_78 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB136_81 Depth 3
	add	x19, x8, x5
	add	x22, x8, x6
	mov	x23, x0
	mov	x24, x20
	mul	x19, x19, x21
	mov	x25, x16
	mul	x22, x22, x21
	mov	x26, x10
	add	x19, x30, x19, lsl #5
	add	x27, x30, x22, lsl #5
	mov	x22, x7
	ldp	q0, q1, [x19]
	ldp	q2, q3, [x27]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x19]
	stp	q0, q1, [x27]
.LBB136_81:                             //   Parent Loop BB136_78 Depth=1
                                        //     Parent Loop BB136_80 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q0, [x24, #-16]
	subs	x26, x26, #1
	ldp	q3, q1, [x22, #-16]
	fadd	v7.2d, v2.2d, v3.2d
	fsub	v2.2d, v2.2d, v3.2d
	fadd	v4.2d, v0.2d, v1.2d
	fsub	v0.2d, v0.2d, v1.2d
	ldp	d5, d1, [x23, #-8]
	add	x23, x23, #16
	ldp	d3, d6, [x25, #-8]
	fneg	v16.2d, v4.2d
	add	x25, x25, #16
	fneg	v17.2d, v0.2d
	fmul	v4.2d, v4.2d, v5.d[0]
	fmul	v0.2d, v0.2d, v3.d[0]
	fmul	v16.2d, v16.2d, v1.d[0]
	fmul	v17.2d, v17.2d, v6.d[0]
	fmla	v4.2d, v7.2d, v1.d[0]
	fmla	v0.2d, v2.2d, v6.d[0]
	fmla	v16.2d, v7.2d, v5.d[0]
	fmla	v17.2d, v2.2d, v3.d[0]
	stp	q16, q4, [x24, #-16]
	add	x24, x24, #32
	stp	q17, q0, [x22, #-16]
	add	x22, x22, #32
	b.ne	.LBB136_81
// %bb.82:                              //   in Loop: Header=BB136_80 Depth=2
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	add	x8, x8, #1
	add	x20, x20, x13
	add	x7, x7, x13
	cmp	x8, x22
	b.ne	.LBB136_80
	b	.LBB136_77
.LBB136_83:                             //   in Loop: Header=BB136_78 Depth=1
	mov	x8, xzr
	mov	x5, x22
.LBB136_84:                             //   Parent Loop BB136_78 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x6, x12, x8
	add	x7, x15, x8
	subs	x5, x5, #1
	add	x8, x8, x13
	ldp	q0, q1, [x6, #-16]
	ldp	q2, q3, [x7]
	fadd	v4.2d, v0.2d, v2.2d
	fsub	v0.2d, v0.2d, v2.2d
	fadd	v5.2d, v1.2d, v3.2d
	fsub	v1.2d, v1.2d, v3.2d
	stp	q4, q5, [x6, #-16]
	stp	q0, q1, [x7]
	b.ne	.LBB136_84
	b	.LBB136_77
.LBB136_85:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end136:
	.size	_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_, .Lfunc_end136-_ZNK9pocketfft6detail5cfftpIdE5passgILb0ENS0_5cmplxIDv2_dEEEEvmmmPT0_S8_PKNS4_IdEESB_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd // -- Begin function _ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd,@function
_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd: // @_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd
.Lfunc_begin44:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception44
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x21, x1
                                        // kill: def $d0 killed $d0 def $q0
	str	q0, [sp]                        // 16-byte Folded Spill
	cbz	x22, .LBB137_4
// %bb.1:
	lsl	x8, x22, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB137_21
// %bb.2:
	add	x8, x0, #64
	and	x20, x8, #0xffffffffffffffc0
	stur	x0, [x20, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB137_5
.LBB137_3:
	cmp	x8, x22
	b.lo	.LBB137_8
	b	.LBB137_10
.LBB137_4:
	mov	x20, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB137_3
.LBB137_5:
	mov	x9, xzr
	mov	x10, xzr
	add	x11, x21, #16
	add	x12, x20, #16
.LBB137_6:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #80]
	add	x10, x10, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x8, x8, x9
	add	x9, x9, #16
	fneg	v3.2d, v0.2d
	ld1r	{ v1.2d }, [x8], #8
	ldr	d4, [x8]
	fmul	v5.2d, v2.2d, v4.d[0]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v5.2d, v1.2d, v0.2d
	fmla	v3.2d, v1.2d, v2.2d
	stp	q5, q3, [x12, #-16]
	add	x12, x12, #32
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB137_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB137_10
.LBB137_8:
	ldp	q0, q2, [x20]
	movi	v1.2d, #0000000000000000
	add	x9, x20, x8, lsl #5
	add	x9, x9, #16
	fmul	v0.2d, v0.2d, v1.2d
	fmul	v1.2d, v2.2d, v1.2d
.LBB137_9:                              // =>This Inner Loop Header: Depth=1
	stp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	ldr	x10, [x19, #8]
	add	x9, x9, #32
	cmp	x8, x10
	b.lo	.LBB137_9
.LBB137_10:
	add	x22, x19, #16
.Ltmp629:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d
.Ltmp630:
// %bb.11:
	ldr	x8, [x19, #88]
	ldp	q0, q2, [x20]
	ld1r	{ v1.2d }, [x8], #8
	fneg	v3.2d, v2.2d
	fmul	v2.2d, v2.2d, v1.2d
	ldr	d4, [x8]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v2.2d, v0.2d, v4.d[0]
	fmla	v3.2d, v1.2d, v0.2d
	stp	q3, q2, [x20]
	ldr	x12, [x19, #8]
	sub	x8, x12, #3
	cmn	x8, #5
	b.hi	.LBB137_14
// %bb.12:
	mov	x8, xzr
	add	x9, x20, #48
	mov	x10, #-1
	mov	w11, #1
.LBB137_13:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #88]
	add	x11, x11, #1
	ldp	q4, q0, [x9, #-16]
	add	x12, x12, x8
	ldp	d3, d2, [x12, #16]
	fneg	v1.2d, v0.2d
	fmul	v0.2d, v0.2d, v3.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	fmla	v0.2d, v4.2d, v2.d[0]
	fmla	v1.2d, v4.2d, v3.d[0]
	stp	q1, q0, [x9, #-16]
	add	x9, x9, #32
	ldr	x12, [x19, #8]
	ldr	x13, [x19, #88]
	add	x12, x10, x12
	sub	x10, x10, #1
	add	x13, x13, x8
	add	x8, x8, #16
	add	x12, x20, x12, lsl #5
	ldp	d3, d2, [x13, #16]
	ldp	q4, q0, [x12]
	fneg	v1.2d, v0.2d
	fmul	v0.2d, v0.2d, v3.d[0]
	fmul	v1.2d, v1.2d, v2.d[0]
	fmla	v0.2d, v4.2d, v2.d[0]
	fmla	v1.2d, v4.2d, v3.d[0]
	stp	q1, q0, [x12]
	ldr	x12, [x19, #8]
	add	x13, x12, #1
	cmp	x11, x13, lsr #1
	b.lo	.LBB137_13
.LBB137_14:
	tbnz	w12, #0, .LBB137_16
// %bb.15:
	lsr	x8, x12, #1
	ldr	x9, [x19, #88]
	add	x10, x20, x8, lsl #5
	add	x8, x9, x8, lsl #4
	ldp	q0, q2, [x10]
	ld1r	{ v1.2d }, [x8], #8
	fneg	v3.2d, v2.2d
	fmul	v2.2d, v2.2d, v1.2d
	ldr	d4, [x8]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v2.2d, v0.2d, v4.d[0]
	fmla	v3.2d, v1.2d, v0.2d
	stp	q3, q2, [x10]
.LBB137_16:
.Ltmp631:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d
.Ltmp632:
// %bb.17:
	ldr	x8, [x19]
	ldr	q6, [sp]                        // 16-byte Folded Reload
	cbz	x8, .LBB137_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
	add	x10, x21, #16
	add	x11, x20, #16
.LBB137_19:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #80]
	add	x9, x9, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x12, x12, x8
	add	x8, x8, #16
	fneg	v3.2d, v0.2d
	ld1r	{ v1.2d }, [x12], #8
	ldr	d4, [x12]
	fmul	v5.2d, v2.2d, v4.d[0]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v5.2d, v1.2d, v0.2d
	fmla	v3.2d, v1.2d, v2.2d
	fmul	v0.2d, v5.2d, v6.d[0]
	fmul	v1.2d, v3.2d, v6.d[0]
	stp	q0, q1, [x10, #-16]
	add	x10, x10, #32
	ldr	x12, [x19]
	cmp	x9, x12
	b.lo	.LBB137_19
.LBB137_20:
	ldur	x0, [x20, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	b	free
.LBB137_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB137_22:
.Ltmp633:
	mov	x19, x0
	ldur	x0, [x20, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end137:
	.size	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd, .Lfunc_end137-_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb1EDv2_dEEvPNS0_5cmplxIT0_EEd,comdat
	.p2align	2
GCC_except_table137:
.Lexception44:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end44-.Lcst_begin44
.Lcst_begin44:
	.uleb128 .Ltmp629-.Lfunc_begin44        // >> Call Site 1 <<
	.uleb128 .Ltmp632-.Ltmp629              //   Call between .Ltmp629 and .Ltmp632
	.uleb128 .Ltmp633-.Lfunc_begin44        //     jumps to .Ltmp633
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp632-.Lfunc_begin44        // >> Call Site 2 <<
	.uleb128 .Lfunc_end137-.Ltmp632         //   Call between .Ltmp632 and .Lfunc_end137
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end44:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd // -- Begin function _ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd,@function
_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd: // @_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd
.Lfunc_begin45:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception45
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x21, x1
                                        // kill: def $d0 killed $d0 def $q0
	str	q0, [sp]                        // 16-byte Folded Spill
	cbz	x22, .LBB138_4
// %bb.1:
	lsl	x8, x22, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB138_21
// %bb.2:
	add	x8, x0, #64
	and	x20, x8, #0xffffffffffffffc0
	stur	x0, [x20, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB138_5
.LBB138_3:
	cmp	x8, x22
	b.lo	.LBB138_8
	b	.LBB138_10
.LBB138_4:
	mov	x20, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB138_3
.LBB138_5:
	mov	x9, xzr
	mov	x10, xzr
	add	x11, x21, #16
	add	x12, x20, #16
.LBB138_6:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #80]
	add	x10, x10, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x8, x8, x9
	add	x9, x9, #16
	ld1r	{ v1.2d }, [x8], #8
	fneg	v3.2d, v2.2d
	fmul	v2.2d, v2.2d, v1.2d
	ldr	d4, [x8]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v2.2d, v0.2d, v4.d[0]
	fmla	v3.2d, v1.2d, v0.2d
	stp	q3, q2, [x12, #-16]
	add	x12, x12, #32
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB138_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB138_10
.LBB138_8:
	ldp	q0, q2, [x20]
	movi	v1.2d, #0000000000000000
	add	x9, x20, x8, lsl #5
	add	x9, x9, #16
	fmul	v0.2d, v0.2d, v1.2d
	fmul	v1.2d, v2.2d, v1.2d
.LBB138_9:                              // =>This Inner Loop Header: Depth=1
	stp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	ldr	x10, [x19, #8]
	add	x9, x9, #32
	cmp	x8, x10
	b.lo	.LBB138_9
.LBB138_10:
	add	x22, x19, #16
.Ltmp634:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIDv2_dEEEEvPT0_d
.Ltmp635:
// %bb.11:
	ldr	x8, [x19, #88]
	ldp	q0, q2, [x20]
	fneg	v3.2d, v0.2d
	ld1r	{ v1.2d }, [x8], #8
	ldr	d4, [x8]
	fmul	v5.2d, v2.2d, v4.d[0]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v5.2d, v1.2d, v0.2d
	fmla	v3.2d, v1.2d, v2.2d
	stp	q5, q3, [x20]
	ldr	x12, [x19, #8]
	sub	x8, x12, #3
	cmn	x8, #5
	b.hi	.LBB138_14
// %bb.12:
	mov	x8, xzr
	add	x9, x20, #48
	mov	x10, #-1
	mov	w11, #1
.LBB138_13:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #88]
	add	x11, x11, #1
	ldp	q0, q1, [x9, #-16]
	add	x12, x12, x8
	fneg	v2.2d, v0.2d
	ldp	d5, d3, [x12, #16]
	fmul	v4.2d, v1.2d, v3.d[0]
	fmul	v2.2d, v2.2d, v3.d[0]
	fmla	v4.2d, v0.2d, v5.d[0]
	fmla	v2.2d, v1.2d, v5.d[0]
	stp	q4, q2, [x9, #-16]
	add	x9, x9, #32
	ldr	x12, [x19, #8]
	ldr	x13, [x19, #88]
	add	x12, x10, x12
	sub	x10, x10, #1
	add	x13, x13, x8
	add	x8, x8, #16
	add	x12, x20, x12, lsl #5
	ldp	d5, d2, [x13, #16]
	ldp	q0, q1, [x12]
	fneg	v3.2d, v0.2d
	fmul	v4.2d, v1.2d, v2.d[0]
	fmul	v2.2d, v3.2d, v2.d[0]
	fmla	v4.2d, v0.2d, v5.d[0]
	fmla	v2.2d, v1.2d, v5.d[0]
	stp	q4, q2, [x12]
	ldr	x12, [x19, #8]
	add	x13, x12, #1
	cmp	x11, x13, lsr #1
	b.lo	.LBB138_13
.LBB138_14:
	tbnz	w12, #0, .LBB138_16
// %bb.15:
	lsr	x8, x12, #1
	ldr	x9, [x19, #88]
	add	x10, x20, x8, lsl #5
	add	x8, x9, x8, lsl #4
	ldp	q0, q2, [x10]
	fneg	v3.2d, v0.2d
	ld1r	{ v1.2d }, [x8], #8
	ldr	d4, [x8]
	fmul	v5.2d, v2.2d, v4.d[0]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v5.2d, v1.2d, v0.2d
	fmla	v3.2d, v1.2d, v2.2d
	stp	q5, q3, [x10]
.LBB138_16:
.Ltmp636:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIDv2_dEEEEvPT0_d
.Ltmp637:
// %bb.17:
	ldr	x8, [x19]
	ldr	q5, [sp]                        // 16-byte Folded Reload
	cbz	x8, .LBB138_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
	add	x10, x21, #16
	add	x11, x20, #16
.LBB138_19:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #80]
	add	x9, x9, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x12, x12, x8
	add	x8, x8, #16
	ld1r	{ v1.2d }, [x12], #8
	fneg	v3.2d, v2.2d
	fmul	v2.2d, v2.2d, v1.2d
	ldr	d4, [x12]
	fmul	v3.2d, v3.2d, v4.d[0]
	fmla	v2.2d, v0.2d, v4.d[0]
	fmla	v3.2d, v1.2d, v0.2d
	fmul	v1.2d, v2.2d, v5.d[0]
	fmul	v0.2d, v3.2d, v5.d[0]
	stp	q0, q1, [x10, #-16]
	add	x10, x10, #32
	ldr	x12, [x19]
	cmp	x9, x12
	b.lo	.LBB138_19
.LBB138_20:
	ldur	x0, [x20, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	b	free
.LBB138_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB138_22:
.Ltmp638:
	mov	x19, x0
	ldur	x0, [x20, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end138:
	.size	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd, .Lfunc_end138-_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb0EDv2_dEEvPNS0_5cmplxIT0_EEd,comdat
	.p2align	2
GCC_except_table138:
.Lexception45:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end45-.Lcst_begin45
.Lcst_begin45:
	.uleb128 .Ltmp634-.Lfunc_begin45        // >> Call Site 1 <<
	.uleb128 .Ltmp637-.Ltmp634              //   Call between .Ltmp634 and .Ltmp637
	.uleb128 .Ltmp638-.Lfunc_begin45        //     jumps to .Ltmp638
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp637-.Lfunc_begin45        // >> Call Site 2 <<
	.uleb128 .Lfunc_end138-.Ltmp637         //   Call between .Ltmp637 and .Lfunc_end138
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end45:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb,"axG",@progbits,_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb,comdat
	.weak	_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb // -- Begin function _ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb
	.p2align	2
	.type	_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb,@function
_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb: // @_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	ldr	x0, [x0]
	cbz	x0, .LBB139_3
// %bb.1:
	tbz	w2, #0, .LBB139_5
// %bb.2:
	b	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
.LBB139_3:
	ldr	x0, [x8, #8]
	tbz	w2, #0, .LBB139_6
// %bb.4:
	b	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd
.LBB139_5:
	b	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d
.LBB139_6:
	b	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd
.Lfunc_end139:
	.size	_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb, .Lfunc_end139-_ZNK9pocketfft6detail11pocketfft_cIdE4execIdEEvPNS0_5cmplxIT_EEdb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd // -- Begin function _ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd,@function
_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd: // @_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd
.Lfunc_begin46:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception46
// %bb.0:
	str	d8, [sp, #-64]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -64
	fmov	d8, d0
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x20, x1
	cbz	x22, .LBB140_4
// %bb.1:
	lsl	x8, x22, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB140_21
// %bb.2:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB140_5
.LBB140_3:
	cmp	x8, x22
	b.lo	.LBB140_8
	b	.LBB140_10
.LBB140_4:
	mov	x21, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB140_3
.LBB140_5:
	mov	x9, xzr
	mov	x10, xzr
.LBB140_6:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #80]
	add	x11, x20, x9
	add	x10, x10, #1
	add	x8, x8, x9
	ldp	d0, d1, [x11]
	ldp	d5, d2, [x8]
	add	x8, x21, x9
	add	x9, x9, #16
	fneg	d3, d0
	fmul	d4, d1, d2
	fmul	d2, d2, d3
	fmadd	d0, d0, d5, d4
	fmadd	d1, d1, d5, d2
	str	d0, [x8]
	str	d1, [x8, #8]
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB140_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB140_10
.LBB140_8:
	movi	v0.2d, #0000000000000000
	ldr	q1, [x21]
	fmul	v0.2d, v1.2d, v0.2d
.LBB140_9:                              // =>This Inner Loop Header: Depth=1
	str	q0, [x21, x8, lsl #4]
	add	x8, x8, #1
	ldr	x9, [x19, #8]
	cmp	x8, x9
	b.lo	.LBB140_9
.LBB140_10:
	add	x22, x19, #16
.Ltmp639:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
.Ltmp640:
// %bb.11:
	ldp	d4, d0, [x21]
	ldr	x8, [x19, #88]
	ldp	d3, d2, [x8]
	fneg	d1, d0
	fmul	d0, d3, d0
	fmul	d1, d2, d1
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d3, d1
	str	d0, [x21, #8]
	str	d1, [x21]
	ldr	x11, [x19, #8]
	sub	x8, x11, #3
	cmn	x8, #5
	b.hi	.LBB140_14
// %bb.12:
	mov	x8, xzr
	mov	x9, #-1
	mov	w10, #1
.LBB140_13:                             // =>This Inner Loop Header: Depth=1
	add	x11, x21, x8
	ldr	x12, [x19, #88]
	add	x10, x10, #1
	ldp	d4, d0, [x11, #16]
	add	x12, x12, x8
	ldp	d3, d2, [x12, #16]
	fneg	d1, d0
	fmul	d0, d3, d0
	fmul	d1, d2, d1
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d3, d1
	stp	d1, d0, [x11, #16]
	ldr	x11, [x19, #8]
	ldr	x12, [x19, #88]
	add	x11, x9, x11
	sub	x9, x9, #1
	add	x12, x12, x8
	add	x8, x8, #16
	add	x11, x21, x11, lsl #4
	ldp	d3, d2, [x12, #16]
	ldp	d4, d0, [x11]
	fneg	d1, d0
	fmul	d0, d3, d0
	fmul	d1, d2, d1
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d3, d1
	stp	d1, d0, [x11]
	ldr	x11, [x19, #8]
	add	x12, x11, #1
	cmp	x10, x12, lsr #1
	b.lo	.LBB140_13
.LBB140_14:
	tbnz	w11, #0, .LBB140_16
// %bb.15:
	lsl	x8, x11, #3
	ldr	x10, [x19, #88]
	and	x8, x8, #0xfffffffffffffff0
	add	x9, x21, x8
	add	x8, x10, x8
	ldp	d4, d0, [x9]
	ldp	d3, d2, [x8]
	fneg	d1, d0
	fmul	d0, d3, d0
	fmul	d1, d2, d1
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d3, d1
	str	d0, [x9, #8]
	str	d1, [x9]
.LBB140_16:
.Ltmp641:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d
.Ltmp642:
// %bb.17:
	ldr	x8, [x19]
	cbz	x8, .LBB140_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
.LBB140_19:                             // =>This Inner Loop Header: Depth=1
	ldr	x10, [x19, #80]
	add	x11, x21, x8
	add	x9, x9, #1
	add	x10, x10, x8
	ldp	d0, d1, [x11]
	ldp	d5, d2, [x10]
	add	x10, x20, x8
	add	x8, x8, #16
	fneg	d3, d0
	fmul	d4, d1, d2
	fmul	d2, d2, d3
	fmadd	d0, d0, d5, d4
	fmadd	d1, d1, d5, d2
	fmul	d0, d0, d8
	fmul	d1, d1, d8
	str	d0, [x10]
	str	d1, [x10, #8]
	ldr	x10, [x19]
	cmp	x9, x10
	b.lo	.LBB140_19
.LBB140_20:
	ldur	x0, [x21, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	b	free
.LBB140_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB140_22:
.Ltmp643:
	mov	x19, x0
	ldur	x0, [x21, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end140:
	.size	_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd, .Lfunc_end140-_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb1EdEEvPNS0_5cmplxIT0_EEd,comdat
	.p2align	2
GCC_except_table140:
.Lexception46:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end46-.Lcst_begin46
.Lcst_begin46:
	.uleb128 .Ltmp639-.Lfunc_begin46        // >> Call Site 1 <<
	.uleb128 .Ltmp642-.Ltmp639              //   Call between .Ltmp639 and .Ltmp642
	.uleb128 .Ltmp643-.Lfunc_begin46        //     jumps to .Ltmp643
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp642-.Lfunc_begin46        // >> Call Site 2 <<
	.uleb128 .Lfunc_end140-.Ltmp642         //   Call between .Ltmp642 and .Lfunc_end140
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end46:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd // -- Begin function _ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd,@function
_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd: // @_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd
.Lfunc_begin47:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception47
// %bb.0:
	str	d8, [sp, #-64]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -64
	fmov	d8, d0
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x20, x1
	cbz	x22, .LBB141_4
// %bb.1:
	lsl	x8, x22, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB141_21
// %bb.2:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB141_5
.LBB141_3:
	cmp	x8, x22
	b.lo	.LBB141_8
	b	.LBB141_10
.LBB141_4:
	mov	x21, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB141_3
.LBB141_5:
	mov	x9, xzr
	mov	x10, xzr
.LBB141_6:                              // =>This Inner Loop Header: Depth=1
	add	x8, x20, x9
	ldr	x11, [x19, #80]
	add	x10, x10, #1
	ldp	d4, d0, [x8]
	add	x11, x11, x9
	add	x8, x21, x9
	add	x9, x9, #16
	ldp	d3, d2, [x11]
	fneg	d1, d0
	fmul	d0, d3, d0
	fmul	d1, d2, d1
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d3, d1
	str	d0, [x8, #8]
	str	d1, [x8]
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB141_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB141_10
.LBB141_8:
	movi	v0.2d, #0000000000000000
	ldr	q1, [x21]
	fmul	v0.2d, v1.2d, v0.2d
.LBB141_9:                              // =>This Inner Loop Header: Depth=1
	str	q0, [x21, x8, lsl #4]
	add	x8, x8, #1
	ldr	x9, [x19, #8]
	cmp	x8, x9
	b.lo	.LBB141_9
.LBB141_10:
	add	x22, x19, #16
.Ltmp644:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb1ENS0_5cmplxIdEEEEvPT0_d
.Ltmp645:
// %bb.11:
	ldr	x8, [x19, #88]
	ldp	d0, d1, [x21]
	ldp	d5, d2, [x8]
	fneg	d3, d0
	fmul	d4, d1, d2
	fmul	d2, d2, d3
	fmadd	d0, d0, d5, d4
	fmadd	d1, d1, d5, d2
	str	d0, [x21]
	str	d1, [x21, #8]
	ldr	x11, [x19, #8]
	sub	x8, x11, #3
	cmn	x8, #5
	b.hi	.LBB141_14
// %bb.12:
	mov	x8, xzr
	mov	x9, #-1
	mov	w10, #1
.LBB141_13:                             // =>This Inner Loop Header: Depth=1
	ldr	x11, [x19, #88]
	add	x12, x21, x8
	add	x10, x10, #1
	add	x11, x11, x8
	ldp	d0, d1, [x12, #16]
	ldp	d5, d2, [x11, #16]
	fneg	d3, d0
	fmul	d4, d1, d2
	fmul	d2, d2, d3
	fmadd	d0, d0, d5, d4
	fmadd	d1, d1, d5, d2
	stp	d0, d1, [x12, #16]
	ldr	x11, [x19, #8]
	ldr	x12, [x19, #88]
	add	x11, x9, x11
	sub	x9, x9, #1
	add	x12, x12, x8
	add	x8, x8, #16
	add	x11, x21, x11, lsl #4
	ldp	d5, d2, [x12, #16]
	ldp	d0, d1, [x11]
	fneg	d3, d0
	fmul	d4, d1, d2
	fmul	d2, d2, d3
	fmadd	d0, d0, d5, d4
	fmadd	d1, d1, d5, d2
	stp	d0, d1, [x11]
	ldr	x11, [x19, #8]
	add	x12, x11, #1
	cmp	x10, x12, lsr #1
	b.lo	.LBB141_13
.LBB141_14:
	tbnz	w11, #0, .LBB141_16
// %bb.15:
	lsl	x8, x11, #3
	ldr	x9, [x19, #88]
	and	x8, x8, #0xfffffffffffffff0
	add	x10, x21, x8
	add	x8, x9, x8
	ldp	d0, d1, [x10]
	ldp	d5, d2, [x8]
	fneg	d3, d0
	fmul	d4, d1, d2
	fmul	d2, d2, d3
	fmadd	d0, d0, d5, d4
	fmadd	d1, d1, d5, d2
	str	d0, [x10]
	str	d1, [x10, #8]
.LBB141_16:
.Ltmp646:
	fmov	d0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIdE8pass_allILb0ENS0_5cmplxIdEEEEvPT0_d
.Ltmp647:
// %bb.17:
	ldr	x8, [x19]
	cbz	x8, .LBB141_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
.LBB141_19:                             // =>This Inner Loop Header: Depth=1
	add	x10, x21, x8
	ldr	x11, [x19, #80]
	add	x9, x9, #1
	ldp	d4, d0, [x10]
	add	x11, x11, x8
	add	x10, x20, x8
	add	x8, x8, #16
	ldp	d3, d2, [x11]
	fneg	d1, d0
	fmul	d0, d3, d0
	fmul	d1, d2, d1
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d3, d1
	fmul	d0, d0, d8
	fmul	d1, d1, d8
	str	d0, [x10, #8]
	str	d1, [x10]
	ldr	x10, [x19]
	cmp	x9, x10
	b.lo	.LBB141_19
.LBB141_20:
	ldur	x0, [x21, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	b	free
.LBB141_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB141_22:
.Ltmp648:
	mov	x19, x0
	ldur	x0, [x21, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end141:
	.size	_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd, .Lfunc_end141-_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIdE3fftILb0EdEEvPNS0_5cmplxIT0_EEd,comdat
	.p2align	2
GCC_except_table141:
.Lexception47:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end47-.Lcst_begin47
.Lcst_begin47:
	.uleb128 .Ltmp644-.Lfunc_begin47        // >> Call Site 1 <<
	.uleb128 .Ltmp647-.Ltmp644              //   Call between .Ltmp644 and .Ltmp647
	.uleb128 .Ltmp648-.Lfunc_begin47        //     jumps to .Ltmp648
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp647-.Lfunc_begin47        // >> Call Site 2 <<
	.uleb128 .Lfunc_end141-.Ltmp647         //   Call between .Ltmp647 and .Lfunc_end141
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end47:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,"axG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,comdat
	.weak	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data // -- Begin function _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.p2align	2
	.type	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,@function
_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data: // @_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.cfi_startproc
// %bb.0:
	ldr	x0, [x0]
	b	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
.Lfunc_end142:
	.size	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data, .Lfunc_end142-_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,"axG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,comdat
	.weak	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation // -- Begin function _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.p2align	2
	.type	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,@function
_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation: // @_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	cmp	w2, #3
	b.hi	.LBB143_3
// %bb.1:
	adrp	x9, .LJTI143_0
	mov	w8, w2
	add	x9, x9, :lo12:.LJTI143_0
	mov	x19, x0
	adr	x10, .LBB143_2
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB143_2:
	adrp	x8, _ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	add	x8, x8, :lo12:_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	str	x8, [x19]
.LBB143_3:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB143_4:
	ldr	x8, [x1]
	str	x8, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB143_5:
	mov	w0, #48
	ldr	x20, [x1]
	bl	_Znwm
	ldp	q0, q1, [x20]
	ldr	q2, [x20, #32]
	stp	q0, q1, [x0]
	str	x0, [x19]
	str	q2, [x0, #32]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB143_6:
	ldr	x0, [x19]
	cbz	x0, .LBB143_3
// %bb.7:
	bl	_ZdlPv
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end143:
	.size	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation, .Lfunc_end143-_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.cfi_endproc
	.section	.rodata._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,"aG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,comdat
.LJTI143_0:
	.byte	(.LBB143_2-.LBB143_2)>>2
	.byte	(.LBB143_4-.LBB143_2)>>2
	.byte	(.LBB143_5-.LBB143_2)>>2
	.byte	(.LBB143_6-.LBB143_2)>>2
                                        // -- End function
	.section	.text._ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,"axG",@progbits,_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,comdat
	.weak	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv // -- Begin function _ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
	.p2align	2
	.type	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,@function
_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv: // @_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
.Lfunc_begin48:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception48
// %bb.0:
	sub	sp, sp, #48
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mrs	x8, TPIDR_EL0
	mov	x19, x0
	ldp	x10, x11, [x0, #32]
	add	x9, x8, :tprel_hi12:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x8, x8, :tprel_hi12:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	add	x9, x9, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x8, x8, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	ldr	x0, [x0]
	str	x10, [x9]
	str	x11, [x8]
.Ltmp649:
	bl	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.Ltmp650:
// %bb.1:
	ldr	x20, [x19, #8]
	add	x19, x20, #8
	mov	x0, x19
	bl	pthread_mutex_lock
	cbnz	w0, .LBB144_11
.LBB144_2:
	mov	x0, #-1
	mov	x1, x20
	bl	__aarch64_ldadd8_acq_rel
	cmp	x0, #1
	b.ne	.LBB144_4
// %bb.3:
	add	x0, x20, #56
	bl	_ZNSt18condition_variable10notify_allEv
.LBB144_4:
	mov	x0, x19
	bl	pthread_mutex_unlock
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #48
	ret
.LBB144_5:
.Ltmp651:
	bl	__cxa_begin_catch
	ldr	x20, [x19, #24]
	mov	x0, x20
	bl	pthread_mutex_lock
	cbnz	w0, .LBB144_12
// %bb.6:
	mov	x8, sp
	bl	_ZSt17current_exceptionv
	ldr	x8, [x19, #16]
	ldr	x9, [sp]
	str	xzr, [sp]
	ldr	x10, [x8]
	str	x10, [sp, #8]
	str	x9, [x8]
	cbz	x10, .LBB144_8
// %bb.7:
	add	x0, sp, #8
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB144_8:
	ldr	x8, [sp]
	cbz	x8, .LBB144_10
// %bb.9:
	mov	x0, sp
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB144_10:
	mov	x0, x20
	bl	pthread_mutex_unlock
	bl	__cxa_end_catch
	ldr	x20, [x19, #8]
	add	x19, x20, #8
	mov	x0, x19
	bl	pthread_mutex_lock
	cbz	w0, .LBB144_2
.LBB144_11:
	bl	_ZSt20__throw_system_errori
.LBB144_12:
.Ltmp652:
	bl	_ZSt20__throw_system_errori
.Ltmp653:
// %bb.13:
.LBB144_14:
.Ltmp654:
	mov	x19, x0
.Ltmp655:
	bl	__cxa_end_catch
.Ltmp656:
// %bb.15:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB144_16:
.Ltmp657:
	bl	__clang_call_terminate
.Lfunc_end144:
	.size	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv, .Lfunc_end144-_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
	.cfi_endproc
	.section	.gcc_except_table._ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,"aG",@progbits,_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,comdat
	.p2align	2
GCC_except_table144:
.Lexception48:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase12-.Lttbaseref12
.Lttbaseref12:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end48-.Lcst_begin48
.Lcst_begin48:
	.uleb128 .Ltmp649-.Lfunc_begin48        // >> Call Site 1 <<
	.uleb128 .Ltmp650-.Ltmp649              //   Call between .Ltmp649 and .Ltmp650
	.uleb128 .Ltmp651-.Lfunc_begin48        //     jumps to .Ltmp651
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp650-.Lfunc_begin48        // >> Call Site 2 <<
	.uleb128 .Ltmp652-.Ltmp650              //   Call between .Ltmp650 and .Ltmp652
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp652-.Lfunc_begin48        // >> Call Site 3 <<
	.uleb128 .Ltmp653-.Ltmp652              //   Call between .Ltmp652 and .Ltmp653
	.uleb128 .Ltmp654-.Lfunc_begin48        //     jumps to .Ltmp654
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp655-.Lfunc_begin48        // >> Call Site 4 <<
	.uleb128 .Ltmp656-.Ltmp655              //   Call between .Ltmp655 and .Ltmp656
	.uleb128 .Ltmp657-.Lfunc_begin48        //     jumps to .Ltmp657
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp656-.Lfunc_begin48        // >> Call Site 5 <<
	.uleb128 .Lfunc_end144-.Ltmp656         //   Call between .Ltmp656 and .Lfunc_end144
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end48:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase12:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,"axG",@progbits,_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,comdat
	.weak	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b // -- Begin function _ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
	.p2align	2
	.type	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,@function
_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b: // @_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
.Lfunc_begin49:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception49
// %bb.0:
	sub	sp, sp, #224
	str	d8, [sp, #112]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #128]            // 16-byte Folded Spill
	add	x29, sp, #128
	stp	x28, x27, [sp, #144]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #160]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #176]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	ldp	x8, x9, [x2]
	sturb	w5, [x29, #-8]
	stur	s0, [x29, #-4]
	stp	xzr, xzr, [x29, #-32]
	stur	xzr, [x29, #-40]
	cmp	x9, x8
	b.eq	.LBB145_36
// %bb.1:
	movi	v8.2s, #1
	mov	x19, x4
	mov	x20, x2
	mov	x21, x3
	mov	x22, x1
	mov	x23, x0
	mov	x10, xzr
	mov	x9, xzr
	sub	x28, x29, #8
	mov	w27, #1065353216
	ldr	x8, [x8, x9, lsl #3]
	ldr	x9, [x23]
	ldr	x24, [x9, x8, lsl #3]
	stur	x24, [x29, #-48]
	cbz	x10, .LBB145_3
.LBB145_2:
	ldr	x8, [x10, #16]
	cmp	x24, x8
	b.eq	.LBB145_12
.LBB145_3:
.Ltmp658:
	mov	w0, #40
	bl	_Znwm
.Ltmp659:
// %bb.4:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x26, x0, #16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
.Ltmp661:
	mov	x0, x26
	mov	x1, x24
	bl	_ZN9pocketfft6detail11pocketfft_cIfEC2Em
.Ltmp662:
// %bb.5:
	ldur	x24, [x29, #-24]
	stp	x26, x25, [x29, #-32]
	cbz	x24, .LBB145_12
// %bb.6:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB145_8
// %bb.7:
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB145_9
	b	.LBB145_12
.LBB145_8:
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB145_12
.LBB145_9:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB145_28
// %bb.10:
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB145_12
.LBB145_11:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB145_12:
	cmp	x21, #1
	b.ne	.LBB145_14
// %bb.13:
	mov	w0, #1
	b	.LBB145_25
.LBB145_14:
	ldp	x8, x9, [x23]
	cmp	x8, x9
	b.eq	.LBB145_17
// %bb.15:
	sub	x10, x9, x8
	sub	x10, x10, #8
	cmp	x10, #8
	b.hs	.LBB145_18
// %bb.16:
	mov	w11, #1
	mov	x10, x8
	b	.LBB145_21
.LBB145_17:
	mov	w11, #1
	b	.LBB145_22
.LBB145_18:
	lsr	x10, x10, #3
	add	x11, x8, #8
	add	x12, x10, #1
	mov	w15, #1
	and	x13, x12, #0x3ffffffffffffffe
	mov	w16, #1
	mov	x14, x13
	add	x10, x8, x13, lsl #3
.LBB145_19:                             // =>This Inner Loop Header: Depth=1
	ldp	x17, x18, [x11, #-8]
	add	x11, x11, #16
	subs	x14, x14, #2
	mul	x15, x17, x15
	mul	x16, x18, x16
	b.ne	.LBB145_19
// %bb.20:
	mul	x11, x16, x15
	cmp	x12, x13
	b.eq	.LBB145_22
.LBB145_21:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x10], #8
	cmp	x10, x9
	mul	x11, x12, x11
	b.ne	.LBB145_21
.LBB145_22:
	ldur	x9, [x29, #-40]
	ldr	x10, [x20]
	ldr	x9, [x10, x9, lsl #3]
	ldr	x8, [x8, x9, lsl #3]
	udiv	x9, x11, x8
	cmp	x8, #1000
	mov	x8, x21
	lsr	x10, x9, #2
	csel	x24, x10, x9, lo
	cbnz	x21, .LBB145_24
// %bb.23:
	bl	_ZNSt6thread20hardware_concurrencyEv
	mov	w8, w0
.LBB145_24:
	cmp	x8, x24
	csel	x8, x8, x24, lo
	cmp	x8, #1
	csinc	x0, x8, xzr, hi
.LBB145_25:
	sub	x8, x29, #48
	stp	x20, x19, [sp, #40]
	stp	x23, x8, [sp, #8]
	sub	x8, x29, #40
	stp	x8, x22, [sp, #24]
	sub	x8, x29, #32
	str	x8, [sp, #56]
	sub	x8, x29, #4
	stp	x8, x28, [sp, #64]
.Ltmp664:
	add	x1, sp, #8
	bl	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
.Ltmp665:
// %bb.26:
	ldp	x8, x10, [x20]
	stur	w27, [x29, #-4]
	ldur	x9, [x29, #-40]
	add	x9, x9, #1
	sub	x10, x10, x8
	cmp	x9, x10, asr #3
	stur	x9, [x29, #-40]
	b.hs	.LBB145_29
// %bb.27:
	ldur	x10, [x29, #-32]
	ldr	x8, [x8, x9, lsl #3]
	ldr	x9, [x23]
	ldr	x24, [x9, x8, lsl #3]
	stur	x24, [x29, #-48]
	cbnz	x10, .LBB145_2
	b	.LBB145_3
.LBB145_28:
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB145_11
	b	.LBB145_12
.LBB145_29:
	ldur	x19, [x29, #-24]
	cbz	x19, .LBB145_36
// %bb.30:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB145_32
// %bb.31:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB145_33
	b	.LBB145_36
.LBB145_32:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB145_36
.LBB145_33:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB145_37
// %bb.34:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB145_36
.LBB145_35:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB145_36:
	ldp	x20, x19, [sp, #208]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #160]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #128]            // 16-byte Folded Reload
	ldr	d8, [sp, #112]                  // 8-byte Folded Reload
	add	sp, sp, #224
	ret
.LBB145_37:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB145_35
	b	.LBB145_36
.LBB145_38:
.Ltmp660:
	b	.LBB145_41
.LBB145_39:
.Ltmp663:
	mov	x19, x0
	mov	x0, x25
	bl	_ZdlPv
	b	.LBB145_42
.LBB145_40:
.Ltmp666:
.LBB145_41:
	mov	x19, x0
.LBB145_42:
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end145:
	.size	_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b, .Lfunc_end145-_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,"aG",@progbits,_ZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_b,comdat
	.p2align	2
GCC_except_table145:
.Lexception49:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end49-.Lcst_begin49
.Lcst_begin49:
	.uleb128 .Ltmp658-.Lfunc_begin49        // >> Call Site 1 <<
	.uleb128 .Ltmp659-.Ltmp658              //   Call between .Ltmp658 and .Ltmp659
	.uleb128 .Ltmp660-.Lfunc_begin49        //     jumps to .Ltmp660
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp661-.Lfunc_begin49        // >> Call Site 2 <<
	.uleb128 .Ltmp662-.Ltmp661              //   Call between .Ltmp661 and .Ltmp662
	.uleb128 .Ltmp663-.Lfunc_begin49        //     jumps to .Ltmp663
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp662-.Lfunc_begin49        // >> Call Site 3 <<
	.uleb128 .Ltmp664-.Ltmp662              //   Call between .Ltmp662 and .Ltmp664
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp664-.Lfunc_begin49        // >> Call Site 4 <<
	.uleb128 .Ltmp665-.Ltmp664              //   Call between .Ltmp664 and .Ltmp665
	.uleb128 .Ltmp666-.Lfunc_begin49        //     jumps to .Ltmp666
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp665-.Lfunc_begin49        // >> Call Site 5 <<
	.uleb128 .Lfunc_end145-.Ltmp665         //   Call between .Ltmp665 and .Lfunc_end145
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end49:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail8arr_infoD2Ev,"axG",@progbits,_ZN9pocketfft6detail8arr_infoD2Ev,comdat
	.weak	_ZN9pocketfft6detail8arr_infoD2Ev // -- Begin function _ZN9pocketfft6detail8arr_infoD2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail8arr_infoD2Ev,@function
_ZN9pocketfft6detail8arr_infoD2Ev:      // @_ZN9pocketfft6detail8arr_infoD2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x0, [x0, #24]
	cbz	x0, .LBB146_2
// %bb.1:
	bl	_ZdlPv
.LBB146_2:
	ldr	x0, [x19]
	cbz	x0, .LBB146_4
// %bb.3:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	_ZdlPv
.LBB146_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end146:
	.size	_ZN9pocketfft6detail8arr_infoD2Ev, .Lfunc_end146-_ZN9pocketfft6detail8arr_infoD2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB147_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB147_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB147_4
	b	.LBB147_8
.LBB147_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB147_8
.LBB147_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB147_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB147_8
.LBB147_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB147_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB147_6
.LBB147_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end147:
	.size	_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end147-_ZNSt12__shared_ptrIN9pocketfft6detail11pocketfft_cIfEELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,"axG",@progbits,_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,comdat
	.weak	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ // -- Begin function _ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
	.p2align	2
	.type	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,@function
_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_: // @_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
.Lfunc_begin50:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception50
// %bb.0:
	sub	sp, sp, #336
	stp	x29, x30, [sp, #240]            // 16-byte Folded Spill
	add	x29, sp, #240
	stp	x28, x27, [sp, #256]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #272]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	adrp	x8, .L_MergedGlobals+8
	cmp	x0, #0
	mov	x20, x1
	ldr	x8, [x8, :lo12:.L_MergedGlobals+8]
	csel	x22, x8, x0, eq
	cmp	x22, #1
	b.ne	.LBB148_2
// %bb.1:
	mov	x0, x20
	ldp	x20, x19, [sp, #320]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #240]            // 16-byte Folded Reload
	add	sp, sp, #336
	b	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.LBB148_2:
	adrp	x8, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x8, x8, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	ldarb	w8, [x8]
	tbz	w8, #0, .LBB148_18
.LBB148_3:
	add	x23, sp, #112
	str	x22, [sp, #112]
	movi	v0.2d, #0000000000000000
	add	x19, x23, #56
	mov	x0, x19
	str	xzr, [sp, #152]
	stur	q0, [sp, #120]
	stur	q0, [sp, #136]
	bl	_ZNSt18condition_variableC1Ev
	movi	v0.2d, #0000000000000000
	str	xzr, [sp, #104]
	str	xzr, [sp, #80]
	stp	q0, q0, [sp, #48]
	cbz	x22, .LBB148_10
// %bb.4:
	adrp	x27, _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	adrp	x28, _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	adrp	x21, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	mov	x24, xzr
	add	x25, sp, #104
	add	x26, sp, #48
	add	x27, x27, :lo12:_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	add	x28, x28, :lo12:_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	add	x21, x21, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	b	.LBB148_6
.LBB148_5:                              //   in Loop: Header=BB148_6 Depth=1
	add	x24, x24, #1
	cmp	x22, x24
	b.eq	.LBB148_10
.LBB148_6:                              // =>This Inner Loop Header: Depth=1
	movi	v0.2d, #0000000000000000
	stp	q0, q0, [sp, #16]
.Ltmp670:
	mov	w0, #48
	bl	_Znwm
.Ltmp671:
// %bb.7:                               //   in Loop: Header=BB148_6 Depth=1
	stp	x20, x23, [x0]
	stp	x25, x26, [x0, #16]
	stp	x24, x22, [x0, #32]
	stp	x28, x27, [sp, #32]
	str	x0, [sp, #16]
.Ltmp673:
	add	x1, sp, #16
	mov	x0, x21
	bl	_ZN9pocketfft6detail9threading11thread_pool6submitESt8functionIFvvEE
.Ltmp674:
// %bb.8:                               //   in Loop: Header=BB148_6 Depth=1
	ldr	x8, [sp, #32]
	cbz	x8, .LBB148_5
// %bb.9:                               //   in Loop: Header=BB148_6 Depth=1
.Ltmp679:
	add	x0, sp, #16
	add	x1, sp, #16
	mov	w2, #3
	blr	x8
.Ltmp680:
	b	.LBB148_5
.LBB148_10:
	add	x0, x23, #8
	stur	x0, [x29, #-24]
	bl	pthread_mutex_lock
	cbnz	w0, .LBB148_21
// %bb.11:
	mov	w8, #1
	add	x20, sp, #112
	sturb	w8, [x29, #-16]
	ldar	x8, [x20]
	cbz	x8, .LBB148_13
.LBB148_12:                             // =>This Inner Loop Header: Depth=1
	sub	x1, x29, #24
	mov	x0, x19
	bl	_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE
	ldar	x8, [x20]
	cbnz	x8, .LBB148_12
.LBB148_13:
	ldurb	w8, [x29, #-16]
	cbz	w8, .LBB148_16
// %bb.14:
	ldur	x0, [x29, #-24]
	cbz	x0, .LBB148_16
// %bb.15:
	bl	pthread_mutex_unlock
.LBB148_16:
	ldr	x8, [sp, #104]
	cbnz	x8, .LBB148_23
// %bb.17:
	mov	x0, x19
	bl	_ZNSt18condition_variableD1Ev
	ldp	x20, x19, [sp, #320]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #240]            // 16-byte Folded Reload
	add	sp, sp, #336
	ret
.LBB148_18:
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_acquire
	cbz	w0, .LBB148_3
// %bb.19:
.Ltmp667:
	adrp	x0, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	_ZN9pocketfft6detail9threading11thread_poolC2Ev
.Ltmp668:
// %bb.20:
	adrp	x0, _ZN9pocketfft6detail9threading11thread_poolD2Ev
	adrp	x1, _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	adrp	x2, __dso_handle
	add	x0, x0, :lo12:_ZN9pocketfft6detail9threading11thread_poolD2Ev
	add	x1, x1, :lo12:_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x2, x2, :lo12:__dso_handle
	bl	__cxa_atexit
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_release
	b	.LBB148_3
.LBB148_21:
.Ltmp682:
	bl	_ZSt20__throw_system_errori
.Ltmp683:
// %bb.22:
.LBB148_23:
	add	x0, sp, #8
	str	x8, [sp, #8]
	bl	_ZNSt15__exception_ptr13exception_ptr9_M_addrefEv
.Ltmp685:
	add	x0, sp, #8
	bl	_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE
.Ltmp686:
// %bb.24:
.LBB148_25:
.Ltmp669:
	mov	x20, x0
	adrp	x0, _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	add	x0, x0, :lo12:_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	bl	__cxa_guard_abort
	mov	x0, x20
	bl	_Unwind_Resume
.LBB148_26:
.Ltmp687:
	ldr	x8, [sp, #8]
	mov	x20, x0
	cbz	x8, .LBB148_34
// %bb.27:
	add	x0, sp, #8
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
	b	.LBB148_34
.LBB148_28:
.Ltmp684:
	b	.LBB148_31
.LBB148_29:
.Ltmp681:
	bl	__clang_call_terminate
.LBB148_30:
.Ltmp672:
.LBB148_31:
	mov	x20, x0
	b	.LBB148_34
.LBB148_32:
.Ltmp675:
	ldr	x8, [sp, #32]
	mov	x20, x0
	cbz	x8, .LBB148_34
// %bb.33:
.Ltmp676:
	add	x0, sp, #16
	add	x1, sp, #16
	mov	w2, #3
	blr	x8
.Ltmp677:
.LBB148_34:
	ldr	x8, [sp, #104]
	cbz	x8, .LBB148_36
// %bb.35:
	add	x0, sp, #104
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB148_36:
	mov	x0, x19
	bl	_ZNSt18condition_variableD1Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB148_37:
.Ltmp678:
	bl	__clang_call_terminate
.Lfunc_end148:
	.size	_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_, .Lfunc_end148-_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,"aG",@progbits,_ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_,comdat
	.p2align	2
GCC_except_table148:
.Lexception50:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase13-.Lttbaseref13
.Lttbaseref13:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end50-.Lcst_begin50
.Lcst_begin50:
	.uleb128 .Lfunc_begin50-.Lfunc_begin50  // >> Call Site 1 <<
	.uleb128 .Ltmp670-.Lfunc_begin50        //   Call between .Lfunc_begin50 and .Ltmp670
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp670-.Lfunc_begin50        // >> Call Site 2 <<
	.uleb128 .Ltmp671-.Ltmp670              //   Call between .Ltmp670 and .Ltmp671
	.uleb128 .Ltmp672-.Lfunc_begin50        //     jumps to .Ltmp672
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp673-.Lfunc_begin50        // >> Call Site 3 <<
	.uleb128 .Ltmp674-.Ltmp673              //   Call between .Ltmp673 and .Ltmp674
	.uleb128 .Ltmp675-.Lfunc_begin50        //     jumps to .Ltmp675
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp679-.Lfunc_begin50        // >> Call Site 4 <<
	.uleb128 .Ltmp680-.Ltmp679              //   Call between .Ltmp679 and .Ltmp680
	.uleb128 .Ltmp681-.Lfunc_begin50        //     jumps to .Ltmp681
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp667-.Lfunc_begin50        // >> Call Site 5 <<
	.uleb128 .Ltmp668-.Ltmp667              //   Call between .Ltmp667 and .Ltmp668
	.uleb128 .Ltmp669-.Lfunc_begin50        //     jumps to .Ltmp669
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp682-.Lfunc_begin50        // >> Call Site 6 <<
	.uleb128 .Ltmp683-.Ltmp682              //   Call between .Ltmp682 and .Ltmp683
	.uleb128 .Ltmp684-.Lfunc_begin50        //     jumps to .Ltmp684
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp685-.Lfunc_begin50        // >> Call Site 7 <<
	.uleb128 .Ltmp686-.Ltmp685              //   Call between .Ltmp685 and .Ltmp686
	.uleb128 .Ltmp687-.Lfunc_begin50        //     jumps to .Ltmp687
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp686-.Lfunc_begin50        // >> Call Site 8 <<
	.uleb128 .Ltmp676-.Ltmp686              //   Call between .Ltmp686 and .Ltmp676
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp676-.Lfunc_begin50        // >> Call Site 9 <<
	.uleb128 .Ltmp677-.Ltmp676              //   Call between .Ltmp676 and .Ltmp677
	.uleb128 .Ltmp678-.Lfunc_begin50        //     jumps to .Ltmp678
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp677-.Lfunc_begin50        // >> Call Site 10 <<
	.uleb128 .Lfunc_end148-.Ltmp677         //   Call between .Ltmp677 and .Lfunc_end148
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end50:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase13:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end149:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end149-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end150:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end150-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	add	x0, x0, #16
	b	_ZN9pocketfft6detail11pocketfft_cIfED2Ev
.Lfunc_end151:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end151-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end152:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end152-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB153_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB153_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB153_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB153_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB153_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB153_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end153:
	.size	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end153-_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail11pocketfft_cIfEC2Em,"axG",@progbits,_ZN9pocketfft6detail11pocketfft_cIfEC2Em,comdat
	.weak	_ZN9pocketfft6detail11pocketfft_cIfEC2Em // -- Begin function _ZN9pocketfft6detail11pocketfft_cIfEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail11pocketfft_cIfEC2Em,@function
_ZN9pocketfft6detail11pocketfft_cIfEC2Em: // @_ZN9pocketfft6detail11pocketfft_cIfEC2Em
.Lfunc_begin51:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception51
// %bb.0:
	str	d8, [sp, #-64]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -64
	mov	x19, x0
	mov	x20, x0
	str	xzr, [x0]
	str	x1, [x0, #16]
	str	xzr, [x20, #8]!
	cbz	x1, .LBB154_24
// %bb.1:
	mov	x21, x1
	cmp	x1, #50
	b.hs	.LBB154_5
// %bb.2:
	mov	x0, xzr
	mul	x8, x0, x0
	cmp	x8, x21
	b.hi	.LBB154_6
.LBB154_3:
.Ltmp688:
	mov	w0, #48
	bl	_Znwm
.Ltmp689:
// %bb.4:
	mov	x22, x0
.Ltmp691:
	mov	x1, x21
	bl	_ZN9pocketfft6detail5cfftpIfEC2Em
.Ltmp692:
	b	.LBB154_17
.LBB154_5:
	mov	x0, x21
	bl	_ZN9pocketfft6detail4util20largest_prime_factorEm
	mul	x8, x0, x0
	cmp	x8, x21
	b.ls	.LBB154_3
.LBB154_6:
	mov	x0, x21
	bl	_ZN9pocketfft6detail4util10cost_guessEm
	lsl	x8, x21, #1
	fmov	d8, d0
	sub	x0, x8, #1
	bl	_ZN9pocketfft6detail4util15good_size_cmplxEm
	bl	_ZN9pocketfft6detail4util10cost_guessEm
	fadd	d0, d0, d0
	fmov	d1, #1.50000000
	fmul	d0, d0, d1
	fcmp	d0, d8
	b.pl	.LBB154_15
// %bb.7:
.Ltmp700:
	mov	w0, #96
	bl	_Znwm
.Ltmp701:
// %bb.8:
	mov	x22, x0
.Ltmp703:
	mov	x1, x21
	bl	_ZN9pocketfft6detail7fftblueIfEC2Em
.Ltmp704:
// %bb.9:
	ldr	x21, [x20]
	str	x22, [x20]
	cbz	x21, .LBB154_23
// %bb.10:
	ldr	x8, [x21, #64]
	cbz	x8, .LBB154_12
// %bb.11:
	ldur	x0, [x8, #-8]
	bl	free
.LBB154_12:
	ldr	x0, [x21, #40]
	cbz	x0, .LBB154_14
// %bb.13:
	bl	_ZdlPv
.LBB154_14:
	ldr	x8, [x21, #24]
	cbnz	x8, .LBB154_21
	b	.LBB154_22
.LBB154_15:
.Ltmp694:
	mov	w0, #48
	bl	_Znwm
.Ltmp695:
// %bb.16:
	mov	x22, x0
.Ltmp697:
	mov	x1, x21
	bl	_ZN9pocketfft6detail5cfftpIfEC2Em
.Ltmp698:
.LBB154_17:
	ldr	x21, [x19]
	str	x22, [x19]
	cbz	x21, .LBB154_23
// %bb.18:
	ldr	x0, [x21, #24]
	cbz	x0, .LBB154_20
// %bb.19:
	bl	_ZdlPv
.LBB154_20:
	ldr	x8, [x21, #8]
	cbz	x8, .LBB154_22
.LBB154_21:
	ldur	x0, [x8, #-8]
	bl	free
.LBB154_22:
	mov	x0, x21
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	b	_ZdlPv
.LBB154_23:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	ret
.LBB154_24:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x22, x0
.Ltmp706:
	adrp	x1, .L.str.8
	add	x1, x1, :lo12:.L.str.8
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp707:
// %bb.25:
.Ltmp709:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x22
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp710:
// %bb.26:
.LBB154_27:
.Ltmp699:
	b	.LBB154_32
.LBB154_28:
.Ltmp705:
	b	.LBB154_32
.LBB154_29:
.Ltmp696:
	mov	x21, x0
	b	.LBB154_36
.LBB154_30:
.Ltmp702:
	mov	x21, x0
	b	.LBB154_36
.LBB154_31:
.Ltmp693:
.LBB154_32:
	mov	x21, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB154_36
.LBB154_33:
.Ltmp690:
	mov	x21, x0
	b	.LBB154_36
.LBB154_34:
.Ltmp711:
	mov	x21, x0
	b	.LBB154_36
.LBB154_35:
.Ltmp708:
	mov	x21, x0
	mov	x0, x22
	bl	__cxa_free_exception
.LBB154_36:
	mov	x0, x20
	bl	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev
	mov	x0, x19
	bl	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev
	mov	x0, x21
	bl	_Unwind_Resume
.Lfunc_end154:
	.size	_ZN9pocketfft6detail11pocketfft_cIfEC2Em, .Lfunc_end154-_ZN9pocketfft6detail11pocketfft_cIfEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail11pocketfft_cIfEC2Em,"aG",@progbits,_ZN9pocketfft6detail11pocketfft_cIfEC2Em,comdat
	.p2align	2
GCC_except_table154:
.Lexception51:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end51-.Lcst_begin51
.Lcst_begin51:
	.uleb128 .Ltmp688-.Lfunc_begin51        // >> Call Site 1 <<
	.uleb128 .Ltmp689-.Ltmp688              //   Call between .Ltmp688 and .Ltmp689
	.uleb128 .Ltmp690-.Lfunc_begin51        //     jumps to .Ltmp690
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp691-.Lfunc_begin51        // >> Call Site 2 <<
	.uleb128 .Ltmp692-.Ltmp691              //   Call between .Ltmp691 and .Ltmp692
	.uleb128 .Ltmp693-.Lfunc_begin51        //     jumps to .Ltmp693
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp700-.Lfunc_begin51        // >> Call Site 3 <<
	.uleb128 .Ltmp701-.Ltmp700              //   Call between .Ltmp700 and .Ltmp701
	.uleb128 .Ltmp702-.Lfunc_begin51        //     jumps to .Ltmp702
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp703-.Lfunc_begin51        // >> Call Site 4 <<
	.uleb128 .Ltmp704-.Ltmp703              //   Call between .Ltmp703 and .Ltmp704
	.uleb128 .Ltmp705-.Lfunc_begin51        //     jumps to .Ltmp705
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp694-.Lfunc_begin51        // >> Call Site 5 <<
	.uleb128 .Ltmp695-.Ltmp694              //   Call between .Ltmp694 and .Ltmp695
	.uleb128 .Ltmp696-.Lfunc_begin51        //     jumps to .Ltmp696
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp697-.Lfunc_begin51        // >> Call Site 6 <<
	.uleb128 .Ltmp698-.Ltmp697              //   Call between .Ltmp697 and .Ltmp698
	.uleb128 .Ltmp699-.Lfunc_begin51        //     jumps to .Ltmp699
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp698-.Lfunc_begin51        // >> Call Site 7 <<
	.uleb128 .Ltmp706-.Ltmp698              //   Call between .Ltmp698 and .Ltmp706
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp706-.Lfunc_begin51        // >> Call Site 8 <<
	.uleb128 .Ltmp707-.Ltmp706              //   Call between .Ltmp706 and .Ltmp707
	.uleb128 .Ltmp708-.Lfunc_begin51        //     jumps to .Ltmp708
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp709-.Lfunc_begin51        // >> Call Site 9 <<
	.uleb128 .Ltmp710-.Ltmp709              //   Call between .Ltmp709 and .Ltmp710
	.uleb128 .Ltmp711-.Lfunc_begin51        //     jumps to .Ltmp711
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp710-.Lfunc_begin51        // >> Call Site 10 <<
	.uleb128 .Lfunc_end154-.Ltmp710         //   Call between .Ltmp710 and .Lfunc_end154
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end51:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIfEC2Em,"axG",@progbits,_ZN9pocketfft6detail5cfftpIfEC2Em,comdat
	.weak	_ZN9pocketfft6detail5cfftpIfEC2Em // -- Begin function _ZN9pocketfft6detail5cfftpIfEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIfEC2Em,@function
_ZN9pocketfft6detail5cfftpIfEC2Em:      // @_ZN9pocketfft6detail5cfftpIfEC2Em
.Lfunc_begin52:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception52
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	movi	v0.2d, #0000000000000000
	mov	x22, x0
	cmp	x1, #1
	str	x1, [x0]
	str	xzr, [x0, #40]
	stur	q0, [x0, #24]
	str	q0, [x22, #8]!
	b.eq	.LBB155_15
// %bb.1:
	mov	x19, x0
	cbz	x1, .LBB155_16
// %bb.2:
.Ltmp717:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIfE9factorizeEv
.Ltmp718:
// %bb.3:
	ldp	x8, x9, [x19, #24]
	mov	x20, xzr
	subs	x9, x9, x8
	b.eq	.LBB155_6
// %bb.4:
	mov	x10, #-6148914691236517206
	mov	w11, #1
	movk	x10, #43691
	movk	x10, #10922, lsl #48
	smulh	x9, x9, x10
	asr	x10, x9, #2
	add	x10, x10, x9, lsr #63
	ldr	x9, [x19]
	cmp	x10, #1
	csinc	x10, x10, xzr, hi
.LBB155_5:                              // =>This Inner Loop Header: Depth=1
	ldr	x12, [x8], #24
	mul	x11, x12, x11
	cmp	x12, #11
	sub	x14, x12, #1
	csel	x12, x12, xzr, hi
	add	x12, x12, x20
	subs	x10, x10, #1
	udiv	x13, x9, x11
	sub	x13, x13, #1
	madd	x20, x13, x14, x12
	b.ne	.LBB155_5
.LBB155_6:
	ldr	x8, [x19, #16]
	cmp	x8, x20
	b.eq	.LBB155_14
// %bb.7:
	ldr	x8, [x22]
	cbz	x8, .LBB155_9
// %bb.8:
	ldur	x0, [x8, #-8]
	bl	free
.LBB155_9:
	cbz	x20, .LBB155_12
// %bb.10:
	lsl	x8, x20, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB155_19
// %bb.11:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
	b	.LBB155_13
.LBB155_12:
	mov	x8, xzr
.LBB155_13:
	stp	x8, x20, [x19, #8]
.LBB155_14:
.Ltmp721:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv
.Ltmp722:
.LBB155_15:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB155_16:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp712:
	adrp	x1, .L.str.8
	add	x1, x1, :lo12:.L.str.8
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp713:
// %bb.17:
.Ltmp715:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp716:
// %bb.18:
.LBB155_19:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp719:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp720:
// %bb.20:
.LBB155_21:
.Ltmp714:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
	b	.LBB155_23
.LBB155_22:
.Ltmp723:
	mov	x20, x0
.LBB155_23:
	ldr	x0, [x19, #24]
	cbnz	x0, .LBB155_26
// %bb.24:
	ldr	x8, [x22]
	cbnz	x8, .LBB155_27
.LBB155_25:
	mov	x0, x20
	bl	_Unwind_Resume
.LBB155_26:
	bl	_ZdlPv
	ldr	x8, [x22]
	cbz	x8, .LBB155_25
.LBB155_27:
	ldur	x0, [x8, #-8]
	bl	free
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end155:
	.size	_ZN9pocketfft6detail5cfftpIfEC2Em, .Lfunc_end155-_ZN9pocketfft6detail5cfftpIfEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail5cfftpIfEC2Em,"aG",@progbits,_ZN9pocketfft6detail5cfftpIfEC2Em,comdat
	.p2align	2
GCC_except_table155:
.Lexception52:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end52-.Lcst_begin52
.Lcst_begin52:
	.uleb128 .Ltmp717-.Lfunc_begin52        // >> Call Site 1 <<
	.uleb128 .Ltmp722-.Ltmp717              //   Call between .Ltmp717 and .Ltmp722
	.uleb128 .Ltmp723-.Lfunc_begin52        //     jumps to .Ltmp723
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp722-.Lfunc_begin52        // >> Call Site 2 <<
	.uleb128 .Ltmp712-.Ltmp722              //   Call between .Ltmp722 and .Ltmp712
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp712-.Lfunc_begin52        // >> Call Site 3 <<
	.uleb128 .Ltmp713-.Ltmp712              //   Call between .Ltmp712 and .Ltmp713
	.uleb128 .Ltmp714-.Lfunc_begin52        //     jumps to .Ltmp714
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp715-.Lfunc_begin52        // >> Call Site 4 <<
	.uleb128 .Ltmp716-.Ltmp715              //   Call between .Ltmp715 and .Ltmp716
	.uleb128 .Ltmp723-.Lfunc_begin52        //     jumps to .Ltmp723
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp716-.Lfunc_begin52        // >> Call Site 5 <<
	.uleb128 .Ltmp719-.Ltmp716              //   Call between .Ltmp716 and .Ltmp719
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp719-.Lfunc_begin52        // >> Call Site 6 <<
	.uleb128 .Ltmp720-.Ltmp719              //   Call between .Ltmp719 and .Ltmp720
	.uleb128 .Ltmp723-.Lfunc_begin52        //     jumps to .Ltmp723
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp720-.Lfunc_begin52        // >> Call Site 7 <<
	.uleb128 .Lfunc_end155-.Ltmp720         //   Call between .Ltmp720 and .Lfunc_end155
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end52:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev,"axG",@progbits,_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev,comdat
	.weak	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev // -- Begin function _ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev
	.p2align	2
	.type	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev,@function
_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev: // @_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0]
	cbz	x20, .LBB156_6
// %bb.1:
	ldr	x0, [x20, #24]
	cbz	x0, .LBB156_3
// %bb.2:
	bl	_ZdlPv
.LBB156_3:
	ldr	x8, [x20, #8]
	cbz	x8, .LBB156_5
// %bb.4:
	ldur	x0, [x8, #-8]
	bl	free
.LBB156_5:
	mov	x0, x20
	bl	_ZdlPv
.LBB156_6:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end156:
	.size	_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev, .Lfunc_end156-_ZNSt10unique_ptrIN9pocketfft6detail5cfftpIfEESt14default_deleteIS3_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZN9pocketfft6detail7fftblueIfEC2Em
.LCPI157_0:
	.word	0x3f800000                      // float 1
	.word	0x00000000                      // float 0
	.section	.text._ZN9pocketfft6detail7fftblueIfEC2Em,"axG",@progbits,_ZN9pocketfft6detail7fftblueIfEC2Em,comdat
	.weak	_ZN9pocketfft6detail7fftblueIfEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail7fftblueIfEC2Em,@function
_ZN9pocketfft6detail7fftblueIfEC2Em:    // @_ZN9pocketfft6detail7fftblueIfEC2Em
.Lfunc_begin53:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception53
// %bb.0:
	sub	sp, sp, #112
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	lsl	x8, x1, #1
	mov	x20, x0
	sub	x0, x8, #1
	str	x1, [x20]
	bl	_ZN9pocketfft6detail4util15good_size_cmplxEm
	add	x19, x20, #16
	mov	x1, x0
	str	x0, [x20, #8]
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIfEC2Em
	ldp	x21, x8, [x20]
	add	x8, x21, x8, lsr #1
	adds	x22, x8, #1
	b.eq	.LBB157_3
// %bb.1:
	lsl	x8, x22, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB157_27
// %bb.2:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
	b	.LBB157_4
.LBB157_3:
	mov	x8, xzr
.LBB157_4:
	add	x9, x8, x21, lsl #3
	lsl	x1, x21, #1
	stp	x8, x22, [x20, #64]
	stp	x8, x9, [x20, #80]
.Ltmp727:
	add	x0, sp, #8
	bl	_ZN9pocketfft6detail13sincos_2pibynIfEC2Em
.Ltmp728:
// %bb.5:
	adrp	x8, .LCPI157_0
	ldr	x9, [x20, #80]
	ldr	d0, [x8, :lo12:.LCPI157_0]
	str	d0, [x9]
	ldr	x12, [x20]
	cmp	x12, #2
	b.lo	.LBB157_11
// %bb.6:
	mov	x8, xzr
	mov	x10, xzr
	mov	x9, #-1
	mov	w11, #1
	b	.LBB157_9
.LBB157_7:                              //   in Loop: Header=BB157_9 Depth=1
	add	x13, x12, x14
	ldr	x16, [sp, #32]
	ldp	x14, x15, [sp, #16]
	sub	x13, x13, x10
	add	x13, x9, x13
	ldr	x17, [sp, #48]
	and	x14, x14, x13
	lsr	x13, x13, x15
	add	x14, x16, x14, lsl #4
	add	x13, x17, x13, lsl #4
	ldp	d4, d0, [x14]
	ldp	d1, d2, [x13]
	fmul	d3, d0, d1
	fneg	d0, d0
	fmadd	d3, d4, d2, d3
	fmul	d0, d2, d0
	fcvt	s2, d3
	fmadd	d1, d4, d1, d0
	fneg	s0, s2
.LBB157_8:                              //   in Loop: Header=BB157_9 Depth=1
	ldr	x13, [x20, #80]
	fcvt	s1, d1
	add	x10, x10, x11, lsl #1
	add	x11, x11, #1
	sub	x9, x9, #2
	add	x13, x13, x8, lsl #2
	add	x8, x8, #2
	stp	s1, s0, [x13, #8]
	mvn	x13, x12
	ldr	x12, [x20]
	add	x10, x13, x10
	cmp	x11, x12
	b.hs	.LBB157_11
.LBB157_9:                              // =>This Inner Loop Header: Depth=1
	add	x13, x10, x8
	lsl	x12, x12, #1
	add	x13, x13, #1
	ldr	x14, [sp, #8]
	cmp	x13, x12
	csel	x12, xzr, x12, lo
	sub	x13, x10, x12
	add	x13, x8, x13
	add	x13, x13, #1
	cmp	x14, x13, lsl #1
	b.lo	.LBB157_7
// %bb.10:                              //   in Loop: Header=BB157_9 Depth=1
	ldp	x14, x15, [sp, #16]
	ldr	x16, [sp, #32]
	ldr	x17, [sp, #48]
	and	x14, x14, x13
	lsr	x13, x13, x15
	add	x14, x16, x14, lsl #4
	add	x13, x17, x13, lsl #4
	ldp	d4, d0, [x14]
	ldp	d1, d2, [x13]
	fneg	d3, d0
	fmul	d0, d0, d1
	fmul	d3, d2, d3
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d1, d3
	fcvt	s0, d0
	b	.LBB157_8
.LBB157_11:
	ldr	x21, [x20, #8]
	lsl	x8, x21, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB157_25
// %bb.12:
	ucvtf	s0, x21
	fmov	s1, #1.00000000
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	fdiv	s0, s1, s0
	stur	x0, [x21, #-8]
	ldr	x8, [x20, #80]
	ldr	d1, [x8]
	fmul	v1.2s, v1.2s, v0.s[0]
	str	d1, [x21]
	ldr	x8, [x20]
	cmp	x8, #2
	b.lo	.LBB157_15
// %bb.13:
	mov	x9, #-1
	mov	w10, #1
.LBB157_14:                             // =>This Inner Loop Header: Depth=1
	lsl	x8, x10, #3
	ldr	x11, [x20, #80]
	add	x10, x10, #1
	ldr	d1, [x11, x8]
	ldr	x11, [x20, #8]
	add	x11, x9, x11
	fmul	v1.2s, v1.2s, v0.s[0]
	sub	x9, x9, #1
	str	d1, [x21, x11, lsl #3]
	str	d1, [x21, x8]
	ldr	x8, [x20]
	cmp	x10, x8
	b.lo	.LBB157_14
.LBB157_15:
	ldr	x9, [x20, #8]
	sub	x9, x9, x8
	cmp	x8, x9
	b.hi	.LBB157_17
// %bb.16:
	add	x9, x9, #1
	add	x10, x8, #1
	cmp	x9, x10
	add	x0, x21, x8, lsl #3
	csinc	x9, x9, x8, hi
	mov	w1, wzr
	sub	x9, x9, x8
	lsl	x2, x9, #3
	bl	memset
.LBB157_17:
.Ltmp730:
	fmov	s0, #1.00000000
	mov	x0, x19
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
.Ltmp731:
// %bb.18:
	mov	x8, xzr
.LBB157_19:                             // =>This Inner Loop Header: Depth=1
	lsl	x9, x8, #3
	ldr	x11, [x20, #88]
	ldr	x10, [x21, x9]
	str	x10, [x11, x9]
	add	x9, x8, #1
	ldr	x10, [x20, #8]
	cmp	x8, x10, lsr #1
	mov	x8, x9
	b.lo	.LBB157_19
// %bb.20:
	ldur	x0, [x21, #-8]
	bl	free
	ldr	x8, [sp, #48]
	cbz	x8, .LBB157_22
// %bb.21:
	ldur	x0, [x8, #-8]
	bl	free
.LBB157_22:
	ldr	x8, [sp, #32]
	cbz	x8, .LBB157_24
// %bb.23:
	ldur	x0, [x8, #-8]
	bl	free
.LBB157_24:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #112
	ret
.LBB157_25:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp733:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp734:
// %bb.26:
.LBB157_27:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp724:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp725:
// %bb.28:
.LBB157_29:
.Ltmp726:
	mov	x22, x0
	b	.LBB157_36
.LBB157_30:
.Ltmp732:
	mov	x22, x0
	ldur	x0, [x21, #-8]
	bl	free
	b	.LBB157_32
.LBB157_31:
.Ltmp735:
	mov	x22, x0
.LBB157_32:
	add	x0, sp, #8
	bl	_ZN9pocketfft6detail13sincos_2pibynIfED2Ev
	b	.LBB157_34
.LBB157_33:
.Ltmp729:
	mov	x22, x0
.LBB157_34:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB157_36
// %bb.35:
	ldur	x0, [x8, #-8]
	bl	free
.LBB157_36:
	mov	x0, x19
	bl	_ZN9pocketfft6detail5cfftpIfED2Ev
	mov	x0, x22
	bl	_Unwind_Resume
.Lfunc_end157:
	.size	_ZN9pocketfft6detail7fftblueIfEC2Em, .Lfunc_end157-_ZN9pocketfft6detail7fftblueIfEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail7fftblueIfEC2Em,"aG",@progbits,_ZN9pocketfft6detail7fftblueIfEC2Em,comdat
	.p2align	2
GCC_except_table157:
.Lexception53:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end53-.Lcst_begin53
.Lcst_begin53:
	.uleb128 .Lfunc_begin53-.Lfunc_begin53  // >> Call Site 1 <<
	.uleb128 .Ltmp727-.Lfunc_begin53        //   Call between .Lfunc_begin53 and .Ltmp727
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp727-.Lfunc_begin53        // >> Call Site 2 <<
	.uleb128 .Ltmp728-.Ltmp727              //   Call between .Ltmp727 and .Ltmp728
	.uleb128 .Ltmp729-.Lfunc_begin53        //     jumps to .Ltmp729
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp728-.Lfunc_begin53        // >> Call Site 3 <<
	.uleb128 .Ltmp730-.Ltmp728              //   Call between .Ltmp728 and .Ltmp730
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp730-.Lfunc_begin53        // >> Call Site 4 <<
	.uleb128 .Ltmp731-.Ltmp730              //   Call between .Ltmp730 and .Ltmp731
	.uleb128 .Ltmp732-.Lfunc_begin53        //     jumps to .Ltmp732
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp731-.Lfunc_begin53        // >> Call Site 5 <<
	.uleb128 .Ltmp733-.Ltmp731              //   Call between .Ltmp731 and .Ltmp733
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp733-.Lfunc_begin53        // >> Call Site 6 <<
	.uleb128 .Ltmp734-.Ltmp733              //   Call between .Ltmp733 and .Ltmp734
	.uleb128 .Ltmp735-.Lfunc_begin53        //     jumps to .Ltmp735
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp734-.Lfunc_begin53        // >> Call Site 7 <<
	.uleb128 .Ltmp724-.Ltmp734              //   Call between .Ltmp734 and .Ltmp724
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp724-.Lfunc_begin53        // >> Call Site 8 <<
	.uleb128 .Ltmp725-.Ltmp724              //   Call between .Ltmp724 and .Ltmp725
	.uleb128 .Ltmp726-.Lfunc_begin53        //     jumps to .Ltmp726
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp725-.Lfunc_begin53        // >> Call Site 9 <<
	.uleb128 .Lfunc_end157-.Ltmp725         //   Call between .Ltmp725 and .Lfunc_end157
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end53:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev,"axG",@progbits,_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev,comdat
	.weak	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev // -- Begin function _ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev
	.p2align	2
	.type	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev,@function
_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev: // @_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0]
	cbz	x20, .LBB158_8
// %bb.1:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB158_3
// %bb.2:
	ldur	x0, [x8, #-8]
	bl	free
.LBB158_3:
	ldr	x0, [x20, #40]
	cbz	x0, .LBB158_5
// %bb.4:
	bl	_ZdlPv
.LBB158_5:
	ldr	x8, [x20, #24]
	cbz	x8, .LBB158_7
// %bb.6:
	ldur	x0, [x8, #-8]
	bl	free
.LBB158_7:
	mov	x0, x20
	bl	_ZdlPv
.LBB158_8:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end158:
	.size	_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev, .Lfunc_end158-_ZNSt10unique_ptrIN9pocketfft6detail7fftblueIfEESt14default_deleteIS3_EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIfE9factorizeEv,"axG",@progbits,_ZN9pocketfft6detail5cfftpIfE9factorizeEv,comdat
	.weak	_ZN9pocketfft6detail5cfftpIfE9factorizeEv // -- Begin function _ZN9pocketfft6detail5cfftpIfE9factorizeEv
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIfE9factorizeEv,@function
_ZN9pocketfft6detail5cfftpIfE9factorizeEv: // @_ZN9pocketfft6detail5cfftpIfE9factorizeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	x24, [x0]
	mov	x19, x0
	tst	x24, #0x7
	b.eq	.LBB159_7
// %bb.1:
	mov	x25, x24
.LBB159_2:
	tst	x25, #0x3
	b.eq	.LBB159_16
// %bb.3:
	mov	x24, x25
.LBB159_4:
	tbnz	w24, #0, .LBB159_32
// %bb.5:
	ldp	x8, x9, [x19, #32]
	cmp	x8, x9
	b.eq	.LBB159_25
// %bb.6:
	mov	w9, #2
	stp	xzr, xzr, [x8, #8]
	str	x9, [x8]
	ldp	x21, x25, [x19, #24]
	add	x8, x25, #24
	str	x8, [x19, #32]
	b	.LBB159_31
.LBB159_7:
	ldr	x8, [x19, #32]
	mov	x27, #9223372036854775800
	mov	w28, #24
	mov	w26, #8
	b	.LBB159_9
.LBB159_8:                              //   in Loop: Header=BB159_9 Depth=1
	stp	xzr, xzr, [x8, #8]
	str	x26, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	lsr	x25, x24, #3
	tst	x24, #0x38
	mov	x24, x25
	b.ne	.LBB159_2
.LBB159_9:                              // =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB159_8
// %bb.10:                              //   in Loop: Header=BB159_9 Depth=1
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB159_55
// %bb.11:                              //   in Loop: Header=BB159_9 Depth=1
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x25, x11, x8, ne
	add	x8, x25, x25, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x23, x23, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x23, #8]
	str	x26, [x23]
	b.lt	.LBB159_13
// %bb.12:                              //   in Loop: Header=BB159_9 Depth=1
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB159_13:                             //   in Loop: Header=BB159_9 Depth=1
	cbz	x20, .LBB159_15
// %bb.14:                              //   in Loop: Header=BB159_9 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB159_15:                             //   in Loop: Header=BB159_9 Depth=1
	madd	x9, x25, x28, x22
	add	x8, x23, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	lsr	x25, x24, #3
	tst	x24, #0x38
	mov	x24, x25
	b.eq	.LBB159_9
	b	.LBB159_2
.LBB159_16:
	ldr	x8, [x19, #32]
	mov	x27, #9223372036854775800
	mov	w28, #24
	mov	w26, #4
	b	.LBB159_18
.LBB159_17:                             //   in Loop: Header=BB159_18 Depth=1
	stp	xzr, xzr, [x8, #8]
	str	x26, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	lsr	x24, x25, #2
	tst	x25, #0xc
	mov	x25, x24
	b.ne	.LBB159_4
.LBB159_18:                             // =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB159_17
// %bb.19:                              //   in Loop: Header=BB159_18 Depth=1
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB159_55
// %bb.20:                              //   in Loop: Header=BB159_18 Depth=1
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x24, x11, x8, ne
	add	x8, x24, x24, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x23, x23, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x23, #8]
	str	x26, [x23]
	b.lt	.LBB159_22
// %bb.21:                              //   in Loop: Header=BB159_18 Depth=1
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB159_22:                             //   in Loop: Header=BB159_18 Depth=1
	cbz	x20, .LBB159_24
// %bb.23:                              //   in Loop: Header=BB159_18 Depth=1
	mov	x0, x20
	bl	_ZdlPv
.LBB159_24:                             //   in Loop: Header=BB159_18 Depth=1
	madd	x9, x24, x28, x22
	add	x8, x23, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	lsr	x24, x25, #2
	tst	x25, #0xc
	mov	x25, x24
	b.eq	.LBB159_18
	b	.LBB159_4
.LBB159_25:
	ldr	x20, [x19, #24]
	sub	x22, x8, x20
	mov	x8, #9223372036854775800
	cmp	x22, x8
	b.eq	.LBB159_55
// %bb.26:
	mov	x9, #-6148914691236517206
	asr	x8, x22, #3
	movk	x9, #43691
	cmp	x22, #0
	mov	x11, #6148914691236517205
	mul	x23, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x23, xzr, ne
	adds	x8, x8, x23
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x26, x11, x8, ne
	add	x8, x26, x26, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	mov	w8, #24
	mov	x21, x0
	cmp	x22, #1
	madd	x25, x23, x8, x0
	mov	w8, #2
	stp	xzr, xzr, [x25, #8]
	str	x8, [x25]
	b.lt	.LBB159_28
// %bb.27:
	mov	x0, x21
	mov	x1, x20
	mov	x2, x22
	bl	memmove
.LBB159_28:
	add	x22, x25, #24
	cbz	x20, .LBB159_30
// %bb.29:
	mov	x0, x20
	bl	_ZdlPv
.LBB159_30:
	mov	w8, #24
	stp	x21, x22, [x19, #24]
	madd	x8, x26, x8, x21
	str	x8, [x19, #40]
.LBB159_31:
	ldr	x8, [x25]
	lsr	x24, x24, #1
	ldr	x9, [x21]
	str	x8, [x21]
	str	x9, [x25]
.LBB159_32:
	cmp	x24, #9
	b.hs	.LBB159_36
.LBB159_33:
	cmp	x24, #1
	b.ls	.LBB159_54
// %bb.34:
	ldp	x8, x9, [x19, #32]
	cmp	x8, x9
	b.eq	.LBB159_48
// %bb.35:
	stp	xzr, xzr, [x8, #8]
	str	x24, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	b	.LBB159_54
.LBB159_36:
	mov	w25, #3
	mov	x27, #9223372036854775800
	mov	w28, #24
	b	.LBB159_38
.LBB159_37:                             //   in Loop: Header=BB159_38 Depth=1
	add	x25, x25, #2
	mul	x8, x25, x25
	cmp	x8, x24
	b.hi	.LBB159_33
.LBB159_38:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB159_41 Depth 2
	udiv	x8, x24, x25
	msub	x8, x8, x25, x24
	cbnz	x8, .LBB159_37
// %bb.39:                              //   in Loop: Header=BB159_38 Depth=1
	ldr	x8, [x19, #32]
	b	.LBB159_41
.LBB159_40:                             //   in Loop: Header=BB159_41 Depth=2
	stp	xzr, xzr, [x8, #8]
	str	x25, [x8]
	ldr	x8, [x19, #32]
	add	x8, x8, #24
	str	x8, [x19, #32]
	udiv	x24, x24, x25
	udiv	x9, x24, x25
	msub	x9, x9, x25, x24
	cbnz	x9, .LBB159_37
.LBB159_41:                             //   Parent Loop BB159_38 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x9, [x19, #40]
	cmp	x8, x9
	b.ne	.LBB159_40
// %bb.42:                              //   in Loop: Header=BB159_41 Depth=2
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	cmp	x21, x27
	b.eq	.LBB159_55
// %bb.43:                              //   in Loop: Header=BB159_41 Depth=2
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x26, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x26, xzr, ne
	adds	x8, x8, x26
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x23, x11, x8, ne
	add	x8, x23, x23, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	madd	x26, x26, x28, x0
	mov	x22, x0
	cmp	x21, #1
	stp	xzr, xzr, [x26, #8]
	str	x25, [x26]
	b.lt	.LBB159_45
// %bb.44:                              //   in Loop: Header=BB159_41 Depth=2
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB159_45:                             //   in Loop: Header=BB159_41 Depth=2
	cbz	x20, .LBB159_47
// %bb.46:                              //   in Loop: Header=BB159_41 Depth=2
	mov	x0, x20
	bl	_ZdlPv
.LBB159_47:                             //   in Loop: Header=BB159_41 Depth=2
	madd	x9, x23, x28, x22
	add	x8, x26, #24
	stp	x22, x8, [x19, #24]
	str	x9, [x19, #40]
	udiv	x24, x24, x25
	udiv	x9, x24, x25
	msub	x9, x9, x25, x24
	cbz	x9, .LBB159_41
	b	.LBB159_37
.LBB159_48:
	ldr	x20, [x19, #24]
	sub	x21, x8, x20
	mov	x8, #9223372036854775800
	cmp	x21, x8
	b.eq	.LBB159_55
// %bb.49:
	mov	x9, #-6148914691236517206
	asr	x8, x21, #3
	movk	x9, #43691
	cmp	x21, #0
	mov	x11, #6148914691236517205
	mul	x25, x8, x9
	movk	x11, #1365, lsl #48
	csinc	x8, x25, xzr, ne
	adds	x8, x8, x25
	cset	w9, hs
	cmp	x8, x11
	cset	w10, hi
	orr	w9, w9, w10
	cmp	w9, #0
	csel	x23, x11, x8, ne
	add	x8, x23, x23, lsl #1
	lsl	x0, x8, #3
	bl	_Znwm
	mov	w8, #24
	mov	x22, x0
	cmp	x21, #1
	madd	x25, x25, x8, x0
	stp	xzr, xzr, [x25, #8]
	str	x24, [x25]
	b.lt	.LBB159_51
// %bb.50:
	mov	x0, x22
	mov	x1, x20
	mov	x2, x21
	bl	memmove
.LBB159_51:
	add	x21, x25, #24
	cbz	x20, .LBB159_53
// %bb.52:
	mov	x0, x20
	bl	_ZdlPv
.LBB159_53:
	mov	w8, #24
	stp	x22, x21, [x19, #24]
	madd	x8, x23, x8, x22
	str	x8, [x19, #40]
.LBB159_54:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB159_55:
	adrp	x0, .L.str.2
	add	x0, x0, :lo12:.L.str.2
	bl	_ZSt20__throw_length_errorPKc
.Lfunc_end159:
	.size	_ZN9pocketfft6detail5cfftpIfE9factorizeEv, .Lfunc_end159-_ZN9pocketfft6detail5cfftpIfE9factorizeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv,"axG",@progbits,_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv,comdat
	.weak	_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv // -- Begin function _ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv,@function
_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv: // @_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x19, x0
	ldr	x1, [x0]
	add	x0, sp, #8
	bl	_ZN9pocketfft6detail13sincos_2pibynIfEC2Em
	ldp	x13, x8, [x19, #24]
	cmp	x8, x13
	b.eq	.LBB160_19
// %bb.1:
	mov	x11, #-6148914691236517206
	mov	x8, xzr
	mov	x9, xzr
	mov	w14, #1
	mov	w10, #24
	movk	x11, #43691
	b	.LBB160_4
.LBB160_2:                              //   in Loop: Header=BB160_4 Depth=1
	add	x8, x8, x13
.LBB160_3:                              //   in Loop: Header=BB160_4 Depth=1
	ldp	x13, x14, [x19, #24]
	add	x9, x9, #1
	sub	x14, x14, x13
	asr	x14, x14, #3
	mul	x15, x14, x11
	mov	x14, x12
	cmp	x9, x15
	b.hs	.LBB160_19
.LBB160_4:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB160_8 Depth 2
                                        //       Child Loop BB160_11 Depth 3
                                        //     Child Loop BB160_17 Depth 2
	madd	x17, x9, x10, x13
	ldp	x15, x18, [x19]
	ldr	x13, [x17]
	add	x18, x18, x8, lsl #3
	mul	x12, x13, x14
	sub	x0, x13, #1
	cmp	x13, #2
	str	x18, [x17, #8]
	udiv	x15, x15, x12
	sub	x16, x15, #1
	madd	x8, x16, x0, x8
	b.lo	.LBB160_3
// %bb.5:                               //   in Loop: Header=BB160_4 Depth=1
	cmp	x15, #2
	b.lo	.LBB160_13
// %bb.6:                               //   in Loop: Header=BB160_4 Depth=1
	lsl	x17, x14, #1
	neg	x18, x14
	mov	x0, x17
	mov	x1, x14
	mov	w2, #1
	b	.LBB160_8
.LBB160_7:                              //   in Loop: Header=BB160_8 Depth=2
	add	x2, x2, #1
	sub	x18, x18, x14
	add	x1, x1, x14
	add	x0, x0, x17
	cmp	x2, x13
	b.eq	.LBB160_13
.LBB160_8:                              //   Parent Loop BB160_4 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB160_11 Depth 3
	sub	x3, x2, #1
	mov	x4, x1
	mov	x6, x18
	mov	w7, #1
	mul	x5, x3, x16
	mov	x3, x0
	sub	x5, x5, #1
	b	.LBB160_11
.LBB160_9:                              //   in Loop: Header=BB160_11 Depth=3
	ldp	x21, x22, [sp, #16]
	add	x20, x6, x20
	ldr	x23, [sp, #32]
	ldr	x24, [sp, #48]
	and	x21, x21, x20
	lsr	x20, x20, x22
	add	x21, x23, x21, lsl #4
	add	x20, x24, x20, lsl #4
	ldp	d4, d0, [x21]
	ldp	d1, d2, [x20]
	fmul	d3, d0, d1
	fneg	d0, d0
	fmadd	d3, d4, d2, d3
	fmul	d0, d2, d0
	fcvt	s2, d3
	fmadd	d1, d4, d1, d0
	fneg	s0, s2
.LBB160_10:                             //   in Loop: Header=BB160_11 Depth=3
	ldr	x20, [x19, #24]
	add	x21, x5, x7
	fcvt	s1, d1
	add	x7, x7, #1
	add	x6, x6, x18
	add	x4, x4, x1
	madd	x20, x9, x10, x20
	add	x3, x3, x0
	cmp	x7, x15
	ldr	x20, [x20, #8]
	add	x20, x20, x21, lsl #3
	str	s1, [x20]
	str	s0, [x20, #4]
	b.eq	.LBB160_7
.LBB160_11:                             //   Parent Loop BB160_4 Depth=1
                                        //     Parent Loop BB160_8 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	x20, [sp, #8]
	cmp	x3, x20
	b.hi	.LBB160_9
// %bb.12:                              //   in Loop: Header=BB160_11 Depth=3
	ldp	x20, x21, [sp, #16]
	ldr	x22, [sp, #32]
	ldr	x23, [sp, #48]
	and	x20, x20, x4
	lsr	x21, x4, x21
	add	x20, x22, x20, lsl #4
	add	x21, x23, x21, lsl #4
	ldp	d4, d0, [x20]
	ldp	d1, d2, [x21]
	fneg	d3, d0
	fmul	d0, d0, d1
	fmul	d3, d2, d3
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d1, d3
	fcvt	s0, d0
	b	.LBB160_10
.LBB160_13:                             //   in Loop: Header=BB160_4 Depth=1
	cmp	x13, #12
	b.lo	.LBB160_3
// %bb.14:                              //   in Loop: Header=BB160_4 Depth=1
	ldr	x18, [x19, #24]
	mul	x14, x15, x14
	ldr	x0, [x19, #8]
	mov	x16, xzr
	mov	x17, xzr
	mov	x15, x13
	madd	x18, x9, x10, x18
	add	x0, x0, x8, lsl #3
	str	x0, [x18, #16]
	b	.LBB160_17
.LBB160_15:                             //   in Loop: Header=BB160_17 Depth=2
	ldp	x1, x2, [sp, #16]
	sub	x18, x0, x18
	ldr	x0, [sp, #32]
	ldr	x3, [sp, #48]
	and	x1, x1, x18
	lsr	x18, x18, x2
	add	x0, x0, x1, lsl #4
	add	x18, x3, x18, lsl #4
	ldp	d4, d0, [x0]
	ldp	d1, d2, [x18]
	fmul	d3, d0, d1
	fneg	d0, d0
	fmadd	d3, d4, d2, d3
	fmul	d0, d2, d0
	fcvt	s2, d3
	fmadd	d1, d4, d1, d0
	fneg	s0, s2
.LBB160_16:                             //   in Loop: Header=BB160_17 Depth=2
	ldr	x18, [x19, #24]
	fcvt	s1, d1
	add	x17, x17, #1
	subs	x15, x15, #1
	madd	x18, x9, x10, x18
	ldr	x18, [x18, #16]
	add	x18, x18, x16
	add	x16, x16, #8
	stp	s1, s0, [x18]
	b.eq	.LBB160_2
.LBB160_17:                             //   Parent Loop BB160_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mul	x18, x14, x17
	ldr	x0, [sp, #8]
	cmp	x0, x18, lsl #1
	b.lo	.LBB160_15
// %bb.18:                              //   in Loop: Header=BB160_17 Depth=2
	ldp	x0, x1, [sp, #16]
	ldr	x2, [sp, #32]
	ldr	x3, [sp, #48]
	and	x0, x0, x18
	lsr	x18, x18, x1
	add	x0, x2, x0, lsl #4
	add	x18, x3, x18, lsl #4
	ldp	d4, d0, [x0]
	ldp	d1, d2, [x18]
	fneg	d3, d0
	fmul	d0, d0, d1
	fmul	d3, d2, d3
	fmadd	d0, d4, d2, d0
	fmadd	d1, d4, d1, d3
	fcvt	s0, d0
	b	.LBB160_16
.LBB160_19:
	ldr	x8, [sp, #48]
	cbz	x8, .LBB160_21
// %bb.20:
	ldur	x0, [x8, #-8]
	bl	free
.LBB160_21:
	ldr	x8, [sp, #32]
	cbz	x8, .LBB160_23
// %bb.22:
	ldur	x0, [x8, #-8]
	bl	free
.LBB160_23:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.Lfunc_end160:
	.size	_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv, .Lfunc_end160-_ZN9pocketfft6detail5cfftpIfE12comp_twiddleEv
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIfEC2Em
.LCPI161_0:
	.xword	0x8469898cc51701b8              // fp128 0.785398163397448309615660845819875699
	.xword	0x3ffe921fb54442d1
.LCPI161_1:
	.xword	0x3ff0000000000000              // double 1
	.xword	0x0000000000000000              // double 0
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIfEC2Em,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIfEC2Em,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIfEC2Em
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIfEC2Em,@function
_ZN9pocketfft6detail13sincos_2pibynIfEC2Em: // @_ZN9pocketfft6detail13sincos_2pibynIfEC2Em
.Lfunc_begin54:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception54
// %bb.0:
	sub	sp, sp, #96
	str	d8, [sp, #16]                   // 8-byte Folded Spill
	stp	x29, x30, [sp, #24]             // 16-byte Folded Spill
	add	x29, sp, #24
	str	x25, [sp, #40]                  // 8-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 72
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w30, -64
	.cfi_offset w29, -72
	.cfi_offset b8, -80
	movi	v0.2d, #0000000000000000
	mov	x19, x0
	mov	x22, x0
	str	x1, [x0]
	mov	x0, x1
	mov	x20, x1
	str	q0, [x22, #24]!
	bl	__floatunditf
	adrp	x8, .LCPI161_0
	mov	v1.16b, v0.16b
	ldr	q0, [x8, :lo12:.LCPI161_0]
	bl	__divtf3
	add	x8, x20, #2
	mov	x21, xzr
	movi	v1.2d, #0000000000000000
	lsr	x23, x8, #1
	mov	w8, #1
	stur	q1, [x19, #40]
.LBB161_1:                              // =>This Inner Loop Header: Depth=1
	add	x21, x21, #1
	lsl	x25, x8, x21
	lsl	x9, x25, x21
	cmp	x9, x23
	b.lo	.LBB161_1
// %bb.2:
	bl	__trunctfdf2
	lsl	x8, x25, #4
	sub	x24, x25, #1
	add	x0, x8, #64
	fmov	d8, d0
	stp	x24, x21, [x19, #8]
	bl	malloc
	cbz	x0, .LBB161_21
// %bb.3:
	adrp	x9, .LCPI161_1
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	ldr	q0, [x9, :lo12:.LCPI161_1]
	stur	x0, [x8, #-8]
	stp	x8, x25, [x19, #24]
	str	q0, [sp]                        // 16-byte Folded Spill
	str	q0, [x8]
	cbz	x21, .LBB161_9
// %bb.4:
	mov	x24, xzr
	mov	w21, #1
.LBB161_5:                              // =>This Inner Loop Header: Depth=1
.Ltmp736:
	fmov	d0, d8
	mov	x0, x21
	mov	x1, x20
	bl	_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd
.Ltmp737:
// %bb.6:                               //   in Loop: Header=BB161_5 Depth=1
	ldr	x8, [x19, #24]
	add	x21, x21, #1
	add	x8, x8, x24
	add	x24, x24, #16
	stp	d0, d1, [x8, #16]
	ldr	x8, [x19, #32]
	cmp	x21, x8
	b.lo	.LBB161_5
// %bb.7:
	ldr	x24, [x19, #8]
	ldp	x8, x9, [x19, #40]
	add	x23, x24, x23
	add	x24, x24, #1
	udiv	x21, x23, x24
	cmp	x9, x21
	b.ne	.LBB161_10
.LBB161_8:
	ldr	q0, [sp]                        // 16-byte Folded Reload
	cmp	x9, #2
	str	q0, [x8]
	b.hs	.LBB161_17
	b	.LBB161_20
.LBB161_9:
	mov	x9, xzr
	add	x23, x24, x23
	add	x24, x24, #1
	ldr	x8, [x19, #40]
	udiv	x21, x23, x24
	cmp	x9, x21
	b.eq	.LBB161_8
.LBB161_10:
	cbz	x8, .LBB161_12
// %bb.11:
	ldur	x0, [x8, #-8]
	bl	free
.LBB161_12:
	cmp	x24, x23
	b.ls	.LBB161_14
// %bb.13:
	mov	x8, xzr
	b	.LBB161_16
.LBB161_14:
	lsl	x8, x21, #4
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB161_23
// %bb.15:
	add	x8, x0, #64
	and	x8, x8, #0xffffffffffffffc0
	stur	x0, [x8, #-8]
.LBB161_16:
	mov	x9, x21
	stp	x8, x21, [x19, #40]
	ldr	q0, [sp]                        // 16-byte Folded Reload
	cmp	x9, #2
	str	q0, [x8]
	b.lo	.LBB161_20
.LBB161_17:
	mov	x21, xzr
	mov	w23, #1
.LBB161_18:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #8]
	madd	x0, x23, x8, x23
.Ltmp741:
	fmov	d0, d8
	mov	x1, x20
	bl	_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd
.Ltmp742:
// %bb.19:                              //   in Loop: Header=BB161_18 Depth=1
	ldr	x8, [x19, #40]
	add	x23, x23, #1
	add	x8, x8, x21
	add	x21, x21, #16
	stp	d0, d1, [x8, #16]
	ldr	x8, [x19, #48]
	cmp	x23, x8
	b.lo	.LBB161_18
.LBB161_20:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #24]             // 16-byte Folded Reload
	ldr	x25, [sp, #40]                  // 8-byte Folded Reload
	ldr	d8, [sp, #16]                   // 8-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB161_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp744:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp745:
// %bb.22:
.LBB161_23:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
.Ltmp739:
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Ltmp740:
// %bb.24:
.LBB161_25:
.Ltmp746:
	b	.LBB161_28
.LBB161_26:
.Ltmp743:
	b	.LBB161_28
.LBB161_27:
.Ltmp738:
.LBB161_28:
	mov	x20, x0
	ldr	x8, [x19, #40]
	cbnz	x8, .LBB161_31
// %bb.29:
	ldr	x8, [x22]
	cbnz	x8, .LBB161_32
.LBB161_30:
	mov	x0, x20
	bl	_Unwind_Resume
.LBB161_31:
	ldur	x0, [x8, #-8]
	bl	free
	ldr	x8, [x22]
	cbz	x8, .LBB161_30
.LBB161_32:
	ldur	x0, [x8, #-8]
	bl	free
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end161:
	.size	_ZN9pocketfft6detail13sincos_2pibynIfEC2Em, .Lfunc_end161-_ZN9pocketfft6detail13sincos_2pibynIfEC2Em
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail13sincos_2pibynIfEC2Em,"aG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIfEC2Em,comdat
	.p2align	2
GCC_except_table161:
.Lexception54:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end54-.Lcst_begin54
.Lcst_begin54:
	.uleb128 .Lfunc_begin54-.Lfunc_begin54  // >> Call Site 1 <<
	.uleb128 .Ltmp736-.Lfunc_begin54        //   Call between .Lfunc_begin54 and .Ltmp736
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp736-.Lfunc_begin54        // >> Call Site 2 <<
	.uleb128 .Ltmp737-.Ltmp736              //   Call between .Ltmp736 and .Ltmp737
	.uleb128 .Ltmp738-.Lfunc_begin54        //     jumps to .Ltmp738
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp741-.Lfunc_begin54        // >> Call Site 3 <<
	.uleb128 .Ltmp742-.Ltmp741              //   Call between .Ltmp741 and .Ltmp742
	.uleb128 .Ltmp743-.Lfunc_begin54        //     jumps to .Ltmp743
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp742-.Lfunc_begin54        // >> Call Site 4 <<
	.uleb128 .Ltmp744-.Ltmp742              //   Call between .Ltmp742 and .Ltmp744
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp744-.Lfunc_begin54        // >> Call Site 5 <<
	.uleb128 .Ltmp745-.Ltmp744              //   Call between .Ltmp744 and .Ltmp745
	.uleb128 .Ltmp746-.Lfunc_begin54        //     jumps to .Ltmp746
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp745-.Lfunc_begin54        // >> Call Site 6 <<
	.uleb128 .Ltmp739-.Ltmp745              //   Call between .Ltmp745 and .Ltmp739
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp739-.Lfunc_begin54        // >> Call Site 7 <<
	.uleb128 .Ltmp740-.Ltmp739              //   Call between .Ltmp739 and .Ltmp740
	.uleb128 .Ltmp746-.Lfunc_begin54        //     jumps to .Ltmp746
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp740-.Lfunc_begin54        // >> Call Site 8 <<
	.uleb128 .Lfunc_end161-.Ltmp740         //   Call between .Ltmp740 and .Lfunc_end161
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end54:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIfED2Ev,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIfED2Ev,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIfED2Ev // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIfED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIfED2Ev,@function
_ZN9pocketfft6detail13sincos_2pibynIfED2Ev: // @_ZN9pocketfft6detail13sincos_2pibynIfED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x8, [x0, #40]
	cbz	x8, .LBB162_2
// %bb.1:
	ldur	x0, [x8, #-8]
	bl	free
.LBB162_2:
	ldr	x8, [x19, #24]
	cbz	x8, .LBB162_4
// %bb.3:
	ldur	x0, [x8, #-8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	free
.LBB162_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end162:
	.size	_ZN9pocketfft6detail13sincos_2pibynIfED2Ev, .Lfunc_end162-_ZN9pocketfft6detail13sincos_2pibynIfED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd,"axG",@progbits,_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd,comdat
	.weak	_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd // -- Begin function _ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd
	.p2align	2
	.type	_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd,@function
_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd: // @_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd
	.cfi_startproc
// %bb.0:
	stp	d9, d8, [sp, #-32]!             // 16-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset b8, -24
	.cfi_offset b9, -32
	lsl	x8, x0, #3
	cmp	x8, x1, lsl #2
	b.hs	.LBB163_4
// %bb.1:
	lsl	x9, x1, #1
	subs	x10, x8, x9
	b.hs	.LBB163_7
// %bb.2:
	cmp	x8, x1
	b.hs	.LBB163_11
// %bb.3:
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fmov	d8, d0
	b	.LBB163_16
.LBB163_4:
	sub	x8, x1, x0
	lsl	x9, x8, #3
	lsl	x8, x1, #1
	subs	x10, x9, x8
	b.hs	.LBB163_9
// %bb.5:
	cmp	x9, x1
	b.hs	.LBB163_13
// %bb.6:
	ucvtf	d1, x9
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fmov	d8, d0
	b	.LBB163_18
.LBB163_7:
	cmp	x10, x1
	b.hs	.LBB163_15
// %bb.8:
	ucvtf	d1, x10
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fneg	d8, d0
	b	.LBB163_12
.LBB163_9:
	cmp	x10, x1
	b.hs	.LBB163_17
// %bb.10:
	ucvtf	d1, x10
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fneg	d8, d0
	b	.LBB163_14
.LBB163_11:
	sub	x8, x9, x8
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fmov	d8, d0
.LBB163_12:
	fmov	d0, d9
	bl	cos
	fmov	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.LBB163_13:
	sub	x8, x8, x9
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	sin
	fmov	d8, d0
.LBB163_14:
	fmov	d0, d9
	bl	cos
	fneg	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.LBB163_15:
	sub	x8, x9, x10
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fneg	d8, d0
.LBB163_16:
	fmov	d0, d9
	bl	sin
	fmov	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.LBB163_17:
	sub	x8, x8, x10
	ucvtf	d1, x8
	fmul	d9, d1, d0
	fmov	d0, d9
	bl	cos
	fneg	d8, d0
.LBB163_18:
	fmov	d0, d9
	bl	sin
	fneg	d1, d0
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	fmov	d0, d8
	ldp	d9, d8, [sp], #32               // 16-byte Folded Reload
	ret
.Lfunc_end163:
	.size	_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd, .Lfunc_end163-_ZN9pocketfft6detail13sincos_2pibynIfE4calcEmmd
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail5cfftpIfED2Ev,"axG",@progbits,_ZN9pocketfft6detail5cfftpIfED2Ev,comdat
	.weak	_ZN9pocketfft6detail5cfftpIfED2Ev // -- Begin function _ZN9pocketfft6detail5cfftpIfED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail5cfftpIfED2Ev,@function
_ZN9pocketfft6detail5cfftpIfED2Ev:      // @_ZN9pocketfft6detail5cfftpIfED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x0, [x0, #24]
	cbz	x0, .LBB164_2
// %bb.1:
	bl	_ZdlPv
.LBB164_2:
	ldr	x8, [x19, #8]
	cbz	x8, .LBB164_4
// %bb.3:
	ldur	x0, [x8, #-8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	free
.LBB164_4:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end164:
	.size	_ZN9pocketfft6detail5cfftpIfED2Ev, .Lfunc_end164-_ZN9pocketfft6detail5cfftpIfED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f // -- Begin function _ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,@function
_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f: // @_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
.Lfunc_begin55:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception55
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x20, x0
	ldr	x23, [x0]
	mov	x19, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB165_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB165_4
// %bb.2:
	ldr	d0, [x19]
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.2s, v0.2s, v1.s[0]
	str	d0, [x19]
	b	.LBB165_41
.LBB165_3:
	mov	x22, xzr
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.ne	.LBB165_6
	b	.LBB165_23
.LBB165_4:
	lsl	x8, x23, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB165_42
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.eq	.LBB165_23
.LBB165_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI165_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x19
	add	x27, x27, :lo12:.LJTI165_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB165_17
.LBB165_7:
	adr	x10, .LBB165_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB165_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp755:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp756:
	mov	x0, x21
	mov	x21, x22
	b	.LBB165_15
.LBB165_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp753:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp754:
	mov	x0, x21
	mov	x21, x22
	b	.LBB165_15
.LBB165_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp759:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp760:
	mov	x0, x21
	mov	x21, x22
	b	.LBB165_15
.LBB165_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp751:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp752:
	mov	x0, x21
	mov	x21, x22
	b	.LBB165_15
.LBB165_12:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp749:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp750:
	mov	x0, x21
	mov	x21, x22
	b	.LBB165_15
.LBB165_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp757:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp758:
	mov	x0, x21
	mov	x21, x22
	b	.LBB165_15
.LBB165_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp747:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp748:
	mov	x0, x21
	mov	x21, x22
.LBB165_15:
	ldp	x8, x9, [x20, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB165_18
// %bb.16:
	ldr	x23, [x20]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB165_7
.LBB165_17:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp761:
	mov	x0, x20
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
.Ltmp762:
	mov	x0, x22
	b	.LBB165_15
.LBB165_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x19
	b.eq	.LBB165_23
// %bb.19:
	fmov	s0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x20]
	fcmp	s1, s0
	b.eq	.LBB165_27
// %bb.20:
	cbz	x8, .LBB165_39
// %bb.21:
	mov	x8, xzr
.LBB165_22:                             // =>This Inner Loop Header: Depth=1
	lsl	x9, x8, #3
	add	x8, x8, #1
	ldr	d0, [x22, x9]
	fmul	v0.2s, v0.2s, v1.s[0]
	str	d0, [x19, x9]
	ldr	x9, [x20]
	cmp	x8, x9
	b.lo	.LBB165_22
	b	.LBB165_40
.LBB165_23:
	fmov	s0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fcmp	s1, s0
	b.eq	.LBB165_39
// %bb.24:
	ldr	x8, [x20]
	cbz	x8, .LBB165_39
// %bb.25:
	cmp	x8, #8
	b.hs	.LBB165_29
// %bb.26:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	mov	x9, xzr
	b	.LBB165_37
.LBB165_27:
	cbz	x8, .LBB165_39
// %bb.28:
	lsl	x2, x8, #3
	mov	x0, x19
	mov	x1, x21
	bl	memmove
	b	.LBB165_39
.LBB165_29:
	sub	x10, x8, #1
	mov	x9, xzr
	lsl	x11, x10, #3
	cmp	xzr, x10, lsr #61
	add	x12, x19, x11
	cset	w10, ne
	cmp	x12, x19
	b.lo	.LBB165_36
// %bb.30:
	tbnz	w10, #0, .LBB165_36
// %bb.31:
	add	x12, x19, #4
	add	x11, x12, x11
	cmp	x11, x12
	b.lo	.LBB165_36
// %bb.32:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	tbnz	w10, #0, .LBB165_37
// %bb.33:
	and	x9, x8, #0xfffffffffffffff8
	add	x10, x19, #32
	mov	x11, x9
	dup	v0.4s, v7.s[0]
.LBB165_34:                             // =>This Inner Loop Header: Depth=1
	ld2	{ v1.4s, v2.4s }, [x10]
	sub	x12, x10, #32
	subs	x11, x11, #8
	ld2	{ v3.4s, v4.4s }, [x12]
	fmul	v5.4s, v1.4s, v7.s[0]
	fmul	v6.4s, v2.4s, v7.s[0]
	fmul	v1.4s, v3.4s, v0.4s
	fmul	v2.4s, v4.4s, v0.4s
	st2	{ v5.4s, v6.4s }, [x10]
	add	x10, x10, #64
	st2	{ v1.4s, v2.4s }, [x12]
	b.ne	.LBB165_34
// %bb.35:
	cmp	x8, x9
	b.ne	.LBB165_37
	b	.LBB165_39
.LBB165_36:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
.LBB165_37:
	sub	x8, x8, x9
	add	x9, x19, x9, lsl #3
.LBB165_38:                             // =>This Inner Loop Header: Depth=1
	ldr	d0, [x9]
	subs	x8, x8, #1
	fmul	v0.2s, v0.2s, v7.s[0]
	str	d0, [x9], #8
	b.ne	.LBB165_38
.LBB165_39:
	cbz	x22, .LBB165_41
.LBB165_40:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB165_41:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB165_42:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB165_43:
.Ltmp763:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB165_45
// %bb.44:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB165_45:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end165:
	.size	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f, .Lfunc_end165-_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,comdat
.LJTI165_0:
	.byte	(.LBB165_8-.LBB165_8)>>2
	.byte	(.LBB165_9-.LBB165_8)>>2
	.byte	(.LBB165_10-.LBB165_8)>>2
	.byte	(.LBB165_11-.LBB165_8)>>2
	.byte	(.LBB165_17-.LBB165_8)>>2
	.byte	(.LBB165_12-.LBB165_8)>>2
	.byte	(.LBB165_13-.LBB165_8)>>2
	.byte	(.LBB165_17-.LBB165_8)>>2
	.byte	(.LBB165_17-.LBB165_8)>>2
	.byte	(.LBB165_14-.LBB165_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f,comdat
	.p2align	2
GCC_except_table165:
.Lexception55:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end55-.Lcst_begin55
.Lcst_begin55:
	.uleb128 .Ltmp755-.Lfunc_begin55        // >> Call Site 1 <<
	.uleb128 .Ltmp762-.Ltmp755              //   Call between .Ltmp755 and .Ltmp762
	.uleb128 .Ltmp763-.Lfunc_begin55        //     jumps to .Ltmp763
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp762-.Lfunc_begin55        // >> Call Site 2 <<
	.uleb128 .Lfunc_end165-.Ltmp762         //   Call between .Ltmp762 and .Lfunc_end165
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end55:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f // -- Begin function _ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,@function
_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f: // @_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f
.Lfunc_begin56:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception56
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x20, x0
	ldr	x23, [x0]
	mov	x19, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB166_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB166_4
// %bb.2:
	ldr	d0, [x19]
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.2s, v0.2s, v1.s[0]
	str	d0, [x19]
	b	.LBB166_41
.LBB166_3:
	mov	x22, xzr
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.ne	.LBB166_6
	b	.LBB166_23
.LBB166_4:
	lsl	x8, x23, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB166_42
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x20, #24]
	cmp	x9, x8
	b.eq	.LBB166_23
.LBB166_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI166_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x19
	add	x27, x27, :lo12:.LJTI166_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB166_17
.LBB166_7:
	adr	x10, .LBB166_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB166_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp772:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp773:
	mov	x0, x21
	mov	x21, x22
	b	.LBB166_15
.LBB166_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp770:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp771:
	mov	x0, x21
	mov	x21, x22
	b	.LBB166_15
.LBB166_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp776:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp777:
	mov	x0, x21
	mov	x21, x22
	b	.LBB166_15
.LBB166_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp768:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp769:
	mov	x0, x21
	mov	x21, x22
	b	.LBB166_15
.LBB166_12:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp766:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp767:
	mov	x0, x21
	mov	x21, x22
	b	.LBB166_15
.LBB166_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp774:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp775:
	mov	x0, x21
	mov	x21, x22
	b	.LBB166_15
.LBB166_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp764:
	mov	x0, x20
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.Ltmp765:
	mov	x0, x21
	mov	x21, x22
.LBB166_15:
	ldp	x8, x9, [x20, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB166_18
// %bb.16:
	ldr	x23, [x20]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB166_7
.LBB166_17:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp778:
	mov	x0, x20
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
.Ltmp779:
	mov	x0, x22
	b	.LBB166_15
.LBB166_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x19
	b.eq	.LBB166_23
// %bb.19:
	fmov	s0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x20]
	fcmp	s1, s0
	b.eq	.LBB166_27
// %bb.20:
	cbz	x8, .LBB166_39
// %bb.21:
	mov	x8, xzr
.LBB166_22:                             // =>This Inner Loop Header: Depth=1
	lsl	x9, x8, #3
	add	x8, x8, #1
	ldr	d0, [x22, x9]
	fmul	v0.2s, v0.2s, v1.s[0]
	str	d0, [x19, x9]
	ldr	x9, [x20]
	cmp	x8, x9
	b.lo	.LBB166_22
	b	.LBB166_40
.LBB166_23:
	fmov	s0, #1.00000000
	ldr	q1, [sp, #16]                   // 16-byte Folded Reload
	fcmp	s1, s0
	b.eq	.LBB166_39
// %bb.24:
	ldr	x8, [x20]
	cbz	x8, .LBB166_39
// %bb.25:
	cmp	x8, #8
	b.hs	.LBB166_29
// %bb.26:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	mov	x9, xzr
	b	.LBB166_37
.LBB166_27:
	cbz	x8, .LBB166_39
// %bb.28:
	lsl	x2, x8, #3
	mov	x0, x19
	mov	x1, x21
	bl	memmove
	b	.LBB166_39
.LBB166_29:
	sub	x10, x8, #1
	mov	x9, xzr
	lsl	x11, x10, #3
	cmp	xzr, x10, lsr #61
	add	x12, x19, x11
	cset	w10, ne
	cmp	x12, x19
	b.lo	.LBB166_36
// %bb.30:
	tbnz	w10, #0, .LBB166_36
// %bb.31:
	add	x12, x19, #4
	add	x11, x12, x11
	cmp	x11, x12
	b.lo	.LBB166_36
// %bb.32:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
	tbnz	w10, #0, .LBB166_37
// %bb.33:
	and	x9, x8, #0xfffffffffffffff8
	add	x10, x19, #32
	mov	x11, x9
	dup	v0.4s, v7.s[0]
.LBB166_34:                             // =>This Inner Loop Header: Depth=1
	ld2	{ v1.4s, v2.4s }, [x10]
	sub	x12, x10, #32
	subs	x11, x11, #8
	ld2	{ v3.4s, v4.4s }, [x12]
	fmul	v5.4s, v1.4s, v7.s[0]
	fmul	v6.4s, v2.4s, v7.s[0]
	fmul	v1.4s, v3.4s, v0.4s
	fmul	v2.4s, v4.4s, v0.4s
	st2	{ v5.4s, v6.4s }, [x10]
	add	x10, x10, #64
	st2	{ v1.4s, v2.4s }, [x12]
	b.ne	.LBB166_34
// %bb.35:
	cmp	x8, x9
	b.ne	.LBB166_37
	b	.LBB166_39
.LBB166_36:
	ldr	q7, [sp, #16]                   // 16-byte Folded Reload
.LBB166_37:
	sub	x8, x8, x9
	add	x9, x19, x9, lsl #3
.LBB166_38:                             // =>This Inner Loop Header: Depth=1
	ldr	d0, [x9]
	subs	x8, x8, #1
	fmul	v0.2s, v0.2s, v7.s[0]
	str	d0, [x9], #8
	b.ne	.LBB166_38
.LBB166_39:
	cbz	x22, .LBB166_41
.LBB166_40:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB166_41:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB166_42:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB166_43:
.Ltmp780:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB166_45
// %bb.44:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB166_45:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end166:
	.size	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f, .Lfunc_end166-_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,comdat
.LJTI166_0:
	.byte	(.LBB166_8-.LBB166_8)>>2
	.byte	(.LBB166_9-.LBB166_8)>>2
	.byte	(.LBB166_10-.LBB166_8)>>2
	.byte	(.LBB166_11-.LBB166_8)>>2
	.byte	(.LBB166_17-.LBB166_8)>>2
	.byte	(.LBB166_12-.LBB166_8)>>2
	.byte	(.LBB166_13-.LBB166_8)>>2
	.byte	(.LBB166_17-.LBB166_8)>>2
	.byte	(.LBB166_17-.LBB166_8)>>2
	.byte	(.LBB166_14-.LBB166_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f,comdat
	.p2align	2
GCC_except_table166:
.Lexception56:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end56-.Lcst_begin56
.Lcst_begin56:
	.uleb128 .Ltmp772-.Lfunc_begin56        // >> Call Site 1 <<
	.uleb128 .Ltmp779-.Ltmp772              //   Call between .Ltmp772 and .Ltmp779
	.uleb128 .Ltmp780-.Lfunc_begin56        //     jumps to .Ltmp780
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp779-.Lfunc_begin56        // >> Call Site 2 <<
	.uleb128 .Lfunc_end166-.Ltmp779         //   Call between .Ltmp779 and .Lfunc_end166
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end56:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	str	x23, [sp, #-48]!                // 8-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	subs	x8, x1, #1
	b.ne	.LBB167_4
// %bb.1:
	cbz	x2, .LBB167_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #4
	lsl	x9, x2, #3
	lsl	x10, x10, #3
	lsl	x11, x2, #4
	add	x12, x3, #16
.LBB167_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x12, #-16]
	ldp	s2, s3, [x12]
	ldp	s4, s5, [x12, #-8]
	ldp	s6, s7, [x12, #8]
	add	x13, x8, x11
	add	x14, x8, x9
	fadd	s16, s0, s2
	fadd	s18, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	fadd	s17, s4, s6
	fadd	s19, s5, s7
	fsub	s2, s5, s7
	fsub	s3, s4, s6
	subs	x2, x2, #1
	add	x12, x12, #32
	fsub	s4, s16, s17
	fsub	s5, s18, s19
	fadd	s6, s16, s17
	fadd	s7, s0, s2
	fsub	s0, s0, s2
	stp	s4, s5, [x13, #-4]
	fadd	s5, s18, s19
	fsub	s4, s1, s3
	fadd	s1, s1, s3
	add	x13, x8, x10
	stp	s6, s5, [x8, #-4]
	add	x8, x8, #8
	stp	s7, s4, [x14, #-4]
	stp	s0, s1, [x13, #-4]
	b.ne	.LBB167_3
	b	.LBB167_10
.LBB167_4:
	cbz	x2, .LBB167_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #24
	lsl	x10, x2, #1
	mov	x9, xzr
	add	x11, x3, #8
	lsl	x12, x1, #5
	madd	x14, x0, x14, x4
	add	x13, x10, x2
	lsl	x15, x1, #3
	add	x16, x5, x8, lsl #4
	add	x17, x4, x0, lsl #4
	add	x18, x5, x8, lsl #3
	add	x0, x4, x0, lsl #3
	mov	x6, x4
	b	.LBB167_7
.LBB167_6:                              //   in Loop: Header=BB167_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x12
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB167_10
.LBB167_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB167_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #3
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #3
	ldp	s0, s1, [x7]
	add	x20, x3, x20, lsl #3
	add	x7, x3, x21, lsl #3
	ldp	s2, s3, [x19]
	mul	x19, x9, x1
	add	x21, x9, x13
	ldp	s4, s5, [x20]
	ldp	s6, s7, [x7]
	fadd	s16, s0, s2
	fadd	s17, s1, s3
	fsub	s0, s0, s2
	add	x7, x9, x10
	fsub	s1, s1, s3
	add	x19, x4, x19, lsl #3
	fadd	s2, s4, s6
	fadd	s18, s5, s7
	fsub	s3, s4, s6
	fsub	s4, s5, s7
	mul	x7, x7, x1
	add	x20, x9, x2
	fadd	s5, s16, s2
	fadd	s6, s17, s18
	fsub	s2, s16, s2
	fsub	s7, s17, s18
	add	x7, x4, x7, lsl #3
	mul	x20, x20, x1
	stp	s5, s6, [x19]
	mul	x19, x21, x1
	fadd	s5, s0, s4
	fsub	s6, s1, s3
	fsub	s0, s0, s4
	fadd	s1, s1, s3
	add	x20, x4, x20, lsl #3
	stp	s2, s7, [x7]
	add	x7, x4, x19, lsl #3
	stp	s5, s6, [x20]
	stp	s0, s1, [x7]
	b.lo	.LBB167_6
// %bb.8:                               //   in Loop: Header=BB167_7 Depth=1
	mov	x7, xzr
	mov	x19, x8
.LBB167_9:                              //   Parent Loop BB167_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x11, x7
	subs	x19, x19, #1
	add	x21, x20, x15
	add	x22, x21, x15
	add	x23, x22, x15
	ldp	s0, s1, [x21]
	ldp	s4, s7, [x22]
	ldp	s2, s3, [x23]
	ldp	s5, s6, [x20]
	add	x20, x5, x7
	add	x21, x18, x7
	fsub	s17, s1, s3
	fsub	s18, s0, s2
	fsub	s16, s5, s4
	fadd	s4, s5, s4
	fsub	s5, s6, s7
	fadd	s0, s0, s2
	ldp	s2, s19, [x20]
	fadd	s6, s6, s7
	fadd	s1, s1, s3
	fadd	s20, s16, s17
	fsub	s16, s16, s17
	fsub	s3, s5, s18
	fsub	s7, s4, s0
	ldp	s21, s22, [x21]
	add	x21, x16, x7
	fadd	s0, s4, s0
	fneg	s23, s20
	fsub	s4, s6, s1
	fmul	s17, s3, s19
	fneg	s24, s7
	fadd	s5, s5, s18
	fadd	s1, s6, s1
	fneg	s6, s16
	add	x20, x6, x7
	fmul	s19, s19, s23
	ldp	s23, s18, [x21]
	fmadd	s17, s20, s2, s17
	fmul	s20, s4, s22
	str	s0, [x20, #8]
	add	x21, x0, x7
	fmadd	s2, s3, s2, s19
	fmul	s3, s22, s24
	fmul	s0, s5, s18
	fmul	s6, s18, s6
	str	s1, [x20, #12]
	fmadd	s1, s7, s21, s20
	add	x20, x17, x7
	str	s17, [x21, #8]
	fmadd	s3, s4, s21, s3
	str	s2, [x21, #12]
	fmadd	s0, s16, s23, s0
	fmadd	s4, s5, s23, s6
	add	x21, x14, x7
	add	x7, x7, #8
	str	s1, [x20, #8]
	str	s3, [x20, #12]
	str	s0, [x21, #8]
	str	s4, [x21, #12]
	b.ne	.LBB167_9
	b	.LBB167_6
.LBB167_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp], #48                  // 8-byte Folded Reload
	ret
.Lfunc_end167:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end167-_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	stp	d9, d8, [sp, #96]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 208
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	subs	x8, x1, #1
	stp	x4, x3, [sp, #80]               // 16-byte Folded Spill
	b.ne	.LBB168_4
// %bb.1:
	cbz	x2, .LBB168_10
// %bb.2:
	ldp	x8, x16, [sp, #80]              // 16-byte Folded Reload
	mov	w10, #56
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	mov	w17, #1267
	mul	x10, x2, x10
	lsl	x9, x13, #3
	add	x8, x8, #4
	lsl	x11, x11, #3
	lsl	x12, x2, #3
	lsl	x13, x13, #4
	lsl	x14, x2, #4
	lsl	x15, x2, #5
	add	x16, x16, #32
	movk	w17, #16181, lsl #16
.LBB168_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x16, #-24]
	ldp	s2, s3, [x16, #8]
	ldp	s4, s5, [x16, #-8]
	ldp	s7, s17, [x16, #24]
	ldp	s21, s23, [x16, #-16]
	fadd	s6, s0, s2
	fsub	s0, s0, s2
	fadd	s16, s1, s3
	fsub	s1, s1, s3
	fadd	s18, s5, s17
	fsub	s5, s5, s17
	fadd	s2, s4, s7
	fsub	s4, s4, s7
	ldp	s3, s19, [x16, #-32]
	ldp	s17, s7, [x16]
	fadd	s24, s0, s5
	fsub	s0, s0, s5
	ldp	s25, s5, [x16, #16]
	fsub	s26, s1, s4
	fadd	s1, s1, s4
	fadd	s4, s3, s17
	fadd	s28, s19, s7
	fadd	s20, s6, s2
	fadd	s22, s16, s18
	fadd	s27, s21, s25
	fadd	s29, s23, s5
	fsub	s16, s16, s18
	fadd	s18, s26, s24
	fsub	s24, s26, s24
	fsub	s2, s6, s2
	fsub	s3, s3, s17
	fsub	s7, s19, s7
	fadd	s26, s4, s27
	fadd	s30, s28, s29
	fsub	s4, s4, s27
	fsub	s21, s21, s25
	fsub	s25, s28, s29
	fneg	s6, s0
	add	x18, x8, x15
	fsub	s5, s23, s5
	fsub	s17, s26, s20
	fsub	s19, s30, s22
	fsub	s0, s1, s0
	add	x0, x8, x13
	fsub	s1, s6, s1
	fmov	s6, w17
	subs	x2, x2, #1
	add	x16, x16, #64
	stp	s17, s19, [x18, #-4]
	fadd	s17, s16, s4
	fsub	s19, s25, s2
	add	x18, x8, x14
	fmul	s18, s18, s6
	fmul	s24, s24, s6
	fsub	s4, s4, s16
	fadd	s2, s2, s25
	fadd	s16, s3, s5
	fmul	s0, s0, s6
	stp	s17, s19, [x18, #-4]
	fsub	s17, s7, s21
	add	x18, x8, x12
	fmul	s1, s1, s6
	stp	s4, s2, [x0, #-4]
	fsub	s3, s3, s5
	fadd	s2, s18, s16
	fsub	s6, s16, s18
	fadd	s4, s24, s17
	fadd	s5, s7, s21
	add	x0, x8, x11
	fadd	s7, s20, s26
	stp	s2, s4, [x18, #-4]
	fsub	s2, s17, s24
	fadd	s4, s0, s3
	add	x18, x8, x9
	fsub	s0, s3, s0
	stp	s6, s2, [x0, #-4]
	fadd	s6, s1, s5
	fadd	s2, s22, s30
	fsub	s1, s5, s1
	stp	s4, s6, [x18, #-4]
	add	x18, x8, x10
	stp	s7, s2, [x8, #-4]
	add	x8, x8, #8
	stp	s0, s1, [x18, #-4]
	b.ne	.LBB168_3
	b	.LBB168_10
.LBB168_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	cbz	x2, .LBB168_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x12, x2, #2
	ldp	x4, x17, [sp, #80]              // 16-byte Folded Reload
	mul	x10, x2, x1
	mov	w11, #56
	stp	x12, x8, [sp, #56]              // 16-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	add	x12, x12, x2
	ldr	x0, [sp]                        // 8-byte Folded Reload
	mov	w13, #24
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	stp	x12, x18, [sp, #32]             // 16-byte Folded Spill
	add	x12, x0, x0, lsl #2
	add	x14, x0, x0, lsl #1
	madd	x16, x10, x11, x4
	lsl	x15, x0, #5
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	lsl	x8, x1, #3
	madd	x11, x1, x11, x17
	mov	x9, xzr
	madd	x7, x10, x13, x4
	add	x25, x4, x10, lsl #3
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	add	x8, x8, x17
	add	x18, x8, #12
	lsl	x8, x12, #3
	lsl	x12, x1, #6
	add	x20, x11, #12
	add	x11, x15, x17
	add	x29, x5, x15
	add	x22, x11, #32
	lsl	x11, x0, #4
	str	x12, [sp, #8]                   // 8-byte Folded Spill
	add	x12, x8, x17
	add	x6, x12, #52
	lsl	x12, x14, #3
	add	x13, x12, x17
	add	x27, x5, x11
	add	x19, x13, #36
	mov	w13, #40
	add	x30, x4, x10, lsl #4
	add	x8, x5, x8
	madd	x21, x10, x13, x4
	lsl	x13, x14, #4
	add	x14, x11, x17
	add	x3, x13, x17
	add	x23, x14, #16
	mov	w14, #48
	add	x24, x3, #48
	add	x26, x5, x13
	madd	x28, x10, x14, x4
	add	x13, x5, x0, lsl #3
	add	x14, x4, x10, lsl #5
	add	x15, x5, x12
	mov	x3, x17
	str	x2, [sp, #72]                   // 8-byte Folded Spill
	b	.LBB168_7
.LBB168_6:                              //   in Loop: Header=BB168_7 Depth=1
	ldp	x11, x10, [sp, #8]              // 16-byte Folded Reload
	add	x9, x9, #1
	ldr	x2, [sp, #72]                   // 8-byte Folded Reload
	add	x18, x18, x11
	add	x6, x6, x11
	add	x16, x16, x10
	add	x7, x7, x10
	add	x19, x19, x11
	add	x20, x20, x11
	add	x21, x21, x10
	add	x3, x3, x11
	add	x22, x22, x11
	add	x23, x23, x11
	add	x24, x24, x11
	add	x4, x4, x10
	add	x25, x25, x10
	add	x28, x28, x10
	add	x30, x30, x10
	add	x14, x14, x10
	cmp	x9, x2
	b.eq	.LBB168_10
.LBB168_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB168_9 Depth 2
	mov	w11, #1
	mov	w12, #5
	bfi	x11, x9, #3, #61
	bfi	x12, x9, #3, #61
	ldr	x10, [sp, #88]                  // 8-byte Folded Reload
	mov	w17, #3
	mul	x11, x11, x1
	mov	x0, x2
	mul	x12, x12, x1
	mov	w2, #7
	bfi	x17, x9, #3, #61
	bfi	x2, x9, #3, #61
	add	x11, x10, x11, lsl #3
	cmp	x1, #2
	add	x12, x10, x12, lsl #3
	mul	x17, x17, x1
	ldp	s0, s1, [x11]
	mul	x11, x2, x1
	add	x17, x10, x17, lsl #3
	ldp	s2, s3, [x12]
	lsl	x12, x9, #3
	add	x11, x10, x11, lsl #3
	mul	x12, x12, x1
	ldp	s4, s5, [x17]
	ldp	s7, s17, [x11]
	add	x11, x10, x12, lsl #3
	mov	w12, #4
	bfi	x12, x9, #3, #61
	fadd	s16, s1, s3
	fsub	s1, s1, s3
	mov	w17, #2
	fadd	s3, s5, s17
	fsub	s5, s5, s17
	ldp	s18, s17, [x11]
	mul	x11, x12, x1
	mov	w12, #6
	bfi	x12, x9, #3, #61
	bfi	x17, x9, #3, #61
	fadd	s6, s0, s2
	fsub	s0, s0, s2
	mul	x12, x12, x1
	fadd	s2, s4, s7
	mul	x17, x17, x1
	fsub	s4, s4, s7
	add	x11, x10, x11, lsl #3
	fadd	s19, s16, s3
	add	x12, x10, x12, lsl #3
	fadd	s20, s0, s5
	add	x17, x10, x17, lsl #3
	fadd	s7, s6, s2
	fsub	s21, s1, s4
	fsub	s2, s6, s2
	ldp	s22, s6, [x11]
	fsub	s3, s16, s3
	fsub	s0, s0, s5
	ldp	s16, s26, [x12]
	ldp	s5, s24, [x17]
	mov	w10, #1267
	fadd	s23, s21, s20
	movk	w10, #16181, lsl #16
	fadd	s27, s18, s22
	fadd	s1, s1, s4
	fsub	s4, s21, s20
	fadd	s28, s5, s16
	fadd	s20, s17, s6
	fadd	s21, s24, s26
	fmov	s25, w10
	ldp	x10, x17, [sp, #56]             // 16-byte Folded Reload
	fsub	s18, s18, s22
	fsub	s6, s17, s6
	fmul	s22, s23, s25
	fadd	s17, s27, s28
	fadd	s23, s20, s21
	mul	x11, x9, x1
	add	x12, x9, x10
	ldr	x10, [sp, #80]                  // 8-byte Folded Reload
	add	x17, x9, x17
	fsub	s5, s5, s16
	fsub	s16, s24, s26
	fadd	s24, s7, s17
	fsub	s26, s27, s28
	fadd	s27, s19, s23
	mul	x12, x12, x1
	add	x11, x10, x11, lsl #3
	mul	x17, x17, x1
	fsub	s7, s17, s7
	fsub	s20, s20, s21
	fsub	s19, s23, s19
	add	x12, x10, x12, lsl #3
	str	s24, [x11]
	str	s27, [x11, #4]
	add	x11, x10, x17, lsl #3
	ldr	x17, [sp, #40]                  // 8-byte Folded Reload
	fsub	s17, s1, s0
	fneg	s0, s0
	fadd	s21, s3, s26
	str	s7, [x12]
	fsub	s7, s20, s2
	add	x17, x9, x17
	str	s19, [x12, #4]
	fmul	s4, s4, s25
	fsub	s3, s26, s3
	mul	x12, x17, x1
	add	x17, x9, x0
	fsub	s0, s0, s1
	str	s21, [x11]
	fadd	s1, s18, s16
	str	s7, [x11, #4]
	fsub	s7, s6, s5
	mul	x11, x17, x1
	ldr	x17, [sp, #32]                  // 8-byte Folded Reload
	fadd	s2, s2, s20
	add	x12, x10, x12, lsl #3
	fmul	s0, s0, s25
	fadd	s19, s22, s1
	add	x11, x10, x11, lsl #3
	add	x17, x9, x17
	fadd	s20, s4, s7
	str	s3, [x12]
	fsub	s1, s1, s22
	str	s2, [x12, #4]
	mul	x12, x17, x1
	str	s19, [x11]
	ldr	x17, [sp, #24]                  // 8-byte Folded Reload
	str	s20, [x11, #4]
	fmul	s2, s17, s25
	add	x11, x10, x12, lsl #3
	ldr	x12, [sp, #48]                  // 8-byte Folded Reload
	fsub	s3, s18, s16
	fadd	s5, s6, s5
	add	x17, x9, x17
	fsub	s4, s7, s4
	add	x12, x9, x12
	mov	w0, #1267
	mul	x17, x17, x1
	str	s1, [x11]
	mul	x12, x12, x1
	fadd	s1, s2, s3
	fadd	s6, s0, s5
	fsub	s2, s3, s2
	fsub	s0, s5, s0
	movk	w0, #16181, lsl #16
	add	x12, x10, x12, lsl #3
	str	s4, [x11, #4]
	add	x11, x10, x17, lsl #3
	str	s1, [x12]
	str	s6, [x12, #4]
	str	s2, [x11]
	str	s0, [x11, #4]
	b.lo	.LBB168_6
// %bb.8:                               //   in Loop: Header=BB168_7 Depth=1
	mov	x12, xzr
	ldr	x11, [sp]                       // 8-byte Folded Reload
.LBB168_9:                              //   Parent Loop BB168_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x17, x18, x12
	add	x2, x6, x12
	subs	x11, x11, #1
	ldp	s0, s1, [x17, #-4]
	add	x17, x19, x12
	ldp	s2, s3, [x2, #-4]
	add	x2, x20, x12
	ldp	s4, s5, [x17, #-4]
	add	x17, x3, x12
	ldp	s6, s7, [x2, #-4]
	add	x2, x22, x12
	fadd	s20, s0, s2
	ldp	s16, s17, [x17, #8]
	add	x17, x24, x12
	fsub	s0, s0, s2
	ldp	s18, s19, [x2, #8]
	add	x2, x23, x12
	fadd	s22, s4, s6
	ldp	s2, s26, [x17, #8]
	fadd	s24, s5, s7
	fsub	s5, s5, s7
	ldp	s23, s25, [x2, #8]
	fadd	s7, s16, s18
	fadd	s21, s1, s3
	fsub	s1, s1, s3
	fsub	s3, s4, s6
	fadd	s4, s20, s22
	fsub	s6, s0, s5
	fadd	s27, s23, s2
	fadd	s28, s17, s19
	fadd	s29, s25, s26
	fadd	s30, s21, s24
	fadd	s0, s0, s5
	fsub	s5, s1, s3
	fsub	s20, s20, s22
	fadd	s1, s1, s3
	fadd	s31, s7, s27
	fneg	s3, s6
	fadd	s22, s28, s29
	fsub	s21, s21, s24
	add	x17, x15, x12
	fadd	s8, s5, s0
	fsub	s0, s5, s0
	fsub	s5, s1, s6
	fsub	s24, s31, s4
	fsub	s1, s3, s1
	fsub	s3, s22, s30
	fsub	s16, s16, s18
	ldp	s9, s18, [x17]
	fsub	s17, s17, s19
	fsub	s7, s7, s27
	fneg	s6, s24
	fsub	s2, s23, s2
	fsub	s19, s28, s29
	add	x17, x13, x12
	fmul	s23, s3, s18
	fadd	s4, s4, s31
	fadd	s27, s21, s7
	fadd	s22, s30, s22
	fmul	s6, s18, s6
	fsub	s25, s25, s26
	fsub	s7, s7, s21
	fmov	s18, w0
	fmadd	s23, s24, s9, s23
	add	x2, x4, x12
	ldp	s24, s28, [x17]
	fmadd	s3, s3, s9, s6
	fsub	s6, s19, s20
	fneg	s29, s27
	add	x17, x8, x12
	fmul	s26, s8, s18
	stp	s4, s22, [x2, #8]
	fadd	s19, s20, s19
	fmul	s0, s0, s18
	fmul	s21, s6, s28
	fmul	s5, s5, s18
	fmul	s4, s28, s29
	fneg	s28, s7
	ldp	s20, s22, [x17]
	add	x17, x14, x12
	fmul	s1, s1, s18
	fmadd	s21, s27, s24, s21
	fadd	s27, s16, s25
	fmadd	s4, s6, s24, s4
	fsub	s24, s17, s2
	fmul	s6, s19, s22
	fmul	s22, s22, s28
	stp	s23, s3, [x17, #8]
	add	x17, x5, x12
	fadd	s28, s26, s27
	fsub	s16, s16, s25
	add	x2, x30, x12
	fadd	s2, s17, s2
	fmadd	s3, s7, s20, s6
	fmadd	s6, s19, s20, s22
	ldp	s20, s22, [x17]
	fneg	s19, s28
	fadd	s7, s0, s24
	add	x17, x28, x12
	stp	s21, s4, [x2, #8]
	add	x2, x27, x12
	fsub	s0, s24, s0
	fmul	s18, s22, s19
	fmul	s4, s7, s22
	stp	s3, s6, [x17, #8]
	fsub	s3, s27, s26
	add	x17, x29, x12
	ldp	s21, s22, [x2]
	fmadd	s6, s7, s20, s18
	fadd	s7, s5, s16
	fmadd	s4, s28, s20, s4
	fneg	s19, s3
	ldp	s17, s18, [x17]
	fadd	s20, s1, s2
	fsub	s5, s16, s5
	fneg	s23, s7
	add	x2, x26, x12
	fsub	s1, s2, s1
	add	x17, x25, x12
	fmul	s16, s0, s18
	fmul	s18, s18, s19
	fmul	s19, s20, s22
	fneg	s2, s5
	fmul	s22, s22, s23
	stp	s4, s6, [x17, #8]
	ldp	s23, s24, [x2]
	fmadd	s3, s3, s17, s16
	fmadd	s0, s0, s17, s18
	add	x17, x21, x12
	fmadd	s6, s7, s21, s19
	fmadd	s7, s20, s21, s22
	add	x2, x7, x12
	fmul	s4, s1, s24
	fmul	s2, s24, s2
	stp	s3, s0, [x17, #8]
	add	x17, x16, x12
	add	x12, x12, #8
	stp	s6, s7, [x2, #8]
	fmadd	s0, s5, s23, s4
	fmadd	s1, s1, s23, s2
	stp	s0, s1, [x17, #8]
	b.ne	.LBB168_9
	b	.LBB168_6
.LBB168_10:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #96]               // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.Lfunc_end168:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end168-_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 176
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	cmp	x1, #1
	str	x5, [sp, #56]                   // 8-byte Folded Spill
	b.ne	.LBB169_4
// %bb.1:
	cbz	x2, .LBB169_46
// %bb.2:
	cmp	x2, #4
	b.hs	.LBB169_31
// %bb.3:
	mov	x8, xzr
	b	.LBB169_42
.LBB169_4:
	cbz	x2, .LBB169_46
// %bb.5:
	subs	x6, x1, #1
	b.ls	.LBB169_44
// %bb.6:
	lsl	x13, x2, #3
	sub	x14, x1, #2
	add	x13, x13, #8
	mul	x12, x2, x1
	cmp	xzr, x14, lsr #61
	lsl	x17, x14, #3
	mul	x8, x13, x1
	mov	x9, xzr
	mov	x10, xzr
	mov	x11, xzr
	add	x18, x12, #1
	cset	w21, ne
	add	x0, x3, #8
	lsl	x15, x1, #4
	stp	x8, x17, [sp, #40]              // 16-byte Folded Spill
	and	x8, x6, #0xfffffffffffffffc
	add	x7, x17, #16
	add	x19, x4, #8
	lsl	x20, x12, #3
	add	x24, x3, #4
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	orr	x8, x8, #0x1
	lsl	x22, x1, #1
	add	x23, x4, #4
	mov	x25, x1
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldr	x8, [sp, #56]                   // 8-byte Folded Reload
	stp	x23, x15, [sp, #16]             // 16-byte Folded Spill
	sub	x8, x8, #4
	stp	x18, x8, [sp, #64]              // 16-byte Folded Spill
.LBB169_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB169_19 Depth 2
                                        //     Child Loop BB169_23 Depth 2
	mov	w14, #1
	lsl	x13, x11, #1
	bfi	x14, x11, #1, #63
	mul	x26, x11, x1
	mul	x13, x13, x1
	cmp	x6, #4
	mul	x14, x14, x1
	add	x30, x4, x26, lsl #3
	add	x13, x3, x13, lsl #3
	add	x14, x3, x14, lsl #3
	ldp	s0, s1, [x13]
	ldp	s2, s3, [x14]
	add	x13, x11, x2
	mov	w14, #1
	mul	x13, x13, x1
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	add	x13, x4, x13, lsl #3
	stp	s4, s5, [x30]
	stp	s0, s1, [x13]
	b.lo	.LBB169_22
// %bb.8:                               //   in Loop: Header=BB169_7 Depth=1
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	add	x18, x30, #12
	add	x29, x30, #8
	add	x14, x18, x17
	add	x13, x8, x26
	add	x28, x4, x13, lsl #3
	add	x27, x28, #4
	add	x13, x28, x17
	cmp	x13, x28
	add	x13, x27, x17
	cset	w16, lo
	cmp	x13, x27
	orr	w5, w16, w21
	cset	w16, lo
	cmp	x14, x18
	add	x13, x29, x17
	cset	w14, lo
	cmp	x13, x29
	cset	w13, lo
	tbnz	w5, #0, .LBB169_21
// %bb.9:                               //   in Loop: Header=BB169_7 Depth=1
	orr	w16, w16, w21
	tbnz	w16, #0, .LBB169_21
// %bb.10:                              //   in Loop: Header=BB169_7 Depth=1
	orr	w14, w14, w21
	tbnz	w14, #0, .LBB169_21
// %bb.11:                              //   in Loop: Header=BB169_7 Depth=1
	orr	w13, w13, w21
	mov	w14, #1
	tbnz	w13, #0, .LBB169_22
// %bb.12:                              //   in Loop: Header=BB169_7 Depth=1
	add	x13, x26, x1
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	mov	x14, x4
	mov	x23, x22
	add	x5, x4, x13, lsl #3
	mov	x22, x24
	add	x24, x30, x8
	sub	x13, x5, #4
	cmp	x29, x5
	mov	x15, x6
	cset	w14, lo
	cmp	x18, x13
	sub	x6, x24, #4
	cset	w16, lo
	cmp	x6, x29
	and	w8, w14, w16
	cset	w14, hi
	cmp	x28, x13
	cset	w30, lo
	cmp	x24, x29
	cset	w26, hi
	cmp	x27, x13
	cset	w16, lo
	cmp	x6, x18
	cset	w29, hi
	cmp	x28, x5
	cset	w13, lo
	cmp	x24, x18
	cset	w18, hi
	cmp	x27, x5
	cset	w5, lo
	cmp	x24, x28
	cset	w28, hi
	cmp	x6, x27
	mov	w17, w21
	cset	w27, hi
	tbnz	w8, #0, .LBB169_28
// %bb.13:                              //   in Loop: Header=BB169_7 Depth=1
	and	w8, w14, w30
	mov	x6, x15
	mov	x24, x22
	tbnz	w8, #0, .LBB169_29
// %bb.14:                              //   in Loop: Header=BB169_7 Depth=1
	and	w8, w26, w16
	mov	x22, x23
	tbnz	w8, #0, .LBB169_27
// %bb.15:                              //   in Loop: Header=BB169_7 Depth=1
	and	w8, w29, w13
	mov	w21, w17
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB169_26
// %bb.16:                              //   in Loop: Header=BB169_7 Depth=1
	and	w8, w18, w5
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB169_25
// %bb.17:                              //   in Loop: Header=BB169_7 Depth=1
	and	w8, w28, w27
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB169_22
// %bb.18:                              //   in Loop: Header=BB169_7 Depth=1
	mov	x14, x19
	ldr	x18, [sp, #32]                  // 8-byte Folded Reload
	mov	x26, x0
	ldr	x27, [sp, #56]                  // 8-byte Folded Reload
	mov	x28, x19
.LBB169_19:                             //   Parent Loop BB169_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x26, x7
	subs	x18, x18, #4
	ld2	{ v0.4s, v1.4s }, [x26], #32
	ld2	{ v2.4s, v3.4s }, [x8]
	add	x8, x14, x20
	fadd	v4.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v6.4s, v1.4s, v3.4s
	fsub	v0.4s, v0.4s, v2.4s
	st2	{ v4.4s, v5.4s }, [x28], #32
	ld2	{ v1.4s, v2.4s }, [x27], #32
	fmul	v3.4s, v6.4s, v2.4s
	fneg	v5.4s, v0.4s
	mov	x14, x28
	fmla	v3.4s, v1.4s, v0.4s
	fmul	v4.4s, v2.4s, v5.4s
	fmla	v4.4s, v1.4s, v6.4s
	st2	{ v3.4s, v4.4s }, [x8]
	b.ne	.LBB169_19
// %bb.20:                              //   in Loop: Header=BB169_7 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cmp	x6, x8
	b.ne	.LBB169_22
	b	.LBB169_24
.LBB169_21:                             //   in Loop: Header=BB169_7 Depth=1
	mov	w14, #1
.LBB169_22:                             //   in Loop: Header=BB169_7 Depth=1
	add	x8, x14, x10
	add	x13, x14, x12
	add	x16, x14, x25
	add	x18, x14, x9
	add	x27, x24, x8, lsl #3
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	sub	x26, x1, x14
	add	x28, x23, x13, lsl #3
	add	x29, x24, x16, lsl #3
	add	x18, x23, x18, lsl #3
	add	x30, x8, x14, lsl #3
.LBB169_23:                             //   Parent Loop BB169_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	s0, s2, [x27, #-4]
	ldp	s1, s3, [x29, #-4]
	ldr	s6, [x30]
	subs	x26, x26, #1
	add	x27, x27, #8
	add	x29, x29, #8
	fsub	s4, s0, s1
	fsub	s5, s2, s3
	fadd	s0, s0, s1
	fadd	s1, s2, s3
	fneg	s7, s4
	fmul	s16, s5, s6
	stur	s0, [x18, #-4]
	str	s1, [x18], #8
	fmul	s6, s6, s7
	ldur	s7, [x30, #-4]
	add	x30, x30, #8
	fmadd	s2, s4, s7, s16
	fmadd	s3, s5, s7, s6
	stur	s2, [x28, #-4]
	str	s3, [x28], #8
	b.ne	.LBB169_23
.LBB169_24:                             //   in Loop: Header=BB169_7 Depth=1
	add	x11, x11, #1
	add	x0, x0, x15
	add	x19, x19, x7
	add	x10, x10, x22
	add	x12, x12, x1
	add	x25, x25, x22
	add	x9, x9, x1
	cmp	x11, x2
	b.ne	.LBB169_7
	b	.LBB169_46
.LBB169_25:                             //   in Loop: Header=BB169_7 Depth=1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	mov	w14, #1
	b	.LBB169_22
.LBB169_26:                             //   in Loop: Header=BB169_7 Depth=1
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB169_22
.LBB169_27:                             //   in Loop: Header=BB169_7 Depth=1
	ldp	x23, x15, [sp, #16]             // 16-byte Folded Reload
	mov	w21, w17
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB169_22
.LBB169_28:                             //   in Loop: Header=BB169_7 Depth=1
	mov	x6, x15
	mov	w21, w17
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	mov	x24, x22
	b	.LBB169_30
.LBB169_29:                             //   in Loop: Header=BB169_7 Depth=1
	mov	w14, #1
	mov	w21, w17
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
.LBB169_30:                             //   in Loop: Header=BB169_7 Depth=1
	mov	x22, x23
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	b	.LBB169_22
.LBB169_31:
	sub	x9, x2, #1
	mov	x8, xzr
	add	x11, x4, x2, lsl #3
	cmp	xzr, x9, lsr #61
	lsl	x9, x9, #3
	cset	w10, ne
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB169_42
// %bb.32:
	tbnz	w10, #0, .LBB169_42
// %bb.33:
	add	x11, x11, #4
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB169_42
// %bb.34:
	tbnz	w10, #0, .LBB169_42
// %bb.35:
	add	x11, x4, #4
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB169_42
// %bb.36:
	tbnz	w10, #0, .LBB169_42
// %bb.37:
	add	x11, x4, x9
	cmp	x11, x4
	b.lo	.LBB169_42
// %bb.38:
	tbnz	w10, #0, .LBB169_42
// %bb.39:
	and	x8, x2, #0xfffffffffffffffc
	add	x9, x9, #8
	mov	x10, x8
	mov	x11, x4
	mov	x12, x3
.LBB169_40:                             // =>This Inner Loop Header: Depth=1
	ld4	{ v0.4s, v1.4s, v2.4s, v3.4s }, [x12], #64
	fadd	v4.4s, v0.4s, v2.4s
	add	x13, x11, x9
	fadd	v5.4s, v1.4s, v3.4s
	subs	x10, x10, #4
	st2	{ v4.4s, v5.4s }, [x11], #32
	fsub	v4.4s, v0.4s, v2.4s
	fsub	v5.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x13]
	b.ne	.LBB169_40
// %bb.41:
	cmp	x8, x2
	b.eq	.LBB169_46
.LBB169_42:
	add	x9, x8, x2
	add	x10, x4, x8, lsl #3
	add	x11, x3, x8, lsl #4
	sub	x8, x2, x8
	add	x12, x4, x9, lsl #3
	add	x9, x10, #4
	add	x10, x12, #4
	add	x11, x11, #8
.LBB169_43:                             // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x11, #-8]
	ldp	s2, s3, [x11], #16
	subs	x8, x8, #1
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stur	s4, [x9, #-4]
	str	s5, [x9], #8
	stur	s0, [x10, #-4]
	str	s1, [x10], #8
	b.ne	.LBB169_43
	b	.LBB169_46
.LBB169_44:
	mul	x10, x2, x1
	add	x8, x4, #4
	lsl	x9, x1, #3
	add	x11, x3, #4
	lsl	x10, x10, #3
	lsl	x12, x1, #4
.LBB169_45:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	s0, s1, [x11, #-4]
	add	x11, x11, x12
	ldp	s2, s3, [x13, #-4]
	add	x13, x8, x10
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stur	s4, [x8, #-4]
	str	s5, [x8]
	add	x8, x8, x9
	stur	s0, [x13, #-4]
	str	s1, [x13]
	b.ne	.LBB169_45
.LBB169_46:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end169:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end169-_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.LCPI170_0:
	.word	0xbf5db3d7                      // float -0.866025388
	.word	0x3f5db3d7                      // float 0.866025388
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x20, x19, [sp, #-16]!           // 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	subs	x8, x1, #1
	b.ne	.LBB170_4
// %bb.1:
	cbz	x2, .LBB170_10
// %bb.2:
	adrp	x10, .LCPI170_0
	movi	v0.2s, #191, lsl #24
	lsl	x8, x2, #4
	add	x9, x3, #8
	ldr	d1, [x10, :lo12:.LCPI170_0]
	mov	x10, x2
.LBB170_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d2, d3, [x9]
	subs	x10, x10, #1
	ldur	d5, [x9, #-8]
	add	x9, x9, #24
	fadd	v4.2s, v2.2s, v3.2s
	fsub	v2.2s, v2.2s, v3.2s
	fmul	v3.2s, v4.2s, v0.2s
	fmul	v2.2s, v2.2s, v1.2s
	fadd	v4.2s, v5.2s, v4.2s
	fadd	v3.2s, v5.2s, v3.2s
	rev64	v2.2s, v2.2s
	str	d4, [x4]
	fadd	v5.2s, v2.2s, v3.2s
	fsub	v2.2s, v3.2s, v2.2s
	str	d5, [x4, x2, lsl #3]
	str	d2, [x4, x8]
	add	x4, x4, #8
	b.ne	.LBB170_3
	b	.LBB170_10
.LBB170_4:
	cbz	x2, .LBB170_10
// %bb.5:
	mul	x16, x2, x1
	adrp	x0, .LCPI170_0
	lsl	x12, x1, #3
	add	x13, x1, x1, lsl #1
	add	x14, x12, x3
	add	x15, x3, x1, lsl #4
	add	x17, x4, x16, lsl #4
	add	x18, x4, x16, lsl #3
	movi	v0.2s, #191, lsl #24
	mov	x9, xzr
	lsl	x10, x2, #1
	add	x11, x3, #8
	lsl	x13, x13, #3
	add	x14, x14, #8
	add	x15, x15, #8
	add	x16, x17, #8
	add	x17, x18, #8
	add	x18, x5, x8, lsl #3
	ldr	d1, [x0, :lo12:.LCPI170_0]
	mov	x0, x4
	b	.LBB170_7
.LBB170_6:                              //   in Loop: Header=BB170_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x13
	add	x14, x14, x13
	add	x15, x15, x13
	add	x16, x16, x12
	add	x0, x0, x12
	add	x17, x17, x12
	cmp	x9, x2
	b.eq	.LBB170_10
.LBB170_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB170_9 Depth 2
	add	x6, x9, x9, lsl #1
	cmp	x1, #2
	add	x7, x6, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	ldr	d2, [x3, x6, lsl #3]
	add	x6, x9, x2
	ldr	d3, [x3, x19, lsl #3]
	add	x19, x9, x10
	ldr	d4, [x3, x7, lsl #3]
	mul	x7, x9, x1
	mul	x6, x6, x1
	mul	x19, x19, x1
	fadd	v5.2s, v3.2s, v4.2s
	fsub	v3.2s, v3.2s, v4.2s
	fmul	v4.2s, v5.2s, v0.2s
	fmul	v3.2s, v3.2s, v1.2s
	fadd	v4.2s, v2.2s, v4.2s
	rev64	v3.2s, v3.2s
	fadd	v2.2s, v2.2s, v5.2s
	fadd	v5.2s, v3.2s, v4.2s
	fsub	v3.2s, v4.2s, v3.2s
	str	d2, [x4, x7, lsl #3]
	str	d5, [x4, x6, lsl #3]
	str	d3, [x4, x19, lsl #3]
	b.lo	.LBB170_6
// %bb.8:                               //   in Loop: Header=BB170_7 Depth=1
	mov	x6, xzr
	mov	x7, x8
.LBB170_9:                              //   Parent Loop BB170_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d2, [x14, x6]
	add	x19, x0, x6
	ldr	d3, [x15, x6]
	add	x20, x5, x6
	subs	x7, x7, #1
	fadd	v4.2s, v2.2s, v3.2s
	fsub	v2.2s, v2.2s, v3.2s
	ldr	d3, [x11, x6]
	fmul	v5.2s, v4.2s, v0.2s
	fmul	v2.2s, v2.2s, v1.2s
	fadd	v5.2s, v3.2s, v5.2s
	rev64	v2.2s, v2.2s
	fadd	v3.2s, v3.2s, v4.2s
	fadd	v4.2s, v2.2s, v5.2s
	fsub	v2.2s, v5.2s, v2.2s
	str	d3, [x19, #8]
	add	x19, x18, x6
	ld1r	{ v6.2s }, [x20], #4
	fneg	s3, s4
	dup	v7.4s, v4.s[1]
	dup	v5.4s, v2.s[1]
	mov	v7.s[1], v3.s[0]
	ldr	s3, [x20]
	fmul	v3.2s, v7.2s, v3.s[0]
	fmla	v3.2s, v6.2s, v4.2s
	fneg	s4, s2
	str	d3, [x17, x6]
	ld1r	{ v3.2s }, [x19], #4
	mov	v5.s[1], v4.s[0]
	ldr	s4, [x19]
	fmul	v4.2s, v5.2s, v4.s[0]
	fmla	v4.2s, v3.2s, v2.2s
	str	d4, [x16, x6]
	add	x6, x6, #8
	b.ne	.LBB170_9
	b	.LBB170_6
.LBB170_10:
	ldp	x20, x19, [sp], #16             // 16-byte Folded Reload
	ret
.Lfunc_end170:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end170-_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 128
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	b.ne	.LBB171_4
// %bb.1:
	cbz	x2, .LBB171_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	mov	w14, #14202
	mov	w15, #7101
	mov	w16, #31000
	mov	w17, #30833
	mov	w18, #30833
	add	x8, x4, #4
	lsl	x9, x2, #4
	lsl	x10, x10, #3
	lsl	x11, x2, #5
	lsl	x12, x2, #3
	add	x13, x3, #20
	movk	w14, #16030, lsl #16
	movk	w15, #48975, lsl #16
	movk	w16, #48918, lsl #16
	movk	w17, #49011, lsl #16
	movk	w18, #16243, lsl #16
.LBB171_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x13, #-12]
	ldp	s2, s3, [x13, #12]
	fmov	s17, w14
	fmov	s18, w16
	fmov	s22, w15
	fmov	s23, w17
	fmov	s27, w18
	add	x1, x8, x11
	fadd	s5, s0, s2
	fadd	s6, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	ldp	s2, s7, [x13, #-4]
	ldp	s3, s4, [x13, #4]
	add	x0, x8, x12
	subs	x2, x2, #1
	fsub	s16, s7, s4
	fadd	s20, s2, s3
	fsub	s2, s2, s3
	fadd	s4, s7, s4
	ldp	s19, s3, [x13, #-20]
	add	x13, x13, #40
	fmul	s21, s16, s18
	fmul	s16, s16, s27
	fmul	s25, s2, s18
	fmul	s2, s2, s27
	fmadd	s7, s5, s17, s19
	fmadd	s24, s6, s17, s3
	fadd	s26, s19, s5
	fmadd	s5, s5, s22, s19
	fmadd	s21, s1, s23, s21
	fmadd	s1, s1, s18, s16
	fmadd	s23, s0, s23, s25
	fmadd	s0, s0, s18, s2
	fmadd	s7, s20, s22, s7
	fmadd	s24, s4, s22, s24
	fmadd	s22, s6, s22, s3
	fmadd	s5, s20, s17, s5
	fadd	s25, s26, s20
	fadd	s3, s3, s6
	fsub	s19, s7, s21
	fadd	s7, s7, s21
	fmadd	s16, s4, s17, s22
	fadd	s26, s24, s23
	fsub	s2, s24, s23
	fsub	s6, s5, s1
	fadd	s1, s5, s1
	stur	s25, [x8, #-4]
	stur	s7, [x1, #-4]
	fadd	s7, s16, s0
	stur	s19, [x0, #-4]
	str	s26, [x0]
	add	x0, x8, x9
	str	s2, [x1]
	fadd	s2, s3, s4
	fsub	s0, s16, s0
	stur	s6, [x0, #-4]
	str	s7, [x0]
	add	x0, x8, x10
	str	s2, [x8], #8
	stur	s1, [x0, #-4]
	str	s0, [x0]
	b.ne	.LBB171_3
	b	.LBB171_10
.LBB171_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	cbz	x2, .LBB171_10
// %bb.5:
	lsl	x11, x2, #2
	lsl	x10, x2, #1
	mul	x8, x2, x1
	mov	w13, #24
	add	x15, x1, x1, lsl #2
	lsl	x14, x1, #3
	stp	x10, x11, [sp, #16]             // 16-byte Folded Spill
	add	x10, x10, x2
	madd	x13, x8, x13, x4
	mov	w23, #14202
	mov	w24, #7101
	mov	w25, #31000
	str	x10, [sp, #8]                   // 8-byte Folded Spill
	ldr	x10, [sp]                       // 8-byte Folded Reload
	mov	w26, #30833
	mov	w27, #30833
	mov	x9, xzr
	lsl	x15, x15, #3
	lsl	x7, x10, #4
	add	x18, x10, x10, lsl #1
	add	x0, x7, x3
	lsl	x21, x18, #3
	add	x18, x0, #16
	add	x0, x21, x3
	add	x16, x3, x14
	add	x17, x3, x1, lsl #5
	add	x0, x0, #24
	add	x6, x4, x8, lsl #4
	add	x7, x5, x7
	add	x19, x5, x10, lsl #3
	add	x20, x4, x8, lsl #5
	add	x21, x5, x21
	add	x22, x4, x8, lsl #3
	movk	w23, #16030, lsl #16
	movk	w24, #48975, lsl #16
	movk	w25, #48918, lsl #16
	movk	w26, #49011, lsl #16
	movk	w27, #16243, lsl #16
	mov	x28, x4
	mov	x29, x3
	b	.LBB171_7
.LBB171_6:                              //   in Loop: Header=BB171_7 Depth=1
	add	x9, x9, #1
	add	x13, x13, x14
	add	x29, x29, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x28, x28, x14
	add	x6, x6, x14
	add	x20, x20, x14
	add	x22, x22, x14
	cmp	x9, x2
	b.eq	.LBB171_10
.LBB171_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB171_9 Depth 2
	add	x8, x9, x9, lsl #2
	fmov	s21, w25
	add	x30, x8, #4
	add	x11, x8, #2
	mul	x10, x8, x1
	add	x8, x8, #3
	mul	x30, x30, x1
	fmov	s19, w23
	add	x12, x1, x10
	mul	x11, x11, x1
	add	x10, x3, x10, lsl #3
	mul	x8, x8, x1
	add	x12, x3, x12, lsl #3
	fmov	s27, w26
	add	x11, x3, x11, lsl #3
	fmov	s23, w24
	ldp	s0, s1, [x10]
	add	x10, x3, x30, lsl #3
	add	x8, x3, x8, lsl #3
	ldp	s2, s3, [x12]
	ldp	s6, s7, [x11]
	ldp	s4, s5, [x10]
	ldr	x11, [sp, #24]                  // 8-byte Folded Reload
	add	x10, x9, x2
	cmp	x1, #2
	mul	x10, x10, x1
	fadd	s17, s2, s4
	fsub	s2, s2, s4
	ldp	s16, s4, [x8]
	fadd	s18, s3, s5
	fsub	s3, s3, s5
	mul	x8, x9, x1
	add	x11, x9, x11
	fadd	s20, s0, s17
	fmadd	s22, s17, s19, s0
	fadd	s5, s6, s16
	fsub	s6, s6, s16
	fsub	s16, s7, s4
	fadd	s4, s7, s4
	fadd	s7, s1, s18
	fmadd	s24, s18, s19, s1
	add	x8, x4, x8, lsl #3
	fmadd	s0, s17, s23, s0
	fmul	s25, s6, s21
	fadd	s20, s20, s5
	fmul	s26, s16, s21
	fmadd	s22, s5, s23, s22
	fadd	s7, s7, s4
	fmadd	s24, s4, s23, s24
	fmadd	s1, s18, s23, s1
	add	x10, x4, x10, lsl #3
	fmadd	s25, s2, s27, s25
	fmadd	s0, s5, s19, s0
	fmadd	s26, s3, s27, s26
	fmov	s27, w27
	stp	s20, s7, [x8]
	mul	x8, x11, x1
	ldp	x12, x11, [sp, #8]              // 16-byte Folded Reload
	fmul	s6, s6, s27
	fmul	s16, s16, s27
	fsub	s7, s22, s26
	fadd	s17, s24, s25
	fmadd	s1, s4, s19, s1
	fadd	s18, s22, s26
	add	x12, x9, x12
	fsub	s20, s24, s25
	fmadd	s2, s2, s21, s6
	fmadd	s3, s3, s21, s16
	add	x11, x9, x11
	add	x8, x4, x8, lsl #3
	stp	s7, s17, [x10]
	mul	x10, x12, x1
	mul	x11, x11, x1
	fsub	s4, s0, s3
	fadd	s5, s1, s2
	fadd	s0, s0, s3
	fsub	s1, s1, s2
	add	x11, x4, x11, lsl #3
	stp	s18, s20, [x8]
	add	x8, x4, x10, lsl #3
	stp	s4, s5, [x11]
	stp	s0, s1, [x8]
	b.lo	.LBB171_6
// %bb.8:                               //   in Loop: Header=BB171_7 Depth=1
	mov	x30, xzr
	ldr	x8, [sp]                        // 8-byte Folded Reload
.LBB171_9:                              //   Parent Loop BB171_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x10, x18, x30
	add	x11, x0, x30
	add	x12, x17, x30
	fmov	s18, w23
	fmov	s20, w25
	fmov	s24, w24
	ldp	s0, s1, [x10, #8]
	add	x10, x16, x30
	fmov	s25, w26
	ldp	s2, s3, [x11, #8]
	ldp	s4, s7, [x12, #8]
	ldp	s5, s6, [x10, #8]
	add	x10, x29, x30
	add	x11, x28, x30
	fsub	s17, s1, s3
	fadd	s1, s1, s3
	subs	x8, x8, #1
	fadd	s16, s5, s4
	fadd	s22, s6, s7
	ldp	s19, s21, [x10, #8]
	fsub	s6, s6, s7
	fadd	s7, s0, s2
	fsub	s0, s0, s2
	fmul	s23, s17, s20
	fsub	s4, s5, s4
	add	x10, x5, x30
	fmadd	s2, s16, s18, s19
	fmadd	s3, s22, s18, s21
	fadd	s26, s19, s16
	fadd	s27, s21, s22
	fmul	s5, s0, s20
	fmadd	s23, s6, s25, s23
	ldp	s28, s30, [x10]
	fmadd	s2, s7, s24, s2
	fmadd	s3, s1, s24, s3
	fadd	s26, s26, s7
	fmadd	s16, s16, s24, s19
	fmadd	s5, s4, s25, s5
	fadd	s27, s27, s1
	fmadd	s21, s22, s24, s21
	add	x10, x22, x30
	fsub	s25, s2, s23
	fadd	s2, s2, s23
	str	s26, [x11, #8]
	fmov	s26, w27
	fadd	s29, s3, s5
	str	s27, [x11, #12]
	add	x11, x21, x30
	fmadd	s7, s7, s18, s16
	fneg	s19, s25
	fmul	s17, s17, s26
	fmul	s0, s0, s26
	fmadd	s1, s1, s18, s21
	fmul	s22, s29, s30
	fsub	s3, s3, s5
	fneg	s5, s2
	fmul	s19, s30, s19
	fmadd	s6, s6, s20, s17
	fmadd	s0, s4, s20, s0
	fmadd	s16, s25, s28, s22
	ldp	s4, s17, [x11]
	fmadd	s18, s29, s28, s19
	add	x11, x19, x30
	fadd	s19, s1, s0
	fsub	s0, s1, s0
	str	s16, [x10, #8]
	fsub	s16, s7, s6
	fadd	s6, s7, s6
	fmul	s7, s3, s17
	str	s18, [x10, #12]
	add	x10, x7, x30
	ldp	s20, s18, [x11]
	fneg	s21, s16
	fmul	s5, s17, s5
	ldp	s1, s22, [x10]
	fneg	s23, s6
	fmadd	s2, s2, s4, s7
	fmul	s17, s19, s18
	add	x10, x20, x30
	fmul	s7, s18, s21
	fmadd	s3, s3, s4, s5
	fmul	s5, s0, s22
	add	x11, x6, x30
	str	s2, [x10, #8]
	fmadd	s4, s16, s20, s17
	fmul	s16, s22, s23
	fmadd	s2, s19, s20, s7
	str	s3, [x10, #12]
	fmadd	s3, s6, s1, s5
	add	x10, x13, x30
	add	x30, x30, #8
	fmadd	s0, s0, s1, s16
	str	s4, [x11, #8]
	str	s2, [x11, #12]
	str	s3, [x10, #8]
	str	s0, [x10, #12]
	b.ne	.LBB171_9
	b	.LBB171_6
.LBB171_10:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.Lfunc_end171:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end171-_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #272
	stp	d15, d14, [sp, #112]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #128]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #144]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #160]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #176]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #192]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #208]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 272
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #96]               // 16-byte Folded Spill
	b.ne	.LBB172_4
// %bb.1:
	cbz	x2, .LBB172_10
// %bb.2:
	ldp	x9, x15, [sp, #96]              // 16-byte Folded Reload
	mov	x7, x2
	lsl	x8, x2, #5
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	lsl	x12, x2, #4
	lsl	x14, x2, #3
	mov	w16, #40199
	mov	w17, #56455
	mov	w18, #42469
	mov	w0, #38112
	mov	w1, #9756
	mov	w2, #9730
	mov	w3, #9730
	mov	w4, #9756
	add	x9, x9, #4
	lsl	x10, x13, #3
	lsl	x11, x11, #3
	lsl	x13, x13, #4
	add	x15, x15, #28
	movk	w16, #16159, lsl #16
	movk	w17, #48739, lsl #16
	movk	w18, #48998, lsl #16
	movk	w0, #49017, lsl #16
	movk	w1, #48968, lsl #16
	movk	w2, #48862, lsl #16
	movk	w3, #16094, lsl #16
	movk	w4, #16200, lsl #16
.LBB172_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x15, #-20]
	ldp	s4, s2, [x15, #20]
	ldp	s5, s7, [x15, #12]
	ldp	s16, s17, [x15, #-12]
	ldp	s22, s24, [x15, #-28]
	fadd	s6, s0, s4
	fadd	s3, s1, s2
	fsub	s0, s0, s4
	fsub	s1, s1, s2
	fadd	s4, s16, s5
	fadd	s2, s17, s7
	fsub	s5, s16, s5
	fsub	s7, s17, s7
	fmov	s17, w16
	fmov	s23, w0
	ldp	s21, s18, [x15, #4]
	ldp	s19, s20, [x15, #-4]
	fmadd	s26, s6, s17, s22
	fmadd	s28, s3, s17, s24
	fmul	s29, s7, s23
	fmul	s30, s5, s23
	fmov	s27, w17
	fmov	s31, w1
	fadd	s25, s19, s21
	fadd	s16, s20, s18
	fsub	s19, s19, s21
	fsub	s18, s20, s18
	fmadd	s20, s4, s27, s26
	fmadd	s26, s2, s27, s28
	fmadd	s28, s1, s31, s29
	fmadd	s29, s0, s31, s30
	fmov	s21, w18
	fmov	s30, w2
	add	x5, x9, x14
	fadd	s9, s22, s6
	fmov	s10, w3
	fmadd	s11, s6, s27, s22
	fmadd	s20, s25, s21, s20
	fmadd	s28, s18, s30, s28
	fmadd	s26, s16, s21, s26
	fmadd	s29, s19, s30, s29
	fmadd	s6, s6, s21, s22
	fadd	s22, s24, s3
	add	x6, x9, x11
	subs	x7, x7, #1
	fsub	s31, s20, s28
	fadd	s20, s20, s28
	fadd	s8, s29, s26
	fmadd	s28, s4, s21, s11
	fsub	s26, s26, s29
	add	x15, x15, #56
	stur	s31, [x5, #-4]
	fmul	s31, s7, s10
	str	s8, [x5]
	add	x5, x9, x13
	fadd	s8, s9, s4
	fmadd	s9, s3, s27, s24
	fmul	s10, s5, s10
	fmadd	s3, s3, s21, s24
	stur	s20, [x5, #-4]
	fmov	s20, w4
	fmadd	s29, s1, s23, s31
	fmadd	s28, s25, s17, s28
	fadd	s31, s8, s25
	fmadd	s8, s2, s21, s9
	fmadd	s9, s0, s23, s10
	fmul	s7, s7, s20
	fmul	s5, s5, s20
	fmadd	s4, s4, s17, s6
	fmadd	s29, s18, s20, s29
	fmadd	s3, s2, s17, s3
	fmadd	s21, s16, s17, s8
	str	s26, [x5]
	fmadd	s20, s19, s20, s9
	fmadd	s1, s1, s30, s7
	fmadd	s0, s0, s30, s5
	fmadd	s4, s25, s27, s4
	fadd	s6, s28, s29
	fmadd	s3, s16, s27, s3
	fsub	s24, s28, s29
	add	x5, x9, x12
	fadd	s5, s20, s21
	fmadd	s1, s18, s23, s1
	fmadd	s0, s19, s23, s0
	fadd	s2, s22, s2
	stur	s6, [x6, #-4]
	fsub	s7, s21, s20
	stur	s24, [x5, #-4]
	str	s5, [x5]
	fsub	s5, s4, s1
	fadd	s6, s0, s3
	add	x5, x9, x10
	fadd	s2, s2, s16
	fadd	s1, s4, s1
	fsub	s0, s3, s0
	str	s7, [x6]
	stur	s5, [x5, #-4]
	str	s6, [x5]
	add	x5, x9, x8
	stur	s31, [x9, #-4]
	str	s2, [x9], #8
	stur	s1, [x5, #-4]
	str	s0, [x5]
	b.ne	.LBB172_3
	b	.LBB172_10
.LBB172_4:
	str	x1, [sp, #88]                   // 8-byte Folded Spill
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	cbz	x2, .LBB172_10
// %bb.5:
	lsl	x10, x2, #1
	lsl	x11, x2, #2
	ldp	x12, x4, [sp, #88]              // 16-byte Folded Reload
	mov	w17, #24
	mov	x9, xzr
	stp	x10, x2, [sp, #72]              // 16-byte Folded Spill
	add	x10, x10, x2
	lsl	x18, x10, #1
	ldr	x3, [sp, #104]                  // 8-byte Folded Reload
	ldr	x26, [sp, #16]                  // 8-byte Folded Reload
	mul	x8, x2, x12
	stp	x11, x10, [sp, #56]             // 16-byte Folded Spill
	add	x10, x11, x2
	lsl	x11, x12, #3
	add	x13, x26, x26, lsl #1
	madd	x21, x8, x17, x4
	stp	x10, x18, [sp, #40]             // 16-byte Folded Spill
	mov	w10, #56
	add	x18, x3, x11
	lsl	x13, x13, #3
	mul	x10, x12, x10
	mov	w17, #9756
	add	x15, x4, x8, lsl #5
	add	x22, x5, x13
	add	x27, x4, x8, lsl #4
	add	x29, x4, x8, lsl #3
	movk	w17, #48968, lsl #16
	stp	x10, x11, [sp, #24]             // 16-byte Folded Spill
	mov	w10, #48
	lsl	x11, x26, #4
	madd	x0, x12, x10, x3
	add	x12, x11, x3
	add	x6, x12, #16
	add	x12, x26, x26, lsl #2
	lsl	x12, x12, #3
	add	x23, x5, x11
	add	x14, x12, x3
	madd	x30, x8, x10, x4
	add	x7, x14, #40
	add	x14, x13, x3
	add	x19, x14, #24
	lsl	x14, x26, #5
	add	x16, x14, x3
	mov	w11, #38112
	add	x20, x16, #32
	mov	w16, #40
	add	x25, x5, x14
	add	x26, x5, x26, lsl #3
	madd	x24, x8, x16, x4
	add	x28, x5, x12
	movk	w11, #49017, lsl #16
	b	.LBB172_7
.LBB172_6:                              //   in Loop: Header=BB172_7 Depth=1
	ldp	x10, x8, [sp, #24]              // 16-byte Folded Reload
	mov	w11, #38112
	mov	w17, #9756
	ldr	x2, [sp, #80]                   // 8-byte Folded Reload
	add	x9, x9, #1
	movk	w11, #49017, lsl #16
	movk	w17, #48968, lsl #16
	add	x3, x3, x10
	add	x18, x18, x10
	add	x15, x15, x8
	add	x0, x0, x10
	add	x6, x6, x10
	add	x7, x7, x10
	add	x19, x19, x10
	add	x20, x20, x10
	add	x4, x4, x8
	add	x21, x21, x8
	add	x24, x24, x8
	add	x27, x27, x8
	add	x29, x29, x8
	add	x30, x30, x8
	cmp	x9, x2
	b.eq	.LBB172_10
.LBB172_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB172_9 Depth 2
	lsl	x8, x9, #3
	ldr	x1, [sp, #88]                   // 8-byte Folded Reload
	sub	x8, x8, x9
	ldr	x12, [sp, #104]                 // 8-byte Folded Reload
	add	x16, x8, #6
	add	x10, x8, #2
	mul	x13, x8, x1
	fmov	s20, w11
	mul	x16, x16, x1
	fmov	s31, w17
	mul	x10, x10, x1
	mov	w17, #42469
	add	x14, x12, x13, lsl #3
	add	x13, x1, x13
	add	x16, x12, x16, lsl #3
	movk	w17, #48998, lsl #16
	add	x13, x12, x13, lsl #3
	add	x10, x12, x10, lsl #3
	ldp	s1, s0, [x14]
	add	x14, x8, #5
	mov	w11, #9730
	ldp	s2, s3, [x13]
	mul	x13, x14, x1
	add	x14, x8, #3
	ldp	s5, s6, [x16]
	add	x8, x8, #4
	movk	w11, #16094, lsl #16
	add	x13, x12, x13, lsl #3
	cmp	x1, #2
	ldp	s7, s18, [x10]
	mul	x8, x8, x1
	fadd	s17, s2, s5
	mul	x10, x14, x1
	fadd	s4, s3, s6
	ldp	s16, s19, [x13]
	add	x8, x12, x8, lsl #3
	fsub	s3, s3, s6
	add	x10, x12, x10, lsl #3
	fadd	s22, s1, s17
	fsub	s2, s2, s5
	fadd	s27, s0, s4
	fadd	s6, s7, s16
	fadd	s5, s18, s19
	ldp	s23, s26, [x8]
	ldp	s24, s25, [x10]
	mov	w8, #40199
	fsub	s16, s7, s16
	movk	w8, #16159, lsl #16
	fsub	s18, s18, s19
	fadd	s28, s22, s6
	mov	w10, #56455
	fadd	s7, s24, s23
	movk	w10, #48739, lsl #16
	fmov	s19, w8
	mul	x8, x9, x1
	ldr	x12, [sp, #96]                  // 8-byte Folded Reload
	fadd	s21, s25, s26
	fmul	s30, s18, s20
	fsub	s25, s25, s26
	fmadd	s29, s17, s19, s1
	fadd	s26, s28, s7
	fmov	s22, w10
	fadd	s27, s27, s5
	add	x8, x12, x8, lsl #3
	mov	w10, #9730
	movk	w10, #48862, lsl #16
	fmadd	s30, s3, s31, s30
	fmadd	s28, s6, s22, s29
	fmul	s9, s16, s20
	str	s26, [x8]
	fmadd	s26, s4, s19, s0
	fmov	s29, w17
	fadd	s27, s27, s21
	fmov	s8, w10
	add	x10, x9, x2
	fsub	s23, s24, s23
	fmadd	s10, s4, s22, s0
	fmadd	s28, s7, s29, s28
	fmadd	s24, s5, s22, s26
	fmadd	s30, s25, s8, s30
	fmadd	s26, s2, s31, s9
	str	s27, [x8, #4]
	fmov	s27, w11
	mul	x8, x10, x1
	fmadd	s9, s17, s22, s1
	fmadd	s24, s21, s29, s24
	mov	w2, #9756
	fsub	s31, s28, s30
	fmul	s11, s18, s27
	fmul	s27, s16, s27
	fmadd	s26, s23, s8, s26
	add	x8, x12, x8, lsl #3
	ldr	x10, [sp, #48]                  // 8-byte Folded Reload
	movk	w2, #16200, lsl #16
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	fadd	s28, s28, s30
	fmadd	s1, s17, s29, s1
	str	s31, [x8]
	fmadd	s31, s6, s29, s9
	fmadd	s9, s5, s29, s10
	fmadd	s10, s3, s20, s11
	fmadd	s27, s2, s20, s27
	fadd	s30, s26, s24
	add	x10, x9, x10
	fmov	s11, w2
	add	x13, x9, x13
	fmadd	s31, s7, s19, s31
	mul	x10, x10, x1
	fmadd	s9, s21, s19, s9
	fmadd	s10, s25, s11, s10
	fmadd	s27, s23, s11, s27
	str	s30, [x8, #4]
	mul	x8, x13, x1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	fsub	s24, s24, s26
	add	x10, x12, x10, lsl #3
	fmul	s18, s18, s11
	fsub	s26, s31, s10
	fadd	s17, s27, s9
	add	x13, x9, x13
	add	x8, x12, x8, lsl #3
	str	s28, [x10]
	fmadd	s0, s4, s29, s0
	str	s24, [x10, #4]
	mul	x10, x13, x1
	fmul	s4, s16, s11
	str	s26, [x8]
	str	s17, [x8, #4]
	fmadd	s1, s6, s19, s1
	add	x8, x12, x10, lsl #3
	fmadd	s3, s3, s8, s18
	ldp	x13, x10, [sp, #56]             // 16-byte Folded Reload
	fmadd	s0, s5, s19, s0
	fmadd	s2, s2, s8, s4
	fadd	s4, s31, s10
	fsub	s5, s9, s27
	fmadd	s1, s7, s22, s1
	fmadd	s3, s25, s20, s3
	add	x13, x9, x13
	add	x10, x9, x10
	fmadd	s0, s21, s22, s0
	fmadd	s2, s23, s20, s2
	mul	x13, x13, x1
	mul	x10, x10, x1
	str	s4, [x8]
	fsub	s4, s1, s3
	str	s5, [x8, #4]
	fadd	s1, s1, s3
	add	x8, x12, x13, lsl #3
	fadd	s6, s2, s0
	add	x10, x12, x10, lsl #3
	fsub	s0, s0, s2
	mov	w12, #40199
	mov	w1, #9730
	movk	w12, #16159, lsl #16
	movk	w1, #48862, lsl #16
	str	s4, [x10]
	str	s6, [x10, #4]
	str	s1, [x8]
	str	s0, [x8, #4]
	b.lo	.LBB172_6
// %bb.8:                               //   in Loop: Header=BB172_7 Depth=1
	mov	x16, xzr
	ldr	x8, [sp, #16]                   // 8-byte Folded Reload
.LBB172_9:                              //   Parent Loop BB172_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x10, x18, x16
	add	x13, x0, x16
	add	x14, x3, x16
	fmov	s16, w12
	subs	x8, x8, #1
	ldp	s0, s3, [x10, #8]
	ldp	s4, s6, [x13, #8]
	add	x10, x7, x16
	add	x13, x6, x16
	ldp	s5, s1, [x14, #8]
	mov	w14, #38112
	ldp	s19, s21, [x10, #8]
	ldp	s20, s18, [x13, #8]
	movk	w14, #49017, lsl #16
	add	x13, x19, x16
	fadd	s7, s0, s4
	fadd	s2, s3, s6
	fsub	s3, s3, s6
	add	x10, x20, x16
	fsub	s6, s18, s21
	fmov	s17, w14
	ldp	s24, s23, [x13, #8]
	mov	w14, #56455
	mov	w13, #9756
	movk	w14, #48739, lsl #16
	movk	w13, #48968, lsl #16
	fsub	s0, s0, s4
	fadd	s4, s20, s19
	ldp	s27, s28, [x10, #8]
	fsub	s20, s20, s19
	fmadd	s25, s7, s16, s5
	fmul	s26, s6, s17
	fmov	s19, w14
	fmov	s29, w13
	fadd	s18, s18, s21
	fadd	s21, s24, s27
	fsub	s22, s23, s28
	fmadd	s30, s2, s16, s1
	fmul	s31, s20, s17
	fmadd	s8, s4, s19, s25
	fmadd	s9, s3, s29, s26
	fmov	s26, w17
	fmov	s25, w1
	fadd	s23, s23, s28
	fsub	s24, s24, s27
	fmadd	s27, s18, s19, s30
	fmadd	s28, s0, s29, s31
	fmadd	s29, s21, s26, s8
	fmadd	s30, s22, s25, s9
	add	x10, x5, x16
	add	x13, x28, x16
	fadd	s14, s1, s2
	fadd	s8, s5, s7
	fmadd	s27, s23, s26, s27
	fmadd	s28, s24, s25, s28
	fsub	s31, s29, s30
	fadd	s29, s29, s30
	ldp	s12, s10, [x10]
	fmov	s30, w11
	fadd	s8, s8, s4
	fadd	s9, s28, s27
	fsub	s27, s27, s28
	fneg	s11, s31
	add	x10, x4, x16
	fadd	s8, s8, s21
	fmul	s28, s9, s10
	fmul	s10, s10, s11
	ldp	s13, s11, [x13]
	add	x13, x29, x16
	fmadd	s28, s31, s12, s28
	fmadd	s31, s9, s12, s10
	fmadd	s9, s7, s19, s5
	fmul	s15, s27, s11
	fmul	s10, s6, s30
	fadd	s12, s14, s18
	fneg	s14, s29
	fmul	s30, s20, s30
	fmadd	s5, s7, s26, s5
	fmadd	s9, s4, s26, s9
	fmadd	s29, s29, s13, s15
	fmadd	s15, s2, s19, s1
	fmadd	s10, s3, s17, s10
	fmul	s11, s11, s14
	fmov	s14, w2
	fadd	s12, s12, s23
	fmadd	s30, s0, s17, s30
	fmadd	s9, s21, s16, s9
	fmadd	s15, s18, s26, s15
	fmadd	s1, s2, s26, s1
	fmadd	s10, s22, s14, s10
	fmul	s6, s6, s14
	stp	s8, s12, [x10, #8]
	add	x10, x26, x16
	fmadd	s30, s24, s14, s30
	stp	s28, s31, [x13, #8]
	fmadd	s8, s23, s16, s15
	fmadd	s4, s4, s16, s5
	fsub	s28, s9, s10
	fmul	s5, s20, s14
	fmadd	s3, s3, s25, s6
	fmadd	s1, s18, s16, s1
	ldp	s6, s2, [x10]
	fadd	s7, s30, s8
	fmadd	s4, s21, s19, s4
	fneg	s26, s28
	fmadd	s0, s0, s25, s5
	fmadd	s3, s22, s17, s3
	fmadd	s27, s27, s13, s11
	add	x13, x30, x16
	fadd	s5, s9, s10
	fmul	s20, s7, s2
	fmadd	s1, s23, s19, s1
	fmul	s2, s2, s26
	fmadd	s0, s24, s17, s0
	stp	s29, s27, [x13, #8]
	add	x10, x25, x16
	add	x13, x23, x16
	fsub	s16, s8, s30
	fmadd	s18, s28, s6, s20
	fneg	s19, s5
	fmadd	s2, s7, s6, s2
	fsub	s6, s4, s3
	ldp	s7, s17, [x10]
	fadd	s20, s0, s1
	fadd	s3, s4, s3
	ldp	s22, s4, [x13]
	fneg	s21, s6
	add	x13, x22, x16
	fmul	s23, s16, s17
	fmul	s17, s17, s19
	fsub	s0, s1, s0
	fneg	s19, s3
	fmul	s1, s20, s4
	add	x10, x27, x16
	fmul	s4, s4, s21
	ldp	s21, s24, [x13]
	stp	s18, s2, [x10, #8]
	fmadd	s2, s5, s7, s23
	fmadd	s5, s16, s7, s17
	add	x10, x24, x16
	fmadd	s1, s6, s22, s1
	fmadd	s4, s20, s22, s4
	fmul	s7, s0, s24
	fmul	s16, s24, s19
	add	x13, x21, x16
	stp	s2, s5, [x10, #8]
	add	x10, x15, x16
	add	x16, x16, #8
	fmadd	s2, s3, s21, s7
	fmadd	s0, s0, s21, s16
	stp	s1, s4, [x13, #8]
	stp	s2, s0, [x10, #8]
	b.ne	.LBB172_9
	b	.LBB172_6
.LBB172_10:
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #176]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #160]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #144]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #128]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.Lfunc_end172:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end172-_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #352
	.cfi_def_cfa_offset 512
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	str	x5, [sp, #280]                  // 8-byte Folded Spill
	stp	x4, x2, [sp, #256]              // 16-byte Folded Spill
	str	x3, [sp, #184]                  // 8-byte Folded Spill
	b.ne	.LBB173_4
// %bb.1:
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	cbz	x8, .LBB173_10
// %bb.2:
	mov	w17, #45383
	mov	w16, #23652
	movk	w17, #16084, lsl #16
	mov	w18, #47867
	movk	w16, #16215, lsl #16
	movk	w18, #15889, lsl #16
	ldp	x2, x1, [sp, #256]              // 16-byte Folded Reload
	dup	v1.2s, w17
	mov	w17, #41301
	movk	w17, #16245, lsl #16
	dup	v0.2s, w16
	mov	w16, #42228
	dup	v2.2s, w18
	mov	w18, #56740
	movk	w16, #16167, lsl #16
	dup	v4.2s, w17
	mov	w17, #25840
	movk	w18, #49000, lsl #16
	movk	w17, #49021, lsl #16
	dup	v3.2s, w16
	mov	w16, #26480
	movk	w16, #48906, lsl #16
	mov	w0, #56740
	dup	v5.2s, w18
	mov	w18, #30926
	dup	v7.2s, w17
	mov	w17, #16192
	movk	w18, #48961, lsl #16
	movk	w17, #16016, lsl #16
	dup	v6.2s, w16
	mov	w16, #16192
	str	d5, [sp, #344]                  // 8-byte Folded Spill
	movk	w16, #48784, lsl #16
	dup	v16.2s, w18
	mov	w18, #25840
	dup	v5.2s, w17
	movk	w18, #16253, lsl #16
	dup	v17.2s, w16
	mov	w16, #26480
	movk	w16, #16138, lsl #16
	movk	w0, #16232, lsl #16
	mov	w9, #48
	mov	w10, #40
	str	d5, [sp, #336]                  // 8-byte Folded Spill
	dup	v5.2s, w18
	mov	w11, #56
	mov	w14, #24
	mov	w15, #72
	mov	w17, #80
	ldr	x18, [sp, #184]                 // 8-byte Folded Reload
	madd	x9, x1, x9, x2
	madd	x10, x1, x10, x2
	str	d5, [sp, #328]                  // 8-byte Folded Spill
	madd	x11, x1, x11, x2
	dup	v5.2s, w16
	madd	x14, x1, x14, x2
	dup	v21.2s, w0
	madd	x15, x1, x15, x2
	mov	x8, xzr
	madd	x17, x1, x17, x2
	add	x12, x2, x1, lsl #5
	add	x13, x2, x1, lsl #6
	add	x16, x2, x1, lsl #4
	add	x18, x18, #40
	add	x0, x2, x1, lsl #3
	str	d5, [sp, #320]                  // 8-byte Folded Spill
.LBB173_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d27, d26, [x18, #32]
	lsl	x1, x8, #3
	add	x8, x8, #1
	ldp	d25, d28, [x18, #-32]
	ldp	d10, d31, [x18, #16]
	fadd	v24.2s, v25.2s, v26.2s
	fsub	v26.2s, v25.2s, v26.2s
	ldp	d29, d30, [x18, #-16]
	fsub	v22.2s, v28.2s, v27.2s
	fadd	v25.2s, v28.2s, v27.2s
	ldur	d23, [x18, #-40]
	fmul	v27.2s, v24.2s, v0.2s
	ldr	d20, [sp, #344]                 // 8-byte Folded Reload
	ldp	d11, d13, [x18]
	fadd	v8.2s, v29.2s, v31.2s
	fsub	v12.2s, v29.2s, v31.2s
	fmul	v28.2s, v22.2s, v20.2s
	rev64	v31.2s, v26.2s
	fmul	v26.2s, v25.2s, v1.2s
	fadd	v27.2s, v23.2s, v27.2s
	fadd	v29.2s, v30.2s, v10.2s
	fsub	v10.2s, v30.2s, v10.2s
	fsub	v14.2s, v11.2s, v13.2s
	fadd	v30.2s, v11.2s, v13.2s
	rev64	v9.2s, v28.2s
	rev64	v28.2s, v12.2s
	fmul	v12.2s, v8.2s, v2.2s
	fadd	v15.2s, v27.2s, v26.2s
	fmul	v13.2s, v29.2s, v3.2s
	rev64	v27.2s, v10.2s
	rev64	v26.2s, v14.2s
	fmul	v11.2s, v30.2s, v4.2s
	fmla	v9.2s, v6.2s, v31.2s
	fmul	v5.2s, v22.2s, v16.2s
	fsub	v14.2s, v15.2s, v12.2s
	fmul	v15.2s, v24.2s, v1.2s
	fmul	v12.2s, v25.2s, v3.2s
	fmul	v19.2s, v24.2s, v3.2s
	fmul	v18.2s, v24.2s, v2.2s
	fadd	v10.2s, v23.2s, v24.2s
	fmla	v9.2s, v7.2s, v28.2s
	rev64	v5.2s, v5.2s
	fsub	v13.2s, v14.2s, v13.2s
	fadd	v15.2s, v23.2s, v15.2s
	fsub	v19.2s, v23.2s, v19.2s
	fmul	v14.2s, v25.2s, v4.2s
	fsub	v18.2s, v23.2s, v18.2s
	fadd	v10.2s, v10.2s, v25.2s
	fmla	v9.2s, v16.2s, v27.2s
	fmla	v5.2s, v20.2s, v31.2s
	fsub	v11.2s, v13.2s, v11.2s
	fmul	v13.2s, v8.2s, v4.2s
	fsub	v12.2s, v15.2s, v12.2s
	fmul	v15.2s, v25.2s, v2.2s
	fmul	v20.2s, v29.2s, v2.2s
	fsub	v18.2s, v18.2s, v14.2s
	fmla	v9.2s, v17.2s, v26.2s
	fadd	v10.2s, v10.2s, v8.2s
	fmul	v24.2s, v24.2s, v4.2s
	ldr	x2, [sp, #256]                  // 8-byte Folded Reload
	fsub	v12.2s, v12.2s, v13.2s
	fsub	v19.2s, v19.2s, v15.2s
	ldr	d15, [sp, #336]                 // 8-byte Folded Reload
	fmul	v13.2s, v8.2s, v1.2s
	fsub	v14.2s, v11.2s, v9.2s
	fadd	v9.2s, v11.2s, v9.2s
	fadd	v10.2s, v10.2s, v29.2s
	fsub	v23.2s, v23.2s, v24.2s
	fmla	v5.2s, v15.2s, v28.2s
	fmul	v15.2s, v22.2s, v15.2s
	fsub	v20.2s, v12.2s, v20.2s
	fmul	v12.2s, v30.2s, v0.2s
	mov	v11.16b, v14.16b
	fadd	v18.2s, v18.2s, v13.2s
	fadd	v10.2s, v10.2s, v30.2s
	rev64	v15.2s, v15.2s
	fmul	v25.2s, v25.2s, v0.2s
	fadd	v20.2s, v20.2s, v12.2s
	ldp	d12, d13, [sp, #320]            // 16-byte Folded Reload
	fmla	v5.2s, v13.2s, v27.2s
	fmul	v13.2s, v22.2s, v13.2s
	mov	v11.s[1], v9.s[1]
	str	d10, [x2, x1]
	fmul	v22.2s, v22.2s, v12.2s
	fmla	v15.2s, v7.2s, v31.2s
	fmul	v10.2s, v29.2s, v0.2s
	fmul	v24.2s, v8.2s, v0.2s
	str	d11, [x0, x1]
	rev64	v11.2s, v13.2s
	fadd	v23.2s, v23.2s, v25.2s
	fmul	v8.2s, v8.2s, v3.2s
	rev64	v22.2s, v22.2s
	fmla	v15.2s, v21.2s, v28.2s
	fmla	v5.2s, v12.2s, v26.2s
	fadd	v18.2s, v18.2s, v10.2s
	fmla	v11.2s, v16.2s, v31.2s
	fmul	v10.2s, v30.2s, v3.2s
	fadd	v19.2s, v19.2s, v24.2s
	fmul	v24.2s, v29.2s, v4.2s
	fmla	v22.2s, v17.2s, v31.2s
	fmla	v15.2s, v6.2s, v27.2s
	fsub	v23.2s, v23.2s, v8.2s
	fmul	v29.2s, v29.2s, v1.2s
	fmla	v11.2s, v6.2s, v28.2s
	fsub	v25.2s, v20.2s, v5.2s
	fsub	v18.2s, v18.2s, v10.2s
	fsub	v19.2s, v19.2s, v24.2s
	fmla	v22.2s, v16.2s, v28.2s
	fmul	v24.2s, v30.2s, v1.2s
	fmla	v15.2s, v16.2s, v26.2s
	fadd	v23.2s, v23.2s, v29.2s
	fmla	v11.2s, v17.2s, v27.2s
	fmul	v28.2s, v30.2s, v2.2s
	fadd	v5.2s, v20.2s, v5.2s
	ldr	x2, [sp, #264]                  // 8-byte Folded Reload
	fmla	v22.2s, v21.2s, v27.2s
	fadd	v19.2s, v19.2s, v24.2s
	mov	v20.16b, v25.16b
	fsub	v24.2s, v18.2s, v15.2s
	fmla	v11.2s, v21.2s, v26.2s
	fsub	v23.2s, v23.2s, v28.2s
	fadd	v18.2s, v18.2s, v15.2s
	add	x18, x18, #88
	fmla	v22.2s, v7.2s, v26.2s
	cmp	x2, x8
	mov	v20.s[1], v5.s[1]
	mov	v5.s[1], v25.s[1]
	mov	v25.16b, v24.16b
	fsub	v27.2s, v19.2s, v11.2s
	str	d20, [x16, x1]
	str	d5, [x15, x1]
	fsub	v5.2s, v23.2s, v22.2s
	fadd	v19.2s, v19.2s, v11.2s
	fadd	v22.2s, v23.2s, v22.2s
	mov	v25.s[1], v18.s[1]
	mov	v18.s[1], v24.s[1]
	mov	v20.16b, v27.16b
	mov	v9.s[1], v14.s[1]
	str	d25, [x14, x1]
	str	d18, [x13, x1]
	mov	v18.16b, v5.16b
	mov	v20.s[1], v19.s[1]
	str	d9, [x17, x1]
	mov	v19.s[1], v27.s[1]
	mov	v18.s[1], v22.s[1]
	str	d20, [x12, x1]
	mov	v22.s[1], v5.s[1]
	str	d19, [x11, x1]
	str	d18, [x10, x1]
	str	d22, [x9, x1]
	b.ne	.LBB173_3
	b	.LBB173_10
.LBB173_4:
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	cbz	x8, .LBB173_10
// %bb.5:
	ldr	x27, [sp, #184]                 // 8-byte Folded Reload
	mov	w11, #88
	mov	w12, #80
	ldr	x29, [sp, #16]                  // 8-byte Folded Reload
	ldp	x2, x26, [sp, #256]             // 16-byte Folded Reload
	add	x10, x27, x1, lsl #3
	madd	x12, x1, x12, x27
	add	x18, x10, #8
	mul	x10, x1, x11
	lsl	x9, x29, #3
	lsl	x11, x29, #4
	add	x13, x9, x29
	add	x14, x11, x27
	lsl	x15, x13, #3
	add	x13, x9, #8
	stp	x13, x10, [sp, #168]            // 16-byte Folded Spill
	add	x10, x12, #8
	add	x17, x27, x13, lsl #3
	mov	w20, #40
	add	x13, x17, #8
	stp	x10, x18, [sp, #240]            // 16-byte Folded Spill
	add	x18, x14, #24
	add	x14, x15, x27
	ldr	x4, [sp, #280]                  // 8-byte Folded Reload
	add	x10, x14, #80
	mov	w7, #48
	lsl	x21, x29, #5
	mov	w19, #56
	mov	x8, xzr
	mov	w25, #47867
	stp	x10, x18, [sp, #224]            // 16-byte Folded Spill
	add	x10, x29, x29, lsl #1
	lsl	x12, x10, #3
	lsl	x10, x10, #4
	add	x16, x12, x27
	add	x18, x21, x27
	add	x14, x16, #32
	add	x16, x18, #40
	mul	x3, x29, x19
	mov	w8, #80
	movk	w25, #15889, lsl #16
	add	x12, x4, x12
	stp	x13, x14, [sp, #208]            // 16-byte Folded Spill
	add	x13, x29, x29, lsl #2
	lsl	x22, x13, #3
	mov	x13, x1
	add	x6, x22, x27
	add	x0, x3, x27
	mul	x13, x26, x13
	add	x18, x6, #48
	dup	v2.2s, w25
	mov	w25, #56740
	movk	w25, #49000, lsl #16
	str	x12, [sp, #136]                 // 8-byte Folded Spill
	madd	x20, x13, x20, x2
	str	x1, [sp, #272]                  // 8-byte Folded Spill
	madd	x23, x13, x7, x2
	add	x7, x10, x27
	add	x14, x20, #8
	add	x10, x4, x10
	dup	v6.2s, w25
	mov	w25, #30926
	movk	w25, #48961, lsl #16
	add	x1, x23, #8
	str	x14, [sp, #200]                 // 8-byte Folded Spill
	add	x14, x4, x22
	add	x23, x2, x13, lsl #6
	madd	x24, x13, x19, x2
	dup	v16.2s, w25
	mov	w25, #24
	str	x14, [sp, #160]                 // 8-byte Folded Spill
	add	x14, x4, x21
	add	x21, x2, x13, lsl #5
	add	x28, x23, #8
	add	x6, x21, #8
	mov	w21, #23652
	movk	w21, #16215, lsl #16
	stp	x10, x14, [sp, #144]            // 16-byte Folded Spill
	mov	w10, #45383
	add	x14, x4, x3
	movk	w10, #16084, lsl #16
	madd	x3, x13, x8, x2
	dup	v0.2s, w21
	mov	w21, #42228
	movk	w21, #16167, lsl #16
	add	x8, x4, x11
	dup	v1.2s, w10
	mov	w10, #41301
	movk	w10, #16245, lsl #16
	madd	x23, x13, x25, x2
	dup	v3.2s, w21
	mov	w21, #26480
	movk	w21, #48906, lsl #16
	stp	x8, x14, [sp, #120]             // 16-byte Folded Spill
	dup	v4.2s, w10
	mov	w10, #25840
	movk	w10, #49021, lsl #16
	add	x8, x4, x9
	dup	v13.2s, w21
	mov	w21, #16192
	movk	w21, #48784, lsl #16
	add	x9, x2, x13, lsl #3
	dup	v7.2s, w10
	mov	w10, #16192
	movk	w10, #16016, lsl #16
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	dup	v17.2s, w21
	mov	w21, #25840
	movk	w21, #16253, lsl #16
	lsl	x8, x26, #2
	dup	v5.2s, w10
	mov	w10, #26480
	movk	w10, #16138, lsl #16
	add	x17, x0, #64
	dup	v18.2s, w21
	mov	w21, #72
	str	x8, [sp, #104]                  // 8-byte Folded Spill
	add	x8, x8, x26
	dup	v14.2s, w10
	mov	w10, #56740
	movk	w10, #16232, lsl #16
	madd	x12, x13, x21, x2
	add	x21, x9, #8
	add	x9, x4, x15
	lsl	x11, x8, #1
	add	x0, x7, #56
	dup	v21.2s, w10
	add	x10, x2, x13, lsl #4
	stp	x9, x8, [sp, #88]               // 16-byte Folded Spill
	lsl	x9, x26, #3
	add	x14, x10, #8
	lsl	x8, x26, #1
	add	x10, x9, x26
	add	x24, x24, #8
	add	x30, x23, #8
	add	x19, x12, #8
	stp	x8, x11, [sp, #72]              // 16-byte Folded Spill
	add	x8, x8, x26
	stp	x10, x9, [sp, #56]              // 16-byte Folded Spill
	sub	x9, x9, x26
	ldp	x26, x20, [sp, #128]            // 16-byte Folded Reload
	mov	x5, xzr
	add	x3, x3, #8
	stp	x9, x8, [sp, #40]               // 16-byte Folded Spill
	lsl	x11, x8, #1
	add	x9, x27, #8
	add	x8, x4, x29, lsl #6
	mov	x23, x2
	stp	d6, d5, [sp, #288]              // 16-byte Folded Spill
	str	d18, [sp, #304]                 // 8-byte Folded Spill
	stp	x8, x11, [sp, #24]              // 16-byte Folded Spill
	str	d13, [sp, #344]                 // 8-byte Folded Spill
	b	.LBB173_7
.LBB173_6:                              //   in Loop: Header=BB173_7 Depth=1
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	ldp	x11, x10, [sp, #328]            // 16-byte Folded Reload
	ldr	x2, [sp, #312]                  // 8-byte Folded Reload
	add	x13, x13, x8
	add	x15, x15, x8
	add	x17, x17, x8
	add	x1, x1, x8
	add	x27, x27, x8
	add	x2, x2, x8
	add	x29, x29, x8
	stp	x15, x13, [sp, #240]            // 16-byte Folded Spill
	add	x16, x0, x8
	stp	x1, x17, [sp, #224]             // 16-byte Folded Spill
	add	x17, x10, x8
	add	x18, x7, x8
	add	x0, x11, x8
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	stp	x29, x27, [sp, #208]            // 16-byte Folded Spill
	ldr	x13, [sp, #320]                 // 8-byte Folded Reload
	ldr	x9, [sp, #192]                  // 8-byte Folded Reload
	add	x23, x23, x8
	add	x22, x22, x8
	add	x1, x13, x8
	add	x24, x24, x8
	add	x6, x6, x8
	add	x28, x28, x8
	add	x30, x30, x8
	add	x19, x12, x8
	add	x14, x14, x8
	add	x3, x3, x8
	add	x21, x21, x8
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	add	x9, x9, #1
	ldr	d18, [sp, #304]                 // 8-byte Folded Reload
	mov	x5, x9
	str	x22, [sp, #200]                 // 8-byte Folded Spill
	cmp	x9, x8
	mov	x9, x2
	b.eq	.LBB173_10
.LBB173_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB173_9 Depth 2
	stp	x9, x1, [sp, #312]              // 16-byte Folded Spill
	mov	w9, #11
	ldp	x7, x13, [sp, #264]             // 16-byte Folded Reload
	mul	x9, x5, x9
	stp	x0, x17, [sp, #328]             // 16-byte Folded Spill
	mov	x0, x16
	ldr	x16, [sp, #184]                 // 8-byte Folded Reload
	add	x25, x9, #10
	mov	x17, x5
	add	x27, x9, #2
	add	x29, x9, #9
	mul	x8, x9, x13
	add	x4, x9, #3
	add	x5, x9, #8
	mul	x25, x25, x13
	add	x15, x13, x8
	mul	x27, x27, x13
	mul	x29, x29, x13
	add	x10, x9, #4
	mul	x13, x4, x13
	ldr	x4, [sp, #272]                  // 8-byte Folded Reload
	ldr	d22, [x16, x15, lsl #3]
	ldr	x15, [sp, #272]                 // 8-byte Folded Reload
	ldr	x12, [sp, #272]                 // 8-byte Folded Reload
	mul	x10, x10, x4
	ldr	d23, [x16, x25, lsl #3]
	mul	x15, x5, x15
	add	x5, x9, #7
	ldr	d24, [x16, x27, lsl #3]
	ldr	d28, [x16, x29, lsl #3]
	ldr	d26, [x16, x8, lsl #3]
	fadd	v29.2s, v22.2s, v23.2s
	ldr	d30, [x16, x15, lsl #3]
	mul	x15, x5, x12
	ldr	x8, [sp, #272]                  // 8-byte Folded Reload
	fsub	v8.2s, v22.2s, v23.2s
	ldr	d25, [x16, x13, lsl #3]
	fsub	v19.2s, v24.2s, v28.2s
	ldr	d31, [x16, x10, lsl #3]
	add	x10, x9, #5
	ldr	d9, [x16, x15, lsl #3]
	add	x9, x9, #6
	ldp	d22, d20, [sp, #288]            // 16-byte Folded Reload
	mul	x8, x10, x8
	fsub	v10.2s, v25.2s, v30.2s
	ldr	x10, [sp, #272]                 // 8-byte Folded Reload
	fadd	v27.2s, v24.2s, v28.2s
	fadd	v24.2s, v25.2s, v30.2s
	fmul	v30.2s, v29.2s, v0.2s
	rev64	v25.2s, v8.2s
	fadd	v23.2s, v31.2s, v9.2s
	fmul	v8.2s, v19.2s, v22.2s
	fsub	v31.2s, v31.2s, v9.2s
	fmul	v9.2s, v29.2s, v1.2s
	mul	x9, x9, x10
	rev64	v6.2s, v10.2s
	fmul	v10.2s, v19.2s, v16.2s
	fadd	v30.2s, v26.2s, v30.2s
	fmul	v11.2s, v27.2s, v1.2s
	fmov	d28, d14
	ldr	d12, [x16, x8, lsl #3]
	rev64	v13.2s, v8.2s
	fadd	v8.2s, v26.2s, v9.2s
	fmul	v9.2s, v27.2s, v3.2s
	ldr	d14, [x16, x9, lsl #3]
	ldr	d5, [sp, #344]                  // 8-byte Folded Reload
	rev64	v10.2s, v10.2s
	fadd	v11.2s, v30.2s, v11.2s
	fmul	v15.2s, v24.2s, v2.2s
	rev64	v30.2s, v31.2s
	str	d25, [sp, #192]                 // 8-byte Folded Spill
	fmla	v13.2s, v5.2s, v25.2s
	fsub	v31.2s, v8.2s, v9.2s
	fmul	v9.2s, v24.2s, v4.2s
	fsub	v5.2s, v12.2s, v14.2s
	fmla	v10.2s, v22.2s, v25.2s
	fsub	v11.2s, v11.2s, v15.2s
	fmul	v15.2s, v23.2s, v3.2s
	fadd	v8.2s, v12.2s, v14.2s
	fmla	v13.2s, v7.2s, v6.2s
	fmul	v12.2s, v23.2s, v2.2s
	fsub	v9.2s, v31.2s, v9.2s
	rev64	v31.2s, v5.2s
	fadd	v5.2s, v26.2s, v29.2s
	fmla	v10.2s, v20.2s, v6.2s
	fsub	v11.2s, v11.2s, v15.2s
	fmul	v14.2s, v8.2s, v4.2s
	fmla	v13.2s, v16.2s, v30.2s
	fmov	d25, d23
	fsub	v9.2s, v9.2s, v12.2s
	fmul	v12.2s, v8.2s, v0.2s
	fadd	v5.2s, v5.2s, v27.2s
	fmla	v10.2s, v18.2s, v30.2s
	fsub	v11.2s, v11.2s, v14.2s
	fmul	v14.2s, v29.2s, v2.2s
	fmla	v13.2s, v17.2s, v31.2s
	fmov	d22, d28
	fadd	v9.2s, v9.2s, v12.2s
	fmov	d23, d18
	fadd	v5.2s, v5.2s, v24.2s
	fmla	v10.2s, v28.2s, v31.2s
	fmul	v18.2s, v19.2s, v20.2s
	fmov	d28, d19
	fsub	v14.2s, v26.2s, v14.2s
	fmul	v19.2s, v27.2s, v4.2s
	ldr	x13, [sp, #272]                 // 8-byte Folded Reload
	fsub	v15.2s, v11.2s, v13.2s
	fadd	v5.2s, v5.2s, v25.2s
	fsub	v20.2s, v9.2s, v10.2s
	fadd	v12.2s, v11.2s, v13.2s
	rev64	v11.2s, v18.2s
	fsub	v18.2s, v14.2s, v19.2s
	fmul	v19.2s, v24.2s, v1.2s
	mul	x8, x17, x13
	fmov	d14, d22
	mov	v13.16b, v15.16b
	ldr	d22, [sp, #192]                 // 8-byte Folded Reload
	fadd	v5.2s, v5.2s, v8.2s
	ldr	x2, [sp, #256]                  // 8-byte Folded Reload
	add	x9, x17, x7
	fadd	v9.2s, v9.2s, v10.2s
	mov	v10.16b, v20.16b
	fmla	v11.2s, v7.2s, v22.2s
	fadd	v18.2s, v18.2s, v19.2s
	str	d5, [x2, x8, lsl #3]
	fmul	v19.2s, v25.2s, v0.2s
	mul	x8, x9, x13
	mov	v13.s[1], v12.s[1]
	ldr	x9, [sp, #80]                   // 8-byte Folded Reload
	mov	v10.s[1], v9.s[1]
	fmla	v11.2s, v21.2s, v6.2s
	mov	v9.s[1], v20.s[1]
	ldr	x12, [sp, #64]                  // 8-byte Folded Reload
	fmul	v20.2s, v29.2s, v3.2s
	str	d13, [x2, x8, lsl #3]
	fadd	v5.2s, v18.2s, v19.2s
	fmul	v18.2s, v8.2s, v3.2s
	fmul	v13.2s, v28.2s, v23.2s
	fmul	v28.2s, v28.2s, v14.2s
	mov	v12.s[1], v15.s[1]
	fmov	d15, d6
	ldr	d6, [sp, #344]                  // 8-byte Folded Reload
	fsub	v19.2s, v26.2s, v20.2s
	fmul	v20.2s, v27.2s, v2.2s
	fsub	v5.2s, v5.2s, v18.2s
	fmul	v18.2s, v29.2s, v4.2s
	rev64	v29.2s, v13.2s
	fmla	v11.2s, v6.2s, v30.2s
	add	x9, x17, x9
	ldr	d13, [sp, #344]                 // 8-byte Folded Reload
	fmul	v23.2s, v25.2s, v1.2s
	fsub	v19.2s, v19.2s, v20.2s
	fmul	v20.2s, v24.2s, v0.2s
	fsub	v18.2s, v26.2s, v18.2s
	fmul	v26.2s, v27.2s, v0.2s
	fmla	v11.2s, v16.2s, v31.2s
	rev64	v27.2s, v28.2s
	fmla	v29.2s, v16.2s, v22.2s
	mul	x8, x9, x13
	fadd	v19.2s, v19.2s, v20.2s
	fmul	v20.2s, v25.2s, v4.2s
	fadd	v18.2s, v18.2s, v26.2s
	fmul	v24.2s, v24.2s, v3.2s
	fsub	v28.2s, v5.2s, v11.2s
	fmla	v27.2s, v17.2s, v22.2s
	ldp	x10, x9, [sp, #48]              // 16-byte Folded Reload
	fmla	v29.2s, v13.2s, v15.2s
	str	d12, [x2, x8, lsl #3]
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	fadd	v5.2s, v5.2s, v11.2s
	fsub	v19.2s, v19.2s, v20.2s
	fsub	v18.2s, v18.2s, v24.2s
	mov	v20.16b, v28.16b
	fmul	v24.2s, v8.2s, v1.2s
	fmla	v29.2s, v17.2s, v30.2s
	fmla	v27.2s, v16.2s, v15.2s
	add	x8, x17, x8
	add	x9, x17, x9
	add	x10, x17, x10
	fmov	d6, d22
	mul	x8, x8, x13
	fadd	v19.2s, v19.2s, v24.2s
	mul	x9, x9, x13
	fmla	v29.2s, v21.2s, v31.2s
	mul	x10, x10, x13
	fadd	v18.2s, v18.2s, v23.2s
	mov	v20.s[1], v5.s[1]
	fmul	v22.2s, v8.2s, v2.2s
	fmla	v27.2s, v21.2s, v30.2s
	add	x15, x17, x12
	str	d10, [x2, x8, lsl #3]
	cmp	x13, #2
	str	d9, [x2, x9, lsl #3]
	mul	x8, x15, x13
	str	d20, [x2, x10, lsl #3]
	fsub	v20.2s, v19.2s, v29.2s
	ldp	x12, x10, [sp, #32]             // 16-byte Folded Reload
	fsub	v18.2s, v18.2s, v22.2s
	fmla	v27.2s, v7.2s, v31.2s
	ldr	x9, [sp, #104]                  // 8-byte Folded Reload
	fadd	v19.2s, v19.2s, v29.2s
	mov	v5.s[1], v28.s[1]
	str	x17, [sp, #192]                 // 8-byte Folded Spill
	mov	v22.16b, v20.16b
	add	x15, x17, x12
	add	x10, x17, x10
	fsub	v23.2s, v18.2s, v27.2s
	add	x9, x17, x9
	str	d5, [x2, x8, lsl #3]
	mul	x8, x10, x13
	ldr	x10, [sp, #96]                  // 8-byte Folded Reload
	mul	x9, x9, x13
	fadd	v5.2s, v18.2s, v27.2s
	mov	v22.s[1], v19.s[1]
	mov	x7, x18
	mov	v18.16b, v23.16b
	add	x10, x17, x10
	mov	v19.s[1], v20.s[1]
	ldr	x22, [sp, #200]                 // 8-byte Folded Reload
	str	d22, [x2, x9, lsl #3]
	mul	x9, x10, x13
	mul	x10, x15, x13
	mov	x12, x19
	mov	v18.s[1], v5.s[1]
	str	d19, [x2, x8, lsl #3]
	mov	v5.s[1], v23.s[1]
	ldr	x19, [sp, #144]                 // 8-byte Folded Reload
	ldp	x15, x13, [sp, #240]            // 16-byte Folded Reload
	str	d18, [x2, x9, lsl #3]
	fmov	d6, d15
	str	d5, [x2, x10, lsl #3]
	ldr	x5, [sp, #88]                   // 8-byte Folded Reload
	ldp	x1, x17, [sp, #224]             // 16-byte Folded Reload
	ldp	x29, x27, [sp, #208]            // 16-byte Folded Reload
	ldp	x18, x16, [sp, #152]            // 16-byte Folded Reload
	ldp	x4, x2, [sp, #112]              // 16-byte Folded Reload
	ldr	x11, [sp, #24]                  // 8-byte Folded Reload
	b.lo	.LBB173_6
// %bb.8:                               //   in Loop: Header=BB173_7 Depth=1
	mov	x25, xzr
	ldr	x9, [sp, #16]                   // 8-byte Folded Reload
.LBB173_9:                              //   Parent Loop BB173_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d5, [x13, x25]
	fmov	d6, d14
	ldr	d18, [x15, x25]
	subs	x9, x9, #1
	ldr	d19, [x17, x25]
	ldr	d20, [x1, x25]
	ldr	d14, [sp, #288]                 // 8-byte Folded Reload
	fadd	v24.2s, v5.2s, v18.2s
	ldr	x8, [sp, #312]                  // 8-byte Folded Reload
	ldr	d26, [x27, x25]
	fsub	v5.2s, v5.2s, v18.2s
	fsub	v23.2s, v19.2s, v20.2s
	ldr	d22, [x8, x25]
	ldr	d27, [x29, x25]
	fadd	v25.2s, v19.2s, v20.2s
	fmul	v20.2s, v24.2s, v0.2s
	ldr	x8, [sp, #336]                  // 8-byte Folded Reload
	ldr	d18, [x0, x25]
	fmul	v29.2s, v23.2s, v14.2s
	ldr	d19, [x8, x25]
	fadd	v28.2s, v26.2s, v27.2s
	fsub	v26.2s, v26.2s, v27.2s
	rev64	v27.2s, v5.2s
	fmul	v5.2s, v25.2s, v1.2s
	fadd	v20.2s, v22.2s, v20.2s
	ldr	x8, [sp, #328]                  // 8-byte Folded Reload
	rev64	v9.2s, v29.2s
	ldr	d31, [x7, x25]
	ldr	d8, [x8, x25]
	fadd	v30.2s, v18.2s, v19.2s
	fsub	v18.2s, v18.2s, v19.2s
	rev64	v29.2s, v26.2s
	fadd	v19.2s, v22.2s, v24.2s
	fmul	v10.2s, v28.2s, v2.2s
	fadd	v5.2s, v20.2s, v5.2s
	fmla	v9.2s, v13.2s, v27.2s
	fadd	v26.2s, v31.2s, v8.2s
	fsub	v20.2s, v31.2s, v8.2s
	rev64	v8.2s, v18.2s
	fmul	v18.2s, v30.2s, v3.2s
	fadd	v19.2s, v19.2s, v25.2s
	ldr	x10, [sp, #280]                 // 8-byte Folded Reload
	fsub	v5.2s, v5.2s, v10.2s
	fmla	v9.2s, v7.2s, v29.2s
	rev64	v31.2s, v20.2s
	fmul	v20.2s, v26.2s, v4.2s
	add	x8, x23, x25
	add	x10, x10, x25
	fadd	v19.2s, v19.2s, v28.2s
	fmul	v10.2s, v23.2s, v16.2s
	fsub	v5.2s, v5.2s, v18.2s
	fmla	v9.2s, v16.2s, v8.2s
	fadd	v18.2s, v19.2s, v30.2s
	rev64	v10.2s, v10.2s
	fsub	v5.2s, v5.2s, v20.2s
	fmla	v9.2s, v17.2s, v31.2s
	fadd	v18.2s, v18.2s, v26.2s
	fmla	v10.2s, v14.2s, v27.2s
	fsub	v19.2s, v5.2s, v9.2s
	fadd	v5.2s, v5.2s, v9.2s
	str	d18, [x8, #8]
	fmul	v18.2s, v24.2s, v1.2s
	fneg	s20, s19
	dup	v11.4s, v5.s[1]
	ld1r	{ v9.2s }, [x10], #4
	mov	v12.16b, v19.16b
	add	x8, x5, x25
	fadd	v18.2s, v22.2s, v18.2s
	mov	v11.s[1], v20.s[0]
	fmul	v20.2s, v25.2s, v3.2s
	ldr	s13, [x10]
	mov	v12.s[1], v5.s[1]
	ldp	d14, d15, [sp, #296]            // 16-byte Folded Reload
	fmul	v11.2s, v11.2s, v13.s[0]
	fmul	v13.2s, v28.2s, v4.2s
	fsub	v18.2s, v18.2s, v20.2s
	fmul	v20.2s, v30.2s, v2.2s
	fmla	v10.2s, v14.2s, v29.2s
	fmla	v11.2s, v9.2s, v12.2s
	fneg	s9, s5
	fsub	v18.2s, v18.2s, v13.2s
	dup	v12.4s, v19.s[1]
	fmul	v13.2s, v26.2s, v0.2s
	str	d11, [x21, x25]
	fmla	v10.2s, v15.2s, v8.2s
	ld1r	{ v11.2s }, [x8], #4
	fsub	v18.2s, v18.2s, v20.2s
	mov	v12.s[1], v9.s[0]
	fmla	v10.2s, v6.2s, v31.2s
	ldr	s20, [x8]
	add	x8, x4, x25
	fadd	v18.2s, v18.2s, v13.2s
	mov	v5.s[1], v19.s[1]
	fmul	v19.2s, v12.2s, v20.s[0]
	fsub	v20.2s, v18.2s, v10.2s
	fmla	v19.2s, v11.2s, v5.2s
	fadd	v5.2s, v18.2s, v10.2s
	fmul	v18.2s, v24.2s, v2.2s
	fmul	v10.2s, v23.2s, v14.2s
	fneg	s9, s20
	fmov	d14, d6
	str	d19, [x3, x25]
	ld1r	{ v19.2s }, [x8], #4
	dup	v11.4s, v5.s[1]
	fsub	v18.2s, v22.2s, v18.2s
	mov	v12.16b, v20.16b
	rev64	v10.2s, v10.2s
	mov	v11.s[1], v9.s[0]
	ldr	s13, [x8]
	fmul	v9.2s, v25.2s, v4.2s
	add	x8, x11, x25
	mov	v12.s[1], v5.s[1]
	fmla	v10.2s, v7.2s, v27.2s
	fmul	v11.2s, v11.2s, v13.s[0]
	fmul	v13.2s, v28.2s, v1.2s
	fsub	v18.2s, v18.2s, v9.2s
	fneg	s9, s5
	fmla	v10.2s, v21.2s, v29.2s
	fmla	v11.2s, v19.2s, v12.2s
	fmul	v19.2s, v30.2s, v0.2s
	fadd	v18.2s, v18.2s, v13.2s
	dup	v12.4s, v20.s[1]
	fmul	v13.2s, v26.2s, v3.2s
	str	d11, [x14, x25]
	ld1r	{ v11.2s }, [x8], #4
	ldr	d6, [sp, #344]                  // 8-byte Folded Reload
	fadd	v18.2s, v18.2s, v19.2s
	mov	v12.s[1], v9.s[0]
	mov	v5.s[1], v20.s[1]
	fmla	v10.2s, v6.2s, v8.2s
	ldr	s19, [x8]
	fsub	v18.2s, v18.2s, v13.2s
	add	x8, x2, x25
	fmul	v19.2s, v12.2s, v19.s[0]
	fmul	v12.2s, v25.2s, v2.2s
	fmla	v10.2s, v16.2s, v31.2s
	fmul	v25.2s, v25.2s, v0.2s
	fmla	v19.2s, v11.2s, v5.2s
	fsub	v20.2s, v18.2s, v10.2s
	fadd	v5.2s, v18.2s, v10.2s
	fmul	v18.2s, v24.2s, v3.2s
	fmul	v10.2s, v23.2s, v15.2s
	str	d19, [x12, x25]
	fmul	v23.2s, v23.2s, v14.2s
	ld1r	{ v19.2s }, [x8], #4
	fneg	s9, s20
	dup	v11.4s, v5.s[1]
	mov	v13.16b, v20.16b
	fsub	v18.2s, v22.2s, v18.2s
	rev64	v10.2s, v10.2s
	rev64	v23.2s, v23.2s
	mov	v11.s[1], v9.s[0]
	ldr	s9, [x8]
	mov	v13.s[1], v5.s[1]
	add	x8, x26, x25
	fsub	v18.2s, v18.2s, v12.2s
	fmla	v10.2s, v16.2s, v27.2s
	dup	v12.4s, v20.s[1]
	fmla	v23.2s, v17.2s, v27.2s
	fmul	v9.2s, v11.2s, v9.s[0]
	fmul	v11.2s, v28.2s, v0.2s
	fmla	v23.2s, v16.2s, v29.2s
	fmla	v9.2s, v19.2s, v13.2s
	ldr	d13, [sp, #344]                 // 8-byte Folded Reload
	fmul	v19.2s, v30.2s, v4.2s
	fadd	v18.2s, v18.2s, v11.2s
	fneg	s11, s5
	fmla	v10.2s, v13.2s, v29.2s
	str	d9, [x30, x25]
	ld1r	{ v9.2s }, [x8], #4
	fsub	v18.2s, v18.2s, v19.2s
	fmul	v19.2s, v26.2s, v1.2s
	mov	v12.s[1], v11.s[0]
	fmla	v23.2s, v21.2s, v8.2s
	fmla	v10.2s, v17.2s, v8.2s
	ldr	s11, [x8]
	add	x8, x20, x25
	fadd	v18.2s, v18.2s, v19.2s
	mov	v5.s[1], v20.s[1]
	fmla	v23.2s, v7.2s, v31.2s
	fmla	v10.2s, v21.2s, v31.2s
	fmul	v19.2s, v12.2s, v11.s[0]
	fsub	v20.2s, v18.2s, v10.2s
	fmla	v19.2s, v9.2s, v5.2s
	fadd	v5.2s, v18.2s, v10.2s
	fmul	v18.2s, v24.2s, v4.2s
	str	d19, [x28, x25]
	fneg	s24, s20
	ld1r	{ v19.2s }, [x8], #4
	dup	v9.4s, v5.s[1]
	fsub	v18.2s, v22.2s, v18.2s
	mov	v9.s[1], v24.s[0]
	mov	v24.16b, v20.16b
	ldr	s22, [x8]
	fadd	v18.2s, v18.2s, v25.2s
	add	x8, x19, x25
	fmul	v25.2s, v28.2s, v3.2s
	fmul	v22.2s, v9.2s, v22.s[0]
	mov	v24.s[1], v5.s[1]
	fsub	v18.2s, v18.2s, v25.2s
	fmul	v25.2s, v26.2s, v2.2s
	fmla	v22.2s, v19.2s, v24.2s
	fmul	v19.2s, v30.2s, v1.2s
	fneg	s24, s5
	mov	v5.s[1], v20.s[1]
	str	d22, [x6, x25]
	ld1r	{ v22.2s }, [x8], #4
	fadd	v18.2s, v18.2s, v19.2s
	dup	v19.4s, v20.s[1]
	mov	v19.s[1], v24.s[0]
	ldr	s24, [x8]
	add	x8, x18, x25
	fsub	v18.2s, v18.2s, v25.2s
	fmul	v19.2s, v19.2s, v24.s[0]
	fsub	v20.2s, v18.2s, v23.2s
	fmla	v19.2s, v22.2s, v5.2s
	fadd	v5.2s, v18.2s, v23.2s
	fneg	s18, s20
	str	d19, [x24, x25]
	ld1r	{ v19.2s }, [x8], #4
	dup	v22.4s, v5.s[1]
	mov	v23.16b, v20.16b
	mov	v22.s[1], v18.s[0]
	ldr	s18, [x8]
	add	x8, x16, x25
	mov	v23.s[1], v5.s[1]
	fmul	v18.2s, v22.2s, v18.s[0]
	dup	v22.4s, v20.s[1]
	fmla	v18.2s, v19.2s, v23.2s
	fneg	s19, s5
	mov	v5.s[1], v20.s[1]
	str	d18, [x22, x25]
	ld1r	{ v18.2s }, [x8], #4
	mov	v22.s[1], v19.s[0]
	ldr	s19, [x8]
	ldr	x8, [sp, #320]                  // 8-byte Folded Reload
	fmul	v19.2s, v22.2s, v19.s[0]
	fmla	v19.2s, v18.2s, v5.2s
	str	d19, [x8, x25]
	add	x25, x25, #8
	b.ne	.LBB173_9
	b	.LBB173_6
.LBB173_10:
	add	sp, sp, #352
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end173:
	.size	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end173-_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_,@function
_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_: // @_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #464
	stp	x29, x30, [sp, #368]            // 16-byte Folded Spill
	add	x29, sp, #368
	stp	x28, x27, [sp, #384]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #400]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #416]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #432]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #448]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #3
	mov	x26, x7
	add	x0, x8, #64
	stur	x6, [x29, #-104]                // 8-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x27, x4
	mov	x28, x3
	mov	x25, x1
	bl	malloc
	cbz	x0, .LBB174_158
// %bb.1:
	add	x8, x0, #64
	add	x22, x23, #1
	and	x14, x8, #0xffffffffffffffc0
	mul	x8, x28, x25
	subs	x15, x23, #2
	lsr	x5, x22, #1
	stp	x25, x28, [x29, #-80]           // 16-byte Folded Spill
	stp	x14, x27, [x29, #-40]           // 16-byte Folded Spill
	stur	x8, [x29, #-16]                 // 8-byte Folded Spill
	mov	w8, #1065353216
	str	x5, [sp, #160]                  // 8-byte Folded Spill
	stp	x0, x8, [x14, #-8]
	b.lo	.LBB174_4
// %bb.2:
	sub	x17, x23, #1
	cmp	x17, #8
	b.hs	.LBB174_6
// %bb.3:
	mov	w8, #1
	b	.LBB174_13
.LBB174_4:
	cbz	x28, .LBB174_125
// %bb.5:
	cbnz	x25, .LBB174_17
	b	.LBB174_125
.LBB174_6:
	cmp	xzr, x15, lsr #61
	add	x11, x14, #8
	lsl	x10, x15, #3
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB174_13
// %bb.7:
	tbnz	w9, #0, .LBB174_13
// %bb.8:
	add	x11, x14, #12
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB174_13
// %bb.9:
	tbnz	w9, #0, .LBB174_13
// %bb.10:
	and	x9, x17, #0xfffffffffffffff8
	add	x10, x14, #40
	orr	x8, x9, #0x1
	add	x11, x26, #40
	mov	x12, x9
.LBB174_11:                             // =>This Inner Loop Header: Depth=1
	ld2	{ v0.4s, v1.4s }, [x11]
	sub	x13, x11, #32
	add	x11, x11, #64
	subs	x12, x12, #8
	ld2	{ v2.4s, v3.4s }, [x13]
	sub	x13, x10, #32
	fneg	v1.4s, v1.4s
	fneg	v3.4s, v3.4s
	st2	{ v0.4s, v1.4s }, [x10]
	add	x10, x10, #64
	st2	{ v2.4s, v3.4s }, [x13]
	b.ne	.LBB174_11
// %bb.12:
	cmp	x17, x9
	b.eq	.LBB174_15
.LBB174_13:
	sub	x9, x23, x8
	lsl	x8, x8, #3
	add	x10, x26, x8
	add	x11, x14, x8
	add	x8, x10, #4
	add	x10, x11, #4
.LBB174_14:                             // =>This Inner Loop Header: Depth=1
	ldr	s0, [x8]
	subs	x9, x9, #1
	ldur	w11, [x8, #-4]
	add	x8, x8, #8
	fneg	s0, s0
	stur	w11, [x10, #-4]
	str	s0, [x10], #8
	b.ne	.LBB174_14
.LBB174_15:
	cbz	x28, .LBB174_75
// %bb.16:
	cbz	x25, .LBB174_77
.LBB174_17:
	mul	x8, x23, x25
	lsl	x2, x25, #3
	mov	x19, x28
	mov	x26, x24
	lsl	x21, x8, #3
	str	x15, [sp, #152]                 // 8-byte Folded Spill
	stur	x2, [x29, #-112]                // 8-byte Folded Spill
.LBB174_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	bl	memcpy
	ldur	x2, [x29, #-112]                // 8-byte Folded Reload
	add	x27, x27, x21
	subs	x19, x19, #1
	add	x26, x26, x2
	b.ne	.LBB174_18
// %bb.19:
	sub	x8, x23, #1
	str	x22, [sp, #144]                 // 8-byte Folded Spill
	cmp	x22, #3
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	b.ls	.LBB174_44
// %bb.20:
	cbz	x25, .LBB174_92
// %bb.21:
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	mov	w9, #2
	lsl	x11, x28, #3
	sub	x10, x25, #1
	add	x11, x11, #8
	lsl	x14, x10, #3
	cmp	x8, #2
	mov	x12, xzr
	csel	x8, x8, x9, hi
	mul	x11, x11, x25
	cmp	xzr, x10, lsr #61
	add	x18, x14, #8
	cset	w13, ne
	stur	x8, [x29, #-168]                // 8-byte Folded Spill
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	stur	x11, [x29, #-64]                // 8-byte Folded Spill
	mul	x9, x8, x28
	mul	x15, x0, x8
	lsl	x9, x9, #3
	add	x9, x9, #8
	add	x17, x24, x15, lsl #3
	mul	x11, x9, x25
	and	x9, x25, #0xfffffffffffffffc
	stur	x15, [x29, #-176]               // 8-byte Folded Spill
	stp	x9, x11, [x29, #-96]            // 16-byte Folded Spill
	mul	x9, x25, x8
	lsl	x8, x0, #3
	add	x11, x24, x0, lsl #3
	str	x8, [sp, #184]                  // 8-byte Folded Spill
	neg	x8, x8
	str	x8, [sp, #176]                  // 8-byte Folded Spill
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-112]               // 8-byte Folded Reload
	add	x3, x8, x9, lsl #3
	mov	w9, #1
	add	x2, x8, x10
	neg	x8, x10
	str	x8, [sp, #168]                  // 8-byte Folded Spill
.LBB174_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB174_23 Depth 2
                                        //       Child Loop BB174_36 Depth 3
                                        //       Child Loop BB174_41 Depth 3
	ldur	x8, [x29, #-176]                // 8-byte Folded Reload
	stp	x9, x3, [x29, #-160]            // 16-byte Folded Spill
	mul	x9, x0, x12
	mov	x6, xzr
	madd	x20, x0, x12, x0
	stp	x11, x12, [x29, #-128]          // 16-byte Folded Spill
	msub	x7, x0, x12, x8
	add	x10, x0, x9
	sub	x8, x8, x9
	stp	x2, x17, [x29, #-144]           // 16-byte Folded Spill
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	stp	x8, x10, [x29, #-56]            // 16-byte Folded Spill
	mov	x10, x11
.LBB174_23:                             //   Parent Loop BB174_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB174_36 Depth 3
                                        //       Child Loop BB174_41 Depth 3
	cmp	x25, #4
	b.hs	.LBB174_25
// %bb.24:                              //   in Loop: Header=BB174_23 Depth=2
	mov	x19, xzr
	b	.LBB174_40
.LBB174_25:                             //   in Loop: Header=BB174_23 Depth=2
	mul	x22, x6, x25
	mov	x19, xzr
	add	x11, x7, x22
	add	x12, x20, x22
	add	x11, x24, x11, lsl #3
	add	x0, x24, x12, lsl #3
	add	x12, x11, #4
	add	x16, x11, x14
	add	x1, x0, #4
	cmp	x16, x11
	add	x11, x12, x14
	cset	w4, lo
	cmp	x11, x12
	add	x11, x1, x14
	cset	w12, lo
	cmp	x11, x1
	add	x11, x0, x14
	cset	w16, lo
	cmp	x11, x0
	orr	w0, w4, w13
	cset	w11, lo
	tbnz	w0, #0, .LBB174_40
// %bb.26:                              //   in Loop: Header=BB174_23 Depth=2
	orr	w12, w12, w13
	tbnz	w12, #0, .LBB174_40
// %bb.27:                              //   in Loop: Header=BB174_23 Depth=2
	orr	w12, w16, w13
	tbnz	w12, #0, .LBB174_40
// %bb.28:                              //   in Loop: Header=BB174_23 Depth=2
	orr	w11, w11, w13
	tbnz	w11, #0, .LBB174_40
// %bb.29:                              //   in Loop: Header=BB174_23 Depth=2
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	mov	x9, x24
	ldp	x15, x12, [x29, #-56]           // 16-byte Folded Reload
	mov	x19, xzr
	add	x11, x8, x22
	sub	x0, x22, x8
	ldur	x8, [x29, #-64]                 // 8-byte Folded Reload
	add	x11, x24, x11, lsl #3
	add	x0, x24, x0, lsl #3
	add	x12, x12, x22
	add	x16, x15, x22
	add	x11, x11, x8
	ldur	x8, [x29, #-88]                 // 8-byte Folded Reload
	add	x12, x24, x12, lsl #3
	sub	x1, x11, #4
	add	x5, x12, #4
	cmp	x11, x12
	add	x8, x0, x8
	cset	w26, hi
	sub	x9, x8, #4
	cmp	x1, x5
	add	x30, x24, x16, lsl #3
	cset	w27, hi
	cmp	x9, x12
	add	x15, x30, #4
	cset	w16, hi
	cmp	x1, x30
	cset	w22, hi
	cmp	x8, x12
	cset	w0, hi
	cmp	x1, x15
	cset	w28, hi
	cmp	x9, x5
	cset	w25, hi
	cmp	x11, x30
	cset	w4, hi
	cmp	x8, x5
	cset	w5, hi
	cmp	x11, x15
	cset	w11, hi
	cmp	x8, x30
	cset	w1, hi
	cmp	x9, x15
	and	w8, w26, w27
	cset	w12, hi
	tbnz	w8, #0, .LBB174_38
// %bb.30:                              //   in Loop: Header=BB174_23 Depth=2
	and	w8, w16, w22
	tbnz	w8, #0, .LBB174_38
// %bb.31:                              //   in Loop: Header=BB174_23 Depth=2
	and	w8, w0, w28
	tbnz	w8, #0, .LBB174_38
// %bb.32:                              //   in Loop: Header=BB174_23 Depth=2
	and	w8, w25, w4
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB174_39
// %bb.33:                              //   in Loop: Header=BB174_23 Depth=2
	and	w8, w5, w11
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB174_40
// %bb.34:                              //   in Loop: Header=BB174_23 Depth=2
	and	w8, w1, w12
	tbnz	w8, #0, .LBB174_40
// %bb.35:                              //   in Loop: Header=BB174_23 Depth=2
	ldur	x19, [x29, #-96]                // 8-byte Folded Reload
	mov	x22, x3
	mov	x28, x2
	mov	x0, x17
	mov	x16, x10
.LBB174_36:                             //   Parent Loop BB174_22 Depth=1
                                        //     Parent Loop BB174_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.4s, v1.4s }, [x28], #32
	subs	x19, x19, #4
	ld2	{ v2.4s, v3.4s }, [x22], #32
	fadd	v4.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x16], #32
	fsub	v4.4s, v0.4s, v2.4s
	fsub	v5.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x0], #32
	b.ne	.LBB174_36
// %bb.37:                              //   in Loop: Header=BB174_23 Depth=2
	ldur	x8, [x29, #-96]                 // 8-byte Folded Reload
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	mov	x19, x8
	cmp	x8, x25
	b.ne	.LBB174_40
	b	.LBB174_42
.LBB174_38:                             //   in Loop: Header=BB174_23 Depth=2
	ldp	x25, x28, [x29, #-80]           // 16-byte Folded Reload
	b	.LBB174_40
.LBB174_39:                             //   in Loop: Header=BB174_23 Depth=2
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
.LBB174_40:                             //   in Loop: Header=BB174_23 Depth=2
	sub	x16, x25, x19
	lsl	x0, x19, #3
.LBB174_41:                             //   Parent Loop BB174_22 Depth=1
                                        //     Parent Loop BB174_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x8, x2, x0
	add	x9, x3, x0
	subs	x16, x16, #1
	ldp	s0, s1, [x8]
	ldp	s2, s3, [x9]
	add	x8, x10, x0
	add	x9, x17, x0
	add	x0, x0, #8
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stp	s4, s5, [x8]
	stp	s0, s1, [x9]
	b.ne	.LBB174_41
.LBB174_42:                             //   in Loop: Header=BB174_23 Depth=2
	add	x6, x6, #1
	add	x10, x10, x18
	add	x17, x17, x18
	add	x2, x2, x21
	add	x3, x3, x21
	cmp	x6, x28
	b.ne	.LBB174_23
// %bb.43:                              //   in Loop: Header=BB174_22 Depth=1
	ldp	x11, x12, [x29, #-128]          // 16-byte Folded Reload
	ldr	x8, [sp, #184]                  // 8-byte Folded Reload
	ldp	x2, x17, [x29, #-144]           // 16-byte Folded Reload
	add	x11, x11, x8
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	ldp	x9, x3, [x29, #-160]            // 16-byte Folded Reload
	add	x12, x12, #1
	add	x2, x2, x18
	add	x17, x17, x8
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	add	x9, x9, #1
	add	x3, x3, x8
	ldur	x8, [x29, #-168]                // 8-byte Folded Reload
	cmp	x9, x8
	b.ne	.LBB174_22
.LBB174_44:
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldr	x2, [sp, #144]                  // 8-byte Folded Reload
	ldur	x18, [x29, #-112]               // 8-byte Folded Reload
	cbz	x25, .LBB174_52
// %bb.45:
	cmp	x2, #3
	b.ls	.LBB174_79
// %bb.46:
	cmp	x5, #2
	mov	w9, #2
	csel	x9, x5, x9, hi
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x24, x0, lsl #3
	lsl	x11, x0, #3
.LBB174_47:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB174_48 Depth 2
                                        //       Child Loop BB174_49 Depth 3
	mul	x13, x8, x25
	mov	x12, xzr
	mov	x14, x10
.LBB174_48:                             //   Parent Loop BB174_47 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB174_49 Depth 3
	add	x15, x12, x13
	mov	x16, x14
	mov	x17, x9
	ldr	d0, [x24, x15, lsl #3]
.LBB174_49:                             //   Parent Loop BB174_47 Depth=1
                                        //     Parent Loop BB174_48 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d1, [x16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.2s, v0.2s, v1.2s
	b.ne	.LBB174_49
// %bb.50:                              //   in Loop: Header=BB174_48 Depth=2
	add	x12, x12, #1
	add	x14, x14, #8
	cmp	x12, x25
	str	d0, [x27, x15, lsl #3]
	b.ne	.LBB174_48
// %bb.51:                              //   in Loop: Header=BB174_47 Depth=1
	add	x8, x8, #1
	add	x10, x10, x18
	cmp	x8, x28
	b.ne	.LBB174_47
.LBB174_52:
	mov	w10, wzr
	mov	w9, wzr
	ldr	x17, [sp, #8]                   // 8-byte Folded Reload
	cmp	x2, #4
	ldr	x15, [sp, #152]                 // 8-byte Folded Reload
	b.hs	.LBB174_93
// %bb.53:
	subs	x8, x25, #1
	b.ne	.LBB174_123
.LBB174_54:
	cmp	x0, #0
	eor	w9, w9, #0x1
	cset	w8, eq
	orr	w8, w9, w8
	tbnz	w8, #0, .LBB174_125
// %bb.55:
	mul	x10, x17, x28
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	lsl	x11, x17, #3
	cmp	x5, #2
	add	x12, x11, #8
	mov	w9, #2
	sub	x14, x0, #1
	mul	x10, x10, x25
	csel	x9, x5, x9, hi
	mul	x12, x0, x12
	cmp	xzr, x14, lsr #61
	lsl	x14, x14, #3
	mov	x8, xzr
	lsl	x11, x0, #1
	cset	w13, ne
	and	x15, x0, #0xfffffffffffffffc
	add	x16, x27, x0, lsl #3
	add	x17, x14, #8
	add	x18, x27, x10, lsl #3
	neg	x0, x0, lsl #3
	mov	w1, #1
.LBB174_56:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB174_72 Depth 2
                                        //     Child Loop BB174_59 Depth 2
	ldur	x4, [x29, #-16]                 // 8-byte Folded Reload
	cmp	x4, #4
	b.hs	.LBB174_61
// %bb.57:                              //   in Loop: Header=BB174_56 Depth=1
	mov	x2, xzr
.LBB174_58:                             //   in Loop: Header=BB174_56 Depth=1
	ldur	x3, [x29, #-16]                 // 8-byte Folded Reload
	sub	x3, x3, x2
	lsl	x2, x2, #3
.LBB174_59:                             //   Parent Loop BB174_56 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x4, x16, x2
	add	x5, x18, x2
	subs	x3, x3, #1
	add	x2, x2, #8
	ldp	s0, s1, [x4]
	ldp	s2, s3, [x5]
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stp	s4, s5, [x4]
	stp	s0, s1, [x5]
	b.ne	.LBB174_59
.LBB174_60:                             //   in Loop: Header=BB174_56 Depth=1
	add	x1, x1, #1
	add	x8, x8, #1
	add	x16, x16, x17
	add	x18, x18, x0
	cmp	x1, x9
	b.ne	.LBB174_56
	b	.LBB174_125
.LBB174_61:                             //   in Loop: Header=BB174_56 Depth=1
	msub	x3, x4, x8, x10
	mov	x2, xzr
	madd	x4, x4, x8, x4
	add	x3, x27, x3, lsl #3
	add	x5, x3, #4
	add	x6, x27, x4, lsl #3
	add	x4, x5, x14
	add	x7, x6, #4
	cmp	x4, x5
	add	x4, x3, x14
	cset	w19, lo
	cmp	x4, x3
	add	x3, x7, x14
	cset	w4, lo
	cmp	x3, x7
	add	x3, x6, x14
	cset	w5, lo
	cmp	x3, x6
	orr	w6, w19, w13
	cset	w3, lo
	tbnz	w6, #0, .LBB174_58
// %bb.62:                              //   in Loop: Header=BB174_56 Depth=1
	orr	w4, w4, w13
	tbnz	w4, #0, .LBB174_58
// %bb.63:                              //   in Loop: Header=BB174_56 Depth=1
	orr	w4, w5, w13
	tbnz	w4, #0, .LBB174_58
// %bb.64:                              //   in Loop: Header=BB174_56 Depth=1
	orr	w3, w3, w13
	tbnz	w3, #0, .LBB174_58
// %bb.65:                              //   in Loop: Header=BB174_56 Depth=1
	ldur	x4, [x29, #-16]                 // 8-byte Folded Reload
	mov	x2, xzr
	mul	x3, x4, x8
	add	x4, x4, x3
	add	x5, x11, x3
	sub	x6, x10, x3
	sub	x3, x27, x3, lsl #3
	add	x4, x27, x4, lsl #3
	add	x21, x27, x5, lsl #3
	add	x23, x27, x6, lsl #3
	add	x24, x3, x12
	sub	x6, x21, #4
	add	x19, x4, #4
	cmp	x4, x21
	sub	x25, x24, #4
	cset	w27, lo
	cmp	x19, x6
	cset	w28, lo
	cmp	x25, x4
	cset	w3, hi
	cmp	x23, x6
	add	x26, x23, #4
	cset	w5, lo
	cmp	x24, x4
	cset	w4, hi
	cmp	x26, x6
	cset	w7, lo
	cmp	x25, x19
	cset	w6, hi
	cmp	x23, x21
	cset	w20, lo
	cmp	x24, x19
	cset	w19, hi
	cmp	x26, x21
	cset	w22, lo
	cmp	x24, x23
	cset	w21, hi
	cmp	x25, x26
	and	w24, w27, w28
	cset	w23, hi
	tbnz	w24, #0, .LBB174_74
// %bb.66:                              //   in Loop: Header=BB174_56 Depth=1
	and	w3, w3, w5
	tbnz	w3, #0, .LBB174_74
// %bb.67:                              //   in Loop: Header=BB174_56 Depth=1
	and	w3, w4, w7
	tbnz	w3, #0, .LBB174_74
// %bb.68:                              //   in Loop: Header=BB174_56 Depth=1
	and	w3, w6, w20
	tbnz	w3, #0, .LBB174_74
// %bb.69:                              //   in Loop: Header=BB174_56 Depth=1
	and	w3, w19, w22
	tbnz	w3, #0, .LBB174_74
// %bb.70:                              //   in Loop: Header=BB174_56 Depth=1
	and	w3, w21, w23
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w3, #0, .LBB174_58
// %bb.71:                              //   in Loop: Header=BB174_56 Depth=1
	mov	x2, x15
	mov	x3, x18
	mov	x4, x16
.LBB174_72:                             //   Parent Loop BB174_56 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v0.4s, v1.4s }, [x4]
	subs	x2, x2, #4
	ld2	{ v2.4s, v3.4s }, [x3]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v6.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v7.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x4], #32
	st2	{ v6.4s, v7.4s }, [x3], #32
	b.ne	.LBB174_72
// %bb.73:                              //   in Loop: Header=BB174_56 Depth=1
	ldur	x3, [x29, #-16]                 // 8-byte Folded Reload
	mov	x2, x15
	cmp	x3, x15
	b.ne	.LBB174_58
	b	.LBB174_60
.LBB174_74:                             //   in Loop: Header=BB174_56 Depth=1
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	b	.LBB174_58
.LBB174_75:
	mov	w10, #1
	cmp	x22, #3
	b.ls	.LBB174_91
// %bb.76:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	b	.LBB174_93
.LBB174_77:
	cmp	x22, #3
	b.ls	.LBB174_125
// %bb.78:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	mov	w10, wzr
	b	.LBB174_93
.LBB174_79:
	sub	x12, x25, #1
	mov	x8, xzr
	mov	x9, xzr
	and	x10, x25, #0xfffffffffffffff8
	cmp	xzr, x12, lsr #61
	lsl	x12, x12, #3
	add	x11, x27, #32
	cset	w13, ne
	add	x14, x12, #8
	add	x15, x24, #32
	b	.LBB174_81
.LBB174_80:                             //   in Loop: Header=BB174_81 Depth=1
	add	x9, x9, #1
	add	x11, x11, x14
	add	x15, x15, x14
	add	x8, x8, x25
	cmp	x9, x28
	b.eq	.LBB174_52
.LBB174_81:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB174_88 Depth 2
                                        //     Child Loop BB174_84 Depth 2
	cmp	x25, #8
	b.hs	.LBB174_85
// %bb.82:                              //   in Loop: Header=BB174_81 Depth=1
	mov	x16, xzr
.LBB174_83:                             //   in Loop: Header=BB174_81 Depth=1
	add	x17, x16, x8
	sub	x16, x25, x16
	lsl	x18, x17, #3
	add	x17, x27, x18
	add	x18, x24, x18
.LBB174_84:                             //   Parent Loop BB174_81 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x18], #8
	subs	x16, x16, #1
	str	d0, [x17], #8
	b.ne	.LBB174_84
	b	.LBB174_80
.LBB174_85:                             //   in Loop: Header=BB174_81 Depth=1
	mul	x17, x9, x25
	mov	x16, xzr
	add	x17, x27, x17, lsl #3
	add	x18, x17, x12
	add	x0, x17, #4
	cmp	x18, x17
	add	x18, x0, x12
	cset	w17, lo
	cmp	x18, x0
	orr	w1, w17, w13
	cset	w17, lo
	tbnz	w1, #0, .LBB174_90
// %bb.86:                              //   in Loop: Header=BB174_81 Depth=1
	orr	w17, w17, w13
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	tbnz	w17, #0, .LBB174_83
// %bb.87:                              //   in Loop: Header=BB174_81 Depth=1
	mov	x16, x10
	mov	x17, x15
	mov	x18, x11
.LBB174_88:                             //   Parent Loop BB174_81 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x17, #-32]
	subs	x16, x16, #8
	ldp	q3, q2, [x17], #64
	stp	q1, q0, [x18, #-32]
	stp	q3, q2, [x18], #64
	b.ne	.LBB174_88
// %bb.89:                              //   in Loop: Header=BB174_81 Depth=1
	mov	x16, x10
	cmp	x10, x25
	b.eq	.LBB174_80
	b	.LBB174_83
.LBB174_90:                             //   in Loop: Header=BB174_81 Depth=1
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	b	.LBB174_83
.LBB174_91:
	mov	w9, wzr
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	subs	x8, x25, #1
	b.ne	.LBB174_123
	b	.LBB174_54
.LBB174_92:
	ldp	x15, x5, [sp, #152]             // 16-byte Folded Reload
	mov	w10, wzr
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	ldr	x17, [sp, #8]                   // 8-byte Folded Reload
.LBB174_93:
	sub	x9, x5, #1
	str	w10, [sp, #4]                   // 4-byte Folded Spill
	lsl	x11, x17, #3
	sub	x13, x0, #1
	add	x11, x11, #8
	cmp	x5, #2
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	mul	x9, x17, x28
	mov	w10, #2
	mul	x8, x0, x15
	csel	x10, x5, x10, hi
	cmp	xzr, x13, lsr #61
	mul	x21, x9, x25
	lsl	x6, x0, #3
	mul	x9, x0, x11
	add	x8, x24, x8, lsl #3
	mul	x14, x0, x17
	sub	x15, x23, #3
	str	x17, [sp, #8]                   // 8-byte Folded Spill
	add	x7, x27, x6
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	lsl	x10, x14, #3
	str	x9, [sp, #136]                  // 8-byte Folded Spill
	cset	w9, ne
	add	x4, x27, x10
	lsl	x30, x0, #4
	mov	x19, xzr
	lsl	x12, x0, #1
	str	w9, [sp, #100]                  // 4-byte Folded Spill
	lsl	x9, x13, #3
	mul	x13, x0, x15
	and	x1, x0, #0xfffffffffffffffc
	neg	x26, x6
	add	x11, x7, #4
	str	x9, [sp, #88]                   // 8-byte Folded Spill
	add	x9, x24, x6
	add	x22, x9, #4
	add	x9, x24, x0, lsl #4
	add	x9, x9, #4
	stur	x14, [x29, #-56]                // 8-byte Folded Spill
	str	x15, [sp, #104]                 // 8-byte Folded Spill
	mov	w15, #1
	stp	x8, x9, [sp, #72]               // 16-byte Folded Spill
	sub	x9, x23, #4
	add	x8, x24, x10
	mov	w10, #24
	mul	x9, x0, x9
	add	x8, x8, #4
	madd	x18, x0, x10, x24
	add	x10, x24, x13, lsl #3
	stp	x13, x8, [sp, #56]              // 16-byte Folded Spill
	add	x8, x24, x0, lsl #5
	str	x9, [sp, #48]                   // 8-byte Folded Spill
	add	x9, x24, x9, lsl #3
	stp	x8, x18, [sp, #32]              // 16-byte Folded Spill
	neg	x8, x30
	stp	x9, x10, [sp, #16]              // 16-byte Folded Spill
	ldur	x3, [x29, #-40]                 // 8-byte Folded Reload
	stur	x0, [x29, #-64]                 // 8-byte Folded Spill
	str	x21, [sp, #144]                 // 8-byte Folded Spill
	stp	x22, x6, [sp, #120]             // 16-byte Folded Spill
	str	x26, [sp, #112]                 // 8-byte Folded Spill
	b	.LBB174_95
.LBB174_94:                             //   in Loop: Header=BB174_95 Depth=1
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	add	x15, x15, #1
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	add	x19, x19, #1
	ldur	x11, [x29, #-88]                // 8-byte Folded Reload
	add	x4, x4, x26
	add	x7, x7, x6
	add	x9, x9, x0
	add	x11, x11, x6
	stur	x9, [x29, #-64]                 // 8-byte Folded Spill
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	sub	x9, x9, x0
	stur	x9, [x29, #-56]                 // 8-byte Folded Spill
	ldp	x21, x9, [sp, #144]             // 16-byte Folded Reload
	cmp	x15, x9
	b.eq	.LBB174_122
.LBB174_95:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB174_97 Depth 2
                                        //     Child Loop BB174_103 Depth 2
                                        //       Child Loop BB174_107 Depth 3
                                        //       Child Loop BB174_110 Depth 3
                                        //     Child Loop BB174_116 Depth 2
                                        //       Child Loop BB174_118 Depth 3
                                        //       Child Loop BB174_121 Depth 3
	mul	x16, x0, x19
	stur	x11, [x29, #-88]                // 8-byte Folded Spill
	sub	x20, x21, x16
	sub	x10, x27, x16, lsl #3
	cbz	x0, .LBB174_99
// %bb.96:                              //   in Loop: Header=BB174_95 Depth=1
	stur	x10, [x29, #-48]                // 8-byte Folded Spill
	add	x18, x3, x15, lsl #3
	ldp	x28, x25, [sp, #72]             // 16-byte Folded Reload
	mov	x14, x0
	add	x0, x3, x15, lsl #4
	mov	x17, xzr
	lsl	x13, x15, #1
	add	x2, x18, #4
	add	x5, x0, #4
	ldur	x10, [x29, #-88]                // 8-byte Folded Reload
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
.LBB174_97:                             //   Parent Loop BB174_95 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x3, x24, x17
	add	x9, x22, x17
	ldr	s0, [x18]
	add	x6, x25, x17
	ldr	s3, [x0]
	subs	x14, x14, #1
	ldp	s2, s4, [x3]
	ldur	s1, [x9, #-4]
	add	x3, x10, x17
	fmadd	s0, s0, s1, s2
	ldp	s1, s2, [x6, #-4]
	fmadd	s0, s3, s1, s0
	ldr	s1, [x9]
	add	x9, x28, x17
	stur	s0, [x3, #-4]
	ldr	s0, [x18]
	fmadd	s0, s0, s1, s4
	ldr	s1, [x0]
	fmadd	s0, s1, s2, s0
	ldp	s3, s2, [x9]
	add	x9, x4, x17
	str	s0, [x3]
	add	x3, x11, x17
	ldr	s0, [x5]
	add	x17, x17, #8
	fneg	s1, s0
	fmul	s0, s0, s3
	ldp	s3, s4, [x3, #-4]
	fmul	s1, s2, s1
	ldr	s2, [x2]
	fmadd	s0, s2, s3, s0
	fmsub	s1, s2, s4, s1
	str	s0, [x9, #4]
	str	s1, [x9]
	b.ne	.LBB174_97
// %bb.98:                              //   in Loop: Header=BB174_95 Depth=1
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	b	.LBB174_100
.LBB174_99:                             //   in Loop: Header=BB174_95 Depth=1
	lsl	x13, x15, #1
.LBB174_100:                            //   in Loop: Header=BB174_95 Depth=1
	ldr	x14, [sp, #136]                 // 8-byte Folded Reload
	add	x17, x12, x16
	msub	x11, x0, x19, x21
	add	x9, x0, x16
	add	x16, x27, x17, lsl #3
	stur	x19, [x29, #-96]                // 8-byte Folded Spill
	add	x18, x10, x14
	madd	x14, x0, x19, x0
	add	x19, x27, x9, lsl #3
	sub	x5, x16, #4
	add	x6, x27, x20, lsl #3
	add	x11, x27, x11, lsl #3
	add	x16, x27, x14, lsl #3
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	sub	x21, x18, #4
	add	x3, x19, #4
	add	x2, x6, #4
	add	x25, x11, #4
	add	x22, x16, #4
	cmp	x9, #4
	stp	x18, x17, [x29, #-120]          // 16-byte Folded Spill
	stp	x3, x2, [x29, #-136]            // 16-byte Folded Spill
	stp	x6, x5, [x29, #-152]            // 16-byte Folded Spill
	stp	x21, x19, [x29, #-168]          // 16-byte Folded Spill
	stur	x22, [x29, #-176]               // 8-byte Folded Spill
	stp	x16, x25, [sp, #176]            // 16-byte Folded Spill
	str	x11, [sp, #168]                 // 8-byte Folded Spill
	b.lo	.LBB174_111
// %bb.101:                             //   in Loop: Header=BB174_95 Depth=1
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	add	x17, x27, x17, lsl #3
	add	x9, x11, x14
	add	x10, x16, x14
	cmp	x9, x11
	add	x9, x25, x14
	cset	w11, lo
	cmp	x10, x16
	ldr	w16, [sp, #100]                 // 4-byte Folded Reload
	orr	w10, w11, w16
	cset	w11, lo
	cmp	x9, x25
	orr	w9, w11, w16
	add	x11, x22, x14
	cset	w14, lo
	cmp	x11, x22
	orr	w11, w14, w16
	cset	w14, lo
	cmp	x21, x19
	orr	w14, w14, w16
	cset	w16, hi
	cmp	x6, x5
	orr	w9, w10, w9
	cset	w10, lo
	cmp	x18, x3
	cset	w18, hi
	cmp	x2, x17
	orr	w9, w9, w11
	cset	w11, lo
	and	w10, w16, w10
	and	w11, w18, w11
	orr	w20, w9, w14
	orr	w9, w10, w11
	mov	w16, #3
	stur	w9, [x29, #-48]                 // 4-byte Folded Spill
	ldp	x10, x28, [sp, #48]             // 16-byte Folded Reload
	ldp	x5, x2, [sp, #16]               // 16-byte Folded Reload
	ldp	x11, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #104]                 // 8-byte Folded Reload
	b	.LBB174_103
.LBB174_102:                            //   in Loop: Header=BB174_103 Depth=2
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	add	x16, x16, #2
	sub	x21, x21, #2
	add	x19, x19, x30
	add	x11, x11, x30
	add	x2, x2, x8
	add	x5, x5, x8
	sub	x28, x28, x12
	sub	x10, x10, x12
	cmp	x16, x9
	b.hs	.LBB174_112
.LBB174_103:                            //   Parent Loop BB174_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB174_107 Depth 3
                                        //       Child Loop BB174_110 Depth 3
	add	x9, x13, x15
	cmp	x9, x23
	csel	x13, x23, xzr, hi
	sub	x9, x9, x13
	add	x13, x9, x15
	cmp	x13, x23
	csel	x14, x23, xzr, hi
	sub	x13, x13, x14
	cbz	x0, .LBB174_102
// %bb.104:                             //   in Loop: Header=BB174_103 Depth=2
	ldur	x14, [x29, #-40]                // 8-byte Folded Reload
	cmp	x0, #4
	cset	w17, lo
	orr	w17, w17, w20
	add	x9, x14, x9, lsl #3
	add	x14, x14, x13, lsl #3
	ldp	s3, s2, [x9]
	ldur	w9, [x29, #-48]                 // 4-byte Folded Reload
	ldp	s0, s1, [x14]
	orr	w9, w17, w9
	tbz	w9, #0, .LBB174_106
// %bb.105:                             //   in Loop: Header=BB174_103 Depth=2
	mov	x9, xzr
	b	.LBB174_109
.LBB174_106:                            //   in Loop: Header=BB174_103 Depth=2
	mov	x17, xzr
	mov	x22, x1
	dup	v4.4s, v3.s[0]
	dup	v5.4s, v2.s[0]
.LBB174_107:                            //   Parent Loop BB174_95 Depth=1
                                        //     Parent Loop BB174_103 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x11, x17
	add	x14, x5, x17
	subs	x22, x22, #4
	ld2	{ v6.4s, v7.4s }, [x9]
	add	x9, x19, x17
	ld2	{ v16.4s, v17.4s }, [x9]
	add	x9, x7, x17
	fmul	v18.4s, v6.4s, v0.s[0]
	fmul	v6.4s, v7.4s, v0.s[0]
	ld2	{ v19.4s, v20.4s }, [x9]
	fmla	v18.4s, v4.4s, v16.4s
	fmla	v6.4s, v4.4s, v17.4s
	ld2	{ v16.4s, v17.4s }, [x14]
	add	x14, x2, x17
	fadd	v21.4s, v19.4s, v18.4s
	fadd	v22.4s, v20.4s, v6.4s
	ld2	{ v6.4s, v7.4s }, [x14]
	add	x14, x4, x17
	add	x17, x17, #32
	fmul	v18.4s, v17.4s, v1.s[0]
	fmul	v16.4s, v16.4s, v1.s[0]
	st2	{ v21.4s, v22.4s }, [x9]
	ld2	{ v19.4s, v20.4s }, [x14]
	fmla	v18.4s, v5.4s, v7.4s
	fmla	v16.4s, v5.4s, v6.4s
	fsub	v6.4s, v19.4s, v18.4s
	fadd	v7.4s, v20.4s, v16.4s
	st2	{ v6.4s, v7.4s }, [x14]
	b.ne	.LBB174_107
// %bb.108:                             //   in Loop: Header=BB174_103 Depth=2
	mov	x9, x1
	cmp	x0, x1
	b.eq	.LBB174_102
.LBB174_109:                            //   in Loop: Header=BB174_103 Depth=2
	ldur	x18, [x29, #-64]                // 8-byte Folded Reload
	sub	x22, x0, x9
	ldur	x0, [x29, #-32]                 // 8-byte Folded Reload
	add	x25, x9, x28
	add	x27, x9, x10
	dup	v3.2s, v3.s[0]
	add	x6, x18, x9
	ldur	x18, [x29, #-56]                // 8-byte Folded Reload
	dup	v2.2s, v2.s[0]
	lsl	x3, x9, #3
	mov	x17, xzr
	add	x14, x19, x3
	add	x18, x18, x9
	add	x3, x11, x3
	add	x6, x0, x6, lsl #3
	add	x26, x24, x25, lsl #3
	add	x9, x24, x27, lsl #3
	add	x25, x0, x18, lsl #3
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
.LBB174_110:                            //   Parent Loop BB174_95 Depth=1
                                        //     Parent Loop BB174_103 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	lsl	x18, x17, #3
	add	x17, x17, #1
	cmp	x22, x17
	ldr	d4, [x3, x18]
	ldr	d5, [x14, x18]
	ldr	d6, [x9, x18]
	ldr	d7, [x6, x18]
	fmul	v4.2s, v4.2s, v0.s[0]
	fmul	v6.2s, v6.2s, v1.s[0]
	fmla	v4.2s, v3.2s, v5.2s
	ldr	d5, [x26, x18]
	rev64	v6.2s, v6.2s
	fadd	v4.2s, v7.2s, v4.2s
	rev64	v5.2s, v5.2s
	str	d4, [x6, x18]
	fmla	v6.2s, v2.2s, v5.2s
	ldr	d4, [x25, x18]
	fsub	v5.2s, v4.2s, v6.2s
	fadd	v4.2s, v4.2s, v6.2s
	mov	v5.s[1], v4.s[1]
	str	d5, [x25, x18]
	b.ne	.LBB174_110
	b	.LBB174_102
.LBB174_111:                            //   in Loop: Header=BB174_95 Depth=1
	ldr	x21, [sp, #104]                 // 8-byte Folded Reload
	mov	w16, #3
.LBB174_112:                            //   in Loop: Header=BB174_95 Depth=1
	ldp	x3, x27, [x29, #-40]            // 16-byte Folded Reload
	ldp	x25, x28, [x29, #-80]           // 16-byte Folded Reload
	ldp	x22, x6, [sp, #120]             // 16-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldur	x19, [x29, #-96]                // 8-byte Folded Reload
	ldr	x26, [sp, #112]                 // 8-byte Folded Reload
	cmp	x16, x5
	b.hs	.LBB174_94
// %bb.113:                             //   in Loop: Header=BB174_95 Depth=1
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	cbz	x9, .LBB174_94
// %bb.114:                             //   in Loop: Header=BB174_95 Depth=1
	ldp	x10, x11, [sp, #168]            // 16-byte Folded Reload
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	ldr	x18, [sp, #184]                 // 8-byte Folded Reload
	ldr	w17, [sp, #100]                 // 4-byte Folded Reload
	add	x9, x10, x14
	ldur	x2, [x29, #-16]                 // 8-byte Folded Reload
	cmp	x9, x10
	add	x9, x11, x14
	cset	w10, lo
	cmp	x9, x11
	add	x9, x18, x14
	cset	w11, lo
	cmp	x9, x18
	ldur	x18, [x29, #-176]               // 8-byte Folded Reload
	orr	w10, w10, w17
	orr	w9, w11, w17
	orr	w9, w10, w9
	add	x11, x18, x14
	cset	w14, lo
	cmp	x11, x18
	orr	w11, w14, w17
	orr	w9, w9, w11
	cset	w14, lo
	ldp	x11, x10, [x29, #-168]          // 16-byte Folded Reload
	orr	w14, w14, w17
	ldur	x18, [x29, #-136]               // 8-byte Folded Reload
	cmp	x11, x10
	ldp	x17, x11, [x29, #-152]          // 16-byte Folded Reload
	cset	w10, hi
	cmp	x17, x11
	ldp	x0, x17, [x29, #-128]           // 16-byte Folded Reload
	cset	w11, lo
	and	w11, w10, w11
	orr	w10, w9, w14
	cmp	x17, x18
	ldur	x18, [x29, #-112]               // 8-byte Folded Reload
	cset	w17, hi
	add	x18, x27, x18, lsl #3
	cmp	x0, x18
	mul	x18, x2, x16
	mul	x2, x2, x21
	cset	w0, lo
	and	w17, w17, w0
	orr	w11, w11, w17
	add	x18, x24, x18, lsl #3
	add	x0, x24, x2, lsl #3
	b	.LBB174_116
.LBB174_115:                            //   in Loop: Header=BB174_116 Depth=2
	add	x16, x16, #1
	add	x18, x18, x6
	add	x0, x0, x26
	cmp	x16, x5
	b.eq	.LBB174_94
.LBB174_116:                            //   Parent Loop BB174_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB174_118 Depth 3
                                        //       Child Loop BB174_121 Depth 3
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mov	x14, xzr
	cmp	x9, #4
	add	x9, x13, x15
	cset	w17, lo
	cmp	x9, x23
	csel	x13, x23, xzr, hi
	orr	w17, w17, w10
	sub	x13, x9, x13
	orr	w17, w17, w11
	add	x9, x3, x13, lsl #3
	ldp	s1, s0, [x9]
	tbnz	w17, #0, .LBB174_120
// %bb.117:                             //   in Loop: Header=BB174_116 Depth=2
	mov	x14, xzr
	mov	x17, x1
	dup	v2.4s, v1.s[0]
	dup	v3.4s, v0.s[0]
.LBB174_118:                            //   Parent Loop BB174_95 Depth=1
                                        //     Parent Loop BB174_116 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x18, x14
	add	x2, x0, x14
	subs	x17, x17, #4
	ld2	{ v4.4s, v5.4s }, [x9]
	add	x9, x7, x14
	ld2	{ v6.4s, v7.4s }, [x9]
	fmla	v6.4s, v2.4s, v4.4s
	fmla	v7.4s, v2.4s, v5.4s
	ld2	{ v4.4s, v5.4s }, [x2]
	add	x2, x4, x14
	add	x14, x14, #32
	st2	{ v6.4s, v7.4s }, [x9]
	ld2	{ v6.4s, v7.4s }, [x2]
	fmls	v6.4s, v3.4s, v5.4s
	fmla	v7.4s, v3.4s, v4.4s
	st2	{ v6.4s, v7.4s }, [x2]
	b.ne	.LBB174_118
// %bb.119:                             //   in Loop: Header=BB174_116 Depth=2
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mov	x14, x1
	cmp	x9, x1
	b.eq	.LBB174_115
.LBB174_120:                            //   in Loop: Header=BB174_116 Depth=2
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	dup	v1.2s, v1.s[0]
	sub	x9, x9, x14
	lsl	x14, x14, #3
.LBB174_121:                            //   Parent Loop BB174_95 Depth=1
                                        //     Parent Loop BB174_116 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d2, [x18, x14]
	add	x17, x0, x14
	ldr	d3, [x7, x14]
	add	x2, x4, x14
	subs	x9, x9, #1
	fmla	v3.2s, v1.2s, v2.2s
	ldp	s4, s2, [x17]
	str	d3, [x7, x14]
	add	x14, x14, #8
	ldp	s3, s5, [x2]
	fmsub	s2, s2, s0, s3
	fmadd	s3, s4, s0, s5
	stp	s2, s3, [x2]
	b.ne	.LBB174_121
	b	.LBB174_115
.LBB174_122:
	ldr	x17, [sp, #8]                   // 8-byte Folded Reload
	mov	w9, #1
	ldr	w10, [sp, #4]                   // 4-byte Folded Reload
	subs	x8, x25, #1
	b.eq	.LBB174_54
.LBB174_123:
	cbz	w9, .LBB174_125
// %bb.124:
	tbz	w10, #0, .LBB174_128
.LBB174_125:
	ldur	x8, [x29, #-40]                 // 8-byte Folded Reload
	cbz	x8, .LBB174_127
// %bb.126:
	ldp	x20, x19, [sp, #448]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #432]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #416]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #400]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #384]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #368]            // 16-byte Folded Reload
	ldur	x0, [x8, #-8]
	add	sp, sp, #464
	b	free
.LBB174_127:
	ldp	x20, x19, [sp, #448]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #432]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #416]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #400]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #384]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #368]            // 16-byte Folded Reload
	add	sp, sp, #464
	ret
.LBB174_128:
	sub	x12, x25, #2
	mul	x10, x17, x28
	cmp	x5, #2
	mov	w11, #2
	csel	x9, x5, x11, hi
	cmp	xzr, x12, lsr #61
	lsl	x16, x12, #3
	and	x12, x8, #0xfffffffffffffffc
	lsl	x13, x28, #3
	mul	x11, x10, x25
	lsl	x10, x10, #3
	stur	x9, [x29, #-176]                // 8-byte Folded Spill
	add	x13, x13, #8
	add	x10, x10, #8
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	stur	x12, [x29, #-112]               // 8-byte Folded Spill
	orr	x12, x12, #0x1
	mul	x13, x13, x25
	mul	x10, x10, x25
	lsl	x2, x25, #3
	add	x0, x9, #1
	add	x18, x11, #1
	stur	x12, [x29, #-120]               // 8-byte Folded Spill
	add	x12, x27, x9, lsl #3
	lsl	x9, x9, #3
	add	x3, x27, x11, lsl #3
	stp	x10, x13, [x29, #-96]           // 16-byte Folded Spill
	sub	x10, x17, #1
	mov	x14, xzr
	cset	w15, ne
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	neg	x9, x9
	mul	x10, x10, x8
	add	x4, x12, #4
	add	x13, x27, x0, lsl #3
	add	x24, x27, x18, lsl #3
	str	x9, [sp, #176]                  // 8-byte Folded Spill
	add	x26, x3, #4
	ldur	x9, [x29, #-104]                // 8-byte Folded Reload
	str	x0, [sp, #144]                  // 8-byte Folded Spill
	add	x6, x9, x10, lsl #3
	mov	w10, #8
	sub	x9, x10, x2
	str	x9, [sp, #168]                  // 8-byte Folded Spill
	sub	x9, x2, #8
	stp	x18, x9, [sp, #152]             // 16-byte Folded Spill
	mov	w18, #1
	b	.LBB174_130
.LBB174_129:                            //   in Loop: Header=BB174_130 Depth=1
	ldp	x10, x9, [sp, #176]             // 16-byte Folded Reload
	ldp	x13, x14, [x29, #-136]          // 16-byte Folded Reload
	ldr	x11, [sp, #168]                 // 8-byte Folded Reload
	add	x3, x3, x10
	ldp	x18, x26, [x29, #-160]          // 16-byte Folded Reload
	add	x4, x4, x9
	add	x13, x13, x9
	add	x6, x6, x11
	ldr	x11, [sp, #160]                 // 8-byte Folded Reload
	ldur	x24, [x29, #-144]               // 8-byte Folded Reload
	add	x14, x14, #1
	ldp	x9, x17, [x29, #-176]           // 16-byte Folded Reload
	add	x18, x18, #1
	add	x20, x20, x11
	add	x24, x24, x10
	add	x26, x26, x10
	cmp	x18, x9
	stur	x20, [x29, #-104]               // 8-byte Folded Spill
	b.eq	.LBB174_125
.LBB174_130:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB174_157 Depth 2
                                        //     Child Loop BB174_132 Depth 2
                                        //       Child Loop BB174_148 Depth 3
                                        //       Child Loop BB174_135 Depth 3
	sub	x9, x17, #1
	cmp	x25, #1
	stp	x13, x14, [x29, #-136]          // 16-byte Folded Spill
	stp	x26, x24, [x29, #-152]          // 16-byte Folded Spill
	stp	x9, x18, [x29, #-168]           // 16-byte Folded Spill
	b.ls	.LBB174_156
// %bb.131:                             //   in Loop: Header=BB174_130 Depth=1
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mul	x18, x18, x28
	ldr	x11, [sp, #152]                 // 8-byte Folded Reload
	mul	x30, x17, x28
	mov	x21, xzr
	mov	x0, x4
	mul	x10, x9, x14
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	msub	x12, x9, x14, x11
	stur	x12, [x29, #-24]                // 8-byte Folded Spill
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	madd	x9, x9, x14, x12
	mov	x14, x13
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x12, x10
	stur	x9, [x29, #-56]                 // 8-byte Folded Spill
	sub	x9, x11, x10
	stur	x9, [x29, #-64]                 // 8-byte Folded Spill
.LBB174_132:                            //   Parent Loop BB174_130 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB174_148 Depth 3
                                        //       Child Loop BB174_135 Depth 3
	add	x13, x21, x18
	add	x17, x21, x30
	cmp	x8, #4
	mul	x13, x13, x25
	mul	x17, x17, x25
	add	x13, x27, x13, lsl #3
	add	x17, x27, x17, lsl #3
	ldp	s0, s1, [x13]
	ldp	s2, s3, [x17]
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	str	s4, [x13]
	str	s5, [x13, #4]
	str	s0, [x17]
	str	s1, [x17, #4]
	b.hs	.LBB174_137
.LBB174_133:                            //   in Loop: Header=BB174_132 Depth=2
	mov	w19, #1
.LBB174_134:                            //   in Loop: Header=BB174_132 Depth=2
	sub	x5, x25, x19
	lsl	x19, x19, #3
.LBB174_135:                            //   Parent Loop BB174_130 Depth=1
                                        //     Parent Loop BB174_132 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x0, x19
	add	x11, x26, x19
	add	x12, x20, x19
	add	x13, x6, x19
	subs	x5, x5, #1
	add	x19, x19, #8
	ldp	s0, s2, [x9, #-4]
	ldp	s1, s3, [x11, #-4]
	ldp	s17, s5, [x12, #-8]
	fadd	s4, s0, s1
	fsub	s0, s0, s1
	fadd	s1, s2, s3
	fsub	s2, s2, s3
	ldp	s18, s3, [x13, #-8]
	fneg	s6, s4
	fneg	s7, s0
	fmul	s16, s1, s5
	fmul	s5, s5, s6
	fmul	s6, s2, s3
	fmul	s3, s3, s7
	fmadd	s4, s4, s17, s16
	fmadd	s1, s1, s17, s5
	fmadd	s0, s0, s18, s6
	fmadd	s2, s2, s18, s3
	stur	s4, [x9, #-4]
	str	s1, [x9]
	stur	s0, [x11, #-4]
	str	s2, [x11]
	b.ne	.LBB174_135
.LBB174_136:                            //   in Loop: Header=BB174_132 Depth=2
	add	x21, x21, #1
	add	x14, x14, x2
	add	x24, x24, x2
	add	x0, x0, x2
	add	x26, x26, x2
	cmp	x21, x28
	b.ne	.LBB174_132
	b	.LBB174_129
.LBB174_137:                            //   in Loop: Header=BB174_132 Depth=2
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	mul	x5, x21, x25
	add	x13, x9, x5
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #3
	add	x17, x9, x5
	add	x1, x13, #4
	add	x7, x27, x17, lsl #3
	add	x17, x1, x16
	add	x19, x7, #4
	cmp	x17, x1
	add	x17, x13, x16
	cset	w1, lo
	cmp	x17, x13
	add	x13, x19, x16
	cset	w17, lo
	cmp	x13, x19
	add	x13, x7, x16
	orr	w22, w1, w15
	cset	w1, lo
	cmp	x13, x7
	cset	w13, lo
	tbnz	w22, #0, .LBB174_150
// %bb.138:                             //   in Loop: Header=BB174_132 Depth=2
	orr	w17, w17, w15
	tbnz	w17, #0, .LBB174_150
// %bb.139:                             //   in Loop: Header=BB174_132 Depth=2
	orr	w17, w1, w15
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w17, #0, .LBB174_133
// %bb.140:                             //   in Loop: Header=BB174_132 Depth=2
	orr	w13, w13, w15
	mov	w19, #1
	tbnz	w13, #0, .LBB174_134
// %bb.141:                             //   in Loop: Header=BB174_132 Depth=2
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	add	x17, x10, x5
	add	x17, x27, x17, lsl #3
	add	x13, x9, x5
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #3
	add	x1, x9, x5
	ldur	x9, [x29, #-88]                 // 8-byte Folded Reload
	sub	x5, x5, x10
	add	x28, x13, #4
	add	x1, x27, x1, lsl #3
	add	x17, x17, x9
	ldur	x9, [x29, #-96]                 // 8-byte Folded Reload
	add	x5, x27, x5, lsl #3
	sub	x7, x17, #4
	cmp	x17, x13
	add	x11, x1, #4
	add	x9, x5, x9
	cset	w5, hi
	sub	x27, x9, #4
	cmp	x7, x28
	cset	w19, hi
	cmp	x27, x13
	and	w12, w5, w19
	cset	w5, hi
	cmp	x7, x1
	cset	w22, hi
	cmp	x9, x13
	cset	w19, hi
	cmp	x7, x11
	cset	w25, hi
	cmp	x27, x28
	cset	w23, hi
	cmp	x17, x1
	cset	w7, hi
	cmp	x9, x28
	cset	w28, hi
	cmp	x17, x11
	cset	w13, hi
	cmp	x9, x1
	cset	w17, hi
	cmp	x27, x11
	cset	w1, hi
	tbnz	w12, #0, .LBB174_152
// %bb.142:                             //   in Loop: Header=BB174_132 Depth=2
	and	w9, w5, w22
	tbnz	w9, #0, .LBB174_152
// %bb.143:                             //   in Loop: Header=BB174_132 Depth=2
	and	w9, w19, w25
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB174_153
// %bb.144:                             //   in Loop: Header=BB174_132 Depth=2
	and	w9, w23, w7
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB174_154
// %bb.145:                             //   in Loop: Header=BB174_132 Depth=2
	and	w9, w28, w13
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	tbnz	w9, #0, .LBB174_151
// %bb.146:                             //   in Loop: Header=BB174_132 Depth=2
	and	w9, w17, w1
	mov	w19, #1
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB174_134
// %bb.147:                             //   in Loop: Header=BB174_132 Depth=2
	ldur	x19, [x29, #-112]               // 8-byte Folded Reload
	mov	x28, x24
	mov	x22, x20
	mov	x23, x14
	mov	x5, x6
.LBB174_148:                            //   Parent Loop BB174_130 Depth=1
                                        //     Parent Loop BB174_132 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.4s, v1.4s }, [x23]
	subs	x19, x19, #4
	ld2	{ v2.4s, v3.4s }, [x28]
	ld2	{ v6.4s, v7.4s }, [x22], #32
	fadd	v4.4s, v1.4s, v3.4s
	fadd	v5.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fmul	v16.4s, v4.4s, v7.4s
	fneg	v18.4s, v5.4s
	fmla	v16.4s, v6.4s, v5.4s
	fmul	v17.4s, v7.4s, v18.4s
	fmla	v17.4s, v6.4s, v4.4s
	fsub	v4.4s, v1.4s, v3.4s
	fneg	v3.4s, v0.4s
	st2	{ v16.4s, v17.4s }, [x23], #32
	ld2	{ v1.4s, v2.4s }, [x5], #32
	fmul	v5.4s, v4.4s, v2.4s
	fmla	v5.4s, v1.4s, v0.4s
	fmul	v6.4s, v2.4s, v3.4s
	fmla	v6.4s, v1.4s, v4.4s
	st2	{ v5.4s, v6.4s }, [x28], #32
	b.ne	.LBB174_148
// %bb.149:                             //   in Loop: Header=BB174_132 Depth=2
	ldp	x19, x9, [x29, #-120]           // 16-byte Folded Reload
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	cmp	x8, x9
	b.ne	.LBB174_134
	b	.LBB174_136
.LBB174_150:                            //   in Loop: Header=BB174_132 Depth=2
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	b	.LBB174_133
.LBB174_151:                            //   in Loop: Header=BB174_132 Depth=2
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	mov	w19, #1
	b	.LBB174_134
.LBB174_152:                            //   in Loop: Header=BB174_132 Depth=2
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	mov	w19, #1
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
	b	.LBB174_155
.LBB174_153:                            //   in Loop: Header=BB174_132 Depth=2
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
.LBB174_154:                            //   in Loop: Header=BB174_132 Depth=2
	mov	w19, #1
.LBB174_155:                            //   in Loop: Header=BB174_132 Depth=2
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	b	.LBB174_134
.LBB174_156:                            //   in Loop: Header=BB174_130 Depth=1
	mov	x10, xzr
	mov	x11, x28
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
.LBB174_157:                            //   Parent Loop BB174_130 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x12, x4, x10
	add	x13, x3, x10
	subs	x11, x11, #1
	add	x10, x10, x2
	ldp	s0, s1, [x12, #-4]
	ldp	s2, s3, [x13]
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stp	s4, s5, [x12, #-4]
	stp	s0, s1, [x13]
	b.ne	.LBB174_157
	b	.LBB174_129
.LBB174_158:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end174:
	.size	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_, .Lfunc_end174-_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x22, x21, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	subs	x8, x1, #1
	b.ne	.LBB175_4
// %bb.1:
	cbz	x2, .LBB175_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #4
	lsl	x9, x2, #3
	lsl	x10, x10, #3
	lsl	x11, x2, #4
	add	x12, x3, #16
.LBB175_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x12, #-16]
	ldp	s2, s3, [x12]
	ldp	s4, s5, [x12, #-8]
	ldp	s6, s7, [x12, #8]
	add	x13, x8, x11
	add	x14, x8, x9
	fadd	s16, s0, s2
	fadd	s18, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	fadd	s17, s4, s6
	fadd	s19, s5, s7
	fsub	s2, s5, s7
	fsub	s3, s4, s6
	subs	x2, x2, #1
	add	x12, x12, #32
	fsub	s4, s16, s17
	fsub	s5, s18, s19
	fadd	s6, s16, s17
	fsub	s7, s0, s2
	fadd	s0, s0, s2
	stp	s4, s5, [x13, #-4]
	fadd	s5, s18, s19
	fadd	s4, s1, s3
	fsub	s1, s1, s3
	add	x13, x8, x10
	stp	s6, s5, [x8, #-4]
	add	x8, x8, #8
	stp	s7, s4, [x14, #-4]
	stp	s0, s1, [x13, #-4]
	b.ne	.LBB175_3
	b	.LBB175_10
.LBB175_4:
	cbz	x2, .LBB175_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #24
	lsl	x10, x2, #1
	mov	x9, xzr
	add	x11, x3, #8
	lsl	x12, x1, #5
	madd	x14, x0, x14, x4
	add	x13, x10, x2
	lsl	x15, x1, #3
	add	x16, x5, x8, lsl #4
	add	x17, x4, x0, lsl #4
	add	x18, x5, x8, lsl #3
	add	x0, x4, x0, lsl #3
	mov	x6, x4
	b	.LBB175_7
.LBB175_6:                              //   in Loop: Header=BB175_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x12
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB175_10
.LBB175_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB175_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #3
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #3
	ldp	s0, s1, [x7]
	add	x20, x3, x20, lsl #3
	add	x7, x3, x21, lsl #3
	ldp	s2, s3, [x19]
	mul	x19, x9, x1
	add	x21, x9, x13
	ldp	s4, s5, [x20]
	ldp	s6, s7, [x7]
	fadd	s16, s0, s2
	fadd	s17, s1, s3
	fsub	s0, s0, s2
	add	x7, x9, x10
	fsub	s1, s1, s3
	add	x19, x4, x19, lsl #3
	fadd	s2, s4, s6
	fadd	s18, s5, s7
	fsub	s3, s4, s6
	fsub	s4, s5, s7
	mul	x7, x7, x1
	add	x20, x9, x2
	fadd	s5, s16, s2
	fadd	s6, s17, s18
	fsub	s2, s16, s2
	fsub	s7, s17, s18
	add	x7, x4, x7, lsl #3
	mul	x20, x20, x1
	stp	s5, s6, [x19]
	mul	x19, x21, x1
	fsub	s5, s0, s4
	fadd	s6, s1, s3
	fadd	s0, s0, s4
	fsub	s1, s1, s3
	add	x20, x4, x20, lsl #3
	stp	s2, s7, [x7]
	add	x7, x4, x19, lsl #3
	stp	s5, s6, [x20]
	stp	s0, s1, [x7]
	b.lo	.LBB175_6
// %bb.8:                               //   in Loop: Header=BB175_7 Depth=1
	mov	x7, xzr
	mov	x19, x8
.LBB175_9:                              //   Parent Loop BB175_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x11, x7
	subs	x19, x19, #1
	add	x21, x20, x15
	add	x22, x21, x15
	ldp	s0, s1, [x20]
	add	x20, x22, x15
	ldp	s2, s3, [x22]
	ldp	s5, s6, [x21]
	ldp	s4, s7, [x20]
	add	x20, x5, x7
	add	x21, x18, x7
	fsub	s16, s1, s3
	fadd	s18, s0, s2
	fsub	s0, s0, s2
	fadd	s1, s1, s3
	fsub	s17, s5, s4
	fadd	s3, s5, s4
	fadd	s4, s6, s7
	fsub	s5, s6, s7
	ldp	s6, s7, [x20]
	add	x20, x16, x7
	fadd	s2, s16, s17
	fsub	s16, s16, s17
	fsub	s21, s1, s4
	fadd	s1, s1, s4
	fsub	s4, s0, s5
	fadd	s20, s18, s3
	fsub	s3, s18, s3
	fadd	s0, s0, s5
	fneg	s19, s2
	fmul	s2, s2, s6
	fneg	s18, s21
	fmul	s17, s7, s19
	fmadd	s2, s4, s7, s2
	ldp	s19, s22, [x21]
	fneg	s7, s16
	add	x21, x6, x7
	fmadd	s4, s4, s6, s17
	ldp	s6, s17, [x20]
	fmul	s18, s22, s18
	fmul	s5, s21, s19
	add	x20, x0, x7
	str	s1, [x21, #12]
	str	s20, [x21, #8]
	add	x21, x17, x7
	fmul	s16, s16, s6
	fmul	s7, s17, s7
	fmadd	s1, s3, s19, s18
	fmadd	s3, s3, s22, s5
	str	s2, [x20, #12]
	str	s4, [x20, #8]
	add	x20, x14, x7
	fmadd	s5, s0, s17, s16
	fmadd	s0, s0, s6, s7
	add	x7, x7, #8
	str	s1, [x21, #8]
	str	s3, [x21, #12]
	str	s0, [x20, #8]
	str	s5, [x20, #12]
	b.ne	.LBB175_9
	b	.LBB175_6
.LBB175_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x22, x21, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end175:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end175-_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	stp	d13, d12, [sp, #96]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #112]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 240
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	subs	x8, x1, #1
	stp	x4, x3, [sp, #80]               // 16-byte Folded Spill
	b.ne	.LBB176_4
// %bb.1:
	cbz	x2, .LBB176_10
// %bb.2:
	ldp	x8, x16, [sp, #80]              // 16-byte Folded Reload
	mov	w10, #56
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	mov	w17, #1267
	mul	x10, x2, x10
	lsl	x9, x13, #3
	add	x8, x8, #4
	lsl	x11, x11, #3
	lsl	x12, x2, #3
	lsl	x13, x13, #4
	lsl	x14, x2, #4
	lsl	x15, x2, #5
	add	x16, x16, #32
	movk	w17, #16181, lsl #16
.LBB176_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x16, #-24]
	ldp	s2, s3, [x16, #8]
	ldp	s4, s5, [x16, #-8]
	ldp	s6, s7, [x16, #24]
	ldp	s21, s23, [x16, #-16]
	fadd	s16, s0, s2
	fsub	s0, s0, s2
	fadd	s17, s1, s3
	fsub	s1, s1, s3
	fsub	s2, s5, s7
	fadd	s18, s4, s6
	ldp	s3, s19, [x16, #-32]
	fadd	s5, s5, s7
	fsub	s4, s4, s6
	ldp	s7, s6, [x16]
	fadd	s20, s0, s2
	fsub	s0, s0, s2
	ldp	s2, s25, [x16, #16]
	fadd	s24, s1, s4
	fadd	s22, s16, s18
	fadd	s26, s3, s7
	fadd	s28, s19, s6
	fsub	s1, s1, s4
	fneg	s4, s20
	fadd	s27, s21, s2
	fadd	s29, s23, s25
	fadd	s30, s17, s5
	fsub	s16, s16, s18
	fsub	s5, s17, s5
	fsub	s17, s0, s24
	fadd	s0, s24, s0
	fsub	s4, s4, s1
	fadd	s18, s26, s27
	fadd	s24, s28, s29
	fsub	s1, s20, s1
	fsub	s6, s19, s6
	fsub	s20, s26, s27
	fsub	s2, s21, s2
	fsub	s21, s28, s29
	add	x18, x8, x15
	fsub	s19, s18, s22
	fsub	s26, s24, s30
	fsub	s3, s3, s7
	fsub	s23, s23, s25
	fmov	s7, w17
	add	x0, x8, x13
	fadd	s25, s16, s21
	fsub	s16, s21, s16
	stp	s19, s26, [x18, #-4]
	fsub	s19, s20, s5
	add	x18, x8, x14
	fmul	s17, s17, s7
	fmul	s0, s0, s7
	fadd	s5, s5, s20
	fsub	s20, s3, s23
	fmul	s4, s4, s7
	stp	s19, s25, [x18, #-4]
	fadd	s19, s6, s2
	fmul	s1, s1, s7
	fadd	s3, s3, s23
	stp	s5, s16, [x0, #-4]
	fsub	s2, s6, s2
	fadd	s5, s17, s20
	fsub	s16, s20, s17
	fadd	s7, s0, s19
	fsub	s0, s19, s0
	add	x18, x8, x12
	add	x0, x8, x11
	fadd	s6, s4, s3
	fsub	s3, s3, s4
	subs	x2, x2, #1
	add	x16, x16, #64
	stp	s5, s7, [x18, #-4]
	fadd	s5, s22, s18
	stp	s16, s0, [x0, #-4]
	fadd	s7, s1, s2
	fadd	s0, s30, s24
	add	x18, x8, x9
	fsub	s1, s2, s1
	stp	s6, s7, [x18, #-4]
	add	x18, x8, x10
	stp	s5, s0, [x8, #-4]
	add	x8, x8, #8
	stp	s3, s1, [x18, #-4]
	b.ne	.LBB176_3
	b	.LBB176_10
.LBB176_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	cbz	x2, .LBB176_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x12, x2, #2
	ldp	x4, x17, [sp, #80]              // 16-byte Folded Reload
	mul	x10, x2, x1
	mov	w11, #56
	stp	x12, x8, [sp, #56]              // 16-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	add	x12, x12, x2
	ldr	x0, [sp]                        // 8-byte Folded Reload
	mov	w13, #24
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	stp	x12, x18, [sp, #32]             // 16-byte Folded Spill
	add	x12, x0, x0, lsl #2
	add	x14, x0, x0, lsl #1
	madd	x16, x10, x11, x4
	lsl	x15, x0, #5
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	lsl	x8, x1, #3
	madd	x11, x1, x11, x17
	mov	x9, xzr
	madd	x7, x10, x13, x4
	add	x25, x4, x10, lsl #3
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	add	x8, x8, x17
	add	x18, x8, #12
	lsl	x8, x12, #3
	lsl	x12, x1, #6
	add	x20, x11, #12
	add	x11, x15, x17
	add	x29, x5, x15
	add	x22, x11, #32
	lsl	x11, x0, #4
	str	x12, [sp, #8]                   // 8-byte Folded Spill
	add	x12, x8, x17
	add	x6, x12, #52
	lsl	x12, x14, #3
	add	x13, x12, x17
	add	x27, x5, x11
	add	x19, x13, #36
	mov	w13, #40
	add	x30, x4, x10, lsl #4
	add	x8, x5, x8
	madd	x21, x10, x13, x4
	lsl	x13, x14, #4
	add	x14, x11, x17
	add	x3, x13, x17
	add	x23, x14, #16
	mov	w14, #48
	add	x24, x3, #48
	add	x26, x5, x13
	madd	x28, x10, x14, x4
	add	x13, x5, x0, lsl #3
	add	x14, x4, x10, lsl #5
	add	x15, x5, x12
	mov	x3, x17
	str	x2, [sp, #72]                   // 8-byte Folded Spill
	b	.LBB176_7
.LBB176_6:                              //   in Loop: Header=BB176_7 Depth=1
	ldp	x11, x10, [sp, #8]              // 16-byte Folded Reload
	add	x9, x9, #1
	ldr	x2, [sp, #72]                   // 8-byte Folded Reload
	add	x18, x18, x11
	add	x6, x6, x11
	add	x16, x16, x10
	add	x7, x7, x10
	add	x19, x19, x11
	add	x20, x20, x11
	add	x21, x21, x10
	add	x3, x3, x11
	add	x22, x22, x11
	add	x23, x23, x11
	add	x24, x24, x11
	add	x4, x4, x10
	add	x25, x25, x10
	add	x28, x28, x10
	add	x30, x30, x10
	add	x14, x14, x10
	cmp	x9, x2
	b.eq	.LBB176_10
.LBB176_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB176_9 Depth 2
	mov	w11, #1
	ldr	x10, [sp, #88]                  // 8-byte Folded Reload
	bfi	x11, x9, #3, #61
	mov	w12, #5
	bfi	x12, x9, #3, #61
	mov	w17, #3
	mul	x11, x11, x1
	mov	x0, x2
	mul	x12, x12, x1
	mov	w2, #7
	bfi	x17, x9, #3, #61
	bfi	x2, x9, #3, #61
	add	x11, x10, x11, lsl #3
	cmp	x1, #2
	mul	x17, x17, x1
	add	x12, x10, x12, lsl #3
	mul	x2, x2, x1
	ldp	s0, s1, [x11]
	lsl	x11, x9, #3
	add	x17, x10, x17, lsl #3
	ldp	s2, s3, [x12]
	mul	x11, x11, x1
	add	x12, x10, x2, lsl #3
	ldp	s4, s5, [x17]
	mov	w17, #6
	add	x11, x10, x11, lsl #3
	bfi	x17, x9, #3, #61
	ldp	s7, s16, [x12]
	mov	w12, #4
	mul	x17, x17, x1
	ldp	s18, s19, [x11]
	mov	w11, #2
	bfi	x12, x9, #3, #61
	bfi	x11, x9, #3, #61
	fadd	s6, s0, s2
	mul	x12, x12, x1
	fadd	s17, s1, s3
	mul	x11, x11, x1
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	fadd	s2, s4, s7
	fadd	s3, s5, s16
	fsub	s4, s4, s7
	fsub	s5, s5, s16
	add	x11, x10, x11, lsl #3
	add	x12, x10, x12, lsl #3
	add	x17, x10, x17, lsl #3
	fadd	s7, s6, s2
	fsub	s2, s6, s2
	fadd	s16, s17, s3
	fsub	s3, s17, s3
	ldp	s6, s24, [x11]
	fsub	s17, s0, s5
	fadd	s21, s1, s4
	ldp	s22, s25, [x17]
	fadd	s0, s0, s5
	mov	w10, #1267
	ldp	s20, s5, [x12]
	movk	w10, #16181, lsl #16
	fsub	s1, s1, s4
	fadd	s26, s6, s22
	fsub	s4, s17, s21
	fadd	s17, s21, s17
	fadd	s28, s24, s25
	fadd	s23, s18, s20
	fadd	s21, s19, s5
	fmov	s27, w10
	fsub	s18, s18, s20
	ldp	x10, x17, [sp, #56]             // 16-byte Folded Reload
	fsub	s6, s6, s22
	mul	x12, x9, x1
	fadd	s20, s23, s26
	fadd	s22, s21, s28
	fsub	s5, s19, s5
	fsub	s19, s24, s25
	add	x11, x9, x10
	ldr	x10, [sp, #80]                  // 8-byte Folded Reload
	add	x17, x9, x17
	fsub	s21, s21, s28
	mul	x11, x11, x1
	fadd	s24, s7, s20
	fadd	s25, s16, s22
	fsub	s7, s20, s7
	add	x12, x10, x12, lsl #3
	mul	x17, x17, x1
	add	x11, x10, x11, lsl #3
	fsub	s23, s23, s26
	fneg	s20, s0
	fsub	s16, s22, s16
	str	s24, [x12]
	fmul	s4, s4, s27
	str	s25, [x12, #4]
	add	x12, x10, x17, lsl #3
	ldr	x17, [sp, #40]                  // 8-byte Folded Reload
	str	s7, [x11]
	fadd	s7, s2, s21
	fsub	s22, s23, s3
	fmul	s17, s17, s27
	fsub	s20, s20, s1
	add	x17, x9, x17
	fsub	s0, s0, s1
	str	s16, [x11, #4]
	fsub	s1, s18, s19
	mul	x11, x17, x1
	add	x17, x9, x0
	str	s7, [x12, #4]
	fadd	s7, s5, s6
	str	s22, [x12]
	mul	x12, x17, x1
	ldr	x17, [sp, #32]                  // 8-byte Folded Reload
	fadd	s3, s3, s23
	fsub	s2, s21, s2
	fadd	s16, s4, s1
	fadd	s21, s17, s7
	add	x11, x10, x11, lsl #3
	add	x12, x10, x12, lsl #3
	add	x17, x9, x17
	fmul	s0, s0, s27
	fsub	s1, s1, s4
	str	s3, [x11]
	fadd	s3, s18, s19
	str	s2, [x11, #4]
	mul	x11, x17, x1
	str	s16, [x12]
	ldr	x17, [sp, #24]                  // 8-byte Folded Reload
	str	s21, [x12, #4]
	ldr	x12, [sp, #48]                  // 8-byte Folded Reload
	fmul	s2, s20, s27
	fsub	s4, s7, s17
	add	x17, x9, x17
	fsub	s5, s5, s6
	add	x12, x9, x12
	add	x11, x10, x11, lsl #3
	mul	x17, x17, x1
	mul	x12, x12, x1
	str	s1, [x11]
	fadd	s1, s2, s3
	fadd	s6, s0, s5
	str	s4, [x11, #4]
	add	x12, x10, x12, lsl #3
	fsub	s2, s3, s2
	fsub	s0, s5, s0
	add	x11, x10, x17, lsl #3
	mov	w10, #1267
	movk	w10, #16181, lsl #16
	str	s1, [x12]
	str	s6, [x12, #4]
	str	s2, [x11]
	str	s0, [x11, #4]
	b.lo	.LBB176_6
// %bb.8:                               //   in Loop: Header=BB176_7 Depth=1
	mov	x12, xzr
	ldr	x11, [sp]                       // 8-byte Folded Reload
.LBB176_9:                              //   Parent Loop BB176_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x17, x18, x12
	add	x2, x6, x12
	add	x0, x3, x12
	subs	x11, x11, #1
	ldp	s0, s1, [x17, #-4]
	ldp	s2, s3, [x2, #-4]
	add	x17, x22, x12
	add	x2, x23, x12
	ldp	s4, s5, [x0, #8]
	add	x0, x19, x12
	ldp	s6, s7, [x17, #8]
	add	x17, x20, x12
	fadd	s22, s1, s3
	ldp	s16, s17, [x2, #8]
	add	x2, x24, x12
	fadd	s28, s0, s2
	ldp	s21, s18, [x0, #-4]
	ldp	s24, s19, [x17, #-4]
	ldp	s27, s20, [x2, #8]
	fadd	s25, s5, s7
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	add	x17, x15, x12
	fadd	s23, s18, s19
	fadd	s29, s21, s24
	fadd	s26, s17, s20
	fsub	s21, s21, s24
	fsub	s18, s18, s19
	fsub	s5, s5, s7
	ldp	s8, s9, [x17]
	fadd	s2, s22, s23
	fadd	s19, s28, s29
	fadd	s3, s25, s26
	fsub	s24, s28, s29
	fadd	s28, s4, s6
	fadd	s29, s16, s27
	fsub	s22, s22, s23
	fsub	s25, s25, s26
	fsub	s26, s0, s18
	fadd	s0, s0, s18
	fsub	s23, s3, s2
	add	x17, x13, x12
	fadd	s18, s28, s29
	fadd	s30, s1, s21
	fadd	s10, s24, s25
	fsub	s1, s1, s21
	fsub	s21, s28, s29
	fsub	s4, s4, s6
	fneg	s31, s23
	fmul	s23, s8, s23
	fsub	s28, s18, s19
	fsub	s12, s26, s30
	ldp	s11, s13, [x17]
	fadd	s26, s30, s26
	fsub	s7, s25, s24
	fmul	s29, s9, s31
	fneg	s31, s10
	fmadd	s23, s28, s9, s23
	fsub	s16, s16, s27
	fmov	s30, w10
	add	x17, x8, x12
	fadd	s18, s19, s18
	fadd	s2, s2, s3
	fmadd	s6, s28, s8, s29
	fsub	s28, s21, s22
	fmul	s29, s13, s31
	fmul	s31, s10, s11
	fmul	s26, s26, s30
	fadd	s3, s5, s16
	fadd	s21, s22, s21
	fsub	s17, s17, s20
	fmul	s25, s12, s30
	add	x0, x14, x12
	fmadd	s24, s28, s11, s29
	fmadd	s27, s28, s13, s31
	fneg	s28, s7
	fadd	s20, s26, s3
	ldp	s29, s19, [x17]
	add	x17, x4, x12
	fneg	s22, s0
	fsub	s0, s0, s1
	fsub	s5, s5, s16
	fmul	s28, s19, s28
	fmul	s7, s7, s29
	stp	s18, s2, [x17, #8]
	add	x17, x5, x12
	fsub	s18, s4, s17
	stp	s6, s23, [x0, #8]
	fmul	s0, s0, s30
	add	x0, x25, x12
	fmadd	s2, s21, s29, s28
	fmadd	s7, s21, s19, s7
	fneg	s19, s20
	fsub	s1, s22, s1
	ldp	s21, s28, [x17]
	add	x17, x30, x12
	fadd	s6, s25, s18
	fadd	s4, s4, s17
	fmul	s1, s1, s30
	fmul	s19, s28, s19
	fmul	s20, s20, s21
	stp	s24, s27, [x17, #8]
	add	x17, x28, x12
	fmadd	s16, s6, s21, s19
	fmadd	s6, s6, s28, s20
	stp	s2, s7, [x17, #8]
	fsub	s2, s3, s26
	add	x17, x29, x12
	fadd	s3, s0, s5
	fsub	s0, s5, s0
	fsub	s5, s18, s25
	stp	s16, s6, [x0, #8]
	add	x0, x27, x12
	ldp	s6, s7, [x17]
	fneg	s16, s2
	add	x17, x26, x12
	fneg	s17, s3
	fneg	s21, s0
	ldp	s19, s20, [x0]
	fmul	s2, s2, s6
	fadd	s18, s1, s4
	fmul	s16, s7, s16
	fsub	s1, s4, s1
	ldp	s22, s23, [x17]
	fmul	s17, s20, s17
	fmul	s3, s3, s19
	fmadd	s2, s5, s7, s2
	add	x17, x21, x12
	fmadd	s6, s5, s6, s16
	add	x0, x7, x12
	fmul	s4, s23, s21
	fmul	s0, s0, s22
	fmadd	s5, s18, s19, s17
	fmadd	s3, s18, s20, s3
	stp	s6, s2, [x17, #8]
	add	x17, x16, x12
	fmadd	s2, s1, s22, s4
	fmadd	s0, s1, s23, s0
	add	x12, x12, #8
	stp	s5, s3, [x0, #8]
	stp	s2, s0, [x17, #8]
	b.ne	.LBB176_9
	b	.LBB176_6
.LBB176_10:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #112]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #96]             // 16-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end176:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end176-_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 176
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	cmp	x1, #1
	str	x5, [sp, #56]                   // 8-byte Folded Spill
	b.ne	.LBB177_4
// %bb.1:
	cbz	x2, .LBB177_46
// %bb.2:
	cmp	x2, #4
	b.hs	.LBB177_31
// %bb.3:
	mov	x8, xzr
	b	.LBB177_42
.LBB177_4:
	cbz	x2, .LBB177_46
// %bb.5:
	subs	x6, x1, #1
	b.ls	.LBB177_44
// %bb.6:
	lsl	x13, x2, #3
	sub	x14, x1, #2
	add	x13, x13, #8
	mul	x12, x2, x1
	cmp	xzr, x14, lsr #61
	lsl	x17, x14, #3
	mul	x8, x13, x1
	mov	x9, xzr
	mov	x10, xzr
	mov	x11, xzr
	add	x18, x12, #1
	cset	w21, ne
	add	x0, x3, #8
	lsl	x15, x1, #4
	stp	x8, x17, [sp, #40]              // 16-byte Folded Spill
	and	x8, x6, #0xfffffffffffffffc
	add	x7, x17, #16
	add	x19, x4, #8
	lsl	x20, x12, #3
	add	x24, x3, #4
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	orr	x8, x8, #0x1
	lsl	x22, x1, #1
	add	x23, x4, #4
	mov	x25, x1
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldr	x8, [sp, #56]                   // 8-byte Folded Reload
	stp	x23, x15, [sp, #16]             // 16-byte Folded Spill
	sub	x8, x8, #4
	stp	x18, x8, [sp, #64]              // 16-byte Folded Spill
.LBB177_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB177_19 Depth 2
                                        //     Child Loop BB177_23 Depth 2
	mov	w14, #1
	lsl	x13, x11, #1
	bfi	x14, x11, #1, #63
	mul	x26, x11, x1
	mul	x13, x13, x1
	cmp	x6, #4
	mul	x14, x14, x1
	add	x30, x4, x26, lsl #3
	add	x13, x3, x13, lsl #3
	add	x14, x3, x14, lsl #3
	ldp	s0, s1, [x13]
	ldp	s2, s3, [x14]
	add	x13, x11, x2
	mov	w14, #1
	mul	x13, x13, x1
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	add	x13, x4, x13, lsl #3
	stp	s4, s5, [x30]
	stp	s0, s1, [x13]
	b.lo	.LBB177_22
// %bb.8:                               //   in Loop: Header=BB177_7 Depth=1
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	add	x18, x30, #12
	add	x29, x30, #8
	add	x14, x18, x17
	add	x13, x8, x26
	add	x28, x4, x13, lsl #3
	add	x27, x28, #4
	add	x13, x28, x17
	cmp	x13, x28
	add	x13, x27, x17
	cset	w16, lo
	cmp	x13, x27
	orr	w5, w16, w21
	cset	w16, lo
	cmp	x14, x18
	add	x13, x29, x17
	cset	w14, lo
	cmp	x13, x29
	cset	w13, lo
	tbnz	w5, #0, .LBB177_21
// %bb.9:                               //   in Loop: Header=BB177_7 Depth=1
	orr	w16, w16, w21
	tbnz	w16, #0, .LBB177_21
// %bb.10:                              //   in Loop: Header=BB177_7 Depth=1
	orr	w14, w14, w21
	tbnz	w14, #0, .LBB177_21
// %bb.11:                              //   in Loop: Header=BB177_7 Depth=1
	orr	w13, w13, w21
	mov	w14, #1
	tbnz	w13, #0, .LBB177_22
// %bb.12:                              //   in Loop: Header=BB177_7 Depth=1
	add	x13, x26, x1
	ldr	x8, [sp, #40]                   // 8-byte Folded Reload
	mov	x14, x4
	mov	x23, x22
	add	x5, x4, x13, lsl #3
	mov	x22, x24
	add	x24, x30, x8
	sub	x13, x5, #4
	cmp	x29, x5
	mov	x15, x6
	cset	w14, lo
	cmp	x18, x13
	sub	x6, x24, #4
	cset	w16, lo
	cmp	x6, x29
	and	w8, w14, w16
	cset	w14, hi
	cmp	x28, x13
	cset	w30, lo
	cmp	x24, x29
	cset	w26, hi
	cmp	x27, x13
	cset	w16, lo
	cmp	x6, x18
	cset	w29, hi
	cmp	x28, x5
	cset	w13, lo
	cmp	x24, x18
	cset	w18, hi
	cmp	x27, x5
	cset	w5, lo
	cmp	x24, x28
	cset	w28, hi
	cmp	x6, x27
	mov	w17, w21
	cset	w27, hi
	tbnz	w8, #0, .LBB177_28
// %bb.13:                              //   in Loop: Header=BB177_7 Depth=1
	and	w8, w14, w30
	mov	x6, x15
	mov	x24, x22
	tbnz	w8, #0, .LBB177_29
// %bb.14:                              //   in Loop: Header=BB177_7 Depth=1
	and	w8, w26, w16
	mov	x22, x23
	tbnz	w8, #0, .LBB177_27
// %bb.15:                              //   in Loop: Header=BB177_7 Depth=1
	and	w8, w29, w13
	mov	w21, w17
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB177_26
// %bb.16:                              //   in Loop: Header=BB177_7 Depth=1
	and	w8, w18, w5
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB177_25
// %bb.17:                              //   in Loop: Header=BB177_7 Depth=1
	and	w8, w28, w27
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	tbnz	w8, #0, .LBB177_22
// %bb.18:                              //   in Loop: Header=BB177_7 Depth=1
	mov	x14, x19
	ldr	x18, [sp, #32]                  // 8-byte Folded Reload
	mov	x26, x0
	ldr	x27, [sp, #56]                  // 8-byte Folded Reload
	mov	x28, x19
.LBB177_19:                             //   Parent Loop BB177_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x8, x26, x7
	subs	x18, x18, #4
	ld2	{ v0.4s, v1.4s }, [x26], #32
	ld2	{ v2.4s, v3.4s }, [x8]
	add	x8, x14, x20
	fsub	v6.4s, v1.4s, v3.4s
	fadd	v4.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v0.4s, v0.4s, v2.4s
	fneg	v7.4s, v6.4s
	st2	{ v4.4s, v5.4s }, [x28], #32
	ld2	{ v1.4s, v2.4s }, [x27], #32
	fmul	v3.4s, v2.4s, v7.4s
	mov	x14, x28
	fmla	v3.4s, v1.4s, v0.4s
	fmul	v4.4s, v6.4s, v1.4s
	fmla	v4.4s, v2.4s, v0.4s
	st2	{ v3.4s, v4.4s }, [x8]
	b.ne	.LBB177_19
// %bb.20:                              //   in Loop: Header=BB177_7 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cmp	x6, x8
	b.ne	.LBB177_22
	b	.LBB177_24
.LBB177_21:                             //   in Loop: Header=BB177_7 Depth=1
	mov	w14, #1
.LBB177_22:                             //   in Loop: Header=BB177_7 Depth=1
	add	x8, x14, x10
	add	x13, x14, x12
	add	x16, x14, x25
	add	x18, x14, x9
	add	x27, x24, x8, lsl #3
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	sub	x26, x1, x14
	add	x28, x23, x13, lsl #3
	add	x29, x24, x16, lsl #3
	add	x18, x23, x18, lsl #3
	add	x30, x8, x14, lsl #3
.LBB177_23:                             //   Parent Loop BB177_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	s3, s0, [x27, #-4]
	ldp	s4, s1, [x29, #-4]
	ldp	s5, s7, [x30, #-4]
	subs	x26, x26, #1
	add	x27, x27, #8
	add	x29, x29, #8
	add	x30, x30, #8
	fsub	s2, s0, s1
	fsub	s16, s3, s4
	fadd	s3, s3, s4
	fadd	s0, s0, s1
	fneg	s6, s2
	fmul	s2, s2, s5
	stur	s3, [x18, #-4]
	str	s0, [x18], #8
	fmul	s6, s7, s6
	fmadd	s1, s16, s7, s2
	fmadd	s2, s16, s5, s6
	str	s1, [x28]
	stur	s2, [x28, #-4]
	add	x28, x28, #8
	b.ne	.LBB177_23
.LBB177_24:                             //   in Loop: Header=BB177_7 Depth=1
	add	x11, x11, #1
	add	x0, x0, x15
	add	x19, x19, x7
	add	x10, x10, x22
	add	x12, x12, x1
	add	x25, x25, x22
	add	x9, x9, x1
	cmp	x11, x2
	b.ne	.LBB177_7
	b	.LBB177_46
.LBB177_25:                             //   in Loop: Header=BB177_7 Depth=1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	mov	w14, #1
	b	.LBB177_22
.LBB177_26:                             //   in Loop: Header=BB177_7 Depth=1
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB177_22
.LBB177_27:                             //   in Loop: Header=BB177_7 Depth=1
	ldp	x23, x15, [sp, #16]             // 16-byte Folded Reload
	mov	w21, w17
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	b	.LBB177_22
.LBB177_28:                             //   in Loop: Header=BB177_7 Depth=1
	mov	x6, x15
	mov	w21, w17
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #1
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	mov	x24, x22
	b	.LBB177_30
.LBB177_29:                             //   in Loop: Header=BB177_7 Depth=1
	mov	w14, #1
	mov	w21, w17
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
.LBB177_30:                             //   in Loop: Header=BB177_7 Depth=1
	mov	x22, x23
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	b	.LBB177_22
.LBB177_31:
	sub	x9, x2, #1
	mov	x8, xzr
	add	x11, x4, x2, lsl #3
	cmp	xzr, x9, lsr #61
	lsl	x9, x9, #3
	cset	w10, ne
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB177_42
// %bb.32:
	tbnz	w10, #0, .LBB177_42
// %bb.33:
	add	x11, x11, #4
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB177_42
// %bb.34:
	tbnz	w10, #0, .LBB177_42
// %bb.35:
	add	x11, x4, #4
	add	x12, x11, x9
	cmp	x12, x11
	b.lo	.LBB177_42
// %bb.36:
	tbnz	w10, #0, .LBB177_42
// %bb.37:
	add	x11, x4, x9
	cmp	x11, x4
	b.lo	.LBB177_42
// %bb.38:
	tbnz	w10, #0, .LBB177_42
// %bb.39:
	and	x8, x2, #0xfffffffffffffffc
	add	x9, x9, #8
	mov	x10, x8
	mov	x11, x4
	mov	x12, x3
.LBB177_40:                             // =>This Inner Loop Header: Depth=1
	ld4	{ v0.4s, v1.4s, v2.4s, v3.4s }, [x12], #64
	fadd	v4.4s, v0.4s, v2.4s
	add	x13, x11, x9
	fadd	v5.4s, v1.4s, v3.4s
	subs	x10, x10, #4
	st2	{ v4.4s, v5.4s }, [x11], #32
	fsub	v4.4s, v0.4s, v2.4s
	fsub	v5.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x13]
	b.ne	.LBB177_40
// %bb.41:
	cmp	x8, x2
	b.eq	.LBB177_46
.LBB177_42:
	add	x9, x8, x2
	add	x10, x4, x8, lsl #3
	add	x11, x3, x8, lsl #4
	sub	x8, x2, x8
	add	x12, x4, x9, lsl #3
	add	x9, x10, #4
	add	x10, x12, #4
	add	x11, x11, #8
.LBB177_43:                             // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x11, #-8]
	ldp	s2, s3, [x11], #16
	subs	x8, x8, #1
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stur	s4, [x9, #-4]
	str	s5, [x9], #8
	stur	s0, [x10, #-4]
	str	s1, [x10], #8
	b.ne	.LBB177_43
	b	.LBB177_46
.LBB177_44:
	mul	x10, x2, x1
	add	x8, x4, #4
	lsl	x9, x1, #3
	add	x11, x3, #4
	lsl	x10, x10, #3
	lsl	x12, x1, #4
.LBB177_45:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	s0, s1, [x11, #-4]
	add	x11, x11, x12
	ldp	s2, s3, [x13, #-4]
	add	x13, x8, x10
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stur	s4, [x8, #-4]
	str	s5, [x8]
	add	x8, x8, x9
	stur	s0, [x13, #-4]
	str	s1, [x13]
	b.ne	.LBB177_45
.LBB177_46:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end177:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end177-_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
.LCPI178_0:
	.word	0x3f5db3d7                      // float 0.866025388
	.word	0xbf5db3d7                      // float -0.866025388
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	x22, x21, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	subs	x8, x1, #1
	b.ne	.LBB178_4
// %bb.1:
	cbz	x2, .LBB178_10
// %bb.2:
	adrp	x10, .LCPI178_0
	movi	v0.2s, #191, lsl #24
	lsl	x8, x2, #4
	add	x9, x3, #8
	ldr	d1, [x10, :lo12:.LCPI178_0]
	mov	x10, x2
.LBB178_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d2, d3, [x9]
	subs	x10, x10, #1
	ldur	d5, [x9, #-8]
	add	x9, x9, #24
	fadd	v4.2s, v2.2s, v3.2s
	fsub	v2.2s, v2.2s, v3.2s
	fmul	v3.2s, v4.2s, v0.2s
	fmul	v2.2s, v2.2s, v1.2s
	fadd	v4.2s, v5.2s, v4.2s
	fadd	v3.2s, v5.2s, v3.2s
	rev64	v2.2s, v2.2s
	str	d4, [x4]
	fadd	v5.2s, v2.2s, v3.2s
	fsub	v2.2s, v3.2s, v2.2s
	str	d5, [x4, x2, lsl #3]
	str	d2, [x4, x8]
	add	x4, x4, #8
	b.ne	.LBB178_3
	b	.LBB178_10
.LBB178_4:
	cbz	x2, .LBB178_10
// %bb.5:
	adrp	x18, .LCPI178_0
	mul	x16, x2, x1
	lsl	x11, x1, #3
	add	x12, x1, x1, lsl #1
	movi	v0.2s, #191, lsl #24
	mov	w0, #46039
	ldr	d1, [x18, :lo12:.LCPI178_0]
	mov	w18, #46039
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #3
	add	x13, x3, x11
	add	x14, x4, x16, lsl #4
	add	x15, x3, x1, lsl #4
	add	x16, x4, x16, lsl #3
	add	x17, x5, x8, lsl #3
	fmov	s2, #0.50000000
	movk	w18, #48989, lsl #16
	movk	w0, #16221, lsl #16
	mov	x6, x4
	mov	x7, x3
	b	.LBB178_7
.LBB178_6:                              //   in Loop: Header=BB178_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x7, x7, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x6, x6, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB178_10
.LBB178_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB178_9 Depth 2
	add	x19, x9, x9, lsl #1
	cmp	x1, #2
	add	x20, x19, #2
	mul	x19, x19, x1
	mul	x20, x20, x1
	add	x21, x1, x19
	ldr	d3, [x3, x19, lsl #3]
	add	x19, x9, x2
	ldr	d4, [x3, x21, lsl #3]
	add	x21, x9, x10
	ldr	d5, [x3, x20, lsl #3]
	mul	x20, x9, x1
	mul	x19, x19, x1
	mul	x21, x21, x1
	fadd	v6.2s, v4.2s, v5.2s
	fsub	v4.2s, v4.2s, v5.2s
	fmul	v5.2s, v6.2s, v0.2s
	fmul	v4.2s, v4.2s, v1.2s
	fadd	v5.2s, v3.2s, v5.2s
	rev64	v4.2s, v4.2s
	fadd	v3.2s, v3.2s, v6.2s
	fadd	v6.2s, v4.2s, v5.2s
	fsub	v4.2s, v5.2s, v4.2s
	str	d3, [x4, x20, lsl #3]
	str	d6, [x4, x19, lsl #3]
	str	d4, [x4, x21, lsl #3]
	b.lo	.LBB178_6
// %bb.8:                               //   in Loop: Header=BB178_7 Depth=1
	mov	x19, xzr
	mov	x20, x8
.LBB178_9:                              //   Parent Loop BB178_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x21, x13, x19
	add	x22, x15, x19
	fmov	s18, w0
	subs	x20, x20, #1
	ldp	s5, s3, [x21, #8]
	ldp	s7, s4, [x22, #8]
	add	x21, x7, x19
	add	x22, x17, x19
	fadd	s6, s3, s4
	fsub	s16, s5, s7
	ldr	s19, [x21, #12]
	fadd	s5, s5, s7
	fsub	s3, s3, s4
	ldp	s24, s25, [x22]
	fmul	s17, s6, s2
	fmul	s7, s16, s18
	fmul	s4, s5, s2
	fmov	s18, w18
	fadd	s6, s19, s6
	add	x22, x16, x19
	fsub	s16, s19, s17
	ldr	s17, [x21, #8]
	add	x21, x5, x19
	fmul	s3, s3, s18
	fsub	s4, s17, s4
	fadd	s5, s17, s5
	fadd	s20, s7, s16
	fsub	s7, s16, s7
	ldp	s16, s21, [x21]
	add	x21, x6, x19
	fadd	s22, s4, s3
	fsub	s3, s4, s3
	fneg	s18, s20
	fneg	s23, s7
	fmul	s20, s16, s20
	fmul	s7, s7, s24
	stp	s5, s6, [x21, #8]
	add	x21, x14, x19
	add	x19, x19, #8
	fmul	s18, s21, s18
	fmul	s17, s25, s23
	fmadd	s4, s22, s21, s20
	fmadd	s16, s22, s16, s18
	fmadd	s5, s3, s24, s17
	fmadd	s3, s3, s25, s7
	stp	s16, s4, [x22, #8]
	stp	s5, s3, [x21, #8]
	b.ne	.LBB178_9
	b	.LBB178_6
.LBB178_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x22, x21, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end178:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end178-_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 128
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	b.ne	.LBB179_4
// %bb.1:
	cbz	x2, .LBB179_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	mov	w14, #14202
	mov	w15, #7101
	mov	w16, #31000
	mov	w17, #30833
	mov	w18, #30833
	add	x8, x4, #4
	lsl	x9, x2, #4
	lsl	x10, x10, #3
	lsl	x11, x2, #5
	lsl	x12, x2, #3
	add	x13, x3, #20
	movk	w14, #16030, lsl #16
	movk	w15, #48975, lsl #16
	movk	w16, #16150, lsl #16
	movk	w17, #16243, lsl #16
	movk	w18, #49011, lsl #16
.LBB179_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x13, #-12]
	ldp	s2, s3, [x13, #12]
	fmov	s17, w14
	fmov	s18, w16
	fmov	s22, w15
	fmov	s23, w17
	fmov	s27, w18
	add	x1, x8, x11
	fadd	s5, s0, s2
	fadd	s6, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	ldp	s2, s7, [x13, #-4]
	ldp	s3, s4, [x13, #4]
	add	x0, x8, x12
	subs	x2, x2, #1
	fsub	s16, s7, s4
	fadd	s20, s2, s3
	fsub	s2, s2, s3
	fadd	s4, s7, s4
	ldp	s19, s3, [x13, #-20]
	add	x13, x13, #40
	fmul	s21, s16, s18
	fmul	s16, s16, s27
	fmul	s25, s2, s18
	fmul	s2, s2, s27
	fmadd	s7, s5, s17, s19
	fmadd	s24, s6, s17, s3
	fadd	s26, s19, s5
	fmadd	s5, s5, s22, s19
	fmadd	s21, s1, s23, s21
	fmadd	s1, s1, s18, s16
	fmadd	s23, s0, s23, s25
	fmadd	s0, s0, s18, s2
	fmadd	s7, s20, s22, s7
	fmadd	s24, s4, s22, s24
	fmadd	s22, s6, s22, s3
	fmadd	s5, s20, s17, s5
	fadd	s25, s26, s20
	fadd	s3, s3, s6
	fsub	s19, s7, s21
	fadd	s7, s7, s21
	fmadd	s16, s4, s17, s22
	fadd	s26, s24, s23
	fsub	s2, s24, s23
	fsub	s6, s5, s1
	fadd	s1, s5, s1
	stur	s25, [x8, #-4]
	stur	s7, [x1, #-4]
	fadd	s7, s16, s0
	stur	s19, [x0, #-4]
	str	s26, [x0]
	add	x0, x8, x9
	str	s2, [x1]
	fadd	s2, s3, s4
	fsub	s0, s16, s0
	stur	s6, [x0, #-4]
	str	s7, [x0]
	add	x0, x8, x10
	str	s2, [x8], #8
	stur	s1, [x0, #-4]
	str	s0, [x0]
	b.ne	.LBB179_3
	b	.LBB179_10
.LBB179_4:
	str	x8, [sp]                        // 8-byte Folded Spill
	cbz	x2, .LBB179_10
// %bb.5:
	lsl	x11, x2, #2
	lsl	x10, x2, #1
	mul	x8, x2, x1
	mov	w13, #24
	add	x15, x1, x1, lsl #2
	lsl	x14, x1, #3
	stp	x10, x11, [sp, #16]             // 16-byte Folded Spill
	add	x10, x10, x2
	madd	x13, x8, x13, x4
	mov	w23, #14202
	mov	w24, #7101
	mov	w25, #31000
	str	x10, [sp, #8]                   // 8-byte Folded Spill
	ldr	x10, [sp]                       // 8-byte Folded Reload
	mov	w26, #30833
	mov	w27, #30833
	mov	x9, xzr
	lsl	x15, x15, #3
	lsl	x7, x10, #4
	add	x18, x10, x10, lsl #1
	add	x0, x7, x3
	lsl	x21, x18, #3
	add	x18, x0, #16
	add	x0, x21, x3
	add	x16, x3, x14
	add	x17, x3, x1, lsl #5
	add	x0, x0, #24
	add	x6, x4, x8, lsl #4
	add	x7, x5, x7
	add	x19, x5, x10, lsl #3
	add	x20, x4, x8, lsl #5
	add	x21, x5, x21
	add	x22, x4, x8, lsl #3
	movk	w23, #16030, lsl #16
	movk	w24, #48975, lsl #16
	movk	w25, #16150, lsl #16
	movk	w26, #16243, lsl #16
	movk	w27, #49011, lsl #16
	mov	x28, x4
	mov	x29, x3
	b	.LBB179_7
.LBB179_6:                              //   in Loop: Header=BB179_7 Depth=1
	add	x9, x9, #1
	add	x13, x13, x14
	add	x29, x29, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x28, x28, x14
	add	x6, x6, x14
	add	x20, x20, x14
	add	x22, x22, x14
	cmp	x9, x2
	b.eq	.LBB179_10
.LBB179_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB179_9 Depth 2
	add	x8, x9, x9, lsl #2
	fmov	s21, w25
	add	x30, x8, #4
	add	x11, x8, #2
	mul	x10, x8, x1
	add	x8, x8, #3
	mul	x30, x30, x1
	fmov	s19, w23
	add	x12, x1, x10
	mul	x11, x11, x1
	add	x10, x3, x10, lsl #3
	mul	x8, x8, x1
	add	x12, x3, x12, lsl #3
	fmov	s27, w26
	add	x11, x3, x11, lsl #3
	fmov	s23, w24
	ldp	s0, s1, [x10]
	add	x10, x3, x30, lsl #3
	add	x8, x3, x8, lsl #3
	ldp	s2, s3, [x12]
	ldp	s6, s7, [x11]
	ldp	s4, s5, [x10]
	ldr	x11, [sp, #24]                  // 8-byte Folded Reload
	add	x10, x9, x2
	cmp	x1, #2
	mul	x10, x10, x1
	fadd	s17, s2, s4
	fsub	s2, s2, s4
	ldp	s16, s4, [x8]
	fadd	s18, s3, s5
	fsub	s3, s3, s5
	mul	x8, x9, x1
	add	x11, x9, x11
	fadd	s20, s0, s17
	fmadd	s22, s17, s19, s0
	fadd	s5, s6, s16
	fsub	s6, s6, s16
	fsub	s16, s7, s4
	fadd	s4, s7, s4
	fadd	s7, s1, s18
	fmadd	s24, s18, s19, s1
	add	x8, x4, x8, lsl #3
	fmadd	s0, s17, s23, s0
	fmul	s25, s6, s21
	fadd	s20, s20, s5
	fmul	s26, s16, s21
	fmadd	s22, s5, s23, s22
	fadd	s7, s7, s4
	fmadd	s24, s4, s23, s24
	fmadd	s1, s18, s23, s1
	add	x10, x4, x10, lsl #3
	fmadd	s25, s2, s27, s25
	fmadd	s0, s5, s19, s0
	fmadd	s26, s3, s27, s26
	fmov	s27, w27
	stp	s20, s7, [x8]
	mul	x8, x11, x1
	ldp	x12, x11, [sp, #8]              // 16-byte Folded Reload
	fmul	s6, s6, s27
	fmul	s16, s16, s27
	fsub	s7, s22, s26
	fadd	s17, s24, s25
	fmadd	s1, s4, s19, s1
	fadd	s18, s22, s26
	add	x12, x9, x12
	fsub	s20, s24, s25
	fmadd	s2, s2, s21, s6
	fmadd	s3, s3, s21, s16
	add	x11, x9, x11
	add	x8, x4, x8, lsl #3
	stp	s7, s17, [x10]
	mul	x10, x12, x1
	mul	x11, x11, x1
	fsub	s4, s0, s3
	fadd	s5, s1, s2
	fadd	s0, s0, s3
	fsub	s1, s1, s2
	add	x11, x4, x11, lsl #3
	stp	s18, s20, [x8]
	add	x8, x4, x10, lsl #3
	stp	s4, s5, [x11]
	stp	s0, s1, [x8]
	b.lo	.LBB179_6
// %bb.8:                               //   in Loop: Header=BB179_7 Depth=1
	mov	x30, xzr
	ldr	x8, [sp]                        // 8-byte Folded Reload
.LBB179_9:                              //   Parent Loop BB179_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x10, x16, x30
	add	x11, x17, x30
	add	x12, x0, x30
	fmov	s18, w23
	fmov	s20, w25
	fmov	s25, w24
	ldp	s0, s1, [x10, #8]
	add	x10, x18, x30
	fmov	s26, w26
	ldp	s2, s3, [x11, #8]
	ldp	s4, s16, [x12, #8]
	ldp	s5, s6, [x10, #8]
	add	x10, x29, x30
	add	x11, x5, x30
	fadd	s7, s1, s3
	fadd	s22, s0, s2
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	fsub	s17, s5, s4
	fadd	s2, s6, s16
	ldp	s21, s19, [x10, #8]
	fadd	s4, s5, s4
	fsub	s5, s6, s16
	add	x10, x28, x30
	subs	x8, x8, #1
	fmul	s24, s17, s20
	fmadd	s23, s7, s18, s19
	fadd	s6, s21, s22
	fmul	s3, s5, s20
	fadd	s16, s19, s7
	fmadd	s27, s22, s18, s21
	fmadd	s21, s22, s25, s21
	fmadd	s24, s0, s26, s24
	fmadd	s23, s2, s25, s23
	fadd	s6, s6, s4
	fmadd	s3, s1, s26, s3
	fmov	s26, w27
	fadd	s16, s16, s2
	fmadd	s27, s4, s25, s27
	fmadd	s4, s4, s18, s21
	fadd	s28, s23, s24
	fmul	s17, s17, s26
	str	s6, [x10, #8]
	fmadd	s6, s7, s25, s19
	ldp	s19, s29, [x11]
	str	s16, [x10, #12]
	add	x10, x21, x30
	fneg	s7, s28
	fmadd	s0, s0, s20, s17
	fsub	s17, s23, s24
	fsub	s16, s27, s3
	fmadd	s2, s2, s18, s6
	fmul	s24, s19, s28
	ldp	s6, s23, [x10]
	fmul	s7, s29, s7
	add	x11, x22, x30
	fneg	s22, s17
	add	x10, x19, x30
	fmul	s5, s5, s26
	fadd	s3, s27, s3
	fmadd	s7, s16, s19, s7
	fadd	s19, s2, s0
	fmadd	s16, s16, s29, s24
	fsub	s0, s2, s0
	fmul	s2, s23, s22
	fmadd	s1, s1, s20, s5
	str	s7, [x11, #8]
	fneg	s5, s19
	ldp	s7, s18, [x10]
	add	x10, x7, x30
	str	s16, [x11, #12]
	fmul	s16, s17, s6
	fneg	s20, s0
	fmadd	s2, s3, s6, s2
	fsub	s17, s4, s1
	ldp	s21, s6, [x10]
	fmul	s5, s18, s5
	fadd	s1, s4, s1
	fmadd	s3, s3, s23, s16
	fmul	s16, s19, s7
	add	x10, x20, x30
	add	x11, x6, x30
	fmul	s4, s6, s20
	fmul	s0, s0, s21
	fmadd	s5, s17, s7, s5
	str	s2, [x10, #8]
	fmadd	s2, s17, s18, s16
	str	s3, [x10, #12]
	add	x10, x13, x30
	fmadd	s3, s1, s21, s4
	fmadd	s0, s1, s6, s0
	add	x30, x30, #8
	str	s5, [x11, #8]
	str	s2, [x11, #12]
	str	s3, [x10, #8]
	str	s0, [x10, #12]
	b.ne	.LBB179_9
	b	.LBB179_6
.LBB179_10:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.Lfunc_end179:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end179-_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #256
	str	d14, [sp, #96]                  // 8-byte Folded Spill
	stp	d13, d12, [sp, #112]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #128]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #144]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #176]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #192]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 256
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #80]               // 16-byte Folded Spill
	b.ne	.LBB180_4
// %bb.1:
	cbz	x2, .LBB180_10
// %bb.2:
	ldp	x9, x15, [sp, #80]              // 16-byte Folded Reload
	mov	x7, x2
	lsl	x8, x2, #5
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	lsl	x12, x2, #4
	lsl	x14, x2, #3
	mov	w16, #40199
	mov	w17, #56455
	mov	w18, #42469
	mov	w0, #38112
	mov	w1, #9756
	mov	w2, #9730
	mov	w3, #9730
	mov	w4, #9756
	add	x9, x9, #4
	lsl	x10, x13, #3
	lsl	x11, x11, #3
	lsl	x13, x13, #4
	add	x15, x15, #28
	movk	w16, #16159, lsl #16
	movk	w17, #48739, lsl #16
	movk	w18, #48998, lsl #16
	movk	w0, #16249, lsl #16
	movk	w1, #16200, lsl #16
	movk	w2, #16094, lsl #16
	movk	w3, #48862, lsl #16
	movk	w4, #48968, lsl #16
.LBB180_3:                              // =>This Inner Loop Header: Depth=1
	ldp	s0, s1, [x15, #-20]
	ldp	s4, s2, [x15, #20]
	ldp	s5, s7, [x15, #12]
	ldp	s16, s17, [x15, #-12]
	ldp	s22, s24, [x15, #-28]
	fadd	s6, s0, s4
	fadd	s3, s1, s2
	fsub	s0, s0, s4
	fsub	s1, s1, s2
	fadd	s4, s16, s5
	fadd	s2, s17, s7
	fsub	s5, s16, s5
	fsub	s7, s17, s7
	fmov	s17, w16
	fmov	s23, w0
	ldp	s21, s18, [x15, #4]
	ldp	s19, s20, [x15, #-4]
	fmadd	s26, s6, s17, s22
	fmadd	s28, s3, s17, s24
	fmul	s29, s7, s23
	fmul	s30, s5, s23
	fmov	s27, w17
	fmov	s31, w1
	fadd	s25, s19, s21
	fadd	s16, s20, s18
	fsub	s19, s19, s21
	fsub	s18, s20, s18
	fmadd	s20, s4, s27, s26
	fmadd	s26, s2, s27, s28
	fmadd	s28, s1, s31, s29
	fmadd	s29, s0, s31, s30
	fmov	s21, w18
	fmov	s30, w2
	add	x5, x9, x14
	fadd	s9, s22, s6
	fmov	s10, w3
	fmadd	s11, s6, s27, s22
	fmadd	s20, s25, s21, s20
	fmadd	s28, s18, s30, s28
	fmadd	s26, s16, s21, s26
	fmadd	s29, s19, s30, s29
	fmadd	s6, s6, s21, s22
	fadd	s22, s24, s3
	add	x6, x9, x11
	subs	x7, x7, #1
	fsub	s31, s20, s28
	fadd	s20, s20, s28
	fadd	s8, s29, s26
	fmadd	s28, s4, s21, s11
	fsub	s26, s26, s29
	add	x15, x15, #56
	stur	s31, [x5, #-4]
	fmul	s31, s7, s10
	str	s8, [x5]
	add	x5, x9, x13
	fadd	s8, s9, s4
	fmadd	s9, s3, s27, s24
	fmul	s10, s5, s10
	fmadd	s3, s3, s21, s24
	stur	s20, [x5, #-4]
	fmov	s20, w4
	fmadd	s29, s1, s23, s31
	fmadd	s28, s25, s17, s28
	fadd	s31, s8, s25
	fmadd	s8, s2, s21, s9
	fmadd	s9, s0, s23, s10
	fmul	s7, s7, s20
	fmul	s5, s5, s20
	fmadd	s4, s4, s17, s6
	fmadd	s29, s18, s20, s29
	fmadd	s3, s2, s17, s3
	fmadd	s21, s16, s17, s8
	str	s26, [x5]
	fmadd	s20, s19, s20, s9
	fmadd	s1, s1, s30, s7
	fmadd	s0, s0, s30, s5
	fmadd	s4, s25, s27, s4
	fadd	s6, s28, s29
	fmadd	s3, s16, s27, s3
	fsub	s24, s28, s29
	add	x5, x9, x12
	fadd	s5, s20, s21
	fmadd	s1, s18, s23, s1
	fmadd	s0, s19, s23, s0
	fadd	s2, s22, s2
	stur	s6, [x6, #-4]
	fsub	s7, s21, s20
	stur	s24, [x5, #-4]
	str	s5, [x5]
	fsub	s5, s4, s1
	fadd	s6, s0, s3
	add	x5, x9, x10
	fadd	s2, s2, s16
	fadd	s1, s4, s1
	fsub	s0, s3, s0
	str	s7, [x6]
	stur	s5, [x5, #-4]
	str	s6, [x5]
	add	x5, x9, x8
	stur	s31, [x9, #-4]
	str	s2, [x9], #8
	stur	s1, [x5, #-4]
	str	s0, [x5]
	b.ne	.LBB180_3
	b	.LBB180_10
.LBB180_4:
	str	x1, [sp, #72]                   // 8-byte Folded Spill
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	cbz	x2, .LBB180_10
// %bb.5:
	lsl	x10, x2, #1
	lsl	x11, x2, #2
	ldp	x12, x4, [sp, #72]              // 16-byte Folded Reload
	mov	x1, x2
	mov	w17, #24
	str	x10, [sp, #64]                  // 8-byte Folded Spill
	add	x10, x10, x2
	lsl	x18, x10, #1
	ldr	x3, [sp, #88]                   // 8-byte Folded Reload
	mul	x8, x2, x12
	mov	x9, xzr
	stp	x11, x10, [sp, #48]             // 16-byte Folded Spill
	add	x10, x11, x2
	lsl	x11, x12, #3
	ldr	x2, [sp, #8]                    // 8-byte Folded Reload
	madd	x21, x8, x17, x4
	mov	w17, #9756
	stp	x10, x18, [sp, #32]             // 16-byte Folded Spill
	mov	w10, #56
	add	x18, x3, x11
	add	x13, x2, x2, lsl #1
	mul	x10, x12, x10
	lsl	x13, x13, #3
	add	x26, x5, x2, lsl #3
	add	x15, x4, x8, lsl #5
	add	x22, x5, x13
	add	x27, x4, x8, lsl #4
	add	x29, x4, x8, lsl #3
	movk	w17, #16200, lsl #16
	stp	x10, x11, [sp, #16]             // 16-byte Folded Spill
	mov	w10, #48
	lsl	x11, x2, #4
	str	x1, [sp, #104]                  // 8-byte Folded Spill
	madd	x0, x12, x10, x3
	add	x12, x11, x3
	add	x6, x12, #16
	add	x12, x2, x2, lsl #2
	lsl	x12, x12, #3
	madd	x30, x8, x10, x4
	add	x14, x12, x3
	add	x28, x5, x12
	add	x7, x14, #40
	add	x14, x13, x3
	add	x19, x14, #24
	lsl	x14, x2, #5
	add	x16, x14, x3
	mov	w12, #38112
	add	x20, x16, #32
	mov	w16, #40
	mov	w2, #9730
	add	x23, x5, x11
	madd	x24, x8, x16, x4
	add	x25, x5, x14
	movk	w12, #16249, lsl #16
	movk	w2, #16094, lsl #16
	b	.LBB180_7
.LBB180_6:                              //   in Loop: Header=BB180_7 Depth=1
	ldp	x10, x8, [sp, #16]              // 16-byte Folded Reload
	mov	w12, #38112
	mov	w17, #9756
	ldr	x1, [sp, #104]                  // 8-byte Folded Reload
	add	x9, x9, #1
	movk	w12, #16249, lsl #16
	movk	w17, #16200, lsl #16
	add	x3, x3, x10
	add	x18, x18, x10
	add	x15, x15, x8
	add	x0, x0, x10
	add	x6, x6, x10
	add	x7, x7, x10
	add	x19, x19, x10
	add	x20, x20, x10
	add	x4, x4, x8
	add	x21, x21, x8
	add	x24, x24, x8
	add	x27, x27, x8
	add	x29, x29, x8
	add	x30, x30, x8
	cmp	x9, x1
	b.eq	.LBB180_10
.LBB180_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB180_9 Depth 2
	lsl	x8, x9, #3
	ldr	x1, [sp, #72]                   // 8-byte Folded Reload
	sub	x8, x8, x9
	ldr	x11, [sp, #88]                  // 8-byte Folded Reload
	add	x16, x8, #6
	add	x10, x8, #2
	mul	x13, x8, x1
	fmov	s20, w12
	mul	x16, x16, x1
	fmov	s31, w17
	mul	x10, x10, x1
	mov	w12, #42469
	add	x14, x11, x13, lsl #3
	add	x13, x1, x13
	add	x16, x11, x16, lsl #3
	movk	w12, #48998, lsl #16
	add	x13, x11, x13, lsl #3
	add	x10, x11, x10, lsl #3
	ldp	s1, s0, [x14]
	add	x14, x8, #5
	fmov	s8, w2
	ldp	s2, s3, [x13]
	mul	x13, x14, x1
	add	x14, x8, #3
	ldp	s5, s6, [x16]
	add	x8, x8, #4
	mov	w17, #9756
	add	x13, x11, x13, lsl #3
	movk	w17, #48968, lsl #16
	ldp	s7, s18, [x10]
	mul	x8, x8, x1
	fadd	s17, s2, s5
	mul	x10, x14, x1
	fadd	s4, s3, s6
	ldp	s16, s19, [x13]
	add	x8, x11, x8, lsl #3
	fsub	s3, s3, s6
	add	x10, x11, x10, lsl #3
	fadd	s22, s1, s17
	fsub	s2, s2, s5
	fadd	s27, s0, s4
	fadd	s6, s7, s16
	fadd	s5, s18, s19
	ldp	s23, s26, [x8]
	ldp	s24, s25, [x10]
	mov	w8, #40199
	fsub	s16, s7, s16
	movk	w8, #16159, lsl #16
	fsub	s18, s18, s19
	fadd	s28, s22, s6
	mov	w14, #56455
	fadd	s7, s24, s23
	fadd	s21, s25, s26
	fmov	s19, w8
	fadd	s27, s27, s5
	mul	x8, x9, x1
	movk	w14, #48739, lsl #16
	ldr	x11, [sp, #80]                  // 8-byte Folded Reload
	fmul	s30, s18, s20
	fmadd	s29, s17, s19, s1
	fsub	s25, s25, s26
	fadd	s26, s28, s7
	ldr	x10, [sp, #104]                 // 8-byte Folded Reload
	fmov	s22, w14
	add	x8, x11, x8, lsl #3
	fadd	s27, s27, s21
	fmadd	s30, s3, s31, s30
	add	x10, x9, x10
	fmul	s9, s16, s20
	fmadd	s28, s6, s22, s29
	str	s26, [x8]
	fmadd	s26, s4, s19, s0
	fmov	s29, w12
	str	s27, [x8, #4]
	mul	x8, x10, x1
	mov	w10, #9730
	fmadd	s30, s25, s8, s30
	movk	w10, #48862, lsl #16
	fmadd	s28, s7, s29, s28
	fsub	s23, s24, s23
	fmadd	s24, s5, s22, s26
	fmadd	s26, s2, s31, s9
	fmadd	s9, s17, s22, s1
	fmov	s27, w10
	fmadd	s10, s4, s22, s0
	fsub	s31, s28, s30
	add	x8, x11, x8, lsl #3
	fmadd	s24, s21, s29, s24
	ldr	x10, [sp, #40]                  // 8-byte Folded Reload
	fmul	s11, s18, s27
	fmul	s27, s16, s27
	fmadd	s26, s23, s8, s26
	ldr	x13, [sp, #64]                  // 8-byte Folded Reload
	str	s31, [x8]
	fmadd	s31, s6, s29, s9
	fmadd	s9, s5, s29, s10
	fadd	s28, s28, s30
	fmadd	s10, s3, s20, s11
	fmadd	s27, s2, s20, s27
	fadd	s30, s26, s24
	add	x10, x9, x10
	fmov	s11, w17
	add	x13, x9, x13
	mul	x10, x10, x1
	fmadd	s31, s7, s19, s31
	fmadd	s9, s21, s19, s9
	fsub	s24, s24, s26
	fmadd	s10, s25, s11, s10
	fmadd	s27, s23, s11, s27
	str	s30, [x8, #4]
	mul	x8, x13, x1
	ldr	x13, [sp, #32]                  // 8-byte Folded Reload
	add	x10, x11, x10, lsl #3
	fmadd	s1, s17, s29, s1
	fmul	s18, s18, s11
	fsub	s26, s31, s10
	fadd	s17, s27, s9
	add	x13, x9, x13
	str	s28, [x10]
	add	x8, x11, x8, lsl #3
	str	s24, [x10, #4]
	mul	x10, x13, x1
	fmadd	s0, s4, s29, s0
	fmul	s4, s16, s11
	fmadd	s1, s6, s19, s1
	str	s26, [x8]
	fmadd	s3, s3, s8, s18
	str	s17, [x8, #4]
	add	x8, x11, x10, lsl #3
	ldp	x13, x10, [sp, #48]             // 16-byte Folded Reload
	fmadd	s0, s5, s19, s0
	fmadd	s2, s2, s8, s4
	fadd	s4, s31, s10
	fsub	s5, s9, s27
	fmadd	s1, s7, s22, s1
	fmadd	s3, s25, s20, s3
	add	x13, x9, x13
	cmp	x1, #2
	add	x10, x9, x10
	fmadd	s0, s21, s22, s0
	fmadd	s2, s23, s20, s2
	mul	x13, x13, x1
	mul	x10, x10, x1
	str	s4, [x8]
	fsub	s4, s1, s3
	str	s5, [x8, #4]
	fadd	s1, s1, s3
	add	x8, x11, x13, lsl #3
	fadd	s6, s2, s0
	add	x10, x11, x10, lsl #3
	fsub	s0, s0, s2
	mov	w11, #40199
	mov	w1, #9730
	movk	w11, #16159, lsl #16
	movk	w1, #48862, lsl #16
	str	s4, [x10]
	str	s6, [x10, #4]
	str	s1, [x8]
	str	s0, [x8, #4]
	b.lo	.LBB180_6
// %bb.8:                               //   in Loop: Header=BB180_7 Depth=1
	mov	x16, xzr
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
.LBB180_9:                              //   Parent Loop BB180_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x13, x0, x16
	add	x10, x18, x16
	fmov	s5, w11
	fmov	s7, w14
	fmov	s14, w1
	subs	x8, x8, #1
	ldp	s18, s19, [x13, #8]
	add	x13, x7, x16
	ldp	s16, s17, [x10, #8]
	add	x10, x6, x16
	ldp	s27, s21, [x13, #8]
	add	x13, x19, x16
	ldp	s25, s20, [x10, #8]
	add	x10, x3, x16
	fadd	s2, s17, s19
	ldp	s28, s29, [x13, #8]
	mov	w13, #38112
	fsub	s0, s16, s18
	ldp	s1, s4, [x10, #8]
	add	x10, x20, x16
	movk	w13, #16249, lsl #16
	fsub	s3, s25, s27
	fadd	s24, s20, s21
	fadd	s23, s16, s18
	fsub	s20, s20, s21
	fmov	s6, w13
	fmadd	s26, s2, s5, s4
	ldp	s30, s31, [x10, #8]
	mov	w10, #9756
	fmov	s18, w2
	movk	w10, #16200, lsl #16
	fmul	s8, s3, s6
	fmadd	s16, s24, s7, s26
	fmov	s26, w12
	fadd	s21, s29, s31
	fsub	s22, s28, s30
	fmov	s9, w10
	fsub	s19, s17, s19
	fadd	s25, s25, s27
	fmadd	s27, s23, s5, s1
	fmul	s11, s20, s6
	fadd	s12, s1, s23
	fmadd	s8, s0, s9, s8
	fmadd	s10, s21, s26, s16
	fadd	s16, s28, s30
	fadd	s28, s4, s2
	fsub	s17, s29, s31
	fmadd	s27, s25, s7, s27
	fmadd	s29, s19, s9, s11
	fadd	s31, s12, s25
	fmadd	s8, s22, s18, s8
	add	x10, x5, x16
	fadd	s28, s28, s24
	add	x13, x4, x16
	fmadd	s27, s16, s26, s27
	fmadd	s29, s17, s18, s29
	fadd	s31, s31, s16
	fadd	s30, s8, s10
	ldp	s12, s11, [x10]
	fadd	s28, s28, s21
	add	x10, x28, x16
	fsub	s13, s27, s29
	fadd	s27, s27, s29
	fneg	s9, s30
	fmul	s30, s12, s30
	stp	s31, s28, [x13, #8]
	fsub	s28, s10, s8
	fmadd	s31, s2, s7, s4
	fmul	s8, s3, s14
	fmul	s9, s11, s9
	fmul	s14, s20, s14
	fmadd	s30, s13, s11, s30
	fmadd	s2, s2, s26, s4
	ldp	s10, s11, [x10]
	fmadd	s31, s24, s26, s31
	fmadd	s8, s0, s6, s8
	fmadd	s29, s13, s12, s9
	fneg	s9, s28
	fmov	s12, w17
	fmadd	s13, s23, s7, s1
	fmul	s28, s28, s10
	add	x10, x29, x16
	fmadd	s31, s21, s5, s31
	add	x13, x26, x16
	fmul	s9, s11, s9
	fmadd	s8, s22, s12, s8
	stp	s29, s30, [x10, #8]
	fmadd	s29, s25, s26, s13
	fmul	s3, s3, s12
	add	x10, x30, x16
	fmadd	s2, s24, s5, s2
	fmadd	s1, s23, s26, s1
	fmadd	s30, s27, s10, s9
	fmadd	s9, s19, s6, s14
	fmadd	s27, s27, s11, s28
	fadd	s28, s8, s31
	fmadd	s29, s16, s5, s29
	fmadd	s0, s0, s18, s3
	ldp	s10, s11, [x13]
	fmadd	s4, s17, s12, s9
	fmul	s20, s20, s12
	fneg	s9, s28
	stp	s30, s27, [x10, #8]
	add	x10, x25, x16
	fsub	s23, s31, s8
	fmul	s27, s28, s10
	fmadd	s2, s21, s7, s2
	fsub	s24, s29, s4
	fadd	s3, s29, s4
	fmul	s4, s11, s9
	fmadd	s0, s22, s6, s0
	fmadd	s1, s25, s5, s1
	fmadd	s5, s19, s18, s20
	ldp	s19, s20, [x10]
	add	x10, x23, x16
	fmadd	s21, s24, s11, s27
	fmadd	s4, s24, s10, s4
	fadd	s18, s0, s2
	fneg	s22, s23
	fsub	s0, s2, s0
	add	x13, x27, x16
	fmadd	s1, s16, s7, s1
	fmadd	s5, s17, s6, s5
	fmul	s16, s23, s19
	ldp	s6, s7, [x10]
	add	x10, x22, x16
	fneg	s2, s18
	stp	s4, s21, [x13, #8]
	fmul	s4, s20, s22
	fneg	s21, s0
	fsub	s17, s1, s5
	ldp	s22, s23, [x10]
	fmul	s2, s7, s2
	fmul	s18, s18, s6
	fmadd	s4, s3, s19, s4
	fmadd	s3, s3, s20, s16
	fadd	s1, s1, s5
	add	x10, x24, x16
	fmul	s5, s23, s21
	fmul	s0, s0, s22
	fmadd	s2, s17, s6, s2
	fmadd	s6, s17, s7, s18
	stp	s4, s3, [x10, #8]
	add	x13, x21, x16
	add	x10, x15, x16
	add	x16, x16, #8
	fmadd	s3, s1, s22, s5
	fmadd	s0, s1, s23, s0
	stp	s2, s6, [x13, #8]
	stp	s3, s0, [x10, #8]
	b.ne	.LBB180_9
	b	.LBB180_6
.LBB180_10:
	ldp	x20, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #144]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #128]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #112]            // 16-byte Folded Reload
	ldr	d14, [sp, #96]                  // 8-byte Folded Reload
	add	sp, sp, #256
	ret
.Lfunc_end180:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end180-_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_,@function
_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_: // @_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #608
	.cfi_def_cfa_offset 768
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x2, x5, [sp, #360]              // 16-byte Folded Spill
	str	x4, [sp, #352]                  // 8-byte Folded Spill
	stp	x1, x3, [sp, #272]              // 16-byte Folded Spill
	b.ne	.LBB181_4
// %bb.1:
	ldr	x8, [sp, #360]                  // 8-byte Folded Reload
	cbz	x8, .LBB181_10
// %bb.2:
	mov	w17, #45383
	mov	w16, #23652
	movk	w17, #16084, lsl #16
	mov	w18, #47867
	movk	w16, #16215, lsl #16
	movk	w18, #15889, lsl #16
	ldp	x2, x1, [sp, #352]              // 16-byte Folded Reload
	dup	v1.2s, w17
	mov	w17, #41301
	movk	w17, #16245, lsl #16
	dup	v0.2s, w16
	mov	w16, #42228
	dup	v2.2s, w18
	mov	w18, #56740
	movk	w16, #16167, lsl #16
	dup	v4.2s, w17
	mov	w17, #25840
	movk	w18, #16232, lsl #16
	movk	w17, #16253, lsl #16
	dup	v3.2s, w16
	mov	w16, #26480
	movk	w16, #16138, lsl #16
	mov	w0, #56740
	dup	v5.2s, w18
	mov	w18, #30926
	dup	v7.2s, w17
	mov	w17, #16192
	movk	w18, #16193, lsl #16
	movk	w17, #48784, lsl #16
	dup	v6.2s, w16
	mov	w16, #16192
	str	d5, [sp, #600]                  // 8-byte Folded Spill
	movk	w16, #16016, lsl #16
	dup	v16.2s, w18
	mov	w18, #25840
	dup	v5.2s, w17
	movk	w18, #49021, lsl #16
	dup	v17.2s, w16
	mov	w16, #26480
	movk	w16, #48906, lsl #16
	movk	w0, #49000, lsl #16
	mov	w9, #48
	mov	w10, #40
	str	d5, [sp, #592]                  // 8-byte Folded Spill
	dup	v5.2s, w18
	mov	w11, #56
	mov	w14, #24
	mov	w15, #72
	mov	w17, #80
	ldr	x18, [sp, #280]                 // 8-byte Folded Reload
	madd	x9, x1, x9, x2
	madd	x10, x1, x10, x2
	str	d5, [sp, #584]                  // 8-byte Folded Spill
	madd	x11, x1, x11, x2
	dup	v5.2s, w16
	madd	x14, x1, x14, x2
	dup	v21.2s, w0
	madd	x15, x1, x15, x2
	mov	x8, xzr
	madd	x17, x1, x17, x2
	add	x12, x2, x1, lsl #5
	add	x13, x2, x1, lsl #6
	add	x16, x2, x1, lsl #4
	add	x18, x18, #40
	add	x0, x2, x1, lsl #3
	str	d5, [sp, #576]                  // 8-byte Folded Spill
.LBB181_3:                              // =>This Inner Loop Header: Depth=1
	ldp	d27, d26, [x18, #32]
	lsl	x1, x8, #3
	add	x8, x8, #1
	ldp	d25, d28, [x18, #-32]
	ldp	d10, d31, [x18, #16]
	fadd	v24.2s, v25.2s, v26.2s
	fsub	v26.2s, v25.2s, v26.2s
	ldp	d29, d30, [x18, #-16]
	fsub	v22.2s, v28.2s, v27.2s
	fadd	v25.2s, v28.2s, v27.2s
	ldur	d23, [x18, #-40]
	fmul	v27.2s, v24.2s, v0.2s
	ldr	d20, [sp, #600]                 // 8-byte Folded Reload
	ldp	d11, d13, [x18]
	fadd	v8.2s, v29.2s, v31.2s
	fsub	v12.2s, v29.2s, v31.2s
	fmul	v28.2s, v22.2s, v20.2s
	rev64	v31.2s, v26.2s
	fmul	v26.2s, v25.2s, v1.2s
	fadd	v27.2s, v23.2s, v27.2s
	fadd	v29.2s, v30.2s, v10.2s
	fsub	v10.2s, v30.2s, v10.2s
	fsub	v14.2s, v11.2s, v13.2s
	fadd	v30.2s, v11.2s, v13.2s
	rev64	v9.2s, v28.2s
	rev64	v28.2s, v12.2s
	fmul	v12.2s, v8.2s, v2.2s
	fadd	v15.2s, v27.2s, v26.2s
	fmul	v13.2s, v29.2s, v3.2s
	rev64	v27.2s, v10.2s
	rev64	v26.2s, v14.2s
	fmul	v11.2s, v30.2s, v4.2s
	fmla	v9.2s, v6.2s, v31.2s
	fmul	v5.2s, v22.2s, v16.2s
	fsub	v14.2s, v15.2s, v12.2s
	fmul	v15.2s, v24.2s, v1.2s
	fmul	v12.2s, v25.2s, v3.2s
	fmul	v19.2s, v24.2s, v3.2s
	fmul	v18.2s, v24.2s, v2.2s
	fadd	v10.2s, v23.2s, v24.2s
	fmla	v9.2s, v7.2s, v28.2s
	rev64	v5.2s, v5.2s
	fsub	v13.2s, v14.2s, v13.2s
	fadd	v15.2s, v23.2s, v15.2s
	fsub	v19.2s, v23.2s, v19.2s
	fmul	v14.2s, v25.2s, v4.2s
	fsub	v18.2s, v23.2s, v18.2s
	fadd	v10.2s, v10.2s, v25.2s
	fmla	v9.2s, v16.2s, v27.2s
	fmla	v5.2s, v20.2s, v31.2s
	fsub	v11.2s, v13.2s, v11.2s
	fmul	v13.2s, v8.2s, v4.2s
	fsub	v12.2s, v15.2s, v12.2s
	fmul	v15.2s, v25.2s, v2.2s
	fmul	v20.2s, v29.2s, v2.2s
	fsub	v18.2s, v18.2s, v14.2s
	fmla	v9.2s, v17.2s, v26.2s
	fadd	v10.2s, v10.2s, v8.2s
	fmul	v24.2s, v24.2s, v4.2s
	ldr	x2, [sp, #352]                  // 8-byte Folded Reload
	fsub	v12.2s, v12.2s, v13.2s
	fsub	v19.2s, v19.2s, v15.2s
	ldr	d15, [sp, #592]                 // 8-byte Folded Reload
	fmul	v13.2s, v8.2s, v1.2s
	fsub	v14.2s, v11.2s, v9.2s
	fadd	v9.2s, v11.2s, v9.2s
	fadd	v10.2s, v10.2s, v29.2s
	fsub	v23.2s, v23.2s, v24.2s
	fmla	v5.2s, v15.2s, v28.2s
	fmul	v15.2s, v22.2s, v15.2s
	fsub	v20.2s, v12.2s, v20.2s
	fmul	v12.2s, v30.2s, v0.2s
	mov	v11.16b, v14.16b
	fadd	v18.2s, v18.2s, v13.2s
	ldr	d13, [sp, #584]                 // 8-byte Folded Reload
	fadd	v10.2s, v10.2s, v30.2s
	rev64	v15.2s, v15.2s
	fmul	v25.2s, v25.2s, v0.2s
	fadd	v20.2s, v20.2s, v12.2s
	ldr	d12, [sp, #576]                 // 8-byte Folded Reload
	fmla	v5.2s, v13.2s, v27.2s
	fmul	v13.2s, v22.2s, v13.2s
	mov	v11.s[1], v9.s[1]
	str	d10, [x2, x1]
	fmul	v22.2s, v22.2s, v12.2s
	fmla	v15.2s, v7.2s, v31.2s
	fmul	v10.2s, v29.2s, v0.2s
	fmul	v24.2s, v8.2s, v0.2s
	str	d11, [x0, x1]
	rev64	v11.2s, v13.2s
	fadd	v23.2s, v23.2s, v25.2s
	fmul	v8.2s, v8.2s, v3.2s
	rev64	v22.2s, v22.2s
	fmla	v15.2s, v21.2s, v28.2s
	fmla	v5.2s, v12.2s, v26.2s
	fadd	v18.2s, v18.2s, v10.2s
	fmla	v11.2s, v16.2s, v31.2s
	fmul	v10.2s, v30.2s, v3.2s
	fadd	v19.2s, v19.2s, v24.2s
	fmul	v24.2s, v29.2s, v4.2s
	fmla	v22.2s, v17.2s, v31.2s
	fmla	v15.2s, v6.2s, v27.2s
	fsub	v23.2s, v23.2s, v8.2s
	fmul	v29.2s, v29.2s, v1.2s
	fmla	v11.2s, v6.2s, v28.2s
	fsub	v25.2s, v20.2s, v5.2s
	fsub	v18.2s, v18.2s, v10.2s
	fsub	v19.2s, v19.2s, v24.2s
	fmla	v22.2s, v16.2s, v28.2s
	fmul	v24.2s, v30.2s, v1.2s
	fmla	v15.2s, v16.2s, v26.2s
	fadd	v23.2s, v23.2s, v29.2s
	fmla	v11.2s, v17.2s, v27.2s
	fmul	v28.2s, v30.2s, v2.2s
	fadd	v5.2s, v20.2s, v5.2s
	ldr	x2, [sp, #360]                  // 8-byte Folded Reload
	fmla	v22.2s, v21.2s, v27.2s
	fadd	v19.2s, v19.2s, v24.2s
	mov	v20.16b, v25.16b
	fsub	v24.2s, v18.2s, v15.2s
	fmla	v11.2s, v21.2s, v26.2s
	fsub	v23.2s, v23.2s, v28.2s
	fadd	v18.2s, v18.2s, v15.2s
	add	x18, x18, #88
	fmla	v22.2s, v7.2s, v26.2s
	cmp	x2, x8
	mov	v20.s[1], v5.s[1]
	mov	v5.s[1], v25.s[1]
	mov	v25.16b, v24.16b
	fsub	v27.2s, v19.2s, v11.2s
	str	d20, [x16, x1]
	str	d5, [x15, x1]
	fsub	v5.2s, v23.2s, v22.2s
	fadd	v19.2s, v19.2s, v11.2s
	fadd	v22.2s, v23.2s, v22.2s
	mov	v25.s[1], v18.s[1]
	mov	v18.s[1], v24.s[1]
	mov	v20.16b, v27.16b
	mov	v9.s[1], v14.s[1]
	str	d25, [x14, x1]
	str	d18, [x13, x1]
	mov	v18.16b, v5.16b
	mov	v20.s[1], v19.s[1]
	str	d9, [x17, x1]
	mov	v19.s[1], v27.s[1]
	mov	v18.s[1], v22.s[1]
	str	d20, [x12, x1]
	mov	v22.s[1], v5.s[1]
	str	d19, [x11, x1]
	str	d18, [x10, x1]
	str	d22, [x9, x1]
	b.ne	.LBB181_3
	b	.LBB181_10
.LBB181_4:
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldr	x8, [sp, #360]                  // 8-byte Folded Reload
	cbz	x8, .LBB181_10
// %bb.5:
	ldp	x4, x2, [sp, #352]              // 16-byte Folded Reload
	mov	w11, #48
	mov	w8, #88
	ldp	x1, x25, [sp, #272]             // 16-byte Folded Reload
	mov	w10, #80
	mov	w13, #56
	ldr	x26, [sp, #8]                   // 8-byte Folded Reload
	mov	w23, #40
	mov	x28, xzr
	mul	x12, x2, x1
	mul	x8, x1, x8
	add	x0, x26, x26, lsl #1
	madd	x18, x1, x10, x25
	lsl	x19, x26, #5
	madd	x9, x12, x11, x4
	lsl	x11, x26, #4
	add	x15, x11, x25
	add	x17, x19, x25
	str	x8, [sp, #264]                  // 8-byte Folded Spill
	lsl	x8, x26, #3
	add	x14, x8, x26
	add	x6, x26, x26, lsl #2
	str	x9, [sp, #416]                  // 8-byte Folded Spill
	add	x9, x15, #16
	lsl	x3, x14, #3
	lsl	x21, x6, #3
	add	x15, x3, x25
	lsl	x22, x0, #4
	stp	x9, x18, [sp, #336]             // 16-byte Folded Spill
	lsl	x9, x0, #3
	add	x16, x9, x25
	add	x18, x15, #72
	add	x14, x16, #24
	ldr	x16, [sp, #368]                 // 8-byte Folded Reload
	mul	x20, x26, x13
	add	x24, x8, #8
	add	x6, x21, x25
	add	x7, x22, x25
	stp	x14, x18, [sp, #320]            // 16-byte Folded Spill
	add	x14, x17, #32
	add	x9, x16, x9
	add	x8, x16, x8
	add	x0, x6, #40
	add	x18, x20, x25
	str	x14, [sp, #312]                 // 8-byte Folded Spill
	add	x14, x16, x21
	str	x8, [sp, #200]                  // 8-byte Folded Spill
	add	x8, x16, x3
	madd	x3, x12, x10, x4
	mov	w10, #23652
	stp	x14, x24, [sp, #248]            // 16-byte Folded Spill
	add	x14, x16, x19
	movk	w10, #16215, lsl #16
	add	x15, x18, #56
	madd	x17, x12, x23, x4
	add	x18, x4, x12, lsl #5
	str	x14, [sp, #240]                 // 8-byte Folded Spill
	madd	x14, x12, x13, x4
	add	x13, x16, x22
	add	x21, x4, x12, lsl #6
	str	x8, [sp, #192]                  // 8-byte Folded Spill
	add	x8, x4, x12, lsl #3
	dup	v1.2s, w10
	mov	w10, #42228
	stp	x9, x13, [sp, #224]             // 16-byte Folded Spill
	add	x9, x16, x20
	add	x13, x4, x12, lsl #4
	movk	w10, #16167, lsl #16
	add	x5, x7, #48
	str	x9, [sp, #216]                  // 8-byte Folded Spill
	add	x9, x16, x11
	mov	w11, #45383
	add	x27, x25, x1, lsl #3
	movk	w11, #16084, lsl #16
	mov	x20, x25
	str	x9, [sp, #208]                  // 8-byte Folded Spill
	mov	w9, #24
	ldr	x7, [sp, #192]                  // 8-byte Folded Reload
	madd	x6, x12, x9, x4
	mov	w9, #72
	dup	v0.2s, w11
	mov	w11, #41301
	madd	x9, x12, x9, x4
	mov	w12, #47867
	movk	w12, #15889, lsl #16
	movk	w11, #16245, lsl #16
	stp	d0, d1, [sp, #176]              // 16-byte Folded Spill
	dup	v0.2s, w10
	dup	v1.2s, w12
	mov	w12, #56740
	movk	w12, #16232, lsl #16
	mov	w10, #26480
	movk	w10, #16138, lsl #16
	stp	d0, d1, [sp, #160]              // 16-byte Folded Spill
	dup	v1.2s, w11
	mov	w11, #25840
	dup	v0.2s, w12
	mov	w12, #30926
	movk	w11, #16253, lsl #16
	movk	w12, #16193, lsl #16
	stp	d0, d1, [sp, #144]              // 16-byte Folded Spill
	dup	v1.2s, w10
	mov	w10, #16192
	dup	v2.2s, w11
	mov	w11, #16192
	dup	v0.2s, w12
	movk	w10, #16016, lsl #16
	movk	w11, #48784, lsl #16
	mov	w12, #25840
	movk	w12, #49021, lsl #16
	stp	d0, d1, [sp, #128]              // 16-byte Folded Spill
	dup	v1.2s, w10
	dup	v0.2s, w11
	mov	w10, #26480
	movk	w10, #48906, lsl #16
	mov	w11, #56740
	movk	w11, #49000, lsl #16
	stp	d0, d1, [sp, #112]              // 16-byte Folded Spill
	dup	v0.2s, w12
	lsl	x12, x2, #2
	str	d0, [sp, #104]                  // 8-byte Folded Spill
	dup	v0.2s, w10
	add	x10, x12, x2
	stp	x10, x12, [sp, #88]             // 16-byte Folded Spill
	lsl	x10, x10, #1
	stp	d0, d2, [sp, #296]              // 16-byte Folded Spill
	dup	v0.2s, w11
	lsl	x11, x2, #3
	str	x10, [sp, #72]                  // 8-byte Folded Spill
	lsl	x10, x2, #1
	add	x12, x11, x2
	str	d0, [sp, #80]                   // 8-byte Folded Spill
	str	x10, [sp, #64]                  // 8-byte Folded Spill
	add	x10, x10, x2
	stp	x12, x11, [sp, #48]             // 16-byte Folded Spill
	sub	x11, x11, x2
	add	x12, x25, x24, lsl #3
	ldp	x29, x24, [sp, #232]            // 16-byte Folded Reload
	stp	x11, x10, [sp, #32]             // 16-byte Folded Spill
	lsl	x11, x10, #1
	add	x10, x16, x26, lsl #6
	mov	x16, x4
	stp	x10, x11, [sp, #16]             // 16-byte Folded Spill
	b	.LBB181_7
.LBB181_6:                              //   in Loop: Header=BB181_7 Depth=1
	ldp	x11, x9, [sp, #256]             // 16-byte Folded Reload
	ldr	x8, [sp, #416]                  // 8-byte Folded Reload
	ldp	x14, x13, [sp, #384]            // 16-byte Folded Reload
	add	x2, x2, x11
	add	x30, x30, x11
	add	x18, x18, x9
	add	x25, x25, x9
	add	x8, x8, x11
	add	x15, x15, x9
	add	x17, x17, x9
	ldr	x10, [sp, #400]                 // 8-byte Folded Reload
	ldr	x19, [sp, #288]                 // 8-byte Folded Reload
	stp	x25, x18, [sp, #320]            // 16-byte Folded Spill
	ldr	x18, [sp, #376]                 // 8-byte Folded Reload
	str	x8, [sp, #416]                  // 8-byte Folded Spill
	add	x20, x20, x9
	add	x27, x27, x9
	stp	x17, x15, [sp, #336]            // 16-byte Folded Spill
	add	x12, x12, x9
	add	x26, x26, x9
	add	x15, x0, x9
	add	x0, x14, x9
	add	x5, x10, x9
	ldr	x9, [sp, #408]                  // 8-byte Folded Reload
	add	x19, x19, #1
	ldr	x8, [sp, #360]                  // 8-byte Folded Reload
	add	x18, x18, x11
	add	x16, x16, x11
	add	x17, x13, x11
	add	x21, x21, x11
	add	x6, x6, x11
	add	x3, x3, x11
	add	x13, x4, x11
	add	x9, x9, x11
	mov	x28, x19
	cmp	x19, x8
	mov	x14, x18
	mov	x18, x2
	mov	x8, x30
	str	x26, [sp, #312]                 // 8-byte Folded Spill
	b.eq	.LBB181_10
.LBB181_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB181_9 Depth 2
	mov	w10, #11
	ldr	x1, [sp, #272]                  // 8-byte Folded Reload
	stp	x17, x5, [sp, #392]             // 16-byte Folded Spill
	mov	x17, x28
	mul	x22, x28, x10
	str	x9, [sp, #408]                  // 8-byte Folded Spill
	stp	x14, x0, [sp, #376]             // 16-byte Folded Spill
	mov	x0, x15
	add	x23, x22, #10
	add	x25, x22, #2
	mul	x28, x22, x1
	add	x26, x22, #9
	add	x9, x22, #8
	mul	x23, x23, x1
	add	x19, x1, x28
	mul	x25, x25, x1
	mul	x26, x26, x1
	ldr	x15, [sp, #280]                 // 8-byte Folded Reload
	mul	x9, x9, x1
	add	x30, x22, #3
	add	x11, x22, #4
	ldr	d0, [x15, x19, lsl #3]
	add	x19, x22, #7
	mul	x30, x30, x1
	ldr	d1, [x15, x23, lsl #3]
	mul	x11, x11, x1
	ldr	d2, [x15, x25, lsl #3]
	mov	x4, x13
	ldr	d16, [x15, x9, lsl #3]
	mul	x9, x19, x1
	ldr	d6, [x15, x26, lsl #3]
	mov	x2, x18
	ldp	d31, d30, [sp, #176]            // 16-byte Folded Reload
	fsub	v18.2s, v0.2s, v1.2s
	fadd	v7.2s, v0.2s, v1.2s
	ldp	d11, d27, [sp, #136]            // 16-byte Folded Reload
	fadd	v5.2s, v2.2s, v6.2s
	fsub	v6.2s, v2.2s, v6.2s
	ldr	d3, [x15, x30, lsl #3]
	str	x17, [sp, #288]                 // 8-byte Folded Spill
	ldr	d17, [x15, x11, lsl #3]
	add	x11, x22, #5
	ldr	d19, [x15, x9, lsl #3]
	mov	x30, x8
	mul	x9, x11, x1
	add	x11, x22, #6
	fsub	v20.2s, v3.2s, v16.2s
	ldr	d4, [x15, x28, lsl #3]
	fadd	v2.2s, v3.2s, v16.2s
	rev64	v3.2s, v18.2s
	fadd	v1.2s, v17.2s, v19.2s
	fmul	v16.2s, v7.2s, v30.2s
	fmul	v18.2s, v6.2s, v27.2s
	fsub	v17.2s, v17.2s, v19.2s
	fmul	v19.2s, v7.2s, v31.2s
	mul	x11, x11, x1
	ldp	d9, d8, [sp, #160]              // 16-byte Folded Reload
	fadd	v16.2s, v4.2s, v16.2s
	fmul	v21.2s, v5.2s, v31.2s
	ldr	d13, [sp, #128]                 // 8-byte Folded Reload
	rev64	v23.2s, v18.2s
	ldr	d22, [x15, x9, lsl #3]
	fadd	v18.2s, v4.2s, v19.2s
	fmul	v19.2s, v5.2s, v9.2s
	ldr	d24, [x15, x11, lsl #3]
	rev64	v12.2s, v20.2s
	fmul	v20.2s, v6.2s, v13.2s
	ldr	d10, [sp, #152]                 // 8-byte Folded Reload
	fadd	v21.2s, v16.2s, v21.2s
	rev64	v16.2s, v17.2s
	fmul	v25.2s, v2.2s, v8.2s
	fsub	v17.2s, v18.2s, v19.2s
	fsub	v26.2s, v22.2s, v24.2s
	fmul	v19.2s, v2.2s, v10.2s
	rev64	v20.2s, v20.2s
	fmla	v23.2s, v11.2s, v3.2s
	ldr	d0, [sp, #304]                  // 8-byte Folded Reload
	fsub	v21.2s, v21.2s, v25.2s
	fmul	v25.2s, v1.2s, v9.2s
	fadd	v18.2s, v22.2s, v24.2s
	fmul	v22.2s, v1.2s, v8.2s
	fsub	v19.2s, v17.2s, v19.2s
	rev64	v17.2s, v26.2s
	ldp	d15, d26, [sp, #104]            // 16-byte Folded Reload
	fmla	v20.2s, v27.2s, v3.2s
	fmla	v23.2s, v0.2s, v12.2s
	fadd	v24.2s, v4.2s, v7.2s
	fsub	v21.2s, v21.2s, v25.2s
	fmul	v25.2s, v18.2s, v10.2s
	fsub	v19.2s, v19.2s, v22.2s
	fmul	v22.2s, v18.2s, v30.2s
	ldr	d14, [sp, #120]                 // 8-byte Folded Reload
	fmla	v20.2s, v26.2s, v12.2s
	fmla	v23.2s, v13.2s, v16.2s
	fadd	v24.2s, v24.2s, v5.2s
	fmul	v26.2s, v6.2s, v26.2s
	fsub	v21.2s, v21.2s, v25.2s
	fmul	v25.2s, v7.2s, v8.2s
	fadd	v19.2s, v19.2s, v22.2s
	ldr	d22, [sp, #296]                 // 8-byte Folded Reload
	fmla	v20.2s, v15.2s, v16.2s
	fmla	v23.2s, v14.2s, v17.2s
	ldp	x13, x10, [sp, #352]            // 16-byte Folded Reload
	fsub	v25.2s, v4.2s, v25.2s
	fmul	v27.2s, v5.2s, v10.2s
	mul	x9, x17, x1
	cmp	x1, #2
	fmla	v20.2s, v22.2s, v17.2s
	fadd	v22.2s, v24.2s, v2.2s
	fsub	v24.2s, v21.2s, v23.2s
	ldr	x26, [sp, #312]                 // 8-byte Folded Reload
	add	x11, x17, x10
	fsub	v25.2s, v25.2s, v27.2s
	fmul	v27.2s, v7.2s, v9.2s
	fmul	v7.2s, v7.2s, v10.2s
	fadd	v29.2s, v22.2s, v1.2s
	fadd	v22.2s, v21.2s, v23.2s
	mov	v23.16b, v24.16b
	rev64	v21.2s, v26.2s
	fmul	v26.2s, v2.2s, v31.2s
	ldr	x10, [sp, #72]                  // 8-byte Folded Reload
	fsub	v28.2s, v19.2s, v20.2s
	fadd	v19.2s, v19.2s, v20.2s
	ldp	x25, x18, [sp, #320]            // 16-byte Folded Reload
	mov	v23.s[1], v22.s[1]
	fmla	v21.2s, v0.2s, v3.2s
	mov	v22.s[1], v24.s[1]
	ldr	d0, [sp, #296]                  // 8-byte Folded Reload
	fadd	v24.2s, v29.2s, v18.2s
	ldr	d29, [sp, #80]                  // 8-byte Folded Reload
	fadd	v25.2s, v25.2s, v26.2s
	fmul	v26.2s, v1.2s, v30.2s
	mov	v20.16b, v28.16b
	ldr	x28, [sp, #248]                 // 8-byte Folded Reload
	str	d24, [x13, x9, lsl #3]
	mul	x9, x11, x1
	fmla	v21.2s, v29.2s, v12.2s
	add	x11, x17, x10
	fadd	v24.2s, v25.2s, v26.2s
	fmul	v25.2s, v18.2s, v9.2s
	fsub	v26.2s, v4.2s, v27.2s
	fmul	v27.2s, v5.2s, v8.2s
	str	d23, [x13, x9, lsl #3]
	fmul	v23.2s, v6.2s, v15.2s
	fmul	v6.2s, v6.2s, v0.2s
	fsub	v4.2s, v4.2s, v7.2s
	fmul	v5.2s, v5.2s, v30.2s
	fmla	v21.2s, v11.2s, v16.2s
	fsub	v24.2s, v24.2s, v25.2s
	mul	x9, x11, x1
	rev64	v23.2s, v23.2s
	fsub	v25.2s, v26.2s, v27.2s
	fmul	v26.2s, v2.2s, v30.2s
	rev64	v6.2s, v6.2s
	fadd	v4.2s, v4.2s, v5.2s
	fmul	v2.2s, v2.2s, v9.2s
	fmla	v21.2s, v13.2s, v17.2s
	str	d22, [x13, x9, lsl #3]
	fmla	v23.2s, v13.2s, v3.2s
	ldr	x10, [sp, #48]                  // 8-byte Folded Reload
	fadd	v22.2s, v25.2s, v26.2s
	fmla	v6.2s, v14.2s, v3.2s
	fmul	v3.2s, v1.2s, v10.2s
	fsub	v2.2s, v4.2s, v2.2s
	fmul	v1.2s, v1.2s, v31.2s
	ldr	x9, [sp, #64]                   // 8-byte Folded Reload
	fmla	v23.2s, v11.2s, v12.2s
	add	x11, x17, x10
	ldr	x10, [sp, #40]                  // 8-byte Folded Reload
	fsub	v7.2s, v24.2s, v21.2s
	fsub	v3.2s, v22.2s, v3.2s
	fmul	v4.2s, v18.2s, v31.2s
	fmla	v6.2s, v13.2s, v12.2s
	fadd	v1.2s, v2.2s, v1.2s
	fmla	v23.2s, v14.2s, v16.2s
	fmul	v2.2s, v18.2s, v8.2s
	add	x9, x17, x9
	add	x19, x17, x10
	ldr	x10, [sp, #56]                  // 8-byte Folded Reload
	fadd	v21.2s, v24.2s, v21.2s
	mul	x9, x9, x1
	fadd	v0.2s, v3.2s, v4.2s
	mul	x11, x11, x1
	fmla	v23.2s, v29.2s, v17.2s
	mov	v5.16b, v7.16b
	fmla	v6.2s, v29.2s, v16.2s
	mov	v20.s[1], v19.s[1]
	add	x22, x17, x10
	mov	v19.s[1], v28.s[1]
	ldr	x10, [sp, #96]                  // 8-byte Folded Reload
	fsub	v1.2s, v1.2s, v2.2s
	ldr	d2, [sp, #304]                  // 8-byte Folded Reload
	mul	x19, x19, x1
	str	d20, [x13, x9, lsl #3]
	mov	v5.s[1], v21.s[1]
	str	d19, [x13, x11, lsl #3]
	fsub	v3.2s, v0.2s, v23.2s
	fmla	v6.2s, v2.2s, v17.2s
	add	x11, x17, x10
	ldr	x10, [sp, #32]                  // 8-byte Folded Reload
	mul	x9, x22, x1
	str	d5, [x13, x19, lsl #3]
	mov	v21.s[1], v7.s[1]
	fadd	v0.2s, v0.2s, v23.2s
	add	x19, x17, x10
	ldr	x10, [sp, #88]                  // 8-byte Folded Reload
	mov	v2.16b, v3.16b
	fsub	v4.2s, v1.2s, v6.2s
	str	d21, [x13, x9, lsl #3]
	mul	x9, x19, x1
	add	x19, x17, x10
	ldp	x5, x10, [sp, #16]              // 16-byte Folded Reload
	mul	x11, x11, x1
	fadd	v1.2s, v1.2s, v6.2s
	mov	v2.s[1], v0.s[1]
	mov	v5.16b, v4.16b
	add	x22, x17, x10
	mov	v0.s[1], v3.s[1]
	str	d2, [x13, x11, lsl #3]
	mul	x11, x19, x1
	mul	x19, x22, x1
	mov	w1, #56740
	mov	v5.s[1], v1.s[1]
	str	d0, [x13, x9, lsl #3]
	mov	v1.s[1], v4.s[1]
	movk	w1, #49000, lsl #16
	ldp	x17, x15, [sp, #336]            // 16-byte Folded Reload
	str	d5, [x13, x11, lsl #3]
	str	d1, [x13, x19, lsl #3]
	ldp	x14, x8, [sp, #216]             // 16-byte Folded Reload
	ldp	x10, x13, [sp, #200]            // 16-byte Folded Reload
	b.lo	.LBB181_6
// %bb.8:                               //   in Loop: Header=BB181_7 Depth=1
	mov	x22, xzr
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
.LBB181_9:                              //   Parent Loop BB181_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x9, x27, x22
	add	x11, x15, x22
	add	x19, x20, x22
	subs	x23, x23, #1
	ldp	s0, s1, [x9, #8]
	ldp	s2, s3, [x11, #8]
	add	x9, x17, x22
	add	x11, x18, x22
	ldp	s28, s16, [x19, #8]
	add	x19, x29, x22
	fadd	s22, s0, s2
	fsub	s23, s0, s2
	ldp	s4, s5, [x9, #8]
	ldp	s0, s2, [x11, #8]
	add	x11, x12, x22
	add	x9, x25, x22
	fadd	s18, s1, s3
	fsub	s15, s1, s3
	str	s16, [sp, #592]                 // 4-byte Folded Spill
	fmov	s13, s22
	fadd	s7, s4, s0
	fsub	s17, s4, s0
	ldp	s6, s0, [x11, #8]
	mov	w11, #23652
	fadd	s21, s5, s2
	movk	w11, #16215, lsl #16
	fsub	s31, s5, s2
	ldp	s1, s3, [x9, #8]
	add	x9, x26, x22
	str	s18, [sp, #600]                 // 4-byte Folded Spill
	fmov	s4, w11
	add	x11, x0, x22
	str	s17, [sp, #572]                 // 4-byte Folded Spill
	fadd	s25, s1, s6
	fadd	s5, s3, s0
	fmul	s2, s18, s4
	fmov	s24, s4
	str	s4, [sp, #548]                  // 4-byte Folded Spill
	fsub	s18, s1, s6
	ldp	s4, s20, [x9, #8]
	mov	w9, #45383
	fsub	s30, s3, s0
	movk	w9, #16084, lsl #16
	fadd	s2, s16, s2
	ldp	s1, s19, [x11, #8]
	mov	w11, #26480
	fmul	s6, s22, s24
	fmov	s10, w9
	mov	w9, #56740
	movk	w9, #16232, lsl #16
	movk	w11, #16138, lsl #16
	fadd	s29, s4, s1
	fsub	s11, s4, s1
	fmul	s3, s21, s10
	fadd	s26, s20, s19
	fmov	s16, w9
	mov	w9, #47867
	movk	w9, #15889, lsl #16
	fmov	s0, w11
	mov	w11, #42228
	str	s5, [sp, #576]                  // 4-byte Folded Spill
	movk	w11, #16167, lsl #16
	fadd	s1, s2, s3
	fmov	s8, w9
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	fmul	s2, s17, s16
	fmov	s24, s0
	fmov	s12, w11
	mov	w11, #25840
	add	x9, x9, x22
	movk	w11, #16253, lsl #16
	str	s0, [sp, #472]                  // 4-byte Folded Spill
	fmul	s3, s5, s8
	fmadd	s2, s23, s0, s2
	str	s26, [sp, #568]                 // 4-byte Folded Spill
	ldp	s17, s22, [x9, #8]
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	fmov	s0, w11
	fmul	s5, s26, s12
	str	s21, [sp, #584]                 // 4-byte Folded Spill
	str	s18, [sp, #512]                 // 4-byte Folded Spill
	fsub	s21, s1, s3
	add	x9, x9, x22
	fmadd	s2, s18, s0, s2
	fmov	s26, s0
	str	s0, [sp, #556]                  // 4-byte Folded Spill
	fadd	s1, s28, s6
	fmul	s3, s7, s10
	ldp	s0, s27, [x9, #8]
	mov	w9, #30926
	fmul	s6, s31, s16
	movk	w9, #16193, lsl #16
	str	s7, [sp, #564]                  // 4-byte Folded Spill
	fadd	s4, s1, s3
	fsub	s7, s21, s5
	fadd	s18, s22, s27
	fmul	s1, s25, s8
	fmov	s14, w9
	mov	w9, #41301
	movk	w9, #16245, lsl #16
	fmov	s21, s25
	str	s25, [sp, #496]                 // 4-byte Folded Spill
	fsub	s25, s17, s0
	fmadd	s5, s11, s14, s2
	fmadd	s3, s15, s24, s6
	fmov	s9, w9
	mov	w9, #16192
	movk	w9, #16016, lsl #16
	str	s18, [sp, #484]                 // 4-byte Folded Spill
	str	s23, [sp, #504]                 // 4-byte Folded Spill
	fmov	s23, s28
	fmul	s2, s18, s9
	str	s31, [sp, #508]                 // 4-byte Folded Spill
	fmov	s18, w9
	fmov	s31, s15
	str	s15, [sp, #560]                 // 4-byte Folded Spill
	fadd	s6, s17, s0
	fsub	s0, s4, s1
	fmul	s1, s29, s12
	fmov	s15, s29
	str	s29, [sp, #492]                 // 4-byte Folded Spill
	fsub	s28, s7, s2
	fmadd	s29, s25, s18, s5
	fsub	s4, s20, s19
	fmadd	s3, s30, s26, s3
	ldr	x9, [sp, #368]                  // 8-byte Folded Reload
	fsub	s0, s0, s1
	fmul	s1, s6, s9
	fsub	s2, s22, s27
	fadd	s7, s29, s28
	str	s25, [sp, #520]                 // 4-byte Folded Spill
	fmadd	s3, s4, s14, s3
	add	x9, x9, x22
	fmov	s25, s30
	str	s30, [sp, #552]                 // 4-byte Folded Spill
	fsub	s17, s0, s1
	fmov	s5, s13
	fneg	s1, s7
	str	s13, [sp, #424]                 // 4-byte Folded Spill
	fmadd	s30, s2, s18, s3
	fmul	s27, s13, s10
	ldp	s20, s19, [x9]
	ldr	s13, [sp, #600]                 // 4-byte Folded Reload
	str	s6, [sp, #516]                  // 4-byte Folded Spill
	ldr	s24, [sp, #564]                 // 4-byte Folded Reload
	str	s11, [sp, #500]                 // 4-byte Folded Spill
	ldr	s26, [sp, #592]                 // 4-byte Folded Reload
	str	s4, [sp, #532]                  // 4-byte Folded Spill
	fmul	s6, s19, s1
	fmul	s7, s20, s7
	fsub	s1, s17, s30
	fmul	s0, s13, s10
	ldr	s11, [sp, #584]                 // 4-byte Folded Reload
	fadd	s27, s23, s27
	fmul	s4, s24, s12
	str	s2, [sp, #544]                  // 4-byte Folded Spill
	str	s18, [sp, #480]                 // 4-byte Folded Spill
	ldr	s18, [sp, #576]                 // 4-byte Folded Reload
	fmadd	s6, s1, s20, s6
	fmadd	s1, s1, s19, s7
	fadd	s3, s26, s0
	fmul	s2, s11, s12
	ldr	s0, [sp, #572]                  // 4-byte Folded Reload
	mov	w9, #16192
	movk	w9, #48784, lsl #16
	fmov	s22, s23
	str	s1, [sp, #476]                  // 4-byte Folded Spill
	fsub	s1, s27, s4
	fmul	s4, s21, s9
	ldr	s21, [sp, #508]                 // 4-byte Folded Reload
	fmul	s0, s0, s14
	str	s23, [sp, #488]                 // 4-byte Folded Spill
	fsub	s2, s3, s2
	fmul	s3, s18, s9
	ldr	s23, [sp, #504]                 // 4-byte Folded Reload
	str	s10, [sp, #524]                 // 4-byte Folded Spill
	fmul	s7, s21, s14
	ldr	s10, [sp, #568]                 // 4-byte Folded Reload
	str	s6, [sp, #468]                  // 4-byte Folded Spill
	fmov	s6, w9
	mov	w9, #25840
	fmadd	s0, s23, s16, s0
	movk	w9, #49021, lsl #16
	str	s14, [sp, #536]                 // 4-byte Folded Spill
	fadd	s14, s17, s30
	fsub	s17, s28, s29
	fsub	s2, s2, s3
	fmul	s3, s10, s8
	ldr	s29, [sp, #512]                 // 4-byte Folded Reload
	str	s12, [sp, #540]                 // 4-byte Folded Spill
	fmadd	s7, s31, s16, s7
	ldr	s30, [sp, #548]                 // 4-byte Folded Reload
	ldr	s12, [sp, #484]                 // 4-byte Folded Reload
	fsub	s4, s1, s4
	fmov	s1, w9
	add	x9, x7, x22
	fmadd	s0, s29, s6, s0
	fmul	s16, s15, s8
	fsub	s3, s2, s3
	fmul	s19, s12, s30
	ldr	s28, [sp, #500]                 // 4-byte Folded Reload
	fneg	s20, s17
	mov	w11, #26480
	fmadd	s7, s25, s6, s7
	ldr	s25, [x9, #4]
	movk	w11, #48906, lsl #16
	fmadd	s0, s28, s1, s0
	fmov	s2, s1
	fsub	s15, s4, s16
	fmul	s16, s5, s8
	str	s1, [sp, #448]                  // 4-byte Folded Spill
	fmov	s1, w11
	fadd	s31, s3, s19
	fmul	s19, s25, s20
	fmul	s20, s13, s8
	ldr	s5, [sp, #520]                  // 4-byte Folded Reload
	ldr	s13, [sp, #532]                 // 4-byte Folded Reload
	str	s25, [sp, #456]                 // 4-byte Folded Spill
	fmov	s3, s1
	str	s1, [sp, #464]                  // 4-byte Folded Spill
	fmadd	s25, s5, s1, s0
	fsub	s16, s22, s16
	fmadd	s2, s13, s2, s7
	ldr	s7, [x9]
	fmul	s1, s24, s9
	str	s8, [sp, #528]                  // 4-byte Folded Spill
	ldr	s4, [sp, #516]                  // 4-byte Folded Reload
	fsub	s20, s26, s20
	fmul	s0, s11, s9
	fmadd	s19, s14, s7, s19
	ldr	s8, [sp, #572]                  // 4-byte Folded Reload
	str	s31, [sp, #444]                 // 4-byte Folded Spill
	fsub	s1, s16, s1
	fadd	s16, s25, s31
	ldr	s31, [sp, #544]                 // 4-byte Folded Reload
	fmul	s27, s4, s30
	fmul	s22, s17, s7
	fmul	s17, s8, s6
	str	s19, [sp, #460]                 // 4-byte Folded Spill
	fsub	s19, s20, s0
	fmadd	s26, s31, s3, s2
	ldr	s0, [sp, #524]                  // 4-byte Folded Reload
	ldr	s2, [sp, #556]                  // 4-byte Folded Reload
	add	x9, x10, x22
	ldr	s24, [sp, #496]                 // 4-byte Folded Reload
	fadd	s15, s15, s27
	fmul	s20, s18, s0
	fmov	s11, s14
	fmadd	s17, s23, s2, s17
	fmov	s14, w1
	fmul	s27, s24, s0
	fneg	s0, s16
	ldr	s3, [x9, #4]
	fmul	s6, s21, s6
	ldr	s21, [sp, #456]                 // 4-byte Folded Reload
	fadd	s19, s19, s20
	fmadd	s17, s29, s14, s17
	fmul	s20, s10, s30
	fmul	s29, s3, s0
	ldr	s0, [sp, #560]                  // 4-byte Folded Reload
	fadd	s7, s1, s27
	fsub	s27, s15, s26
	fmadd	s21, s11, s21, s22
	fmov	s23, s15
	fmadd	s6, s0, s2, s6
	ldr	s0, [sp, #472]                  // 4-byte Folded Reload
	ldr	s1, [x9]
	fadd	s19, s19, s20
	ldr	s15, [sp, #492]                 // 4-byte Folded Reload
	add	x9, x5, x22
	fmadd	s17, s28, s0, s17
	ldr	s28, [sp, #540]                 // 4-byte Folded Reload
	str	s21, [sp, #432]                 // 4-byte Folded Spill
	fmadd	s21, s27, s1, s29
	fmul	s20, s15, s30
	fmul	s1, s16, s1
	fmul	s2, s12, s28
	ldr	s16, [sp, #552]                 // 4-byte Folded Reload
	ldr	s18, [sp, #424]                 // 4-byte Folded Reload
	add	x11, x13, x22
	ldr	s30, [sp, #592]                 // 4-byte Folded Reload
	str	s21, [sp, #452]                 // 4-byte Folded Spill
	fmadd	s22, s16, s14, s6
	fadd	s7, s7, s20
	fmul	s6, s4, s28
	fsub	s11, s19, s2
	ldr	s2, [sp, #536]                  // 4-byte Folded Reload
	fmadd	s1, s27, s3, s1
	ldr	s16, [sp, #488]                 // 4-byte Folded Reload
	fmadd	s3, s13, s0, s22
	fmov	s13, s0
	fmadd	s10, s5, s2, s17
	ldr	s5, [sp, #600]                  // 4-byte Folded Reload
	fadd	s17, s16, s18
	ldr	s0, [sp, #444]                  // 4-byte Folded Reload
	fsub	s12, s7, s6
	ldr	s7, [sp, #564]                  // 4-byte Folded Reload
	fadd	s19, s30, s5
	str	s1, [sp, #456]                  // 4-byte Folded Spill
	fsub	s1, s0, s25
	fadd	s4, s10, s11
	fadd	s6, s17, s7
	ldr	s17, [sp, #584]                 // 4-byte Folded Reload
	ldp	s20, s22, [x9]
	fmadd	s29, s31, s2, s3
	ldr	s27, [x11, #4]
	fadd	s21, s19, s17
	fneg	s19, s1
	fneg	s25, s4
	fmul	s3, s5, s28
	fadd	s5, s23, s26
	ldr	s0, [sp, #576]                  // 4-byte Folded Reload
	fmul	s2, s1, s20
	fadd	s6, s6, s24
	fmul	s19, s22, s19
	fmov	s23, s24
	fadd	s24, s21, s0
	fmul	s21, s27, s25
	fsub	s1, s12, s29
	fsub	s25, s30, s3
	ldr	s30, [x11]
	fmadd	s2, s5, s22, s2
	ldr	s26, [sp, #528]                 // 4-byte Folded Reload
	fmadd	s3, s5, s20, s19
	ldr	s5, [sp, #568]                  // 4-byte Folded Reload
	fadd	s6, s6, s15
	fmul	s20, s18, s28
	fmov	s22, s18
	fmul	s31, s17, s26
	fmadd	s17, s1, s30, s21
	str	s3, [sp, #436]                  // 4-byte Folded Spill
	fmov	s3, s15
	str	s2, [sp, #440]                  // 4-byte Folded Spill
	fadd	s2, s24, s5
	fmul	s24, s4, s30
	ldr	s15, [sp, #516]                 // 4-byte Folded Reload
	ldr	s18, [sp, #548]                 // 4-byte Folded Reload
	str	s17, [sp, #444]                 // 4-byte Folded Spill
	ldr	s4, [sp, #484]                  // 4-byte Folded Reload
	fsub	s17, s25, s31
	ldr	s30, [sp, #448]                 // 4-byte Folded Reload
	fadd	s6, s6, s15
	fsub	s25, s16, s20
	fmul	s20, s7, s26
	fmul	s21, s0, s18
	add	x9, x16, x22
	fmadd	s0, s1, s27, s24
	fadd	s2, s2, s4
	fmul	s19, s8, s30
	ldr	s28, [sp, #504]                 // 4-byte Folded Reload
	ldr	s8, [sp, #536]                  // 4-byte Folded Reload
	str	s6, [x9, #8]
	fsub	s25, s25, s20
	fadd	s20, s17, s21
	fmul	s6, s5, s9
	ldr	s24, [sp, #508]                 // 4-byte Folded Reload
	add	x11, x30, x22
	str	s0, [sp, #428]                  // 4-byte Folded Spill
	ldr	s0, [sp, #468]                  // 4-byte Folded Reload
	str	s2, [x9, #12]
	ldr	s26, [sp, #524]                 // 4-byte Folded Reload
	fmadd	s1, s28, s8, s19
	fsub	s2, s11, s10
	ldr	s31, [sp, #512]                 // 4-byte Folded Reload
	fmul	s16, s24, s30
	fmul	s19, s23, s18
	str	s0, [x11, #8]
	add	x9, x14, x22
	fadd	s0, s12, s29
	fsub	s5, s20, s6
	fmul	s6, s4, s26
	ldr	s29, [sp, #560]                 // 4-byte Folded Reload
	fmadd	s1, s31, s13, s1
	fneg	s17, s2
	fmov	s27, s18
	fmov	s7, s4
	ldr	s10, [sp, #500]                 // 4-byte Folded Reload
	ldr	s18, [sp, #480]                 // 4-byte Folded Reload
	fmadd	s16, s29, s8, s16
	fadd	s4, s25, s19
	ldp	s19, s21, [x9]
	fadd	s30, s5, s6
	ldr	s5, [sp, #552]                  // 4-byte Folded Reload
	fmadd	s1, s10, s18, s1
	fmul	s17, s21, s17
	fmul	s20, s3, s9
	ldr	s3, [sp, #476]                  // 4-byte Folded Reload
	fmul	s2, s2, s19
	fmadd	s6, s5, s13, s16
	ldr	s16, [sp, #520]                 // 4-byte Folded Reload
	add	x9, x3, x22
	str	s3, [x11, #12]
	ldr	s3, [sp, #600]                  // 4-byte Folded Reload
	fmadd	s12, s0, s19, s17
	fmov	s23, s8
	fmadd	s1, s16, s14, s1
	fmadd	s0, s0, s21, s2
	ldr	s2, [sp, #460]                  // 4-byte Folded Reload
	fmul	s19, s15, s26
	fmov	s8, s15
	ldr	s15, [sp, #532]                 // 4-byte Folded Reload
	fmul	s17, s3, s9
	ldr	s3, [sp, #592]                  // 4-byte Folded Reload
	str	s2, [x9, #8]
	ldr	s2, [sp, #432]                  // 4-byte Folded Reload
	fsub	s4, s4, s20
	fmadd	s6, s15, s18, s6
	fadd	s20, s1, s30
	ldr	s13, [sp, #544]                 // 4-byte Folded Reload
	str	s2, [x9, #12]
	add	x9, x8, x22
	fsub	s3, s3, s17
	ldr	s17, [sp, #584]                 // 4-byte Folded Reload
	fadd	s2, s4, s19
	fmadd	s4, s13, s14, s6
	fneg	s6, s20
	ldr	s19, [x9, #4]
	fmul	s17, s17, s27
	fmov	s11, s26
	fmul	s26, s22, s9
	ldr	s22, [sp, #464]                 // 4-byte Folded Reload
	ldr	s21, [sp, #572]                 // 4-byte Folded Reload
	fsub	s25, s2, s4
	fmul	s6, s19, s6
	add	x11, x4, x22
	fadd	s3, s3, s17
	ldr	s17, [x9]
	fmul	s21, s21, s22
	fmul	s22, s24, s22
	ldr	x9, [sp, #408]                  // 8-byte Folded Reload
	fsub	s1, s30, s1
	fmadd	s6, s25, s17, s6
	fmul	s17, s20, s17
	ldr	s24, [sp, #540]                 // 4-byte Folded Reload
	fadd	s2, s2, s4
	fmadd	s21, s28, s18, s21
	fmadd	s22, s29, s18, s22
	ldr	s18, [sp, #452]                 // 4-byte Folded Reload
	add	x9, x9, x22
	fmadd	s17, s25, s19, s17
	ldr	s19, [sp, #456]                 // 4-byte Folded Reload
	ldr	s28, [sp, #576]                 // 4-byte Folded Reload
	str	s18, [x11, #8]
	ldr	s18, [sp, #488]                 // 4-byte Folded Reload
	ldr	s20, [sp, #564]                 // 4-byte Folded Reload
	str	s19, [x11, #12]
	fmadd	s19, s5, s23, s22
	ldr	s5, [sp, #436]                  // 4-byte Folded Reload
	fmul	s28, s28, s24
	fsub	s18, s18, s26
	fmul	s20, s20, s27
	ldr	s26, [sp, #568]                 // 4-byte Folded Reload
	str	s5, [x9, #8]
	ldr	s5, [sp, #496]                  // 4-byte Folded Reload
	fmadd	s21, s31, s23, s21
	ldr	s23, [sp, #528]                 // 4-byte Folded Reload
	fsub	s3, s3, s28
	fmul	s28, s26, s11
	fadd	s18, s18, s20
	fmul	s20, s5, s24
	ldr	s5, [sp, #440]                  // 4-byte Folded Reload
	fmul	s22, s7, s23
	fmadd	s7, s15, s14, s19
	fmadd	s21, s10, s14, s21
	fadd	s3, s3, s28
	add	x11, x6, x22
	str	s5, [x9, #12]
	ldr	s5, [sp, #492]                  // 4-byte Folded Reload
	fsub	s18, s18, s20
	fneg	s20, s1
	add	x9, x21, x22
	fmul	s19, s5, s11
	ldr	s5, [sp, #444]                  // 4-byte Folded Reload
	fsub	s3, s3, s22
	ldr	s22, [sp, #556]                 // 4-byte Folded Reload
	str	s5, [x11, #8]
	fadd	s18, s18, s19
	fmul	s19, s8, s23
	fmadd	s5, s16, s22, s21
	ldr	s16, [sp, #428]                 // 4-byte Folded Reload
	fmadd	s7, s13, s22, s7
	str	s16, [x11, #12]
	fsub	s18, s18, s19
	ldp	s19, s16, [x19]
	fadd	s4, s5, s3
	fsub	s3, s3, s5
	str	s12, [x9, #8]
	add	x11, x24, x22
	str	s0, [x9, #12]
	add	x9, x28, x22
	fmul	s20, s16, s20
	fmul	s1, s1, s19
	fneg	s5, s4
	ldp	s21, s22, [x11]
	ldr	x11, [sp, #376]                 // 8-byte Folded Reload
	fmadd	s0, s2, s19, s20
	fneg	s20, s3
	fmadd	s1, s2, s16, s1
	fsub	s19, s18, s7
	ldp	s16, s2, [x9]
	add	x9, x2, x22
	add	x11, x11, x22
	fmul	s5, s22, s5
	fmul	s4, s4, s21
	fadd	s7, s18, s7
	fmul	s18, s2, s20
	fmul	s3, s3, s16
	str	s6, [x9, #8]
	str	s17, [x9, #12]
	ldr	x9, [sp, #392]                  // 8-byte Folded Reload
	str	s0, [x11, #8]
	fmadd	s5, s19, s21, s5
	str	s1, [x11, #12]
	ldr	x11, [sp, #416]                 // 8-byte Folded Reload
	fmadd	s4, s19, s22, s4
	fmadd	s0, s7, s16, s18
	fmadd	s2, s7, s2, s3
	add	x9, x9, x22
	add	x11, x11, x22
	add	x22, x22, #8
	str	s5, [x9, #8]
	str	s4, [x9, #12]
	str	s0, [x11, #8]
	str	s2, [x11, #12]
	b.ne	.LBB181_9
	b	.LBB181_6
.LBB181_10:
	add	sp, sp, #608
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end181:
	.size	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_, .Lfunc_end181-_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIfEEEEvmmPKT0_PS6_PKS5_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_,@function
_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_: // @_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #464
	stp	x29, x30, [sp, #368]            // 16-byte Folded Spill
	add	x29, sp, #368
	stp	x28, x27, [sp, #384]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #400]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #416]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #432]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #448]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #3
	mov	x26, x7
	add	x0, x8, #64
	stur	x6, [x29, #-104]                // 8-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x27, x4
	mov	x28, x3
	mov	x25, x1
	bl	malloc
	cbz	x0, .LBB182_158
// %bb.1:
	add	x8, x0, #64
	add	x22, x23, #1
	and	x13, x8, #0xffffffffffffffc0
	mul	x8, x28, x25
	subs	x15, x23, #2
	lsr	x5, x22, #1
	stp	x25, x28, [x29, #-80]           // 16-byte Folded Spill
	stp	x13, x27, [x29, #-40]           // 16-byte Folded Spill
	stur	x8, [x29, #-16]                 // 8-byte Folded Spill
	mov	w8, #1065353216
	str	x5, [sp, #160]                  // 8-byte Folded Spill
	stp	x0, x8, [x13, #-8]
	b.lo	.LBB182_4
// %bb.2:
	sub	x14, x23, #1
	cmp	x14, #8
	b.hs	.LBB182_6
// %bb.3:
	mov	w8, #1
	b	.LBB182_13
.LBB182_4:
	cbz	x28, .LBB182_125
// %bb.5:
	cbnz	x25, .LBB182_17
	b	.LBB182_125
.LBB182_6:
	cmp	xzr, x15, lsr #61
	add	x11, x13, #8
	lsl	x10, x15, #3
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB182_13
// %bb.7:
	tbnz	w9, #0, .LBB182_13
// %bb.8:
	add	x11, x13, #12
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB182_13
// %bb.9:
	tbnz	w9, #0, .LBB182_13
// %bb.10:
	and	x9, x14, #0xfffffffffffffff8
	add	x10, x13, #40
	orr	x8, x9, #0x1
	add	x11, x26, #40
	mov	x12, x9
.LBB182_11:                             // =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x11, #-32]
	subs	x12, x12, #8
	ldp	q3, q2, [x11], #64
	stp	q1, q0, [x10, #-32]
	stp	q3, q2, [x10], #64
	b.ne	.LBB182_11
// %bb.12:
	cmp	x14, x9
	b.eq	.LBB182_15
.LBB182_13:
	lsl	x10, x8, #3
	sub	x9, x23, x8
	add	x8, x26, x10
	add	x10, x13, x10
.LBB182_14:                             // =>This Inner Loop Header: Depth=1
	ldr	d0, [x8], #8
	subs	x9, x9, #1
	str	d0, [x10], #8
	b.ne	.LBB182_14
.LBB182_15:
	cbz	x28, .LBB182_75
// %bb.16:
	cbz	x25, .LBB182_77
.LBB182_17:
	mul	x8, x23, x25
	lsl	x2, x25, #3
	mov	x19, x28
	mov	x26, x24
	lsl	x21, x8, #3
	str	x15, [sp, #152]                 // 8-byte Folded Spill
	stur	x2, [x29, #-112]                // 8-byte Folded Spill
.LBB182_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	bl	memcpy
	ldur	x2, [x29, #-112]                // 8-byte Folded Reload
	add	x27, x27, x21
	subs	x19, x19, #1
	add	x26, x26, x2
	b.ne	.LBB182_18
// %bb.19:
	sub	x8, x23, #1
	str	x22, [sp, #144]                 // 8-byte Folded Spill
	cmp	x22, #3
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	b.ls	.LBB182_44
// %bb.20:
	cbz	x25, .LBB182_92
// %bb.21:
	ldr	x8, [sp, #160]                  // 8-byte Folded Reload
	mov	w9, #2
	lsl	x11, x28, #3
	sub	x10, x25, #1
	add	x11, x11, #8
	lsl	x14, x10, #3
	cmp	x8, #2
	mov	x12, xzr
	csel	x8, x8, x9, hi
	mul	x11, x11, x25
	cmp	xzr, x10, lsr #61
	add	x18, x14, #8
	cset	w13, ne
	stur	x8, [x29, #-168]                // 8-byte Folded Spill
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	stur	x11, [x29, #-64]                // 8-byte Folded Spill
	mul	x9, x8, x28
	mul	x15, x0, x8
	lsl	x9, x9, #3
	add	x9, x9, #8
	add	x17, x24, x15, lsl #3
	mul	x11, x9, x25
	and	x9, x25, #0xfffffffffffffffc
	stur	x15, [x29, #-176]               // 8-byte Folded Spill
	stp	x9, x11, [x29, #-96]            // 16-byte Folded Spill
	mul	x9, x25, x8
	lsl	x8, x0, #3
	add	x11, x24, x0, lsl #3
	str	x8, [sp, #184]                  // 8-byte Folded Spill
	neg	x8, x8
	str	x8, [sp, #176]                  // 8-byte Folded Spill
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-112]               // 8-byte Folded Reload
	add	x3, x8, x9, lsl #3
	mov	w9, #1
	add	x2, x8, x10
	neg	x8, x10
	str	x8, [sp, #168]                  // 8-byte Folded Spill
.LBB182_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB182_23 Depth 2
                                        //       Child Loop BB182_36 Depth 3
                                        //       Child Loop BB182_41 Depth 3
	ldur	x8, [x29, #-176]                // 8-byte Folded Reload
	stp	x9, x3, [x29, #-160]            // 16-byte Folded Spill
	mul	x9, x0, x12
	mov	x6, xzr
	madd	x20, x0, x12, x0
	stp	x11, x12, [x29, #-128]          // 16-byte Folded Spill
	msub	x7, x0, x12, x8
	add	x10, x0, x9
	sub	x8, x8, x9
	stp	x2, x17, [x29, #-144]           // 16-byte Folded Spill
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	stp	x8, x10, [x29, #-56]            // 16-byte Folded Spill
	mov	x10, x11
.LBB182_23:                             //   Parent Loop BB182_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB182_36 Depth 3
                                        //       Child Loop BB182_41 Depth 3
	cmp	x25, #4
	b.hs	.LBB182_25
// %bb.24:                              //   in Loop: Header=BB182_23 Depth=2
	mov	x19, xzr
	b	.LBB182_40
.LBB182_25:                             //   in Loop: Header=BB182_23 Depth=2
	mul	x22, x6, x25
	mov	x19, xzr
	add	x11, x7, x22
	add	x12, x20, x22
	add	x11, x24, x11, lsl #3
	add	x0, x24, x12, lsl #3
	add	x12, x11, #4
	add	x16, x11, x14
	add	x1, x0, #4
	cmp	x16, x11
	add	x11, x12, x14
	cset	w4, lo
	cmp	x11, x12
	add	x11, x1, x14
	cset	w12, lo
	cmp	x11, x1
	add	x11, x0, x14
	cset	w16, lo
	cmp	x11, x0
	orr	w0, w4, w13
	cset	w11, lo
	tbnz	w0, #0, .LBB182_40
// %bb.26:                              //   in Loop: Header=BB182_23 Depth=2
	orr	w12, w12, w13
	tbnz	w12, #0, .LBB182_40
// %bb.27:                              //   in Loop: Header=BB182_23 Depth=2
	orr	w12, w16, w13
	tbnz	w12, #0, .LBB182_40
// %bb.28:                              //   in Loop: Header=BB182_23 Depth=2
	orr	w11, w11, w13
	tbnz	w11, #0, .LBB182_40
// %bb.29:                              //   in Loop: Header=BB182_23 Depth=2
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	mov	x9, x24
	ldp	x15, x12, [x29, #-56]           // 16-byte Folded Reload
	mov	x19, xzr
	add	x11, x8, x22
	sub	x0, x22, x8
	ldur	x8, [x29, #-64]                 // 8-byte Folded Reload
	add	x11, x24, x11, lsl #3
	add	x0, x24, x0, lsl #3
	add	x12, x12, x22
	add	x16, x15, x22
	add	x11, x11, x8
	ldur	x8, [x29, #-88]                 // 8-byte Folded Reload
	add	x12, x24, x12, lsl #3
	sub	x1, x11, #4
	add	x5, x12, #4
	cmp	x11, x12
	add	x8, x0, x8
	cset	w26, hi
	sub	x9, x8, #4
	cmp	x1, x5
	add	x30, x24, x16, lsl #3
	cset	w27, hi
	cmp	x9, x12
	add	x15, x30, #4
	cset	w16, hi
	cmp	x1, x30
	cset	w22, hi
	cmp	x8, x12
	cset	w0, hi
	cmp	x1, x15
	cset	w28, hi
	cmp	x9, x5
	cset	w25, hi
	cmp	x11, x30
	cset	w4, hi
	cmp	x8, x5
	cset	w5, hi
	cmp	x11, x15
	cset	w11, hi
	cmp	x8, x30
	cset	w1, hi
	cmp	x9, x15
	and	w8, w26, w27
	cset	w12, hi
	tbnz	w8, #0, .LBB182_38
// %bb.30:                              //   in Loop: Header=BB182_23 Depth=2
	and	w8, w16, w22
	tbnz	w8, #0, .LBB182_38
// %bb.31:                              //   in Loop: Header=BB182_23 Depth=2
	and	w8, w0, w28
	tbnz	w8, #0, .LBB182_38
// %bb.32:                              //   in Loop: Header=BB182_23 Depth=2
	and	w8, w25, w4
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB182_39
// %bb.33:                              //   in Loop: Header=BB182_23 Depth=2
	and	w8, w5, w11
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
	tbnz	w8, #0, .LBB182_40
// %bb.34:                              //   in Loop: Header=BB182_23 Depth=2
	and	w8, w1, w12
	tbnz	w8, #0, .LBB182_40
// %bb.35:                              //   in Loop: Header=BB182_23 Depth=2
	ldur	x19, [x29, #-96]                // 8-byte Folded Reload
	mov	x22, x3
	mov	x28, x2
	mov	x0, x17
	mov	x16, x10
.LBB182_36:                             //   Parent Loop BB182_22 Depth=1
                                        //     Parent Loop BB182_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.4s, v1.4s }, [x28], #32
	subs	x19, x19, #4
	ld2	{ v2.4s, v3.4s }, [x22], #32
	fadd	v4.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x16], #32
	fsub	v4.4s, v0.4s, v2.4s
	fsub	v5.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x0], #32
	b.ne	.LBB182_36
// %bb.37:                              //   in Loop: Header=BB182_23 Depth=2
	ldur	x8, [x29, #-96]                 // 8-byte Folded Reload
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	mov	x19, x8
	cmp	x8, x25
	b.ne	.LBB182_40
	b	.LBB182_42
.LBB182_38:                             //   in Loop: Header=BB182_23 Depth=2
	ldp	x25, x28, [x29, #-80]           // 16-byte Folded Reload
	b	.LBB182_40
.LBB182_39:                             //   in Loop: Header=BB182_23 Depth=2
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
.LBB182_40:                             //   in Loop: Header=BB182_23 Depth=2
	sub	x16, x25, x19
	lsl	x0, x19, #3
.LBB182_41:                             //   Parent Loop BB182_22 Depth=1
                                        //     Parent Loop BB182_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x8, x2, x0
	add	x9, x3, x0
	subs	x16, x16, #1
	ldp	s0, s1, [x8]
	ldp	s2, s3, [x9]
	add	x8, x10, x0
	add	x9, x17, x0
	add	x0, x0, #8
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stp	s4, s5, [x8]
	stp	s0, s1, [x9]
	b.ne	.LBB182_41
.LBB182_42:                             //   in Loop: Header=BB182_23 Depth=2
	add	x6, x6, #1
	add	x10, x10, x18
	add	x17, x17, x18
	add	x2, x2, x21
	add	x3, x3, x21
	cmp	x6, x28
	b.ne	.LBB182_23
// %bb.43:                              //   in Loop: Header=BB182_22 Depth=1
	ldp	x11, x12, [x29, #-128]          // 16-byte Folded Reload
	ldr	x8, [sp, #184]                  // 8-byte Folded Reload
	ldp	x2, x17, [x29, #-144]           // 16-byte Folded Reload
	add	x11, x11, x8
	ldr	x8, [sp, #176]                  // 8-byte Folded Reload
	ldp	x9, x3, [x29, #-160]            // 16-byte Folded Reload
	add	x12, x12, #1
	add	x2, x2, x18
	add	x17, x17, x8
	ldr	x8, [sp, #168]                  // 8-byte Folded Reload
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	add	x9, x9, #1
	add	x3, x3, x8
	ldur	x8, [x29, #-168]                // 8-byte Folded Reload
	cmp	x9, x8
	b.ne	.LBB182_22
.LBB182_44:
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldr	x2, [sp, #144]                  // 8-byte Folded Reload
	ldur	x18, [x29, #-112]               // 8-byte Folded Reload
	cbz	x25, .LBB182_52
// %bb.45:
	cmp	x2, #3
	b.ls	.LBB182_79
// %bb.46:
	cmp	x5, #2
	mov	w9, #2
	csel	x9, x5, x9, hi
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x24, x0, lsl #3
	lsl	x11, x0, #3
.LBB182_47:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB182_48 Depth 2
                                        //       Child Loop BB182_49 Depth 3
	mul	x13, x8, x25
	mov	x12, xzr
	mov	x14, x10
.LBB182_48:                             //   Parent Loop BB182_47 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB182_49 Depth 3
	add	x15, x12, x13
	mov	x16, x14
	mov	x17, x9
	ldr	d0, [x24, x15, lsl #3]
.LBB182_49:                             //   Parent Loop BB182_47 Depth=1
                                        //     Parent Loop BB182_48 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d1, [x16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.2s, v0.2s, v1.2s
	b.ne	.LBB182_49
// %bb.50:                              //   in Loop: Header=BB182_48 Depth=2
	add	x12, x12, #1
	add	x14, x14, #8
	cmp	x12, x25
	str	d0, [x27, x15, lsl #3]
	b.ne	.LBB182_48
// %bb.51:                              //   in Loop: Header=BB182_47 Depth=1
	add	x8, x8, #1
	add	x10, x10, x18
	cmp	x8, x28
	b.ne	.LBB182_47
.LBB182_52:
	mov	w10, wzr
	mov	w9, wzr
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	cmp	x2, #4
	ldr	x15, [sp, #152]                 // 8-byte Folded Reload
	b.hs	.LBB182_93
// %bb.53:
	subs	x8, x25, #1
	b.ne	.LBB182_123
.LBB182_54:
	cmp	x0, #0
	eor	w9, w9, #0x1
	cset	w8, eq
	orr	w8, w9, w8
	tbnz	w8, #0, .LBB182_125
// %bb.55:
	mul	x10, x14, x28
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	lsl	x11, x14, #3
	cmp	x5, #2
	add	x12, x11, #8
	mov	w9, #2
	sub	x14, x0, #1
	mul	x10, x10, x25
	csel	x9, x5, x9, hi
	mul	x12, x0, x12
	cmp	xzr, x14, lsr #61
	lsl	x14, x14, #3
	mov	x8, xzr
	lsl	x11, x0, #1
	cset	w13, ne
	and	x15, x0, #0xfffffffffffffffc
	add	x16, x27, x0, lsl #3
	add	x17, x14, #8
	add	x18, x27, x10, lsl #3
	neg	x0, x0, lsl #3
	mov	w1, #1
.LBB182_56:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB182_72 Depth 2
                                        //     Child Loop BB182_59 Depth 2
	ldur	x4, [x29, #-16]                 // 8-byte Folded Reload
	cmp	x4, #4
	b.hs	.LBB182_61
// %bb.57:                              //   in Loop: Header=BB182_56 Depth=1
	mov	x2, xzr
.LBB182_58:                             //   in Loop: Header=BB182_56 Depth=1
	ldur	x3, [x29, #-16]                 // 8-byte Folded Reload
	sub	x3, x3, x2
	lsl	x2, x2, #3
.LBB182_59:                             //   Parent Loop BB182_56 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x4, x16, x2
	add	x5, x18, x2
	subs	x3, x3, #1
	add	x2, x2, #8
	ldp	s0, s1, [x4]
	ldp	s2, s3, [x5]
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stp	s4, s5, [x4]
	stp	s0, s1, [x5]
	b.ne	.LBB182_59
.LBB182_60:                             //   in Loop: Header=BB182_56 Depth=1
	add	x1, x1, #1
	add	x8, x8, #1
	add	x16, x16, x17
	add	x18, x18, x0
	cmp	x1, x9
	b.ne	.LBB182_56
	b	.LBB182_125
.LBB182_61:                             //   in Loop: Header=BB182_56 Depth=1
	msub	x3, x4, x8, x10
	mov	x2, xzr
	madd	x4, x4, x8, x4
	add	x3, x27, x3, lsl #3
	add	x5, x3, #4
	add	x6, x27, x4, lsl #3
	add	x4, x5, x14
	add	x7, x6, #4
	cmp	x4, x5
	add	x4, x3, x14
	cset	w19, lo
	cmp	x4, x3
	add	x3, x7, x14
	cset	w4, lo
	cmp	x3, x7
	add	x3, x6, x14
	cset	w5, lo
	cmp	x3, x6
	orr	w6, w19, w13
	cset	w3, lo
	tbnz	w6, #0, .LBB182_58
// %bb.62:                              //   in Loop: Header=BB182_56 Depth=1
	orr	w4, w4, w13
	tbnz	w4, #0, .LBB182_58
// %bb.63:                              //   in Loop: Header=BB182_56 Depth=1
	orr	w4, w5, w13
	tbnz	w4, #0, .LBB182_58
// %bb.64:                              //   in Loop: Header=BB182_56 Depth=1
	orr	w3, w3, w13
	tbnz	w3, #0, .LBB182_58
// %bb.65:                              //   in Loop: Header=BB182_56 Depth=1
	ldur	x4, [x29, #-16]                 // 8-byte Folded Reload
	mov	x2, xzr
	mul	x3, x4, x8
	add	x4, x4, x3
	add	x5, x11, x3
	sub	x6, x10, x3
	sub	x3, x27, x3, lsl #3
	add	x4, x27, x4, lsl #3
	add	x21, x27, x5, lsl #3
	add	x23, x27, x6, lsl #3
	add	x24, x3, x12
	sub	x6, x21, #4
	add	x19, x4, #4
	cmp	x4, x21
	sub	x25, x24, #4
	cset	w27, lo
	cmp	x19, x6
	cset	w28, lo
	cmp	x25, x4
	cset	w3, hi
	cmp	x23, x6
	add	x26, x23, #4
	cset	w5, lo
	cmp	x24, x4
	cset	w4, hi
	cmp	x26, x6
	cset	w7, lo
	cmp	x25, x19
	cset	w6, hi
	cmp	x23, x21
	cset	w20, lo
	cmp	x24, x19
	cset	w19, hi
	cmp	x26, x21
	cset	w22, lo
	cmp	x24, x23
	cset	w21, hi
	cmp	x25, x26
	and	w24, w27, w28
	cset	w23, hi
	tbnz	w24, #0, .LBB182_74
// %bb.66:                              //   in Loop: Header=BB182_56 Depth=1
	and	w3, w3, w5
	tbnz	w3, #0, .LBB182_74
// %bb.67:                              //   in Loop: Header=BB182_56 Depth=1
	and	w3, w4, w7
	tbnz	w3, #0, .LBB182_74
// %bb.68:                              //   in Loop: Header=BB182_56 Depth=1
	and	w3, w6, w20
	tbnz	w3, #0, .LBB182_74
// %bb.69:                              //   in Loop: Header=BB182_56 Depth=1
	and	w3, w19, w22
	tbnz	w3, #0, .LBB182_74
// %bb.70:                              //   in Loop: Header=BB182_56 Depth=1
	and	w3, w21, w23
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w3, #0, .LBB182_58
// %bb.71:                              //   in Loop: Header=BB182_56 Depth=1
	mov	x2, x15
	mov	x3, x18
	mov	x4, x16
.LBB182_72:                             //   Parent Loop BB182_56 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v0.4s, v1.4s }, [x4]
	subs	x2, x2, #4
	ld2	{ v2.4s, v3.4s }, [x3]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v6.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v7.4s, v1.4s, v3.4s
	st2	{ v4.4s, v5.4s }, [x4], #32
	st2	{ v6.4s, v7.4s }, [x3], #32
	b.ne	.LBB182_72
// %bb.73:                              //   in Loop: Header=BB182_56 Depth=1
	ldur	x3, [x29, #-16]                 // 8-byte Folded Reload
	mov	x2, x15
	cmp	x3, x15
	b.ne	.LBB182_58
	b	.LBB182_60
.LBB182_74:                             //   in Loop: Header=BB182_56 Depth=1
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	b	.LBB182_58
.LBB182_75:
	mov	w10, #1
	cmp	x22, #3
	b.ls	.LBB182_91
// %bb.76:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	b	.LBB182_93
.LBB182_77:
	cmp	x22, #3
	b.ls	.LBB182_125
// %bb.78:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	mov	w10, wzr
	b	.LBB182_93
.LBB182_79:
	sub	x12, x25, #1
	mov	x8, xzr
	mov	x9, xzr
	and	x10, x25, #0xfffffffffffffff8
	cmp	xzr, x12, lsr #61
	lsl	x12, x12, #3
	add	x11, x27, #32
	cset	w13, ne
	add	x14, x12, #8
	add	x15, x24, #32
	b	.LBB182_81
.LBB182_80:                             //   in Loop: Header=BB182_81 Depth=1
	add	x9, x9, #1
	add	x11, x11, x14
	add	x15, x15, x14
	add	x8, x8, x25
	cmp	x9, x28
	b.eq	.LBB182_52
.LBB182_81:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB182_88 Depth 2
                                        //     Child Loop BB182_84 Depth 2
	cmp	x25, #8
	b.hs	.LBB182_85
// %bb.82:                              //   in Loop: Header=BB182_81 Depth=1
	mov	x16, xzr
.LBB182_83:                             //   in Loop: Header=BB182_81 Depth=1
	add	x17, x16, x8
	sub	x16, x25, x16
	lsl	x18, x17, #3
	add	x17, x27, x18
	add	x18, x24, x18
.LBB182_84:                             //   Parent Loop BB182_81 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x18], #8
	subs	x16, x16, #1
	str	d0, [x17], #8
	b.ne	.LBB182_84
	b	.LBB182_80
.LBB182_85:                             //   in Loop: Header=BB182_81 Depth=1
	mul	x17, x9, x25
	mov	x16, xzr
	add	x17, x27, x17, lsl #3
	add	x18, x17, x12
	add	x0, x17, #4
	cmp	x18, x17
	add	x18, x0, x12
	cset	w17, lo
	cmp	x18, x0
	orr	w1, w17, w13
	cset	w17, lo
	tbnz	w1, #0, .LBB182_90
// %bb.86:                              //   in Loop: Header=BB182_81 Depth=1
	orr	w17, w17, w13
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	tbnz	w17, #0, .LBB182_83
// %bb.87:                              //   in Loop: Header=BB182_81 Depth=1
	mov	x16, x10
	mov	x17, x15
	mov	x18, x11
.LBB182_88:                             //   Parent Loop BB182_81 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x17, #-32]
	subs	x16, x16, #8
	ldp	q3, q2, [x17], #64
	stp	q1, q0, [x18, #-32]
	stp	q3, q2, [x18], #64
	b.ne	.LBB182_88
// %bb.89:                              //   in Loop: Header=BB182_81 Depth=1
	mov	x16, x10
	cmp	x10, x25
	b.eq	.LBB182_80
	b	.LBB182_83
.LBB182_90:                             //   in Loop: Header=BB182_81 Depth=1
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	b	.LBB182_83
.LBB182_91:
	mov	w9, wzr
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	subs	x8, x25, #1
	b.ne	.LBB182_123
	b	.LBB182_54
.LBB182_92:
	ldp	x15, x5, [sp, #152]             // 16-byte Folded Reload
	mov	w10, wzr
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
.LBB182_93:
	sub	x9, x5, #1
	str	w10, [sp, #4]                   // 4-byte Folded Spill
	lsl	x11, x14, #3
	sub	x13, x0, #1
	add	x11, x11, #8
	cmp	x5, #2
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	mul	x9, x14, x28
	mov	w10, #2
	mul	x8, x0, x15
	csel	x10, x5, x10, hi
	cmp	xzr, x13, lsr #61
	mul	x21, x9, x25
	lsl	x6, x0, #3
	mul	x9, x0, x11
	add	x8, x24, x8, lsl #3
	mul	x16, x0, x14
	sub	x15, x23, #3
	str	x14, [sp, #8]                   // 8-byte Folded Spill
	add	x7, x27, x6
	str	x10, [sp, #152]                 // 8-byte Folded Spill
	lsl	x10, x16, #3
	str	x9, [sp, #136]                  // 8-byte Folded Spill
	cset	w9, ne
	add	x4, x27, x10
	lsl	x30, x0, #4
	mov	x19, xzr
	lsl	x12, x0, #1
	str	w9, [sp, #100]                  // 4-byte Folded Spill
	lsl	x9, x13, #3
	mul	x13, x0, x15
	and	x1, x0, #0xfffffffffffffffc
	neg	x26, x6
	add	x11, x7, #4
	str	x9, [sp, #88]                   // 8-byte Folded Spill
	add	x9, x24, x6
	add	x22, x9, #4
	add	x9, x24, x0, lsl #4
	add	x9, x9, #4
	stur	x16, [x29, #-56]                // 8-byte Folded Spill
	str	x15, [sp, #104]                 // 8-byte Folded Spill
	mov	w15, #1
	stp	x8, x9, [sp, #72]               // 16-byte Folded Spill
	sub	x9, x23, #4
	add	x8, x24, x10
	mov	w10, #24
	mul	x9, x0, x9
	add	x8, x8, #4
	madd	x18, x0, x10, x24
	add	x10, x24, x13, lsl #3
	stp	x13, x8, [sp, #56]              // 16-byte Folded Spill
	add	x8, x24, x0, lsl #5
	str	x9, [sp, #48]                   // 8-byte Folded Spill
	add	x9, x24, x9, lsl #3
	stp	x8, x18, [sp, #32]              // 16-byte Folded Spill
	neg	x8, x30
	stp	x9, x10, [sp, #16]              // 16-byte Folded Spill
	ldur	x3, [x29, #-40]                 // 8-byte Folded Reload
	stur	x0, [x29, #-64]                 // 8-byte Folded Spill
	str	x21, [sp, #144]                 // 8-byte Folded Spill
	stp	x22, x6, [sp, #120]             // 16-byte Folded Spill
	str	x26, [sp, #112]                 // 8-byte Folded Spill
	b	.LBB182_95
.LBB182_94:                             //   in Loop: Header=BB182_95 Depth=1
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	add	x15, x15, #1
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	add	x19, x19, #1
	ldur	x11, [x29, #-88]                // 8-byte Folded Reload
	add	x4, x4, x26
	add	x7, x7, x6
	add	x9, x9, x0
	add	x11, x11, x6
	stur	x9, [x29, #-64]                 // 8-byte Folded Spill
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	sub	x9, x9, x0
	stur	x9, [x29, #-56]                 // 8-byte Folded Spill
	ldp	x21, x9, [sp, #144]             // 16-byte Folded Reload
	cmp	x15, x9
	b.eq	.LBB182_122
.LBB182_95:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB182_97 Depth 2
                                        //     Child Loop BB182_103 Depth 2
                                        //       Child Loop BB182_107 Depth 3
                                        //       Child Loop BB182_110 Depth 3
                                        //     Child Loop BB182_116 Depth 2
                                        //       Child Loop BB182_118 Depth 3
                                        //       Child Loop BB182_121 Depth 3
	mul	x16, x0, x19
	stur	x11, [x29, #-88]                // 8-byte Folded Spill
	sub	x20, x21, x16
	sub	x10, x27, x16, lsl #3
	cbz	x0, .LBB182_99
// %bb.96:                              //   in Loop: Header=BB182_95 Depth=1
	stur	x10, [x29, #-48]                // 8-byte Folded Spill
	add	x18, x3, x15, lsl #3
	ldp	x28, x25, [sp, #72]             // 16-byte Folded Reload
	mov	x14, x0
	add	x0, x3, x15, lsl #4
	mov	x17, xzr
	lsl	x13, x15, #1
	add	x2, x18, #4
	add	x5, x0, #4
	ldur	x10, [x29, #-88]                // 8-byte Folded Reload
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
.LBB182_97:                             //   Parent Loop BB182_95 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x3, x24, x17
	add	x9, x22, x17
	ldr	s0, [x18]
	add	x6, x25, x17
	ldr	s3, [x0]
	subs	x14, x14, #1
	ldp	s2, s4, [x3]
	ldur	s1, [x9, #-4]
	add	x3, x10, x17
	fmadd	s0, s0, s1, s2
	ldp	s1, s2, [x6, #-4]
	fmadd	s0, s3, s1, s0
	ldr	s1, [x9]
	add	x9, x28, x17
	stur	s0, [x3, #-4]
	ldr	s0, [x18]
	fmadd	s0, s0, s1, s4
	ldr	s1, [x0]
	fmadd	s0, s1, s2, s0
	ldp	s3, s2, [x9]
	add	x9, x4, x17
	str	s0, [x3]
	add	x3, x11, x17
	ldr	s0, [x5]
	add	x17, x17, #8
	fneg	s1, s0
	fmul	s0, s0, s3
	ldp	s3, s4, [x3, #-4]
	fmul	s1, s2, s1
	ldr	s2, [x2]
	fmadd	s0, s2, s3, s0
	fmsub	s1, s2, s4, s1
	stp	s1, s0, [x9]
	b.ne	.LBB182_97
// %bb.98:                              //   in Loop: Header=BB182_95 Depth=1
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	b	.LBB182_100
.LBB182_99:                             //   in Loop: Header=BB182_95 Depth=1
	lsl	x13, x15, #1
.LBB182_100:                            //   in Loop: Header=BB182_95 Depth=1
	ldr	x14, [sp, #136]                 // 8-byte Folded Reload
	add	x17, x12, x16
	msub	x11, x0, x19, x21
	add	x9, x0, x16
	add	x16, x27, x17, lsl #3
	stur	x19, [x29, #-96]                // 8-byte Folded Spill
	add	x18, x10, x14
	madd	x14, x0, x19, x0
	add	x19, x27, x9, lsl #3
	sub	x5, x16, #4
	add	x6, x27, x20, lsl #3
	add	x11, x27, x11, lsl #3
	add	x16, x27, x14, lsl #3
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	sub	x21, x18, #4
	add	x3, x19, #4
	add	x2, x6, #4
	add	x25, x11, #4
	add	x22, x16, #4
	cmp	x9, #4
	stp	x18, x17, [x29, #-120]          // 16-byte Folded Spill
	stp	x3, x2, [x29, #-136]            // 16-byte Folded Spill
	stp	x6, x5, [x29, #-152]            // 16-byte Folded Spill
	stp	x21, x19, [x29, #-168]          // 16-byte Folded Spill
	stur	x22, [x29, #-176]               // 8-byte Folded Spill
	stp	x16, x25, [sp, #176]            // 16-byte Folded Spill
	str	x11, [sp, #168]                 // 8-byte Folded Spill
	b.lo	.LBB182_111
// %bb.101:                             //   in Loop: Header=BB182_95 Depth=1
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	add	x17, x27, x17, lsl #3
	add	x9, x11, x14
	add	x10, x16, x14
	cmp	x9, x11
	add	x9, x25, x14
	cset	w11, lo
	cmp	x10, x16
	ldr	w16, [sp, #100]                 // 4-byte Folded Reload
	orr	w10, w11, w16
	cset	w11, lo
	cmp	x9, x25
	orr	w9, w11, w16
	add	x11, x22, x14
	cset	w14, lo
	cmp	x11, x22
	orr	w11, w14, w16
	cset	w14, lo
	cmp	x21, x19
	orr	w14, w14, w16
	cset	w16, hi
	cmp	x6, x5
	orr	w9, w10, w9
	cset	w10, lo
	cmp	x18, x3
	cset	w18, hi
	cmp	x2, x17
	orr	w9, w9, w11
	cset	w11, lo
	and	w10, w16, w10
	and	w11, w18, w11
	orr	w20, w9, w14
	orr	w9, w10, w11
	mov	w16, #3
	stur	w9, [x29, #-48]                 // 4-byte Folded Spill
	ldp	x10, x28, [sp, #48]             // 16-byte Folded Reload
	ldp	x5, x2, [sp, #16]               // 16-byte Folded Reload
	ldp	x11, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #104]                 // 8-byte Folded Reload
	b	.LBB182_103
.LBB182_102:                            //   in Loop: Header=BB182_103 Depth=2
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	add	x16, x16, #2
	sub	x21, x21, #2
	add	x19, x19, x30
	add	x11, x11, x30
	add	x2, x2, x8
	add	x5, x5, x8
	sub	x28, x28, x12
	sub	x10, x10, x12
	cmp	x16, x9
	b.hs	.LBB182_112
.LBB182_103:                            //   Parent Loop BB182_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB182_107 Depth 3
                                        //       Child Loop BB182_110 Depth 3
	add	x9, x13, x15
	cmp	x9, x23
	csel	x13, x23, xzr, hi
	sub	x9, x9, x13
	add	x13, x9, x15
	cmp	x13, x23
	csel	x14, x23, xzr, hi
	sub	x13, x13, x14
	cbz	x0, .LBB182_102
// %bb.104:                             //   in Loop: Header=BB182_103 Depth=2
	ldur	x14, [x29, #-40]                // 8-byte Folded Reload
	cmp	x0, #4
	cset	w17, lo
	orr	w17, w17, w20
	add	x9, x14, x9, lsl #3
	add	x14, x14, x13, lsl #3
	ldp	s3, s2, [x9]
	ldur	w9, [x29, #-48]                 // 4-byte Folded Reload
	ldp	s0, s1, [x14]
	orr	w9, w17, w9
	tbz	w9, #0, .LBB182_106
// %bb.105:                             //   in Loop: Header=BB182_103 Depth=2
	mov	x9, xzr
	b	.LBB182_109
.LBB182_106:                            //   in Loop: Header=BB182_103 Depth=2
	mov	x17, xzr
	mov	x22, x1
	dup	v4.4s, v3.s[0]
	dup	v5.4s, v2.s[0]
.LBB182_107:                            //   Parent Loop BB182_95 Depth=1
                                        //     Parent Loop BB182_103 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x11, x17
	add	x14, x5, x17
	subs	x22, x22, #4
	ld2	{ v6.4s, v7.4s }, [x9]
	add	x9, x19, x17
	ld2	{ v16.4s, v17.4s }, [x9]
	add	x9, x7, x17
	fmul	v18.4s, v6.4s, v0.s[0]
	fmul	v6.4s, v7.4s, v0.s[0]
	ld2	{ v19.4s, v20.4s }, [x9]
	fmla	v18.4s, v4.4s, v16.4s
	fmla	v6.4s, v4.4s, v17.4s
	ld2	{ v16.4s, v17.4s }, [x14]
	add	x14, x2, x17
	fadd	v21.4s, v19.4s, v18.4s
	fadd	v22.4s, v20.4s, v6.4s
	ld2	{ v6.4s, v7.4s }, [x14]
	add	x14, x4, x17
	add	x17, x17, #32
	fmul	v18.4s, v17.4s, v1.s[0]
	fmul	v16.4s, v16.4s, v1.s[0]
	st2	{ v21.4s, v22.4s }, [x9]
	ld2	{ v19.4s, v20.4s }, [x14]
	fmla	v18.4s, v5.4s, v7.4s
	fmla	v16.4s, v5.4s, v6.4s
	fsub	v6.4s, v19.4s, v18.4s
	fadd	v7.4s, v20.4s, v16.4s
	st2	{ v6.4s, v7.4s }, [x14]
	b.ne	.LBB182_107
// %bb.108:                             //   in Loop: Header=BB182_103 Depth=2
	mov	x9, x1
	cmp	x0, x1
	b.eq	.LBB182_102
.LBB182_109:                            //   in Loop: Header=BB182_103 Depth=2
	ldur	x18, [x29, #-64]                // 8-byte Folded Reload
	sub	x22, x0, x9
	ldur	x0, [x29, #-32]                 // 8-byte Folded Reload
	add	x25, x9, x28
	add	x27, x9, x10
	dup	v3.2s, v3.s[0]
	add	x6, x18, x9
	ldur	x18, [x29, #-56]                // 8-byte Folded Reload
	dup	v2.2s, v2.s[0]
	lsl	x3, x9, #3
	mov	x17, xzr
	add	x14, x19, x3
	add	x18, x18, x9
	add	x3, x11, x3
	add	x6, x0, x6, lsl #3
	add	x26, x24, x25, lsl #3
	add	x9, x24, x27, lsl #3
	add	x25, x0, x18, lsl #3
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
.LBB182_110:                            //   Parent Loop BB182_95 Depth=1
                                        //     Parent Loop BB182_103 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	lsl	x18, x17, #3
	add	x17, x17, #1
	cmp	x22, x17
	ldr	d4, [x3, x18]
	ldr	d5, [x14, x18]
	ldr	d6, [x9, x18]
	ldr	d7, [x6, x18]
	fmul	v4.2s, v4.2s, v0.s[0]
	fmul	v6.2s, v6.2s, v1.s[0]
	fmla	v4.2s, v3.2s, v5.2s
	ldr	d5, [x26, x18]
	rev64	v6.2s, v6.2s
	fadd	v4.2s, v7.2s, v4.2s
	rev64	v5.2s, v5.2s
	str	d4, [x6, x18]
	fmla	v6.2s, v2.2s, v5.2s
	ldr	d4, [x25, x18]
	fsub	v5.2s, v4.2s, v6.2s
	fadd	v4.2s, v4.2s, v6.2s
	mov	v5.s[1], v4.s[1]
	str	d5, [x25, x18]
	b.ne	.LBB182_110
	b	.LBB182_102
.LBB182_111:                            //   in Loop: Header=BB182_95 Depth=1
	ldr	x21, [sp, #104]                 // 8-byte Folded Reload
	mov	w16, #3
.LBB182_112:                            //   in Loop: Header=BB182_95 Depth=1
	ldp	x3, x27, [x29, #-40]            // 16-byte Folded Reload
	ldp	x25, x28, [x29, #-80]           // 16-byte Folded Reload
	ldp	x22, x6, [sp, #120]             // 16-byte Folded Reload
	ldr	x5, [sp, #160]                  // 8-byte Folded Reload
	ldur	x19, [x29, #-96]                // 8-byte Folded Reload
	ldr	x26, [sp, #112]                 // 8-byte Folded Reload
	cmp	x16, x5
	b.hs	.LBB182_94
// %bb.113:                             //   in Loop: Header=BB182_95 Depth=1
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	cbz	x9, .LBB182_94
// %bb.114:                             //   in Loop: Header=BB182_95 Depth=1
	ldp	x10, x11, [sp, #168]            // 16-byte Folded Reload
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	ldr	x18, [sp, #184]                 // 8-byte Folded Reload
	ldr	w17, [sp, #100]                 // 4-byte Folded Reload
	add	x9, x10, x14
	ldur	x2, [x29, #-16]                 // 8-byte Folded Reload
	cmp	x9, x10
	add	x9, x11, x14
	cset	w10, lo
	cmp	x9, x11
	add	x9, x18, x14
	cset	w11, lo
	cmp	x9, x18
	ldur	x18, [x29, #-176]               // 8-byte Folded Reload
	orr	w10, w10, w17
	orr	w9, w11, w17
	orr	w9, w10, w9
	add	x11, x18, x14
	cset	w14, lo
	cmp	x11, x18
	orr	w11, w14, w17
	orr	w9, w9, w11
	cset	w14, lo
	ldp	x11, x10, [x29, #-168]          // 16-byte Folded Reload
	orr	w14, w14, w17
	ldur	x18, [x29, #-136]               // 8-byte Folded Reload
	cmp	x11, x10
	ldp	x17, x11, [x29, #-152]          // 16-byte Folded Reload
	cset	w10, hi
	cmp	x17, x11
	ldp	x0, x17, [x29, #-128]           // 16-byte Folded Reload
	cset	w11, lo
	and	w11, w10, w11
	orr	w10, w9, w14
	cmp	x17, x18
	ldur	x18, [x29, #-112]               // 8-byte Folded Reload
	cset	w17, hi
	add	x18, x27, x18, lsl #3
	cmp	x0, x18
	mul	x18, x2, x16
	mul	x2, x2, x21
	cset	w0, lo
	and	w17, w17, w0
	orr	w11, w11, w17
	add	x18, x24, x18, lsl #3
	add	x0, x24, x2, lsl #3
	b	.LBB182_116
.LBB182_115:                            //   in Loop: Header=BB182_116 Depth=2
	add	x16, x16, #1
	add	x18, x18, x6
	add	x0, x0, x26
	cmp	x16, x5
	b.eq	.LBB182_94
.LBB182_116:                            //   Parent Loop BB182_95 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB182_118 Depth 3
                                        //       Child Loop BB182_121 Depth 3
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mov	x14, xzr
	cmp	x9, #4
	add	x9, x13, x15
	cset	w17, lo
	cmp	x9, x23
	csel	x13, x23, xzr, hi
	orr	w17, w17, w10
	sub	x13, x9, x13
	orr	w17, w17, w11
	add	x9, x3, x13, lsl #3
	ldp	s1, s0, [x9]
	tbnz	w17, #0, .LBB182_120
// %bb.117:                             //   in Loop: Header=BB182_116 Depth=2
	mov	x14, xzr
	mov	x17, x1
	dup	v2.4s, v1.s[0]
	dup	v3.4s, v0.s[0]
.LBB182_118:                            //   Parent Loop BB182_95 Depth=1
                                        //     Parent Loop BB182_116 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x18, x14
	add	x2, x0, x14
	subs	x17, x17, #4
	ld2	{ v4.4s, v5.4s }, [x9]
	add	x9, x7, x14
	ld2	{ v6.4s, v7.4s }, [x9]
	fmla	v6.4s, v2.4s, v4.4s
	fmla	v7.4s, v2.4s, v5.4s
	ld2	{ v4.4s, v5.4s }, [x2]
	add	x2, x4, x14
	add	x14, x14, #32
	st2	{ v6.4s, v7.4s }, [x9]
	ld2	{ v6.4s, v7.4s }, [x2]
	fmls	v6.4s, v3.4s, v5.4s
	fmla	v7.4s, v3.4s, v4.4s
	st2	{ v6.4s, v7.4s }, [x2]
	b.ne	.LBB182_118
// %bb.119:                             //   in Loop: Header=BB182_116 Depth=2
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mov	x14, x1
	cmp	x9, x1
	b.eq	.LBB182_115
.LBB182_120:                            //   in Loop: Header=BB182_116 Depth=2
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	dup	v1.2s, v1.s[0]
	sub	x9, x9, x14
	lsl	x14, x14, #3
.LBB182_121:                            //   Parent Loop BB182_95 Depth=1
                                        //     Parent Loop BB182_116 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d2, [x18, x14]
	add	x17, x0, x14
	ldr	d3, [x7, x14]
	add	x2, x4, x14
	subs	x9, x9, #1
	fmla	v3.2s, v1.2s, v2.2s
	ldp	s4, s2, [x17]
	str	d3, [x7, x14]
	add	x14, x14, #8
	ldp	s3, s5, [x2]
	fmsub	s2, s2, s0, s3
	fmadd	s3, s4, s0, s5
	str	s2, [x2]
	str	s3, [x2, #4]
	b.ne	.LBB182_121
	b	.LBB182_115
.LBB182_122:
	ldr	x14, [sp, #8]                   // 8-byte Folded Reload
	mov	w9, #1
	ldr	w10, [sp, #4]                   // 4-byte Folded Reload
	subs	x8, x25, #1
	b.eq	.LBB182_54
.LBB182_123:
	cbz	w9, .LBB182_125
// %bb.124:
	tbz	w10, #0, .LBB182_128
.LBB182_125:
	ldur	x8, [x29, #-40]                 // 8-byte Folded Reload
	cbz	x8, .LBB182_127
// %bb.126:
	ldp	x20, x19, [sp, #448]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #432]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #416]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #400]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #384]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #368]            // 16-byte Folded Reload
	ldur	x0, [x8, #-8]
	add	sp, sp, #464
	b	free
.LBB182_127:
	ldp	x20, x19, [sp, #448]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #432]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #416]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #400]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #384]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #368]            // 16-byte Folded Reload
	add	sp, sp, #464
	ret
.LBB182_128:
	sub	x12, x25, #2
	mul	x10, x14, x28
	cmp	x5, #2
	mov	w11, #2
	csel	x9, x5, x11, hi
	cmp	xzr, x12, lsr #61
	lsl	x16, x12, #3
	and	x12, x8, #0xfffffffffffffffc
	lsl	x13, x28, #3
	mul	x11, x10, x25
	lsl	x10, x10, #3
	stur	x9, [x29, #-176]                // 8-byte Folded Spill
	add	x13, x13, #8
	add	x10, x10, #8
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	stur	x12, [x29, #-112]               // 8-byte Folded Spill
	orr	x12, x12, #0x1
	mul	x13, x13, x25
	mul	x10, x10, x25
	lsl	x2, x25, #3
	add	x0, x9, #1
	add	x18, x11, #1
	stur	x12, [x29, #-120]               // 8-byte Folded Spill
	add	x12, x27, x9, lsl #3
	lsl	x9, x9, #3
	add	x3, x27, x11, lsl #3
	stp	x10, x13, [x29, #-96]           // 16-byte Folded Spill
	sub	x10, x14, #1
	mov	x17, xzr
	cset	w15, ne
	str	x9, [sp, #184]                  // 8-byte Folded Spill
	neg	x9, x9
	mul	x10, x10, x8
	add	x4, x12, #4
	add	x13, x27, x0, lsl #3
	add	x24, x27, x18, lsl #3
	str	x9, [sp, #176]                  // 8-byte Folded Spill
	add	x26, x3, #4
	ldur	x9, [x29, #-104]                // 8-byte Folded Reload
	str	x0, [sp, #144]                  // 8-byte Folded Spill
	add	x6, x9, x10, lsl #3
	mov	w10, #8
	sub	x9, x10, x2
	str	x9, [sp, #168]                  // 8-byte Folded Spill
	sub	x9, x2, #8
	stp	x18, x9, [sp, #152]             // 16-byte Folded Spill
	mov	w18, #1
	b	.LBB182_130
.LBB182_129:                            //   in Loop: Header=BB182_130 Depth=1
	ldp	x10, x9, [sp, #176]             // 16-byte Folded Reload
	ldp	x13, x17, [x29, #-136]          // 16-byte Folded Reload
	ldr	x11, [sp, #168]                 // 8-byte Folded Reload
	add	x3, x3, x10
	ldp	x18, x26, [x29, #-160]          // 16-byte Folded Reload
	add	x4, x4, x9
	add	x13, x13, x9
	add	x6, x6, x11
	ldr	x11, [sp, #160]                 // 8-byte Folded Reload
	ldur	x24, [x29, #-144]               // 8-byte Folded Reload
	add	x17, x17, #1
	ldp	x9, x14, [x29, #-176]           // 16-byte Folded Reload
	add	x18, x18, #1
	add	x20, x20, x11
	add	x24, x24, x10
	add	x26, x26, x10
	cmp	x18, x9
	stur	x20, [x29, #-104]               // 8-byte Folded Spill
	b.eq	.LBB182_125
.LBB182_130:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB182_157 Depth 2
                                        //     Child Loop BB182_132 Depth 2
                                        //       Child Loop BB182_148 Depth 3
                                        //       Child Loop BB182_135 Depth 3
	sub	x9, x14, #1
	cmp	x25, #1
	stp	x13, x17, [x29, #-136]          // 16-byte Folded Spill
	stp	x26, x24, [x29, #-152]          // 16-byte Folded Spill
	stp	x9, x18, [x29, #-168]           // 16-byte Folded Spill
	b.ls	.LBB182_156
// %bb.131:                             //   in Loop: Header=BB182_130 Depth=1
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mul	x18, x18, x28
	ldr	x11, [sp, #152]                 // 8-byte Folded Reload
	mul	x30, x14, x28
	mov	x21, xzr
	mov	x0, x4
	mul	x10, x9, x17
	mov	x14, x13
	msub	x12, x9, x17, x11
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	stur	x12, [x29, #-24]                // 8-byte Folded Spill
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	madd	x9, x9, x17, x12
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x12, x10
	stur	x9, [x29, #-56]                 // 8-byte Folded Spill
	sub	x9, x11, x10
	stur	x9, [x29, #-64]                 // 8-byte Folded Spill
.LBB182_132:                            //   Parent Loop BB182_130 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB182_148 Depth 3
                                        //       Child Loop BB182_135 Depth 3
	add	x13, x21, x18
	add	x17, x21, x30
	cmp	x8, #4
	mul	x13, x13, x25
	mul	x17, x17, x25
	add	x13, x27, x13, lsl #3
	add	x17, x27, x17, lsl #3
	ldp	s0, s1, [x13]
	ldp	s2, s3, [x17]
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	str	s4, [x13]
	str	s5, [x13, #4]
	str	s0, [x17]
	str	s1, [x17, #4]
	b.hs	.LBB182_137
.LBB182_133:                            //   in Loop: Header=BB182_132 Depth=2
	mov	w19, #1
.LBB182_134:                            //   in Loop: Header=BB182_132 Depth=2
	sub	x5, x25, x19
	lsl	x19, x19, #3
.LBB182_135:                            //   Parent Loop BB182_130 Depth=1
                                        //     Parent Loop BB182_132 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x9, x0, x19
	add	x11, x26, x19
	add	x12, x20, x19
	subs	x5, x5, #1
	ldp	s4, s0, [x9, #-4]
	ldp	s5, s1, [x11, #-4]
	fadd	s2, s0, s1
	fsub	s0, s0, s1
	ldp	s1, s3, [x12, #-8]
	add	x12, x6, x19
	fadd	s18, s4, s5
	fsub	s4, s4, s5
	add	x19, x19, #8
	fneg	s6, s2
	fneg	s7, s0
	ldp	s16, s17, [x12, #-8]
	fmul	s2, s1, s2
	fmul	s6, s3, s6
	fmul	s5, s17, s7
	fmul	s0, s0, s16
	fmadd	s2, s18, s3, s2
	fmadd	s1, s18, s1, s6
	fmadd	s3, s4, s16, s5
	fmadd	s0, s4, s17, s0
	str	s2, [x9]
	stur	s1, [x9, #-4]
	stur	s3, [x11, #-4]
	str	s0, [x11]
	b.ne	.LBB182_135
.LBB182_136:                            //   in Loop: Header=BB182_132 Depth=2
	add	x21, x21, #1
	add	x14, x14, x2
	add	x24, x24, x2
	add	x0, x0, x2
	add	x26, x26, x2
	cmp	x21, x28
	b.ne	.LBB182_132
	b	.LBB182_129
.LBB182_137:                            //   in Loop: Header=BB182_132 Depth=2
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	mul	x5, x21, x25
	add	x13, x9, x5
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #3
	add	x17, x9, x5
	add	x1, x13, #4
	add	x7, x27, x17, lsl #3
	add	x17, x1, x16
	add	x19, x7, #4
	cmp	x17, x1
	add	x17, x13, x16
	cset	w1, lo
	cmp	x17, x13
	add	x13, x19, x16
	cset	w17, lo
	cmp	x13, x19
	add	x13, x7, x16
	orr	w22, w1, w15
	cset	w1, lo
	cmp	x13, x7
	cset	w13, lo
	tbnz	w22, #0, .LBB182_150
// %bb.138:                             //   in Loop: Header=BB182_132 Depth=2
	orr	w17, w17, w15
	tbnz	w17, #0, .LBB182_150
// %bb.139:                             //   in Loop: Header=BB182_132 Depth=2
	orr	w17, w1, w15
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w17, #0, .LBB182_133
// %bb.140:                             //   in Loop: Header=BB182_132 Depth=2
	orr	w13, w13, w15
	mov	w19, #1
	tbnz	w13, #0, .LBB182_134
// %bb.141:                             //   in Loop: Header=BB182_132 Depth=2
	ldur	x9, [x29, #-56]                 // 8-byte Folded Reload
	add	x17, x10, x5
	add	x17, x27, x17, lsl #3
	add	x13, x9, x5
	ldur	x9, [x29, #-64]                 // 8-byte Folded Reload
	add	x13, x27, x13, lsl #3
	add	x1, x9, x5
	ldur	x9, [x29, #-88]                 // 8-byte Folded Reload
	sub	x5, x5, x10
	add	x28, x13, #4
	add	x1, x27, x1, lsl #3
	add	x17, x17, x9
	ldur	x9, [x29, #-96]                 // 8-byte Folded Reload
	add	x5, x27, x5, lsl #3
	sub	x7, x17, #4
	cmp	x17, x13
	add	x11, x1, #4
	add	x9, x5, x9
	cset	w5, hi
	sub	x27, x9, #4
	cmp	x7, x28
	cset	w19, hi
	cmp	x27, x13
	and	w12, w5, w19
	cset	w5, hi
	cmp	x7, x1
	cset	w22, hi
	cmp	x9, x13
	cset	w19, hi
	cmp	x7, x11
	cset	w25, hi
	cmp	x27, x28
	cset	w23, hi
	cmp	x17, x1
	cset	w7, hi
	cmp	x9, x28
	cset	w28, hi
	cmp	x17, x11
	cset	w13, hi
	cmp	x9, x1
	cset	w17, hi
	cmp	x27, x11
	cset	w1, hi
	tbnz	w12, #0, .LBB182_152
// %bb.142:                             //   in Loop: Header=BB182_132 Depth=2
	and	w9, w5, w22
	tbnz	w9, #0, .LBB182_152
// %bb.143:                             //   in Loop: Header=BB182_132 Depth=2
	and	w9, w19, w25
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB182_153
// %bb.144:                             //   in Loop: Header=BB182_132 Depth=2
	and	w9, w23, w7
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB182_154
// %bb.145:                             //   in Loop: Header=BB182_132 Depth=2
	and	w9, w28, w13
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	tbnz	w9, #0, .LBB182_151
// %bb.146:                             //   in Loop: Header=BB182_132 Depth=2
	and	w9, w17, w1
	mov	w19, #1
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	tbnz	w9, #0, .LBB182_134
// %bb.147:                             //   in Loop: Header=BB182_132 Depth=2
	ldur	x19, [x29, #-112]               // 8-byte Folded Reload
	mov	x28, x24
	mov	x22, x20
	mov	x23, x14
	mov	x5, x6
.LBB182_148:                            //   Parent Loop BB182_130 Depth=1
                                        //     Parent Loop BB182_132 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ld2	{ v0.4s, v1.4s }, [x23]
	subs	x19, x19, #4
	ld2	{ v2.4s, v3.4s }, [x28]
	ld2	{ v6.4s, v7.4s }, [x22], #32
	fadd	v4.4s, v1.4s, v3.4s
	fadd	v16.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fneg	v5.4s, v4.4s
	fmul	v17.4s, v7.4s, v5.4s
	fmla	v17.4s, v6.4s, v16.4s
	fmul	v18.4s, v6.4s, v4.4s
	fsub	v4.4s, v1.4s, v3.4s
	fmla	v18.4s, v7.4s, v16.4s
	fneg	v5.4s, v4.4s
	st2	{ v17.4s, v18.4s }, [x23], #32
	ld2	{ v1.4s, v2.4s }, [x5], #32
	fmul	v5.4s, v2.4s, v5.4s
	fmla	v5.4s, v1.4s, v0.4s
	fmul	v6.4s, v4.4s, v1.4s
	fmla	v6.4s, v2.4s, v0.4s
	st2	{ v5.4s, v6.4s }, [x28], #32
	b.ne	.LBB182_148
// %bb.149:                             //   in Loop: Header=BB182_132 Depth=2
	ldp	x19, x9, [x29, #-120]           // 16-byte Folded Reload
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	cmp	x8, x9
	b.ne	.LBB182_134
	b	.LBB182_136
.LBB182_150:                            //   in Loop: Header=BB182_132 Depth=2
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	b	.LBB182_133
.LBB182_151:                            //   in Loop: Header=BB182_132 Depth=2
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	mov	w19, #1
	b	.LBB182_134
.LBB182_152:                            //   in Loop: Header=BB182_132 Depth=2
	ldur	x27, [x29, #-32]                // 8-byte Folded Reload
	mov	w19, #1
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
	b	.LBB182_155
.LBB182_153:                            //   in Loop: Header=BB182_132 Depth=2
	ldur	x25, [x29, #-80]                // 8-byte Folded Reload
.LBB182_154:                            //   in Loop: Header=BB182_132 Depth=2
	mov	w19, #1
.LBB182_155:                            //   in Loop: Header=BB182_132 Depth=2
	ldur	x28, [x29, #-72]                // 8-byte Folded Reload
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
	b	.LBB182_134
.LBB182_156:                            //   in Loop: Header=BB182_130 Depth=1
	mov	x10, xzr
	mov	x11, x28
	ldur	x20, [x29, #-104]               // 8-byte Folded Reload
.LBB182_157:                            //   Parent Loop BB182_130 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x12, x4, x10
	add	x13, x3, x10
	subs	x11, x11, #1
	add	x10, x10, x2
	ldp	s0, s1, [x12, #-4]
	ldp	s2, s3, [x13]
	fadd	s4, s0, s2
	fadd	s5, s1, s3
	fsub	s0, s0, s2
	fsub	s1, s1, s3
	stp	s4, s5, [x12, #-4]
	stp	s0, s1, [x13]
	b.ne	.LBB182_157
	b	.LBB182_129
.LBB182_158:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end182:
	.size	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_, .Lfunc_end182-_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIfEEEEvmmmPT0_S7_PKS5_S9_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9pocketfft6detail11pocketfft_cIfED2Ev,"axG",@progbits,_ZN9pocketfft6detail11pocketfft_cIfED2Ev,comdat
	.weak	_ZN9pocketfft6detail11pocketfft_cIfED2Ev // -- Begin function _ZN9pocketfft6detail11pocketfft_cIfED2Ev
	.p2align	2
	.type	_ZN9pocketfft6detail11pocketfft_cIfED2Ev,@function
_ZN9pocketfft6detail11pocketfft_cIfED2Ev: // @_ZN9pocketfft6detail11pocketfft_cIfED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	ldr	x20, [x0, #8]
	cbz	x20, .LBB183_8
// %bb.1:
	ldr	x8, [x20, #64]
	cbz	x8, .LBB183_3
// %bb.2:
	ldur	x0, [x8, #-8]
	bl	free
.LBB183_3:
	ldr	x0, [x20, #40]
	cbz	x0, .LBB183_5
// %bb.4:
	bl	_ZdlPv
.LBB183_5:
	ldr	x8, [x20, #24]
	cbz	x8, .LBB183_7
// %bb.6:
	ldur	x0, [x8, #-8]
	bl	free
.LBB183_7:
	mov	x0, x20
	bl	_ZdlPv
.LBB183_8:
	ldr	x20, [x19]
	str	xzr, [x19, #8]
	cbz	x20, .LBB183_14
// %bb.9:
	ldr	x0, [x20, #24]
	cbz	x0, .LBB183_11
// %bb.10:
	bl	_ZdlPv
.LBB183_11:
	ldr	x8, [x20, #8]
	cbz	x8, .LBB183_13
// %bb.12:
	ldur	x0, [x8, #-8]
	bl	free
.LBB183_13:
	mov	x0, x20
	bl	_ZdlPv
.LBB183_14:
	str	xzr, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end183:
	.size	_ZN9pocketfft6detail11pocketfft_cIfED2Ev, .Lfunc_end183-_ZN9pocketfft6detail11pocketfft_cIfED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,"axG",@progbits,_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,comdat
	.weak	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv // -- Begin function _ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
	.p2align	2
	.type	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,@function
_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv: // @_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.Lfunc_begin57:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception57
// %bb.0:
	sub	sp, sp, #224
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	add	x29, sp, #160
	str	x23, [sp, #176]                 // 8-byte Folded Spill
	stp	x22, x21, [sp, #192]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x8, x9, [x0]
	mov	x19, x0
	ldp	x15, x10, [x8]
	ldr	x9, [x9]
	cmp	x15, x10
	b.eq	.LBB184_3
// %bb.1:
	sub	x11, x10, x15
	sub	x11, x11, #8
	cmp	x11, #8
	b.hs	.LBB184_4
// %bb.2:
	mov	w12, #1
	mov	x11, x15
	b	.LBB184_7
.LBB184_3:
	mov	w12, #1
	b	.LBB184_8
.LBB184_4:
	lsr	x11, x11, #3
	mov	w12, #1
	add	x13, x11, #1
	mov	w17, #1
	and	x14, x13, #0x3ffffffffffffffe
	mov	x16, x14
	add	x11, x15, x14, lsl #3
	add	x15, x15, #8
.LBB184_5:                              // =>This Inner Loop Header: Depth=1
	ldp	x18, x0, [x15, #-8]
	add	x15, x15, #16
	subs	x16, x16, #2
	mul	x12, x18, x12
	mul	x17, x0, x17
	b.ne	.LBB184_5
// %bb.6:
	mul	x12, x17, x12
	cmp	x13, x14
	b.eq	.LBB184_8
.LBB184_7:                              // =>This Inner Loop Header: Depth=1
	ldr	x13, [x11], #8
	cmp	x11, x10
	mul	x12, x13, x12
	b.ne	.LBB184_7
.LBB184_8:
	udiv	x10, x12, x9
	cmp	x10, #4
	mov	w10, #4
	csinc	x10, x10, xzr, hs
	mul	x9, x9, x10
	lsl	x9, x9, #3
	cbz	x9, .LBB184_11
// %bb.9:
	add	x0, x9, #64
	bl	malloc
	cbz	x0, .LBB184_45
// %bb.10:
	add	x8, x0, #64
	and	x20, x8, #0xffffffffffffffc0
	stur	x0, [x20, #-8]
	ldr	x8, [x19]
	b	.LBB184_12
.LBB184_11:
	mov	x20, xzr
.LBB184_12:
	ldp	x9, x2, [x19, #16]
	ldr	x10, [x19, #32]
	ldr	x9, [x9]
	ldr	x10, [x10]
	cmp	x9, #0
	ldr	x3, [x10, x9, lsl #3]
	csel	x21, x8, x2, eq
.Ltmp781:
	add	x0, sp, #8
	mov	x1, x21
	bl	_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m
.Ltmp782:
// %bb.13:
	ldr	x8, [sp, #152]
	cmp	x8, #4
	b.lo	.LBB184_24
// %bb.14:
	add	x22, x20, #16
	b	.LBB184_16
.LBB184_15:                             //   in Loop: Header=BB184_16 Depth=1
	ldr	x8, [sp, #152]
	cmp	x8, #3
	b.ls	.LBB184_24
.LBB184_16:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB184_19 Depth 2
                                        //     Child Loop BB184_23 Depth 2
.Ltmp784:
	add	x0, sp, #8
	mov	w1, #4
	bl	_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm
.Ltmp785:
// %bb.17:                              //   in Loop: Header=BB184_16 Depth=1
	ldr	x9, [sp, #32]
	ldp	x8, x10, [x19, #40]
	ldr	x11, [sp, #144]
	ldr	x9, [x9]
	ldr	x12, [x19, #56]
	ldr	x9, [x9, x11, lsl #3]
	ldr	x23, [x19, #24]
	ldr	x0, [x10]
	ldr	s0, [x12]
	cbz	x9, .LBB184_20
// %bb.18:                              //   in Loop: Header=BB184_16 Depth=1
	ldp	x12, x13, [sp, #56]
	mov	x15, x22
	ldp	x16, x10, [sp, #80]
	ldr	x11, [x21, #48]
	add	x12, x12, #4
	add	x13, x13, #4
	ldr	x14, [sp, #72]
.LBB184_19:                             //   Parent Loop BB184_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x17, x11, x12
	add	x18, x11, x13
	sub	x1, x18, #4
	add	x2, x11, x16
	subs	x9, x9, #1
	ldp	s1, s2, [x17, #-4]
	ld1	{ v1.s }[1], [x1]
	add	x1, x11, x14
	add	x11, x11, x10
	ld1	{ v1.s }[2], [x1], #4
	ld1	{ v1.s }[3], [x2], #4
	ld1	{ v2.s }[1], [x18]
	ld1	{ v2.s }[2], [x1]
	ld1	{ v2.s }[3], [x2]
	stp	q1, q2, [x15, #-16]
	add	x15, x15, #32
	b.ne	.LBB184_19
.LBB184_20:                             //   in Loop: Header=BB184_16 Depth=1
	ldrb	w2, [x8]
.Ltmp787:
	mov	x1, x20
	bl	_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb
.Ltmp788:
// %bb.21:                              //   in Loop: Header=BB184_16 Depth=1
	ldr	x8, [sp, #40]
	ldr	x9, [sp, #144]
	ldr	x8, [x8]
	ldr	x8, [x8, x9, lsl #3]
	cbz	x8, .LBB184_15
// %bb.22:                              //   in Loop: Header=BB184_16 Depth=1
	ldp	x12, x11, [sp, #104]
	mov	x14, x22
	ldp	x15, x9, [sp, #128]
	ldr	x10, [x23, #48]
	add	x12, x12, #4
	ldr	x13, [sp, #120]
.LBB184_23:                             //   Parent Loop BB184_16 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x14, #-16]
	add	x16, x10, x12
	subs	x8, x8, #1
	add	x14, x14, #32
	ext	v3.16b, v1.16b, v1.16b, #8
	ext	v2.16b, v0.16b, v0.16b, #8
	zip1	v4.2s, v1.2s, v0.2s
	zip2	v0.2s, v1.2s, v0.2s
	zip1	v1.2s, v3.2s, v2.2s
	zip2	v2.2s, v3.2s, v2.2s
	stur	d4, [x16, #-4]
	str	d0, [x10, x11]
	str	d1, [x10, x13]
	str	d2, [x10, x15]
	add	x10, x10, x9
	b.ne	.LBB184_23
	b	.LBB184_15
.LBB184_24:
	cbnz	x8, .LBB184_31
.LBB184_25:
	ldr	x0, [sp, #8]
	cbz	x0, .LBB184_27
// %bb.26:
	bl	_ZdlPv
.LBB184_27:
	cbz	x20, .LBB184_29
// %bb.28:
	ldur	x0, [x20, #-8]
	bl	free
.LBB184_29:
	ldp	x20, x19, [sp, #208]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldr	x23, [sp, #176]                 // 8-byte Folded Reload
	add	sp, sp, #224
	ret
.LBB184_30:                             //   in Loop: Header=BB184_31 Depth=1
	ldr	x8, [sp, #152]
	cbz	x8, .LBB184_25
.LBB184_31:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB184_38 Depth 2
                                        //     Child Loop BB184_44 Depth 2
.Ltmp790:
	add	x0, sp, #8
	mov	w1, #1
	bl	_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm
.Ltmp791:
// %bb.32:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x8, [x19, #64]
	mov	x22, x20
	ldr	x23, [x19, #24]
	ldrb	w8, [x8]
	cbz	w8, .LBB184_35
// %bb.33:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x8, [sp, #136]
	mov	x22, x20
	cmp	x8, #8
	b.ne	.LBB184_35
// %bb.34:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x8, [sp, #104]
	ldr	x9, [x23, #48]
	add	x22, x9, x8
.LBB184_35:                             //   in Loop: Header=BB184_31 Depth=1
	ldp	x9, x10, [x19, #48]
	ldr	x13, [sp, #56]
	ldr	x14, [x21, #48]
	ldr	x8, [x19, #40]
	ldr	x0, [x9]
	ldr	s0, [x10]
	add	x9, x14, x13
	cmp	x9, x22
	b.eq	.LBB184_39
// %bb.36:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x9, [sp, #32]
	ldr	x10, [sp, #144]
	ldr	x11, [x9]
	ldr	x11, [x11, x10, lsl #3]
	cbz	x11, .LBB184_39
// %bb.37:                              //   in Loop: Header=BB184_31 Depth=1
	mov	x11, xzr
	ldr	x12, [sp, #88]
	add	x13, x14, x13
.LBB184_38:                             //   Parent Loop BB184_31 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x14, [x13]
	add	x13, x13, x12
	str	x14, [x22, x11, lsl #3]
	add	x11, x11, #1
	ldr	x14, [x9]
	ldr	x14, [x14, x10, lsl #3]
	cmp	x11, x14
	b.lo	.LBB184_38
.LBB184_39:                             //   in Loop: Header=BB184_31 Depth=1
	ldrb	w2, [x8]
.Ltmp793:
	mov	x1, x22
	bl	_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb
.Ltmp794:
// %bb.40:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x8, [sp, #104]
	ldr	x9, [x23, #48]
	add	x8, x9, x8
	cmp	x8, x22
	b.eq	.LBB184_30
// %bb.41:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x9, [sp, #40]
	ldr	x10, [sp, #144]
	ldr	x9, [x9]
	ldr	x9, [x9, x10, lsl #3]
	cbz	x9, .LBB184_30
// %bb.42:                              //   in Loop: Header=BB184_31 Depth=1
	ldr	x9, [x22]
	str	x9, [x8]
	ldr	x8, [sp, #40]
	ldr	x9, [sp, #144]
	ldr	x8, [x8]
	ldr	x8, [x8, x9, lsl #3]
	cmp	x8, #2
	b.lo	.LBB184_30
// %bb.43:                              //   in Loop: Header=BB184_31 Depth=1
	mov	w8, #1
.LBB184_44:                             //   Parent Loop BB184_31 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x9, [sp, #104]
	ldr	x10, [sp, #136]
	ldr	x11, [x23, #48]
	madd	x9, x10, x8, x9
	ldr	x10, [x22, x8, lsl #3]
	add	x8, x8, #1
	str	x10, [x11, x9]
	ldr	x9, [sp, #40]
	ldr	x10, [sp, #144]
	ldr	x9, [x9]
	ldr	x9, [x9, x10, lsl #3]
	cmp	x8, x9
	b.lo	.LBB184_44
	b	.LBB184_30
.LBB184_45:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB184_46:
.Ltmp783:
	mov	x19, x0
	cbz	x20, .LBB184_53
	b	.LBB184_55
.LBB184_47:
.Ltmp789:
	b	.LBB184_51
.LBB184_48:
.Ltmp786:
	b	.LBB184_51
.LBB184_49:
.Ltmp795:
	b	.LBB184_51
.LBB184_50:
.Ltmp792:
.LBB184_51:
	mov	x19, x0
	ldr	x0, [sp, #8]
	cbnz	x0, .LBB184_54
// %bb.52:
	cbnz	x20, .LBB184_55
.LBB184_53:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB184_54:
	bl	_ZdlPv
	cbz	x20, .LBB184_53
.LBB184_55:
	ldur	x0, [x20, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end184:
	.size	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv, .Lfunc_end184-_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
	.cfi_endproc
	.section	.gcc_except_table._ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,"aG",@progbits,_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv,comdat
	.p2align	2
GCC_except_table184:
.Lexception57:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end57-.Lcst_begin57
.Lcst_begin57:
	.uleb128 .Ltmp781-.Lfunc_begin57        // >> Call Site 1 <<
	.uleb128 .Ltmp782-.Ltmp781              //   Call between .Ltmp781 and .Ltmp782
	.uleb128 .Ltmp783-.Lfunc_begin57        //     jumps to .Ltmp783
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp784-.Lfunc_begin57        // >> Call Site 2 <<
	.uleb128 .Ltmp785-.Ltmp784              //   Call between .Ltmp784 and .Ltmp785
	.uleb128 .Ltmp786-.Lfunc_begin57        //     jumps to .Ltmp786
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp787-.Lfunc_begin57        // >> Call Site 3 <<
	.uleb128 .Ltmp788-.Ltmp787              //   Call between .Ltmp787 and .Ltmp788
	.uleb128 .Ltmp789-.Lfunc_begin57        //     jumps to .Ltmp789
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp790-.Lfunc_begin57        // >> Call Site 4 <<
	.uleb128 .Ltmp791-.Ltmp790              //   Call between .Ltmp790 and .Ltmp791
	.uleb128 .Ltmp792-.Lfunc_begin57        //     jumps to .Ltmp792
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp793-.Lfunc_begin57        // >> Call Site 5 <<
	.uleb128 .Ltmp794-.Ltmp793              //   Call between .Ltmp793 and .Ltmp794
	.uleb128 .Ltmp795-.Lfunc_begin57        //     jumps to .Ltmp795
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp794-.Lfunc_begin57        // >> Call Site 6 <<
	.uleb128 .Lfunc_end184-.Ltmp794         //   Call between .Ltmp794 and .Lfunc_end184
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end57:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m,"axG",@progbits,_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m,comdat
	.weak	_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m // -- Begin function _ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m
	.p2align	2
	.type	_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m,@function
_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m: // @_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m
.Lfunc_begin58:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception58
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x10, x9, [x1]
	mov	x8, #-7
	movk	x8, #32767, lsl #48
	sub	x24, x9, x10
	cmp	x24, x8
	b.hs	.LBB185_22
// %bb.1:
	mov	x20, x3
	mov	x23, x2
	mov	x22, x1
	mov	x19, x0
	stp	xzr, xzr, [x0]
	str	xzr, [x0, #16]
	cbz	x24, .LBB185_3
// %bb.2:
	mov	x0, x24
	asr	x25, x24, #3
	bl	_Znwm
	and	x2, x24, #0xfffffffffffffff8
	add	x24, x0, x25, lsl #3
	mov	w1, wzr
	mov	x21, x0
	str	x0, [x19]
	str	x24, [x19, #16]
	bl	memset
	b	.LBB185_4
.LBB185_3:
	mov	x21, xzr
	stp	xzr, xzr, [x19]
	str	xzr, [x19, #16]
.LBB185_4:
	stp	x22, x23, [x19, #24]
	lsl	x10, x20, #3
	ldr	x8, [x22, #24]
	str	xzr, [x19, #40]
	ldr	x9, [x23, #24]
	str	x24, [x19, #8]
	ldr	x11, [x8, x10]
	stp	x11, xzr, [x19, #80]
	ldr	x12, [x9, x10]
	ldp	x10, x11, [x22]
	stp	x12, x20, [x19, #128]
	cmp	x10, x11
	b.eq	.LBB185_7
// %bb.5:
	sub	x12, x11, x10
	sub	x12, x12, #8
	cmp	x12, #8
	b.hs	.LBB185_8
// %bb.6:
	mov	w13, #1
	mov	x12, x10
	b	.LBB185_11
.LBB185_7:
	mov	w13, #1
	b	.LBB185_12
.LBB185_8:
	lsr	x12, x12, #3
	add	x16, x10, #8
	add	x14, x12, #1
	mov	w13, #1
	and	x15, x14, #0x3ffffffffffffffe
	mov	w18, #1
	mov	x17, x15
	add	x12, x10, x15, lsl #3
.LBB185_9:                              // =>This Inner Loop Header: Depth=1
	ldp	x0, x1, [x16, #-8]
	add	x16, x16, #16
	subs	x17, x17, #2
	mul	x13, x0, x13
	mul	x18, x1, x18
	b.ne	.LBB185_9
// %bb.10:
	mul	x13, x18, x13
	cmp	x14, x15
	b.eq	.LBB185_12
.LBB185_11:                             // =>This Inner Loop Header: Depth=1
	ldr	x14, [x12], #8
	cmp	x12, x11
	mul	x13, x14, x13
	b.ne	.LBB185_11
.LBB185_12:
	ldr	x11, [x10, x20, lsl #3]
	mrs	x14, TPIDR_EL0
	add	x12, x14, :tprel_hi12:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	add	x12, x12, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	udiv	x11, x13, x11
	ldr	x12, [x12]
	cmp	x12, #1
	str	x11, [x19, #144]
	b.eq	.LBB185_21
// %bb.13:
	cbz	x12, .LBB185_23
// %bb.14:
	add	x13, x14, :tprel_hi12:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x13, x13, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	ldr	x15, [x13]
	cmp	x15, x12
	b.hs	.LBB185_25
// %bb.15:
	udiv	x16, x11, x12
	msub	x17, x16, x12, x11
	cmp	x15, x17
	cinc	x12, x16, lo
	subs	x18, x24, x21
	b.eq	.LBB185_20
// %bb.16:
	cmp	x15, x17
	asr	x18, x18, #3
	csel	x17, x15, x17, lo
	cmp	x18, #1
	madd	x15, x16, x15, x17
	mov	x13, xzr
	mov	x14, xzr
	csinc	x16, x18, xzr, hi
	b	.LBB185_18
.LBB185_17:                             //   in Loop: Header=BB185_18 Depth=1
	sub	x16, x16, #1
	sub	x20, x20, #1
	add	x10, x10, #8
	add	x21, x21, #8
	add	x8, x8, #8
	add	x9, x9, #8
	cbz	x16, .LBB185_20
.LBB185_18:                             // =>This Inner Loop Header: Depth=1
	cbz	x20, .LBB185_17
// %bb.19:                              //   in Loop: Header=BB185_18 Depth=1
	ldr	x17, [x10]
	ldr	x18, [x21]
	udiv	x11, x11, x17
	udiv	x17, x15, x11
	add	x18, x18, x17
	msub	x15, x17, x11, x15
	str	x18, [x21]
	ldr	x18, [x8]
	madd	x14, x18, x17, x14
	str	x14, [x19, #40]
	ldr	x18, [x9]
	madd	x13, x18, x17, x13
	str	x13, [x19, #88]
	b	.LBB185_17
.LBB185_20:
	str	x12, [x19, #144]
.LBB185_21:
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB185_22:
	adrp	x0, .L.str
	add	x0, x0, :lo12:.L.str
	bl	_ZSt20__throw_length_errorPKc
.LBB185_23:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp796:
	adrp	x1, .L.str.9
	add	x1, x1, :lo12:.L.str.9
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp797:
// %bb.24:
.Ltmp799:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp800:
	b	.LBB185_27
.LBB185_25:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x21, x0
.Ltmp802:
	adrp	x1, .L.str.10
	add	x1, x1, :lo12:.L.str.10
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp803:
// %bb.26:
.Ltmp805:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x21
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.Ltmp806:
.LBB185_27:
.LBB185_28:
.Ltmp807:
	b	.LBB185_31
.LBB185_29:
.Ltmp804:
	b	.LBB185_33
.LBB185_30:
.Ltmp801:
.LBB185_31:
	mov	x20, x0
	b	.LBB185_34
.LBB185_32:
.Ltmp798:
.LBB185_33:
	mov	x20, x0
	mov	x0, x21
	bl	__cxa_free_exception
.LBB185_34:
	ldr	x0, [x19]
	cbz	x0, .LBB185_36
// %bb.35:
	bl	_ZdlPv
.LBB185_36:
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end185:
	.size	_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m, .Lfunc_end185-_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m,"aG",@progbits,_ZN9pocketfft6detail10multi_iterILm4EEC2ERKNS0_8arr_infoES5_m,comdat
	.p2align	2
GCC_except_table185:
.Lexception58:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end58-.Lcst_begin58
.Lcst_begin58:
	.uleb128 .Lfunc_begin58-.Lfunc_begin58  // >> Call Site 1 <<
	.uleb128 .Ltmp796-.Lfunc_begin58        //   Call between .Lfunc_begin58 and .Ltmp796
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp796-.Lfunc_begin58        // >> Call Site 2 <<
	.uleb128 .Ltmp797-.Ltmp796              //   Call between .Ltmp796 and .Ltmp797
	.uleb128 .Ltmp798-.Lfunc_begin58        //     jumps to .Ltmp798
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp799-.Lfunc_begin58        // >> Call Site 3 <<
	.uleb128 .Ltmp800-.Ltmp799              //   Call between .Ltmp799 and .Ltmp800
	.uleb128 .Ltmp801-.Lfunc_begin58        //     jumps to .Ltmp801
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp800-.Lfunc_begin58        // >> Call Site 4 <<
	.uleb128 .Ltmp802-.Ltmp800              //   Call between .Ltmp800 and .Ltmp802
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp802-.Lfunc_begin58        // >> Call Site 5 <<
	.uleb128 .Ltmp803-.Ltmp802              //   Call between .Ltmp802 and .Ltmp803
	.uleb128 .Ltmp804-.Lfunc_begin58        //     jumps to .Ltmp804
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp805-.Lfunc_begin58        // >> Call Site 6 <<
	.uleb128 .Ltmp806-.Ltmp805              //   Call between .Ltmp805 and .Ltmp806
	.uleb128 .Ltmp807-.Lfunc_begin58        //     jumps to .Ltmp807
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp806-.Lfunc_begin58        // >> Call Site 7 <<
	.uleb128 .Lfunc_end185-.Ltmp806         //   Call between .Ltmp806 and .Lfunc_end185
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end58:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9pocketfft6detail10multi_iterILm4EE7advanceEm,"axG",@progbits,_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm,comdat
	.weak	_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm // -- Begin function _ZN9pocketfft6detail10multi_iterILm4EE7advanceEm
	.p2align	2
	.type	_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm,@function
_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm: // @_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm
.Lfunc_begin59:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception59
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x8, [x0, #144]
	cmp	x8, x1
	b.lo	.LBB186_13
// %bb.1:
	cbz	x1, .LBB186_12
// %bb.2:
	ldp	x8, x9, [x0]
	sub	x10, x9, x8
	lsr	x9, x10, #3
	cmp	w9, #0
	b.le	.LBB186_10
// %bb.3:
	ubfx	x10, x10, #3, #32
	mov	x9, xzr
	add	x10, x10, #1
	b	.LBB186_5
.LBB186_4:                              //   in Loop: Header=BB186_5 Depth=1
	add	x9, x9, #1
	cmp	x9, x1
	b.eq	.LBB186_12
.LBB186_5:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB186_8 Depth 2
	ldr	x11, [x0, #40]
	add	x12, x0, x9, lsl #3
	mov	x13, x10
	str	x11, [x12, #48]
	ldr	x11, [x0, #88]
	str	x11, [x12, #96]
	ldp	x11, x12, [x0, #24]
	b	.LBB186_8
.LBB186_6:                              //   in Loop: Header=BB186_8 Depth=2
	str	xzr, [x8, x14]
	ldr	x17, [x17, x14]
	ldr	x16, [x16, x14]
	ldr	x18, [x0, #40]
	msub	x16, x16, x17, x18
	ldr	x17, [x12]
	str	x16, [x0, #40]
	ldr	x16, [x17, x14]
	ldr	x14, [x15, x14]
	ldr	x15, [x0, #88]
	msub	x14, x14, x16, x15
	str	x14, [x0, #88]
.LBB186_7:                              //   in Loop: Header=BB186_8 Depth=2
	sub	x13, x13, #1
	cmp	x13, #1
	b.ls	.LBB186_4
.LBB186_8:                              //   Parent Loop BB186_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x15, [x0, #136]
	sub	w14, w13, #2
	cmp	x15, x14
	b.eq	.LBB186_7
// %bb.9:                               //   in Loop: Header=BB186_8 Depth=2
	lsl	x14, x14, #3
	ldr	x16, [x11, #24]
	ldr	x17, [x0, #40]
	ldr	x18, [x0, #88]
	ldr	x15, [x16, x14]
	add	x17, x17, x15
	ldr	x15, [x12, #24]
	str	x17, [x0, #40]
	ldr	x17, [x15, x14]
	add	x17, x18, x17
	str	x17, [x0, #88]
	ldr	x17, [x8, x14]
	add	x18, x17, #1
	ldr	x17, [x11]
	str	x18, [x8, x14]
	ldr	x2, [x17, x14]
	cmp	x18, x2
	b.hs	.LBB186_6
	b	.LBB186_4
.LBB186_10:
	add	x8, x0, #48
	mov	x9, x1
.LBB186_11:                             // =>This Inner Loop Header: Depth=1
	ldr	x10, [x0, #40]
	subs	x9, x9, #1
	str	x10, [x8]
	ldr	x10, [x0, #88]
	str	x10, [x8, #48]
	add	x8, x8, #8
	b.ne	.LBB186_11
.LBB186_12:
	ldr	x8, [x0, #144]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	sub	x8, x8, x1
	str	x8, [x0, #144]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB186_13:
	mov	w0, #16
	bl	__cxa_allocate_exception
	mov	x19, x0
.Ltmp808:
	adrp	x1, .L.str.11
	add	x1, x1, :lo12:.L.str.11
	bl	_ZNSt13runtime_errorC1EPKc
.Ltmp809:
// %bb.14:
	adrp	x1, :got:_ZTISt13runtime_error
	adrp	x2, :got:_ZNSt13runtime_errorD1Ev
	mov	x0, x19
	ldr	x1, [x1, :got_lo12:_ZTISt13runtime_error]
	ldr	x2, [x2, :got_lo12:_ZNSt13runtime_errorD1Ev]
	bl	__cxa_throw
.LBB186_15:
.Ltmp810:
	mov	x20, x0
	mov	x0, x19
	bl	__cxa_free_exception
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end186:
	.size	_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm, .Lfunc_end186-_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm
	.cfi_endproc
	.section	.gcc_except_table._ZN9pocketfft6detail10multi_iterILm4EE7advanceEm,"aG",@progbits,_ZN9pocketfft6detail10multi_iterILm4EE7advanceEm,comdat
	.p2align	2
GCC_except_table186:
.Lexception59:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end59-.Lcst_begin59
.Lcst_begin59:
	.uleb128 .Lfunc_begin59-.Lfunc_begin59  // >> Call Site 1 <<
	.uleb128 .Ltmp808-.Lfunc_begin59        //   Call between .Lfunc_begin59 and .Ltmp808
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp808-.Lfunc_begin59        // >> Call Site 2 <<
	.uleb128 .Ltmp809-.Ltmp808              //   Call between .Ltmp808 and .Ltmp809
	.uleb128 .Ltmp810-.Lfunc_begin59        //     jumps to .Ltmp810
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp809-.Lfunc_begin59        // >> Call Site 3 <<
	.uleb128 .Lfunc_end186-.Ltmp809         //   Call between .Ltmp809 and .Lfunc_end186
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end59:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb,"axG",@progbits,_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb,comdat
	.weak	_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb // -- Begin function _ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb
	.p2align	2
	.type	_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb,@function
_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb: // @_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	ldr	x0, [x0]
	cbz	x0, .LBB187_3
// %bb.1:
	tbz	w2, #0, .LBB187_5
// %bb.2:
	b	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f
.LBB187_3:
	ldr	x0, [x8, #8]
	tbz	w2, #0, .LBB187_6
// %bb.4:
	b	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf
.LBB187_5:
	b	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f
.LBB187_6:
	b	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf
.Lfunc_end187:
	.size	_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb, .Lfunc_end187-_ZNK9pocketfft6detail11pocketfft_cIfE4execIDv4_fEEvPNS0_5cmplxIT_EEfb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f // -- Begin function _ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,@function
_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f: // @_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f
.Lfunc_begin60:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception60
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	ldr	x23, [x0]
	mov	x20, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB188_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB188_4
// %bb.2:
	ldp	q0, q1, [x20]
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.4s, v0.4s, v2.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	stp	q0, q1, [x20]
	b	.LBB188_31
.LBB188_3:
	mov	x22, xzr
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.ne	.LBB188_6
	b	.LBB188_23
.LBB188_4:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB188_32
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.eq	.LBB188_23
.LBB188_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI188_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x20
	add	x27, x27, :lo12:.LJTI188_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB188_12
.LBB188_7:
	adr	x10, .LBB188_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB188_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp819:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp820:
	mov	x0, x21
	mov	x21, x22
	b	.LBB188_16
.LBB188_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp817:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp818:
	mov	x0, x21
	mov	x21, x22
	b	.LBB188_16
.LBB188_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp823:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp824:
	mov	x0, x21
	mov	x21, x22
	b	.LBB188_16
.LBB188_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp815:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp816:
	mov	x0, x21
	mov	x21, x22
	b	.LBB188_16
.LBB188_12:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp825:
	mov	x0, x19
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
.Ltmp826:
	mov	x0, x22
	b	.LBB188_16
.LBB188_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp813:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp814:
	mov	x0, x21
	mov	x21, x22
	b	.LBB188_16
.LBB188_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp821:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp822:
	mov	x0, x21
	mov	x21, x22
	b	.LBB188_16
.LBB188_15:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp811:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp812:
	mov	x0, x21
	mov	x21, x22
.LBB188_16:
	ldp	x8, x9, [x19, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB188_18
// %bb.17:
	ldr	x23, [x19]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB188_7
	b	.LBB188_12
.LBB188_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x20
	b.eq	.LBB188_23
// %bb.19:
	fmov	s0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x19]
	fcmp	s2, s0
	b.eq	.LBB188_27
// %bb.20:
	cbz	x8, .LBB188_29
// %bb.21:
	mov	x8, xzr
	add	x9, x20, #16
	add	x10, x22, #16
.LBB188_22:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-16]
	add	x8, x8, #1
	add	x10, x10, #32
	fmul	v0.4s, v0.4s, v2.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x11, [x19]
	cmp	x8, x11
	b.lo	.LBB188_22
	b	.LBB188_30
.LBB188_23:
	fmov	s0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fcmp	s2, s0
	b.eq	.LBB188_29
// %bb.24:
	ldr	x8, [x19]
	cbz	x8, .LBB188_29
// %bb.25:
	mov	x8, xzr
	add	x9, x20, #16
.LBB188_26:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	fmul	v0.4s, v0.4s, v2.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x10, [x19]
	cmp	x8, x10
	b.lo	.LBB188_26
	b	.LBB188_29
.LBB188_27:
	cbz	x8, .LBB188_29
// %bb.28:
	lsl	x2, x8, #5
	mov	x0, x20
	mov	x1, x21
	bl	memmove
.LBB188_29:
	cbz	x22, .LBB188_31
.LBB188_30:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB188_31:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB188_32:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB188_33:
.Ltmp827:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB188_35
// %bb.34:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB188_35:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end188:
	.size	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f, .Lfunc_end188-_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,comdat
.LJTI188_0:
	.byte	(.LBB188_8-.LBB188_8)>>2
	.byte	(.LBB188_9-.LBB188_8)>>2
	.byte	(.LBB188_10-.LBB188_8)>>2
	.byte	(.LBB188_11-.LBB188_8)>>2
	.byte	(.LBB188_12-.LBB188_8)>>2
	.byte	(.LBB188_13-.LBB188_8)>>2
	.byte	(.LBB188_14-.LBB188_8)>>2
	.byte	(.LBB188_12-.LBB188_8)>>2
	.byte	(.LBB188_12-.LBB188_8)>>2
	.byte	(.LBB188_15-.LBB188_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f,comdat
	.p2align	2
GCC_except_table188:
.Lexception60:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end60-.Lcst_begin60
.Lcst_begin60:
	.uleb128 .Ltmp819-.Lfunc_begin60        // >> Call Site 1 <<
	.uleb128 .Ltmp812-.Ltmp819              //   Call between .Ltmp819 and .Ltmp812
	.uleb128 .Ltmp827-.Lfunc_begin60        //     jumps to .Ltmp827
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp812-.Lfunc_begin60        // >> Call Site 2 <<
	.uleb128 .Lfunc_end188-.Ltmp812         //   Call between .Ltmp812 and .Lfunc_end188
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end60:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f // -- Begin function _ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,@function
_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f: // @_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f
.Lfunc_begin61:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception61
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	ldr	x23, [x0]
	mov	x20, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	cbz	x23, .LBB189_3
// %bb.1:
	cmp	x23, #1
	b.ne	.LBB189_4
// %bb.2:
	ldp	q0, q1, [x20]
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fmul	v0.4s, v0.4s, v2.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	stp	q0, q1, [x20]
	b	.LBB189_31
.LBB189_3:
	mov	x22, xzr
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.ne	.LBB189_6
	b	.LBB189_23
.LBB189_4:
	lsl	x8, x23, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB189_32
// %bb.5:
	add	x8, x0, #64
	and	x22, x8, #0xffffffffffffffc0
	stur	x0, [x22, #-8]
	ldp	x8, x9, [x19, #24]
	cmp	x9, x8
	b.eq	.LBB189_23
.LBB189_6:
	mov	x26, #-6148914691236517206
	adrp	x27, .LJTI189_0
	mov	x24, xzr
	mov	w25, #1
	movk	x26, #43691
	mov	w3, #1
	mov	x21, x20
	add	x27, x27, :lo12:.LJTI189_0
	str	x22, [sp, #8]                   // 8-byte Folded Spill
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.hi	.LBB189_12
.LBB189_7:
	adr	x10, .LBB189_8
	ldrb	w11, [x27, x9]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB189_8:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp836:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp837:
	mov	x0, x21
	mov	x21, x22
	b	.LBB189_16
.LBB189_9:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp834:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp835:
	mov	x0, x21
	mov	x21, x22
	b	.LBB189_16
.LBB189_10:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp840:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp841:
	mov	x0, x21
	mov	x21, x22
	b	.LBB189_16
.LBB189_11:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp832:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp833:
	mov	x0, x21
	mov	x21, x22
	b	.LBB189_16
.LBB189_12:
	add	x8, x8, x24
	ldp	x6, x7, [x8, #8]
.Ltmp842:
	mov	x0, x19
	mov	x4, x21
	mov	x5, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
.Ltmp843:
	mov	x0, x22
	b	.LBB189_16
.LBB189_13:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp830:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp831:
	mov	x0, x21
	mov	x21, x22
	b	.LBB189_16
.LBB189_14:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp838:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp839:
	mov	x0, x21
	mov	x21, x22
	b	.LBB189_16
.LBB189_15:
	add	x8, x8, x24
	ldr	x5, [x8, #8]
.Ltmp828:
	mov	x0, x19
	mov	x2, x3
	mov	x3, x21
	mov	x4, x22
	bl	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
.Ltmp829:
	mov	x0, x21
	mov	x21, x22
.LBB189_16:
	ldp	x8, x9, [x19, #24]
	sub	x9, x9, x8
	asr	x9, x9, #3
	mul	x9, x9, x26
	cmp	x25, x9
	b.hs	.LBB189_18
// %bb.17:
	ldr	x23, [x19]
	add	x25, x25, #1
	add	x24, x24, #24
	mov	x3, x28
	mov	x22, x0
	ldr	x2, [x8, x24]
	mul	x28, x2, x3
	sub	x9, x2, #2
	cmp	x9, #9
	udiv	x1, x23, x28
	b.ls	.LBB189_7
	b	.LBB189_12
.LBB189_18:
	ldr	x22, [sp, #8]                   // 8-byte Folded Reload
	cmp	x21, x20
	b.eq	.LBB189_23
// %bb.19:
	fmov	s0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	ldr	x8, [x19]
	fcmp	s2, s0
	b.eq	.LBB189_27
// %bb.20:
	cbz	x8, .LBB189_29
// %bb.21:
	mov	x8, xzr
	add	x9, x20, #16
	add	x10, x22, #16
.LBB189_22:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-16]
	add	x8, x8, #1
	add	x10, x10, #32
	fmul	v0.4s, v0.4s, v2.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x11, [x19]
	cmp	x8, x11
	b.lo	.LBB189_22
	b	.LBB189_30
.LBB189_23:
	fmov	s0, #1.00000000
	ldr	q2, [sp, #16]                   // 16-byte Folded Reload
	fcmp	s2, s0
	b.eq	.LBB189_29
// %bb.24:
	ldr	x8, [x19]
	cbz	x8, .LBB189_29
// %bb.25:
	mov	x8, xzr
	add	x9, x20, #16
.LBB189_26:                             // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	fmul	v0.4s, v0.4s, v2.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	stp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	ldr	x10, [x19]
	cmp	x8, x10
	b.lo	.LBB189_26
	b	.LBB189_29
.LBB189_27:
	cbz	x8, .LBB189_29
// %bb.28:
	lsl	x2, x8, #5
	mov	x0, x20
	mov	x1, x21
	bl	memmove
.LBB189_29:
	cbz	x22, .LBB189_31
.LBB189_30:
	ldur	x0, [x22, #-8]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	b	free
.LBB189_31:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB189_32:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB189_33:
.Ltmp844:
	mov	x19, x0
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	cbz	x8, .LBB189_35
// %bb.34:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldur	x0, [x8, #-8]
	bl	free
.LBB189_35:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end189:
	.size	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f, .Lfunc_end189-_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f
	.cfi_endproc
	.section	.rodata._ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,comdat
.LJTI189_0:
	.byte	(.LBB189_8-.LBB189_8)>>2
	.byte	(.LBB189_9-.LBB189_8)>>2
	.byte	(.LBB189_10-.LBB189_8)>>2
	.byte	(.LBB189_11-.LBB189_8)>>2
	.byte	(.LBB189_12-.LBB189_8)>>2
	.byte	(.LBB189_13-.LBB189_8)>>2
	.byte	(.LBB189_14-.LBB189_8)>>2
	.byte	(.LBB189_12-.LBB189_8)>>2
	.byte	(.LBB189_12-.LBB189_8)>>2
	.byte	(.LBB189_15-.LBB189_8)>>2
	.section	.gcc_except_table._ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,"aG",@progbits,_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f,comdat
	.p2align	2
GCC_except_table189:
.Lexception61:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end61-.Lcst_begin61
.Lcst_begin61:
	.uleb128 .Ltmp836-.Lfunc_begin61        // >> Call Site 1 <<
	.uleb128 .Ltmp829-.Ltmp836              //   Call between .Ltmp836 and .Ltmp829
	.uleb128 .Ltmp844-.Lfunc_begin61        //     jumps to .Ltmp844
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp829-.Lfunc_begin61        // >> Call Site 2 <<
	.uleb128 .Lfunc_end189-.Ltmp829         //   Call between .Ltmp829 and .Lfunc_end189
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end61:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	str	x23, [sp, #-48]!                // 8-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	subs	x8, x1, #1
	b.ne	.LBB190_4
// %bb.1:
	cbz	x2, .LBB190_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #5
	lsl	x10, x10, #5
	lsl	x11, x2, #6
	add	x12, x3, #64
.LBB190_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x12, #-64]
	add	x13, x8, x11
	add	x14, x8, x9
	subs	x2, x2, #1
	ldp	q2, q3, [x12]
	fadd	v5.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	ldp	q6, q16, [x12, #-32]
	fadd	v7.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	ldp	q4, q2, [x12, #32]
	add	x12, x12, #128
	fadd	v17.4s, v6.4s, v4.4s
	fsub	v4.4s, v6.4s, v4.4s
	fadd	v3.4s, v16.4s, v2.4s
	fsub	v2.4s, v16.4s, v2.4s
	fsub	v16.4s, v5.4s, v17.4s
	fadd	v5.4s, v5.4s, v17.4s
	fsub	v6.4s, v7.4s, v3.4s
	fadd	v3.4s, v7.4s, v3.4s
	fadd	v17.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	stp	q16, q6, [x13, #-16]
	add	x13, x8, x10
	fsub	v16.4s, v1.4s, v4.4s
	stp	q5, q3, [x8, #-16]
	fadd	v1.4s, v1.4s, v4.4s
	add	x8, x8, #32
	stp	q17, q16, [x14, #-16]
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB190_3
	b	.LBB190_10
.LBB190_4:
	cbz	x2, .LBB190_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #96
	lsl	x10, x2, #1
	lsl	x16, x1, #4
	lsl	x18, x1, #3
	mov	x9, xzr
	madd	x14, x0, x14, x4
	add	x11, x3, #32
	lsl	x12, x1, #7
	add	x13, x10, x2
	lsl	x15, x1, #5
	sub	x16, x16, #16
	add	x17, x4, x0, lsl #6
	sub	x18, x18, #8
	add	x0, x4, x0, lsl #5
	mov	x6, x4
	b	.LBB190_7
.LBB190_6:                              //   in Loop: Header=BB190_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x12
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB190_10
.LBB190_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB190_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #5
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #5
	ldp	q0, q1, [x7]
	add	x7, x3, x20, lsl #5
	add	x20, x3, x21, lsl #5
	ldp	q2, q3, [x19]
	mul	x19, x9, x1
	fadd	v16.4s, v0.4s, v2.4s
	add	x19, x4, x19, lsl #5
	fsub	v0.4s, v0.4s, v2.4s
	ldp	q4, q5, [x7]
	fadd	v17.4s, v1.4s, v3.4s
	add	x7, x9, x10
	fsub	v1.4s, v1.4s, v3.4s
	mul	x7, x7, x1
	ldp	q6, q7, [x20]
	add	x7, x4, x7, lsl #5
	add	x20, x9, x2
	mul	x20, x20, x1
	fadd	v2.4s, v4.4s, v6.4s
	fsub	v4.4s, v4.4s, v6.4s
	fadd	v3.4s, v5.4s, v7.4s
	fsub	v5.4s, v5.4s, v7.4s
	fadd	v6.4s, v16.4s, v2.4s
	fsub	v2.4s, v16.4s, v2.4s
	fadd	v16.4s, v17.4s, v3.4s
	fsub	v3.4s, v17.4s, v3.4s
	stp	q6, q16, [x19]
	add	x19, x9, x13
	stp	q2, q3, [x7]
	mul	x7, x19, x1
	add	x19, x4, x20, lsl #5
	fadd	v2.4s, v0.4s, v5.4s
	fsub	v3.4s, v1.4s, v4.4s
	fsub	v0.4s, v0.4s, v5.4s
	add	x7, x4, x7, lsl #5
	fadd	v1.4s, v1.4s, v4.4s
	stp	q2, q3, [x19]
	stp	q0, q1, [x7]
	b.lo	.LBB190_6
// %bb.8:                               //   in Loop: Header=BB190_7 Depth=1
	mov	x7, xzr
	mov	x19, x5
	mov	x20, x8
.LBB190_9:                              //   Parent Loop BB190_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x21, x11, x7
	ldr	s16, [x19, #4]
	add	x22, x21, x15
	subs	x20, x20, #1
	add	x23, x22, x15
	ldp	q0, q1, [x21]
	add	x21, x23, x15
	ldp	q2, q3, [x22]
	mov	x22, x19
	ldp	q6, q7, [x21]
	add	x21, x6, x7
	ldp	q4, q5, [x23]
	add	x23, x19, x18
	add	x19, x19, #8
	fadd	v17.4s, v0.4s, v4.4s
	fsub	v0.4s, v0.4s, v4.4s
	fsub	v4.4s, v3.4s, v7.4s
	fadd	v18.4s, v1.4s, v5.4s
	fsub	v1.4s, v1.4s, v5.4s
	fadd	v5.4s, v2.4s, v6.4s
	fsub	v2.4s, v2.4s, v6.4s
	fadd	v6.4s, v0.4s, v4.4s
	fadd	v3.4s, v3.4s, v7.4s
	fadd	v7.4s, v17.4s, v5.4s
	fsub	v19.4s, v1.4s, v2.4s
	fneg	v20.4s, v6.4s
	fadd	v21.4s, v18.4s, v3.4s
	fsub	v5.4s, v17.4s, v5.4s
	fmul	v22.4s, v19.4s, v16.s[0]
	fmul	v16.4s, v20.4s, v16.s[0]
	stp	q7, q21, [x21, #32]
	add	x21, x0, x7
	ld1r	{ v7.4s }, [x22], x16
	fmla	v22.4s, v7.4s, v6.4s
	fmla	v16.4s, v7.4s, v19.4s
	fsub	v3.4s, v18.4s, v3.4s
	fneg	v7.4s, v5.4s
	fsub	v0.4s, v0.4s, v4.4s
	stp	q22, q16, [x21, #32]
	add	x21, x17, x7
	ld1r	{ v6.4s }, [x23], #4
	fadd	v1.4s, v1.4s, v2.4s
	fneg	v2.4s, v0.4s
	ldr	s16, [x23]
	fmul	v17.4s, v3.4s, v16.s[0]
	fmul	v7.4s, v7.4s, v16.s[0]
	fmla	v17.4s, v6.4s, v5.4s
	fmla	v7.4s, v6.4s, v3.4s
	stp	q17, q7, [x21, #32]
	add	x21, x14, x7
	ld1r	{ v3.4s }, [x22], #4
	add	x7, x7, #32
	ldr	s4, [x22]
	fmul	v5.4s, v1.4s, v4.s[0]
	fmul	v2.4s, v2.4s, v4.s[0]
	fmla	v5.4s, v3.4s, v0.4s
	fmla	v2.4s, v3.4s, v1.4s
	stp	q5, q2, [x21, #32]
	b.ne	.LBB190_9
	b	.LBB190_6
.LBB190_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp], #48                  // 8-byte Folded Reload
	ret
.Lfunc_end190:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end190-_ZNK9pocketfft6detail5cfftpIfE5pass4ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #256
	str	d14, [sp, #96]                  // 8-byte Folded Spill
	stp	d13, d12, [sp, #112]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #128]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #144]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #176]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #192]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 256
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -160
	subs	x8, x1, #1
	str	x4, [sp, #88]                   // 8-byte Folded Spill
	str	x3, [sp, #104]                  // 8-byte Folded Spill
	b.ne	.LBB191_4
// %bb.1:
	cbz	x2, .LBB191_10
// %bb.2:
	mov	w10, #224
	ldr	x8, [sp, #88]                   // 8-byte Folded Reload
	mov	w17, #1267
	ldr	x15, [sp, #104]                 // 8-byte Folded Reload
	movk	w17, #16181, lsl #16
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	mul	x10, x2, x10
	add	x8, x8, #16
	lsl	x9, x13, #5
	lsl	x11, x11, #5
	lsl	x12, x2, #5
	lsl	x13, x13, #6
	lsl	x14, x2, #6
	lsl	x16, x2, #7
	add	x15, x15, #128
	dup	v0.4s, w17
.LBB191_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q1, q2, [x15, #-96]
	add	x17, x8, x16
	add	x18, x8, x13
	subs	x2, x2, #1
	ldp	q3, q4, [x15, #32]
	fadd	v6.4s, v1.4s, v3.4s
	fsub	v3.4s, v1.4s, v3.4s
	ldp	q5, q7, [x15, #-32]
	fadd	v16.4s, v2.4s, v4.4s
	fsub	v1.4s, v2.4s, v4.4s
	ldp	q17, q18, [x15, #96]
	fadd	v2.4s, v5.4s, v17.4s
	fsub	v5.4s, v5.4s, v17.4s
	fadd	v4.4s, v7.4s, v18.4s
	ldp	q19, q17, [x15, #-128]
	fsub	v7.4s, v7.4s, v18.4s
	fadd	v20.4s, v6.4s, v2.4s
	fadd	v22.4s, v16.4s, v4.4s
	fsub	v2.4s, v6.4s, v2.4s
	fsub	v4.4s, v16.4s, v4.4s
	ldp	q18, q21, [x15]
	fadd	v27.4s, v3.4s, v7.4s
	fsub	v28.4s, v1.4s, v5.4s
	fsub	v3.4s, v3.4s, v7.4s
	fadd	v24.4s, v19.4s, v18.4s
	fsub	v18.4s, v19.4s, v18.4s
	ldp	q23, q25, [x15, #64]
	fadd	v29.4s, v17.4s, v21.4s
	fadd	v7.4s, v28.4s, v27.4s
	fsub	v17.4s, v17.4s, v21.4s
	fsub	v27.4s, v28.4s, v27.4s
	fadd	v1.4s, v1.4s, v5.4s
	ldp	q6, q16, [x15, #-64]
	fmul	v7.4s, v7.4s, v0.4s
	add	x15, x15, #256
	fneg	v5.4s, v3.4s
	fsub	v3.4s, v1.4s, v3.4s
	fadd	v26.4s, v6.4s, v23.4s
	fsub	v6.4s, v6.4s, v23.4s
	fadd	v31.4s, v16.4s, v25.4s
	fsub	v16.4s, v16.4s, v25.4s
	fadd	v30.4s, v24.4s, v26.4s
	fsub	v21.4s, v24.4s, v26.4s
	fadd	v9.4s, v29.4s, v31.4s
	fsub	v24.4s, v29.4s, v31.4s
	fsub	v8.4s, v30.4s, v20.4s
	fsub	v23.4s, v17.4s, v6.4s
	fsub	v19.4s, v9.4s, v22.4s
	fsub	v25.4s, v24.4s, v2.4s
	fadd	v2.4s, v2.4s, v24.4s
	fsub	v1.4s, v5.4s, v1.4s
	stp	q8, q19, [x17, #-16]
	add	x17, x8, x14
	fadd	v19.4s, v4.4s, v21.4s
	fsub	v4.4s, v21.4s, v4.4s
	fadd	v21.4s, v18.4s, v16.4s
	fmul	v1.4s, v1.4s, v0.4s
	stp	q19, q25, [x17, #-16]
	add	x17, x8, x12
	fmul	v19.4s, v27.4s, v0.4s
	stp	q4, q2, [x18, #-16]
	fadd	v4.4s, v7.4s, v21.4s
	add	x18, x8, x11
	fadd	v5.4s, v17.4s, v6.4s
	fadd	v6.4s, v20.4s, v30.4s
	fadd	v2.4s, v19.4s, v23.4s
	stp	q4, q2, [x17, #-16]
	fsub	v4.4s, v21.4s, v7.4s
	stur	q6, [x8, #-16]
	add	x17, x8, x9
	fmul	v2.4s, v3.4s, v0.4s
	stur	q4, [x18, #-16]
	fsub	v3.4s, v18.4s, v16.4s
	fsub	v4.4s, v23.4s, v19.4s
	fadd	v6.4s, v22.4s, v9.4s
	fadd	v7.4s, v2.4s, v3.4s
	str	q4, [x18]
	fadd	v4.4s, v1.4s, v5.4s
	fsub	v2.4s, v3.4s, v2.4s
	fsub	v1.4s, v5.4s, v1.4s
	stp	q7, q4, [x17, #-16]
	add	x17, x8, x10
	str	q6, [x8], #32
	stp	q2, q1, [x17, #-16]
	b.ne	.LBB191_3
	b	.LBB191_10
.LBB191_4:
	stp	x5, x8, [sp, #8]                // 16-byte Folded Spill
	cbz	x2, .LBB191_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x12, x2, #2
	ldr	x14, [sp, #104]                 // 8-byte Folded Reload
	mul	x10, x2, x1
	ldr	x15, [sp, #16]                  // 8-byte Folded Reload
	mov	w11, #224
	stp	x12, x8, [sp, #64]              // 16-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	ldr	x4, [sp, #88]                   // 8-byte Folded Reload
	add	x12, x12, x2
	lsl	x17, x1, #5
	str	x8, [sp, #56]                   // 8-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	madd	x16, x10, x11, x4
	madd	x11, x1, x11, x14
	stp	x12, x18, [sp, #40]             // 16-byte Folded Spill
	mov	w12, #96
	add	x13, x17, x14
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	mov	w8, #160
	add	x20, x11, #48
	add	x11, x14, x15, lsl #7
	madd	x3, x15, x8, x14
	add	x18, x13, #48
	madd	x13, x15, x12, x14
	add	x22, x11, #128
	add	x6, x3, #208
	mov	w3, #48
	madd	x7, x10, x12, x4
	add	x12, x14, x15, lsl #6
	mul	x11, x1, x3
	add	x23, x12, #64
	mov	w12, #40
	madd	x21, x10, x8, x4
	mov	w8, #192
	sub	x26, x11, #48
	lsl	x11, x1, #4
	add	x19, x13, #144
	sub	x27, x11, #16
	mul	x11, x1, x12
	madd	x13, x15, x8, x14
	mov	x9, xzr
	madd	x28, x10, x8, x4
	mov	w8, #24
	sub	x30, x11, #40
	lsl	x11, x1, #3
	mul	x12, x1, x8
	sub	x8, x11, #8
	mov	w11, #1267
	lsl	x0, x1, #8
	movk	w11, #16181, lsl #16
	add	x24, x13, #192
	add	x25, x4, x10, lsl #5
	add	x29, x4, x10, lsl #6
	add	x5, x4, x10, lsl #7
	sub	x13, x12, #24
	mov	x3, x14
	dup	v0.4s, w11
	str	x0, [sp, #24]                   // 8-byte Folded Spill
	str	x2, [sp, #80]                   // 8-byte Folded Spill
	b	.LBB191_7
.LBB191_6:                              //   in Loop: Header=BB191_7 Depth=1
	ldr	x10, [sp, #24]                  // 8-byte Folded Reload
	add	x9, x9, #1
	ldr	x2, [sp, #80]                   // 8-byte Folded Reload
	add	x16, x16, x17
	add	x7, x7, x17
	add	x21, x21, x17
	add	x18, x18, x10
	add	x6, x6, x10
	add	x19, x19, x10
	add	x20, x20, x10
	add	x3, x3, x10
	add	x22, x22, x10
	add	x23, x23, x10
	add	x24, x24, x10
	add	x4, x4, x17
	add	x25, x25, x17
	add	x28, x28, x17
	add	x29, x29, x17
	add	x5, x5, x17
	cmp	x9, x2
	b.eq	.LBB191_10
.LBB191_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB191_9 Depth 2
	mov	w10, #1
	mov	w11, #5
	bfi	x10, x9, #3, #61
	bfi	x11, x9, #3, #61
	ldr	x14, [sp, #104]                 // 8-byte Folded Reload
	mov	w12, #3
	mul	x10, x10, x1
	mov	w15, #7
	mul	x11, x11, x1
	bfi	x12, x9, #3, #61
	bfi	x15, x9, #3, #61
	cmp	x1, #2
	add	x10, x14, x10, lsl #5
	mul	x12, x12, x1
	add	x11, x14, x11, lsl #5
	ldp	q1, q2, [x10]
	mul	x10, x15, x1
	add	x12, x14, x12, lsl #5
	add	x10, x14, x10, lsl #5
	ldp	q3, q4, [x11]
	lsl	x11, x9, #3
	fadd	v7.4s, v1.4s, v3.4s
	fsub	v18.4s, v1.4s, v3.4s
	ldp	q5, q6, [x12]
	mov	w12, #2
	fadd	v16.4s, v2.4s, v4.4s
	bfi	x12, x9, #3, #61
	fsub	v4.4s, v2.4s, v4.4s
	mul	x12, x12, x1
	ldp	q17, q1, [x10]
	mul	x10, x11, x1
	mov	w11, #4
	bfi	x11, x9, #3, #61
	add	x12, x14, x12, lsl #5
	fadd	v19.4s, v5.4s, v17.4s
	add	x10, x14, x10, lsl #5
	fsub	v5.4s, v5.4s, v17.4s
	mul	x11, x11, x1
	fadd	v20.4s, v6.4s, v1.4s
	fsub	v6.4s, v6.4s, v1.4s
	fadd	v3.4s, v7.4s, v19.4s
	add	x11, x14, x11, lsl #5
	fsub	v1.4s, v7.4s, v19.4s
	ldp	q19, q21, [x10]
	mov	w10, #6
	bfi	x10, x9, #3, #61
	fadd	v7.4s, v18.4s, v6.4s
	mul	x10, x10, x1
	fsub	v17.4s, v4.4s, v5.4s
	fadd	v2.4s, v16.4s, v20.4s
	add	x10, x14, x10, lsl #5
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	fsub	v16.4s, v16.4s, v20.4s
	fsub	v6.4s, v18.4s, v6.4s
	fadd	v4.4s, v4.4s, v5.4s
	fadd	v5.4s, v17.4s, v7.4s
	ldp	q18, q20, [x11]
	fsub	v7.4s, v17.4s, v7.4s
	fsub	v22.4s, v4.4s, v6.4s
	fneg	v6.4s, v6.4s
	fadd	v25.4s, v19.4s, v18.4s
	fmul	v5.4s, v5.4s, v0.4s
	ldp	q17, q23, [x12]
	fadd	v27.4s, v21.4s, v20.4s
	fsub	v4.4s, v6.4s, v4.4s
	fsub	v6.4s, v19.4s, v18.4s
	fsub	v20.4s, v21.4s, v20.4s
	fmul	v7.4s, v7.4s, v0.4s
	ldp	q24, q26, [x10]
	mul	x10, x9, x1
	fadd	v28.4s, v17.4s, v24.4s
	add	x10, x14, x10, lsl #5
	fadd	v29.4s, v23.4s, v26.4s
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
	fsub	v21.4s, v23.4s, v26.4s
	ldr	x12, [sp, #48]                  // 8-byte Folded Reload
	fadd	v18.4s, v25.4s, v28.4s
	add	x11, x9, x11
	fadd	v19.4s, v27.4s, v29.4s
	add	x12, x9, x12
	mul	x11, x11, x1
	fadd	v23.4s, v3.4s, v18.4s
	fsub	v3.4s, v18.4s, v3.4s
	fadd	v26.4s, v2.4s, v19.4s
	add	x11, x14, x11, lsl #5
	fsub	v2.4s, v19.4s, v2.4s
	stp	q23, q26, [x10]
	ldr	x10, [sp, #72]                  // 8-byte Folded Reload
	fsub	v23.4s, v25.4s, v28.4s
	stp	q3, q2, [x11]
	fsub	v25.4s, v27.4s, v29.4s
	mul	x11, x12, x1
	add	x10, x9, x10
	ldr	x12, [sp, #40]                  // 8-byte Folded Reload
	fsub	v3.4s, v17.4s, v24.4s
	mul	x10, x10, x1
	add	x11, x14, x11, lsl #5
	fadd	v18.4s, v16.4s, v23.4s
	add	x12, x9, x12
	fsub	v19.4s, v25.4s, v1.4s
	add	x10, x14, x10, lsl #5
	fadd	v2.4s, v6.4s, v21.4s
	fsub	v17.4s, v20.4s, v3.4s
	stp	q18, q19, [x10]
	add	x10, x9, x2
	fsub	v16.4s, v23.4s, v16.4s
	fadd	v1.4s, v1.4s, v25.4s
	mul	x10, x10, x1
	fadd	v18.4s, v5.4s, v2.4s
	fadd	v19.4s, v7.4s, v17.4s
	add	x10, x14, x10, lsl #5
	stp	q16, q1, [x11]
	mul	x11, x12, x1
	ldr	x12, [sp, #32]                  // 8-byte Folded Reload
	stp	q18, q19, [x10]
	add	x10, x14, x11, lsl #5
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	fmul	v1.4s, v4.4s, v0.4s
	add	x12, x9, x12
	fsub	v2.4s, v2.4s, v5.4s
	fsub	v4.4s, v17.4s, v7.4s
	add	x11, x9, x11
	fmul	v16.4s, v22.4s, v0.4s
	fsub	v5.4s, v6.4s, v21.4s
	mul	x11, x11, x1
	fadd	v3.4s, v20.4s, v3.4s
	stp	q2, q4, [x10]
	mul	x10, x12, x1
	add	x11, x14, x11, lsl #5
	fadd	v2.4s, v16.4s, v5.4s
	fadd	v4.4s, v1.4s, v3.4s
	add	x10, x14, x10, lsl #5
	fsub	v5.4s, v5.4s, v16.4s
	fsub	v1.4s, v3.4s, v1.4s
	stp	q2, q4, [x11]
	stp	q5, q1, [x10]
	b.lo	.LBB191_6
// %bb.8:                               //   in Loop: Header=BB191_7 Depth=1
	ldp	x11, x12, [sp, #8]              // 16-byte Folded Reload
	mov	x10, xzr
.LBB191_9:                              //   Parent Loop BB191_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x15, x18, x10
	add	x14, x6, x10
	add	x0, x19, x10
	subs	x12, x12, #1
	ldp	q1, q2, [x15, #-16]
	add	x15, x20, x10
	ldp	q3, q5, [x14, #-16]
	add	x14, x3, x10
	fadd	v19.4s, v1.4s, v3.4s
	ldp	q4, q6, [x0, #-16]
	add	x0, x22, x10
	fadd	v22.4s, v2.4s, v5.4s
	ldp	q7, q16, [x15, #-16]
	add	x15, x23, x10
	fadd	v24.4s, v4.4s, v7.4s
	ldp	q17, q18, [x14, #32]
	add	x14, x24, x10
	fadd	v26.4s, v6.4s, v16.4s
	fadd	v9.4s, v19.4s, v24.4s
	fsub	v6.4s, v6.4s, v16.4s
	ldp	q20, q21, [x0, #32]
	fadd	v10.4s, v22.4s, v26.4s
	add	x0, x11, x17
	fsub	v22.4s, v22.4s, v26.4s
	fadd	v28.4s, v17.4s, v20.4s
	ldp	q23, q25, [x15, #32]
	fadd	v30.4s, v18.4s, v21.4s
	add	x15, x11, x13
	ldp	q27, q29, [x14, #32]
	add	x14, x4, x10
	fadd	v31.4s, v23.4s, v27.4s
	fadd	v8.4s, v25.4s, v29.4s
	fadd	v11.4s, v28.4s, v31.4s
	fsub	v26.4s, v28.4s, v31.4s
	fadd	v12.4s, v30.4s, v8.4s
	fadd	v13.4s, v9.4s, v11.4s
	fsub	v9.4s, v11.4s, v9.4s
	fadd	v14.4s, v10.4s, v12.4s
	fsub	v10.4s, v12.4s, v10.4s
	fneg	v12.4s, v9.4s
	stp	q13, q14, [x14, #32]
	add	x14, x5, x10
	ld1r	{ v11.4s }, [x15], #4
	ldr	s13, [x15]
	add	x15, x11, x8
	fmul	v12.4s, v12.4s, v13.s[0]
	fmul	v13.4s, v10.4s, v13.s[0]
	fmla	v13.4s, v11.4s, v9.4s
	fmla	v12.4s, v11.4s, v10.4s
	fsub	v9.4s, v1.4s, v3.4s
	fsub	v3.4s, v4.4s, v7.4s
	fsub	v7.4s, v19.4s, v24.4s
	fsub	v19.4s, v30.4s, v8.4s
	stp	q13, q12, [x14, #32]
	fadd	v24.4s, v22.4s, v26.4s
	add	x14, x29, x10
	ld1r	{ v28.4s }, [x15], #4
	fsub	v1.4s, v2.4s, v5.4s
	fsub	v2.4s, v17.4s, v20.4s
	fsub	v16.4s, v19.4s, v7.4s
	fneg	v17.4s, v24.4s
	ldr	s20, [x15]
	fsub	v4.4s, v18.4s, v21.4s
	add	x15, x11, x30
	fsub	v5.4s, v23.4s, v27.4s
	fmul	v18.4s, v16.4s, v20.s[0]
	fmul	v17.4s, v17.4s, v20.s[0]
	fadd	v21.4s, v9.4s, v6.4s
	fsub	v23.4s, v1.4s, v3.4s
	fmla	v18.4s, v28.4s, v24.4s
	fmla	v17.4s, v28.4s, v16.4s
	fsub	v20.4s, v25.4s, v29.4s
	fadd	v25.4s, v23.4s, v21.4s
	fadd	v7.4s, v7.4s, v19.4s
	stp	q18, q17, [x14, #32]
	add	x14, x28, x10
	fsub	v18.4s, v26.4s, v22.4s
	ld1r	{ v17.4s }, [x15], #4
	fadd	v16.4s, v2.4s, v20.4s
	fsub	v21.4s, v23.4s, v21.4s
	fneg	v19.4s, v18.4s
	fmul	v22.4s, v25.4s, v0.4s
	ldr	s23, [x15]
	fsub	v24.4s, v4.4s, v5.4s
	mov	x15, x11
	fmul	v21.4s, v21.4s, v0.4s
	fmul	v25.4s, v7.4s, v23.s[0]
	fmul	v19.4s, v19.4s, v23.s[0]
	fadd	v23.4s, v22.4s, v16.4s
	fsub	v16.4s, v16.4s, v22.4s
	fmla	v25.4s, v17.4s, v18.4s
	fmla	v19.4s, v17.4s, v7.4s
	ldr	s7, [x11, #4]
	fadd	v26.4s, v21.4s, v24.4s
	fneg	v18.4s, v23.4s
	fsub	v17.4s, v24.4s, v21.4s
	stp	q25, q19, [x14, #32]
	add	x14, x25, x10
	fneg	v19.4s, v16.4s
	fmul	v21.4s, v26.4s, v7.s[0]
	fmul	v7.4s, v18.4s, v7.s[0]
	ld1r	{ v18.4s }, [x15], x26
	ldur	s22, [x0, #-28]
	fsub	v6.4s, v9.4s, v6.4s
	fmla	v21.4s, v18.4s, v23.4s
	fadd	v1.4s, v1.4s, v3.4s
	fmla	v7.4s, v18.4s, v26.4s
	fmul	v3.4s, v17.4s, v22.s[0]
	ldur	s18, [x0, #-32]
	fmul	v19.4s, v19.4s, v22.s[0]
	fsub	v2.4s, v2.4s, v20.4s
	fsub	v22.4s, v1.4s, v6.4s
	stp	q21, q7, [x14, #32]
	fneg	v6.4s, v6.4s
	fmla	v3.4s, v16.4s, v18.s[0]
	fmla	v19.4s, v17.4s, v18.s[0]
	add	x14, x21, x10
	fsub	v1.4s, v6.4s, v1.4s
	fmul	v6.4s, v22.4s, v0.4s
	stp	q3, q19, [x14, #32]
	add	x14, x11, x27
	add	x11, x11, #8
	fadd	v3.4s, v4.4s, v5.4s
	fmul	v1.4s, v1.4s, v0.4s
	fadd	v4.4s, v6.4s, v2.4s
	ld1r	{ v5.4s }, [x14], #4
	fsub	v2.4s, v2.4s, v6.4s
	fadd	v7.4s, v1.4s, v3.4s
	fneg	v16.4s, v4.4s
	ldr	s17, [x14]
	add	x14, x7, x10
	fsub	v1.4s, v3.4s, v1.4s
	fneg	v3.4s, v2.4s
	fmul	v18.4s, v7.4s, v17.s[0]
	fmul	v16.4s, v16.4s, v17.s[0]
	fmla	v18.4s, v5.4s, v4.4s
	fmla	v16.4s, v5.4s, v7.4s
	stp	q18, q16, [x14, #32]
	add	x14, x16, x10
	ld1r	{ v4.4s }, [x15], #4
	add	x10, x10, #32
	ldr	s5, [x15]
	fmul	v6.4s, v1.4s, v5.s[0]
	fmul	v3.4s, v3.4s, v5.s[0]
	fmla	v6.4s, v4.4s, v2.4s
	fmla	v3.4s, v4.4s, v1.4s
	stp	q6, q3, [x14, #32]
	b.ne	.LBB191_9
	b	.LBB191_6
.LBB191_10:
	ldp	x20, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #144]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #128]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #112]            // 16-byte Folded Reload
	ldr	d14, [sp, #96]                  // 8-byte Folded Reload
	add	sp, sp, #256
	ret
.Lfunc_end191:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end191-_ZNK9pocketfft6detail5cfftpIfE5pass8ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	cmp	x1, #1
	b.ne	.LBB192_4
// %bb.1:
	cbz	x2, .LBB192_12
// %bb.2:
	lsl	x8, x2, #5
	add	x9, x4, #16
	add	x10, x3, #32
.LBB192_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-32]
	add	x11, x9, x8
	subs	x2, x2, #1
	ldp	q2, q3, [x10], #64
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x9, #-16]
	add	x9, x9, #32
	stp	q0, q1, [x11, #-16]
	b.ne	.LBB192_3
	b	.LBB192_12
.LBB192_4:
	cbz	x2, .LBB192_12
// %bb.5:
	subs	x8, x1, #1
	b.ls	.LBB192_10
// %bb.6:
	mul	x13, x2, x1
	mov	x9, xzr
	add	x10, x4, #32
	lsl	x11, x1, #5
	add	x12, x3, #48
	lsl	x13, x13, #5
	lsl	x14, x1, #6
	add	x15, x5, #4
.LBB192_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB192_8 Depth 2
	mov	w17, #1
	lsl	x16, x9, #1
	bfi	x17, x9, #1, #63
	mul	x5, x9, x1
	mul	x16, x16, x1
	add	x18, x9, x2
	mul	x17, x17, x1
	mul	x18, x18, x1
	add	x16, x3, x16, lsl #5
	add	x0, x3, x17, lsl #5
	mov	x17, x12
	ldp	q0, q1, [x16]
	mov	x16, x15
	ldp	q2, q3, [x0]
	add	x0, x4, x5, lsl #5
	add	x5, x4, x18, lsl #5
	mov	x18, x10
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x0]
	mov	x0, x8
	stp	q0, q1, [x5]
.LBB192_8:                              //   Parent Loop BB192_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x5, x17, x11
	ldr	s6, [x16]
	ldp	q0, q2, [x17, #-16]
	subs	x0, x0, #1
	add	x17, x17, #32
	ldp	q1, q3, [x5, #-16]
	add	x5, x18, x13
	fsub	v4.4s, v0.4s, v1.4s
	fadd	v0.4s, v0.4s, v1.4s
	fsub	v5.4s, v2.4s, v3.4s
	fadd	v1.4s, v2.4s, v3.4s
	fneg	v7.4s, v4.4s
	fmul	v2.4s, v5.4s, v6.s[0]
	stp	q0, q1, [x18], #32
	fmul	v3.4s, v7.4s, v6.s[0]
	ldur	s6, [x16, #-4]
	add	x16, x16, #8
	fmla	v2.4s, v4.4s, v6.s[0]
	fmla	v3.4s, v5.4s, v6.s[0]
	stp	q2, q3, [x5]
	b.ne	.LBB192_8
// %bb.9:                               //   in Loop: Header=BB192_7 Depth=1
	add	x9, x9, #1
	add	x10, x10, x11
	add	x12, x12, x14
	cmp	x9, x2
	b.ne	.LBB192_7
	b	.LBB192_12
.LBB192_10:
	mul	x10, x2, x1
	add	x8, x4, #16
	lsl	x9, x1, #5
	add	x11, x3, #16
	lsl	x10, x10, #5
	lsl	x12, x1, #6
.LBB192_11:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	q0, q1, [x11, #-16]
	add	x11, x11, x12
	ldp	q2, q3, [x13, #-16]
	add	x13, x8, x10
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x8, #-16]
	add	x8, x8, x9
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB192_11
.LBB192_12:
	ret
.Lfunc_end192:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end192-_ZNK9pocketfft6detail5cfftpIfE5pass2ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	stp	x22, x21, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	subs	x8, x1, #1
	b.ne	.LBB193_4
// %bb.1:
	cbz	x2, .LBB193_10
// %bb.2:
	mov	w12, #46039
	mov	w13, #46039
	movk	w12, #16221, lsl #16
	movk	w13, #48989, lsl #16
	movi	v0.4s, #63, lsl #24
	lsl	x8, x2, #6
	add	x9, x4, #16
	lsl	x10, x2, #5
	add	x11, x3, #48
	dup	v1.4s, w12
	dup	v2.4s, w13
.LBB193_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q3, q4, [x11, #-16]
	add	x12, x9, x10
	subs	x2, x2, #1
	ldp	q5, q6, [x11, #16]
	fadd	v7.4s, v3.4s, v5.4s
	fsub	v3.4s, v3.4s, v5.4s
	fadd	v17.4s, v4.4s, v6.4s
	ldp	q16, q18, [x11, #-48]
	fsub	v4.4s, v4.4s, v6.4s
	add	x11, x11, #96
	fmul	v5.4s, v7.4s, v0.4s
	fmul	v6.4s, v17.4s, v0.4s
	fmul	v3.4s, v3.4s, v2.4s
	fmul	v4.4s, v4.4s, v1.4s
	fsub	v5.4s, v16.4s, v5.4s
	fsub	v6.4s, v18.4s, v6.4s
	fadd	v7.4s, v16.4s, v7.4s
	fadd	v16.4s, v18.4s, v17.4s
	fadd	v19.4s, v5.4s, v4.4s
	fadd	v20.4s, v3.4s, v6.4s
	fsub	v4.4s, v5.4s, v4.4s
	fsub	v3.4s, v6.4s, v3.4s
	stp	q7, q16, [x9, #-16]
	stp	q19, q20, [x12, #-16]
	add	x12, x9, x8
	add	x9, x9, #32
	stp	q4, q3, [x12, #-16]
	b.ne	.LBB193_3
	b	.LBB193_10
.LBB193_4:
	cbz	x2, .LBB193_10
// %bb.5:
	mul	x16, x2, x1
	mov	w6, #46039
	mov	w7, #46039
	movk	w6, #16221, lsl #16
	movk	w7, #48989, lsl #16
	add	x12, x1, x1, lsl #1
	lsl	x11, x1, #5
	lsl	x17, x1, #3
	movi	v0.4s, #63, lsl #24
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #5
	add	x13, x3, x11
	add	x14, x4, x16, lsl #6
	add	x15, x3, x1, lsl #6
	add	x16, x4, x16, lsl #5
	sub	x17, x17, #8
	mov	x18, x4
	mov	x0, x3
	dup	v1.4s, w6
	dup	v2.4s, w7
	b	.LBB193_7
.LBB193_6:                              //   in Loop: Header=BB193_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x0, x0, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x18, x18, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB193_10
.LBB193_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB193_9 Depth 2
	add	x6, x9, x9, lsl #1
	add	x20, x9, x2
	add	x7, x6, #2
	cmp	x1, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	add	x6, x3, x6, lsl #5
	add	x19, x3, x19, lsl #5
	add	x7, x3, x7, lsl #5
	ldp	q3, q4, [x6]
	mul	x6, x9, x1
	add	x6, x4, x6, lsl #5
	ldp	q5, q6, [x19]
	add	x19, x9, x10
	mul	x19, x19, x1
	ldp	q7, q16, [x7]
	mul	x7, x20, x1
	add	x19, x4, x19, lsl #5
	fadd	v17.4s, v5.4s, v7.4s
	add	x7, x4, x7, lsl #5
	fsub	v5.4s, v5.4s, v7.4s
	fadd	v18.4s, v6.4s, v16.4s
	fsub	v6.4s, v6.4s, v16.4s
	fadd	v7.4s, v3.4s, v17.4s
	fmul	v17.4s, v17.4s, v0.4s
	fadd	v16.4s, v4.4s, v18.4s
	fmul	v18.4s, v18.4s, v0.4s
	fmul	v6.4s, v6.4s, v1.4s
	fmul	v5.4s, v5.4s, v2.4s
	fsub	v3.4s, v3.4s, v17.4s
	stp	q7, q16, [x6]
	fsub	v4.4s, v4.4s, v18.4s
	fadd	v7.4s, v3.4s, v6.4s
	fadd	v16.4s, v5.4s, v4.4s
	fsub	v3.4s, v3.4s, v6.4s
	fsub	v4.4s, v4.4s, v5.4s
	stp	q7, q16, [x7]
	stp	q3, q4, [x19]
	b.lo	.LBB193_6
// %bb.8:                               //   in Loop: Header=BB193_7 Depth=1
	mov	x6, xzr
	mov	x7, x5
	mov	x19, x8
.LBB193_9:                              //   Parent Loop BB193_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x15, x6
	add	x21, x13, x6
	add	x22, x0, x6
	ldr	s20, [x7, #4]
	subs	x19, x19, #1
	ldp	q3, q6, [x20, #32]
	add	x20, x18, x6
	ldp	q4, q5, [x21, #32]
	mov	x21, x7
	add	x7, x7, #8
	fadd	v7.4s, v4.4s, v3.4s
	fsub	v3.4s, v4.4s, v3.4s
	ldp	q16, q17, [x22, #32]
	fadd	v18.4s, v5.4s, v6.4s
	fsub	v5.4s, v5.4s, v6.4s
	fmul	v6.4s, v7.4s, v0.4s
	fmul	v3.4s, v3.4s, v2.4s
	fmul	v4.4s, v18.4s, v0.4s
	fmul	v5.4s, v5.4s, v1.4s
	fsub	v6.4s, v16.4s, v6.4s
	fadd	v7.4s, v16.4s, v7.4s
	fsub	v4.4s, v17.4s, v4.4s
	fadd	v17.4s, v17.4s, v18.4s
	fadd	v19.4s, v6.4s, v5.4s
	fsub	v5.4s, v6.4s, v5.4s
	fadd	v16.4s, v3.4s, v4.4s
	stp	q7, q17, [x20, #32]
	add	x20, x16, x6
	fneg	v21.4s, v19.4s
	ld1r	{ v7.4s }, [x21], x17
	fmul	v18.4s, v16.4s, v20.s[0]
	fsub	v3.4s, v4.4s, v3.4s
	fmul	v20.4s, v21.4s, v20.s[0]
	fneg	v4.4s, v5.4s
	fmla	v18.4s, v7.4s, v19.4s
	fmla	v20.4s, v7.4s, v16.4s
	stp	q18, q20, [x20, #32]
	add	x20, x14, x6
	ld1r	{ v6.4s }, [x21], #4
	add	x6, x6, #32
	ldr	s7, [x21]
	fmul	v16.4s, v3.4s, v7.s[0]
	fmul	v4.4s, v4.4s, v7.s[0]
	fmla	v16.4s, v6.4s, v5.4s
	fmla	v4.4s, v6.4s, v3.4s
	stp	q16, q4, [x20, #32]
	b.ne	.LBB193_9
	b	.LBB193_6
.LBB193_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x22, x21, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end193:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end193-_ZNK9pocketfft6detail5cfftpIfE5pass3ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	stp	d9, d8, [sp, #-112]!            // 16-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #32]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 112
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	subs	x8, x1, #1
	b.ne	.LBB194_4
// %bb.1:
	cbz	x2, .LBB194_10
// %bb.2:
	mov	w11, #14202
	mov	w12, #7101
	mov	w13, #31000
	movk	w11, #16030, lsl #16
	movk	w12, #48975, lsl #16
	movk	w13, #48918, lsl #16
	mov	w14, #30833
	mov	w15, #30833
	movk	w14, #49011, lsl #16
	movk	w15, #16243, lsl #16
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #6
	lsl	x10, x10, #5
	dup	v0.4s, w11
	dup	v1.4s, w12
	lsl	x11, x2, #7
	dup	v2.4s, w13
	lsl	x12, x2, #5
	add	x13, x3, #80
	dup	v3.4s, w14
	dup	v4.4s, w15
.LBB194_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x13, #-48]
	add	x14, x8, x12
	add	x15, x8, x9
	subs	x2, x2, #1
	ldp	q16, q7, [x13, #48]
	fadd	v19.4s, v5.4s, v16.4s
	fsub	v5.4s, v5.4s, v16.4s
	ldp	q17, q20, [x13, #-16]
	fadd	v21.4s, v6.4s, v7.4s
	fsub	v6.4s, v6.4s, v7.4s
	ldp	q22, q18, [x13, #16]
	fadd	v23.4s, v17.4s, v22.4s
	fsub	v17.4s, v17.4s, v22.4s
	ldp	q16, q7, [x13, #-80]
	fsub	v24.4s, v20.4s, v18.4s
	add	x13, x13, #160
	fadd	v18.4s, v20.4s, v18.4s
	fmul	v22.4s, v17.4s, v2.4s
	mov	v25.16b, v16.16b
	fmul	v20.4s, v24.4s, v2.4s
	mov	v26.16b, v7.16b
	fmla	v22.4s, v3.4s, v5.4s
	fmla	v25.4s, v0.4s, v19.4s
	fmla	v20.4s, v3.4s, v6.4s
	fmla	v26.4s, v0.4s, v21.4s
	fadd	v27.4s, v16.4s, v19.4s
	fmla	v16.4s, v1.4s, v19.4s
	fmla	v25.4s, v1.4s, v23.4s
	fadd	v28.4s, v7.4s, v21.4s
	fmla	v7.4s, v1.4s, v21.4s
	fmla	v26.4s, v1.4s, v18.4s
	fmul	v24.4s, v24.4s, v4.4s
	fmla	v16.4s, v0.4s, v23.4s
	fmul	v17.4s, v17.4s, v4.4s
	fsub	v19.4s, v25.4s, v20.4s
	fmla	v7.4s, v0.4s, v18.4s
	fadd	v21.4s, v26.4s, v22.4s
	fadd	v20.4s, v25.4s, v20.4s
	fmla	v24.4s, v2.4s, v6.4s
	fmla	v17.4s, v2.4s, v5.4s
	fsub	v5.4s, v26.4s, v22.4s
	fadd	v6.4s, v27.4s, v23.4s
	stp	q19, q21, [x14, #-16]
	add	x14, x8, x11
	fsub	v19.4s, v16.4s, v24.4s
	stp	q20, q5, [x14, #-16]
	add	x14, x8, x10
	fadd	v20.4s, v7.4s, v17.4s
	stur	q6, [x8, #-16]
	fadd	v5.4s, v28.4s, v18.4s
	fadd	v6.4s, v16.4s, v24.4s
	fsub	v7.4s, v7.4s, v17.4s
	stp	q19, q20, [x15, #-16]
	str	q5, [x8], #32
	stp	q6, q7, [x14, #-16]
	b.ne	.LBB194_3
	b	.LBB194_10
.LBB194_4:
	cbz	x2, .LBB194_10
// %bb.5:
	mul	x22, x2, x1
	mov	w17, #96
	mov	w19, #24
	mov	w23, #14202
	mov	w24, #7101
	movk	w23, #16030, lsl #16
	movk	w24, #48975, lsl #16
	mov	w25, #31000
	mov	w26, #30833
	mov	w27, #30833
	madd	x0, x8, x17, x3
	movk	w25, #48918, lsl #16
	mul	x21, x1, x19
	movk	w26, #49011, lsl #16
	movk	w27, #16243, lsl #16
	lsl	x11, x2, #1
	add	x15, x1, x1, lsl #2
	madd	x13, x22, x17, x4
	lsl	x14, x1, #5
	add	x18, x3, x8, lsl #6
	lsl	x7, x1, #4
	lsl	x20, x1, #3
	mov	x9, xzr
	lsl	x10, x2, #2
	add	x12, x11, x2
	lsl	x15, x15, #5
	add	x16, x3, x14
	add	x17, x3, x1, lsl #7
	add	x18, x18, #64
	add	x0, x0, #96
	add	x6, x4, x22, lsl #6
	sub	x7, x7, #16
	sub	x19, x20, #8
	add	x20, x4, x22, lsl #7
	sub	x21, x21, #24
	add	x22, x4, x22, lsl #5
	dup	v0.4s, w23
	dup	v1.4s, w24
	mov	x23, x4
	mov	x24, x3
	dup	v2.4s, w25
	dup	v3.4s, w26
	dup	v4.4s, w27
	b	.LBB194_7
.LBB194_6:                              //   in Loop: Header=BB194_7 Depth=1
	add	x9, x9, #1
	add	x13, x13, x14
	add	x24, x24, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x23, x23, x14
	add	x6, x6, x14
	add	x20, x20, x14
	add	x22, x22, x14
	cmp	x9, x2
	b.eq	.LBB194_10
.LBB194_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB194_9 Depth 2
	add	x25, x9, x9, lsl #2
	cmp	x1, #2
	add	x26, x25, #4
	add	x29, x25, #2
	mul	x27, x25, x1
	add	x25, x25, #3
	mul	x26, x26, x1
	mul	x25, x25, x1
	add	x28, x3, x27, lsl #5
	add	x27, x1, x27
	add	x26, x3, x26, lsl #5
	add	x27, x3, x27, lsl #5
	add	x25, x3, x25, lsl #5
	ldp	q6, q5, [x28]
	mul	x28, x29, x1
	ldp	q7, q16, [x27]
	add	x27, x3, x28, lsl #5
	mov	v25.16b, v5.16b
	ldp	q17, q18, [x26]
	add	x26, x9, x2
	mul	x26, x26, x1
	fadd	v21.4s, v7.4s, v17.4s
	fsub	v7.4s, v7.4s, v17.4s
	ldp	q19, q20, [x27]
	fadd	v22.4s, v16.4s, v18.4s
	add	x26, x4, x26, lsl #5
	fsub	v16.4s, v16.4s, v18.4s
	add	x27, x9, x12
	fadd	v28.4s, v5.4s, v22.4s
	fmla	v25.4s, v0.4s, v22.4s
	ldp	q23, q17, [x25]
	mul	x25, x9, x1
	fmla	v5.4s, v1.4s, v22.4s
	fadd	v18.4s, v19.4s, v23.4s
	add	x25, x4, x25, lsl #5
	fsub	v19.4s, v19.4s, v23.4s
	fadd	v24.4s, v20.4s, v17.4s
	fsub	v17.4s, v20.4s, v17.4s
	mov	v20.16b, v6.16b
	fadd	v23.4s, v6.4s, v21.4s
	fmla	v6.4s, v1.4s, v21.4s
	fmul	v27.4s, v19.4s, v2.4s
	fmla	v25.4s, v1.4s, v24.4s
	fmul	v26.4s, v17.4s, v2.4s
	fmla	v5.4s, v0.4s, v24.4s
	fmla	v20.4s, v0.4s, v21.4s
	fadd	v23.4s, v23.4s, v18.4s
	fmla	v6.4s, v0.4s, v18.4s
	fadd	v28.4s, v28.4s, v24.4s
	fmla	v27.4s, v3.4s, v7.4s
	fmla	v26.4s, v3.4s, v16.4s
	fmla	v20.4s, v1.4s, v18.4s
	fmul	v17.4s, v17.4s, v4.4s
	stp	q23, q28, [x25]
	add	x25, x9, x10
	fadd	v30.4s, v25.4s, v27.4s
	fsub	v29.4s, v20.4s, v26.4s
	mul	x25, x25, x1
	fmul	v19.4s, v19.4s, v4.4s
	fmla	v17.4s, v2.4s, v16.4s
	fadd	v20.4s, v20.4s, v26.4s
	fsub	v21.4s, v25.4s, v27.4s
	add	x25, x4, x25, lsl #5
	stp	q29, q30, [x26]
	add	x26, x9, x11
	fmla	v19.4s, v2.4s, v7.4s
	mul	x26, x26, x1
	stp	q20, q21, [x25]
	mul	x25, x27, x1
	fsub	v7.4s, v6.4s, v17.4s
	fadd	v16.4s, v5.4s, v19.4s
	add	x26, x4, x26, lsl #5
	fadd	v6.4s, v6.4s, v17.4s
	add	x25, x4, x25, lsl #5
	fsub	v5.4s, v5.4s, v19.4s
	stp	q7, q16, [x26]
	stp	q6, q5, [x25]
	b.lo	.LBB194_6
// %bb.8:                               //   in Loop: Header=BB194_7 Depth=1
	mov	x25, xzr
	mov	x26, x5
	mov	x27, x8
.LBB194_9:                              //   Parent Loop BB194_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x28, x16, x25
	add	x29, x17, x25
	add	x30, x18, x25
	subs	x27, x27, #1
	ldp	q18, q5, [x28, #32]
	add	x28, x0, x25
	ldp	q19, q7, [x29, #32]
	add	x29, x24, x25
	fadd	v23.4s, v18.4s, v19.4s
	fsub	v18.4s, v18.4s, v19.4s
	ldp	q20, q21, [x30, #32]
	fadd	v16.4s, v5.4s, v7.4s
	add	x30, x26, x21
	fsub	v7.4s, v5.4s, v7.4s
	ldp	q22, q24, [x28, #32]
	add	x28, x23, x25
	fadd	v26.4s, v20.4s, v22.4s
	fsub	v20.4s, v20.4s, v22.4s
	ldp	q6, q5, [x29, #32]
	fsub	v17.4s, v21.4s, v24.4s
	mov	x29, x26
	fadd	v19.4s, v21.4s, v24.4s
	fmul	v21.4s, v20.4s, v2.4s
	mov	v25.16b, v6.16b
	fmul	v27.4s, v17.4s, v2.4s
	mov	v22.16b, v5.16b
	ldr	s24, [x26, #4]
	fmla	v21.4s, v3.4s, v18.4s
	fmla	v25.4s, v0.4s, v23.4s
	fmla	v27.4s, v3.4s, v7.4s
	fmla	v22.4s, v0.4s, v16.4s
	fadd	v28.4s, v6.4s, v23.4s
	fmla	v6.4s, v1.4s, v23.4s
	fmla	v25.4s, v1.4s, v26.4s
	fadd	v30.4s, v5.4s, v16.4s
	fmla	v5.4s, v1.4s, v16.4s
	fmla	v22.4s, v1.4s, v19.4s
	fadd	v28.4s, v28.4s, v26.4s
	fmla	v6.4s, v0.4s, v26.4s
	fsub	v29.4s, v25.4s, v27.4s
	fadd	v30.4s, v30.4s, v19.4s
	fmla	v5.4s, v0.4s, v19.4s
	fadd	v31.4s, v22.4s, v21.4s
	fsub	v21.4s, v22.4s, v21.4s
	fneg	v8.4s, v29.4s
	stp	q28, q30, [x28, #32]
	add	x28, x22, x25
	fmul	v9.4s, v31.4s, v24.s[0]
	ld1r	{ v28.4s }, [x29], x7
	fmul	v24.4s, v8.4s, v24.s[0]
	fmul	v17.4s, v17.4s, v4.4s
	fmla	v9.4s, v28.4s, v29.4s
	fmul	v16.4s, v20.4s, v4.4s
	fmla	v24.4s, v28.4s, v31.4s
	fmla	v17.4s, v2.4s, v7.4s
	fmla	v16.4s, v2.4s, v18.4s
	stp	q9, q24, [x28, #32]
	add	x28, x20, x25
	fadd	v24.4s, v25.4s, v27.4s
	ld1r	{ v25.4s }, [x30], #4
	fsub	v7.4s, v6.4s, v17.4s
	fadd	v19.4s, v5.4s, v16.4s
	fneg	v22.4s, v24.4s
	ldr	s27, [x30]
	fneg	v20.4s, v7.4s
	fadd	v6.4s, v6.4s, v17.4s
	fmul	v28.4s, v21.4s, v27.s[0]
	fmul	v22.4s, v22.4s, v27.s[0]
	fsub	v5.4s, v5.4s, v16.4s
	fneg	v16.4s, v6.4s
	fmla	v28.4s, v25.4s, v24.4s
	fmla	v22.4s, v25.4s, v21.4s
	stp	q28, q22, [x28, #32]
	add	x28, x26, x19
	add	x26, x26, #8
	ld1r	{ v18.4s }, [x28], #4
	ldr	s21, [x28]
	add	x28, x6, x25
	fmul	v22.4s, v19.4s, v21.s[0]
	fmul	v20.4s, v20.4s, v21.s[0]
	fmla	v22.4s, v18.4s, v7.4s
	fmla	v20.4s, v18.4s, v19.4s
	stp	q22, q20, [x28, #32]
	add	x28, x13, x25
	ld1r	{ v7.4s }, [x29], #4
	add	x25, x25, #32
	ldr	s17, [x29]
	fmul	v18.4s, v5.4s, v17.s[0]
	fmul	v16.4s, v16.4s, v17.s[0]
	fmla	v18.4s, v7.4s, v6.4s
	fmla	v16.4s, v7.4s, v5.4s
	stp	q18, q16, [x28, #32]
	b.ne	.LBB194_9
	b	.LBB194_6
.LBB194_10:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldp	d9, d8, [sp], #112              // 16-byte Folded Reload
	ret
.Lfunc_end194:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end194-_ZNK9pocketfft6detail5cfftpIfE5pass5ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	d15, d14, [sp, #128]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #144]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #160]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #176]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #208]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 288
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	mov	x8, x4
	subs	x9, x1, #1
	str	x3, [sp, #72]                   // 8-byte Folded Spill
	b.ne	.LBB195_4
// %bb.1:
	cbz	x2, .LBB195_10
// %bb.2:
	mov	w15, #56455
	mov	w16, #42469
	movk	w15, #48739, lsl #16
	mov	w17, #38112
	movk	w16, #48998, lsl #16
	movk	w17, #49017, lsl #16
	mov	w12, #40199
	mov	w18, #9756
	dup	v1.4s, w15
	mov	w15, #9730
	movk	w12, #16159, lsl #16
	dup	v2.4s, w16
	movk	w15, #48862, lsl #16
	dup	v3.4s, w17
	mov	w16, #9730
	mov	w17, #9756
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	movk	w18, #48968, lsl #16
	movk	w16, #16094, lsl #16
	movk	w17, #16200, lsl #16
	add	x14, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	lsl	x9, x2, #7
	add	x8, x8, #16
	lsl	x10, x14, #5
	lsl	x11, x11, #5
	dup	v0.4s, w12
	lsl	x12, x2, #6
	lsl	x14, x14, #6
	dup	v5.4s, w15
	lsl	x15, x2, #5
	add	x13, x13, #112
	dup	v4.4s, w18
	dup	v6.4s, w16
	dup	v7.4s, w17
.LBB195_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q16, q17, [x13, #-80]
	add	x16, x8, x15
	add	x17, x8, x14
	subs	x2, x2, #1
	ldp	q18, q19, [x13, #80]
	fadd	v24.4s, v16.4s, v18.4s
	fsub	v18.4s, v16.4s, v18.4s
	ldp	q27, q23, [x13, #48]
	fadd	v22.4s, v17.4s, v19.4s
	fsub	v19.4s, v17.4s, v19.4s
	ldp	q25, q26, [x13, #-48]
	fadd	v20.4s, v25.4s, v27.4s
	fsub	v25.4s, v25.4s, v27.4s
	ldp	q16, q17, [x13, #-112]
	fsub	v21.4s, v26.4s, v23.4s
	fadd	v23.4s, v26.4s, v23.4s
	fmul	v11.4s, v25.4s, v3.4s
	mov	v30.16b, v16.16b
	fmul	v10.4s, v21.4s, v3.4s
	mov	v9.16b, v17.16b
	ldp	q8, q29, [x13, #16]
	fmla	v30.4s, v0.4s, v24.4s
	fmla	v11.4s, v4.4s, v18.4s
	fmla	v10.4s, v4.4s, v19.4s
	fmla	v9.4s, v0.4s, v22.4s
	mov	v12.16b, v17.16b
	fmla	v30.4s, v1.4s, v20.4s
	ldp	q31, q26, [x13, #-16]
	fmla	v9.4s, v1.4s, v23.4s
	add	x13, x13, #224
	fmla	v12.4s, v1.4s, v22.4s
	fadd	v28.4s, v31.4s, v8.4s
	fsub	v27.4s, v26.4s, v29.4s
	fmla	v12.4s, v2.4s, v23.4s
	fadd	v26.4s, v26.4s, v29.4s
	fsub	v29.4s, v31.4s, v8.4s
	fmla	v30.4s, v2.4s, v28.4s
	mov	v31.16b, v16.16b
	fmla	v10.4s, v5.4s, v27.4s
	fmla	v9.4s, v2.4s, v26.4s
	fmla	v12.4s, v0.4s, v26.4s
	fmla	v11.4s, v5.4s, v29.4s
	fmla	v31.4s, v1.4s, v24.4s
	fsub	v8.4s, v30.4s, v10.4s
	fadd	v30.4s, v30.4s, v10.4s
	fadd	v13.4s, v11.4s, v9.4s
	fmul	v10.4s, v25.4s, v6.4s
	fmla	v31.4s, v2.4s, v20.4s
	fsub	v9.4s, v9.4s, v11.4s
	fadd	v11.4s, v16.4s, v24.4s
	fmla	v16.4s, v2.4s, v24.4s
	stp	q8, q13, [x16, #-16]
	add	x16, x8, x12
	fmul	v8.4s, v21.4s, v6.4s
	fmla	v10.4s, v3.4s, v18.4s
	stp	q30, q9, [x17, #-16]
	fmla	v31.4s, v0.4s, v28.4s
	fadd	v9.4s, v17.4s, v22.4s
	fmla	v17.4s, v2.4s, v22.4s
	fmul	v21.4s, v21.4s, v7.4s
	fmla	v16.4s, v0.4s, v20.4s
	fmla	v8.4s, v3.4s, v19.4s
	fmla	v10.4s, v7.4s, v29.4s
	fmul	v22.4s, v25.4s, v7.4s
	add	x17, x8, x10
	fadd	v30.4s, v11.4s, v20.4s
	fmla	v17.4s, v0.4s, v23.4s
	fmla	v21.4s, v5.4s, v19.4s
	fmla	v16.4s, v1.4s, v28.4s
	fmla	v8.4s, v7.4s, v27.4s
	fmla	v22.4s, v5.4s, v18.4s
	fadd	v25.4s, v10.4s, v12.4s
	fmla	v17.4s, v1.4s, v26.4s
	fadd	v18.4s, v30.4s, v28.4s
	fmla	v21.4s, v3.4s, v27.4s
	fsub	v24.4s, v31.4s, v8.4s
	fadd	v19.4s, v31.4s, v8.4s
	fmla	v22.4s, v3.4s, v29.4s
	fsub	v20.4s, v12.4s, v10.4s
	fadd	v23.4s, v9.4s, v23.4s
	stur	q18, [x8, #-16]
	stp	q24, q25, [x16, #-16]
	add	x16, x8, x11
	fadd	v24.4s, v22.4s, v17.4s
	fsub	v17.4s, v17.4s, v22.4s
	stp	q19, q20, [x16, #-16]
	add	x16, x8, x9
	fsub	v19.4s, v16.4s, v21.4s
	fadd	v18.4s, v23.4s, v26.4s
	fadd	v16.4s, v16.4s, v21.4s
	stp	q19, q24, [x17, #-16]
	str	q18, [x8], #32
	stp	q16, q17, [x16, #-16]
	b.ne	.LBB195_3
	b	.LBB195_10
.LBB195_4:
	str	x9, [sp, #16]                   // 8-byte Folded Spill
	cbz	x2, .LBB195_10
// %bb.5:
	lsl	x11, x2, #1
	lsl	x12, x2, #2
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	mul	x10, x2, x1
	mov	w14, #160
	mov	x23, x5
	str	x11, [sp, #64]                  // 8-byte Folded Spill
	add	x11, x11, x2
	lsl	x18, x11, #1
	mov	w5, #96
	add	x17, x23, #4
	madd	x23, x10, x14, x8
	stp	x12, x11, [sp, #48]             // 16-byte Folded Spill
	add	x11, x12, x2
	ldr	x12, [sp, #16]                  // 8-byte Folded Reload
	add	x15, x8, x10, lsl #7
	madd	x21, x10, x5, x8
	add	x27, x8, x10, lsl #6
	stp	x11, x18, [sp, #32]             // 16-byte Folded Spill
	mov	w11, #224
	add	x3, x13, x12, lsl #6
	madd	x4, x12, x14, x13
	add	x6, x3, #64
	mov	w3, #24
	mul	x11, x1, x11
	add	x29, x8, x10, lsl #5
	mul	x3, x1, x3
	add	x7, x4, #160
	madd	x4, x12, x5, x13
	lsl	x16, x1, #5
	sub	x22, x3, #24
	mov	w3, #40
	str	x11, [sp, #24]                  // 8-byte Folded Spill
	mov	w11, #192
	mul	x14, x1, x3
	mov	w3, #56455
	madd	x0, x1, x11, x13
	movk	w3, #48739, lsl #16
	sub	x28, x14, #40
	mov	w14, #40199
	madd	x30, x10, x11, x8
	mov	w10, #42469
	mov	w11, #38112
	movk	w14, #16159, lsl #16
	movk	w10, #48998, lsl #16
	movk	w11, #49017, lsl #16
	dup	v14.4s, w3
	mov	w3, #9730
	dup	v11.4s, w14
	mov	w14, #9756
	movk	w3, #48862, lsl #16
	dup	v2.4s, w10
	dup	v3.4s, w11
	mov	w10, #9730
	mov	w11, #9756
	movk	w14, #48968, lsl #16
	movk	w10, #16094, lsl #16
	movk	w11, #16200, lsl #16
	add	x20, x13, x12, lsl #7
	add	x19, x4, #96
	lsl	x4, x1, #4
	mov	x9, xzr
	add	x18, x13, x16
	add	x20, x20, #128
	mov	x12, x2
	sub	x24, x4, #16
	sub	x25, x16, #32
	lsl	x26, x1, #3
	dup	v12.4s, w3
	mov	x4, x8
	mov	x3, x13
	dup	v7.4s, w14
	dup	v6.4s, w10
	dup	v0.4s, w11
	str	x17, [sp, #8]                   // 8-byte Folded Spill
	stp	q12, q14, [sp, #80]             // 32-byte Folded Spill
	str	q11, [sp, #112]                 // 16-byte Folded Spill
	b	.LBB195_7
.LBB195_6:                              //   in Loop: Header=BB195_7 Depth=1
	ldr	x10, [sp, #24]                  // 8-byte Folded Reload
	add	x9, x9, #1
	mov	v6.16b, v5.16b
	add	x15, x15, x16
	add	x4, x4, x16
	add	x21, x21, x16
	add	x3, x3, x10
	add	x18, x18, x10
	add	x0, x0, x10
	add	x6, x6, x10
	add	x7, x7, x10
	add	x19, x19, x10
	add	x20, x20, x10
	add	x23, x23, x16
	add	x27, x27, x16
	add	x29, x29, x16
	add	x30, x30, x16
	mov	x12, x2
	cmp	x9, x2
	b.eq	.LBB195_10
.LBB195_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB195_9 Depth 2
	lsl	x10, x9, #3
	ldr	x17, [sp, #72]                  // 8-byte Folded Reload
	sub	x10, x10, x9
	mov	x13, x12
	add	x11, x10, #6
	add	x12, x10, #2
	mul	x14, x10, x1
	ldr	q5, [sp, #80]                   // 16-byte Folded Reload
	mul	x11, x11, x1
	cmp	x1, #2
	mul	x12, x12, x1
	add	x5, x17, x14, lsl #5
	add	x14, x1, x14
	add	x11, x17, x11, lsl #5
	add	x14, x17, x14, lsl #5
	add	x12, x17, x12, lsl #5
	ldp	q16, q17, [x5]
	ldp	q18, q19, [x14]
	add	x14, x10, #5
	mul	x14, x14, x1
	ldp	q20, q21, [x11]
	add	x11, x10, #3
	add	x10, x10, #4
	mul	x11, x11, x1
	mul	x10, x10, x1
	fadd	v28.4s, v18.4s, v20.4s
	ldp	q24, q26, [x12]
	add	x12, x17, x14, lsl #5
	add	x11, x17, x11, lsl #5
	add	x10, x17, x10, lsl #5
	fsub	v18.4s, v18.4s, v20.4s
	fadd	v27.4s, v19.4s, v21.4s
	fsub	v19.4s, v19.4s, v21.4s
	ldp	q20, q29, [x12]
	fadd	v10.4s, v17.4s, v27.4s
	fadd	v22.4s, v24.4s, v20.4s
	fsub	v25.4s, v24.4s, v20.4s
	ldp	q30, q31, [x11]
	fadd	v23.4s, v26.4s, v29.4s
	fsub	v26.4s, v26.4s, v29.4s
	fadd	v29.4s, v16.4s, v28.4s
	fmul	v12.4s, v25.4s, v3.4s
	fadd	v10.4s, v10.4s, v23.4s
	ldp	q8, q9, [x10]
	fadd	v29.4s, v29.4s, v22.4s
	mul	x10, x9, x1
	fmla	v12.4s, v7.4s, v18.4s
	fmul	v15.4s, v26.4s, v6.4s
	fadd	v20.4s, v30.4s, v8.4s
	add	x10, x8, x10, lsl #5
	fsub	v24.4s, v30.4s, v8.4s
	mov	v30.16b, v16.16b
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	mov	v8.16b, v17.16b
	fmla	v15.4s, v3.4s, v19.4s
	fadd	v21.4s, v31.4s, v9.4s
	fadd	v13.4s, v29.4s, v20.4s
	add	x11, x9, x11
	fmla	v30.4s, v11.4s, v28.4s
	fmla	v8.4s, v11.4s, v27.4s
	fmul	v11.4s, v26.4s, v3.4s
	fsub	v29.4s, v31.4s, v9.4s
	fadd	v10.4s, v10.4s, v21.4s
	fmla	v30.4s, v14.4s, v22.4s
	fmla	v8.4s, v14.4s, v23.4s
	fmla	v11.4s, v7.4s, v19.4s
	mov	v31.16b, v16.16b
	fmla	v15.4s, v0.4s, v29.4s
	stp	q13, q10, [x10]
	fmla	v30.4s, v2.4s, v20.4s
	add	x10, x9, x13
	fmla	v8.4s, v2.4s, v21.4s
	fmla	v11.4s, v5.4s, v29.4s
	ldr	q5, [sp, #80]                   // 16-byte Folded Reload
	mul	x10, x10, x1
	fmla	v31.4s, v14.4s, v28.4s
	mov	v9.16b, v17.16b
	fmla	v16.4s, v2.4s, v28.4s
	fmla	v12.4s, v5.4s, v24.4s
	fmla	v17.4s, v2.4s, v27.4s
	fsub	v10.4s, v30.4s, v11.4s
	add	x10, x8, x10, lsl #5
	fmla	v31.4s, v2.4s, v22.4s
	fmla	v9.4s, v14.4s, v27.4s
	fadd	v13.4s, v12.4s, v8.4s
	fmul	v14.4s, v25.4s, v6.4s
	fadd	v30.4s, v30.4s, v11.4s
	ldr	q11, [sp, #112]                 // 16-byte Folded Reload
	fmla	v9.4s, v2.4s, v23.4s
	stp	q10, q13, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
	fmla	v14.4s, v3.4s, v18.4s
	fsub	v8.4s, v8.4s, v12.4s
	fmla	v31.4s, v11.4s, v20.4s
	add	x10, x8, x10, lsl #5
	fmla	v9.4s, v11.4s, v21.4s
	add	x11, x9, x11
	ldr	q12, [sp, #80]                  // 16-byte Folded Reload
	fmla	v14.4s, v0.4s, v24.4s
	fmla	v16.4s, v11.4s, v22.4s
	stp	q30, q8, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #32]                  // 8-byte Folded Reload
	fmla	v17.4s, v11.4s, v23.4s
	fsub	v30.4s, v31.4s, v15.4s
	fadd	v8.4s, v14.4s, v9.4s
	add	x10, x8, x10, lsl #5
	add	x11, x9, x11
	fmul	v26.4s, v26.4s, v0.4s
	fmul	v25.4s, v25.4s, v0.4s
	mul	x11, x11, x1
	stp	q30, q8, [x10]
	mov	v5.16b, v6.16b
	add	x10, x8, x11, lsl #5
	fmla	v26.4s, v12.4s, v19.4s
	ldp	x12, x11, [sp, #48]             // 16-byte Folded Reload
	fmla	v25.4s, v12.4s, v18.4s
	fsub	v18.4s, v9.4s, v14.4s
	ldr	q14, [sp, #96]                  // 16-byte Folded Reload
	fadd	v19.4s, v31.4s, v15.4s
	fmla	v26.4s, v3.4s, v29.4s
	add	x12, x9, x12
	fmla	v16.4s, v14.4s, v20.4s
	fmla	v17.4s, v14.4s, v21.4s
	add	x11, x9, x11
	fmla	v25.4s, v3.4s, v24.4s
	stp	q19, q18, [x10]
	mul	x10, x12, x1
	mul	x11, x11, x1
	fsub	v18.4s, v16.4s, v26.4s
	fadd	v19.4s, v25.4s, v17.4s
	add	x10, x8, x10, lsl #5
	fadd	v16.4s, v16.4s, v26.4s
	add	x11, x8, x11, lsl #5
	fsub	v17.4s, v17.4s, v25.4s
	stp	q18, q19, [x11]
	stp	q16, q17, [x10]
	b.lo	.LBB195_6
// %bb.8:                               //   in Loop: Header=BB195_7 Depth=1
	ldp	x14, x10, [sp, #8]              // 16-byte Folded Reload
	mov	x5, xzr
.LBB195_9:                              //   Parent Loop BB195_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x11, x18, x5
	add	x12, x0, x5
	add	x13, x3, x5
	ldur	s13, [x14, #-4]
	add	x17, x30, x5
	subs	x10, x10, #1
	ldp	q19, q20, [x11, #32]
	add	x11, x6, x5
	ldp	q21, q22, [x12, #32]
	add	x12, x7, x5
	fadd	v29.4s, v19.4s, v21.4s
	fsub	v19.4s, v19.4s, v21.4s
	ldp	q24, q25, [x11, #32]
	add	x11, x19, x5
	fadd	v18.4s, v20.4s, v22.4s
	fsub	v23.4s, v20.4s, v22.4s
	ldp	q21, q28, [x12, #32]
	add	x12, x20, x5
	fadd	v26.4s, v24.4s, v21.4s
	fsub	v27.4s, v24.4s, v21.4s
	ldp	q17, q16, [x13, #32]
	fadd	v22.4s, v25.4s, v28.4s
	add	x13, x14, x26
	fsub	v28.4s, v25.4s, v28.4s
	ldp	q30, q31, [x11, #32]
	fmul	v10.4s, v28.4s, v3.4s
	add	x11, x4, x5
	fmul	v6.4s, v28.4s, v5.4s
	fmul	v28.4s, v28.4s, v0.4s
	fmla	v10.4s, v7.4s, v23.4s
	ldp	q8, q9, [x12, #32]
	fmla	v6.4s, v3.4s, v23.4s
	add	x12, x14, x28
	fadd	v24.4s, v30.4s, v8.4s
	fsub	v21.4s, v30.4s, v8.4s
	mov	v30.16b, v17.16b
	fadd	v20.4s, v31.4s, v9.4s
	fsub	v25.4s, v31.4s, v9.4s
	fadd	v31.4s, v17.4s, v29.4s
	fadd	v9.4s, v16.4s, v18.4s
	fmla	v30.4s, v11.4s, v29.4s
	mov	v8.16b, v16.16b
	fmla	v10.4s, v12.4s, v25.4s
	fmla	v6.4s, v0.4s, v25.4s
	fadd	v31.4s, v31.4s, v26.4s
	fadd	v9.4s, v9.4s, v22.4s
	fmla	v30.4s, v14.4s, v26.4s
	fmla	v8.4s, v11.4s, v18.4s
	fmul	v11.4s, v27.4s, v3.4s
	fadd	v31.4s, v31.4s, v24.4s
	fadd	v9.4s, v9.4s, v20.4s
	fmla	v30.4s, v2.4s, v24.4s
	fmla	v8.4s, v14.4s, v22.4s
	fmla	v11.4s, v7.4s, v19.4s
	stp	q31, q9, [x11, #32]
	mov	x11, x14
	fmla	v8.4s, v2.4s, v20.4s
	fmla	v11.4s, v12.4s, v21.4s
	fsub	v9.4s, v30.4s, v10.4s
	fadd	v10.4s, v30.4s, v10.4s
	mov	v30.16b, v17.16b
	fmla	v17.4s, v2.4s, v29.4s
	ld1r	{ v14.4s }, [x11], x22
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	fadd	v12.4s, v11.4s, v8.4s
	fneg	v15.4s, v9.4s
	fmla	v30.4s, v1.4s, v29.4s
	ldr	q1, [sp, #96]                   // 16-byte Folded Reload
	mov	v31.16b, v16.16b
	fmla	v16.4s, v2.4s, v18.4s
	fmul	v4.4s, v12.4s, v14.4s
	fmul	v14.4s, v14.4s, v15.4s
	fmul	v15.4s, v27.4s, v5.4s
	fmla	v30.4s, v2.4s, v26.4s
	fmla	v31.4s, v1.4s, v18.4s
	mov	v1.16b, v5.16b
	ldr	q5, [sp, #112]                  // 16-byte Folded Reload
	fsub	v8.4s, v8.4s, v11.4s
	fmla	v4.4s, v9.4s, v13.s[0]
	fmla	v14.4s, v12.4s, v13.s[0]
	fmla	v15.4s, v3.4s, v19.4s
	ldp	s12, s9, [x12, #-4]
	fmla	v31.4s, v2.4s, v22.4s
	fmla	v30.4s, v5.4s, v24.4s
	fneg	v11.4s, v10.4s
	ldr	q5, [sp, #112]                  // 16-byte Folded Reload
	fmla	v15.4s, v0.4s, v21.4s
	add	x12, x29, x5
	fmul	v13.4s, v8.4s, v9.s[0]
	fmla	v31.4s, v5.4s, v20.4s
	fsub	v5.4s, v30.4s, v6.4s
	fmul	v9.4s, v11.4s, v9.s[0]
	stp	q4, q14, [x12, #32]
	add	x12, x27, x5
	fmla	v13.4s, v10.4s, v12.s[0]
	fadd	v10.4s, v15.4s, v31.4s
	fneg	v11.4s, v5.4s
	fmla	v9.4s, v8.4s, v12.s[0]
	ldur	s8, [x13, #-8]
	ldp	q12, q14, [sp, #80]             // 32-byte Folded Reload
	fadd	v6.4s, v30.4s, v6.4s
	fmul	v4.4s, v10.4s, v8.s[0]
	stp	q13, q9, [x17, #32]
	fmul	v8.4s, v11.4s, v8.s[0]
	fmla	v28.4s, v12.4s, v23.4s
	ldur	s11, [x13, #-12]
	fmla	v28.4s, v3.4s, v25.4s
	fmla	v4.4s, v5.4s, v11.s[0]
	fmla	v8.4s, v10.4s, v11.s[0]
	ldr	q11, [sp, #112]                 // 16-byte Folded Reload
	fmul	v5.4s, v27.4s, v0.4s
	fmla	v17.4s, v11.4s, v26.4s
	fmla	v16.4s, v11.4s, v22.4s
	stp	q4, q8, [x12, #32]
	add	x12, x14, x25
	fmla	v5.4s, v12.4s, v19.4s
	fsub	v4.4s, v31.4s, v15.4s
	fmla	v17.4s, v14.4s, v24.4s
	fmla	v16.4s, v14.4s, v20.4s
	fneg	v19.4s, v6.4s
	fmla	v5.4s, v3.4s, v21.4s
	ldp	s21, s18, [x12, #-4]
	fsub	v20.4s, v17.4s, v28.4s
	add	x12, x14, x24
	fadd	v17.4s, v17.4s, v28.4s
	add	x14, x14, #8
	fmul	v22.4s, v4.4s, v18.s[0]
	fmul	v18.4s, v19.4s, v18.s[0]
	fadd	v19.4s, v5.4s, v16.4s
	fneg	v24.4s, v20.4s
	fsub	v5.4s, v16.4s, v5.4s
	ldp	s16, s23, [x12, #-4]
	fneg	v26.4s, v17.4s
	fmla	v22.4s, v6.4s, v21.s[0]
	fmla	v18.4s, v4.4s, v21.s[0]
	add	x12, x23, x5
	fmul	v25.4s, v19.4s, v23.s[0]
	fmul	v23.4s, v24.4s, v23.s[0]
	ldr	s24, [x11]
	stp	q22, q18, [x12, #32]
	add	x12, x15, x5
	fmul	v4.4s, v5.4s, v24.s[0]
	fmul	v6.4s, v26.4s, v24.s[0]
	fmla	v25.4s, v20.4s, v16.s[0]
	fmla	v23.4s, v19.4s, v16.s[0]
	ldur	s16, [x11, #-4]
	add	x11, x21, x5
	add	x5, x5, #32
	fmla	v4.4s, v17.4s, v16.s[0]
	fmla	v6.4s, v5.4s, v16.s[0]
	mov	v5.16b, v1.16b
	stp	q25, q23, [x11, #32]
	stp	q4, q6, [x12, #32]
	b.ne	.LBB195_9
	b	.LBB195_6
.LBB195_10:
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #208]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #192]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #176]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #160]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #144]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #128]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end195:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end195-_ZNK9pocketfft6detail5cfftpIfE5pass7ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #992
	.cfi_def_cfa_offset 1152
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #208]              // 16-byte Folded Spill
	b.ne	.LBB196_4
// %bb.1:
	cbz	x2, .LBB196_10
// %bb.2:
	mov	w16, #23652
	mov	w0, #45383
	movk	w16, #16215, lsl #16
	movk	w0, #16084, lsl #16
	mov	w1, #47867
	mov	w3, #42228
	movk	w1, #15889, lsl #16
	movk	w3, #16167, lsl #16
	dup	v1.4s, w16
	mov	w16, #41301
	dup	v0.4s, w0
	movk	w16, #16245, lsl #16
	mov	w0, #56740
	mov	w4, #16192
	str	q0, [sp, #928]                  // 16-byte Folded Spill
	dup	v0.4s, w1
	movk	w0, #49000, lsl #16
	movk	w4, #48784, lsl #16
	stp	q0, q1, [sp, #464]              // 32-byte Folded Spill
	dup	v1.4s, w3
	dup	v0.4s, w16
	mov	w16, #26480
	movk	w16, #48906, lsl #16
	mov	w1, #30926
	stp	q0, q1, [sp, #432]              // 32-byte Folded Spill
	dup	v1.4s, w0
	mov	w0, #25840
	mov	w3, #16192
	movk	w0, #49021, lsl #16
	movk	w1, #48961, lsl #16
	movk	w3, #16016, lsl #16
	dup	v2.4s, w16
	ldp	x9, x14, [sp, #208]             // 16-byte Folded Reload
	dup	v0.4s, w0
	mov	w0, #25840
	movk	w0, #16253, lsl #16
	dup	v3.4s, w1
	str	q0, [sp, #944]                  // 16-byte Folded Spill
	dup	v0.4s, w4
	mov	w1, #26480
	mov	w11, #224
	stp	q0, q2, [sp, #624]              // 32-byte Folded Spill
	dup	v0.4s, w3
	movk	w1, #16138, lsl #16
	mov	w3, #56740
	stp	q0, q1, [sp, #512]              // 32-byte Folded Spill
	dup	v0.4s, w0
	ldp	q8, q30, [sp, #464]             // 32-byte Folded Reload
	movk	w3, #16232, lsl #16
	add	x15, x2, x2, lsl #1
	add	x18, x2, x2, lsl #2
	mul	x11, x2, x11
	add	x17, x2, x2, lsl #3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	dup	v0.4s, w1
	lsl	x8, x15, #6
	add	x9, x9, #16
	lsl	x10, x18, #5
	lsl	x12, x2, #7
	lsl	x13, x2, #8
	add	x14, x14, #176
	lsl	x15, x15, #5
	lsl	x16, x17, #5
	lsl	x17, x2, #6
	lsl	x18, x18, #6
	lsl	x0, x2, #5
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	dup	v0.4s, w3
	stp	q0, q3, [sp, #400]              // 32-byte Folded Spill
.LBB196_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x14, #-144]
	add	x1, x9, x0
	add	x3, x9, x17
	subs	x2, x2, #1
	ldp	q18, q19, [x14, #144]
	fadd	v3.4s, v5.4s, v18.4s
	fsub	v28.4s, v5.4s, v18.4s
	ldp	q25, q20, [x14, #112]
	fadd	v10.4s, v6.4s, v19.4s
	fsub	v1.4s, v6.4s, v19.4s
	stp	q3, q10, [sp, #736]             // 32-byte Folded Spill
	fmul	v14.4s, v3.4s, v30.4s
	ldp	q26, q5, [x14, #-112]
	fadd	v29.4s, v26.4s, v25.4s
	fsub	v25.4s, v26.4s, v25.4s
	ldp	q18, q6, [x14, #80]
	fadd	v11.4s, v5.4s, v20.4s
	fsub	v22.4s, v5.4s, v20.4s
	stp	q29, q28, [sp, #656]            // 32-byte Folded Spill
	str	q25, [sp, #768]                 // 16-byte Folded Spill
	stp	q1, q11, [sp, #704]             // 32-byte Folded Spill
	ldp	q19, q26, [x14, #-80]
	fadd	v2.4s, v19.4s, v18.4s
	fsub	v16.4s, v19.4s, v18.4s
	ldp	q20, q5, [x14, #48]
	fadd	v23.4s, v26.4s, v6.4s
	fsub	v6.4s, v26.4s, v6.4s
	str	q2, [sp, #688]                  // 16-byte Folded Spill
	stp	q16, q22, [sp, #960]            // 32-byte Folded Spill
	ldp	q12, q13, [x14, #-48]
	fadd	v19.4s, v12.4s, v20.4s
	fsub	v17.4s, v12.4s, v20.4s
	ldp	q3, q0, [x14, #-176]
	fmul	v20.4s, v10.4s, v30.4s
	fadd	v16.4s, v13.4s, v5.4s
	stp	q19, q23, [sp, #848]            // 32-byte Folded Spill
	fsub	v12.4s, v13.4s, v5.4s
	fadd	v14.4s, v3.4s, v14.4s
	mov	v5.16b, v2.16b
	ldr	q9, [sp, #928]                  // 16-byte Folded Reload
	stp	q0, q3, [sp, #896]              // 32-byte Folded Spill
	ldr	q24, [sp, #528]                 // 16-byte Folded Reload
	stp	q17, q16, [sp, #816]            // 32-byte Folded Spill
	fadd	v3.4s, v0.4s, v20.4s
	ldr	q18, [sp, #640]                 // 16-byte Folded Reload
	fmul	v15.4s, v29.4s, v9.4s
	ldp	q20, q31, [x14, #16]
	fmul	v0.4s, v22.4s, v24.4s
	ldr	q26, [sp, #448]                 // 16-byte Folded Reload
	fmul	v21.4s, v11.4s, v9.4s
	fmul	v27.4s, v25.4s, v24.4s
	str	q12, [sp, #880]                 // 16-byte Folded Spill
	ldp	q7, q17, [x14, #-16]
	fadd	v15.4s, v14.4s, v15.4s
	fmla	v0.4s, v18.4s, v1.4s
	fmul	v22.4s, v2.4s, v8.4s
	add	x14, x14, #352
	fadd	v21.4s, v3.4s, v21.4s
	fmla	v27.4s, v18.4s, v28.4s
	fadd	v4.4s, v7.4s, v20.4s
	fmul	v2.4s, v23.4s, v8.4s
	ldr	q3, [sp, #944]                  // 16-byte Folded Reload
	ldp	q25, q18, [sp, #416]            // 32-byte Folded Reload
	fsub	v15.4s, v15.4s, v22.4s
	stp	q4, q6, [sp, #784]              // 32-byte Folded Spill
	fmul	v23.4s, v19.4s, v26.4s
	fmla	v0.4s, v3.4s, v6.4s
	fsub	v14.4s, v17.4s, v31.4s
	mov	v22.16b, v6.16b
	fsub	v6.4s, v21.4s, v2.4s
	fmul	v21.4s, v16.4s, v26.4s
	fmla	v0.4s, v25.4s, v12.4s
	fsub	v23.4s, v15.4s, v23.4s
	ldr	q12, [sp, #736]                 // 16-byte Folded Reload
	mov	v16.16b, v28.16b
	fmul	v28.4s, v4.4s, v18.4s
	fsub	v19.4s, v7.4s, v20.4s
	ldr	q7, [sp, #624]                  // 16-byte Folded Reload
	ldr	q20, [sp, #960]                 // 16-byte Folded Reload
	fadd	v2.4s, v17.4s, v31.4s
	ldr	q31, [sp, #912]                 // 16-byte Folded Reload
	fsub	v15.4s, v23.4s, v28.4s
	fmla	v0.4s, v7.4s, v14.4s
	fmul	v28.4s, v12.4s, v9.4s
	fmla	v27.4s, v3.4s, v20.4s
	fmul	v17.4s, v10.4s, v9.4s
	stp	q14, q19, [sp, #576]            // 32-byte Folded Spill
	mov	v13.16b, v1.16b
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	fsub	v23.4s, v15.4s, v0.4s
	fadd	v31.4s, v31.4s, v28.4s
	ldr	q28, [sp, #896]                 // 16-byte Folded Reload
	fsub	v6.4s, v6.4s, v21.4s
	fmla	v27.4s, v25.4s, v1.4s
	fmul	v21.4s, v2.4s, v18.4s
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #768]                  // 16-byte Folded Reload
	fadd	v17.4s, v28.4s, v17.4s
	stur	q23, [x1, #-16]
	fmul	v28.4s, v29.4s, v26.4s
	fmla	v27.4s, v7.4s, v19.4s
	fmul	v23.4s, v2.4s, v25.4s
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fmul	v29.4s, v11.4s, v26.4s
	str	q9, [sp, #560]                  // 16-byte Folded Spill
	fsub	v3.4s, v6.4s, v21.4s
	fsub	v7.4s, v31.4s, v28.4s
	fmul	v28.4s, v2.4s, v25.4s
	fmla	v23.4s, v24.4s, v16.4s
	ldp	q31, q4, [sp, #848]             // 32-byte Folded Reload
	fsub	v17.4s, v17.4s, v29.4s
	fmul	v21.4s, v5.4s, v18.4s
	fmla	v28.4s, v24.4s, v13.4s
	fadd	v0.4s, v15.4s, v0.4s
	fsub	v5.4s, v3.4s, v27.4s
	ldp	q10, q24, [sp, #496]            // 32-byte Folded Reload
	fmul	v29.4s, v4.4s, v18.4s
	fsub	v7.4s, v7.4s, v21.4s
	fmul	v21.4s, v31.4s, v8.4s
	mov	v11.16b, v19.16b
	fsub	v17.4s, v17.4s, v29.4s
	ldr	q13, [sp, #832]                 // 16-byte Folded Reload
	fmla	v23.4s, v24.4s, v20.4s
	fmla	v28.4s, v24.4s, v22.4s
	ldr	q2, [sp, #784]                  // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v21.4s
	fmul	v29.4s, v13.4s, v8.4s
	fmla	v23.4s, v10.4s, v1.4s
	ldr	q1, [sp, #880]                  // 16-byte Folded Reload
	fmul	v20.4s, v9.4s, v30.4s
	fadd	v21.4s, v27.4s, v3.4s
	ldr	q27, [sp, #656]                 // 16-byte Folded Reload
	fsub	v17.4s, v17.4s, v29.4s
	fmla	v28.4s, v10.4s, v1.4s
	fmul	v29.4s, v2.4s, v30.4s
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	ldp	q16, q11, [sp, #896]            // 32-byte Folded Reload
	str	q21, [x1]
	add	x1, x9, x18
	fmla	v28.4s, v1.4s, v14.4s
	fmla	v23.4s, v1.4s, v19.4s
	fadd	v6.4s, v7.4s, v29.4s
	fadd	v7.4s, v17.4s, v20.4s
	stp	q0, q5, [x1, #-16]
	fmul	v5.4s, v12.4s, v8.4s
	add	x1, x9, x16
	ldp	q19, q29, [sp, #752]            // 32-byte Folded Reload
	fsub	v0.4s, v6.4s, v28.4s
	ldr	q1, [sp, #928]                  // 16-byte Folded Reload
	fadd	v17.4s, v23.4s, v7.4s
	fsub	v5.4s, v11.4s, v5.4s
	ldr	q20, [sp, #400]                 // 16-byte Folded Reload
	mov	v3.16b, v12.16b
	ldr	q12, [sp, #720]                 // 16-byte Folded Reload
	fadd	v6.4s, v6.4s, v28.4s
	ldr	q28, [sp, #688]                 // 16-byte Folded Reload
	stp	q0, q17, [x3, #-16]
	fmul	v0.4s, v19.4s, v8.4s
	fmul	v17.4s, v27.4s, v18.4s
	fmul	v21.4s, v12.4s, v18.4s
	fsub	v7.4s, v7.4s, v23.4s
	fsub	v0.4s, v16.4s, v0.4s
	fsub	v5.4s, v5.4s, v17.4s
	fmul	v17.4s, v28.4s, v1.4s
	stp	q6, q7, [x1, #-16]
	add	x1, x9, x15
	fsub	v0.4s, v0.4s, v21.4s
	fmul	v6.4s, v4.4s, v1.4s
	fadd	v5.4s, v5.4s, v17.4s
	fmul	v17.4s, v31.4s, v30.4s
	ldr	q31, [sp, #704]                 // 16-byte Folded Reload
	mov	v22.16b, v4.16b
	ldr	q4, [sp, #976]                  // 16-byte Folded Reload
	fadd	v1.4s, v0.4s, v6.4s
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fmul	v6.4s, v29.4s, v24.4s
	fadd	v5.4s, v5.4s, v17.4s
	fmul	v17.4s, v4.4s, v24.4s
	ldr	q24, [sp, #672]                 // 16-byte Folded Reload
	fmul	v21.4s, v2.4s, v26.4s
	fmul	v7.4s, v13.4s, v30.4s
	fmla	v6.4s, v0.4s, v24.4s
	fmla	v17.4s, v0.4s, v31.4s
	fsub	v0.4s, v5.4s, v21.4s
	ldr	q5, [sp, #880]                  // 16-byte Folded Reload
	fmul	v21.4s, v3.4s, v26.4s
	ldr	q3, [sp, #960]                  // 16-byte Folded Reload
	fadd	v1.4s, v1.4s, v7.4s
	fmul	v7.4s, v9.4s, v26.4s
	fmul	v23.4s, v27.4s, v8.4s
	str	q0, [sp, #544]                  // 16-byte Folded Spill
	fsub	v21.4s, v11.4s, v21.4s
	ldr	q0, [sp, #800]                  // 16-byte Folded Reload
	fmla	v6.4s, v20.4s, v3.4s
	fsub	v9.4s, v1.4s, v7.4s
	ldr	q1, [sp, #640]                  // 16-byte Folded Reload
	fmla	v17.4s, v20.4s, v0.4s
	fmul	v7.4s, v19.4s, v26.4s
	ldr	q19, [sp, #816]                 // 16-byte Folded Reload
	fsub	v21.4s, v21.4s, v23.4s
	fmul	v23.4s, v28.4s, v30.4s
	mov	v15.16b, v2.16b
	fmla	v6.4s, v1.4s, v19.4s
	ldp	q2, q13, [sp, #576]             // 32-byte Folded Reload
	fmla	v17.4s, v1.4s, v5.4s
	fsub	v7.4s, v16.4s, v7.4s
	fmul	v27.4s, v12.4s, v8.4s
	fadd	v21.4s, v21.4s, v23.4s
	fmul	v23.4s, v4.4s, v10.4s
	fmla	v17.4s, v25.4s, v2.4s
	fmul	v28.4s, v29.4s, v10.4s
	fmla	v6.4s, v25.4s, v13.4s
	ldp	q10, q4, [sp, #832]             // 32-byte Folded Reload
	mov	v14.16b, v1.16b
	fsub	v7.4s, v7.4s, v27.4s
	fmla	v23.4s, v25.4s, v31.4s
	fmul	v27.4s, v22.4s, v30.4s
	fmla	v28.4s, v25.4s, v24.4s
	mov	v12.16b, v29.16b
	fmul	v24.4s, v10.4s, v18.4s
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	fmla	v23.4s, v14.4s, v0.4s
	fadd	v7.4s, v7.4s, v27.4s
	fmla	v28.4s, v14.4s, v3.4s
	fadd	v27.4s, v6.4s, v9.4s
	ldr	q22, [sp, #928]                 // 16-byte Folded Reload
	fsub	v29.4s, v1.4s, v17.4s
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	fmul	v31.4s, v4.4s, v18.4s
	ldr	q14, [sp, #560]                 // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v24.4s
	ldr	q3, [sp, #688]                  // 16-byte Folded Reload
	fmul	v24.4s, v15.4s, v22.4s
	fmla	v23.4s, v0.4s, v5.4s
	stp	q29, q27, [x1, #-16]
	fmla	v28.4s, v0.4s, v19.4s
	fsub	v21.4s, v21.4s, v31.4s
	add	x1, x9, x13
	fmul	v27.4s, v14.4s, v22.4s
	mov	v31.16b, v5.16b
	fmla	v23.4s, v20.4s, v2.4s
	mov	v15.16b, v0.16b
	fmla	v28.4s, v20.4s, v13.4s
	fadd	v5.4s, v1.4s, v17.4s
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	fsub	v0.4s, v9.4s, v6.4s
	fadd	v6.4s, v21.4s, v24.4s
	ldr	q21, [sp, #736]                 // 16-byte Folded Reload
	fadd	v7.4s, v7.4s, v27.4s
	ldr	q24, [sp, #656]                 // 16-byte Folded Reload
	mov	v29.16b, v19.16b
	stp	q5, q0, [x1, #-16]
	add	x1, x9, x12
	fsub	v0.4s, v6.4s, v23.4s
	fadd	v5.4s, v28.4s, v7.4s
	fadd	v17.4s, v11.4s, v21.4s
	fmul	v21.4s, v21.4s, v18.4s
	fmul	v19.4s, v24.4s, v30.4s
	stp	q0, q5, [x1, #-16]
	add	x1, x9, x11
	fadd	v0.4s, v17.4s, v24.4s
	fsub	v5.4s, v11.4s, v21.4s
	ldr	q21, [sp, #752]                 // 16-byte Folded Reload
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fadd	v6.4s, v6.4s, v23.4s
	fmul	v17.4s, v21.4s, v18.4s
	fadd	v21.4s, v16.4s, v21.4s
	fadd	v5.4s, v5.4s, v19.4s
	fmul	v19.4s, v12.4s, v1.4s
	fsub	v17.4s, v16.4s, v17.4s
	ldr	q16, [sp, #720]                 // 16-byte Folded Reload
	fmul	v23.4s, v2.4s, v1.4s
	ldr	q1, [sp, #672]                  // 16-byte Folded Reload
	fadd	v0.4s, v0.4s, v3.4s
	fmul	v18.4s, v16.4s, v30.4s
	fmla	v19.4s, v15.4s, v1.4s
	ldr	q1, [sp, #704]                  // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v28.4s
	fadd	v21.4s, v21.4s, v16.4s
	fadd	v17.4s, v17.4s, v18.4s
	fmla	v23.4s, v15.4s, v1.4s
	fmul	v18.4s, v3.4s, v26.4s
	ldr	q3, [sp, #864]                  // 16-byte Folded Reload
	ldp	q16, q1, [sp, #944]             // 32-byte Folded Reload
	stp	q6, q7, [x1, #-16]
	fadd	v0.4s, v0.4s, v4.4s
	add	x1, x9, x10
	fmul	v24.4s, v3.4s, v26.4s
	fmla	v19.4s, v25.4s, v1.4s
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	fsub	v5.4s, v5.4s, v18.4s
	fmul	v18.4s, v10.4s, v22.4s
	fsub	v6.4s, v17.4s, v24.4s
	fmla	v23.4s, v25.4s, v1.4s
	fmul	v17.4s, v4.4s, v22.4s
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	fmla	v19.4s, v20.4s, v29.4s
	mov	v2.16b, v4.16b
	fmul	v7.4s, v1.4s, v8.4s
	fmla	v23.4s, v20.4s, v31.4s
	fadd	v5.4s, v5.4s, v17.4s
	fadd	v6.4s, v6.4s, v18.4s
	fmla	v19.4s, v16.4s, v13.4s
	fmul	v17.4s, v14.4s, v8.4s
	fmla	v23.4s, v16.4s, v9.4s
	fsub	v5.4s, v5.4s, v7.4s
	fadd	v7.4s, v21.4s, v3.4s
	fsub	v6.4s, v6.4s, v17.4s
	fadd	v3.4s, v0.4s, v1.4s
	fsub	v17.4s, v5.4s, v23.4s
	fadd	v7.4s, v7.4s, v10.4s
	fadd	v18.4s, v19.4s, v6.4s
	fadd	v5.4s, v5.4s, v23.4s
	fsub	v6.4s, v6.4s, v19.4s
	fadd	v0.4s, v7.4s, v14.4s
	stp	q17, q18, [x1, #-16]
	add	x1, x9, x8
	mov	v16.16b, v14.16b
	stp	q3, q0, [x9, #-16]
	add	x9, x9, #32
	stp	q5, q6, [x1, #-16]
	b.ne	.LBB196_3
	b	.LBB196_10
.LBB196_4:
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	cbz	x2, .LBB196_10
// %bb.5:
	lsl	x8, x2, #2
	ldr	x19, [sp, #24]                  // 8-byte Folded Reload
	ldp	x27, x22, [sp, #208]            // 16-byte Folded Reload
	mul	x11, x2, x1
	mov	w14, #192
	str	x8, [sp, #184]                  // 8-byte Folded Spill
	add	x8, x8, x2
	lsl	x9, x8, #1
	lsl	x0, x19, #3
	madd	x20, x11, x14, x27
	mov	w10, #288
	str	x8, [sp, #176]                  // 8-byte Folded Spill
	mov	w8, #352
	add	x16, x22, x19, lsl #6
	mov	w3, #160
	mul	x8, x1, x8
	mov	w15, #40
	madd	x14, x19, x14, x22
	add	x4, x22, x19, lsl #7
	madd	x17, x19, x10, x22
	add	x6, x4, #128
	stp	x2, x1, [sp, #192]              // 16-byte Folded Spill
	madd	x4, x19, x3, x22
	stp	x8, x9, [sp, #160]              // 16-byte Folded Spill
	mov	w8, #96
	add	x9, x16, #64
	mov	x24, xzr
	madd	x18, x19, x8, x22
	mov	w24, #26480
	movk	w24, #16138, lsl #16
	mov	w12, #320
	str	x9, [sp, #248]                  // 8-byte Folded Spill
	add	x9, x18, #96
	add	x18, x5, #4
	mov	w25, #56740
	movk	w25, #16232, lsl #16
	madd	x21, x1, x12, x22
	str	x9, [sp, #240]                  // 8-byte Folded Spill
	add	x9, x0, #8
	mov	w0, #224
	str	x18, [sp, #16]                  // 8-byte Folded Spill
	add	x16, x4, #160
	madd	x4, x11, x3, x27
	madd	x7, x19, x0, x22
	mov	x19, x2
	madd	x26, x11, x0, x27
	mov	w0, #24
	add	x13, x7, #224
	add	x7, x14, #192
	mov	w14, #48
	madd	x10, x11, x10, x27
	add	x17, x17, #288
	add	x29, x27, x11, lsl #7
	str	x13, [sp, #232]                 // 8-byte Folded Spill
	mov	x13, x1
	add	x30, x27, x11, lsl #8
	str	x9, [sp, #152]                  // 8-byte Folded Spill
	mul	x2, x13, x15
	mov	x13, x1
	madd	x1, x11, x12, x27
	add	x12, x27, x11, lsl #6
	mul	x14, x13, x14
	sub	x15, x2, #40
	mov	w2, #56
	mul	x0, x13, x0
	sub	x14, x14, #48
	add	x3, x22, x9, lsl #5
	sub	x18, x0, #24
	lsl	x0, x13, #4
	mov	x9, xzr
	stp	x14, x15, [sp, #136]            // 16-byte Folded Spill
	mul	x14, x13, x2
	mov	w2, #45383
	sub	x15, x0, #16
	sub	x14, x14, #56
	movk	w2, #16084, lsl #16
	mov	w0, #47867
	movk	w0, #15889, lsl #16
	str	x15, [sp, #112]                 // 8-byte Folded Spill
	stp	x14, x18, [sp, #120]            // 16-byte Folded Spill
	mov	w14, #23652
	movk	w14, #16215, lsl #16
	dup	v1.4s, w2
	mov	w2, #41301
	dup	v2.4s, w0
	movk	w2, #16245, lsl #16
	mov	w0, #56740
	dup	v10.4s, w14
	mov	w14, #42228
	movk	w14, #16167, lsl #16
	movk	w0, #49000, lsl #16
	lsl	x18, x19, #3
	madd	x15, x11, x8, x27
	ldr	x23, [sp, #112]                 // 8-byte Folded Reload
	dup	v0.4s, w14
	mov	w14, #26480
	movk	w14, #48906, lsl #16
	stp	q1, q0, [sp, #928]              // 32-byte Folded Spill
	dup	v0.4s, w2
	mov	w2, #25840
	dup	v1.4s, w0
	movk	w2, #49021, lsl #16
	stp	q2, q0, [sp, #960]              // 32-byte Folded Spill
	mov	w0, #30926
	dup	v0.4s, w14
	movk	w0, #48961, lsl #16
	mov	w14, #16192
	str	q0, [sp, #912]                  // 16-byte Folded Spill
	dup	v0.4s, w2
	movk	w14, #48784, lsl #16
	mov	w2, #16192
	str	q0, [sp, #880]                  // 16-byte Folded Spill
	dup	v0.4s, w0
	mov	w0, #72
	movk	w2, #16016, lsl #16
	stp	q0, q1, [sp, #304]              // 32-byte Folded Spill
	dup	v2.4s, w14
	mov	w14, #25840
	mul	x0, x13, x0
	movk	w14, #16253, lsl #16
	sub	x8, x0, #72
	add	x0, x18, x19
	dup	v1.4s, w2
	dup	v0.4s, w14
	lsl	x14, x19, #1
	stp	x0, x18, [sp, #80]              // 16-byte Folded Spill
	sub	x18, x18, x19
	stp	q0, q1, [sp, #272]              // 32-byte Folded Spill
	dup	v0.4s, w24
	stp	x14, x8, [sp, #96]              // 16-byte Folded Spill
	add	x14, x14, x19
	add	x8, x27, x11, lsl #5
	lsl	x11, x13, #6
	mov	x0, x27
	stp	x18, x14, [sp, #64]             // 16-byte Folded Spill
	lsl	x18, x13, #5
	lsl	x14, x14, #1
	add	x2, x22, x18
	stp	q0, q2, [sp, #592]              // 32-byte Folded Spill
	dup	v0.4s, w25
	stp	x14, x18, [sp, #48]             // 16-byte Folded Spill
	sub	x14, x18, #32
	str	q0, [sp, #256]                  // 16-byte Folded Spill
	stp	x11, x14, [sp, #32]             // 16-byte Folded Spill
	b	.LBB196_7
.LBB196_6:                              //   in Loop: Header=BB196_7 Depth=1
	ldr	x14, [sp, #160]                 // 8-byte Folded Reload
	ldp	x20, x16, [sp, #344]            // 16-byte Folded Reload
	mov	v10.16b, v27.16b
	ldp	x1, x15, [sp, #368]             // 16-byte Folded Reload
	add	x17, x17, x14
	add	x6, x6, x14
	ldr	x4, [sp, #360]                  // 8-byte Folded Reload
	add	x22, x22, x14
	add	x2, x2, x14
	add	x21, x16, x14
	stp	x6, x17, [sp, #240]             // 16-byte Folded Spill
	add	x17, x18, x14
	add	x3, x3, x14
	add	x6, x7, x14
	add	x19, x19, x14
	add	x16, x15, x14
	add	x7, x4, x14
	ldp	x14, x11, [sp, #384]            // 16-byte Folded Reload
	str	x19, [sp, #232]                 // 8-byte Folded Spill
	ldr	x13, [sp, #56]                  // 8-byte Folded Reload
	ldr	x9, [sp, #224]                  // 8-byte Folded Reload
	add	x20, x20, x13
	add	x0, x0, x13
	add	x1, x1, x13
	add	x26, x26, x13
	add	x29, x29, x13
	add	x30, x30, x13
	add	x8, x8, x13
	add	x12, x12, x13
	add	x10, x10, x13
	add	x14, x14, x13
	add	x11, x11, x13
	add	x9, x9, #1
	ldp	x19, x13, [sp, #192]            // 16-byte Folded Reload
	mov	x4, x1
	mov	x15, x8
	mov	x8, x12
	mov	x1, x10
	mov	x10, x11
	mov	x12, x14
	cmp	x9, x19
	b.eq	.LBB196_10
.LBB196_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB196_9 Depth 2
	mov	w11, #11
	stp	x7, x4, [sp, #360]              // 16-byte Folded Spill
	ldr	x4, [sp, #216]                  // 8-byte Folded Reload
	stp	x16, x12, [sp, #376]            // 16-byte Folded Spill
	mul	x24, x9, x11
	ldr	x16, [sp, #80]                  // 8-byte Folded Reload
	stp	x20, x21, [sp, #344]            // 16-byte Folded Spill
	cmp	x13, #2
	add	x14, x24, #9
	add	x25, x24, #10
	mul	x27, x24, x13
	add	x5, x24, #2
	mul	x14, x14, x13
	str	x10, [sp, #392]                 // 8-byte Folded Spill
	mul	x25, x25, x13
	str	x9, [sp, #224]                  // 8-byte Folded Spill
	add	x28, x4, x27, lsl #5
	add	x27, x13, x27
	mul	x5, x5, x13
	add	x14, x4, x14, lsl #5
	add	x27, x4, x27, lsl #5
	add	x25, x4, x25, lsl #5
	ldp	q5, q31, [x28]
	add	x28, x24, #3
	add	x5, x4, x5, lsl #5
	mov	x18, x17
	mov	x7, x6
	mov	x12, x8
	mov	x10, x1
	mov	x8, x15
	ldp	q0, q1, [x27]
	mul	x27, x28, x13
	ldp	q7, q16, [x14]
	add	x14, x24, #8
	mul	x14, x14, x13
	ldp	q2, q3, [x25]
	add	x14, x4, x14, lsl #5
	fadd	v18.4s, v0.4s, v2.4s
	fsub	v19.4s, v0.4s, v2.4s
	ldp	q4, q6, [x5]
	add	x5, x4, x27, lsl #5
	fadd	v26.4s, v1.4s, v3.4s
	stp	q18, q5, [sp, #640]             // 32-byte Folded Spill
	fsub	v15.4s, v1.4s, v3.4s
	str	q19, [sp, #528]                 // 16-byte Folded Spill
	fadd	v22.4s, v4.4s, v7.4s
	fsub	v25.4s, v4.4s, v7.4s
	ldp	q17, q21, [x5]
	add	x5, x24, #4
	stp	q15, q25, [sp, #672]            // 32-byte Folded Spill
	fadd	v4.4s, v5.4s, v18.4s
	str	q22, [sp, #832]                 // 16-byte Folded Spill
	mul	x5, x5, x13
	str	q26, [sp, #576]                 // 16-byte Folded Spill
	fadd	v28.4s, v6.4s, v16.4s
	fsub	v27.4s, v6.4s, v16.4s
	ldp	q0, q1, [x14]
	add	x14, x24, #7
	add	x5, x4, x5, lsl #5
	fadd	v4.4s, v4.4s, v22.4s
	mul	x14, x14, x13
	fadd	v29.4s, v17.4s, v0.4s
	fsub	v8.4s, v17.4s, v0.4s
	add	x14, x4, x14, lsl #5
	ldr	x21, [sp, #120]                 // 8-byte Folded Reload
	ldp	q2, q3, [x5]
	add	x5, x24, #5
	add	x24, x24, #6
	fadd	v23.4s, v21.4s, v1.4s
	mul	x5, x5, x13
	mul	x24, x24, x13
	fsub	v20.4s, v21.4s, v1.4s
	ldp	q0, q1, [x14]
	add	x5, x4, x5, lsl #5
	add	x14, x4, x24, lsl #5
	mov	v17.16b, v22.16b
	mov	v21.16b, v29.16b
	str	q20, [sp, #896]                 // 16-byte Folded Spill
	fadd	v24.4s, v2.4s, v0.4s
	fsub	v9.4s, v2.4s, v0.4s
	fadd	v2.4s, v4.4s, v29.4s
	ldr	x4, [sp, #208]                  // 8-byte Folded Reload
	ldp	q6, q7, [x5]
	fadd	v14.4s, v3.4s, v1.4s
	add	x5, x9, x19
	fsub	v11.4s, v3.4s, v1.4s
	fadd	v1.4s, v2.4s, v24.4s
	mul	x5, x5, x13
	fmul	v2.4s, v18.4s, v10.4s
	mov	v29.16b, v24.16b
	ldp	q16, q0, [x14]
	mov	v24.16b, v21.16b
	mul	x14, x9, x13
	fadd	v2.4s, v5.4s, v2.4s
	add	x5, x4, x5, lsl #5
	fadd	v4.4s, v31.4s, v26.4s
	str	q11, [sp, #704]                 // 16-byte Folded Spill
	fadd	v13.4s, v6.4s, v16.4s
	add	x14, x4, x14, lsl #5
	fsub	v12.4s, v6.4s, v16.4s
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fadd	v22.4s, v7.4s, v0.4s
	ldr	x19, [sp, #232]                 // 8-byte Folded Reload
	fadd	v30.4s, v1.4s, v13.4s
	stp	q9, q13, [sp, #544]             // 32-byte Folded Spill
	fmul	v3.4s, v17.4s, v3.4s
	ldp	q17, q6, [sp, #912]             // 32-byte Folded Reload
	fmul	v1.4s, v26.4s, v10.4s
	str	q22, [sp, #624]                 // 16-byte Folded Spill
	fsub	v0.4s, v7.4s, v0.4s
	fadd	v2.4s, v2.4s, v3.4s
	fadd	v4.4s, v4.4s, v28.4s
	fadd	v1.4s, v31.4s, v1.4s
	ldr	q3, [sp, #960]                  // 16-byte Folded Reload
	stp	q21, q0, [sp, #848]             // 32-byte Folded Spill
	fmul	v6.4s, v28.4s, v6.4s
	mov	v18.16b, v10.16b
	fmul	v3.4s, v21.4s, v3.4s
	ldr	q21, [sp, #320]                 // 16-byte Folded Reload
	mov	v10.16b, v28.16b
	fadd	v1.4s, v1.4s, v6.4s
	ldr	q6, [sp, #960]                  // 16-byte Folded Reload
	fmul	v16.4s, v25.4s, v21.4s
	fsub	v2.4s, v2.4s, v3.4s
	ldr	q3, [sp, #912]                  // 16-byte Folded Reload
	fmul	v6.4s, v23.4s, v6.4s
	fmul	v7.4s, v27.4s, v21.4s
	fmla	v16.4s, v3.4s, v19.4s
	ldr	q3, [sp, #944]                  // 16-byte Folded Reload
	mov	v28.16b, v8.16b
	fsub	v1.4s, v1.4s, v6.4s
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	fmul	v3.4s, v29.4s, v3.4s
	fmla	v7.4s, v17.4s, v15.4s
	mov	v15.16b, v29.16b
	mov	v29.16b, v14.16b
	fmul	v6.4s, v14.4s, v6.4s
	ldr	q14, [sp, #880]                 // 16-byte Folded Reload
	fsub	v2.4s, v2.4s, v3.4s
	ldr	q3, [sp, #976]                  // 16-byte Folded Reload
	fadd	v4.4s, v4.4s, v23.4s
	fmla	v7.4s, v14.4s, v20.4s
	fmla	v16.4s, v14.4s, v8.4s
	fmul	v3.4s, v13.4s, v3.4s
	ldr	q8, [sp, #304]                  // 16-byte Folded Reload
	fsub	v1.4s, v1.4s, v6.4s
	ldr	q6, [sp, #976]                  // 16-byte Folded Reload
	fadd	v4.4s, v4.4s, v29.4s
	stp	q29, q15, [sp, #768]            // 32-byte Folded Spill
	fmla	v7.4s, v8.4s, v11.4s
	fmla	v16.4s, v8.4s, v9.4s
	fmul	v6.4s, v22.4s, v6.4s
	fsub	v2.4s, v2.4s, v3.4s
	ldr	q3, [sp, #608]                  // 16-byte Folded Reload
	mov	v5.16b, v31.16b
	mov	v31.16b, v12.16b
	fmla	v7.4s, v3.4s, v0.4s
	fmla	v16.4s, v3.4s, v12.4s
	fsub	v1.4s, v1.4s, v6.4s
	ldr	q0, [sp, #928]                  // 16-byte Folded Reload
	fadd	v3.4s, v4.4s, v22.4s
	ldr	q12, [sp, #640]                 // 16-byte Folded Reload
	mov	v17.16b, v23.16b
	stp	q31, q28, [sp, #800]            // 32-byte Folded Spill
	fsub	v4.4s, v2.4s, v7.4s
	fadd	v6.4s, v16.4s, v1.4s
	stp	q30, q3, [x14]
	ldr	q30, [sp, #832]                 // 16-byte Folded Reload
	fmul	v0.4s, v12.4s, v0.4s
	ldr	x14, [sp, #168]                 // 8-byte Folded Reload
	mov	v23.16b, v22.16b
	stp	q4, q6, [x5]
	ldr	q6, [sp, #944]                  // 16-byte Folded Reload
	ldp	q3, q4, [sp, #928]              // 32-byte Folded Reload
	mov	v22.16b, v26.16b
	add	x14, x9, x14
	fmul	v6.4s, v10.4s, v6.4s
	add	x5, x9, x16
	mul	x14, x14, x13
	fmul	v3.4s, v26.4s, v3.4s
	fadd	v2.4s, v2.4s, v7.4s
	ldr	q26, [sp, #656]                 // 16-byte Folded Reload
	add	x14, x4, x14, lsl #5
	fmul	v4.4s, v30.4s, v4.4s
	ldr	x16, [sp, #72]                  // 8-byte Folded Reload
	fadd	v3.4s, v5.4s, v3.4s
	fadd	v0.4s, v26.4s, v0.4s
	fsub	v1.4s, v1.4s, v16.4s
	mov	v20.16b, v9.16b
	fsub	v3.4s, v3.4s, v6.4s
	fsub	v4.4s, v0.4s, v4.4s
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	stp	q2, q1, [x14]
	ldp	q1, q6, [sp, #960]              // 32-byte Folded Reload
	fmul	v6.4s, v17.4s, v6.4s
	ldr	x14, [sp, #96]                  // 8-byte Folded Reload
	fmul	v7.4s, v24.4s, v0.4s
	ldr	q24, [sp, #672]                 // 16-byte Folded Reload
	fmul	v0.4s, v25.4s, v8.4s
	mov	v11.16b, v5.16b
	add	x14, x9, x14
	mov	v9.16b, v25.16b
	fsub	v4.4s, v4.4s, v7.4s
	ldr	q7, [sp, #960]                  // 16-byte Folded Reload
	mov	v25.16b, v17.16b
	fmla	v0.4s, v21.4s, v19.4s
	fsub	v2.4s, v3.4s, v6.4s
	stp	q11, q10, [sp, #720]            // 32-byte Folded Spill
	fmul	v3.4s, v29.4s, v1.4s
	ldr	q19, [sp, #592]                 // 16-byte Folded Reload
	ldp	q5, q17, [sp, #272]             // 32-byte Folded Reload
	fmul	v7.4s, v15.4s, v7.4s
	mul	x14, x14, x13
	fmul	v1.4s, v27.4s, v8.4s
	str	q25, [sp, #752]                 // 16-byte Folded Spill
	fsub	v2.4s, v2.4s, v3.4s
	fmul	v3.4s, v23.4s, v18.4s
	add	x14, x4, x14, lsl #5
	fsub	v4.4s, v4.4s, v7.4s
	fmla	v0.4s, v17.4s, v28.4s
	fmla	v1.4s, v21.4s, v24.4s
	fmul	v6.4s, v13.4s, v18.4s
	mov	v21.16b, v18.16b
	fadd	v18.4s, v2.4s, v3.4s
	ldr	q2, [sp, #960]                  // 16-byte Folded Reload
	fmla	v0.4s, v5.4s, v20.4s
	fadd	v20.4s, v4.4s, v6.4s
	fmul	v3.4s, v22.4s, v2.4s
	ldp	q4, q2, [sp, #960]              // 32-byte Folded Reload
	mov	v23.16b, v10.16b
	fmul	v6.4s, v12.4s, v4.4s
	ldr	q4, [sp, #896]                  // 16-byte Folded Reload
	fmul	v7.4s, v30.4s, v2.4s
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fsub	v3.4s, v11.4s, v3.4s
	ldr	q30, [sp, #528]                 // 16-byte Folded Reload
	fmla	v1.4s, v17.4s, v4.4s
	fmla	v0.4s, v19.4s, v31.4s
	fsub	v6.4s, v26.4s, v6.4s
	fmul	v16.4s, v10.4s, v2.4s
	ldr	q2, [sp, #928]                  // 16-byte Folded Reload
	ldp	q10, q22, [sp, #848]            // 32-byte Folded Reload
	mov	v13.16b, v12.16b
	fsub	v6.4s, v6.4s, v7.4s
	fsub	v3.4s, v3.4s, v16.4s
	fmul	v7.4s, v10.4s, v2.4s
	ldr	q12, [sp, #704]                 // 16-byte Folded Reload
	ldr	q2, [sp, #928]                  // 16-byte Folded Reload
	fadd	v6.4s, v6.4s, v7.4s
	fmla	v1.4s, v5.4s, v12.4s
	fmul	v16.4s, v25.4s, v2.4s
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fmul	v7.4s, v9.4s, v17.4s
	mov	v9.16b, v21.16b
	fmul	v17.4s, v27.4s, v17.4s
	fmla	v1.4s, v19.4s, v22.4s
	fmul	v21.4s, v15.4s, v21.4s
	ldr	q15, [sp, #256]                 // 16-byte Folded Reload
	fadd	v3.4s, v3.4s, v16.4s
	fmla	v7.4s, v14.4s, v30.4s
	fmul	v16.4s, v29.4s, v9.4s
	fmla	v17.4s, v14.4s, v24.4s
	ldp	q14, q29, [sp, #544]            // 32-byte Folded Reload
	fadd	v6.4s, v6.4s, v21.4s
	fmla	v7.4s, v15.4s, v28.4s
	fsub	v21.4s, v20.4s, v1.4s
	fadd	v3.4s, v3.4s, v16.4s
	fmla	v17.4s, v15.4s, v4.4s
	fadd	v16.4s, v0.4s, v18.4s
	fadd	v1.4s, v20.4s, v1.4s
	ldr	q28, [sp, #624]                 // 16-byte Folded Reload
	fsub	v0.4s, v18.4s, v0.4s
	ldr	q18, [sp, #816]                 // 16-byte Folded Reload
	stp	q21, q16, [x14]
	mul	x14, x5, x13
	fmul	v21.4s, v29.4s, v2.4s
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	add	x5, x9, x16
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	add	x14, x4, x14, lsl #5
	fmla	v7.4s, v2.4s, v14.4s
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	fsub	v6.4s, v6.4s, v21.4s
	mul	x5, x5, x13
	stp	q1, q0, [x14]
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	fmla	v17.4s, v2.4s, v12.4s
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fmla	v7.4s, v8.4s, v31.4s
	add	x5, x4, x5, lsl #5
	mov	v16.16b, v5.16b
	add	x14, x9, x14
	fmul	v2.4s, v28.4s, v2.4s
	add	x24, x9, x16
	fmla	v17.4s, v8.4s, v22.4s
	ldr	q22, [sp, #576]                 // 16-byte Folded Reload
	mov	v31.16b, v26.16b
	mul	x14, x14, x13
	ldp	x6, x17, [sp, #240]             // 16-byte Folded Reload
	fsub	v2.4s, v3.4s, v2.4s
	fsub	v3.4s, v6.4s, v17.4s
	add	x14, x4, x14, lsl #5
	fadd	v1.4s, v6.4s, v17.4s
	ldr	q6, [sp, #976]                  // 16-byte Folded Reload
	ldp	x20, x1, [sp, #128]             // 16-byte Folded Reload
	fadd	v4.4s, v7.4s, v2.4s
	fsub	v2.4s, v2.4s, v7.4s
	ldr	x16, [sp, #104]                 // 8-byte Folded Reload
	mov	v7.16b, v30.16b
	ldp	x11, x15, [sp, #32]             // 16-byte Folded Reload
	stp	q3, q4, [x5]
	ldp	q0, q4, [sp, #944]              // 32-byte Folded Reload
	stp	q1, q2, [x14]
	fmul	v2.4s, v10.4s, v9.4s
	fmul	v1.4s, v27.4s, v16.4s
	fmul	v0.4s, v13.4s, v0.4s
	ldp	q3, q5, [sp, #944]              // 32-byte Folded Reload
	fmla	v1.4s, v8.4s, v24.4s
	fsub	v0.4s, v26.4s, v0.4s
	fmul	v3.4s, v22.4s, v3.4s
	ldr	q26, [sp, #832]                 // 16-byte Folded Reload
	fmul	v5.4s, v23.4s, v5.4s
	ldp	x5, x14, [sp, #176]             // 16-byte Folded Reload
	fsub	v3.4s, v11.4s, v3.4s
	fmul	v4.4s, v26.4s, v4.4s
	mov	v23.16b, v29.16b
	add	x14, x9, x14
	mov	v11.16b, v28.16b
	add	x5, x9, x5
	fsub	v3.4s, v3.4s, v5.4s
	ldr	q5, [sp, #688]                  // 16-byte Folded Reload
	fsub	v0.4s, v0.4s, v4.4s
	mul	x14, x14, x13
	fmul	v4.4s, v25.4s, v9.4s
	mul	x5, x5, x13
	add	x14, x4, x14, lsl #5
	fadd	v2.4s, v0.4s, v2.4s
	add	x5, x4, x5, lsl #5
	fmul	v0.4s, v5.4s, v16.4s
	fadd	v17.4s, v3.4s, v4.4s
	mov	v16.16b, v24.16b
	ldp	q20, q4, [sp, #960]             // 32-byte Folded Reload
	fmul	v5.4s, v5.4s, v19.4s
	fmla	v0.4s, v8.4s, v30.4s
	ldp	q24, q25, [sp, #768]            // 32-byte Folded Reload
	fmul	v6.4s, v24.4s, v6.4s
	fmul	v4.4s, v25.4s, v4.4s
	ldr	q30, [sp, #608]                 // 16-byte Folded Reload
	fsub	v17.4s, v17.4s, v6.4s
	ldr	q6, [sp, #912]                  // 16-byte Folded Reload
	fmla	v5.4s, v30.4s, v7.4s
	fsub	v2.4s, v2.4s, v4.4s
	ldp	q3, q4, [sp, #896]              // 32-byte Folded Reload
	fmul	v7.4s, v27.4s, v19.4s
	fmla	v0.4s, v6.4s, v18.4s
	fmla	v5.4s, v8.4s, v18.4s
	mov	v18.16b, v30.16b
	mov	v27.16b, v9.16b
	fmla	v7.4s, v30.4s, v16.4s
	fmla	v0.4s, v30.4s, v14.4s
	fmla	v1.4s, v4.4s, v3.4s
	ldr	q6, [sp, #928]                  // 16-byte Folded Reload
	ldp	q4, q21, [sp, #928]             // 32-byte Folded Reload
	fmla	v5.4s, v15.4s, v14.4s
	fmul	v6.4s, v28.4s, v6.4s
	fmla	v7.4s, v8.4s, v3.4s
	fmla	v1.4s, v30.4s, v12.4s
	fmul	v4.4s, v29.4s, v4.4s
	mov	v28.16b, v9.16b
	ldr	q16, [sp, #976]                 // 16-byte Folded Reload
	fmla	v7.4s, v15.4s, v12.4s
	fadd	v10.4s, v17.4s, v6.4s
	ldp	q3, q29, [sp, #848]             // 32-byte Folded Reload
	fadd	v2.4s, v2.4s, v4.4s
	ldr	q4, [sp, #976]                  // 16-byte Folded Reload
	fmul	v16.4s, v13.4s, v16.4s
	fmla	v1.4s, v15.4s, v29.4s
	ldr	q19, [sp, #928]                 // 16-byte Folded Reload
	fmul	v4.4s, v22.4s, v4.4s
	ldr	q22, [sp, #800]                 // 16-byte Folded Reload
	mov	v13.16b, v14.16b
	fsub	v6.4s, v31.4s, v16.4s
	ldp	q16, q18, [sp, #720]            // 32-byte Folded Reload
	fmla	v0.4s, v15.4s, v22.4s
	fsub	v17.4s, v2.4s, v1.4s
	fadd	v1.4s, v2.4s, v1.4s
	fsub	v4.4s, v16.4s, v4.4s
	fmul	v16.4s, v26.4s, v9.4s
	fmul	v18.4s, v18.4s, v9.4s
	fadd	v6.4s, v6.4s, v16.4s
	fadd	v16.4s, v0.4s, v10.4s
	fadd	v4.4s, v4.4s, v18.4s
	fsub	v0.4s, v10.4s, v0.4s
	stp	q17, q16, [x14]
	ldr	x14, [sp, #64]                  // 8-byte Folded Reload
	fmul	v17.4s, v3.4s, v21.4s
	ldr	q3, [sp, #752]                  // 16-byte Folded Reload
	fmul	v16.4s, v25.4s, v19.4s
	add	x14, x9, x14
	fmul	v18.4s, v3.4s, v21.4s
	ldr	q3, [sp, #880]                  // 16-byte Folded Reload
	fsub	v6.4s, v6.4s, v17.4s
	mul	x14, x14, x13
	fmul	v17.4s, v24.4s, v19.4s
	fmla	v5.4s, v3.4s, v22.4s
	fmla	v7.4s, v3.4s, v29.4s
	fsub	v4.4s, v4.4s, v18.4s
	add	x14, x4, x14, lsl #5
	fadd	v2.4s, v6.4s, v16.4s
	fmul	v6.4s, v23.4s, v20.4s
	fmul	v16.4s, v11.4s, v20.4s
	stp	q1, q0, [x14]
	fadd	v4.4s, v4.4s, v17.4s
	mul	x14, x24, x13
	mov	v26.16b, v3.16b
	fsub	v2.4s, v2.4s, v6.4s
	ldp	x13, x9, [sp, #144]             // 16-byte Folded Reload
	fsub	v3.4s, v4.4s, v16.4s
	add	x14, x4, x14, lsl #5
	fsub	v0.4s, v2.4s, v7.4s
	fadd	v2.4s, v2.4s, v7.4s
	fadd	v1.4s, v5.4s, v3.4s
	fsub	v3.4s, v3.4s, v5.4s
	stp	q0, q1, [x5]
	stp	q2, q3, [x14]
	b.lo	.LBB196_6
// %bb.8:                               //   in Loop: Header=BB196_7 Depth=1
	ldp	x25, x27, [sp, #16]             // 16-byte Folded Reload
	mov	x24, xzr
.LBB196_9:                              //   Parent Loop BB196_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x4, [sp, #352]                  // 8-byte Folded Reload
	add	x14, x2, x24
	mov	v31.16b, v26.16b
	add	x28, x22, x24
	subs	x27, x27, #1
	add	x5, x4, x24
	ldr	x4, [sp, #360]                  // 8-byte Folded Reload
	ldp	q0, q1, [x14, #32]
	add	x14, x17, x24
	ldp	q2, q3, [x5, #32]
	add	x5, x18, x24
	fadd	v24.4s, v0.4s, v2.4s
	fsub	v30.4s, v0.4s, v2.4s
	ldp	q4, q5, [x14, #32]
	add	x14, x6, x24
	fadd	v18.4s, v1.4s, v3.4s
	fsub	v14.4s, v1.4s, v3.4s
	ldp	q0, q2, [x5, #32]
	add	x5, x3, x24
	str	q18, [sp, #896]                 // 16-byte Folded Spill
	str	q14, [sp, #672]                 // 16-byte Folded Spill
	fadd	v20.4s, v4.4s, v0.4s
	fsub	v12.4s, v4.4s, v0.4s
	ldp	q1, q3, [x14, #32]
	add	x14, x7, x24
	fadd	v22.4s, v5.4s, v2.4s
	fsub	v25.4s, v5.4s, v2.4s
	stp	q30, q12, [sp, #720]            // 32-byte Folded Spill
	ldp	q6, q0, [x5, #32]
	add	x5, x19, x24
	fadd	v10.4s, v1.4s, v6.4s
	fsub	v8.4s, v1.4s, v6.4s
	ldp	q1, q2, [x14, #32]
	fadd	v11.4s, v3.4s, v0.4s
	fsub	v26.4s, v3.4s, v0.4s
	ldr	x14, [sp, #376]                 // 8-byte Folded Reload
	stp	q26, q8, [sp, #688]             // 32-byte Folded Spill
	ldp	q0, q3, [x5, #32]
	add	x5, x4, x24
	add	x4, x25, x23
	add	x14, x14, x24
	fadd	v21.4s, v1.4s, v0.4s
	fsub	v23.4s, v1.4s, v0.4s
	ldp	q5, q6, [x14, #32]
	fadd	v15.4s, v2.4s, v3.4s
	add	x14, x0, x24
	fsub	v19.4s, v2.4s, v3.4s
	ldp	q7, q0, [x5, #32]
	add	x5, x25, x11
	fadd	v13.4s, v5.4s, v7.4s
	fsub	v29.4s, v5.4s, v7.4s
	ldp	q16, q17, [x28, #32]
	fadd	v2.4s, v6.4s, v0.4s
	mov	x28, x25
	fsub	v9.4s, v6.4s, v0.4s
	fmul	v0.4s, v24.4s, v27.4s
	stp	q23, q29, [sp, #784]            // 32-byte Folded Spill
	stp	q16, q20, [sp, #640]            // 32-byte Folded Spill
	fadd	v4.4s, v16.4s, v24.4s
	str	q2, [sp, #624]                  // 16-byte Folded Spill
	fmul	v2.4s, v18.4s, v27.4s
	stp	q19, q9, [sp, #752]             // 32-byte Folded Spill
	fadd	v0.4s, v16.4s, v0.4s
	ldp	q16, q28, [sp, #912]            // 32-byte Folded Reload
	fadd	v3.4s, v17.4s, v18.4s
	fadd	v1.4s, v4.4s, v20.4s
	fadd	v2.4s, v17.4s, v2.4s
	fadd	v3.4s, v3.4s, v22.4s
	ldr	q18, [sp, #320]                 // 16-byte Folded Reload
	fmul	v4.4s, v20.4s, v28.4s
	mov	v20.16b, v17.16b
	mov	v17.16b, v25.16b
	fmul	v6.4s, v25.4s, v18.4s
	ldr	q25, [sp, #960]                 // 16-byte Folded Reload
	fadd	v0.4s, v0.4s, v4.4s
	fmul	v7.4s, v12.4s, v18.4s
	fmul	v4.4s, v10.4s, v25.4s
	fmla	v6.4s, v16.4s, v14.4s
	ldr	q14, [sp, #944]                 // 16-byte Folded Reload
	fmul	v5.4s, v22.4s, v28.4s
	fmla	v7.4s, v16.4s, v30.4s
	ldr	q16, [sp, #976]                 // 16-byte Folded Reload
	fsub	v0.4s, v0.4s, v4.4s
	fmul	v4.4s, v21.4s, v14.4s
	fmla	v6.4s, v31.4s, v26.4s
	fadd	v2.4s, v2.4s, v5.4s
	fmul	v5.4s, v11.4s, v25.4s
	fmla	v7.4s, v31.4s, v8.4s
	ldr	q8, [sp, #304]                  // 16-byte Folded Reload
	fsub	v0.4s, v0.4s, v4.4s
	fmul	v4.4s, v13.4s, v16.4s
	fsub	v2.4s, v2.4s, v5.4s
	fmla	v6.4s, v8.4s, v19.4s
	fmul	v5.4s, v15.4s, v14.4s
	fmla	v7.4s, v8.4s, v23.4s
	mov	v26.16b, v13.16b
	fsub	v0.4s, v0.4s, v4.4s
	ldp	q4, q13, [sp, #608]             // 32-byte Folded Reload
	fadd	v1.4s, v1.4s, v10.4s
	fadd	v3.4s, v3.4s, v11.4s
	fsub	v2.4s, v2.4s, v5.4s
	fmla	v6.4s, v4.4s, v9.4s
	fmul	v5.4s, v13.4s, v16.4s
	fmla	v7.4s, v4.4s, v29.4s
	fadd	v1.4s, v1.4s, v21.4s
	str	q26, [sp, #864]                 // 16-byte Folded Spill
	fadd	v3.4s, v3.4s, v15.4s
	fsub	v4.4s, v0.4s, v6.4s
	fsub	v2.4s, v2.4s, v5.4s
	fadd	v1.4s, v1.4s, v26.4s
	fadd	v3.4s, v3.4s, v13.4s
	fneg	v16.4s, v4.4s
	fadd	v5.4s, v7.4s, v2.4s
	mov	v12.16b, v11.16b
	stp	q1, q3, [x14, #32]
	ldur	s1, [x25, #-4]
	ld1r	{ v3.4s }, [x28], x13
	ldp	q11, q31, [sp, #640]            // 32-byte Folded Reload
	fmul	v25.4s, v5.4s, v3.4s
	add	x14, x25, x16
	mov	v9.16b, v8.16b
	stp	q15, q17, [sp, #400]            // 32-byte Folded Spill
	fmul	v23.4s, v3.4s, v16.4s
	stp	q12, q22, [sp, #832]            // 32-byte Folded Spill
	fmul	v3.4s, v24.4s, v28.4s
	str	q24, [sp, #816]                 // 16-byte Folded Spill
	fmla	v25.4s, v4.4s, v1.s[0]
	ldr	q8, [sp, #896]                  // 16-byte Folded Reload
	fmla	v23.4s, v5.4s, v1.s[0]
	ldr	q30, [sp, #256]                 // 16-byte Folded Reload
	fadd	v1.4s, v11.4s, v3.4s
	fmul	v16.4s, v8.4s, v28.4s
	fmul	v4.4s, v31.4s, v14.4s
	fadd	v6.4s, v0.4s, v6.4s
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	fmul	v5.4s, v22.4s, v14.4s
	stp	q25, q23, [sp, #544]            // 32-byte Folded Spill
	fadd	v3.4s, v20.4s, v16.4s
	ldr	q23, [sp, #672]                 // 16-byte Folded Reload
	mov	v25.16b, v20.16b
	ldp	s20, s16, [x14, #-4]
	fsub	v7.4s, v2.4s, v7.4s
	add	x14, x25, x9
	fsub	v2.4s, v1.4s, v4.4s
	fmul	v4.4s, v10.4s, v0.4s
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	fsub	v3.4s, v3.4s, v5.4s
	str	q25, [sp, #448]                 // 16-byte Folded Spill
	fneg	v5.4s, v6.4s
	stp	q7, q20, [sp, #512]             // 32-byte Folded Spill
	fmul	v1.4s, v7.4s, v16.s[0]
	fmul	v7.4s, v12.4s, v0.4s
	ldr	q0, [sp, #960]                  // 16-byte Folded Reload
	fsub	v2.4s, v2.4s, v4.4s
	mov	v29.16b, v13.16b
	fmul	v4.4s, v21.4s, v0.4s
	fmla	v1.4s, v6.4s, v20.s[0]
	fmul	v0.4s, v5.4s, v16.s[0]
	fsub	v3.4s, v3.4s, v7.4s
	fmul	v6.4s, v26.4s, v27.4s
	fsub	v4.4s, v2.4s, v4.4s
	str	q1, [sp, #576]                  // 16-byte Folded Spill
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	ldr	q0, [sp, #960]                  // 16-byte Folded Reload
	mov	v14.16b, v10.16b
	fmul	v2.4s, v17.4s, v9.4s
	fmul	v5.4s, v15.4s, v0.4s
	ldr	q0, [sp, #960]                  // 16-byte Folded Reload
	mov	v10.16b, v17.16b
	ldp	q20, q26, [sp, #736]            // 32-byte Folded Reload
	fmul	v7.4s, v24.4s, v0.4s
	fmla	v2.4s, v18.4s, v23.4s
	mov	v19.16b, v12.16b
	str	q14, [sp, #464]                 // 16-byte Folded Spill
	fadd	v4.4s, v4.4s, v6.4s
	mov	v12.16b, v29.16b
	fsub	v3.4s, v3.4s, v5.4s
	ldr	q0, [sp, #960]                  // 16-byte Folded Reload
	fsub	v5.4s, v11.4s, v7.4s
	fmul	v7.4s, v20.4s, v9.4s
	fmul	v16.4s, v8.4s, v0.4s
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	mov	v13.16b, v21.16b
	mov	v8.16b, v25.16b
	fmul	v17.4s, v31.4s, v0.4s
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	fsub	v6.4s, v25.4s, v16.4s
	ldr	q25, [sp, #688]                 // 16-byte Folded Reload
	fmul	v16.4s, v29.4s, v27.4s
	str	q13, [sp, #432]                 // 16-byte Folded Spill
	fmul	v0.4s, v22.4s, v0.4s
	ldp	q22, q29, [sp, #704]            // 32-byte Folded Reload
	fsub	v5.4s, v5.4s, v17.4s
	fadd	v3.4s, v3.4s, v16.4s
	fsub	v1.4s, v6.4s, v0.4s
	fmul	v6.4s, v14.4s, v28.4s
	fmul	v16.4s, v19.4s, v28.4s
	fmla	v7.4s, v18.4s, v29.4s
	ldr	q28, [sp, #592]                 // 16-byte Folded Reload
	ldp	q21, q18, [sp, #272]            // 32-byte Folded Reload
	fadd	v5.4s, v5.4s, v6.4s
	fadd	v1.4s, v1.4s, v16.4s
	fmul	v16.4s, v15.4s, v27.4s
	mov	v24.16b, v14.16b
	fmla	v2.4s, v18.4s, v25.4s
	ldr	q6, [sp, #880]                  // 16-byte Folded Reload
	fmul	v17.4s, v20.4s, v18.4s
	fmla	v7.4s, v18.4s, v22.4s
	fmul	v0.4s, v10.4s, v18.4s
	ldp	q10, q18, [sp, #768]            // 32-byte Folded Reload
	fmla	v2.4s, v21.4s, v26.4s
	fmla	v17.4s, v6.4s, v29.4s
	fadd	v1.4s, v1.4s, v16.4s
	mov	v29.16b, v27.16b
	fmla	v2.4s, v28.4s, v10.4s
	ldr	q6, [sp, #880]                  // 16-byte Folded Reload
	fmla	v17.4s, v30.4s, v22.4s
	fmla	v7.4s, v21.4s, v18.4s
	fmla	v0.4s, v6.4s, v23.4s
	fmul	v6.4s, v13.4s, v27.4s
	ldr	q27, [sp, #800]                 // 16-byte Folded Reload
	fsub	v19.4s, v4.4s, v2.4s
	fadd	v20.4s, v4.4s, v2.4s
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fmla	v0.4s, v30.4s, v25.4s
	fmla	v7.4s, v28.4s, v27.4s
	fadd	v4.4s, v5.4s, v6.4s
	ldr	q5, [sp, #864]                  // 16-byte Folded Reload
	mov	v25.16b, v12.16b
	ldp	q28, q15, [sp, #496]            // 32-byte Folded Reload
	fmul	v5.4s, v5.4s, v2.4s
	fadd	v6.4s, v7.4s, v3.4s
	fsub	v23.4s, v4.4s, v5.4s
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	fneg	v5.4s, v19.4s
	fmul	v16.4s, v12.4s, v2.4s
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	mov	v12.16b, v21.16b
	fsub	v21.4s, v3.4s, v7.4s
	fmla	v17.4s, v2.4s, v18.4s
	ldr	q2, [sp, #912]                  // 16-byte Folded Reload
	ldp	s3, s7, [x14, #-12]
	fsub	v22.4s, v1.4s, v16.4s
	ldr	s1, [x4]
	fmla	v0.4s, v2.4s, v26.4s
	add	x14, x25, x21
	fmla	v17.4s, v9.4s, v27.4s
	fmul	v14.4s, v5.4s, v7.s[0]
	fmul	v27.4s, v6.4s, v7.s[0]
	ldp	s18, s2, [x5, #-68]
	fmla	v0.4s, v9.4s, v10.4s
	ldr	q10, [sp, #528]                 // 16-byte Folded Reload
	fneg	v7.4s, v20.4s
	fadd	v5.4s, v17.4s, v22.4s
	fmla	v27.4s, v19.4s, v3.s[0]
	fmul	v26.4s, v21.4s, v2.s[0]
	fmla	v28.4s, v15.4s, v10.s[0]
	fsub	v16.4s, v23.4s, v0.4s
	fmla	v14.4s, v6.4s, v3.s[0]
	fmul	v15.4s, v7.4s, v2.s[0]
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	ldr	q3, [sp, #816]                  // 16-byte Folded Reload
	fmul	v6.4s, v5.4s, v1.s[0]
	fmla	v26.4s, v20.4s, v18.s[0]
	fneg	v4.4s, v16.4s
	fmul	v2.4s, v3.4s, v2.4s
	ldr	q3, [sp, #896]                  // 16-byte Folded Reload
	fmla	v15.4s, v21.4s, v18.s[0]
	ldp	s20, s18, [x14, #-4]
	fmul	v7.4s, v4.4s, v1.s[0]
	ldr	q4, [sp, #944]                  // 16-byte Folded Reload
	ldur	s1, [x4, #-4]
	add	x14, x12, x24
	fmul	v21.4s, v24.4s, v29.4s
	ldr	x4, [sp, #384]                  // 8-byte Folded Reload
	fmul	v4.4s, v3.4s, v4.4s
	ldr	q3, [sp, #848]                  // 16-byte Folded Reload
	fmla	v7.4s, v5.4s, v1.s[0]
	ldr	q5, [sp, #960]                  // 16-byte Folded Reload
	fmla	v6.4s, v16.4s, v1.s[0]
	add	x4, x4, x24
	fsub	v1.4s, v11.4s, v2.4s
	fsub	v2.4s, v8.4s, v4.4s
	ldr	q4, [sp, #960]                  // 16-byte Folded Reload
	fmul	v5.4s, v3.4s, v5.4s
	str	q7, [sp, #496]                  // 16-byte Folded Spill
	fsub	v16.4s, v22.4s, v17.4s
	stp	q6, q26, [sp, #512]             // 32-byte Folded Spill
	fadd	v17.4s, v23.4s, v0.4s
	ldr	q0, [sp, #832]                  // 16-byte Folded Reload
	ldp	q24, q3, [sp, #720]             // 32-byte Folded Reload
	fsub	v5.4s, v2.4s, v5.4s
	fmul	v6.4s, v16.4s, v18.s[0]
	fneg	v2.4s, v17.4s
	fmul	v4.4s, v31.4s, v4.4s
	fmul	v22.4s, v0.4s, v29.4s
	fmla	v6.4s, v17.4s, v20.s[0]
	ldr	q17, [sp, #976]                 // 16-byte Folded Reload
	fmul	v10.4s, v2.4s, v18.s[0]
	ldr	q18, [sp, #976]                 // 16-byte Folded Reload
	fmul	v17.4s, v13.4s, v17.4s
	ldp	q13, q23, [sp, #400]            // 32-byte Folded Reload
	fsub	v4.4s, v1.4s, v4.4s
	ldr	q26, [sp, #672]                 // 16-byte Folded Reload
	fmla	v10.4s, v16.4s, v20.s[0]
	str	q6, [sp, #480]                  // 16-byte Folded Spill
	ldp	q16, q20, [sp, #544]            // 32-byte Folded Reload
	fmul	v1.4s, v3.4s, v12.4s
	fmul	v0.4s, v23.4s, v12.4s
	fadd	v5.4s, v5.4s, v22.4s
	fmul	v18.4s, v13.4s, v18.4s
	fadd	v4.4s, v4.4s, v21.4s
	fmla	v1.4s, v9.4s, v24.4s
	ldp	q19, q2, [sp, #688]             // 32-byte Folded Reload
	fmla	v0.4s, v9.4s, v26.4s
	stp	q16, q20, [x14, #32]
	fsub	v5.4s, v5.4s, v18.4s
	add	x14, x10, x24
	mov	v12.16b, v9.16b
	fsub	v4.4s, v4.4s, v17.4s
	ldp	q22, q8, [sp, #592]             // 32-byte Folded Reload
	fmul	v17.4s, v3.4s, v22.4s
	fmul	v22.4s, v23.4s, v22.4s
	ldp	q11, q31, [sp, #864]            // 32-byte Folded Reload
	fmla	v17.4s, v8.4s, v24.4s
	fmla	v22.4s, v8.4s, v26.4s
	ldp	q16, q18, [sp, #912]            // 32-byte Folded Reload
	fmla	v17.4s, v12.4s, v2.4s
	fmla	v22.4s, v12.4s, v19.4s
	ldp	q9, q7, [sp, #768]              // 32-byte Folded Reload
	fmla	v1.4s, v16.4s, v2.4s
	fmla	v0.4s, v16.4s, v19.4s
	fmul	v18.4s, v11.4s, v18.4s
	ldr	q16, [sp, #928]                 // 16-byte Folded Reload
	fmla	v1.4s, v8.4s, v7.4s
	ldr	q21, [sp, #976]                 // 16-byte Folded Reload
	fmla	v17.4s, v30.4s, v7.4s
	fadd	v4.4s, v4.4s, v18.4s
	ldp	q3, q18, [sp, #800]             // 32-byte Folded Reload
	fmul	v16.4s, v25.4s, v16.4s
	ldr	q24, [sp, #896]                 // 16-byte Folded Reload
	fmul	v18.4s, v18.4s, v21.4s
	ldr	q2, [sp, #640]                  // 16-byte Folded Reload
	fmla	v1.4s, v30.4s, v3.4s
	fmla	v17.4s, v31.4s, v3.4s
	fadd	v6.4s, v5.4s, v16.4s
	ldr	q5, [sp, #752]                  // 16-byte Folded Reload
	ldr	q16, [sp, #576]                 // 16-byte Folded Reload
	fmul	v21.4s, v24.4s, v21.4s
	ldr	q3, [sp, #512]                  // 16-byte Folded Reload
	fmla	v0.4s, v8.4s, v5.4s
	fmla	v22.4s, v30.4s, v5.4s
	stp	q16, q28, [x14, #32]
	add	x14, x25, x20
	fsub	v18.4s, v2.4s, v18.4s
	ldr	q2, [sp, #448]                  // 16-byte Folded Reload
	fadd	v16.4s, v1.4s, v6.4s
	stp	q27, q14, [x4, #32]
	fmla	v0.4s, v30.4s, v9.4s
	fmla	v22.4s, v31.4s, v9.4s
	ldp	s25, s20, [x14, #-4]
	fsub	v21.4s, v2.4s, v21.4s
	ldr	q2, [sp, #656]                  // 16-byte Folded Reload
	ldr	x14, [sp, #392]                 // 8-byte Folded Reload
	add	x4, x8, x24
	fsub	v24.4s, v4.4s, v0.4s
	fmul	v27.4s, v2.4s, v29.4s
	ldr	q2, [sp, #848]                  // 16-byte Folded Reload
	fmul	v23.4s, v16.4s, v20.s[0]
	add	x14, x14, x24
	fadd	v0.4s, v4.4s, v0.4s
	fmul	v28.4s, v2.4s, v29.4s
	ldr	q2, [sp, #528]                  // 16-byte Folded Reload
	fadd	v18.4s, v18.4s, v27.4s
	fmla	v23.4s, v24.4s, v25.s[0]
	fneg	v24.4s, v24.4s
	stp	q2, q15, [x14, #32]
	ldp	q26, q27, [sp, #944]            // 32-byte Folded Reload
	fadd	v21.4s, v21.4s, v28.4s
	add	x14, x25, x1
	fsub	v1.4s, v6.4s, v1.4s
	fmul	v20.4s, v24.4s, v20.s[0]
	ldr	q2, [sp, #464]                  // 16-byte Folded Reload
	fmla	v20.4s, v16.4s, v25.s[0]
	ldr	s6, [x28]
	fneg	v25.4s, v0.4s
	fmul	v24.4s, v2.4s, v26.4s
	ldr	q2, [sp, #832]                  // 16-byte Folded Reload
	fmul	v26.4s, v2.4s, v26.4s
	ldr	q2, [sp, #432]                  // 16-byte Folded Reload
	fsub	v7.4s, v18.4s, v24.4s
	fsub	v16.4s, v21.4s, v26.4s
	ldr	q21, [sp, #928]                 // 16-byte Folded Reload
	mov	v26.16b, v31.16b
	fmul	v18.4s, v2.4s, v21.4s
	ldr	q2, [sp, #624]                  // 16-byte Folded Reload
	fmul	v21.4s, v13.4s, v21.4s
	fadd	v5.4s, v7.4s, v18.4s
	fadd	v16.4s, v16.4s, v21.4s
	fmul	v21.4s, v11.4s, v27.4s
	ldp	s4, s7, [x14, #-4]
	fmul	v18.4s, v2.4s, v27.4s
	ldr	q2, [sp, #496]                  // 16-byte Folded Reload
	add	x14, x25, x15
	add	x25, x25, #8
	fsub	v5.4s, v5.4s, v21.4s
	fmul	v24.4s, v1.4s, v7.s[0]
	stp	q3, q2, [x4, #32]
	fsub	v16.4s, v16.4s, v18.4s
	fmul	v3.4s, v25.4s, v7.s[0]
	ldr	q2, [sp, #480]                  // 16-byte Folded Reload
	add	x4, x26, x24
	fsub	v18.4s, v5.4s, v22.4s
	fadd	v5.4s, v5.4s, v22.4s
	fmla	v24.4s, v0.4s, v4.s[0]
	ldp	s19, s0, [x14, #-4]
	fadd	v7.4s, v17.4s, v16.4s
	add	x14, x30, x24
	fmla	v3.4s, v1.4s, v4.s[0]
	fneg	v4.4s, v18.4s
	fsub	v16.4s, v16.4s, v17.4s
	stp	q2, q10, [x14, #32]
	fneg	v17.4s, v5.4s
	add	x14, x29, x24
	fmul	v1.4s, v7.4s, v0.s[0]
	fmul	v0.4s, v4.4s, v0.s[0]
	fmul	v2.4s, v16.4s, v6.s[0]
	stp	q23, q20, [x14, #32]
	fmul	v4.4s, v17.4s, v6.s[0]
	ldur	s6, [x28, #-4]
	ldr	x14, [sp, #368]                 // 8-byte Folded Reload
	stp	q24, q3, [x4, #32]
	ldr	x4, [sp, #344]                  // 8-byte Folded Reload
	fmla	v1.4s, v18.4s, v19.s[0]
	fmla	v0.4s, v7.4s, v19.s[0]
	fmla	v2.4s, v5.4s, v6.s[0]
	mov	v27.16b, v29.16b
	fmla	v4.4s, v16.4s, v6.s[0]
	add	x14, x14, x24
	add	x4, x4, x24
	add	x24, x24, #32
	stp	q1, q0, [x14, #32]
	stp	q2, q4, [x4, #32]
	b.ne	.LBB196_9
	b	.LBB196_6
.LBB196_10:
	add	sp, sp, #992
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end196:
	.size	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end196-_ZNK9pocketfft6detail5cfftpIfE6pass11ILb1ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_,@function
_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_: // @_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #3
	mov	x25, x7
	add	x0, x8, #64
	stp	x6, x4, [sp, #24]               // 16-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x22, x3
	mov	x21, x1
	bl	malloc
	cbz	x0, .LBB197_85
// %bb.1:
	add	x8, x0, #64
	add	x14, x23, #1
	mul	x19, x22, x21
	and	x28, x8, #0xffffffffffffffc0
	mov	w8, #1065353216
	subs	x18, x23, #2
	lsr	x26, x14, #1
	stp	x0, x8, [x28, #-8]
	stp	x26, x22, [x29, #-16]           // 16-byte Folded Spill
	b.lo	.LBB197_4
// %bb.2:
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cmp	x27, #8
	b.hs	.LBB197_6
// %bb.3:
	mov	w8, #1
	b	.LBB197_13
.LBB197_4:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cbz	x22, .LBB197_73
// %bb.5:
	cbnz	x21, .LBB197_17
	b	.LBB197_73
.LBB197_6:
	cmp	xzr, x18, lsr #61
	add	x11, x28, #8
	lsl	x10, x18, #3
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB197_13
// %bb.7:
	tbnz	w9, #0, .LBB197_13
// %bb.8:
	add	x11, x28, #12
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB197_13
// %bb.9:
	tbnz	w9, #0, .LBB197_13
// %bb.10:
	and	x9, x27, #0xfffffffffffffff8
	add	x10, x28, #40
	orr	x8, x9, #0x1
	add	x11, x25, #40
	mov	x12, x9
.LBB197_11:                             // =>This Inner Loop Header: Depth=1
	ld2	{ v0.4s, v1.4s }, [x11]
	sub	x13, x11, #32
	add	x11, x11, #64
	subs	x12, x12, #8
	ld2	{ v2.4s, v3.4s }, [x13]
	sub	x13, x10, #32
	fneg	v1.4s, v1.4s
	fneg	v3.4s, v3.4s
	st2	{ v0.4s, v1.4s }, [x10]
	add	x10, x10, #64
	st2	{ v2.4s, v3.4s }, [x13]
	b.ne	.LBB197_11
// %bb.12:
	cmp	x27, x9
	b.eq	.LBB197_15
.LBB197_13:
	sub	x9, x23, x8
	lsl	x8, x8, #3
	add	x10, x25, x8
	add	x11, x28, x8
	add	x8, x10, #4
	add	x10, x11, #4
.LBB197_14:                             // =>This Inner Loop Header: Depth=1
	ldr	s0, [x8]
	subs	x9, x9, #1
	ldur	w11, [x8, #-4]
	add	x8, x8, #8
	fneg	s0, s0
	stur	w11, [x10, #-4]
	str	s0, [x10], #8
	b.ne	.LBB197_14
.LBB197_15:
	cbz	x22, .LBB197_35
// %bb.16:
	cbz	x21, .LBB197_37
.LBB197_17:
	mul	x8, x23, x21
	lsl	x25, x21, #5
	mov	x26, x24
	mov	x27, x30
	lsl	x20, x8, #5
	stp	x18, x14, [x29, #-32]           // 16-byte Folded Spill
.LBB197_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	mov	x2, x25
	bl	memcpy
	add	x27, x27, x20
	add	x26, x26, x25
	subs	x22, x22, #1
	b.ne	.LBB197_18
// %bb.19:
	ldp	x8, x26, [x29, #-24]            // 16-byte Folded Reload
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	cmp	x8, #3
	b.ls	.LBB197_27
// %bb.20:
	cbz	x21, .LBB197_49
// %bb.21:
	mul	x10, x21, x27
	add	x11, x24, x19, lsl #5
	mul	x13, x19, x27
	cmp	x26, #2
	mov	w8, #2
	add	x14, x30, x25
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	lsl	x12, x19, #5
	add	x15, x24, x13, lsl #5
	neg	x9, x25
	csel	x8, x26, x8, hi
	add	x13, x14, #16
	add	x14, x15, #16
	neg	x15, x12
	mov	w16, #1
.LBB197_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB197_23 Depth 2
                                        //       Child Loop BB197_24 Depth 3
	mov	x17, xzr
	mov	x18, x14
	mov	x0, x13
	mov	x1, x10
	mov	x2, x11
.LBB197_23:                             //   Parent Loop BB197_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB197_24 Depth 3
	mov	x3, x18
	mov	x4, x0
	mov	x5, x1
	mov	x6, x2
	mov	x7, x21
.LBB197_24:                             //   Parent Loop BB197_22 Depth=1
                                        //     Parent Loop BB197_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x4, #-16]
	subs	x7, x7, #1
	add	x4, x4, #32
	ldp	q2, q3, [x6, #-16]
	add	x6, x6, #32
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x5, #-16]
	add	x5, x5, #32
	stp	q0, q1, [x3, #-16]
	add	x3, x3, #32
	b.ne	.LBB197_24
// %bb.25:                              //   in Loop: Header=BB197_23 Depth=2
	add	x17, x17, #1
	add	x2, x2, x20
	add	x1, x1, x25
	add	x0, x0, x20
	add	x18, x18, x25
	cmp	x17, x22
	b.ne	.LBB197_23
// %bb.26:                              //   in Loop: Header=BB197_22 Depth=1
	add	x16, x16, #1
	add	x11, x11, x9
	add	x10, x10, x12
	add	x13, x13, x25
	add	x14, x14, x15
	cmp	x16, x8
	b.ne	.LBB197_22
.LBB197_27:
	ldp	x18, x0, [x29, #-32]            // 16-byte Folded Reload
	cbz	x21, .LBB197_42
// %bb.28:
	cmp	x0, #3
	b.ls	.LBB197_38
// %bb.29:
	cmp	x26, #2
	mov	w9, #2
	csel	x9, x26, x9, hi
	add	x10, x24, x19, lsl #5
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x10, #16
	lsl	x11, x19, #5
.LBB197_30:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB197_31 Depth 2
                                        //       Child Loop BB197_32 Depth 3
	mul	x13, x8, x21
	mov	x12, xzr
	mov	x14, x10
.LBB197_31:                             //   Parent Loop BB197_30 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB197_32 Depth 3
	add	x15, x12, x13
	mov	x17, x9
	add	x16, x24, x15, lsl #5
	ldp	q0, q1, [x16]
	mov	x16, x14
.LBB197_32:                             //   Parent Loop BB197_30 Depth=1
                                        //     Parent Loop BB197_31 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q3, [x16, #-16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.4s, v0.4s, v2.4s
	fadd	v1.4s, v1.4s, v3.4s
	b.ne	.LBB197_32
// %bb.33:                              //   in Loop: Header=BB197_31 Depth=2
	add	x15, x30, x15, lsl #5
	add	x12, x12, #1
	add	x14, x14, #32
	cmp	x12, x21
	stp	q0, q1, [x15]
	b.ne	.LBB197_31
// %bb.34:                              //   in Loop: Header=BB197_30 Depth=1
	add	x8, x8, #1
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB197_30
	b	.LBB197_42
.LBB197_35:
	mov	w9, #1
	cmp	x14, #3
	b.hi	.LBB197_51
// %bb.36:
	mov	w8, wzr
	subs	x10, x21, #1
	b.eq	.LBB197_44
	b	.LBB197_71
.LBB197_37:
	cmp	x14, #3
	b.hi	.LBB197_50
	b	.LBB197_73
.LBB197_38:
	mov	x8, xzr
	add	x9, x30, #16
	add	x10, x24, #16
.LBB197_39:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB197_40 Depth 2
	mov	x11, x10
	mov	x12, x9
	mov	x13, x21
.LBB197_40:                             //   Parent Loop BB197_39 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x13, x13, #1
	add	x11, x11, #32
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB197_40
// %bb.41:                              //   in Loop: Header=BB197_39 Depth=1
	add	x8, x8, #1
	add	x9, x9, x25
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB197_39
.LBB197_42:
	mov	w9, wzr
	mov	w8, wzr
	cmp	x0, #4
	b.hs	.LBB197_51
// %bb.43:
	subs	x10, x21, #1
	b.ne	.LBB197_71
.LBB197_44:
	cmp	x19, #0
	eor	w8, w8, #0x1
	cset	w9, eq
	orr	w8, w8, w9
	tbnz	w8, #0, .LBB197_73
// %bb.45:
	mul	x8, x27, x22
	cmp	x26, #2
	mov	w9, #2
	add	x11, x30, x19, lsl #5
	csel	x9, x26, x9, hi
	mov	w13, #1
	mul	x10, x8, x21
	lsl	x8, x19, #5
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	neg	x12, x8
.LBB197_46:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB197_47 Depth 2
	mov	x14, x11
	mov	x15, x10
	mov	x16, x19
.LBB197_47:                             //   Parent Loop BB197_46 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x15, #-16]
	subs	x16, x16, #1
	ldp	q2, q3, [x14, #-16]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x15, #-16]
	add	x15, x15, #32
	stp	q0, q1, [x14, #-16]
	add	x14, x14, #32
	b.ne	.LBB197_47
// %bb.48:                              //   in Loop: Header=BB197_46 Depth=1
	add	x13, x13, #1
	add	x10, x10, x8
	add	x11, x11, x12
	cmp	x13, x9
	b.ne	.LBB197_46
	b	.LBB197_73
.LBB197_49:
	ldur	x18, [x29, #-32]                // 8-byte Folded Reload
.LBB197_50:
	mov	w9, wzr
.LBB197_51:
	str	w9, [sp, #12]                   // 4-byte Folded Spill
	mul	x9, x19, x18
	sub	x1, x23, #4
	mul	x8, x19, x27
	cmp	x26, #2
	mov	w13, #2
	add	x18, x24, x9, lsl #5
	mov	w9, #96
	mul	x2, x19, x1
	lsl	x8, x8, #5
	madd	x9, x19, x9, x24
	add	x15, x30, x8
	add	x8, x24, x8
	csel	x13, x26, x13, hi
	add	x1, x8, #16
	add	x8, x9, #16
	add	x9, x24, x2, lsl #5
	sub	x10, x23, #3
	str	x27, [sp, #16]                  // 8-byte Folded Spill
	lsl	x12, x19, #5
	stp	x8, x13, [x29, #-32]            // 16-byte Folded Spill
	mul	x8, x19, x10
	stur	x9, [x29, #-40]                 // 8-byte Folded Spill
	add	x9, x24, x19, lsl #7
	add	x9, x9, #16
	add	x14, x24, x12
	add	x17, x24, x19, lsl #6
	add	x0, x30, x12
	lsl	x3, x19, #6
	sub	x11, x26, #1
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x24, x8, lsl #5
	add	x8, x24, #16
	add	x14, x14, #16
	neg	x16, x12
	add	x17, x17, #16
	add	x0, x0, #16
	neg	x5, x3
	stp	x8, x9, [sp, #48]               // 16-byte Folded Spill
	lsl	x8, x19, #1
	mov	w27, #1
	str	x8, [sp, #40]                   // 8-byte Folded Spill
	b	.LBB197_53
.LBB197_52:                             //   in Loop: Header=BB197_53 Depth=1
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	add	x27, x27, #1
	add	x15, x15, x16
	add	x0, x0, x12
	cmp	x27, x8
	b.eq	.LBB197_70
.LBB197_53:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB197_55 Depth 2
                                        //     Child Loop BB197_59 Depth 2
                                        //       Child Loop BB197_61 Depth 3
                                        //     Child Loop BB197_67 Depth 2
                                        //       Child Loop BB197_68 Depth 3
	cbz	x19, .LBB197_62
// %bb.54:                              //   in Loop: Header=BB197_53 Depth=1
	add	x2, x28, x27, lsl #3
	add	x4, x28, x27, lsl #4
	mov	x9, xzr
	lsl	x30, x27, #1
	add	x6, x2, #4
	add	x7, x4, #4
	mov	x8, x19
.LBB197_55:                             //   Parent Loop BB197_53 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x14, x9
	add	x25, x24, x9
	ldr	s0, [x2]
	add	x22, x17, x9
	ldr	s1, [x7]
	add	x26, x18, x9
	ldp	q3, q16, [x20, #-16]
	add	x20, x1, x9
	subs	x8, x8, #1
	dup	v4.4s, v1.s[0]
	fneg	v4.4s, v4.4s
	ldp	q6, q7, [x25]
	fmla	v6.4s, v3.4s, v0.s[0]
	ldp	q17, q3, [x26]
	fmla	v7.4s, v16.4s, v0.s[0]
	fmul	v1.4s, v17.4s, v1.s[0]
	ldp	q5, q0, [x22, #-16]
	fmul	v3.4s, v3.4s, v4.4s
	add	x22, x15, x9
	ldr	s2, [x4]
	ldr	s4, [x6]
	fmla	v6.4s, v5.4s, v2.s[0]
	fmla	v7.4s, v0.4s, v2.s[0]
	ldp	q5, q16, [x20, #-16]
	add	x20, x0, x9
	add	x9, x9, #32
	fmla	v1.4s, v5.4s, v4.s[0]
	stp	q6, q7, [x20, #-16]
	fmls	v3.4s, v16.4s, v4.s[0]
	stp	q3, q1, [x22]
	b.ne	.LBB197_55
// %bb.56:                              //   in Loop: Header=BB197_53 Depth=1
	cmp	x11, #4
	b.lo	.LBB197_63
.LBB197_57:                             //   in Loop: Header=BB197_53 Depth=1
	ldp	x6, x4, [x29, #-48]             // 16-byte Folded Reload
	mov	w9, #3
	mov	x20, x10
	ldr	x7, [sp, #56]                   // 8-byte Folded Reload
	ldur	x2, [x29, #-32]                 // 8-byte Folded Reload
	b	.LBB197_59
.LBB197_58:                             //   in Loop: Header=BB197_59 Depth=2
	add	x9, x9, #2
	sub	x20, x20, #2
	add	x2, x2, x3
	add	x4, x4, x5
	add	x6, x6, x3
	add	x7, x7, x5
	cmp	x9, x11
	b.hs	.LBB197_64
.LBB197_59:                             //   Parent Loop BB197_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB197_61 Depth 3
	add	x8, x30, x27
	cmp	x8, x23
	csel	x22, x23, xzr, hi
	sub	x22, x8, x22
	add	x8, x22, x27
	cmp	x8, x23
	csel	x25, x23, xzr, hi
	sub	x30, x8, x25
	cbz	x19, .LBB197_58
// %bb.60:                              //   in Loop: Header=BB197_59 Depth=2
	add	x22, x28, x22, lsl #3
	add	x25, x28, x30, lsl #3
	mov	x8, xzr
	ld1r	{ v0.4s }, [x22], #4
	ld1r	{ v1.4s }, [x25], #4
	ld1r	{ v2.4s }, [x22]
	mov	x22, x19
	ld1r	{ v3.4s }, [x25]
.LBB197_61:                             //   Parent Loop BB197_53 Depth=1
                                        //     Parent Loop BB197_59 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x25, x6, x8
	add	x26, x2, x8
	add	x13, x0, x8
	subs	x22, x22, #1
	ldp	q4, q5, [x25, #-16]
	add	x25, x4, x8
	fmul	v4.4s, v1.4s, v4.4s
	ldp	q6, q7, [x26, #-16]
	fmul	v5.4s, v1.4s, v5.4s
	add	x26, x7, x8
	fmla	v4.4s, v0.4s, v6.4s
	ldp	q16, q17, [x13, #-16]
	fmla	v5.4s, v0.4s, v7.4s
	fadd	v4.4s, v16.4s, v4.4s
	ldp	q7, q6, [x25]
	fadd	v5.4s, v17.4s, v5.4s
	add	x25, x15, x8
	add	x8, x8, #32
	fmul	v7.4s, v3.4s, v7.4s
	stp	q4, q5, [x13, #-16]
	ldp	q17, q16, [x26]
	fmul	v6.4s, v3.4s, v6.4s
	fmla	v7.4s, v2.4s, v17.4s
	ldp	q4, q5, [x25]
	fmla	v6.4s, v2.4s, v16.4s
	fsub	v4.4s, v4.4s, v6.4s
	fadd	v5.4s, v5.4s, v7.4s
	stp	q4, q5, [x25]
	b.ne	.LBB197_61
	b	.LBB197_58
.LBB197_62:                             //   in Loop: Header=BB197_53 Depth=1
	lsl	x30, x27, #1
	cmp	x11, #4
	b.hs	.LBB197_57
.LBB197_63:                             //   in Loop: Header=BB197_53 Depth=1
	mov	x20, x10
	mov	w9, #3
.LBB197_64:                             //   in Loop: Header=BB197_53 Depth=1
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cmp	x9, x26
	b.hs	.LBB197_52
// %bb.65:                              //   in Loop: Header=BB197_53 Depth=1
	cbz	x19, .LBB197_52
// %bb.66:                              //   in Loop: Header=BB197_53 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	mul	x8, x13, x9
	mul	x4, x13, x20
	ldr	x13, [sp, #48]                  // 8-byte Folded Reload
	add	x2, x13, x8, lsl #4
	add	x4, x13, x4, lsl #4
.LBB197_67:                             //   Parent Loop BB197_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB197_68 Depth 3
	add	x6, x30, x27
	mov	x8, xzr
	cmp	x6, x23
	csel	x7, x23, xzr, hi
	sub	x30, x6, x7
	add	x6, x28, x30, lsl #3
	ld1r	{ v0.4s }, [x6], #4
	ld1r	{ v1.4s }, [x6]
	mov	x6, x19
.LBB197_68:                             //   Parent Loop BB197_53 Depth=1
                                        //     Parent Loop BB197_67 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x7, x2, x8
	add	x20, x0, x8
	add	x22, x15, x8
	subs	x6, x6, #1
	ldp	q2, q4, [x7, #-16]
	add	x7, x4, x8
	add	x8, x8, #32
	ldp	q3, q5, [x20, #-16]
	fmla	v3.4s, v0.4s, v2.4s
	fmla	v5.4s, v0.4s, v4.4s
	stp	q3, q5, [x20, #-16]
	ldp	q3, q2, [x7, #-16]
	ldp	q4, q5, [x22]
	fmls	v4.4s, v1.4s, v2.4s
	fmla	v5.4s, v1.4s, v3.4s
	stp	q4, q5, [x22]
	b.ne	.LBB197_68
// %bb.69:                              //   in Loop: Header=BB197_67 Depth=2
	add	x9, x9, #1
	add	x2, x2, x12
	add	x4, x4, x16
	cmp	x9, x26
	b.ne	.LBB197_67
	b	.LBB197_52
.LBB197_70:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	mov	w8, #1
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	ldr	w9, [sp, #12]                   // 4-byte Folded Reload
	subs	x10, x21, #1
	b.eq	.LBB197_44
.LBB197_71:
	cbz	w8, .LBB197_73
// %bb.72:
	tbz	w9, #0, .LBB197_76
.LBB197_73:
	cbz	x28, .LBB197_75
// %bb.74:
	ldur	x0, [x28, #-8]
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	b	free
.LBB197_75:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB197_76:
	mul	x8, x27, x22
	sub	x11, x27, #1
	ldr	x0, [sp, #24]                   // 8-byte Folded Reload
	cmp	x26, #2
	mul	x15, x11, x10
	mov	w12, #2
	mul	x8, x8, x21
	add	x18, x30, x19, lsl #5
	lsl	x9, x19, #5
	mov	w17, #8
	add	x16, x0, x15, lsl #3
	csel	x11, x26, x12, hi
	add	x15, x30, x8, lsl #5
	lsl	x8, x21, #3
	add	x12, x18, #16
	lsl	x13, x21, #5
	neg	x14, x9
	add	x16, x16, #4
	sub	x17, x17, x8
	add	x18, x18, #48
	add	x0, x0, #4
	sub	x1, x8, #8
	add	x2, x15, #48
	mov	w3, #1
	b	.LBB197_78
.LBB197_77:                             //   in Loop: Header=BB197_78 Depth=1
	add	x3, x3, #1
	add	x12, x12, x9
	add	x15, x15, x14
	add	x16, x16, x17
	add	x18, x18, x9
	add	x0, x0, x1
	add	x2, x2, x14
	mov	x27, x4
	cmp	x3, x11
	b.eq	.LBB197_73
.LBB197_78:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB197_84 Depth 2
                                        //     Child Loop BB197_80 Depth 2
                                        //       Child Loop BB197_81 Depth 3
	sub	x4, x27, #1
	cmp	x21, #1
	b.ls	.LBB197_83
// %bb.79:                              //   in Loop: Header=BB197_78 Depth=1
	mul	x5, x3, x22
	mov	x8, xzr
	mul	x6, x27, x22
	mov	x7, x2
	mov	x20, x18
.LBB197_80:                             //   Parent Loop BB197_78 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB197_81 Depth 3
	add	x19, x8, x5
	add	x22, x8, x6
	mov	x23, x0
	mov	x24, x20
	mul	x19, x19, x21
	mov	x25, x16
	mul	x22, x22, x21
	mov	x26, x10
	add	x19, x30, x19, lsl #5
	add	x27, x30, x22, lsl #5
	mov	x22, x7
	ldp	q0, q1, [x19]
	ldp	q2, q3, [x27]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x19]
	stp	q0, q1, [x27]
.LBB197_81:                             //   Parent Loop BB197_78 Depth=1
                                        //     Parent Loop BB197_80 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q2, [x24, #-16]
	subs	x26, x26, #1
	ldp	q1, q3, [x22, #-16]
	fadd	v4.4s, v0.4s, v1.4s
	fsub	v0.4s, v0.4s, v1.4s
	ldp	s17, s5, [x23, #-4]
	fadd	v1.4s, v2.4s, v3.4s
	ldr	s6, [x25]
	fneg	v7.4s, v4.4s
	add	x23, x23, #8
	fsub	v2.4s, v2.4s, v3.4s
	fneg	v3.4s, v0.4s
	fmul	v16.4s, v1.4s, v5.s[0]
	fmul	v5.4s, v7.4s, v5.s[0]
	fmul	v7.4s, v2.4s, v6.s[0]
	fmul	v3.4s, v3.4s, v6.s[0]
	ldur	s6, [x25, #-4]
	fmla	v16.4s, v4.4s, v17.s[0]
	add	x25, x25, #8
	fmla	v5.4s, v1.4s, v17.s[0]
	fmla	v7.4s, v0.4s, v6.s[0]
	fmla	v3.4s, v2.4s, v6.s[0]
	stp	q16, q5, [x24, #-16]
	add	x24, x24, #32
	stp	q7, q3, [x22, #-16]
	add	x22, x22, #32
	b.ne	.LBB197_81
// %bb.82:                              //   in Loop: Header=BB197_80 Depth=2
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	add	x8, x8, #1
	add	x20, x20, x13
	add	x7, x7, x13
	cmp	x8, x22
	b.ne	.LBB197_80
	b	.LBB197_77
.LBB197_83:                             //   in Loop: Header=BB197_78 Depth=1
	mov	x8, xzr
	mov	x5, x22
.LBB197_84:                             //   Parent Loop BB197_78 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x6, x12, x8
	add	x7, x15, x8
	subs	x5, x5, #1
	add	x8, x8, x13
	ldp	q0, q1, [x6, #-16]
	ldp	q2, q3, [x7]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x6, #-16]
	stp	q0, q1, [x7]
	b.ne	.LBB197_84
	b	.LBB197_77
.LBB197_85:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end197:
	.size	_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_, .Lfunc_end197-_ZNK9pocketfft6detail5cfftpIfE5passgILb1ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	str	x23, [sp, #-48]!                // 8-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	subs	x8, x1, #1
	b.ne	.LBB198_4
// %bb.1:
	cbz	x2, .LBB198_10
// %bb.2:
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #5
	lsl	x10, x10, #5
	lsl	x11, x2, #6
	add	x12, x3, #64
.LBB198_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x12, #-64]
	add	x13, x8, x11
	add	x14, x8, x9
	subs	x2, x2, #1
	ldp	q2, q3, [x12]
	fadd	v5.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	ldp	q6, q16, [x12, #-32]
	fadd	v7.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	ldp	q4, q2, [x12, #32]
	add	x12, x12, #128
	fadd	v17.4s, v6.4s, v4.4s
	fsub	v4.4s, v6.4s, v4.4s
	fadd	v3.4s, v16.4s, v2.4s
	fsub	v2.4s, v16.4s, v2.4s
	fsub	v16.4s, v5.4s, v17.4s
	fadd	v5.4s, v5.4s, v17.4s
	fsub	v6.4s, v7.4s, v3.4s
	fadd	v3.4s, v7.4s, v3.4s
	fsub	v17.4s, v0.4s, v2.4s
	fadd	v0.4s, v0.4s, v2.4s
	stp	q16, q6, [x13, #-16]
	add	x13, x8, x10
	fadd	v16.4s, v1.4s, v4.4s
	stp	q5, q3, [x8, #-16]
	fsub	v1.4s, v1.4s, v4.4s
	add	x8, x8, #32
	stp	q17, q16, [x14, #-16]
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB198_3
	b	.LBB198_10
.LBB198_4:
	cbz	x2, .LBB198_10
// %bb.5:
	mul	x0, x2, x1
	mov	w14, #96
	lsl	x10, x2, #1
	lsl	x16, x1, #4
	lsl	x18, x1, #3
	mov	x9, xzr
	madd	x14, x0, x14, x4
	add	x11, x3, #32
	lsl	x12, x1, #7
	add	x13, x10, x2
	lsl	x15, x1, #5
	sub	x16, x16, #16
	add	x17, x4, x0, lsl #6
	sub	x18, x18, #8
	add	x0, x4, x0, lsl #5
	mov	x6, x4
	b	.LBB198_7
.LBB198_6:                              //   in Loop: Header=BB198_7 Depth=1
	add	x9, x9, #1
	add	x11, x11, x12
	add	x14, x14, x15
	add	x6, x6, x15
	add	x17, x17, x15
	add	x0, x0, x15
	cmp	x9, x2
	b.eq	.LBB198_10
.LBB198_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB198_9 Depth 2
	lsl	x7, x9, #2
	mov	w19, #2
	mov	w20, #1
	mov	w21, #3
	mul	x7, x7, x1
	bfi	x19, x9, #2, #62
	bfi	x20, x9, #2, #62
	bfi	x21, x9, #2, #62
	mul	x19, x19, x1
	cmp	x1, #2
	add	x7, x3, x7, lsl #5
	mul	x20, x20, x1
	mul	x21, x21, x1
	add	x19, x3, x19, lsl #5
	ldp	q0, q1, [x7]
	add	x7, x3, x20, lsl #5
	add	x20, x3, x21, lsl #5
	ldp	q2, q3, [x19]
	mul	x19, x9, x1
	fadd	v16.4s, v0.4s, v2.4s
	add	x19, x4, x19, lsl #5
	fsub	v0.4s, v0.4s, v2.4s
	ldp	q4, q5, [x7]
	fadd	v17.4s, v1.4s, v3.4s
	add	x7, x9, x10
	fsub	v1.4s, v1.4s, v3.4s
	mul	x7, x7, x1
	ldp	q6, q7, [x20]
	add	x7, x4, x7, lsl #5
	add	x20, x9, x2
	mul	x20, x20, x1
	fadd	v2.4s, v4.4s, v6.4s
	fsub	v4.4s, v4.4s, v6.4s
	fadd	v3.4s, v5.4s, v7.4s
	fsub	v5.4s, v5.4s, v7.4s
	fadd	v6.4s, v16.4s, v2.4s
	fsub	v2.4s, v16.4s, v2.4s
	fadd	v16.4s, v17.4s, v3.4s
	fsub	v3.4s, v17.4s, v3.4s
	stp	q6, q16, [x19]
	add	x19, x9, x13
	stp	q2, q3, [x7]
	mul	x7, x19, x1
	add	x19, x4, x20, lsl #5
	fsub	v2.4s, v0.4s, v5.4s
	fadd	v3.4s, v1.4s, v4.4s
	fadd	v0.4s, v0.4s, v5.4s
	add	x7, x4, x7, lsl #5
	fsub	v1.4s, v1.4s, v4.4s
	stp	q2, q3, [x19]
	stp	q0, q1, [x7]
	b.lo	.LBB198_6
// %bb.8:                               //   in Loop: Header=BB198_7 Depth=1
	mov	x7, xzr
	mov	x19, x5
	mov	x20, x8
.LBB198_9:                              //   Parent Loop BB198_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x21, x11, x7
	ldr	s20, [x19, #4]
	add	x22, x21, x15
	subs	x20, x20, #1
	add	x23, x22, x15
	ldp	q0, q1, [x21]
	add	x21, x23, x15
	ldp	q4, q5, [x23]
	add	x23, x19, x18
	fadd	v16.4s, v0.4s, v4.4s
	fsub	v0.4s, v0.4s, v4.4s
	ldp	q2, q3, [x22]
	fadd	v17.4s, v1.4s, v5.4s
	add	x22, x6, x7
	fsub	v1.4s, v1.4s, v5.4s
	ldp	q6, q7, [x21]
	mov	x21, x19
	add	x19, x19, #8
	fsub	v4.4s, v2.4s, v6.4s
	fadd	v2.4s, v2.4s, v6.4s
	fadd	v5.4s, v3.4s, v7.4s
	fsub	v3.4s, v3.4s, v7.4s
	fadd	v6.4s, v1.4s, v4.4s
	fadd	v7.4s, v16.4s, v2.4s
	fadd	v18.4s, v17.4s, v5.4s
	fsub	v5.4s, v17.4s, v5.4s
	fneg	v19.4s, v6.4s
	fsub	v2.4s, v16.4s, v2.4s
	stp	q7, q18, [x22, #32]
	add	x22, x0, x7
	fsub	v7.4s, v0.4s, v3.4s
	ld1r	{ v18.4s }, [x21], x16
	fmul	v19.4s, v19.4s, v20.s[0]
	fmul	v6.4s, v6.4s, v18.4s
	fsub	v1.4s, v1.4s, v4.4s
	fadd	v0.4s, v0.4s, v3.4s
	fmla	v19.4s, v18.4s, v7.4s
	fmla	v6.4s, v7.4s, v20.s[0]
	fneg	v7.4s, v5.4s
	fneg	v4.4s, v1.4s
	stp	q19, q6, [x22, #32]
	add	x22, x17, x7
	ld1r	{ v6.4s }, [x23], #4
	fmul	v5.4s, v5.4s, v6.4s
	ldr	s17, [x23]
	fmul	v7.4s, v7.4s, v17.s[0]
	fmla	v5.4s, v2.4s, v17.s[0]
	fmla	v7.4s, v6.4s, v2.4s
	stp	q7, q5, [x22, #32]
	ld1r	{ v2.4s }, [x21], #4
	fmul	v1.4s, v1.4s, v2.4s
	ldr	s5, [x21]
	add	x21, x14, x7
	add	x7, x7, #32
	fmul	v3.4s, v4.4s, v5.s[0]
	fmla	v1.4s, v0.4s, v5.s[0]
	fmla	v3.4s, v2.4s, v0.4s
	stp	q3, q1, [x21, #32]
	b.ne	.LBB198_9
	b	.LBB198_6
.LBB198_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp], #48                  // 8-byte Folded Reload
	ret
.Lfunc_end198:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end198-_ZNK9pocketfft6detail5cfftpIfE5pass4ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	str	d14, [sp, #80]                  // 8-byte Folded Spill
	stp	d13, d12, [sp, #96]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #112]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 240
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -160
	subs	x8, x1, #1
	str	x4, [sp, #72]                   // 8-byte Folded Spill
	str	x3, [sp, #88]                   // 8-byte Folded Spill
	b.ne	.LBB199_4
// %bb.1:
	cbz	x2, .LBB199_10
// %bb.2:
	mov	w10, #224
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	mov	w17, #1267
	ldr	x15, [sp, #88]                  // 8-byte Folded Reload
	movk	w17, #16181, lsl #16
	add	x13, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	mul	x10, x2, x10
	add	x8, x8, #16
	lsl	x9, x13, #5
	lsl	x11, x11, #5
	lsl	x12, x2, #5
	lsl	x13, x13, #6
	lsl	x14, x2, #6
	lsl	x16, x2, #7
	add	x15, x15, #128
	dup	v0.4s, w17
.LBB199_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q1, q2, [x15, #-96]
	add	x17, x8, x16
	add	x18, x8, x13
	subs	x2, x2, #1
	ldp	q3, q4, [x15, #32]
	fadd	v6.4s, v1.4s, v3.4s
	fsub	v3.4s, v1.4s, v3.4s
	ldp	q5, q7, [x15, #-32]
	fadd	v16.4s, v2.4s, v4.4s
	fsub	v1.4s, v2.4s, v4.4s
	ldp	q17, q18, [x15, #96]
	fadd	v2.4s, v5.4s, v17.4s
	fsub	v5.4s, v5.4s, v17.4s
	fadd	v4.4s, v7.4s, v18.4s
	ldp	q19, q17, [x15, #-128]
	fsub	v7.4s, v7.4s, v18.4s
	fadd	v20.4s, v6.4s, v2.4s
	fadd	v22.4s, v16.4s, v4.4s
	fsub	v2.4s, v6.4s, v2.4s
	fsub	v4.4s, v16.4s, v4.4s
	ldp	q18, q21, [x15]
	fsub	v27.4s, v3.4s, v7.4s
	fadd	v28.4s, v1.4s, v5.4s
	fadd	v3.4s, v3.4s, v7.4s
	fadd	v24.4s, v19.4s, v18.4s
	fsub	v18.4s, v19.4s, v18.4s
	ldp	q23, q25, [x15, #64]
	fadd	v29.4s, v17.4s, v21.4s
	fsub	v7.4s, v27.4s, v28.4s
	fsub	v17.4s, v17.4s, v21.4s
	fadd	v27.4s, v28.4s, v27.4s
	fsub	v1.4s, v1.4s, v5.4s
	ldp	q6, q16, [x15, #-64]
	fmul	v7.4s, v7.4s, v0.4s
	add	x15, x15, #256
	fneg	v5.4s, v3.4s
	fadd	v26.4s, v6.4s, v23.4s
	fsub	v6.4s, v6.4s, v23.4s
	fadd	v31.4s, v16.4s, v25.4s
	fsub	v16.4s, v16.4s, v25.4s
	fadd	v30.4s, v24.4s, v26.4s
	fsub	v21.4s, v24.4s, v26.4s
	fadd	v9.4s, v29.4s, v31.4s
	fsub	v24.4s, v29.4s, v31.4s
	fsub	v8.4s, v30.4s, v20.4s
	fadd	v23.4s, v17.4s, v6.4s
	fsub	v19.4s, v9.4s, v22.4s
	fadd	v25.4s, v2.4s, v24.4s
	fsub	v2.4s, v24.4s, v2.4s
	fsub	v5.4s, v5.4s, v1.4s
	stp	q8, q19, [x17, #-16]
	add	x17, x8, x14
	fsub	v19.4s, v21.4s, v4.4s
	fadd	v4.4s, v4.4s, v21.4s
	fsub	v21.4s, v18.4s, v16.4s
	fsub	v1.4s, v3.4s, v1.4s
	stp	q19, q25, [x17, #-16]
	add	x17, x8, x12
	fmul	v19.4s, v27.4s, v0.4s
	stp	q4, q2, [x18, #-16]
	fadd	v4.4s, v7.4s, v21.4s
	add	x18, x8, x11
	fmul	v1.4s, v1.4s, v0.4s
	fadd	v3.4s, v18.4s, v16.4s
	fadd	v2.4s, v19.4s, v23.4s
	stp	q4, q2, [x17, #-16]
	fsub	v4.4s, v21.4s, v7.4s
	add	x17, x8, x9
	fmul	v2.4s, v5.4s, v0.4s
	stur	q4, [x18, #-16]
	fsub	v4.4s, v23.4s, v19.4s
	fsub	v5.4s, v17.4s, v6.4s
	fadd	v6.4s, v20.4s, v30.4s
	fadd	v7.4s, v2.4s, v3.4s
	str	q4, [x18]
	fadd	v4.4s, v1.4s, v5.4s
	stur	q6, [x8, #-16]
	fadd	v6.4s, v22.4s, v9.4s
	fsub	v2.4s, v3.4s, v2.4s
	fsub	v1.4s, v5.4s, v1.4s
	stp	q7, q4, [x17, #-16]
	add	x17, x8, x10
	str	q6, [x8], #32
	stp	q2, q1, [x17, #-16]
	b.ne	.LBB199_3
	b	.LBB199_10
.LBB199_4:
	stp	x5, x8, [sp, #8]                // 16-byte Folded Spill
	cbz	x2, .LBB199_10
// %bb.5:
	lsl	x8, x2, #1
	lsl	x12, x2, #2
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	mul	x10, x2, x1
	ldr	x15, [sp, #16]                  // 8-byte Folded Reload
	mov	w11, #224
	stp	x12, x8, [sp, #56]              // 16-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	ldr	x4, [sp, #72]                   // 8-byte Folded Reload
	add	x12, x12, x2
	lsl	x17, x1, #5
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	lsl	x8, x2, #3
	sub	x8, x8, x2
	madd	x16, x10, x11, x4
	madd	x11, x1, x11, x14
	stp	x12, x18, [sp, #32]             // 16-byte Folded Spill
	mov	w12, #96
	add	x13, x17, x14
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	mov	w8, #160
	add	x20, x11, #48
	add	x11, x14, x15, lsl #7
	madd	x3, x15, x8, x14
	add	x18, x13, #48
	madd	x13, x15, x12, x14
	add	x22, x11, #128
	add	x6, x3, #208
	mov	w3, #48
	madd	x7, x10, x12, x4
	add	x12, x14, x15, lsl #6
	mul	x11, x1, x3
	add	x23, x12, #64
	mov	w12, #40
	madd	x21, x10, x8, x4
	mov	w8, #192
	sub	x26, x11, #48
	lsl	x11, x1, #4
	add	x19, x13, #144
	sub	x27, x11, #16
	mul	x11, x1, x12
	madd	x13, x15, x8, x14
	mov	x9, xzr
	madd	x28, x10, x8, x4
	mov	w8, #24
	sub	x30, x11, #40
	lsl	x11, x1, #3
	mul	x12, x1, x8
	sub	x8, x11, #8
	mov	w11, #1267
	lsl	x0, x1, #8
	movk	w11, #16181, lsl #16
	add	x24, x13, #192
	add	x25, x4, x10, lsl #5
	add	x29, x4, x10, lsl #6
	add	x5, x4, x10, lsl #7
	sub	x13, x12, #24
	mov	x3, x14
	dup	v0.4s, w11
	b	.LBB199_7
.LBB199_6:                              //   in Loop: Header=BB199_7 Depth=1
	add	x9, x9, #1
	add	x16, x16, x17
	add	x18, x18, x0
	add	x6, x6, x0
	add	x7, x7, x17
	add	x19, x19, x0
	add	x20, x20, x0
	add	x21, x21, x17
	add	x3, x3, x0
	add	x22, x22, x0
	add	x23, x23, x0
	add	x24, x24, x0
	add	x4, x4, x17
	add	x25, x25, x17
	add	x28, x28, x17
	add	x29, x29, x17
	add	x5, x5, x17
	cmp	x9, x2
	b.eq	.LBB199_10
.LBB199_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB199_9 Depth 2
	mov	w10, #1
	mov	w11, #5
	bfi	x10, x9, #3, #61
	bfi	x11, x9, #3, #61
	ldr	x14, [sp, #88]                  // 8-byte Folded Reload
	mov	w12, #3
	mul	x10, x10, x1
	mov	w15, #7
	mul	x11, x11, x1
	bfi	x12, x9, #3, #61
	bfi	x15, x9, #3, #61
	cmp	x1, #2
	add	x10, x14, x10, lsl #5
	mul	x12, x12, x1
	add	x11, x14, x11, lsl #5
	ldp	q1, q2, [x10]
	mul	x10, x15, x1
	add	x12, x14, x12, lsl #5
	add	x10, x14, x10, lsl #5
	ldp	q3, q4, [x11]
	lsl	x11, x9, #3
	fadd	v7.4s, v1.4s, v3.4s
	fsub	v18.4s, v1.4s, v3.4s
	ldp	q5, q6, [x12]
	fadd	v16.4s, v2.4s, v4.4s
	mov	w12, #2
	fsub	v19.4s, v2.4s, v4.4s
	bfi	x12, x9, #3, #61
	mul	x12, x12, x1
	ldp	q17, q1, [x10]
	mul	x10, x11, x1
	mov	w11, #4
	bfi	x11, x9, #3, #61
	add	x12, x14, x12, lsl #5
	fadd	v2.4s, v5.4s, v17.4s
	add	x10, x14, x10, lsl #5
	fsub	v5.4s, v5.4s, v17.4s
	mul	x11, x11, x1
	fadd	v20.4s, v6.4s, v1.4s
	fsub	v6.4s, v6.4s, v1.4s
	fadd	v4.4s, v7.4s, v2.4s
	add	x11, x14, x11, lsl #5
	fsub	v1.4s, v7.4s, v2.4s
	fadd	v3.4s, v16.4s, v20.4s
	fsub	v2.4s, v16.4s, v20.4s
	ldp	q16, q17, [x10]
	mov	w10, #6
	bfi	x10, x9, #3, #61
	fadd	v7.4s, v18.4s, v6.4s
	mul	x10, x10, x1
	fsub	v6.4s, v18.4s, v6.4s
	fadd	v18.4s, v19.4s, v5.4s
	add	x10, x14, x10, lsl #5
	ldr	x14, [sp, #72]                  // 8-byte Folded Reload
	ldp	q20, q21, [x11]
	fsub	v5.4s, v19.4s, v5.4s
	fsub	v22.4s, v6.4s, v18.4s
	fadd	v6.4s, v18.4s, v6.4s
	fneg	v19.4s, v7.4s
	fadd	v25.4s, v16.4s, v20.4s
	ldp	q23, q18, [x12]
	fadd	v27.4s, v17.4s, v21.4s
	fsub	v19.4s, v19.4s, v5.4s
	fsub	v5.4s, v7.4s, v5.4s
	fsub	v7.4s, v16.4s, v20.4s
	fsub	v17.4s, v17.4s, v21.4s
	ldp	q24, q26, [x10]
	mul	x10, x9, x1
	fmul	v22.4s, v22.4s, v0.4s
	fmul	v6.4s, v6.4s, v0.4s
	fadd	v28.4s, v23.4s, v24.4s
	add	x10, x14, x10, lsl #5
	fadd	v29.4s, v18.4s, v26.4s
	ldr	x11, [sp, #56]                  // 8-byte Folded Reload
	fsub	v18.4s, v18.4s, v26.4s
	ldr	x12, [sp, #40]                  // 8-byte Folded Reload
	fadd	v16.4s, v25.4s, v28.4s
	add	x11, x9, x11
	fadd	v20.4s, v27.4s, v29.4s
	add	x12, x9, x12
	mul	x11, x11, x1
	fadd	v21.4s, v4.4s, v16.4s
	fsub	v4.4s, v16.4s, v4.4s
	fadd	v26.4s, v3.4s, v20.4s
	add	x11, x14, x11, lsl #5
	fsub	v3.4s, v20.4s, v3.4s
	stp	q21, q26, [x10]
	ldr	x10, [sp, #64]                  // 8-byte Folded Reload
	fsub	v21.4s, v25.4s, v28.4s
	stp	q4, q3, [x11]
	fsub	v25.4s, v27.4s, v29.4s
	mul	x11, x12, x1
	add	x10, x9, x10
	ldr	x12, [sp, #32]                  // 8-byte Folded Reload
	fsub	v4.4s, v23.4s, v24.4s
	mul	x10, x10, x1
	add	x11, x14, x11, lsl #5
	fsub	v16.4s, v21.4s, v2.4s
	add	x12, x9, x12
	fadd	v20.4s, v1.4s, v25.4s
	add	x10, x14, x10, lsl #5
	fsub	v3.4s, v7.4s, v18.4s
	fadd	v2.4s, v2.4s, v21.4s
	stp	q16, q20, [x10]
	add	x10, x9, x2
	fadd	v16.4s, v17.4s, v4.4s
	fsub	v1.4s, v25.4s, v1.4s
	mul	x10, x10, x1
	fadd	v20.4s, v22.4s, v3.4s
	fsub	v3.4s, v3.4s, v22.4s
	fadd	v21.4s, v6.4s, v16.4s
	add	x10, x14, x10, lsl #5
	stp	q2, q1, [x11]
	mul	x11, x12, x1
	ldr	x12, [sp, #24]                  // 8-byte Folded Reload
	fmul	v1.4s, v5.4s, v0.4s
	stp	q20, q21, [x10]
	add	x10, x14, x11, lsl #5
	ldr	x11, [sp, #48]                  // 8-byte Folded Reload
	add	x12, x9, x12
	fsub	v5.4s, v16.4s, v6.4s
	fmul	v2.4s, v19.4s, v0.4s
	add	x11, x9, x11
	fadd	v6.4s, v7.4s, v18.4s
	fsub	v4.4s, v17.4s, v4.4s
	mul	x11, x11, x1
	stp	q3, q5, [x10]
	mul	x10, x12, x1
	fadd	v3.4s, v2.4s, v6.4s
	add	x11, x14, x11, lsl #5
	fadd	v5.4s, v1.4s, v4.4s
	add	x10, x14, x10, lsl #5
	fsub	v2.4s, v6.4s, v2.4s
	fsub	v1.4s, v4.4s, v1.4s
	stp	q3, q5, [x11]
	stp	q2, q1, [x10]
	b.lo	.LBB199_6
// %bb.8:                               //   in Loop: Header=BB199_7 Depth=1
	ldp	x11, x12, [sp, #8]              // 16-byte Folded Reload
	mov	x10, xzr
.LBB199_9:                              //   Parent Loop BB199_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x15, x18, x10
	add	x14, x6, x10
	subs	x12, x12, #1
	ldp	q2, q1, [x15, #-16]
	add	x15, x19, x10
	ldp	q6, q3, [x14, #-16]
	add	x14, x20, x10
	fadd	v19.4s, v2.4s, v6.4s
	fsub	v2.4s, v2.4s, v6.4s
	ldp	q5, q4, [x15, #-16]
	add	x15, x3, x10
	fadd	v22.4s, v1.4s, v3.4s
	fsub	v3.4s, v1.4s, v3.4s
	ldp	q7, q16, [x14, #-16]
	add	x14, x22, x10
	fadd	v24.4s, v5.4s, v7.4s
	fsub	v5.4s, v5.4s, v7.4s
	ldp	q17, q18, [x15, #32]
	add	x15, x23, x10
	fadd	v26.4s, v4.4s, v16.4s
	fadd	v9.4s, v19.4s, v24.4s
	fsub	v19.4s, v19.4s, v24.4s
	fsub	v4.4s, v4.4s, v16.4s
	ldp	q20, q21, [x14, #32]
	add	x14, x24, x10
	fadd	v10.4s, v22.4s, v26.4s
	fsub	v22.4s, v22.4s, v26.4s
	fadd	v28.4s, v17.4s, v20.4s
	fsub	v1.4s, v17.4s, v20.4s
	ldp	q23, q25, [x15, #32]
	fadd	v30.4s, v18.4s, v21.4s
	add	x15, x11, x13
	fsub	v16.4s, v18.4s, v21.4s
	fadd	v18.4s, v3.4s, v5.4s
	fsub	v3.4s, v3.4s, v5.4s
	ldp	q27, q29, [x14, #32]
	add	x14, x4, x10
	fadd	v31.4s, v23.4s, v27.4s
	fsub	v17.4s, v23.4s, v27.4s
	fadd	v8.4s, v25.4s, v29.4s
	fsub	v20.4s, v25.4s, v29.4s
	fadd	v11.4s, v28.4s, v31.4s
	fsub	v26.4s, v28.4s, v31.4s
	fadd	v12.4s, v30.4s, v8.4s
	fsub	v24.4s, v30.4s, v8.4s
	fadd	v13.4s, v9.4s, v11.4s
	fsub	v9.4s, v11.4s, v9.4s
	fadd	v14.4s, v10.4s, v12.4s
	fsub	v10.4s, v12.4s, v10.4s
	fadd	v6.4s, v19.4s, v24.4s
	fsub	v7.4s, v26.4s, v22.4s
	stp	q13, q14, [x14, #32]
	add	x14, x5, x10
	ld1r	{ v12.4s }, [x15], #4
	fneg	v13.4s, v10.4s
	fmul	v10.4s, v10.4s, v12.4s
	fneg	v28.4s, v6.4s
	ldr	s14, [x15]
	add	x15, x11, x8
	fsub	v19.4s, v24.4s, v19.4s
	fadd	v23.4s, v16.4s, v17.4s
	fmul	v11.4s, v13.4s, v14.s[0]
	fmla	v10.4s, v9.4s, v14.s[0]
	fadd	v22.4s, v22.4s, v26.4s
	fneg	v24.4s, v19.4s
	fsub	v26.4s, v1.4s, v20.4s
	fmla	v11.4s, v12.4s, v9.4s
	fsub	v16.4s, v16.4s, v17.4s
	fadd	v1.4s, v1.4s, v20.4s
	stp	q11, q10, [x14, #32]
	add	x14, x29, x10
	ld1r	{ v30.4s }, [x15], #4
	fmul	v6.4s, v6.4s, v30.4s
	ldr	s31, [x15]
	add	x15, x11, x30
	fmul	v28.4s, v28.4s, v31.s[0]
	fmla	v6.4s, v7.4s, v31.s[0]
	fmla	v28.4s, v30.4s, v7.4s
	fsub	v7.4s, v2.4s, v4.4s
	fadd	v2.4s, v2.4s, v4.4s
	stp	q28, q6, [x14, #32]
	add	x14, x28, x10
	ld1r	{ v6.4s }, [x15], #4
	fadd	v21.4s, v18.4s, v7.4s
	ldr	s4, [x11, #4]
	fsub	v7.4s, v7.4s, v18.4s
	fmul	v19.4s, v19.4s, v6.4s
	ldr	s18, [x15]
	mov	x15, x11
	fmul	v21.4s, v21.4s, v0.4s
	fmul	v24.4s, v24.4s, v18.s[0]
	fmla	v19.4s, v22.4s, v18.s[0]
	fadd	v25.4s, v21.4s, v23.4s
	fsub	v18.4s, v23.4s, v21.4s
	fmla	v24.4s, v6.4s, v22.4s
	fmul	v6.4s, v7.4s, v0.4s
	fneg	v7.4s, v25.4s
	fneg	v23.4s, v18.4s
	stp	q24, q19, [x14, #32]
	add	x14, x11, x17
	fadd	v19.4s, v6.4s, v26.4s
	fmul	v7.4s, v7.4s, v4.s[0]
	ld1r	{ v21.4s }, [x15], x26
	fmul	v22.4s, v25.4s, v21.4s
	ldp	s24, s25, [x14, #-32]
	fmla	v7.4s, v21.4s, v19.4s
	add	x14, x25, x10
	fsub	v5.4s, v26.4s, v6.4s
	fmla	v22.4s, v19.4s, v4.s[0]
	fmul	v4.4s, v23.4s, v25.s[0]
	fmul	v6.4s, v18.4s, v24.s[0]
	stp	q7, q22, [x14, #32]
	add	x14, x21, x10
	fsub	v7.4s, v2.4s, v3.4s
	fmla	v4.4s, v5.4s, v24.s[0]
	fmla	v6.4s, v5.4s, v25.s[0]
	fneg	v2.4s, v2.4s
	fmul	v5.4s, v7.4s, v0.4s
	stp	q4, q6, [x14, #32]
	add	x14, x11, x27
	fsub	v2.4s, v2.4s, v3.4s
	add	x11, x11, #8
	fadd	v3.4s, v5.4s, v16.4s
	ld1r	{ v4.4s }, [x14], #4
	fmul	v2.4s, v2.4s, v0.4s
	fneg	v6.4s, v3.4s
	ldr	s7, [x14]
	add	x14, x7, x10
	fadd	v17.4s, v2.4s, v1.4s
	fmul	v3.4s, v3.4s, v4.4s
	fmul	v6.4s, v6.4s, v7.s[0]
	fsub	v1.4s, v1.4s, v2.4s
	fmla	v3.4s, v17.4s, v7.s[0]
	fmla	v6.4s, v4.4s, v17.4s
	fsub	v4.4s, v16.4s, v5.4s
	stp	q6, q3, [x14, #32]
	add	x14, x16, x10
	ld1r	{ v3.4s }, [x15], #4
	fneg	v5.4s, v4.4s
	add	x10, x10, #32
	fmul	v4.4s, v4.4s, v3.4s
	ldr	s6, [x15]
	fmul	v2.4s, v5.4s, v6.s[0]
	fmla	v4.4s, v1.4s, v6.s[0]
	fmla	v2.4s, v3.4s, v1.4s
	stp	q2, q4, [x14, #32]
	b.ne	.LBB199_9
	b	.LBB199_6
.LBB199_10:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #112]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #96]             // 16-byte Folded Reload
	ldr	d14, [sp, #80]                  // 8-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end199:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end199-_ZNK9pocketfft6detail5cfftpIfE5pass8ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	cmp	x1, #1
	b.ne	.LBB200_4
// %bb.1:
	cbz	x2, .LBB200_12
// %bb.2:
	lsl	x8, x2, #5
	add	x9, x4, #16
	add	x10, x3, #32
.LBB200_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x10, #-32]
	add	x11, x9, x8
	subs	x2, x2, #1
	ldp	q2, q3, [x10], #64
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x9, #-16]
	add	x9, x9, #32
	stp	q0, q1, [x11, #-16]
	b.ne	.LBB200_3
	b	.LBB200_12
.LBB200_4:
	cbz	x2, .LBB200_12
// %bb.5:
	subs	x8, x1, #1
	b.ls	.LBB200_10
// %bb.6:
	mul	x13, x2, x1
	mov	x9, xzr
	add	x10, x4, #32
	lsl	x11, x1, #5
	add	x12, x3, #48
	lsl	x13, x13, #5
	lsl	x14, x1, #6
	add	x15, x5, #4
.LBB200_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB200_8 Depth 2
	mov	w17, #1
	lsl	x16, x9, #1
	bfi	x17, x9, #1, #63
	mul	x5, x9, x1
	mul	x16, x16, x1
	add	x18, x9, x2
	mul	x17, x17, x1
	mul	x18, x18, x1
	add	x16, x3, x16, lsl #5
	add	x0, x3, x17, lsl #5
	mov	x17, x12
	ldp	q0, q1, [x16]
	mov	x16, x15
	ldp	q2, q3, [x0]
	add	x0, x4, x5, lsl #5
	add	x5, x4, x18, lsl #5
	mov	x18, x10
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x0]
	mov	x0, x8
	stp	q0, q1, [x5]
.LBB200_8:                              //   Parent Loop BB200_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x5, x17, x11
	subs	x0, x0, #1
	ldp	q3, q0, [x17, #-16]
	add	x17, x17, #32
	ldp	q6, q1, [x5, #-16]
	add	x5, x18, x13
	fsub	v16.4s, v3.4s, v6.4s
	fadd	v3.4s, v3.4s, v6.4s
	fsub	v2.4s, v0.4s, v1.4s
	ldp	s7, s4, [x16, #-4]
	fadd	v0.4s, v0.4s, v1.4s
	add	x16, x16, #8
	fneg	v5.4s, v2.4s
	fmul	v2.4s, v2.4s, v7.s[0]
	stp	q3, q0, [x18], #32
	fmul	v5.4s, v5.4s, v4.s[0]
	fmla	v2.4s, v16.4s, v4.s[0]
	fmla	v5.4s, v16.4s, v7.s[0]
	stp	q5, q2, [x5]
	b.ne	.LBB200_8
// %bb.9:                               //   in Loop: Header=BB200_7 Depth=1
	add	x9, x9, #1
	add	x10, x10, x11
	add	x12, x12, x14
	cmp	x9, x2
	b.ne	.LBB200_7
	b	.LBB200_12
.LBB200_10:
	mul	x10, x2, x1
	add	x8, x4, #16
	lsl	x9, x1, #5
	add	x11, x3, #16
	lsl	x10, x10, #5
	lsl	x12, x1, #6
.LBB200_11:                             // =>This Inner Loop Header: Depth=1
	add	x13, x11, x9
	subs	x2, x2, #1
	ldp	q0, q1, [x11, #-16]
	add	x11, x11, x12
	ldp	q2, q3, [x13, #-16]
	add	x13, x8, x10
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x8, #-16]
	add	x8, x8, x9
	stp	q0, q1, [x13, #-16]
	b.ne	.LBB200_11
.LBB200_12:
	ret
.Lfunc_end200:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end200-_ZNK9pocketfft6detail5cfftpIfE5pass2ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	str	x21, [sp, #-32]!                // 8-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	subs	x8, x1, #1
	b.ne	.LBB201_4
// %bb.1:
	cbz	x2, .LBB201_10
// %bb.2:
	mov	w12, #46039
	mov	w13, #46039
	movk	w12, #48989, lsl #16
	movk	w13, #16221, lsl #16
	movi	v0.4s, #63, lsl #24
	lsl	x8, x2, #6
	add	x9, x4, #16
	lsl	x10, x2, #5
	add	x11, x3, #48
	dup	v1.4s, w12
	dup	v2.4s, w13
.LBB201_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q3, q4, [x11, #-16]
	add	x12, x9, x10
	subs	x2, x2, #1
	ldp	q5, q6, [x11, #16]
	fadd	v7.4s, v3.4s, v5.4s
	fsub	v3.4s, v3.4s, v5.4s
	fadd	v17.4s, v4.4s, v6.4s
	ldp	q16, q18, [x11, #-48]
	fsub	v4.4s, v4.4s, v6.4s
	add	x11, x11, #96
	fmul	v5.4s, v7.4s, v0.4s
	fmul	v6.4s, v17.4s, v0.4s
	fmul	v3.4s, v3.4s, v2.4s
	fmul	v4.4s, v4.4s, v1.4s
	fsub	v5.4s, v16.4s, v5.4s
	fsub	v6.4s, v18.4s, v6.4s
	fadd	v7.4s, v16.4s, v7.4s
	fadd	v16.4s, v18.4s, v17.4s
	fadd	v19.4s, v5.4s, v4.4s
	fadd	v20.4s, v3.4s, v6.4s
	fsub	v4.4s, v5.4s, v4.4s
	fsub	v3.4s, v6.4s, v3.4s
	stp	q7, q16, [x9, #-16]
	stp	q19, q20, [x12, #-16]
	add	x12, x9, x8
	add	x9, x9, #32
	stp	q4, q3, [x12, #-16]
	b.ne	.LBB201_3
	b	.LBB201_10
.LBB201_4:
	cbz	x2, .LBB201_10
// %bb.5:
	mul	x16, x2, x1
	mov	w6, #46039
	mov	w7, #46039
	movk	w6, #48989, lsl #16
	movk	w7, #16221, lsl #16
	add	x12, x1, x1, lsl #1
	lsl	x11, x1, #5
	lsl	x17, x1, #3
	movi	v0.4s, #63, lsl #24
	mov	x9, xzr
	lsl	x10, x2, #1
	lsl	x12, x12, #5
	add	x13, x3, x11
	add	x14, x4, x16, lsl #6
	add	x15, x3, x1, lsl #6
	add	x16, x4, x16, lsl #5
	sub	x17, x17, #8
	mov	x18, x4
	mov	x0, x3
	dup	v1.4s, w6
	dup	v2.4s, w7
	b	.LBB201_7
.LBB201_6:                              //   in Loop: Header=BB201_7 Depth=1
	add	x9, x9, #1
	add	x14, x14, x11
	add	x0, x0, x12
	add	x13, x13, x12
	add	x15, x15, x12
	add	x18, x18, x11
	add	x16, x16, x11
	cmp	x9, x2
	b.eq	.LBB201_10
.LBB201_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB201_9 Depth 2
	add	x6, x9, x9, lsl #1
	add	x20, x9, x2
	add	x7, x6, #2
	cmp	x1, #2
	mul	x6, x6, x1
	mul	x7, x7, x1
	add	x19, x1, x6
	add	x6, x3, x6, lsl #5
	add	x19, x3, x19, lsl #5
	add	x7, x3, x7, lsl #5
	ldp	q3, q4, [x6]
	mul	x6, x9, x1
	add	x6, x4, x6, lsl #5
	ldp	q5, q6, [x19]
	add	x19, x9, x10
	mul	x19, x19, x1
	ldp	q7, q16, [x7]
	mul	x7, x20, x1
	add	x19, x4, x19, lsl #5
	fadd	v17.4s, v5.4s, v7.4s
	add	x7, x4, x7, lsl #5
	fsub	v5.4s, v5.4s, v7.4s
	fadd	v18.4s, v6.4s, v16.4s
	fsub	v6.4s, v6.4s, v16.4s
	fadd	v7.4s, v3.4s, v17.4s
	fmul	v17.4s, v17.4s, v0.4s
	fadd	v16.4s, v4.4s, v18.4s
	fmul	v18.4s, v18.4s, v0.4s
	fmul	v6.4s, v6.4s, v1.4s
	fmul	v5.4s, v5.4s, v2.4s
	fsub	v3.4s, v3.4s, v17.4s
	stp	q7, q16, [x6]
	fsub	v4.4s, v4.4s, v18.4s
	fadd	v7.4s, v3.4s, v6.4s
	fadd	v16.4s, v5.4s, v4.4s
	fsub	v3.4s, v3.4s, v6.4s
	fsub	v4.4s, v4.4s, v5.4s
	stp	q7, q16, [x7]
	stp	q3, q4, [x19]
	b.lo	.LBB201_6
// %bb.8:                               //   in Loop: Header=BB201_7 Depth=1
	mov	x6, xzr
	mov	x7, x5
	mov	x19, x8
.LBB201_9:                              //   Parent Loop BB201_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x13, x6
	add	x21, x15, x6
	subs	x19, x19, #1
	ldp	q5, q3, [x20, #32]
	add	x20, x0, x6
	ldp	q6, q4, [x21, #32]
	add	x21, x18, x6
	fsub	v16.4s, v5.4s, v6.4s
	fadd	v5.4s, v5.4s, v6.4s
	fadd	v7.4s, v3.4s, v4.4s
	ldp	q18, q19, [x20, #32]
	fmul	v6.4s, v16.4s, v2.4s
	mov	x20, x7
	fsub	v3.4s, v3.4s, v4.4s
	fmul	v17.4s, v7.4s, v0.4s
	fadd	v4.4s, v18.4s, v5.4s
	fmul	v5.4s, v5.4s, v0.4s
	fadd	v7.4s, v19.4s, v7.4s
	fsub	v16.4s, v19.4s, v17.4s
	fmul	v3.4s, v3.4s, v1.4s
	fsub	v5.4s, v18.4s, v5.4s
	stp	q4, q7, [x21, #32]
	ldr	s4, [x7, #4]
	fadd	v17.4s, v6.4s, v16.4s
	add	x21, x16, x6
	ld1r	{ v7.4s }, [x20], x17
	fadd	v19.4s, v5.4s, v3.4s
	add	x7, x7, #8
	fsub	v3.4s, v5.4s, v3.4s
	fneg	v18.4s, v17.4s
	fmul	v17.4s, v17.4s, v7.4s
	fmul	v18.4s, v18.4s, v4.s[0]
	fmla	v17.4s, v19.4s, v4.s[0]
	fsub	v4.4s, v16.4s, v6.4s
	fmla	v18.4s, v7.4s, v19.4s
	fneg	v7.4s, v4.4s
	stp	q18, q17, [x21, #32]
	ld1r	{ v6.4s }, [x20], #4
	fmul	v4.4s, v4.4s, v6.4s
	ldr	s16, [x20]
	add	x20, x14, x6
	add	x6, x6, #32
	fmul	v5.4s, v7.4s, v16.s[0]
	fmla	v4.4s, v3.4s, v16.s[0]
	fmla	v5.4s, v6.4s, v3.4s
	stp	q5, q4, [x20, #32]
	b.ne	.LBB201_9
	b	.LBB201_6
.LBB201_10:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp], #32                  // 8-byte Folded Reload
	ret
.Lfunc_end201:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end201-_ZNK9pocketfft6detail5cfftpIfE5pass3ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	subs	x8, x1, #1
	b.ne	.LBB202_4
// %bb.1:
	cbz	x2, .LBB202_10
// %bb.2:
	mov	w11, #14202
	mov	w12, #7101
	mov	w13, #31000
	movk	w11, #16030, lsl #16
	movk	w12, #48975, lsl #16
	movk	w13, #16150, lsl #16
	mov	w14, #30833
	mov	w15, #30833
	movk	w14, #16243, lsl #16
	movk	w15, #49011, lsl #16
	add	x10, x2, x2, lsl #1
	add	x8, x4, #16
	lsl	x9, x2, #6
	lsl	x10, x10, #5
	dup	v0.4s, w11
	dup	v1.4s, w12
	lsl	x11, x2, #7
	dup	v2.4s, w13
	lsl	x12, x2, #5
	add	x13, x3, #80
	dup	v3.4s, w14
	dup	v4.4s, w15
.LBB202_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x13, #-48]
	add	x14, x8, x12
	add	x15, x8, x9
	subs	x2, x2, #1
	ldp	q16, q7, [x13, #48]
	fadd	v19.4s, v5.4s, v16.4s
	fsub	v5.4s, v5.4s, v16.4s
	ldp	q17, q20, [x13, #-16]
	fadd	v21.4s, v6.4s, v7.4s
	fsub	v6.4s, v6.4s, v7.4s
	ldp	q22, q18, [x13, #16]
	fadd	v23.4s, v17.4s, v22.4s
	fsub	v17.4s, v17.4s, v22.4s
	ldp	q16, q7, [x13, #-80]
	fsub	v24.4s, v20.4s, v18.4s
	add	x13, x13, #160
	fadd	v18.4s, v20.4s, v18.4s
	fmul	v22.4s, v17.4s, v2.4s
	mov	v25.16b, v16.16b
	fmul	v20.4s, v24.4s, v2.4s
	mov	v26.16b, v7.16b
	fmla	v22.4s, v3.4s, v5.4s
	fmla	v25.4s, v0.4s, v19.4s
	fmla	v20.4s, v3.4s, v6.4s
	fmla	v26.4s, v0.4s, v21.4s
	fadd	v27.4s, v16.4s, v19.4s
	fmla	v16.4s, v1.4s, v19.4s
	fmla	v25.4s, v1.4s, v23.4s
	fadd	v28.4s, v7.4s, v21.4s
	fmla	v7.4s, v1.4s, v21.4s
	fmla	v26.4s, v1.4s, v18.4s
	fmul	v24.4s, v24.4s, v4.4s
	fmla	v16.4s, v0.4s, v23.4s
	fmul	v17.4s, v17.4s, v4.4s
	fsub	v19.4s, v25.4s, v20.4s
	fmla	v7.4s, v0.4s, v18.4s
	fadd	v21.4s, v26.4s, v22.4s
	fadd	v20.4s, v25.4s, v20.4s
	fmla	v24.4s, v2.4s, v6.4s
	fmla	v17.4s, v2.4s, v5.4s
	fsub	v5.4s, v26.4s, v22.4s
	fadd	v6.4s, v27.4s, v23.4s
	stp	q19, q21, [x14, #-16]
	add	x14, x8, x11
	fsub	v19.4s, v16.4s, v24.4s
	stp	q20, q5, [x14, #-16]
	add	x14, x8, x10
	fadd	v20.4s, v7.4s, v17.4s
	stur	q6, [x8, #-16]
	fadd	v5.4s, v28.4s, v18.4s
	fadd	v6.4s, v16.4s, v24.4s
	fsub	v7.4s, v7.4s, v17.4s
	stp	q19, q20, [x15, #-16]
	str	q5, [x8], #32
	stp	q6, q7, [x14, #-16]
	b.ne	.LBB202_3
	b	.LBB202_10
.LBB202_4:
	cbz	x2, .LBB202_10
// %bb.5:
	mul	x22, x2, x1
	mov	w17, #96
	mov	w19, #24
	mov	w23, #14202
	mov	w24, #7101
	movk	w23, #16030, lsl #16
	movk	w24, #48975, lsl #16
	mov	w25, #31000
	mov	w26, #30833
	mov	w27, #30833
	madd	x0, x8, x17, x3
	movk	w25, #16150, lsl #16
	mul	x21, x1, x19
	movk	w26, #16243, lsl #16
	movk	w27, #49011, lsl #16
	lsl	x11, x2, #1
	add	x15, x1, x1, lsl #2
	madd	x13, x22, x17, x4
	lsl	x14, x1, #5
	add	x18, x3, x8, lsl #6
	lsl	x7, x1, #4
	lsl	x20, x1, #3
	mov	x9, xzr
	lsl	x10, x2, #2
	add	x12, x11, x2
	lsl	x15, x15, #5
	add	x16, x3, x14
	add	x17, x3, x1, lsl #7
	add	x18, x18, #64
	add	x0, x0, #96
	add	x6, x4, x22, lsl #6
	sub	x7, x7, #16
	sub	x19, x20, #8
	add	x20, x4, x22, lsl #7
	sub	x21, x21, #24
	add	x22, x4, x22, lsl #5
	dup	v0.4s, w23
	dup	v1.4s, w24
	mov	x23, x4
	mov	x24, x3
	dup	v2.4s, w25
	dup	v3.4s, w26
	dup	v4.4s, w27
	b	.LBB202_7
.LBB202_6:                              //   in Loop: Header=BB202_7 Depth=1
	add	x9, x9, #1
	add	x13, x13, x14
	add	x24, x24, x15
	add	x16, x16, x15
	add	x17, x17, x15
	add	x18, x18, x15
	add	x0, x0, x15
	add	x23, x23, x14
	add	x6, x6, x14
	add	x20, x20, x14
	add	x22, x22, x14
	cmp	x9, x2
	b.eq	.LBB202_10
.LBB202_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB202_9 Depth 2
	add	x25, x9, x9, lsl #2
	cmp	x1, #2
	add	x26, x25, #4
	add	x29, x25, #2
	mul	x27, x25, x1
	add	x25, x25, #3
	mul	x26, x26, x1
	mul	x25, x25, x1
	add	x28, x3, x27, lsl #5
	add	x27, x1, x27
	add	x26, x3, x26, lsl #5
	add	x27, x3, x27, lsl #5
	add	x25, x3, x25, lsl #5
	ldp	q6, q5, [x28]
	mul	x28, x29, x1
	ldp	q7, q16, [x27]
	add	x27, x3, x28, lsl #5
	mov	v25.16b, v5.16b
	ldp	q17, q18, [x26]
	add	x26, x9, x2
	mul	x26, x26, x1
	fadd	v21.4s, v7.4s, v17.4s
	fsub	v7.4s, v7.4s, v17.4s
	ldp	q19, q20, [x27]
	fadd	v22.4s, v16.4s, v18.4s
	add	x26, x4, x26, lsl #5
	fsub	v16.4s, v16.4s, v18.4s
	add	x27, x9, x12
	fadd	v28.4s, v5.4s, v22.4s
	fmla	v25.4s, v0.4s, v22.4s
	ldp	q23, q17, [x25]
	mul	x25, x9, x1
	fmla	v5.4s, v1.4s, v22.4s
	fadd	v18.4s, v19.4s, v23.4s
	add	x25, x4, x25, lsl #5
	fsub	v19.4s, v19.4s, v23.4s
	fadd	v24.4s, v20.4s, v17.4s
	fsub	v17.4s, v20.4s, v17.4s
	mov	v20.16b, v6.16b
	fadd	v23.4s, v6.4s, v21.4s
	fmla	v6.4s, v1.4s, v21.4s
	fmul	v27.4s, v19.4s, v2.4s
	fmla	v25.4s, v1.4s, v24.4s
	fmul	v26.4s, v17.4s, v2.4s
	fmla	v5.4s, v0.4s, v24.4s
	fmla	v20.4s, v0.4s, v21.4s
	fadd	v23.4s, v23.4s, v18.4s
	fmla	v6.4s, v0.4s, v18.4s
	fadd	v28.4s, v28.4s, v24.4s
	fmla	v27.4s, v3.4s, v7.4s
	fmla	v26.4s, v3.4s, v16.4s
	fmla	v20.4s, v1.4s, v18.4s
	fmul	v17.4s, v17.4s, v4.4s
	stp	q23, q28, [x25]
	add	x25, x9, x10
	fadd	v30.4s, v25.4s, v27.4s
	fsub	v29.4s, v20.4s, v26.4s
	mul	x25, x25, x1
	fmul	v19.4s, v19.4s, v4.4s
	fmla	v17.4s, v2.4s, v16.4s
	fadd	v20.4s, v20.4s, v26.4s
	fsub	v21.4s, v25.4s, v27.4s
	add	x25, x4, x25, lsl #5
	stp	q29, q30, [x26]
	add	x26, x9, x11
	fmla	v19.4s, v2.4s, v7.4s
	mul	x26, x26, x1
	stp	q20, q21, [x25]
	mul	x25, x27, x1
	fsub	v7.4s, v6.4s, v17.4s
	fadd	v16.4s, v5.4s, v19.4s
	add	x26, x4, x26, lsl #5
	fadd	v6.4s, v6.4s, v17.4s
	add	x25, x4, x25, lsl #5
	fsub	v5.4s, v5.4s, v19.4s
	stp	q7, q16, [x26]
	stp	q6, q5, [x25]
	b.lo	.LBB202_6
// %bb.8:                               //   in Loop: Header=BB202_7 Depth=1
	mov	x25, xzr
	mov	x26, x5
	mov	x27, x8
.LBB202_9:                              //   Parent Loop BB202_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x28, x24, x25
	add	x29, x16, x25
	add	x30, x17, x25
	subs	x27, x27, #1
	ldp	q5, q6, [x28, #32]
	add	x28, x0, x25
	ldp	q17, q18, [x29, #32]
	add	x29, x18, x25
	mov	v26.16b, v6.16b
	ldp	q19, q20, [x30, #32]
	add	x30, x26, x21
	fadd	v7.4s, v17.4s, v19.4s
	fsub	v17.4s, v17.4s, v19.4s
	ldp	q21, q25, [x28, #32]
	fadd	v24.4s, v18.4s, v20.4s
	mov	x28, x26
	fsub	v18.4s, v18.4s, v20.4s
	fmla	v26.4s, v0.4s, v24.4s
	ldp	q22, q23, [x29, #32]
	fadd	v27.4s, v6.4s, v24.4s
	add	x29, x23, x25
	fmla	v6.4s, v1.4s, v24.4s
	fsub	v16.4s, v22.4s, v21.4s
	fadd	v21.4s, v22.4s, v21.4s
	fadd	v19.4s, v23.4s, v25.4s
	fsub	v22.4s, v23.4s, v25.4s
	fmul	v20.4s, v16.4s, v2.4s
	mov	v23.16b, v5.16b
	fmla	v26.4s, v1.4s, v19.4s
	fmla	v6.4s, v0.4s, v19.4s
	fadd	v25.4s, v5.4s, v7.4s
	fmla	v5.4s, v1.4s, v7.4s
	fmla	v20.4s, v3.4s, v17.4s
	fmla	v23.4s, v0.4s, v7.4s
	fmul	v28.4s, v22.4s, v2.4s
	fadd	v25.4s, v25.4s, v21.4s
	fmla	v5.4s, v0.4s, v21.4s
	fadd	v29.4s, v26.4s, v20.4s
	fadd	v27.4s, v27.4s, v19.4s
	fmla	v23.4s, v1.4s, v21.4s
	fmla	v28.4s, v3.4s, v18.4s
	fsub	v20.4s, v26.4s, v20.4s
	fneg	v30.4s, v29.4s
	stp	q25, q27, [x29, #32]
	ldr	s25, [x26, #4]
	fsub	v27.4s, v23.4s, v28.4s
	add	x29, x22, x25
	ld1r	{ v31.4s }, [x28], x7
	fmul	v30.4s, v30.4s, v25.s[0]
	fmul	v29.4s, v29.4s, v31.4s
	fneg	v26.4s, v20.4s
	fadd	v23.4s, v23.4s, v28.4s
	fmla	v30.4s, v31.4s, v27.4s
	fmla	v29.4s, v27.4s, v25.s[0]
	fmul	v16.4s, v16.4s, v4.4s
	fmul	v7.4s, v22.4s, v4.4s
	stp	q30, q29, [x29, #32]
	add	x29, x20, x25
	ld1r	{ v25.4s }, [x30], #4
	fmul	v20.4s, v20.4s, v25.4s
	fmla	v16.4s, v2.4s, v17.4s
	fmla	v7.4s, v2.4s, v18.4s
	ldr	s27, [x30]
	fadd	v17.4s, v6.4s, v16.4s
	fsub	v21.4s, v5.4s, v7.4s
	fmul	v26.4s, v26.4s, v27.s[0]
	fmla	v20.4s, v23.4s, v27.s[0]
	fsub	v6.4s, v6.4s, v16.4s
	fneg	v18.4s, v17.4s
	fadd	v5.4s, v5.4s, v7.4s
	fmla	v26.4s, v25.4s, v23.4s
	stp	q26, q20, [x29, #32]
	add	x29, x26, x19
	add	x26, x26, #8
	ld1r	{ v19.4s }, [x29], #4
	fmul	v17.4s, v17.4s, v19.4s
	ldr	s20, [x29]
	add	x29, x6, x25
	fmul	v18.4s, v18.4s, v20.s[0]
	fmla	v17.4s, v21.4s, v20.s[0]
	fmla	v18.4s, v19.4s, v21.4s
	stp	q18, q17, [x29, #32]
	ld1r	{ v16.4s }, [x28], #4
	fneg	v17.4s, v6.4s
	fmul	v6.4s, v6.4s, v16.4s
	ldr	s18, [x28]
	add	x28, x13, x25
	add	x25, x25, #32
	fmul	v7.4s, v17.4s, v18.s[0]
	fmla	v6.4s, v5.4s, v18.s[0]
	fmla	v7.4s, v16.4s, v5.4s
	stp	q7, q6, [x28, #32]
	b.ne	.LBB202_9
	b	.LBB202_6
.LBB202_10:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.Lfunc_end202:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end202-_ZNK9pocketfft6detail5cfftpIfE5pass5ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	d15, d14, [sp, #128]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #144]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #160]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #176]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #208]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 288
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	mov	x8, x4
	subs	x9, x1, #1
	str	x3, [sp, #72]                   // 8-byte Folded Spill
	b.ne	.LBB203_4
// %bb.1:
	cbz	x2, .LBB203_10
// %bb.2:
	mov	w15, #56455
	mov	w16, #42469
	movk	w15, #48739, lsl #16
	mov	w17, #38112
	movk	w16, #48998, lsl #16
	movk	w17, #16249, lsl #16
	mov	w12, #40199
	mov	w18, #9756
	dup	v1.4s, w15
	mov	w15, #9730
	movk	w12, #16159, lsl #16
	dup	v2.4s, w16
	movk	w15, #16094, lsl #16
	dup	v3.4s, w17
	mov	w16, #9730
	mov	w17, #9756
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	movk	w18, #16200, lsl #16
	movk	w16, #48862, lsl #16
	movk	w17, #48968, lsl #16
	add	x14, x2, x2, lsl #1
	add	x11, x2, x2, lsl #2
	lsl	x9, x2, #7
	add	x8, x8, #16
	lsl	x10, x14, #5
	lsl	x11, x11, #5
	dup	v0.4s, w12
	lsl	x12, x2, #6
	lsl	x14, x14, #6
	dup	v5.4s, w15
	lsl	x15, x2, #5
	add	x13, x13, #112
	dup	v4.4s, w18
	dup	v6.4s, w16
	dup	v7.4s, w17
.LBB203_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q16, q17, [x13, #-80]
	add	x16, x8, x15
	add	x17, x8, x14
	subs	x2, x2, #1
	ldp	q18, q19, [x13, #80]
	fadd	v24.4s, v16.4s, v18.4s
	fsub	v18.4s, v16.4s, v18.4s
	ldp	q27, q23, [x13, #48]
	fadd	v22.4s, v17.4s, v19.4s
	fsub	v19.4s, v17.4s, v19.4s
	ldp	q25, q26, [x13, #-48]
	fadd	v20.4s, v25.4s, v27.4s
	fsub	v25.4s, v25.4s, v27.4s
	ldp	q16, q17, [x13, #-112]
	fsub	v21.4s, v26.4s, v23.4s
	fadd	v23.4s, v26.4s, v23.4s
	fmul	v11.4s, v25.4s, v3.4s
	mov	v30.16b, v16.16b
	fmul	v10.4s, v21.4s, v3.4s
	mov	v9.16b, v17.16b
	ldp	q8, q29, [x13, #16]
	fmla	v30.4s, v0.4s, v24.4s
	fmla	v11.4s, v4.4s, v18.4s
	fmla	v10.4s, v4.4s, v19.4s
	fmla	v9.4s, v0.4s, v22.4s
	mov	v12.16b, v17.16b
	fmla	v30.4s, v1.4s, v20.4s
	ldp	q31, q26, [x13, #-16]
	fmla	v9.4s, v1.4s, v23.4s
	add	x13, x13, #224
	fmla	v12.4s, v1.4s, v22.4s
	fadd	v28.4s, v31.4s, v8.4s
	fsub	v27.4s, v26.4s, v29.4s
	fmla	v12.4s, v2.4s, v23.4s
	fadd	v26.4s, v26.4s, v29.4s
	fsub	v29.4s, v31.4s, v8.4s
	fmla	v30.4s, v2.4s, v28.4s
	mov	v31.16b, v16.16b
	fmla	v10.4s, v5.4s, v27.4s
	fmla	v9.4s, v2.4s, v26.4s
	fmla	v12.4s, v0.4s, v26.4s
	fmla	v11.4s, v5.4s, v29.4s
	fmla	v31.4s, v1.4s, v24.4s
	fsub	v8.4s, v30.4s, v10.4s
	fadd	v30.4s, v30.4s, v10.4s
	fadd	v13.4s, v11.4s, v9.4s
	fmul	v10.4s, v25.4s, v6.4s
	fmla	v31.4s, v2.4s, v20.4s
	fsub	v9.4s, v9.4s, v11.4s
	fadd	v11.4s, v16.4s, v24.4s
	fmla	v16.4s, v2.4s, v24.4s
	stp	q8, q13, [x16, #-16]
	add	x16, x8, x12
	fmul	v8.4s, v21.4s, v6.4s
	fmla	v10.4s, v3.4s, v18.4s
	stp	q30, q9, [x17, #-16]
	fmla	v31.4s, v0.4s, v28.4s
	fadd	v9.4s, v17.4s, v22.4s
	fmla	v17.4s, v2.4s, v22.4s
	fmul	v21.4s, v21.4s, v7.4s
	fmla	v16.4s, v0.4s, v20.4s
	fmla	v8.4s, v3.4s, v19.4s
	fmla	v10.4s, v7.4s, v29.4s
	fmul	v22.4s, v25.4s, v7.4s
	add	x17, x8, x10
	fadd	v30.4s, v11.4s, v20.4s
	fmla	v17.4s, v0.4s, v23.4s
	fmla	v21.4s, v5.4s, v19.4s
	fmla	v16.4s, v1.4s, v28.4s
	fmla	v8.4s, v7.4s, v27.4s
	fmla	v22.4s, v5.4s, v18.4s
	fadd	v25.4s, v10.4s, v12.4s
	fmla	v17.4s, v1.4s, v26.4s
	fadd	v18.4s, v30.4s, v28.4s
	fmla	v21.4s, v3.4s, v27.4s
	fsub	v24.4s, v31.4s, v8.4s
	fadd	v19.4s, v31.4s, v8.4s
	fmla	v22.4s, v3.4s, v29.4s
	fsub	v20.4s, v12.4s, v10.4s
	fadd	v23.4s, v9.4s, v23.4s
	stur	q18, [x8, #-16]
	stp	q24, q25, [x16, #-16]
	add	x16, x8, x11
	fadd	v24.4s, v22.4s, v17.4s
	fsub	v17.4s, v17.4s, v22.4s
	stp	q19, q20, [x16, #-16]
	add	x16, x8, x9
	fsub	v19.4s, v16.4s, v21.4s
	fadd	v18.4s, v23.4s, v26.4s
	fadd	v16.4s, v16.4s, v21.4s
	stp	q19, q24, [x17, #-16]
	str	q18, [x8], #32
	stp	q16, q17, [x16, #-16]
	b.ne	.LBB203_3
	b	.LBB203_10
.LBB203_4:
	str	x9, [sp, #24]                   // 8-byte Folded Spill
	cbz	x2, .LBB203_10
// %bb.5:
	lsl	x11, x2, #1
	lsl	x12, x2, #2
	ldr	x13, [sp, #24]                  // 8-byte Folded Reload
	mov	w14, #160
	mul	x10, x2, x1
	mov	x23, x5
	str	x11, [sp, #64]                  // 8-byte Folded Spill
	add	x11, x11, x2
	lsl	x18, x11, #1
	mov	w5, #96
	add	x15, x8, x10, lsl #7
	add	x27, x8, x10, lsl #6
	stp	x12, x11, [sp, #48]             // 16-byte Folded Spill
	add	x11, x12, x2
	ldr	x12, [sp, #72]                  // 8-byte Folded Reload
	madd	x21, x10, x5, x8
	add	x29, x8, x10, lsl #5
	lsl	x16, x1, #5
	stp	x11, x18, [sp, #32]             // 16-byte Folded Spill
	mov	w11, #224
	add	x3, x12, x13, lsl #6
	madd	x4, x13, x14, x12
	add	x6, x3, #64
	mov	w3, #24
	mul	x17, x1, x11
	mov	w11, #192
	mul	x3, x1, x3
	add	x7, x4, #160
	madd	x4, x13, x5, x12
	add	x20, x12, x13, lsl #7
	sub	x22, x3, #24
	mov	w3, #40
	add	x13, x23, #4
	madd	x23, x10, x14, x8
	mul	x14, x1, x3
	mov	w3, #56455
	madd	x0, x1, x11, x12
	movk	w3, #48739, lsl #16
	sub	x28, x14, #40
	mov	w14, #40199
	madd	x30, x10, x11, x8
	mov	w10, #42469
	mov	w11, #38112
	movk	w14, #16159, lsl #16
	movk	w10, #48998, lsl #16
	movk	w11, #16249, lsl #16
	dup	v1.4s, w3
	mov	w3, #9730
	dup	v11.4s, w14
	mov	w14, #9756
	movk	w3, #16094, lsl #16
	dup	v2.4s, w10
	dup	v3.4s, w11
	mov	w10, #9730
	mov	w11, #9756
	movk	w14, #16200, lsl #16
	movk	w10, #48862, lsl #16
	movk	w11, #48968, lsl #16
	add	x19, x4, #96
	lsl	x4, x1, #4
	mov	x9, xzr
	add	x18, x12, x16
	add	x20, x20, #128
	sub	x24, x4, #16
	sub	x25, x16, #32
	lsl	x26, x1, #3
	dup	v15.4s, w3
	mov	x4, x8
	mov	x3, x12
	dup	v4.4s, w14
	dup	v7.4s, w10
	dup	v0.4s, w11
	str	x13, [sp, #16]                  // 8-byte Folded Spill
	stp	q15, q11, [sp, #96]             // 32-byte Folded Spill
	str	q4, [sp, #80]                   // 16-byte Folded Spill
	b	.LBB203_7
.LBB203_6:                              //   in Loop: Header=BB203_7 Depth=1
	add	x9, x9, #1
	add	x15, x15, x16
	add	x3, x3, x17
	add	x18, x18, x17
	add	x0, x0, x17
	add	x6, x6, x17
	add	x7, x7, x17
	add	x19, x19, x17
	add	x20, x20, x17
	add	x4, x4, x16
	add	x21, x21, x16
	add	x23, x23, x16
	add	x27, x27, x16
	add	x29, x29, x16
	add	x30, x30, x16
	cmp	x9, x2
	b.eq	.LBB203_10
.LBB203_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB203_9 Depth 2
	lsl	x10, x9, #3
	ldr	x13, [sp, #72]                  // 8-byte Folded Reload
	sub	x10, x10, x9
	ldr	q5, [sp, #96]                   // 16-byte Folded Reload
	add	x11, x10, #6
	add	x12, x10, #2
	mul	x14, x10, x1
	cmp	x1, #2
	mul	x11, x11, x1
	mul	x12, x12, x1
	add	x5, x13, x14, lsl #5
	add	x14, x1, x14
	add	x11, x13, x11, lsl #5
	add	x14, x13, x14, lsl #5
	add	x12, x13, x12, lsl #5
	ldp	q16, q17, [x5]
	ldp	q18, q19, [x14]
	add	x14, x10, #5
	mul	x14, x14, x1
	ldp	q20, q21, [x11]
	add	x11, x10, #3
	add	x10, x10, #4
	mul	x11, x11, x1
	mul	x10, x10, x1
	fadd	v28.4s, v18.4s, v20.4s
	ldp	q24, q26, [x12]
	add	x12, x13, x14, lsl #5
	add	x11, x13, x11, lsl #5
	add	x10, x13, x10, lsl #5
	fsub	v18.4s, v18.4s, v20.4s
	fadd	v27.4s, v19.4s, v21.4s
	fsub	v19.4s, v19.4s, v21.4s
	ldp	q20, q29, [x12]
	fadd	v10.4s, v17.4s, v27.4s
	fadd	v22.4s, v24.4s, v20.4s
	fsub	v25.4s, v24.4s, v20.4s
	ldp	q30, q31, [x11]
	fadd	v23.4s, v26.4s, v29.4s
	fsub	v26.4s, v26.4s, v29.4s
	fadd	v29.4s, v16.4s, v28.4s
	fmul	v12.4s, v25.4s, v3.4s
	fadd	v10.4s, v10.4s, v23.4s
	ldp	q8, q9, [x10]
	fadd	v29.4s, v29.4s, v22.4s
	mul	x10, x9, x1
	fmla	v12.4s, v4.4s, v18.4s
	fmul	v14.4s, v25.4s, v7.4s
	fadd	v20.4s, v30.4s, v8.4s
	add	x10, x8, x10, lsl #5
	fsub	v24.4s, v30.4s, v8.4s
	mov	v30.16b, v16.16b
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	mov	v8.16b, v17.16b
	fmla	v14.4s, v3.4s, v18.4s
	fadd	v21.4s, v31.4s, v9.4s
	fadd	v13.4s, v29.4s, v20.4s
	fmla	v12.4s, v15.4s, v24.4s
	fmla	v30.4s, v11.4s, v28.4s
	add	x11, x9, x11
	fmla	v8.4s, v11.4s, v27.4s
	fmla	v14.4s, v0.4s, v24.4s
	fmul	v11.4s, v26.4s, v3.4s
	fadd	v10.4s, v10.4s, v21.4s
	fmla	v30.4s, v1.4s, v22.4s
	fsub	v29.4s, v31.4s, v9.4s
	fmla	v8.4s, v1.4s, v23.4s
	fmla	v11.4s, v4.4s, v19.4s
	stp	q13, q10, [x10]
	add	x10, x9, x2
	fmla	v30.4s, v2.4s, v20.4s
	fmla	v8.4s, v2.4s, v21.4s
	mul	x10, x10, x1
	fmla	v11.4s, v15.4s, v29.4s
	mov	v31.16b, v16.16b
	fmla	v16.4s, v2.4s, v28.4s
	mov	v9.16b, v17.16b
	add	x10, x8, x10, lsl #5
	fadd	v13.4s, v12.4s, v8.4s
	fmla	v17.4s, v2.4s, v27.4s
	fsub	v10.4s, v30.4s, v11.4s
	fmla	v31.4s, v1.4s, v28.4s
	fmla	v9.4s, v1.4s, v27.4s
	fmul	v15.4s, v26.4s, v7.4s
	stp	q10, q13, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #64]                  // 8-byte Folded Reload
	fmla	v31.4s, v2.4s, v22.4s
	fmla	v9.4s, v2.4s, v23.4s
	fmla	v15.4s, v3.4s, v19.4s
	add	x10, x8, x10, lsl #5
	fadd	v30.4s, v30.4s, v11.4s
	ldr	q11, [sp, #112]                 // 16-byte Folded Reload
	fsub	v8.4s, v8.4s, v12.4s
	add	x11, x9, x11
	fmul	v26.4s, v26.4s, v0.4s
	fmla	v31.4s, v11.4s, v20.4s
	fmla	v9.4s, v11.4s, v21.4s
	fmla	v15.4s, v0.4s, v29.4s
	fmla	v16.4s, v11.4s, v22.4s
	stp	q30, q8, [x10]
	mul	x10, x11, x1
	ldr	x11, [sp, #32]                  // 8-byte Folded Reload
	fmla	v26.4s, v5.4s, v19.4s
	fadd	v8.4s, v14.4s, v9.4s
	fmla	v17.4s, v11.4s, v23.4s
	fsub	v30.4s, v31.4s, v15.4s
	add	x10, x8, x10, lsl #5
	add	x11, x9, x11
	fmla	v16.4s, v1.4s, v20.4s
	fmul	v25.4s, v25.4s, v0.4s
	fmla	v26.4s, v3.4s, v29.4s
	mul	x11, x11, x1
	fmla	v17.4s, v1.4s, v21.4s
	fadd	v19.4s, v31.4s, v15.4s
	ldr	q15, [sp, #96]                  // 16-byte Folded Reload
	stp	q30, q8, [x10]
	add	x10, x8, x11, lsl #5
	ldp	x12, x11, [sp, #48]             // 16-byte Folded Reload
	fmla	v25.4s, v15.4s, v18.4s
	fsub	v18.4s, v9.4s, v14.4s
	add	x12, x9, x12
	add	x11, x9, x11
	fmla	v25.4s, v3.4s, v24.4s
	stp	q19, q18, [x10]
	mul	x10, x12, x1
	mul	x11, x11, x1
	fsub	v18.4s, v16.4s, v26.4s
	fadd	v19.4s, v25.4s, v17.4s
	add	x10, x8, x10, lsl #5
	fadd	v16.4s, v16.4s, v26.4s
	add	x11, x8, x11, lsl #5
	fsub	v17.4s, v17.4s, v25.4s
	stp	q18, q19, [x11]
	stp	q16, q17, [x10]
	b.lo	.LBB203_6
// %bb.8:                               //   in Loop: Header=BB203_7 Depth=1
	ldp	x14, x10, [sp, #16]             // 16-byte Folded Reload
	mov	x5, xzr
.LBB203_9:                              //   Parent Loop BB203_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x11, x18, x5
	add	x12, x0, x5
	add	x13, x3, x5
	subs	x10, x10, #1
	mov	v5.16b, v1.16b
	ldp	q19, q20, [x11, #32]
	add	x11, x6, x5
	ldp	q21, q23, [x12, #32]
	add	x12, x7, x5
	fadd	v18.4s, v19.4s, v21.4s
	fsub	v21.4s, v19.4s, v21.4s
	ldp	q16, q17, [x13, #32]
	fadd	v22.4s, v20.4s, v23.4s
	add	x13, x14, x26
	fsub	v19.4s, v20.4s, v23.4s
	mov	v10.16b, v16.16b
	ldp	q24, q25, [x11, #32]
	add	x11, x19, x5
	mov	v8.16b, v17.16b
	fmla	v10.4s, v11.4s, v18.4s
	ldp	q26, q27, [x12, #32]
	add	x12, x20, x5
	fmla	v8.4s, v11.4s, v22.4s
	fadd	v20.4s, v24.4s, v26.4s
	fsub	v24.4s, v24.4s, v26.4s
	ldp	q29, q30, [x11, #32]
	fadd	v23.4s, v25.4s, v27.4s
	mov	x11, x14
	fsub	v27.4s, v25.4s, v27.4s
	fmla	v10.4s, v1.4s, v20.4s
	fmul	v9.4s, v24.4s, v3.4s
	fmla	v8.4s, v1.4s, v23.4s
	ldp	q26, q31, [x12, #32]
	fmla	v9.4s, v4.4s, v21.4s
	add	x12, x4, x5
	fmul	v11.4s, v27.4s, v3.4s
	fadd	v25.4s, v29.4s, v26.4s
	fsub	v29.4s, v29.4s, v26.4s
	fadd	v28.4s, v30.4s, v31.4s
	fmla	v11.4s, v4.4s, v19.4s
	fsub	v26.4s, v30.4s, v31.4s
	fadd	v30.4s, v16.4s, v18.4s
	fmla	v10.4s, v2.4s, v25.4s
	fadd	v31.4s, v17.4s, v22.4s
	fmla	v9.4s, v15.4s, v29.4s
	fmla	v8.4s, v2.4s, v28.4s
	fmla	v11.4s, v15.4s, v26.4s
	fadd	v30.4s, v30.4s, v20.4s
	fadd	v31.4s, v31.4s, v23.4s
	fadd	v12.4s, v9.4s, v8.4s
	fsub	v14.4s, v10.4s, v11.4s
	fadd	v30.4s, v30.4s, v25.4s
	fadd	v31.4s, v31.4s, v28.4s
	fneg	v13.4s, v12.4s
	fmul	v4.4s, v24.4s, v7.4s
	fsub	v9.4s, v8.4s, v9.4s
	stp	q30, q31, [x12, #32]
	ldur	s30, [x14, #-4]
	mov	v31.16b, v17.16b
	add	x12, x14, x28
	ld1r	{ v15.4s }, [x11], x22
	fmul	v13.4s, v15.4s, v13.4s
	fmul	v12.4s, v12.4s, v30.s[0]
	fmla	v4.4s, v3.4s, v21.4s
	fmla	v17.4s, v2.4s, v22.4s
	fmla	v31.4s, v1.4s, v22.4s
	fmul	v8.4s, v27.4s, v7.4s
	fmla	v13.4s, v14.4s, v30.s[0]
	fmla	v12.4s, v15.4s, v14.4s
	mov	v30.16b, v16.16b
	fmla	v4.4s, v0.4s, v29.4s
	fmla	v31.4s, v2.4s, v23.4s
	fmla	v16.4s, v2.4s, v18.4s
	ldp	s14, s15, [x12, #-4]
	fneg	v6.4s, v9.4s
	fmla	v8.4s, v3.4s, v19.4s
	fmla	v30.4s, v1.4s, v18.4s
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	fadd	v10.4s, v10.4s, v11.4s
	add	x12, x29, x5
	fmul	v9.4s, v9.4s, v14.s[0]
	fmla	v31.4s, v1.4s, v28.4s
	fmul	v6.4s, v6.4s, v15.s[0]
	fmla	v30.4s, v2.4s, v20.4s
	ldr	q1, [sp, #112]                  // 16-byte Folded Reload
	fmla	v8.4s, v0.4s, v26.4s
	stp	q13, q12, [x12, #32]
	fmla	v9.4s, v10.4s, v15.s[0]
	add	x12, x30, x5
	fadd	v11.4s, v4.4s, v31.4s
	fmla	v6.4s, v10.4s, v14.s[0]
	fmla	v30.4s, v1.4s, v25.4s
	ldp	s13, s10, [x13, #-12]
	ldp	q15, q1, [sp, #96]              // 32-byte Folded Reload
	fneg	v12.4s, v11.4s
	stp	q6, q9, [x12, #32]
	fmul	v24.4s, v24.4s, v0.4s
	add	x12, x27, x5
	fsub	v14.4s, v30.4s, v8.4s
	add	x13, x14, x25
	fmul	v11.4s, v11.4s, v13.s[0]
	fmul	v22.4s, v12.4s, v10.s[0]
	fmla	v17.4s, v1.4s, v23.4s
	fmla	v24.4s, v15.4s, v21.4s
	fsub	v4.4s, v31.4s, v4.4s
	fmla	v11.4s, v14.4s, v10.s[0]
	fmla	v22.4s, v14.4s, v13.s[0]
	fmla	v17.4s, v5.4s, v28.4s
	fmla	v24.4s, v3.4s, v29.4s
	fmul	v6.4s, v27.4s, v0.4s
	fneg	v21.4s, v4.4s
	stp	q22, q11, [x12, #32]
	ldr	q11, [sp, #112]                 // 16-byte Folded Reload
	ldp	s22, s18, [x13, #-4]
	fmla	v6.4s, v15.4s, v19.4s
	add	x12, x14, x24
	fmla	v16.4s, v11.4s, v20.4s
	add	x14, x14, #8
	fadd	v19.4s, v24.4s, v17.4s
	fsub	v17.4s, v17.4s, v24.4s
	fadd	v20.4s, v30.4s, v8.4s
	fmla	v6.4s, v3.4s, v26.4s
	fmul	v21.4s, v21.4s, v18.s[0]
	fmla	v16.4s, v5.4s, v25.4s
	fneg	v23.4s, v19.4s
	fmul	v4.4s, v4.4s, v22.s[0]
	ldp	s25, s24, [x12, #-4]
	ldp	s26, s28, [x11, #-4]
	fneg	v27.4s, v17.4s
	fmla	v21.4s, v20.4s, v22.s[0]
	fsub	v22.4s, v16.4s, v6.4s
	fmla	v4.4s, v20.4s, v18.s[0]
	fmul	v23.4s, v23.4s, v24.s[0]
	add	x11, x23, x5
	fmul	v19.4s, v19.4s, v25.s[0]
	fmul	v17.4s, v17.4s, v26.s[0]
	fadd	v6.4s, v16.4s, v6.4s
	fmul	v16.4s, v27.4s, v28.s[0]
	mov	v1.16b, v5.16b
	add	x12, x21, x5
	fmla	v23.4s, v22.4s, v25.s[0]
	stp	q21, q4, [x11, #32]
	fmla	v19.4s, v22.4s, v24.s[0]
	ldr	q4, [sp, #80]                   // 16-byte Folded Reload
	fmla	v16.4s, v6.4s, v26.s[0]
	fmla	v17.4s, v6.4s, v28.s[0]
	add	x11, x15, x5
	add	x5, x5, #32
	stp	q23, q19, [x12, #32]
	stp	q16, q17, [x11, #32]
	b.ne	.LBB203_9
	b	.LBB203_6
.LBB203_10:
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #208]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #192]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #176]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #160]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #144]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #128]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end203:
	.size	_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end203-_ZNK9pocketfft6detail5cfftpIfE5pass7ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE // -- Begin function _ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE,@function
_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE: // @_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_startproc
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #992
	.cfi_def_cfa_offset 1152
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	subs	x8, x1, #1
	stp	x4, x3, [sp, #208]              // 16-byte Folded Spill
	b.ne	.LBB204_4
// %bb.1:
	cbz	x2, .LBB204_10
// %bb.2:
	mov	w16, #23652
	mov	w0, #45383
	movk	w16, #16215, lsl #16
	movk	w0, #16084, lsl #16
	mov	w1, #47867
	mov	w3, #42228
	movk	w1, #15889, lsl #16
	movk	w3, #16167, lsl #16
	dup	v1.4s, w16
	mov	w16, #41301
	dup	v0.4s, w0
	movk	w16, #16245, lsl #16
	mov	w0, #56740
	mov	w4, #16192
	str	q0, [sp, #928]                  // 16-byte Folded Spill
	dup	v0.4s, w1
	movk	w0, #16232, lsl #16
	movk	w4, #16016, lsl #16
	stp	q0, q1, [sp, #464]              // 32-byte Folded Spill
	dup	v1.4s, w3
	dup	v0.4s, w16
	mov	w16, #26480
	movk	w16, #16138, lsl #16
	mov	w1, #30926
	stp	q0, q1, [sp, #432]              // 32-byte Folded Spill
	dup	v1.4s, w0
	mov	w0, #25840
	mov	w3, #16192
	movk	w0, #16253, lsl #16
	movk	w1, #16193, lsl #16
	movk	w3, #48784, lsl #16
	dup	v2.4s, w16
	ldp	x9, x14, [sp, #208]             // 16-byte Folded Reload
	dup	v0.4s, w0
	mov	w0, #25840
	movk	w0, #49021, lsl #16
	dup	v3.4s, w1
	str	q0, [sp, #944]                  // 16-byte Folded Spill
	dup	v0.4s, w4
	mov	w1, #26480
	mov	w11, #224
	stp	q0, q2, [sp, #624]              // 32-byte Folded Spill
	dup	v0.4s, w3
	movk	w1, #48906, lsl #16
	mov	w3, #56740
	stp	q0, q1, [sp, #512]              // 32-byte Folded Spill
	dup	v0.4s, w0
	ldp	q8, q30, [sp, #464]             // 32-byte Folded Reload
	movk	w3, #49000, lsl #16
	add	x15, x2, x2, lsl #1
	add	x18, x2, x2, lsl #2
	mul	x11, x2, x11
	add	x17, x2, x2, lsl #3
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	dup	v0.4s, w1
	lsl	x8, x15, #6
	add	x9, x9, #16
	lsl	x10, x18, #5
	lsl	x12, x2, #7
	lsl	x13, x2, #8
	add	x14, x14, #176
	lsl	x15, x15, #5
	lsl	x16, x17, #5
	lsl	x17, x2, #6
	lsl	x18, x18, #6
	lsl	x0, x2, #5
	str	q0, [sp, #608]                  // 16-byte Folded Spill
	dup	v0.4s, w3
	stp	q0, q3, [sp, #400]              // 32-byte Folded Spill
.LBB204_3:                              // =>This Inner Loop Header: Depth=1
	ldp	q5, q6, [x14, #-144]
	add	x1, x9, x0
	add	x3, x9, x17
	subs	x2, x2, #1
	ldp	q18, q19, [x14, #144]
	fadd	v3.4s, v5.4s, v18.4s
	fsub	v28.4s, v5.4s, v18.4s
	ldp	q25, q20, [x14, #112]
	fadd	v10.4s, v6.4s, v19.4s
	fsub	v1.4s, v6.4s, v19.4s
	stp	q3, q10, [sp, #736]             // 32-byte Folded Spill
	fmul	v14.4s, v3.4s, v30.4s
	ldp	q26, q5, [x14, #-112]
	fadd	v29.4s, v26.4s, v25.4s
	fsub	v25.4s, v26.4s, v25.4s
	ldp	q18, q6, [x14, #80]
	fadd	v11.4s, v5.4s, v20.4s
	fsub	v22.4s, v5.4s, v20.4s
	stp	q29, q28, [sp, #656]            // 32-byte Folded Spill
	str	q25, [sp, #768]                 // 16-byte Folded Spill
	stp	q1, q11, [sp, #704]             // 32-byte Folded Spill
	ldp	q19, q26, [x14, #-80]
	fadd	v2.4s, v19.4s, v18.4s
	fsub	v16.4s, v19.4s, v18.4s
	ldp	q20, q5, [x14, #48]
	fadd	v23.4s, v26.4s, v6.4s
	fsub	v6.4s, v26.4s, v6.4s
	str	q2, [sp, #688]                  // 16-byte Folded Spill
	stp	q16, q22, [sp, #960]            // 32-byte Folded Spill
	ldp	q12, q13, [x14, #-48]
	fadd	v19.4s, v12.4s, v20.4s
	fsub	v17.4s, v12.4s, v20.4s
	ldp	q3, q0, [x14, #-176]
	fmul	v20.4s, v10.4s, v30.4s
	fadd	v16.4s, v13.4s, v5.4s
	stp	q19, q23, [sp, #848]            // 32-byte Folded Spill
	fsub	v12.4s, v13.4s, v5.4s
	fadd	v14.4s, v3.4s, v14.4s
	mov	v5.16b, v2.16b
	ldr	q9, [sp, #928]                  // 16-byte Folded Reload
	stp	q0, q3, [sp, #896]              // 32-byte Folded Spill
	ldr	q24, [sp, #528]                 // 16-byte Folded Reload
	stp	q17, q16, [sp, #816]            // 32-byte Folded Spill
	fadd	v3.4s, v0.4s, v20.4s
	ldr	q18, [sp, #640]                 // 16-byte Folded Reload
	fmul	v15.4s, v29.4s, v9.4s
	ldp	q20, q31, [x14, #16]
	fmul	v0.4s, v22.4s, v24.4s
	ldr	q26, [sp, #448]                 // 16-byte Folded Reload
	fmul	v21.4s, v11.4s, v9.4s
	fmul	v27.4s, v25.4s, v24.4s
	str	q12, [sp, #880]                 // 16-byte Folded Spill
	ldp	q7, q17, [x14, #-16]
	fadd	v15.4s, v14.4s, v15.4s
	fmla	v0.4s, v18.4s, v1.4s
	fmul	v22.4s, v2.4s, v8.4s
	add	x14, x14, #352
	fadd	v21.4s, v3.4s, v21.4s
	fmla	v27.4s, v18.4s, v28.4s
	fadd	v4.4s, v7.4s, v20.4s
	fmul	v2.4s, v23.4s, v8.4s
	ldr	q3, [sp, #944]                  // 16-byte Folded Reload
	ldp	q25, q18, [sp, #416]            // 32-byte Folded Reload
	fsub	v15.4s, v15.4s, v22.4s
	stp	q4, q6, [sp, #784]              // 32-byte Folded Spill
	fmul	v23.4s, v19.4s, v26.4s
	fmla	v0.4s, v3.4s, v6.4s
	fsub	v14.4s, v17.4s, v31.4s
	mov	v22.16b, v6.16b
	fsub	v6.4s, v21.4s, v2.4s
	fmul	v21.4s, v16.4s, v26.4s
	fmla	v0.4s, v25.4s, v12.4s
	fsub	v23.4s, v15.4s, v23.4s
	ldr	q12, [sp, #736]                 // 16-byte Folded Reload
	mov	v16.16b, v28.16b
	fmul	v28.4s, v4.4s, v18.4s
	fsub	v19.4s, v7.4s, v20.4s
	ldr	q7, [sp, #624]                  // 16-byte Folded Reload
	ldr	q20, [sp, #960]                 // 16-byte Folded Reload
	fadd	v2.4s, v17.4s, v31.4s
	ldr	q31, [sp, #912]                 // 16-byte Folded Reload
	fsub	v15.4s, v23.4s, v28.4s
	fmla	v0.4s, v7.4s, v14.4s
	fmul	v28.4s, v12.4s, v9.4s
	fmla	v27.4s, v3.4s, v20.4s
	fmul	v17.4s, v10.4s, v9.4s
	stp	q14, q19, [sp, #576]            // 32-byte Folded Spill
	mov	v13.16b, v1.16b
	ldr	q1, [sp, #816]                  // 16-byte Folded Reload
	fsub	v23.4s, v15.4s, v0.4s
	fadd	v31.4s, v31.4s, v28.4s
	ldr	q28, [sp, #896]                 // 16-byte Folded Reload
	fsub	v6.4s, v6.4s, v21.4s
	fmla	v27.4s, v25.4s, v1.4s
	fmul	v21.4s, v2.4s, v18.4s
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #768]                  // 16-byte Folded Reload
	fadd	v17.4s, v28.4s, v17.4s
	stur	q23, [x1, #-16]
	fmul	v28.4s, v29.4s, v26.4s
	fmla	v27.4s, v7.4s, v19.4s
	fmul	v23.4s, v2.4s, v25.4s
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fmul	v29.4s, v11.4s, v26.4s
	str	q9, [sp, #560]                  // 16-byte Folded Spill
	fsub	v3.4s, v6.4s, v21.4s
	fsub	v7.4s, v31.4s, v28.4s
	fmul	v28.4s, v2.4s, v25.4s
	fmla	v23.4s, v24.4s, v16.4s
	ldp	q31, q4, [sp, #848]             // 32-byte Folded Reload
	fsub	v17.4s, v17.4s, v29.4s
	fmul	v21.4s, v5.4s, v18.4s
	fmla	v28.4s, v24.4s, v13.4s
	fadd	v0.4s, v15.4s, v0.4s
	fsub	v5.4s, v3.4s, v27.4s
	ldp	q10, q24, [sp, #496]            // 32-byte Folded Reload
	fmul	v29.4s, v4.4s, v18.4s
	fsub	v7.4s, v7.4s, v21.4s
	fmul	v21.4s, v31.4s, v8.4s
	mov	v11.16b, v19.16b
	fsub	v17.4s, v17.4s, v29.4s
	ldr	q13, [sp, #832]                 // 16-byte Folded Reload
	fmla	v23.4s, v24.4s, v20.4s
	fmla	v28.4s, v24.4s, v22.4s
	ldr	q2, [sp, #784]                  // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v21.4s
	fmul	v29.4s, v13.4s, v8.4s
	fmla	v23.4s, v10.4s, v1.4s
	ldr	q1, [sp, #880]                  // 16-byte Folded Reload
	fmul	v20.4s, v9.4s, v30.4s
	fadd	v21.4s, v27.4s, v3.4s
	ldr	q27, [sp, #656]                 // 16-byte Folded Reload
	fsub	v17.4s, v17.4s, v29.4s
	fmla	v28.4s, v10.4s, v1.4s
	fmul	v29.4s, v2.4s, v30.4s
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	ldp	q16, q11, [sp, #896]            // 32-byte Folded Reload
	str	q21, [x1]
	add	x1, x9, x18
	fmla	v28.4s, v1.4s, v14.4s
	fmla	v23.4s, v1.4s, v19.4s
	fadd	v6.4s, v7.4s, v29.4s
	fadd	v7.4s, v17.4s, v20.4s
	stp	q0, q5, [x1, #-16]
	fmul	v5.4s, v12.4s, v8.4s
	add	x1, x9, x16
	ldp	q19, q29, [sp, #752]            // 32-byte Folded Reload
	fsub	v0.4s, v6.4s, v28.4s
	ldr	q1, [sp, #928]                  // 16-byte Folded Reload
	fadd	v17.4s, v23.4s, v7.4s
	fsub	v5.4s, v11.4s, v5.4s
	ldr	q20, [sp, #400]                 // 16-byte Folded Reload
	mov	v3.16b, v12.16b
	ldr	q12, [sp, #720]                 // 16-byte Folded Reload
	fadd	v6.4s, v6.4s, v28.4s
	ldr	q28, [sp, #688]                 // 16-byte Folded Reload
	stp	q0, q17, [x3, #-16]
	fmul	v0.4s, v19.4s, v8.4s
	fmul	v17.4s, v27.4s, v18.4s
	fmul	v21.4s, v12.4s, v18.4s
	fsub	v7.4s, v7.4s, v23.4s
	fsub	v0.4s, v16.4s, v0.4s
	fsub	v5.4s, v5.4s, v17.4s
	fmul	v17.4s, v28.4s, v1.4s
	stp	q6, q7, [x1, #-16]
	add	x1, x9, x15
	fsub	v0.4s, v0.4s, v21.4s
	fmul	v6.4s, v4.4s, v1.4s
	fadd	v5.4s, v5.4s, v17.4s
	fmul	v17.4s, v31.4s, v30.4s
	ldr	q31, [sp, #704]                 // 16-byte Folded Reload
	mov	v22.16b, v4.16b
	ldr	q4, [sp, #976]                  // 16-byte Folded Reload
	fadd	v1.4s, v0.4s, v6.4s
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fmul	v6.4s, v29.4s, v24.4s
	fadd	v5.4s, v5.4s, v17.4s
	fmul	v17.4s, v4.4s, v24.4s
	ldr	q24, [sp, #672]                 // 16-byte Folded Reload
	fmul	v21.4s, v2.4s, v26.4s
	fmul	v7.4s, v13.4s, v30.4s
	fmla	v6.4s, v0.4s, v24.4s
	fmla	v17.4s, v0.4s, v31.4s
	fsub	v0.4s, v5.4s, v21.4s
	ldr	q5, [sp, #880]                  // 16-byte Folded Reload
	fmul	v21.4s, v3.4s, v26.4s
	ldr	q3, [sp, #960]                  // 16-byte Folded Reload
	fadd	v1.4s, v1.4s, v7.4s
	fmul	v7.4s, v9.4s, v26.4s
	fmul	v23.4s, v27.4s, v8.4s
	str	q0, [sp, #544]                  // 16-byte Folded Spill
	fsub	v21.4s, v11.4s, v21.4s
	ldr	q0, [sp, #800]                  // 16-byte Folded Reload
	fmla	v6.4s, v20.4s, v3.4s
	fsub	v9.4s, v1.4s, v7.4s
	ldr	q1, [sp, #640]                  // 16-byte Folded Reload
	fmla	v17.4s, v20.4s, v0.4s
	fmul	v7.4s, v19.4s, v26.4s
	ldr	q19, [sp, #816]                 // 16-byte Folded Reload
	fsub	v21.4s, v21.4s, v23.4s
	fmul	v23.4s, v28.4s, v30.4s
	mov	v15.16b, v2.16b
	fmla	v6.4s, v1.4s, v19.4s
	ldp	q2, q13, [sp, #576]             // 32-byte Folded Reload
	fmla	v17.4s, v1.4s, v5.4s
	fsub	v7.4s, v16.4s, v7.4s
	fmul	v27.4s, v12.4s, v8.4s
	fadd	v21.4s, v21.4s, v23.4s
	fmul	v23.4s, v4.4s, v10.4s
	fmla	v17.4s, v25.4s, v2.4s
	fmul	v28.4s, v29.4s, v10.4s
	fmla	v6.4s, v25.4s, v13.4s
	ldp	q10, q4, [sp, #832]             // 32-byte Folded Reload
	mov	v14.16b, v1.16b
	fsub	v7.4s, v7.4s, v27.4s
	fmla	v23.4s, v25.4s, v31.4s
	fmul	v27.4s, v22.4s, v30.4s
	fmla	v28.4s, v25.4s, v24.4s
	mov	v12.16b, v29.16b
	fmul	v24.4s, v10.4s, v18.4s
	ldr	q1, [sp, #544]                  // 16-byte Folded Reload
	fmla	v23.4s, v14.4s, v0.4s
	fadd	v7.4s, v7.4s, v27.4s
	fmla	v28.4s, v14.4s, v3.4s
	fadd	v27.4s, v6.4s, v9.4s
	ldr	q22, [sp, #928]                 // 16-byte Folded Reload
	fsub	v29.4s, v1.4s, v17.4s
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	fmul	v31.4s, v4.4s, v18.4s
	ldr	q14, [sp, #560]                 // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v24.4s
	ldr	q3, [sp, #688]                  // 16-byte Folded Reload
	fmul	v24.4s, v15.4s, v22.4s
	fmla	v23.4s, v0.4s, v5.4s
	stp	q29, q27, [x1, #-16]
	fmla	v28.4s, v0.4s, v19.4s
	fsub	v21.4s, v21.4s, v31.4s
	add	x1, x9, x13
	fmul	v27.4s, v14.4s, v22.4s
	mov	v31.16b, v5.16b
	fmla	v23.4s, v20.4s, v2.4s
	mov	v15.16b, v0.16b
	fmla	v28.4s, v20.4s, v13.4s
	fadd	v5.4s, v1.4s, v17.4s
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	fsub	v0.4s, v9.4s, v6.4s
	fadd	v6.4s, v21.4s, v24.4s
	ldr	q21, [sp, #736]                 // 16-byte Folded Reload
	fadd	v7.4s, v7.4s, v27.4s
	ldr	q24, [sp, #656]                 // 16-byte Folded Reload
	mov	v29.16b, v19.16b
	stp	q5, q0, [x1, #-16]
	add	x1, x9, x12
	fsub	v0.4s, v6.4s, v23.4s
	fadd	v5.4s, v28.4s, v7.4s
	fadd	v17.4s, v11.4s, v21.4s
	fmul	v21.4s, v21.4s, v18.4s
	fmul	v19.4s, v24.4s, v30.4s
	stp	q0, q5, [x1, #-16]
	add	x1, x9, x11
	fadd	v0.4s, v17.4s, v24.4s
	fsub	v5.4s, v11.4s, v21.4s
	ldr	q21, [sp, #752]                 // 16-byte Folded Reload
	mov	v9.16b, v2.16b
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fadd	v6.4s, v6.4s, v23.4s
	fmul	v17.4s, v21.4s, v18.4s
	fadd	v21.4s, v16.4s, v21.4s
	fadd	v5.4s, v5.4s, v19.4s
	fmul	v19.4s, v12.4s, v1.4s
	fsub	v17.4s, v16.4s, v17.4s
	ldr	q16, [sp, #720]                 // 16-byte Folded Reload
	fmul	v23.4s, v2.4s, v1.4s
	ldr	q1, [sp, #672]                  // 16-byte Folded Reload
	fadd	v0.4s, v0.4s, v3.4s
	fmul	v18.4s, v16.4s, v30.4s
	fmla	v19.4s, v15.4s, v1.4s
	ldr	q1, [sp, #704]                  // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v28.4s
	fadd	v21.4s, v21.4s, v16.4s
	fadd	v17.4s, v17.4s, v18.4s
	fmla	v23.4s, v15.4s, v1.4s
	fmul	v18.4s, v3.4s, v26.4s
	ldr	q3, [sp, #864]                  // 16-byte Folded Reload
	ldp	q16, q1, [sp, #944]             // 32-byte Folded Reload
	stp	q6, q7, [x1, #-16]
	fadd	v0.4s, v0.4s, v4.4s
	add	x1, x9, x10
	fmul	v24.4s, v3.4s, v26.4s
	fmla	v19.4s, v25.4s, v1.4s
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	fsub	v5.4s, v5.4s, v18.4s
	fmul	v18.4s, v10.4s, v22.4s
	fsub	v6.4s, v17.4s, v24.4s
	fmla	v23.4s, v25.4s, v1.4s
	fmul	v17.4s, v4.4s, v22.4s
	ldr	q1, [sp, #784]                  // 16-byte Folded Reload
	fmla	v19.4s, v20.4s, v29.4s
	mov	v2.16b, v4.16b
	fmul	v7.4s, v1.4s, v8.4s
	fmla	v23.4s, v20.4s, v31.4s
	fadd	v5.4s, v5.4s, v17.4s
	fadd	v6.4s, v6.4s, v18.4s
	fmla	v19.4s, v16.4s, v13.4s
	fmul	v17.4s, v14.4s, v8.4s
	fmla	v23.4s, v16.4s, v9.4s
	fsub	v5.4s, v5.4s, v7.4s
	fadd	v7.4s, v21.4s, v3.4s
	fsub	v6.4s, v6.4s, v17.4s
	fadd	v3.4s, v0.4s, v1.4s
	fsub	v17.4s, v5.4s, v23.4s
	fadd	v7.4s, v7.4s, v10.4s
	fadd	v18.4s, v19.4s, v6.4s
	fadd	v5.4s, v5.4s, v23.4s
	fsub	v6.4s, v6.4s, v19.4s
	fadd	v0.4s, v7.4s, v14.4s
	stp	q17, q18, [x1, #-16]
	add	x1, x9, x8
	mov	v16.16b, v14.16b
	stp	q3, q0, [x9, #-16]
	add	x9, x9, #32
	stp	q5, q6, [x1, #-16]
	b.ne	.LBB204_3
	b	.LBB204_10
.LBB204_4:
	str	x8, [sp, #24]                   // 8-byte Folded Spill
	cbz	x2, .LBB204_10
// %bb.5:
	lsl	x8, x2, #2
	ldr	x19, [sp, #24]                  // 8-byte Folded Reload
	ldp	x9, x22, [sp, #208]             // 16-byte Folded Reload
	mul	x11, x2, x1
	mov	w14, #192
	stp	x8, x2, [sp, #192]              // 16-byte Folded Spill
	add	x8, x8, x2
	lsl	x18, x8, #1
	lsl	x0, x19, #3
	add	x24, x0, #8
	mov	w0, #224
	str	x8, [sp, #184]                  // 8-byte Folded Spill
	mov	w8, #352
	add	x16, x22, x19, lsl #6
	madd	x21, x11, x14, x9
	mul	x8, x1, x8
	add	x15, x16, #64
	madd	x7, x19, x0, x22
	mov	w20, #40
	madd	x14, x19, x14, x22
	mov	x29, x2
	mul	x2, x1, x20
	stp	x8, x18, [sp, #168]             // 16-byte Folded Spill
	mov	w8, #96
	str	x24, [sp, #160]                 // 8-byte Folded Spill
	mov	w10, #288
	madd	x18, x19, x8, x22
	mov	w3, #160
	madd	x16, x11, x8, x9
	mov	w12, #320
	add	x13, x18, #96
	lsl	x18, x29, #3
	add	x4, x22, x19, lsl #7
	mov	w25, #56740
	madd	x17, x19, x10, x22
	add	x6, x4, #128
	stp	x13, x15, [sp, #256]            // 16-byte Folded Spill
	add	x15, x7, #224
	add	x13, x14, #192
	mov	w14, #48
	madd	x4, x19, x3, x22
	movk	w25, #49000, lsl #16
	mul	x14, x1, x14
	add	x17, x17, #288
	stp	x13, x15, [sp, #240]            // 16-byte Folded Spill
	sub	x13, x2, #40
	mov	w2, #56
	sub	x15, x14, #48
	madd	x26, x1, x12, x22
	add	x19, x4, #160
	str	x13, [sp, #152]                 // 8-byte Folded Spill
	madd	x13, x11, x0, x9
	mov	w0, #24
	mul	x14, x1, x2
	mov	w2, #45383
	madd	x23, x11, x3, x9
	mul	x0, x1, x0
	movk	w2, #16084, lsl #16
	str	x13, [sp, #232]                 // 8-byte Folded Spill
	add	x13, x5, #4
	madd	x12, x11, x12, x9
	mov	x4, xzr
	dup	v1.4s, w2
	mov	w2, #41301
	str	x13, [sp, #16]                  // 8-byte Folded Spill
	sub	x13, x0, #24
	lsl	x0, x1, #4
	movk	w2, #16245, lsl #16
	madd	x10, x11, x10, x9
	mov	x27, xzr
	stp	x13, x15, [sp, #128]            // 16-byte Folded Spill
	sub	x13, x14, #56
	mov	w14, #23652
	dup	v0.4s, w2
	movk	w14, #16215, lsl #16
	mov	w2, #25840
	str	x13, [sp, #120]                 // 8-byte Folded Spill
	sub	x13, x0, #16
	mov	w0, #47867
	movk	w2, #16253, lsl #16
	dup	v31.4s, w14
	mov	w14, #42228
	movk	w0, #15889, lsl #16
	movk	w14, #16167, lsl #16
	stp	q0, q1, [sp, #864]              // 32-byte Folded Spill
	add	x15, x9, x11, lsl #7
	str	x13, [sp, #112]                 // 8-byte Folded Spill
	add	x13, x9, x11, lsl #8
	dup	v2.4s, w0
	mov	w0, #56740
	dup	v3.4s, w14
	mov	w14, #26480
	movk	w0, #16232, lsl #16
	movk	w14, #16138, lsl #16
	ldr	x30, [sp, #112]                 // 8-byte Folded Reload
	str	x1, [sp, #144]                  // 8-byte Folded Spill
	str	q31, [sp, #944]                 // 16-byte Folded Spill
	dup	v1.4s, w0
	mov	w0, #30926
	dup	v0.4s, w14
	mov	w14, #16192
	movk	w0, #16193, lsl #16
	movk	w14, #16016, lsl #16
	str	q0, [sp, #848]                  // 16-byte Folded Spill
	dup	v0.4s, w2
	mov	w2, #16192
	movk	w2, #48784, lsl #16
	stp	q0, q2, [sp, #912]              // 32-byte Folded Spill
	dup	v0.4s, w0
	mov	w0, #72
	dup	v2.4s, w14
	mov	w14, #25840
	movk	w14, #49021, lsl #16
	stp	q0, q3, [sp, #960]              // 32-byte Folded Spill
	mul	x0, x1, x0
	dup	v0.4s, w2
	stp	q0, q1, [sp, #272]              // 32-byte Folded Spill
	sub	x8, x0, #72
	dup	v0.4s, w14
	lsl	x14, x29, #1
	add	x0, x18, x29
	stp	q0, q2, [sp, #576]              // 32-byte Folded Spill
	stp	x14, x8, [sp, #96]              // 16-byte Folded Spill
	add	x14, x14, x29
	stp	x0, x18, [sp, #80]              // 16-byte Folded Spill
	sub	x18, x18, x29
	add	x0, x22, x24, lsl #5
	mov	w24, #26480
	movk	w24, #48906, lsl #16
	stp	x18, x14, [sp, #64]             // 16-byte Folded Spill
	lsl	x18, x1, #5
	lsl	x14, x14, #1
	add	x8, x9, x11, lsl #5
	dup	v0.4s, w24
	add	x11, x9, x11, lsl #6
	add	x3, x22, x18
	stp	x14, x18, [sp, #48]             // 16-byte Folded Spill
	sub	x14, x18, #32
	str	q0, [sp, #560]                  // 16-byte Folded Spill
	dup	v0.4s, w25
	str	x14, [sp, #40]                  // 8-byte Folded Spill
	lsl	x14, x1, #6
	str	q0, [sp, #896]                  // 16-byte Folded Spill
	str	x14, [sp, #32]                  // 8-byte Folded Spill
	b	.LBB204_7
.LBB204_6:                              //   in Loop: Header=BB204_7 Depth=1
	ldr	x9, [sp, #168]                  // 8-byte Folded Reload
	ldp	x14, x13, [sp, #344]            // 16-byte Folded Reload
	ldr	x10, [sp, #56]                  // 8-byte Folded Reload
	add	x17, x17, x9
	ldp	x24, x22, [sp, #312]            // 16-byte Folded Reload
	add	x6, x6, x9
	add	x19, x19, x9
	ldp	x5, x2, [sp, #328]              // 16-byte Folded Reload
	add	x24, x24, x9
	add	x3, x3, x9
	ldr	x4, [sp, #224]                  // 8-byte Folded Reload
	add	x26, x14, x9
	stp	x6, x17, [sp, #256]             // 16-byte Folded Spill
	add	x17, x18, x9
	add	x0, x0, x9
	add	x6, x7, x9
	str	x19, [sp, #248]                 // 8-byte Folded Spill
	add	x19, x20, x9
	add	x21, x21, x9
	ldr	x9, [sp, #360]                  // 8-byte Folded Reload
	add	x1, x1, x10
	add	x13, x13, x10
	add	x8, x8, x10
	add	x2, x2, x10
	add	x22, x22, x10
	ldr	x29, [sp, #200]                 // 8-byte Folded Reload
	add	x4, x4, #1
	add	x9, x9, x10
	add	x23, x23, x10
	stp	x1, x21, [sp, #232]             // 16-byte Folded Spill
	add	x15, x15, x10
	add	x16, x12, x10
	add	x12, x5, x10
	add	x10, x11, x10
	mov	x21, x13
	ldr	x1, [sp, #144]                  // 8-byte Folded Reload
	mov	x13, x8
	mov	x8, x2
	mov	x11, x22
	mov	x22, x24
	cmp	x4, x29
	b.eq	.LBB204_10
.LBB204_7:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB204_9 Depth 2
	str	x9, [sp, #360]                  // 8-byte Folded Spill
	mov	w9, #11
	ldr	q28, [sp, #592]                 // 16-byte Folded Reload
	stp	x12, x8, [sp, #328]             // 16-byte Folded Spill
	mul	x24, x4, x9
	ldr	x9, [sp, #216]                  // 8-byte Folded Reload
	ldr	x8, [sp, #96]                   // 8-byte Folded Reload
	stp	x22, x11, [sp, #312]            // 16-byte Folded Spill
	add	x25, x24, #10
	add	x14, x24, #9
	mul	x27, x24, x1
	add	x5, x24, #2
	mul	x25, x25, x1
	stp	x26, x21, [sp, #344]            // 16-byte Folded Spill
	mul	x14, x14, x1
	mov	x18, x17
	add	x28, x9, x27, lsl #5
	add	x27, x1, x27
	mul	x5, x5, x1
	add	x25, x9, x25, lsl #5
	add	x27, x9, x27, lsl #5
	add	x14, x9, x14, lsl #5
	ldp	q14, q5, [x28]
	add	x28, x24, #3
	add	x5, x9, x5, lsl #5
	mov	x7, x6
	mov	x20, x19
	mov	x12, x16
	cmp	x1, #2
	str	q14, [sp, #608]                 // 16-byte Folded Spill
	mov	x11, x10
	str	x4, [sp, #224]                  // 8-byte Folded Spill
	ldp	q0, q1, [x27]
	mul	x27, x28, x1
	ldp	q2, q3, [x25]
	fadd	v26.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	ldp	q7, q16, [x14]
	add	x14, x24, #8
	fadd	v25.4s, v1.4s, v3.4s
	mul	x14, x14, x1
	str	q0, [sp, #816]                  // 16-byte Folded Spill
	fsub	v9.4s, v1.4s, v3.4s
	ldp	q4, q6, [x5]
	add	x5, x9, x27, lsl #5
	add	x14, x9, x14, lsl #5
	stp	q26, q9, [sp, #624]             // 32-byte Folded Spill
	fadd	v18.4s, v4.4s, v7.4s
	fsub	v30.4s, v4.4s, v7.4s
	ldp	q17, q21, [x5]
	add	x5, x24, #4
	fadd	v4.4s, v14.4s, v26.4s
	stp	q5, q18, [sp, #736]             // 32-byte Folded Spill
	mul	x5, x5, x1
	fadd	v22.4s, v6.4s, v16.4s
	fsub	v19.4s, v6.4s, v16.4s
	ldp	q0, q1, [x14]
	add	x14, x24, #7
	add	x5, x9, x5, lsl #5
	fadd	v4.4s, v4.4s, v18.4s
	str	q22, [sp, #768]                 // 16-byte Folded Spill
	mul	x14, x14, x1
	str	q19, [sp, #464]                 // 16-byte Folded Spill
	fadd	v27.4s, v17.4s, v0.4s
	fsub	v24.4s, v17.4s, v0.4s
	ldp	q2, q3, [x5]
	add	x5, x24, #5
	add	x24, x24, #6
	add	x14, x9, x14, lsl #5
	mul	x5, x5, x1
	mul	x24, x24, x1
	fadd	v10.4s, v21.4s, v1.4s
	fsub	v23.4s, v21.4s, v1.4s
	add	x5, x9, x5, lsl #5
	ldp	q0, q1, [x14]
	add	x14, x9, x24, lsl #5
	str	q23, [sp, #832]                 // 16-byte Folded Spill
	fadd	v8.4s, v2.4s, v0.4s
	fsub	v21.4s, v2.4s, v0.4s
	ldp	q6, q7, [x5]
	fadd	v2.4s, v4.4s, v27.4s
	add	x5, x4, x29
	fadd	v11.4s, v3.4s, v1.4s
	stp	q30, q8, [sp, #656]             // 32-byte Folded Spill
	fsub	v20.4s, v3.4s, v1.4s
	mul	x5, x5, x1
	fadd	v4.4s, v5.4s, v25.4s
	fadd	v1.4s, v2.4s, v8.4s
	ldp	q16, q0, [x14]
	mul	x14, x4, x1
	fadd	v4.4s, v4.4s, v22.4s
	fadd	v3.4s, v6.4s, v16.4s
	fsub	v2.4s, v6.4s, v16.4s
	ldr	q6, [sp, #880]                  // 16-byte Folded Reload
	fadd	v13.4s, v7.4s, v0.4s
	ldr	q17, [sp, #848]                 // 16-byte Folded Reload
	fadd	v29.4s, v1.4s, v3.4s
	ldr	x9, [sp, #208]                  // 8-byte Folded Reload
	stp	q25, q2, [sp, #528]             // 32-byte Folded Spill
	ldr	x29, [sp, #120]                 // 8-byte Folded Reload
	fmul	v2.4s, v26.4s, v31.4s
	ldr	q12, [sp, #544]                 // 16-byte Folded Reload
	fmul	v1.4s, v25.4s, v31.4s
	add	x14, x9, x14, lsl #5
	mov	v15.16b, v3.16b
	ldr	q3, [sp, #880]                  // 16-byte Folded Reload
	fmul	v6.4s, v22.4s, v6.4s
	str	q13, [sp, #512]                 // 16-byte Folded Spill
	fadd	v2.4s, v14.4s, v2.4s
	add	x5, x9, x5, lsl #5
	fmul	v3.4s, v18.4s, v3.4s
	ldr	q18, [sp, #288]                 // 16-byte Folded Reload
	fadd	v1.4s, v5.4s, v1.4s
	stp	q10, q15, [sp, #480]            // 32-byte Folded Spill
	fsub	v0.4s, v7.4s, v0.4s
	ldr	x10, [sp, #104]                 // 8-byte Folded Reload
	fmul	v7.4s, v19.4s, v18.4s
	fadd	v2.4s, v2.4s, v3.4s
	ldr	q3, [sp, #928]                  // 16-byte Folded Reload
	fadd	v1.4s, v1.4s, v6.4s
	ldp	q5, q6, [sp, #912]              // 32-byte Folded Reload
	fmul	v3.4s, v27.4s, v3.4s
	fmla	v7.4s, v17.4s, v9.4s
	fmul	v16.4s, v30.4s, v18.4s
	stp	q20, q0, [sp, #784]             // 32-byte Folded Spill
	fadd	v4.4s, v4.4s, v10.4s
	mov	v9.16b, v15.16b
	fsub	v2.4s, v2.4s, v3.4s
	fmla	v7.4s, v5.4s, v23.4s
	fmul	v6.4s, v10.4s, v6.4s
	ldr	q3, [sp, #848]                  // 16-byte Folded Reload
	ldr	q17, [sp, #816]                 // 16-byte Folded Reload
	fadd	v4.4s, v4.4s, v11.4s
	mov	v23.16b, v24.16b
	fmla	v16.4s, v3.4s, v17.4s
	ldr	q3, [sp, #976]                  // 16-byte Folded Reload
	fsub	v1.4s, v1.4s, v6.4s
	ldr	q6, [sp, #976]                  // 16-byte Folded Reload
	mov	v25.16b, v10.16b
	fmul	v3.4s, v8.4s, v3.4s
	fmul	v6.4s, v11.4s, v6.4s
	fmla	v16.4s, v5.4s, v24.4s
	ldr	q5, [sp, #960]                  // 16-byte Folded Reload
	mov	v26.16b, v11.16b
	fsub	v2.4s, v2.4s, v3.4s
	ldr	q3, [sp, #864]                  // 16-byte Folded Reload
	fsub	v1.4s, v1.4s, v6.4s
	ldr	q6, [sp, #864]                  // 16-byte Folded Reload
	fmla	v7.4s, v5.4s, v20.4s
	fmla	v16.4s, v5.4s, v21.4s
	fmul	v3.4s, v15.4s, v3.4s
	stp	q26, q23, [sp, #688]            // 32-byte Folded Spill
	fmul	v6.4s, v13.4s, v6.4s
	mov	v15.16b, v13.16b
	fmla	v7.4s, v28.4s, v0.4s
	fmla	v16.4s, v28.4s, v12.4s
	fsub	v2.4s, v2.4s, v3.4s
	ldr	q0, [sp, #880]                  // 16-byte Folded Reload
	fsub	v1.4s, v1.4s, v6.4s
	fadd	v3.4s, v4.4s, v13.4s
	ldr	q13, [sp, #624]                 // 16-byte Folded Reload
	ldp	q20, q24, [sp, #736]            // 32-byte Folded Reload
	fsub	v4.4s, v2.4s, v7.4s
	fadd	v6.4s, v16.4s, v1.4s
	stp	q29, q3, [x14]
	fmul	v0.4s, v13.4s, v0.4s
	fadd	v2.4s, v2.4s, v7.4s
	ldr	q3, [sp, #880]                  // 16-byte Folded Reload
	stp	q4, q6, [x5]
	ldr	q29, [sp, #528]                 // 16-byte Folded Reload
	ldr	q4, [sp, #976]                  // 16-byte Folded Reload
	ldr	x14, [sp, #176]                 // 8-byte Folded Reload
	fmul	v3.4s, v29.4s, v3.4s
	ldr	q6, [sp, #976]                  // 16-byte Folded Reload
	fadd	v0.4s, v14.4s, v0.4s
	fmul	v4.4s, v24.4s, v4.4s
	add	x14, x4, x14
	fmul	v6.4s, v22.4s, v6.4s
	fadd	v3.4s, v20.4s, v3.4s
	mul	x14, x14, x1
	fsub	v1.4s, v1.4s, v16.4s
	fsub	v4.4s, v0.4s, v4.4s
	ldr	q0, [sp, #864]                  // 16-byte Folded Reload
	add	x14, x9, x14, lsl #5
	fsub	v3.4s, v3.4s, v6.4s
	ldr	q6, [sp, #864]                  // 16-byte Folded Reload
	fmul	v7.4s, v27.4s, v0.4s
	stp	q2, q1, [x14]
	ldr	q1, [sp, #928]                  // 16-byte Folded Reload
	fmul	v6.4s, v25.4s, v6.4s
	add	x14, x4, x8
	fmul	v0.4s, v30.4s, v5.4s
	ldr	x8, [sp, #80]                   // 8-byte Folded Reload
	fsub	v4.4s, v4.4s, v7.4s
	ldr	q7, [sp, #928]                  // 16-byte Folded Reload
	mov	v10.16b, v21.16b
	mul	x14, x14, x1
	fsub	v2.4s, v3.4s, v6.4s
	add	x5, x4, x8
	fmul	v3.4s, v26.4s, v1.4s
	fmla	v0.4s, v18.4s, v17.4s
	fmul	v7.4s, v8.4s, v7.4s
	add	x14, x9, x14, lsl #5
	fmul	v1.4s, v19.4s, v5.4s
	ldr	x8, [sp, #72]                   // 8-byte Folded Reload
	mov	v21.16b, v14.16b
	ldr	q14, [sp, #640]                 // 16-byte Folded Reload
	fsub	v2.4s, v2.4s, v3.4s
	str	q10, [sp, #720]                 // 16-byte Folded Spill
	fmul	v3.4s, v15.4s, v31.4s
	fsub	v4.4s, v4.4s, v7.4s
	fmla	v1.4s, v18.4s, v14.4s
	fmul	v6.4s, v9.4s, v31.4s
	mov	v25.16b, v8.16b
	fadd	v18.4s, v2.4s, v3.4s
	ldr	q2, [sp, #928]                  // 16-byte Folded Reload
	mov	v8.16b, v26.16b
	fadd	v9.4s, v4.4s, v6.4s
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	fmul	v3.4s, v29.4s, v2.4s
	ldr	q2, [sp, #864]                  // 16-byte Folded Reload
	mov	v11.16b, v17.16b
	ldr	q17, [sp, #272]                 // 16-byte Folded Reload
	fmul	v6.4s, v13.4s, v4.4s
	ldr	q4, [sp, #832]                  // 16-byte Folded Reload
	fmul	v7.4s, v24.4s, v2.4s
	ldr	q2, [sp, #864]                  // 16-byte Folded Reload
	ldp	q26, q24, [sp, #768]            // 32-byte Folded Reload
	fsub	v3.4s, v20.4s, v3.4s
	fmla	v0.4s, v17.4s, v23.4s
	fsub	v6.4s, v21.4s, v6.4s
	fmla	v1.4s, v17.4s, v4.4s
	mov	v22.16b, v23.16b
	fmul	v16.4s, v26.4s, v2.4s
	mov	v23.16b, v13.16b
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	mov	v13.16b, v29.16b
	ldr	q20, [sp, #800]                 // 16-byte Folded Reload
	fsub	v6.4s, v6.4s, v7.4s
	mov	v29.16b, v27.16b
	fmul	v7.4s, v27.4s, v2.4s
	ldr	q2, [sp, #880]                  // 16-byte Folded Reload
	ldr	q27, [sp, #480]                 // 16-byte Folded Reload
	ldp	q15, q19, [sp, #560]            // 32-byte Folded Reload
	fsub	v3.4s, v3.4s, v16.4s
	fmul	v16.4s, v27.4s, v2.4s
	fadd	v6.4s, v6.4s, v7.4s
	fmul	v7.4s, v30.4s, v17.4s
	fmul	v21.4s, v25.4s, v31.4s
	fadd	v3.4s, v3.4s, v16.4s
	fmla	v0.4s, v19.4s, v10.4s
	fmul	v16.4s, v8.4s, v31.4s
	fmla	v1.4s, v19.4s, v24.4s
	ldp	q8, q2, [sp, #896]              // 32-byte Folded Reload
	fadd	v6.4s, v6.4s, v21.4s
	fmla	v0.4s, v15.4s, v12.4s
	fmla	v1.4s, v15.4s, v20.4s
	fadd	v3.4s, v3.4s, v16.4s
	ldr	q30, [sp, #464]                 // 16-byte Folded Reload
	fmla	v7.4s, v2.4s, v11.4s
	fsub	v21.4s, v9.4s, v1.4s
	fadd	v16.4s, v0.4s, v18.4s
	fmul	v17.4s, v30.4s, v17.4s
	fmla	v7.4s, v8.4s, v22.4s
	ldp	q11, q22, [sp, #496]            // 32-byte Folded Reload
	stp	q21, q16, [x14]
	mul	x14, x5, x1
	fmla	v17.4s, v2.4s, v14.4s
	add	x5, x4, x8
	fadd	v1.4s, v9.4s, v1.4s
	mul	x5, x5, x1
	add	x14, x9, x14, lsl #5
	fsub	v0.4s, v18.4s, v0.4s
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fmla	v17.4s, v8.4s, v4.4s
	add	x5, x9, x5, lsl #5
	ldr	x8, [sp, #88]                   // 8-byte Folded Reload
	mov	v18.16b, v30.16b
	fmul	v21.4s, v11.4s, v2.4s
	ldr	q2, [sp, #848]                  // 16-byte Folded Reload
	stp	q1, q0, [x14]
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	add	x14, x4, x8
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	fmla	v7.4s, v2.4s, v10.4s
	ldr	q2, [sp, #848]                  // 16-byte Folded Reload
	fsub	v6.4s, v6.4s, v21.4s
	mul	x14, x14, x1
	fmul	v0.4s, v23.4s, v0.4s
	ldr	q21, [sp, #784]                 // 16-byte Folded Reload
	fmla	v17.4s, v2.4s, v24.4s
	ldr	q2, [sp, #976]                  // 16-byte Folded Reload
	fmla	v7.4s, v5.4s, v12.4s
	add	x14, x9, x14, lsl #5
	mov	v24.16b, v5.16b
	fmul	v2.4s, v22.4s, v2.4s
	fmla	v17.4s, v5.4s, v20.4s
	ldr	q5, [sp, #928]                  // 16-byte Folded Reload
	ldp	q9, q20, [sp, #736]             // 32-byte Folded Reload
	mov	v10.16b, v12.16b
	fsub	v2.4s, v3.4s, v2.4s
	fsub	v3.4s, v6.4s, v17.4s
	fmul	v5.4s, v26.4s, v5.4s
	fadd	v1.4s, v6.4s, v17.4s
	fadd	v4.4s, v7.4s, v2.4s
	ldr	q12, [sp, #608]                 // 16-byte Folded Reload
	fsub	v2.4s, v2.4s, v7.4s
	ldr	q6, [sp, #864]                  // 16-byte Folded Reload
	ldr	q26, [sp, #688]                 // 16-byte Folded Reload
	fsub	v0.4s, v12.4s, v0.4s
	ldr	q7, [sp, #816]                  // 16-byte Folded Reload
	stp	q3, q4, [x5]
	ldr	q3, [sp, #976]                  // 16-byte Folded Reload
	ldr	q4, [sp, #928]                  // 16-byte Folded Reload
	stp	q1, q2, [x14]
	fmul	v1.4s, v30.4s, v19.4s
	ldp	x5, x14, [sp, #184]             // 16-byte Folded Reload
	fmul	v3.4s, v13.4s, v3.4s
	fmul	v4.4s, v20.4s, v4.4s
	fmul	v2.4s, v29.4s, v31.4s
	add	x14, x4, x14
	fmul	v6.4s, v26.4s, v6.4s
	fmla	v1.4s, v24.4s, v14.4s
	fsub	v3.4s, v9.4s, v3.4s
	mul	x14, x14, x1
	fsub	v0.4s, v0.4s, v4.4s
	add	x5, x4, x5
	fmul	v4.4s, v27.4s, v31.4s
	add	x14, x9, x14, lsl #5
	mul	x5, x5, x1
	fsub	v3.4s, v3.4s, v5.4s
	ldp	q5, q30, [sp, #656]             // 32-byte Folded Reload
	fadd	v2.4s, v0.4s, v2.4s
	add	x5, x9, x5, lsl #5
	fadd	v3.4s, v3.4s, v4.4s
	fmul	v0.4s, v5.4s, v19.4s
	fmul	v5.4s, v5.4s, v15.4s
	fsub	v3.4s, v3.4s, v6.4s
	ldp	q6, q4, [sp, #848]              // 32-byte Folded Reload
	fmla	v0.4s, v24.4s, v7.4s
	ldr	q19, [sp, #928]                 // 16-byte Folded Reload
	fmul	v4.4s, v30.4s, v4.4s
	fmla	v5.4s, v28.4s, v7.4s
	fmul	v7.4s, v18.4s, v15.4s
	ldr	q15, [sp, #832]                 // 16-byte Folded Reload
	ldp	q18, q25, [sp, #704]            // 32-byte Folded Reload
	fsub	v2.4s, v2.4s, v4.4s
	fmla	v7.4s, v28.4s, v14.4s
	fmla	v0.4s, v6.4s, v18.4s
	fmla	v5.4s, v24.4s, v18.4s
	mov	v14.16b, v22.16b
	ldp	q4, q17, [sp, #848]             // 32-byte Folded Reload
	fmla	v7.4s, v24.4s, v15.4s
	fmla	v0.4s, v28.4s, v25.4s
	fmla	v5.4s, v8.4s, v25.4s
	fmla	v1.4s, v4.4s, v15.4s
	fmla	v7.4s, v8.4s, v21.4s
	ldr	q4, [sp, #880]                  // 16-byte Folded Reload
	fmla	v0.4s, v8.4s, v10.4s
	ldr	q6, [sp, #880]                  // 16-byte Folded Reload
	fmla	v1.4s, v28.4s, v21.4s
	ldr	q18, [sp, #768]                 // 16-byte Folded Reload
	fmul	v4.4s, v11.4s, v4.4s
	fmul	v6.4s, v22.4s, v6.4s
	ldr	q22, [sp, #880]                 // 16-byte Folded Reload
	fmul	v16.4s, v23.4s, v17.4s
	ldr	q23, [sp, #800]                 // 16-byte Folded Reload
	fmul	v18.4s, v18.4s, v31.4s
	fadd	v2.4s, v2.4s, v4.4s
	fmul	v4.4s, v13.4s, v17.4s
	fmla	v1.4s, v8.4s, v23.4s
	fadd	v3.4s, v3.4s, v6.4s
	fsub	v6.4s, v12.4s, v16.4s
	fmul	v16.4s, v20.4s, v31.4s
	fsub	v4.4s, v9.4s, v4.4s
	fsub	v17.4s, v2.4s, v1.4s
	mov	v28.16b, v10.16b
	fadd	v6.4s, v6.4s, v16.4s
	fadd	v16.4s, v0.4s, v3.4s
	fadd	v4.4s, v4.4s, v18.4s
	ldr	q18, [sp, #976]                 // 16-byte Folded Reload
	fadd	v1.4s, v2.4s, v1.4s
	fsub	v0.4s, v3.4s, v0.4s
	stp	q17, q16, [x14]
	ldr	q17, [sp, #976]                 // 16-byte Folded Reload
	fmul	v18.4s, v27.4s, v18.4s
	add	x14, x4, x8
	fmul	v16.4s, v30.4s, v22.4s
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	fmul	v17.4s, v29.4s, v17.4s
	mul	x14, x14, x1
	ldr	q27, [sp, #912]                 // 16-byte Folded Reload
	fsub	v4.4s, v4.4s, v18.4s
	add	x24, x4, x8
	add	x14, x9, x14, lsl #5
	mov	x8, x13
	fsub	v6.4s, v6.4s, v17.4s
	fmla	v5.4s, v27.4s, v28.4s
	fmul	v17.4s, v26.4s, v22.4s
	fmla	v7.4s, v27.4s, v23.4s
	stp	q1, q0, [x14]
	mul	x14, x24, x1
	ldp	x6, x17, [sp, #256]             // 16-byte Folded Reload
	fadd	v2.4s, v6.4s, v16.4s
	fadd	v4.4s, v4.4s, v17.4s
	add	x14, x9, x14, lsl #5
	fmul	v6.4s, v11.4s, v19.4s
	ldr	x1, [sp, #232]                  // 8-byte Folded Reload
	fmul	v16.4s, v14.4s, v19.4s
	ldp	x13, x9, [sp, #152]             // 16-byte Folded Reload
	mov	v10.16b, v31.16b
	fsub	v2.4s, v2.4s, v6.4s
	fsub	v3.4s, v4.4s, v16.4s
	ldp	x21, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x16, x26, [sp, #128]            // 16-byte Folded Reload
	fsub	v0.4s, v2.4s, v7.4s
	ldp	x22, x2, [sp, #32]              // 16-byte Folded Reload
	fadd	v1.4s, v5.4s, v3.4s
	fadd	v2.4s, v2.4s, v7.4s
	fsub	v3.4s, v3.4s, v5.4s
	stp	q0, q1, [x5]
	stp	q2, q3, [x14]
	b.lo	.LBB204_6
// %bb.8:                               //   in Loop: Header=BB204_7 Depth=1
	ldp	x25, x27, [sp, #16]             // 16-byte Folded Reload
	mov	x24, xzr
.LBB204_9:                              //   Parent Loop BB204_7 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x4, [sp, #344]                  // 8-byte Folded Reload
	add	x14, x3, x24
	ldr	q21, [sp, #880]                 // 16-byte Folded Reload
	subs	x27, x27, #1
	add	x5, x4, x24
	ldr	x4, [sp, #312]                  // 8-byte Folded Reload
	ldp	q0, q1, [x14, #32]
	add	x14, x17, x24
	add	x28, x4, x24
	ldp	q2, q3, [x5, #32]
	add	x5, x18, x24
	fadd	v16.4s, v0.4s, v2.4s
	fsub	v20.4s, v0.4s, v2.4s
	ldp	q4, q5, [x14, #32]
	add	x14, x6, x24
	fadd	v29.4s, v1.4s, v3.4s
	fsub	v28.4s, v1.4s, v3.4s
	ldp	q0, q2, [x5, #32]
	add	x5, x0, x24
	fadd	v19.4s, v4.4s, v0.4s
	fsub	v10.4s, v4.4s, v0.4s
	ldp	q1, q3, [x14, #32]
	add	x14, x19, x24
	fadd	v26.4s, v5.4s, v2.4s
	fsub	v24.4s, v5.4s, v2.4s
	ldp	q6, q0, [x5, #32]
	add	x5, x7, x24
	stp	q24, q28, [sp, #784]            // 32-byte Folded Spill
	stp	q16, q26, [sp, #704]            // 32-byte Folded Spill
	fadd	v22.4s, v1.4s, v6.4s
	fsub	v9.4s, v1.4s, v6.4s
	ldp	q7, q17, [x28, #32]
	fadd	v23.4s, v3.4s, v0.4s
	mov	x28, x25
	fsub	v18.4s, v3.4s, v0.4s
	str	q22, [sp, #400]                 // 16-byte Folded Spill
	fadd	v2.4s, v7.4s, v16.4s
	stp	q10, q23, [sp, #640]            // 32-byte Folded Spill
	ldp	q4, q5, [x5, #32]
	add	x5, x20, x24
	stp	q17, q19, [sp, #816]            // 32-byte Folded Spill
	fadd	v2.4s, v2.4s, v19.4s
	ldp	q1, q0, [x14, #32]
	add	x14, x21, x24
	fadd	v2.4s, v2.4s, v22.4s
	fadd	v25.4s, v4.4s, v1.4s
	fsub	v12.4s, v4.4s, v1.4s
	fadd	v15.4s, v5.4s, v0.4s
	fsub	v0.4s, v5.4s, v0.4s
	ldp	q3, q6, [x5, #32]
	mov	v30.16b, v25.16b
	str	q25, [sp, #368]                 // 16-byte Folded Spill
	stp	q15, q7, [sp, #672]             // 32-byte Folded Spill
	add	x5, x25, x9
	str	q0, [sp, #736]                  // 16-byte Folded Spill
	stp	q20, q12, [sp, #608]            // 32-byte Folded Spill
	ldp	q1, q0, [x14, #32]
	fadd	v4.4s, v3.4s, v1.4s
	fsub	v27.4s, v3.4s, v1.4s
	fadd	v1.4s, v2.4s, v25.4s
	ldr	x14, [sp, #360]                 // 8-byte Folded Reload
	fadd	v2.4s, v17.4s, v29.4s
	fadd	v13.4s, v6.4s, v0.4s
	stp	q4, q13, [sp, #752]             // 32-byte Folded Spill
	fsub	v14.4s, v6.4s, v0.4s
	add	x14, x14, x24
	fmul	v0.4s, v16.4s, v31.4s
	ldr	q16, [sp, #288]                 // 16-byte Folded Reload
	fadd	v3.4s, v1.4s, v4.4s
	str	q27, [sp, #432]                 // 16-byte Folded Spill
	fadd	v1.4s, v2.4s, v26.4s
	mov	v11.16b, v4.16b
	stp	q14, q18, [sp, #496]            // 32-byte Folded Spill
	fadd	v0.4s, v7.4s, v0.4s
	fmul	v4.4s, v19.4s, v21.4s
	fadd	v5.4s, v1.4s, v23.4s
	mov	v19.16b, v24.16b
	fmul	v1.4s, v24.4s, v16.4s
	ldr	q24, [sp, #928]                 // 16-byte Folded Reload
	fmul	v2.4s, v29.4s, v31.4s
	fadd	v4.4s, v0.4s, v4.4s
	fmul	v7.4s, v22.4s, v24.4s
	ldp	q22, q8, [sp, #848]             // 32-byte Folded Reload
	fmul	v0.4s, v10.4s, v16.4s
	fadd	v2.4s, v17.4s, v2.4s
	fmul	v6.4s, v26.4s, v21.4s
	fmla	v1.4s, v22.4s, v28.4s
	fsub	v4.4s, v4.4s, v7.4s
	fmla	v0.4s, v22.4s, v20.4s
	ldr	q17, [sp, #976]                 // 16-byte Folded Reload
	ldr	q28, [sp, #912]                 // 16-byte Folded Reload
	fadd	v2.4s, v2.4s, v6.4s
	ldr	q22, [sp, #736]                 // 16-byte Folded Reload
	fmul	v7.4s, v25.4s, v17.4s
	fmul	v6.4s, v23.4s, v24.4s
	fmla	v1.4s, v28.4s, v18.4s
	fmla	v0.4s, v28.4s, v9.4s
	ldr	q28, [sp, #960]                 // 16-byte Folded Reload
	fadd	v5.4s, v5.4s, v15.4s
	fsub	v4.4s, v4.4s, v7.4s
	fmul	v7.4s, v11.4s, v8.4s
	fmla	v1.4s, v28.4s, v22.4s
	fsub	v2.4s, v2.4s, v6.4s
	fmla	v0.4s, v28.4s, v12.4s
	fmul	v6.4s, v15.4s, v17.4s
	fadd	v5.4s, v5.4s, v13.4s
	fsub	v4.4s, v4.4s, v7.4s
	ldr	q7, [sp, #592]                  // 16-byte Folded Reload
	mov	v11.16b, v13.16b
	fsub	v2.4s, v2.4s, v6.4s
	fmul	v6.4s, v13.4s, v8.4s
	fmla	v1.4s, v7.4s, v14.4s
	ldp	q13, q15, [sp, #688]            // 32-byte Folded Reload
	stp	q3, q5, [x14, #32]
	fmla	v0.4s, v7.4s, v27.4s
	fmul	v3.4s, v10.4s, v28.4s
	add	x14, x25, x10
	fsub	v2.4s, v2.4s, v6.4s
	mov	v6.16b, v27.16b
	fsub	v10.4s, v4.4s, v1.4s
	fmul	v5.4s, v29.4s, v21.4s
	fmla	v3.4s, v16.4s, v20.4s
	fadd	v27.4s, v4.4s, v1.4s
	ldr	q4, [sp, #976]                  // 16-byte Folded Reload
	ldp	q1, q17, [sp, #816]             // 32-byte Folded Reload
	fmul	v7.4s, v15.4s, v21.4s
	fadd	v25.4s, v0.4s, v2.4s
	fadd	v1.4s, v1.4s, v5.4s
	fmul	v5.4s, v26.4s, v4.4s
	ldr	q4, [sp, #976]                  // 16-byte Folded Reload
	fadd	v7.4s, v13.4s, v7.4s
	ldr	q26, [sp, #672]                 // 16-byte Folded Reload
	fmul	v17.4s, v17.4s, v4.4s
	fsub	v4.4s, v2.4s, v0.4s
	fsub	v1.4s, v1.4s, v5.4s
	fmul	v2.4s, v23.4s, v8.4s
	fmul	v0.4s, v19.4s, v28.4s
	ldr	q19, [sp, #272]                 // 16-byte Folded Reload
	fsub	v5.4s, v7.4s, v17.4s
	ldr	q28, [sp, #400]                 // 16-byte Folded Reload
	ldr	q17, [sp, #800]                 // 16-byte Folded Reload
	fsub	v1.4s, v1.4s, v2.4s
	fmla	v3.4s, v19.4s, v9.4s
	fmul	v2.4s, v26.4s, v24.4s
	fmul	v7.4s, v28.4s, v8.4s
	fmla	v0.4s, v16.4s, v17.4s
	ldr	q16, [sp, #576]                 // 16-byte Folded Reload
	fneg	v21.4s, v4.4s
	fsub	v1.4s, v1.4s, v2.4s
	fmul	v2.4s, v11.4s, v31.4s
	fmla	v3.4s, v16.4s, v12.4s
	fsub	v5.4s, v5.4s, v7.4s
	fmla	v0.4s, v19.4s, v18.4s
	fmul	v7.4s, v30.4s, v24.4s
	ldur	s18, [x25, #-4]
	mov	v8.16b, v28.16b
	fadd	v23.4s, v1.4s, v2.4s
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	fmla	v0.4s, v16.4s, v22.4s
	fsub	v5.4s, v5.4s, v7.4s
	ldr	q7, [sp, #752]                  // 16-byte Folded Reload
	fmla	v3.4s, v1.4s, v6.4s
	ld1r	{ v17.4s }, [x28], x13
	fmul	v7.4s, v7.4s, v31.4s
	fmla	v0.4s, v1.4s, v14.4s
	ldp	s16, s6, [x14, #-4]
	fadd	v22.4s, v3.4s, v23.4s
	fmul	v31.4s, v25.4s, v18.s[0]
	ldr	q1, [sp, #928]                  // 16-byte Folded Reload
	add	x14, x25, x22
	fadd	v20.4s, v5.4s, v7.4s
	str	q9, [sp, #384]                  // 16-byte Folded Spill
	fneg	v7.4s, v25.4s
	fneg	v24.4s, v22.4s
	fmla	v31.4s, v17.4s, v10.4s
	ldp	s5, s2, [x5, #-12]
	fmul	v25.4s, v21.4s, v6.s[0]
	fmul	v30.4s, v4.4s, v16.s[0]
	fmul	v12.4s, v17.4s, v7.4s
	fsub	v4.4s, v20.4s, v0.4s
	str	q31, [sp, #416]                 // 16-byte Folded Spill
	fmul	v7.4s, v24.4s, v2.s[0]
	ldp	q31, q24, [sp, #624]            // 32-byte Folded Reload
	fmul	v21.4s, v22.4s, v5.s[0]
	fmla	v30.4s, v27.4s, v6.s[0]
	fmul	v1.4s, v29.4s, v1.4s
	fmla	v25.4s, v27.4s, v16.s[0]
	mov	v22.16b, v29.16b
	fmla	v12.4s, v10.4s, v18.s[0]
	fmla	v7.4s, v4.4s, v5.s[0]
	ldr	q10, [sp, #368]                 // 16-byte Folded Reload
	fmla	v21.4s, v4.4s, v2.s[0]
	stp	q30, q29, [sp, #464]            // 32-byte Folded Spill
	ldr	q29, [sp, #720]                 // 16-byte Folded Reload
	str	q25, [sp, #448]                 // 16-byte Folded Spill
	mov	v25.16b, v15.16b
	fsub	v3.4s, v23.4s, v3.4s
	stp	q7, q21, [sp, #528]             // 32-byte Folded Spill
	ldr	q7, [sp, #816]                  // 16-byte Folded Reload
	ldr	q21, [sp, #608]                 // 16-byte Folded Reload
	mov	v23.16b, v13.16b
	fsub	v2.4s, v7.4s, v1.4s
	ldr	q1, [sp, #864]                  // 16-byte Folded Reload
	fneg	v6.4s, v3.4s
	mov	v30.16b, v9.16b
	fmul	v4.4s, v29.4s, v1.4s
	fadd	v1.4s, v20.4s, v0.4s
	ldp	q16, q0, [sp, #912]             // 32-byte Folded Reload
	fsub	v5.4s, v2.4s, v4.4s
	fmul	v4.4s, v24.4s, v19.4s
	fmul	v0.4s, v15.4s, v0.4s
	ldr	q15, [sp, #832]                 // 16-byte Folded Reload
	ldp	q2, q17, [sp, #864]             // 32-byte Folded Reload
	fmla	v4.4s, v16.4s, v21.4s
	fsub	v0.4s, v13.4s, v0.4s
	fmul	v2.4s, v15.4s, v2.4s
	ldur	s16, [x14, #-64]
	ldr	q13, [sp, #656]                 // 16-byte Folded Reload
	fsub	v0.4s, v0.4s, v2.4s
	ldp	q18, q2, [sp, #880]             // 32-byte Folded Reload
	fmul	v14.4s, v6.4s, v16.s[0]
	fmul	v17.4s, v13.4s, v17.4s
	fmul	v18.4s, v28.4s, v18.4s
	ldur	s6, [x14, #-68]
	fmla	v4.4s, v2.4s, v9.4s
	ldr	q2, [sp, #944]                  // 16-byte Folded Reload
	add	x14, x25, x30
	fadd	v5.4s, v5.4s, v17.4s
	ldr	q28, [sp, #432]                 // 16-byte Folded Reload
	fmla	v14.4s, v1.4s, v6.s[0]
	fmul	v11.4s, v3.4s, v6.s[0]
	fadd	v6.4s, v0.4s, v18.4s
	ldr	q0, [sp, #944]                  // 16-byte Folded Reload
	fmul	v17.4s, v26.4s, v2.4s
	ldr	q2, [sp, #768]                  // 16-byte Folded Reload
	mov	v9.16b, v26.16b
	fmul	v18.4s, v10.4s, v0.4s
	ldr	q0, [sp, #848]                  // 16-byte Folded Reload
	fmla	v11.4s, v1.4s, v16.s[0]
	ldr	q1, [sp, #896]                  // 16-byte Folded Reload
	fadd	v5.4s, v5.4s, v17.4s
	ldr	q16, [sp, #848]                 // 16-byte Folded Reload
	fmla	v4.4s, v0.4s, v31.4s
	ldr	q0, [sp, #976]                  // 16-byte Folded Reload
	fadd	v6.4s, v6.4s, v18.4s
	fmul	v17.4s, v2.4s, v0.4s
	ldp	q2, q18, [sp, #960]             // 32-byte Folded Reload
	fsub	v17.4s, v5.4s, v17.4s
	fmla	v4.4s, v2.4s, v28.4s
	ldp	q0, q27, [sp, #784]             // 32-byte Folded Reload
	fmul	v18.4s, v22.4s, v18.4s
	fmul	v0.4s, v0.4s, v19.4s
	fsub	v18.4s, v7.4s, v18.4s
	ldp	q2, q19, [sp, #912]             // 32-byte Folded Reload
	fmla	v0.4s, v2.4s, v27.4s
	ldp	q3, q22, [sp, #736]             // 32-byte Folded Reload
	fmul	v19.4s, v29.4s, v19.4s
	ldr	q5, [sp, #976]                  // 16-byte Folded Reload
	ldr	q29, [sp, #512]                 // 16-byte Folded Reload
	ldp	q7, q20, [sp, #960]             // 32-byte Folded Reload
	fmul	v5.4s, v22.4s, v5.4s
	fmla	v0.4s, v1.4s, v29.4s
	fsub	v2.4s, v6.4s, v5.4s
	fsub	v6.4s, v18.4s, v19.4s
	fmla	v0.4s, v16.4s, v3.4s
	ldp	s18, s19, [x14, #-4]
	ldp	x14, x4, [sp, #328]             // 16-byte Folded Reload
	fadd	v5.4s, v4.4s, v17.4s
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	fmul	v20.4s, v25.4s, v20.4s
	add	x14, x14, x24
	add	x5, x4, x24
	add	x4, x12, x24
	fneg	v16.4s, v5.4s
	fsub	v20.4s, v23.4s, v20.4s
	stp	q12, q1, [x5, #32]
	ldr	q12, [sp, #496]                 // 16-byte Folded Reload
	ldr	q1, [sp, #576]                  // 16-byte Folded Reload
	fsub	v17.4s, v17.4s, v4.4s
	add	x5, x25, x29
	fmla	v0.4s, v7.4s, v12.4s
	fmul	v7.4s, v16.4s, v19.s[0]
	fmul	v16.4s, v5.4s, v18.s[0]
	ldr	q5, [sp, #928]                  // 16-byte Folded Reload
	fsub	v23.4s, v2.4s, v0.4s
	fmul	v25.4s, v15.4s, v5.4s
	fmul	v5.4s, v24.4s, v1.4s
	ldr	q24, [sp, #944]                 // 16-byte Folded Reload
	mov	v15.16b, v8.16b
	fmla	v7.4s, v23.4s, v18.s[0]
	fmul	v26.4s, v13.4s, v24.4s
	ldp	q24, q18, [sp, #448]            // 32-byte Folded Reload
	fmla	v16.4s, v23.4s, v19.s[0]
	ldp	q13, q23, [sp, #864]            // 32-byte Folded Reload
	stp	q24, q18, [x14, #32]
	fsub	v18.4s, v20.4s, v25.4s
	fadd	v6.4s, v6.4s, v26.4s
	fmul	v20.4s, v9.4s, v13.4s
	ldp	q19, q25, [sp, #960]            // 32-byte Folded Reload
	fsub	v4.4s, v6.4s, v20.4s
	fmla	v5.4s, v19.4s, v21.4s
	fadd	v21.4s, v2.4s, v0.4s
	ldr	q26, [sp, #848]                 // 16-byte Folded Reload
	ldr	q9, [sp, #592]                  // 16-byte Folded Reload
	ldr	x14, [sp, #320]                 // 8-byte Folded Reload
	fmla	v5.4s, v26.4s, v30.4s
	ldp	q19, q20, [sp, #944]            // 32-byte Folded Reload
	add	x14, x14, x24
	fmul	v19.4s, v8.4s, v19.4s
	ldr	q30, [sp, #928]                 // 16-byte Folded Reload
	fmla	v5.4s, v9.4s, v31.4s
	ldp	q31, q24, [sp, #768]            // 32-byte Folded Reload
	mov	v8.16b, v9.16b
	fadd	v0.4s, v18.4s, v19.4s
	fneg	v18.4s, v17.4s
	fmul	v6.4s, v31.4s, v23.4s
	fmul	v19.4s, v10.4s, v13.4s
	fmul	v1.4s, v24.4s, v1.4s
	fadd	v4.4s, v4.4s, v6.4s
	ldp	q6, q2, [sp, #528]              // 32-byte Folded Reload
	fmla	v1.4s, v20.4s, v27.4s
	ldr	s20, [x5]
	stp	q6, q2, [x14, #32]
	ldr	q6, [sp, #896]                  // 16-byte Folded Reload
	ldr	q2, [sp, #896]                  // 16-byte Folded Reload
	add	x14, x25, x16
	fmla	v5.4s, v6.4s, v28.4s
	fmla	v1.4s, v26.4s, v29.4s
	fsub	v6.4s, v0.4s, v19.4s
	fmul	v0.4s, v18.4s, v20.s[0]
	mov	v26.16b, v22.16b
	ldur	s18, [x5, #-4]
	fmul	v19.4s, v22.4s, v23.4s
	add	x5, x11, x24
	fadd	v22.4s, v5.4s, v4.4s
	fmla	v1.4s, v9.4s, v3.4s
	fmla	v0.4s, v21.4s, v18.s[0]
	fmul	v17.4s, v17.4s, v18.s[0]
	stp	q14, q11, [x5, #32]
	fadd	v6.4s, v6.4s, v19.4s
	fneg	v18.4s, v22.4s
	fmla	v1.4s, v2.4s, v12.4s
	stp	q7, q16, [x4, #32]
	ldp	s16, s19, [x14, #-4]
	mov	v9.16b, v3.16b
	fmla	v17.4s, v21.4s, v20.s[0]
	ldr	q20, [sp, #560]                 // 16-byte Folded Reload
	add	x14, x8, x24
	fmul	v2.4s, v18.4s, v19.s[0]
	ldr	q18, [sp, #480]                 // 16-byte Folded Reload
	fsub	v7.4s, v6.4s, v1.4s
	ldr	q3, [sp, #640]                  // 16-byte Folded Reload
	ldr	q21, [sp, #608]                 // 16-byte Folded Reload
	stp	q0, q17, [x14, #32]
	fmul	v18.4s, v18.4s, v13.4s
	fmul	v3.4s, v3.4s, v20.4s
	ldr	q17, [sp, #384]                 // 16-byte Folded Reload
	fmla	v2.4s, v7.4s, v16.s[0]
	fmul	v16.4s, v22.4s, v16.s[0]
	ldr	q22, [sp, #816]                 // 16-byte Folded Reload
	add	x14, x25, x26
	fmul	v20.4s, v24.4s, v20.4s
	add	x4, x1, x24
	fmla	v3.4s, v8.4s, v21.4s
	ldr	q21, [sp, #896]                 // 16-byte Folded Reload
	fsub	v18.4s, v22.4s, v18.4s
	ldr	q22, [sp, #720]                 // 16-byte Folded Reload
	fmla	v16.4s, v7.4s, v19.s[0]
	ldp	q0, q7, [sp, #944]              // 32-byte Folded Reload
	fmla	v20.4s, v8.4s, v27.4s
	ldr	q19, [sp, #832]                 // 16-byte Folded Reload
	fmul	v0.4s, v22.4s, v0.4s
	fmla	v3.4s, v7.4s, v17.4s
	ldr	q7, [sp, #704]                  // 16-byte Folded Reload
	ldr	q17, [sp, #656]                 // 16-byte Folded Reload
	fsub	v4.4s, v4.4s, v5.4s
	fadd	v0.4s, v18.4s, v0.4s
	ldr	q18, [sp, #624]                 // 16-byte Folded Reload
	fmul	v7.4s, v7.4s, v13.4s
	fmul	v17.4s, v17.4s, v25.4s
	fmla	v3.4s, v21.4s, v18.4s
	ldr	q18, [sp, #960]                 // 16-byte Folded Reload
	fadd	v1.4s, v6.4s, v1.4s
	fmla	v20.4s, v18.4s, v29.4s
	fsub	v0.4s, v0.4s, v17.4s
	ldp	q17, q18, [sp, #672]            // 32-byte Folded Reload
	fsub	v7.4s, v18.4s, v7.4s
	ldr	q18, [sp, #944]                 // 16-byte Folded Reload
	fmul	v17.4s, v17.4s, v23.4s
	fmla	v20.4s, v21.4s, v9.4s
	fmul	v21.4s, v26.4s, v30.4s
	fmul	v18.4s, v19.4s, v18.4s
	ldr	q19, [sp, #912]                 // 16-byte Folded Reload
	fadd	v0.4s, v0.4s, v17.4s
	fmul	v17.4s, v31.4s, v30.4s
	fmla	v3.4s, v19.4s, v28.4s
	fadd	v7.4s, v7.4s, v18.4s
	ldr	q31, [sp, #944]                 // 16-byte Folded Reload
	fmul	v18.4s, v15.4s, v25.4s
	fmul	v19.4s, v10.4s, v23.4s
	fsub	v0.4s, v0.4s, v17.4s
	ldr	q17, [sp, #912]                 // 16-byte Folded Reload
	fsub	v7.4s, v7.4s, v18.4s
	ldp	s5, s18, [x14, #-4]
	fmla	v20.4s, v17.4s, v12.4s
	add	x14, x25, x2
	fneg	v17.4s, v4.4s
	add	x25, x25, #8
	fadd	v7.4s, v7.4s, v19.4s
	fadd	v19.4s, v3.4s, v0.4s
	fsub	v0.4s, v0.4s, v3.4s
	fmul	v17.4s, v17.4s, v18.s[0]
	fsub	v7.4s, v7.4s, v21.4s
	fmul	v3.4s, v4.4s, v5.s[0]
	fneg	v6.4s, v19.4s
	ldp	s4, s22, [x14, #-4]
	fmla	v17.4s, v1.4s, v5.s[0]
	add	x14, x15, x24
	fneg	v21.4s, v0.4s
	fmla	v3.4s, v1.4s, v18.s[0]
	ldp	s18, s1, [x28, #-4]
	fmul	v5.4s, v6.4s, v22.s[0]
	fmul	v19.4s, v19.4s, v4.s[0]
	fsub	v6.4s, v7.4s, v20.4s
	stp	q2, q16, [x14, #32]
	fadd	v7.4s, v7.4s, v20.4s
	stp	q17, q3, [x4, #32]
	fmul	v0.4s, v0.4s, v18.s[0]
	ldr	x4, [sp, #352]                  // 8-byte Folded Reload
	add	x14, x23, x24
	fmla	v5.4s, v6.4s, v4.s[0]
	fmul	v4.4s, v21.4s, v1.s[0]
	fmla	v19.4s, v6.4s, v22.s[0]
	add	x4, x4, x24
	fmla	v0.4s, v7.4s, v1.s[0]
	add	x24, x24, #32
	fmla	v4.4s, v7.4s, v18.s[0]
	stp	q5, q19, [x14, #32]
	stp	q4, q0, [x4, #32]
	b.ne	.LBB204_9
	b	.LBB204_6
.LBB204_10:
	add	sp, sp, #992
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.Lfunc_end204:
	.size	_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE, .Lfunc_end204-_ZNK9pocketfft6detail5cfftpIfE6pass11ILb0ENS0_5cmplxIDv4_fEEEEvmmPKT0_PS7_PKNS4_IfEE
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_,"axG",@progbits,_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_,comdat
	.weak	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_ // -- Begin function _ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
	.p2align	2
	.type	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_,@function
_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_: // @_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	lsl	x8, x2, #3
	mov	x25, x7
	add	x0, x8, #64
	stp	x6, x4, [sp, #24]               // 16-byte Folded Spill
	mov	x23, x2
	mov	x24, x5
	mov	x22, x3
	mov	x21, x1
	bl	malloc
	cbz	x0, .LBB205_85
// %bb.1:
	add	x8, x0, #64
	add	x14, x23, #1
	mul	x19, x22, x21
	and	x28, x8, #0xffffffffffffffc0
	mov	w8, #1065353216
	subs	x13, x23, #2
	lsr	x26, x14, #1
	stp	x0, x8, [x28, #-8]
	stp	x26, x22, [x29, #-16]           // 16-byte Folded Spill
	b.lo	.LBB205_4
// %bb.2:
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cmp	x27, #8
	b.hs	.LBB205_6
// %bb.3:
	mov	w8, #1
	b	.LBB205_13
.LBB205_4:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	cbz	x22, .LBB205_73
// %bb.5:
	cbnz	x21, .LBB205_17
	b	.LBB205_73
.LBB205_6:
	cmp	xzr, x13, lsr #61
	add	x11, x28, #8
	lsl	x10, x13, #3
	cset	w9, ne
	mov	w8, #1
	add	x12, x11, x10
	cmp	x12, x11
	b.lo	.LBB205_13
// %bb.7:
	tbnz	w9, #0, .LBB205_13
// %bb.8:
	add	x11, x28, #12
	add	x10, x11, x10
	cmp	x10, x11
	b.lo	.LBB205_13
// %bb.9:
	tbnz	w9, #0, .LBB205_13
// %bb.10:
	and	x9, x27, #0xfffffffffffffff8
	add	x10, x28, #40
	orr	x8, x9, #0x1
	add	x11, x25, #40
	mov	x12, x9
.LBB205_11:                             // =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x11, #-32]
	subs	x12, x12, #8
	ldp	q3, q2, [x11], #64
	stp	q1, q0, [x10, #-32]
	stp	q3, q2, [x10], #64
	b.ne	.LBB205_11
// %bb.12:
	cmp	x27, x9
	b.eq	.LBB205_15
.LBB205_13:
	lsl	x10, x8, #3
	sub	x9, x23, x8
	add	x8, x25, x10
	add	x10, x28, x10
.LBB205_14:                             // =>This Inner Loop Header: Depth=1
	ldr	d0, [x8], #8
	subs	x9, x9, #1
	str	d0, [x10], #8
	b.ne	.LBB205_14
.LBB205_15:
	cbz	x22, .LBB205_35
// %bb.16:
	cbz	x21, .LBB205_37
.LBB205_17:
	mul	x8, x23, x21
	lsl	x25, x21, #5
	mov	x26, x24
	mov	x27, x30
	lsl	x20, x8, #5
	stp	x13, x14, [x29, #-32]           // 16-byte Folded Spill
.LBB205_18:                             // =>This Inner Loop Header: Depth=1
	mov	x0, x26
	mov	x1, x27
	mov	x2, x25
	bl	memcpy
	add	x27, x27, x20
	add	x26, x26, x25
	subs	x22, x22, #1
	b.ne	.LBB205_18
// %bb.19:
	ldp	x8, x26, [x29, #-24]            // 16-byte Folded Reload
	sub	x27, x23, #1
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	cmp	x8, #3
	b.ls	.LBB205_27
// %bb.20:
	cbz	x21, .LBB205_49
// %bb.21:
	mul	x10, x21, x27
	add	x11, x24, x19, lsl #5
	mul	x13, x19, x27
	cmp	x26, #2
	mov	w8, #2
	add	x14, x30, x25
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	lsl	x12, x19, #5
	add	x15, x24, x13, lsl #5
	neg	x9, x25
	csel	x8, x26, x8, hi
	add	x13, x14, #16
	add	x14, x15, #16
	neg	x15, x12
	mov	w16, #1
.LBB205_22:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB205_23 Depth 2
                                        //       Child Loop BB205_24 Depth 3
	mov	x17, xzr
	mov	x18, x14
	mov	x0, x13
	mov	x1, x10
	mov	x2, x11
.LBB205_23:                             //   Parent Loop BB205_22 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB205_24 Depth 3
	mov	x3, x18
	mov	x4, x0
	mov	x5, x1
	mov	x6, x2
	mov	x7, x21
.LBB205_24:                             //   Parent Loop BB205_22 Depth=1
                                        //     Parent Loop BB205_23 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x4, #-16]
	subs	x7, x7, #1
	add	x4, x4, #32
	ldp	q2, q3, [x6, #-16]
	add	x6, x6, #32
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x5, #-16]
	add	x5, x5, #32
	stp	q0, q1, [x3, #-16]
	add	x3, x3, #32
	b.ne	.LBB205_24
// %bb.25:                              //   in Loop: Header=BB205_23 Depth=2
	add	x17, x17, #1
	add	x2, x2, x20
	add	x1, x1, x25
	add	x0, x0, x20
	add	x18, x18, x25
	cmp	x17, x22
	b.ne	.LBB205_23
// %bb.26:                              //   in Loop: Header=BB205_22 Depth=1
	add	x16, x16, #1
	add	x11, x11, x9
	add	x10, x10, x12
	add	x13, x13, x25
	add	x14, x14, x15
	cmp	x16, x8
	b.ne	.LBB205_22
.LBB205_27:
	ldur	x18, [x29, #-24]                // 8-byte Folded Reload
	cbz	x21, .LBB205_42
// %bb.28:
	cmp	x18, #3
	b.ls	.LBB205_38
// %bb.29:
	cmp	x26, #2
	mov	w9, #2
	csel	x9, x26, x9, hi
	add	x10, x24, x19, lsl #5
	mov	x8, xzr
	sub	x9, x9, #1
	add	x10, x10, #16
	lsl	x11, x19, #5
.LBB205_30:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB205_31 Depth 2
                                        //       Child Loop BB205_32 Depth 3
	mul	x13, x8, x21
	mov	x12, xzr
	mov	x14, x10
.LBB205_31:                             //   Parent Loop BB205_30 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB205_32 Depth 3
	add	x15, x12, x13
	mov	x17, x9
	add	x16, x24, x15, lsl #5
	ldp	q0, q1, [x16]
	mov	x16, x14
.LBB205_32:                             //   Parent Loop BB205_30 Depth=1
                                        //     Parent Loop BB205_31 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q3, [x16, #-16]
	subs	x17, x17, #1
	add	x16, x16, x11
	fadd	v0.4s, v0.4s, v2.4s
	fadd	v1.4s, v1.4s, v3.4s
	b.ne	.LBB205_32
// %bb.33:                              //   in Loop: Header=BB205_31 Depth=2
	add	x15, x30, x15, lsl #5
	add	x12, x12, #1
	add	x14, x14, #32
	cmp	x12, x21
	stp	q0, q1, [x15]
	b.ne	.LBB205_31
// %bb.34:                              //   in Loop: Header=BB205_30 Depth=1
	add	x8, x8, #1
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB205_30
	b	.LBB205_42
.LBB205_35:
	mov	w9, #1
	cmp	x14, #3
	b.hi	.LBB205_51
// %bb.36:
	mov	w8, wzr
	subs	x10, x21, #1
	b.eq	.LBB205_44
	b	.LBB205_71
.LBB205_37:
	cmp	x14, #3
	b.hi	.LBB205_50
	b	.LBB205_73
.LBB205_38:
	mov	x8, xzr
	add	x9, x30, #16
	add	x10, x24, #16
.LBB205_39:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB205_40 Depth 2
	mov	x11, x10
	mov	x12, x9
	mov	x13, x21
.LBB205_40:                             //   Parent Loop BB205_39 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x13, x13, #1
	add	x11, x11, #32
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB205_40
// %bb.41:                              //   in Loop: Header=BB205_39 Depth=1
	add	x8, x8, #1
	add	x9, x9, x25
	add	x10, x10, x25
	cmp	x8, x22
	b.ne	.LBB205_39
.LBB205_42:
	mov	w9, wzr
	mov	w8, wzr
	ldur	x13, [x29, #-32]                // 8-byte Folded Reload
	cmp	x18, #4
	b.hs	.LBB205_51
// %bb.43:
	subs	x10, x21, #1
	b.ne	.LBB205_71
.LBB205_44:
	cmp	x19, #0
	eor	w8, w8, #0x1
	cset	w9, eq
	orr	w8, w8, w9
	tbnz	w8, #0, .LBB205_73
// %bb.45:
	mul	x8, x27, x22
	cmp	x26, #2
	mov	w9, #2
	add	x11, x30, x19, lsl #5
	csel	x9, x26, x9, hi
	mov	w13, #1
	mul	x10, x8, x21
	lsl	x8, x19, #5
	add	x12, x30, x10, lsl #5
	add	x10, x11, #16
	add	x11, x12, #16
	neg	x12, x8
.LBB205_46:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB205_47 Depth 2
	mov	x14, x11
	mov	x15, x10
	mov	x16, x19
.LBB205_47:                             //   Parent Loop BB205_46 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x15, #-16]
	subs	x16, x16, #1
	ldp	q2, q3, [x14, #-16]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x15, #-16]
	add	x15, x15, #32
	stp	q0, q1, [x14, #-16]
	add	x14, x14, #32
	b.ne	.LBB205_47
// %bb.48:                              //   in Loop: Header=BB205_46 Depth=1
	add	x13, x13, #1
	add	x10, x10, x8
	add	x11, x11, x12
	cmp	x13, x9
	b.ne	.LBB205_46
	b	.LBB205_73
.LBB205_49:
	ldur	x13, [x29, #-32]                // 8-byte Folded Reload
.LBB205_50:
	mov	w9, wzr
.LBB205_51:
	str	w9, [sp, #12]                   // 4-byte Folded Spill
	mul	x9, x19, x13
	sub	x1, x23, #4
	mul	x8, x19, x27
	cmp	x26, #2
	mov	w13, #2
	add	x18, x24, x9, lsl #5
	mov	w9, #96
	mul	x2, x19, x1
	lsl	x8, x8, #5
	madd	x9, x19, x9, x24
	add	x15, x30, x8
	add	x8, x24, x8
	csel	x13, x26, x13, hi
	add	x1, x8, #16
	add	x8, x9, #16
	add	x9, x24, x2, lsl #5
	sub	x10, x23, #3
	str	x27, [sp, #16]                  // 8-byte Folded Spill
	lsl	x12, x19, #5
	stp	x8, x13, [x29, #-32]            // 16-byte Folded Spill
	mul	x8, x19, x10
	stur	x9, [x29, #-40]                 // 8-byte Folded Spill
	add	x9, x24, x19, lsl #7
	add	x9, x9, #16
	add	x14, x24, x12
	add	x17, x24, x19, lsl #6
	add	x0, x30, x12
	lsl	x3, x19, #6
	sub	x11, x26, #1
	stur	x9, [x29, #-48]                 // 8-byte Folded Spill
	add	x9, x24, x8, lsl #5
	add	x8, x24, #16
	add	x14, x14, #16
	neg	x16, x12
	add	x17, x17, #16
	add	x0, x0, #16
	neg	x5, x3
	stp	x8, x9, [sp, #48]               // 16-byte Folded Spill
	lsl	x8, x19, #1
	mov	w27, #1
	str	x8, [sp, #40]                   // 8-byte Folded Spill
	b	.LBB205_53
.LBB205_52:                             //   in Loop: Header=BB205_53 Depth=1
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	add	x27, x27, #1
	add	x15, x15, x16
	add	x0, x0, x12
	cmp	x27, x8
	b.eq	.LBB205_70
.LBB205_53:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB205_55 Depth 2
                                        //     Child Loop BB205_59 Depth 2
                                        //       Child Loop BB205_61 Depth 3
                                        //     Child Loop BB205_67 Depth 2
                                        //       Child Loop BB205_68 Depth 3
	cbz	x19, .LBB205_62
// %bb.54:                              //   in Loop: Header=BB205_53 Depth=1
	add	x2, x28, x27, lsl #3
	add	x4, x28, x27, lsl #4
	mov	x9, xzr
	lsl	x30, x27, #1
	add	x6, x2, #4
	add	x7, x4, #4
	mov	x8, x19
.LBB205_55:                             //   Parent Loop BB205_53 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x20, x14, x9
	add	x25, x24, x9
	ldr	s0, [x2]
	add	x22, x17, x9
	ldr	s1, [x7]
	add	x26, x18, x9
	ldp	q3, q16, [x20, #-16]
	add	x20, x1, x9
	subs	x8, x8, #1
	dup	v4.4s, v1.s[0]
	fneg	v4.4s, v4.4s
	ldp	q6, q7, [x25]
	fmla	v6.4s, v3.4s, v0.s[0]
	ldp	q17, q3, [x26]
	fmla	v7.4s, v16.4s, v0.s[0]
	fmul	v1.4s, v17.4s, v1.s[0]
	ldp	q5, q0, [x22, #-16]
	fmul	v3.4s, v3.4s, v4.4s
	add	x22, x15, x9
	ldr	s2, [x4]
	ldr	s4, [x6]
	fmla	v6.4s, v5.4s, v2.s[0]
	fmla	v7.4s, v0.4s, v2.s[0]
	ldp	q5, q16, [x20, #-16]
	add	x20, x0, x9
	add	x9, x9, #32
	fmla	v1.4s, v5.4s, v4.s[0]
	stp	q6, q7, [x20, #-16]
	fmls	v3.4s, v16.4s, v4.s[0]
	stp	q3, q1, [x22]
	b.ne	.LBB205_55
// %bb.56:                              //   in Loop: Header=BB205_53 Depth=1
	cmp	x11, #4
	b.lo	.LBB205_63
.LBB205_57:                             //   in Loop: Header=BB205_53 Depth=1
	ldp	x6, x4, [x29, #-48]             // 16-byte Folded Reload
	mov	w9, #3
	mov	x20, x10
	ldr	x7, [sp, #56]                   // 8-byte Folded Reload
	ldur	x2, [x29, #-32]                 // 8-byte Folded Reload
	b	.LBB205_59
.LBB205_58:                             //   in Loop: Header=BB205_59 Depth=2
	add	x9, x9, #2
	sub	x20, x20, #2
	add	x2, x2, x3
	add	x4, x4, x5
	add	x6, x6, x3
	add	x7, x7, x5
	cmp	x9, x11
	b.hs	.LBB205_64
.LBB205_59:                             //   Parent Loop BB205_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB205_61 Depth 3
	add	x8, x30, x27
	cmp	x8, x23
	csel	x22, x23, xzr, hi
	sub	x22, x8, x22
	add	x8, x22, x27
	cmp	x8, x23
	csel	x25, x23, xzr, hi
	sub	x30, x8, x25
	cbz	x19, .LBB205_58
// %bb.60:                              //   in Loop: Header=BB205_59 Depth=2
	add	x22, x28, x22, lsl #3
	add	x25, x28, x30, lsl #3
	mov	x8, xzr
	ld1r	{ v0.4s }, [x22], #4
	ld1r	{ v1.4s }, [x25], #4
	ld1r	{ v2.4s }, [x22]
	mov	x22, x19
	ld1r	{ v3.4s }, [x25]
.LBB205_61:                             //   Parent Loop BB205_53 Depth=1
                                        //     Parent Loop BB205_59 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x25, x6, x8
	add	x26, x2, x8
	add	x13, x0, x8
	subs	x22, x22, #1
	ldp	q4, q5, [x25, #-16]
	add	x25, x4, x8
	fmul	v4.4s, v1.4s, v4.4s
	ldp	q6, q7, [x26, #-16]
	fmul	v5.4s, v1.4s, v5.4s
	add	x26, x7, x8
	fmla	v4.4s, v0.4s, v6.4s
	ldp	q16, q17, [x13, #-16]
	fmla	v5.4s, v0.4s, v7.4s
	fadd	v4.4s, v16.4s, v4.4s
	ldp	q7, q6, [x25]
	fadd	v5.4s, v17.4s, v5.4s
	add	x25, x15, x8
	add	x8, x8, #32
	fmul	v7.4s, v3.4s, v7.4s
	stp	q4, q5, [x13, #-16]
	ldp	q17, q16, [x26]
	fmul	v6.4s, v3.4s, v6.4s
	fmla	v7.4s, v2.4s, v17.4s
	ldp	q4, q5, [x25]
	fmla	v6.4s, v2.4s, v16.4s
	fsub	v4.4s, v4.4s, v6.4s
	fadd	v5.4s, v5.4s, v7.4s
	stp	q4, q5, [x25]
	b.ne	.LBB205_61
	b	.LBB205_58
.LBB205_62:                             //   in Loop: Header=BB205_53 Depth=1
	lsl	x30, x27, #1
	cmp	x11, #4
	b.hs	.LBB205_57
.LBB205_63:                             //   in Loop: Header=BB205_53 Depth=1
	mov	x20, x10
	mov	w9, #3
.LBB205_64:                             //   in Loop: Header=BB205_53 Depth=1
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	cmp	x9, x26
	b.hs	.LBB205_52
// %bb.65:                              //   in Loop: Header=BB205_53 Depth=1
	cbz	x19, .LBB205_52
// %bb.66:                              //   in Loop: Header=BB205_53 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	mul	x8, x13, x9
	mul	x4, x13, x20
	ldr	x13, [sp, #48]                  // 8-byte Folded Reload
	add	x2, x13, x8, lsl #4
	add	x4, x13, x4, lsl #4
.LBB205_67:                             //   Parent Loop BB205_53 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB205_68 Depth 3
	add	x6, x30, x27
	mov	x8, xzr
	cmp	x6, x23
	csel	x7, x23, xzr, hi
	sub	x30, x6, x7
	add	x6, x28, x30, lsl #3
	ld1r	{ v0.4s }, [x6], #4
	ld1r	{ v1.4s }, [x6]
	mov	x6, x19
.LBB205_68:                             //   Parent Loop BB205_53 Depth=1
                                        //     Parent Loop BB205_67 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x7, x2, x8
	add	x20, x0, x8
	add	x22, x15, x8
	subs	x6, x6, #1
	ldp	q2, q4, [x7, #-16]
	add	x7, x4, x8
	add	x8, x8, #32
	ldp	q3, q5, [x20, #-16]
	fmla	v3.4s, v0.4s, v2.4s
	fmla	v5.4s, v0.4s, v4.4s
	stp	q3, q5, [x20, #-16]
	ldp	q3, q2, [x7, #-16]
	ldp	q4, q5, [x22]
	fmls	v4.4s, v1.4s, v2.4s
	fmla	v5.4s, v1.4s, v3.4s
	stp	q4, q5, [x22]
	b.ne	.LBB205_68
// %bb.69:                              //   in Loop: Header=BB205_67 Depth=2
	add	x9, x9, #1
	add	x2, x2, x12
	add	x4, x4, x16
	cmp	x9, x26
	b.ne	.LBB205_67
	b	.LBB205_52
.LBB205_70:
	ldr	x30, [sp, #32]                  // 8-byte Folded Reload
	mov	w8, #1
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	ldr	w9, [sp, #12]                   // 4-byte Folded Reload
	subs	x10, x21, #1
	b.eq	.LBB205_44
.LBB205_71:
	cbz	w8, .LBB205_73
// %bb.72:
	tbz	w9, #0, .LBB205_76
.LBB205_73:
	cbz	x28, .LBB205_75
// %bb.74:
	ldur	x0, [x28, #-8]
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	b	free
.LBB205_75:
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB205_76:
	mul	x8, x27, x22
	sub	x11, x27, #1
	ldr	x0, [sp, #24]                   // 8-byte Folded Reload
	cmp	x26, #2
	mul	x15, x11, x10
	mov	w12, #2
	mul	x8, x8, x21
	add	x18, x30, x19, lsl #5
	lsl	x9, x19, #5
	mov	w17, #8
	add	x16, x0, x15, lsl #3
	csel	x11, x26, x12, hi
	add	x15, x30, x8, lsl #5
	lsl	x8, x21, #3
	add	x12, x18, #16
	lsl	x13, x21, #5
	neg	x14, x9
	add	x16, x16, #4
	sub	x17, x17, x8
	add	x18, x18, #48
	add	x0, x0, #4
	sub	x1, x8, #8
	add	x2, x15, #48
	mov	w3, #1
	b	.LBB205_78
.LBB205_77:                             //   in Loop: Header=BB205_78 Depth=1
	add	x3, x3, #1
	add	x12, x12, x9
	add	x15, x15, x14
	add	x16, x16, x17
	add	x18, x18, x9
	add	x0, x0, x1
	add	x2, x2, x14
	mov	x27, x4
	cmp	x3, x11
	b.eq	.LBB205_73
.LBB205_78:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB205_84 Depth 2
                                        //     Child Loop BB205_80 Depth 2
                                        //       Child Loop BB205_81 Depth 3
	sub	x4, x27, #1
	cmp	x21, #1
	b.ls	.LBB205_83
// %bb.79:                              //   in Loop: Header=BB205_78 Depth=1
	mul	x5, x3, x22
	mov	x8, xzr
	mul	x6, x27, x22
	mov	x7, x2
	mov	x20, x18
.LBB205_80:                             //   Parent Loop BB205_78 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB205_81 Depth 3
	add	x19, x8, x5
	add	x22, x8, x6
	mov	x23, x0
	mov	x24, x20
	mul	x19, x19, x21
	mov	x25, x16
	mul	x22, x22, x21
	mov	x26, x10
	add	x19, x30, x19, lsl #5
	add	x27, x30, x22, lsl #5
	mov	x22, x7
	ldp	q0, q1, [x19]
	ldp	q2, q3, [x27]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x19]
	stp	q0, q1, [x27]
.LBB205_81:                             //   Parent Loop BB205_78 Depth=1
                                        //     Parent Loop BB205_80 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q2, q0, [x24, #-16]
	subs	x26, x26, #1
	ldp	q3, q1, [x22, #-16]
	fadd	v7.4s, v2.4s, v3.4s
	fsub	v2.4s, v2.4s, v3.4s
	fadd	v4.4s, v0.4s, v1.4s
	fsub	v0.4s, v0.4s, v1.4s
	ldp	s5, s1, [x23, #-4]
	ldp	s3, s6, [x25, #-4]
	fneg	v16.4s, v4.4s
	add	x25, x25, #8
	fneg	v17.4s, v0.4s
	add	x23, x23, #8
	fmul	v4.4s, v4.4s, v5.s[0]
	fmul	v0.4s, v0.4s, v3.s[0]
	fmul	v16.4s, v16.4s, v1.s[0]
	fmul	v17.4s, v17.4s, v6.s[0]
	fmla	v4.4s, v7.4s, v1.s[0]
	fmla	v0.4s, v2.4s, v6.s[0]
	fmla	v16.4s, v7.4s, v5.s[0]
	fmla	v17.4s, v2.4s, v3.s[0]
	stp	q16, q4, [x24, #-16]
	add	x24, x24, #32
	stp	q17, q0, [x22, #-16]
	add	x22, x22, #32
	b.ne	.LBB205_81
// %bb.82:                              //   in Loop: Header=BB205_80 Depth=2
	ldur	x22, [x29, #-8]                 // 8-byte Folded Reload
	add	x8, x8, #1
	add	x20, x20, x13
	add	x7, x7, x13
	cmp	x8, x22
	b.ne	.LBB205_80
	b	.LBB205_77
.LBB205_83:                             //   in Loop: Header=BB205_78 Depth=1
	mov	x8, xzr
	mov	x5, x22
.LBB205_84:                             //   Parent Loop BB205_78 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x6, x12, x8
	add	x7, x15, x8
	subs	x5, x5, #1
	add	x8, x8, x13
	ldp	q0, q1, [x6, #-16]
	ldp	q2, q3, [x7]
	fadd	v4.4s, v0.4s, v2.4s
	fsub	v0.4s, v0.4s, v2.4s
	fadd	v5.4s, v1.4s, v3.4s
	fsub	v1.4s, v1.4s, v3.4s
	stp	q4, q5, [x6, #-16]
	stp	q0, q1, [x7]
	b.ne	.LBB205_84
	b	.LBB205_77
.LBB205_85:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.Lfunc_end205:
	.size	_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_, .Lfunc_end205-_ZNK9pocketfft6detail5cfftpIfE5passgILb0ENS0_5cmplxIDv4_fEEEEvmmmPT0_S8_PKNS4_IfEESB_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf // -- Begin function _ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf,@function
_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf: // @_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf
.Lfunc_begin62:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception62
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x21, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp]                        // 16-byte Folded Spill
	cbz	x22, .LBB206_4
// %bb.1:
	lsl	x8, x22, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB206_21
// %bb.2:
	add	x8, x0, #64
	and	x20, x8, #0xffffffffffffffc0
	stur	x0, [x20, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB206_5
.LBB206_3:
	cmp	x8, x22
	b.lo	.LBB206_8
	b	.LBB206_10
.LBB206_4:
	mov	x20, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB206_3
.LBB206_5:
	mov	x9, xzr
	mov	x10, xzr
	add	x11, x21, #16
	add	x12, x20, #16
.LBB206_6:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #80]
	add	x10, x10, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x8, x8, x9
	add	x9, x9, #8
	fneg	v3.4s, v0.4s
	ld1r	{ v1.4s }, [x8], #4
	ldr	s4, [x8]
	fmul	v5.4s, v2.4s, v4.s[0]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v5.4s, v1.4s, v0.4s
	fmla	v3.4s, v1.4s, v2.4s
	stp	q5, q3, [x12, #-16]
	add	x12, x12, #32
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB206_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB206_10
.LBB206_8:
	ldp	q0, q2, [x20]
	movi	v1.2d, #0000000000000000
	add	x9, x20, x8, lsl #5
	add	x9, x9, #16
	fmul	v0.4s, v0.4s, v1.4s
	fmul	v1.4s, v2.4s, v1.4s
.LBB206_9:                              // =>This Inner Loop Header: Depth=1
	stp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	ldr	x10, [x19, #8]
	add	x9, x9, #32
	cmp	x8, x10
	b.lo	.LBB206_9
.LBB206_10:
	add	x22, x19, #16
.Ltmp845:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f
.Ltmp846:
// %bb.11:
	ldr	x8, [x19, #88]
	ldp	q0, q2, [x20]
	ld1r	{ v1.4s }, [x8], #4
	fneg	v3.4s, v2.4s
	fmul	v2.4s, v2.4s, v1.4s
	ldr	s4, [x8]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v2.4s, v0.4s, v4.s[0]
	fmla	v3.4s, v1.4s, v0.4s
	stp	q3, q2, [x20]
	ldr	x12, [x19, #8]
	sub	x8, x12, #3
	cmn	x8, #5
	b.hi	.LBB206_14
// %bb.12:
	mov	x8, xzr
	add	x9, x20, #48
	mov	x10, #-1
	mov	w11, #1
.LBB206_13:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #88]
	add	x11, x11, #1
	ldp	q4, q0, [x9, #-16]
	add	x12, x12, x8
	fneg	v1.4s, v0.4s
	ldp	s3, s2, [x12, #8]
	fmul	v1.4s, v1.4s, v2.s[0]
	fmul	v0.4s, v0.4s, v3.s[0]
	fmla	v1.4s, v4.4s, v3.s[0]
	fmla	v0.4s, v4.4s, v2.s[0]
	stp	q1, q0, [x9, #-16]
	add	x9, x9, #32
	ldr	x12, [x19, #8]
	ldr	x13, [x19, #88]
	add	x12, x10, x12
	sub	x10, x10, #1
	add	x13, x13, x8
	add	x8, x8, #8
	add	x12, x20, x12, lsl #5
	ldp	s3, s2, [x13, #8]
	ldp	q4, q0, [x12]
	fneg	v1.4s, v0.4s
	fmul	v0.4s, v0.4s, v3.s[0]
	fmul	v1.4s, v1.4s, v2.s[0]
	fmla	v0.4s, v4.4s, v2.s[0]
	fmla	v1.4s, v4.4s, v3.s[0]
	stp	q1, q0, [x12]
	ldr	x12, [x19, #8]
	add	x13, x12, #1
	cmp	x11, x13, lsr #1
	b.lo	.LBB206_13
.LBB206_14:
	tbnz	w12, #0, .LBB206_16
// %bb.15:
	lsr	x8, x12, #1
	ldr	x9, [x19, #88]
	add	x10, x20, x8, lsl #5
	add	x8, x9, x8, lsl #3
	ldp	q0, q2, [x10]
	ld1r	{ v1.4s }, [x8], #4
	fneg	v3.4s, v2.4s
	fmul	v2.4s, v2.4s, v1.4s
	ldr	s4, [x8]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v2.4s, v0.4s, v4.s[0]
	fmla	v3.4s, v1.4s, v0.4s
	stp	q3, q2, [x10]
.LBB206_16:
.Ltmp847:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f
.Ltmp848:
// %bb.17:
	ldr	x8, [x19]
	ldr	q6, [sp]                        // 16-byte Folded Reload
	cbz	x8, .LBB206_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
	add	x10, x21, #16
	add	x11, x20, #16
.LBB206_19:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #80]
	add	x9, x9, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x12, x12, x8
	add	x8, x8, #8
	fneg	v3.4s, v0.4s
	ld1r	{ v1.4s }, [x12], #4
	ldr	s4, [x12]
	fmul	v5.4s, v2.4s, v4.s[0]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v5.4s, v1.4s, v0.4s
	fmla	v3.4s, v1.4s, v2.4s
	fmul	v0.4s, v5.4s, v6.s[0]
	fmul	v1.4s, v3.4s, v6.s[0]
	stp	q0, q1, [x10, #-16]
	add	x10, x10, #32
	ldr	x12, [x19]
	cmp	x9, x12
	b.lo	.LBB206_19
.LBB206_20:
	ldur	x0, [x20, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	b	free
.LBB206_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB206_22:
.Ltmp849:
	mov	x19, x0
	ldur	x0, [x20, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end206:
	.size	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf, .Lfunc_end206-_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb1EDv4_fEEvPNS0_5cmplxIT0_EEf,comdat
	.p2align	2
GCC_except_table206:
.Lexception62:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end62-.Lcst_begin62
.Lcst_begin62:
	.uleb128 .Ltmp845-.Lfunc_begin62        // >> Call Site 1 <<
	.uleb128 .Ltmp848-.Ltmp845              //   Call between .Ltmp845 and .Ltmp848
	.uleb128 .Ltmp849-.Lfunc_begin62        //     jumps to .Ltmp849
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp848-.Lfunc_begin62        // >> Call Site 2 <<
	.uleb128 .Lfunc_end206-.Ltmp848         //   Call between .Ltmp848 and .Lfunc_end206
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end62:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf // -- Begin function _ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf,@function
_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf: // @_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf
.Lfunc_begin63:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception63
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x21, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp]                        // 16-byte Folded Spill
	cbz	x22, .LBB207_4
// %bb.1:
	lsl	x8, x22, #5
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB207_21
// %bb.2:
	add	x8, x0, #64
	and	x20, x8, #0xffffffffffffffc0
	stur	x0, [x20, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB207_5
.LBB207_3:
	cmp	x8, x22
	b.lo	.LBB207_8
	b	.LBB207_10
.LBB207_4:
	mov	x20, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB207_3
.LBB207_5:
	mov	x9, xzr
	mov	x10, xzr
	add	x11, x21, #16
	add	x12, x20, #16
.LBB207_6:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #80]
	add	x10, x10, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x8, x8, x9
	add	x9, x9, #8
	ld1r	{ v1.4s }, [x8], #4
	fneg	v3.4s, v2.4s
	fmul	v2.4s, v2.4s, v1.4s
	ldr	s4, [x8]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v2.4s, v0.4s, v4.s[0]
	fmla	v3.4s, v1.4s, v0.4s
	stp	q3, q2, [x12, #-16]
	add	x12, x12, #32
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB207_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB207_10
.LBB207_8:
	ldp	q0, q2, [x20]
	movi	v1.2d, #0000000000000000
	add	x9, x20, x8, lsl #5
	add	x9, x9, #16
	fmul	v0.4s, v0.4s, v1.4s
	fmul	v1.4s, v2.4s, v1.4s
.LBB207_9:                              // =>This Inner Loop Header: Depth=1
	stp	q0, q1, [x9, #-16]
	add	x8, x8, #1
	ldr	x10, [x19, #8]
	add	x9, x9, #32
	cmp	x8, x10
	b.lo	.LBB207_9
.LBB207_10:
	add	x22, x19, #16
.Ltmp850:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIDv4_fEEEEvPT0_f
.Ltmp851:
// %bb.11:
	ldr	x8, [x19, #88]
	ldp	q0, q2, [x20]
	fneg	v3.4s, v0.4s
	ld1r	{ v1.4s }, [x8], #4
	ldr	s4, [x8]
	fmul	v5.4s, v2.4s, v4.s[0]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v5.4s, v1.4s, v0.4s
	fmla	v3.4s, v1.4s, v2.4s
	stp	q5, q3, [x20]
	ldr	x12, [x19, #8]
	sub	x8, x12, #3
	cmn	x8, #5
	b.hi	.LBB207_14
// %bb.12:
	mov	x8, xzr
	add	x9, x20, #48
	mov	x10, #-1
	mov	w11, #1
.LBB207_13:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #88]
	add	x11, x11, #1
	ldp	q0, q1, [x9, #-16]
	add	x12, x12, x8
	fneg	v2.4s, v0.4s
	ldp	s5, s3, [x12, #8]
	fmul	v4.4s, v1.4s, v3.s[0]
	fmul	v2.4s, v2.4s, v3.s[0]
	fmla	v4.4s, v0.4s, v5.s[0]
	fmla	v2.4s, v1.4s, v5.s[0]
	stp	q4, q2, [x9, #-16]
	add	x9, x9, #32
	ldr	x12, [x19, #8]
	ldr	x13, [x19, #88]
	add	x12, x10, x12
	sub	x10, x10, #1
	add	x13, x13, x8
	add	x8, x8, #8
	add	x12, x20, x12, lsl #5
	ldp	s5, s2, [x13, #8]
	ldp	q0, q1, [x12]
	fneg	v3.4s, v0.4s
	fmul	v4.4s, v1.4s, v2.s[0]
	fmul	v2.4s, v3.4s, v2.s[0]
	fmla	v4.4s, v0.4s, v5.s[0]
	fmla	v2.4s, v1.4s, v5.s[0]
	stp	q4, q2, [x12]
	ldr	x12, [x19, #8]
	add	x13, x12, #1
	cmp	x11, x13, lsr #1
	b.lo	.LBB207_13
.LBB207_14:
	tbnz	w12, #0, .LBB207_16
// %bb.15:
	lsr	x8, x12, #1
	ldr	x9, [x19, #88]
	add	x10, x20, x8, lsl #5
	add	x8, x9, x8, lsl #3
	ldp	q0, q2, [x10]
	fneg	v3.4s, v0.4s
	ld1r	{ v1.4s }, [x8], #4
	ldr	s4, [x8]
	fmul	v5.4s, v2.4s, v4.s[0]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v5.4s, v1.4s, v0.4s
	fmla	v3.4s, v1.4s, v2.4s
	stp	q5, q3, [x10]
.LBB207_16:
.Ltmp852:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x20
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIDv4_fEEEEvPT0_f
.Ltmp853:
// %bb.17:
	ldr	x8, [x19]
	ldr	q5, [sp]                        // 16-byte Folded Reload
	cbz	x8, .LBB207_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
	add	x10, x21, #16
	add	x11, x20, #16
.LBB207_19:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [x19, #80]
	add	x9, x9, #1
	ldp	q0, q2, [x11, #-16]
	add	x11, x11, #32
	add	x12, x12, x8
	add	x8, x8, #8
	ld1r	{ v1.4s }, [x12], #4
	fneg	v3.4s, v2.4s
	fmul	v2.4s, v2.4s, v1.4s
	ldr	s4, [x12]
	fmul	v3.4s, v3.4s, v4.s[0]
	fmla	v2.4s, v0.4s, v4.s[0]
	fmla	v3.4s, v1.4s, v0.4s
	fmul	v1.4s, v2.4s, v5.s[0]
	fmul	v0.4s, v3.4s, v5.s[0]
	stp	q0, q1, [x10, #-16]
	add	x10, x10, #32
	ldr	x12, [x19]
	cmp	x9, x12
	b.lo	.LBB207_19
.LBB207_20:
	ldur	x0, [x20, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	b	free
.LBB207_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB207_22:
.Ltmp854:
	mov	x19, x0
	ldur	x0, [x20, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end207:
	.size	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf, .Lfunc_end207-_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb0EDv4_fEEvPNS0_5cmplxIT0_EEf,comdat
	.p2align	2
GCC_except_table207:
.Lexception63:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end63-.Lcst_begin63
.Lcst_begin63:
	.uleb128 .Ltmp850-.Lfunc_begin63        // >> Call Site 1 <<
	.uleb128 .Ltmp853-.Ltmp850              //   Call between .Ltmp850 and .Ltmp853
	.uleb128 .Ltmp854-.Lfunc_begin63        //     jumps to .Ltmp854
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp853-.Lfunc_begin63        // >> Call Site 2 <<
	.uleb128 .Lfunc_end207-.Ltmp853         //   Call between .Ltmp853 and .Lfunc_end207
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end63:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb,"axG",@progbits,_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb,comdat
	.weak	_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb // -- Begin function _ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb
	.p2align	2
	.type	_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb,@function
_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb: // @_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	ldr	x0, [x0]
	cbz	x0, .LBB208_3
// %bb.1:
	tbz	w2, #0, .LBB208_5
// %bb.2:
	b	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
.LBB208_3:
	ldr	x0, [x8, #8]
	tbz	w2, #0, .LBB208_6
// %bb.4:
	b	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf
.LBB208_5:
	b	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f
.LBB208_6:
	b	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf
.Lfunc_end208:
	.size	_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb, .Lfunc_end208-_ZNK9pocketfft6detail11pocketfft_cIfE4execIfEEvPNS0_5cmplxIT_EEfb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf // -- Begin function _ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf,@function
_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf: // @_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf
.Lfunc_begin64:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception64
// %bb.0:
	str	d8, [sp, #-64]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -64
	fmov	s8, s0
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x20, x1
	cbz	x22, .LBB209_4
// %bb.1:
	lsl	x8, x22, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB209_21
// %bb.2:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB209_5
.LBB209_3:
	cmp	x8, x22
	b.lo	.LBB209_8
	b	.LBB209_10
.LBB209_4:
	mov	x21, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB209_3
.LBB209_5:
	mov	x9, xzr
	mov	x10, xzr
.LBB209_6:                              // =>This Inner Loop Header: Depth=1
	add	x11, x20, x9
	ldr	x8, [x19, #80]
	add	x10, x10, #1
	ldp	s0, s1, [x11]
	add	x8, x8, x9
	ldp	s5, s2, [x8]
	fneg	s3, s0
	add	x8, x21, x9
	add	x9, x9, #8
	fmul	s4, s1, s2
	fmul	s2, s2, s3
	fmadd	s0, s0, s5, s4
	fmadd	s1, s1, s5, s2
	str	s0, [x8]
	str	s1, [x8, #4]
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB209_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB209_10
.LBB209_8:
	movi	d0, #0000000000000000
	ldr	d1, [x21]
	fmul	v0.2s, v1.2s, v0.2s
.LBB209_9:                              // =>This Inner Loop Header: Depth=1
	str	d0, [x21, x8, lsl #3]
	add	x8, x8, #1
	ldr	x9, [x19, #8]
	cmp	x8, x9
	b.lo	.LBB209_9
.LBB209_10:
	add	x22, x19, #16
.Ltmp855:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
.Ltmp856:
// %bb.11:
	ldp	s4, s0, [x21]
	ldr	x8, [x19, #88]
	fneg	s1, s0
	ldp	s3, s2, [x8]
	fmul	s1, s2, s1
	fmul	s0, s3, s0
	fmadd	s1, s4, s3, s1
	fmadd	s0, s4, s2, s0
	str	s1, [x21]
	str	s0, [x21, #4]
	ldr	x11, [x19, #8]
	sub	x8, x11, #3
	cmn	x8, #5
	b.hi	.LBB209_14
// %bb.12:
	mov	x8, xzr
	mov	x9, #-1
	mov	w10, #1
.LBB209_13:                             // =>This Inner Loop Header: Depth=1
	add	x11, x21, x8
	ldr	x12, [x19, #88]
	add	x10, x10, #1
	ldp	s4, s0, [x11, #8]
	add	x12, x12, x8
	fneg	s1, s0
	ldp	s3, s2, [x12, #8]
	fmul	s1, s2, s1
	fmul	s0, s3, s0
	fmadd	s1, s4, s3, s1
	fmadd	s0, s4, s2, s0
	stp	s1, s0, [x11, #8]
	ldr	x11, [x19, #8]
	ldr	x12, [x19, #88]
	add	x11, x9, x11
	sub	x9, x9, #1
	add	x12, x12, x8
	add	x8, x8, #8
	add	x11, x21, x11, lsl #3
	ldp	s3, s2, [x12, #8]
	ldp	s4, s0, [x11]
	fneg	s1, s0
	fmul	s0, s3, s0
	fmul	s1, s2, s1
	fmadd	s0, s4, s2, s0
	fmadd	s1, s4, s3, s1
	stp	s1, s0, [x11]
	ldr	x11, [x19, #8]
	add	x12, x11, #1
	cmp	x10, x12, lsr #1
	b.lo	.LBB209_13
.LBB209_14:
	tbnz	w11, #0, .LBB209_16
// %bb.15:
	lsl	x8, x11, #2
	ldr	x10, [x19, #88]
	and	x8, x8, #0xfffffffffffffff8
	add	x9, x21, x8
	add	x8, x10, x8
	ldp	s4, s0, [x9]
	ldp	s3, s2, [x8]
	fneg	s1, s0
	fmul	s0, s3, s0
	fmul	s1, s2, s1
	fmadd	s0, s4, s2, s0
	fmadd	s1, s4, s3, s1
	str	s0, [x9, #4]
	str	s1, [x9]
.LBB209_16:
.Ltmp857:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f
.Ltmp858:
// %bb.17:
	ldr	x8, [x19]
	cbz	x8, .LBB209_20
// %bb.18:
	mov	x8, xzr
	mov	x9, xzr
.LBB209_19:                             // =>This Inner Loop Header: Depth=1
	add	x11, x21, x8
	ldr	x10, [x19, #80]
	add	x9, x9, #1
	ldp	s0, s1, [x11]
	add	x10, x10, x8
	ldp	s5, s2, [x10]
	fneg	s3, s0
	add	x10, x20, x8
	add	x8, x8, #8
	fmul	s4, s1, s2
	fmul	s2, s2, s3
	fmadd	s0, s0, s5, s4
	fmadd	s1, s1, s5, s2
	fmul	s0, s0, s8
	fmul	s1, s1, s8
	str	s0, [x10]
	str	s1, [x10, #4]
	ldr	x10, [x19]
	cmp	x9, x10
	b.lo	.LBB209_19
.LBB209_20:
	ldur	x0, [x21, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #64                   // 8-byte Folded Reload
	b	free
.LBB209_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB209_22:
.Ltmp859:
	mov	x19, x0
	ldur	x0, [x21, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end209:
	.size	_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf, .Lfunc_end209-_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb1EfEEvPNS0_5cmplxIT0_EEf,comdat
	.p2align	2
GCC_except_table209:
.Lexception64:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end64-.Lcst_begin64
.Lcst_begin64:
	.uleb128 .Ltmp855-.Lfunc_begin64        // >> Call Site 1 <<
	.uleb128 .Ltmp858-.Ltmp855              //   Call between .Ltmp855 and .Ltmp858
	.uleb128 .Ltmp859-.Lfunc_begin64        //     jumps to .Ltmp859
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp858-.Lfunc_begin64        // >> Call Site 2 <<
	.uleb128 .Lfunc_end209-.Ltmp858         //   Call between .Ltmp858 and .Lfunc_end209
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end64:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf,"axG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf,comdat
	.weak	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf // -- Begin function _ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf
	.p2align	2
	.type	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf,@function
_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf: // @_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf
.Lfunc_begin65:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception65
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	ldr	x22, [x0, #8]
	mov	x20, x1
                                        // kill: def $s0 killed $s0 def $q0
	str	q0, [sp]                        // 16-byte Folded Spill
	cbz	x22, .LBB210_4
// %bb.1:
	lsl	x8, x22, #3
	add	x0, x8, #64
	bl	malloc
	cbz	x0, .LBB210_21
// %bb.2:
	add	x8, x0, #64
	and	x21, x8, #0xffffffffffffffc0
	stur	x0, [x21, #-8]
	ldr	x8, [x19]
	cbnz	x8, .LBB210_5
.LBB210_3:
	cmp	x8, x22
	b.lo	.LBB210_8
	b	.LBB210_10
.LBB210_4:
	mov	x21, xzr
	ldr	x8, [x19]
	cbz	x8, .LBB210_3
.LBB210_5:
	mov	x9, xzr
	mov	x10, xzr
.LBB210_6:                              // =>This Inner Loop Header: Depth=1
	add	x8, x20, x9
	ldr	x11, [x19, #80]
	add	x10, x10, #1
	ldp	s4, s0, [x8]
	add	x11, x11, x9
	add	x8, x21, x9
	add	x9, x9, #8
	fneg	s1, s0
	ldp	s3, s2, [x11]
	fmul	s1, s2, s1
	fmul	s0, s3, s0
	fmadd	s1, s4, s3, s1
	fmadd	s0, s4, s2, s0
	str	s1, [x8]
	str	s0, [x8, #4]
	ldr	x8, [x19]
	cmp	x10, x8
	b.lo	.LBB210_6
// %bb.7:
	ldr	x22, [x19, #8]
	cmp	x8, x22
	b.hs	.LBB210_10
.LBB210_8:
	movi	d0, #0000000000000000
	ldr	d1, [x21]
	fmul	v0.2s, v1.2s, v0.2s
.LBB210_9:                              // =>This Inner Loop Header: Depth=1
	str	d0, [x21, x8, lsl #3]
	add	x8, x8, #1
	ldr	x9, [x19, #8]
	cmp	x8, x9
	b.lo	.LBB210_9
.LBB210_10:
	add	x22, x19, #16
.Ltmp860:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb1ENS0_5cmplxIfEEEEvPT0_f
.Ltmp861:
// %bb.11:
	ldp	s0, s1, [x21]
	ldr	x8, [x19, #88]
	ldp	s5, s2, [x8]
	fneg	s3, s0
	fmul	s4, s1, s2
	fmul	s2, s2, s3
	fmadd	s0, s0, s5, s4
	fmadd	s1, s1, s5, s2
	str	s0, [x21]
	str	s1, [x21, #4]
	ldr	x11, [x19, #8]
	sub	x8, x11, #3
	cmn	x8, #5
	b.hi	.LBB210_14
// %bb.12:
	mov	x8, xzr
	mov	x9, #-1
	mov	w10, #1
.LBB210_13:                             // =>This Inner Loop Header: Depth=1
	add	x12, x21, x8
	ldr	x11, [x19, #88]
	add	x10, x10, #1
	ldp	s0, s1, [x12, #8]
	add	x11, x11, x8
	ldp	s5, s2, [x11, #8]
	fneg	s3, s0
	fmul	s4, s1, s2
	fmul	s2, s2, s3
	fmadd	s0, s0, s5, s4
	fmadd	s1, s1, s5, s2
	stp	s0, s1, [x12, #8]
	ldr	x11, [x19, #8]
	ldr	x12, [x19, #88]
	add	x11, x9, x11
	sub	x9, x9, #1
	add	x12, x12, x8
	add	x8, x8, #8
	add	x11, x21, x11, lsl #3
	ldp	s5, s2, [x12, #8]
	ldp	s0, s1, [x11]
	fneg	s3, s0
	fmul	s4, s1, s2
	fmul	s2, s2, s3
	fmadd	s0, s0, s5, s4
	fmadd	s1, s1, s5, s2
	stp	s0, s1, [x11]
	ldr	x11, [x19, #8]
	add	x12, x11, #1
	cmp	x10, x12, lsr #1
	b.lo	.LBB210_13
.LBB210_14:
	tbnz	w11, #0, .LBB210_16
// %bb.15:
	lsl	x8, x11, #2
	ldr	x9, [x19, #88]
	and	x8, x8, #0xfffffffffffffff8
	add	x10, x21, x8
	add	x8, x9, x8
	ldp	s0, s1, [x10]
	ldp	s5, s2, [x8]
	fneg	s3, s0
	fmul	s4, s1, s2
	fmul	s2, s2, s3
	fmadd	s0, s0, s5, s4
	fmadd	s1, s1, s5, s2
	str	s0, [x10]
	str	s1, [x10, #4]
.LBB210_16:
.Ltmp862:
	fmov	s0, #1.00000000
	mov	x0, x22
	mov	x1, x21
	bl	_ZNK9pocketfft6detail5cfftpIfE8pass_allILb0ENS0_5cmplxIfEEEEvPT0_f
.Ltmp863:
// %bb.17:
	ldr	x8, [x19]
	ldr	q3, [sp]                        // 16-byte Folded Reload
	cbz	x8, .LBB210_20
// %bb.18:
	mov	x8, xzr
	add	x9, x21, #4
.LBB210_19:                             // =>This Inner Loop Header: Depth=1
	ldr	s0, [x9]
	lsl	x10, x8, #3
	ldr	x11, [x19, #80]
	add	x8, x8, #1
	fneg	s1, s0
	ldr	d2, [x11, x10]
	mov	v0.s[1], v1.s[0]
	ldur	s1, [x9, #-4]
	add	x9, x9, #8
	fmul	v0.2s, v2.2s, v0.2s
	rev64	v0.2s, v0.2s
	fmla	v0.2s, v2.2s, v1.s[0]
	fmul	v0.2s, v0.2s, v3.s[0]
	str	d0, [x20, x10]
	ldr	x10, [x19]
	cmp	x8, x10
	b.lo	.LBB210_19
.LBB210_20:
	ldur	x0, [x21, #-8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	b	free
.LBB210_21:
	mov	w0, #8
	bl	__cxa_allocate_exception
	adrp	x8, :got:_ZTVSt9bad_alloc
	adrp	x1, :got:_ZTISt9bad_alloc
	adrp	x2, :got:_ZNSt9bad_allocD1Ev
	ldr	x8, [x8, :got_lo12:_ZTVSt9bad_alloc]
	add	x8, x8, #16
	str	x8, [x0]
	ldr	x1, [x1, :got_lo12:_ZTISt9bad_alloc]
	ldr	x2, [x2, :got_lo12:_ZNSt9bad_allocD1Ev]
	bl	__cxa_throw
.LBB210_22:
.Ltmp864:
	mov	x19, x0
	ldur	x0, [x21, #-8]
	bl	free
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end210:
	.size	_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf, .Lfunc_end210-_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf
	.cfi_endproc
	.section	.gcc_except_table._ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf,"aG",@progbits,_ZNK9pocketfft6detail7fftblueIfE3fftILb0EfEEvPNS0_5cmplxIT0_EEf,comdat
	.p2align	2
GCC_except_table210:
.Lexception65:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end65-.Lcst_begin65
.Lcst_begin65:
	.uleb128 .Ltmp860-.Lfunc_begin65        // >> Call Site 1 <<
	.uleb128 .Ltmp863-.Ltmp860              //   Call between .Ltmp860 and .Ltmp863
	.uleb128 .Ltmp864-.Lfunc_begin65        //     jumps to .Ltmp864
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp863-.Lfunc_begin65        // >> Call Site 2 <<
	.uleb128 .Lfunc_end210-.Ltmp863         //   Call between .Ltmp863 and .Lfunc_end210
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end65:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,"axG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,comdat
	.weak	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data // -- Begin function _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.p2align	2
	.type	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data,@function
_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data: // @_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.cfi_startproc
// %bb.0:
	ldr	x0, [x0]
	b	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
.Lfunc_end211:
	.size	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data, .Lfunc_end211-_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,"axG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,comdat
	.weak	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation // -- Begin function _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.p2align	2
	.type	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,@function
_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation: // @_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	cmp	w2, #3
	b.hi	.LBB212_3
// %bb.1:
	adrp	x9, .LJTI212_0
	mov	w8, w2
	add	x9, x9, :lo12:.LJTI212_0
	mov	x19, x0
	adr	x10, .LBB212_2
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB212_2:
	adrp	x8, _ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	add	x8, x8, :lo12:_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	str	x8, [x19]
.LBB212_3:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB212_4:
	ldr	x8, [x1]
	str	x8, [x19]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB212_5:
	mov	w0, #48
	ldr	x20, [x1]
	bl	_Znwm
	ldp	q0, q1, [x20]
	ldr	q2, [x20, #32]
	stp	q0, q1, [x0]
	str	x0, [x19]
	str	q2, [x0, #32]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB212_6:
	ldr	x0, [x19]
	cbz	x0, .LBB212_3
// %bb.7:
	bl	_ZdlPv
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end212:
	.size	_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation, .Lfunc_end212-_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.cfi_endproc
	.section	.rodata._ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,"aG",@progbits,_ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation,comdat
.LJTI212_0:
	.byte	(.LBB212_2-.LBB212_2)>>2
	.byte	(.LBB212_4-.LBB212_2)>>2
	.byte	(.LBB212_5-.LBB212_2)>>2
	.byte	(.LBB212_6-.LBB212_2)>>2
                                        // -- End function
	.section	.text._ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,"axG",@progbits,_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,comdat
	.weak	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv // -- Begin function _ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
	.p2align	2
	.type	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,@function
_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv: // @_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
.Lfunc_begin66:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception66
// %bb.0:
	sub	sp, sp, #48
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mrs	x8, TPIDR_EL0
	mov	x19, x0
	ldp	x10, x11, [x0, #32]
	add	x9, x8, :tprel_hi12:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x8, x8, :tprel_hi12:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	add	x9, x9, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	add	x8, x8, :tprel_lo12_nc:_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	ldr	x0, [x0]
	str	x10, [x9]
	str	x11, [x8]
.Ltmp865:
	bl	_ZZN9pocketfft6detail10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrIS8_EERKSt6vectorImSaImEET1_mRKT2_bENKUlvE_clEv
.Ltmp866:
// %bb.1:
	ldr	x20, [x19, #8]
	add	x19, x20, #8
	mov	x0, x19
	bl	pthread_mutex_lock
	cbnz	w0, .LBB213_11
.LBB213_2:
	mov	x0, #-1
	mov	x1, x20
	bl	__aarch64_ldadd8_acq_rel
	cmp	x0, #1
	b.ne	.LBB213_4
// %bb.3:
	add	x0, x20, #56
	bl	_ZNSt18condition_variable10notify_allEv
.LBB213_4:
	mov	x0, x19
	bl	pthread_mutex_unlock
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #48
	ret
.LBB213_5:
.Ltmp867:
	bl	__cxa_begin_catch
	ldr	x20, [x19, #24]
	mov	x0, x20
	bl	pthread_mutex_lock
	cbnz	w0, .LBB213_12
// %bb.6:
	mov	x8, sp
	bl	_ZSt17current_exceptionv
	ldr	x8, [x19, #16]
	ldr	x9, [sp]
	str	xzr, [sp]
	ldr	x10, [x8]
	str	x10, [sp, #8]
	str	x9, [x8]
	cbz	x10, .LBB213_8
// %bb.7:
	add	x0, sp, #8
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB213_8:
	ldr	x8, [sp]
	cbz	x8, .LBB213_10
// %bb.9:
	mov	x0, sp
	bl	_ZNSt15__exception_ptr13exception_ptr10_M_releaseEv
.LBB213_10:
	mov	x0, x20
	bl	pthread_mutex_unlock
	bl	__cxa_end_catch
	ldr	x20, [x19, #8]
	add	x19, x20, #8
	mov	x0, x19
	bl	pthread_mutex_lock
	cbz	w0, .LBB213_2
.LBB213_11:
	bl	_ZSt20__throw_system_errori
.LBB213_12:
.Ltmp868:
	bl	_ZSt20__throw_system_errori
.Ltmp869:
// %bb.13:
.LBB213_14:
.Ltmp870:
	mov	x19, x0
.Ltmp871:
	bl	__cxa_end_catch
.Ltmp872:
// %bb.15:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB213_16:
.Ltmp873:
	bl	__clang_call_terminate
.Lfunc_end213:
	.size	_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv, .Lfunc_end213-_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv
	.cfi_endproc
	.section	.gcc_except_table._ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,"aG",@progbits,_ZZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_ENKUlvE_clEv,comdat
	.p2align	2
GCC_except_table213:
.Lexception66:
	.byte	255                             // @LPStart Encoding = omit
	.byte	156                             // @TType Encoding = indirect pcrel sdata8
	.uleb128 .Lttbase14-.Lttbaseref14
.Lttbaseref14:
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end66-.Lcst_begin66
.Lcst_begin66:
	.uleb128 .Ltmp865-.Lfunc_begin66        // >> Call Site 1 <<
	.uleb128 .Ltmp866-.Ltmp865              //   Call between .Ltmp865 and .Ltmp866
	.uleb128 .Ltmp867-.Lfunc_begin66        //     jumps to .Ltmp867
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp866-.Lfunc_begin66        // >> Call Site 2 <<
	.uleb128 .Ltmp868-.Ltmp866              //   Call between .Ltmp866 and .Ltmp868
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp868-.Lfunc_begin66        // >> Call Site 3 <<
	.uleb128 .Ltmp869-.Ltmp868              //   Call between .Ltmp868 and .Ltmp869
	.uleb128 .Ltmp870-.Lfunc_begin66        //     jumps to .Ltmp870
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp871-.Lfunc_begin66        // >> Call Site 4 <<
	.uleb128 .Ltmp872-.Ltmp871              //   Call between .Ltmp871 and .Ltmp872
	.uleb128 .Ltmp873-.Lfunc_begin66        //     jumps to .Ltmp873
	.byte	1                               //   On action: 1
	.uleb128 .Ltmp872-.Lfunc_begin66        // >> Call Site 5 <<
	.uleb128 .Lfunc_end213-.Ltmp872         //   Call between .Ltmp872 and .Lfunc_end213
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end66:
	.byte	1                               // >> Action Record 1 <<
                                        //   Catch TypeInfo 1
	.byte	0                               //   No further actions
	.p2align	2
                                        // >> Catch TypeInfos <<
	.xword	0                               // TypeInfo 1
.Lttbase14:
	.p2align	2
                                        // -- End function
	.section	.text.startup,"ax",@progbits
	.p2align	2                               // -- Begin function _GLOBAL__sub_I_pocketfft_demo.cc
	.type	_GLOBAL__sub_I_pocketfft_demo.cc,@function
_GLOBAL__sub_I_pocketfft_demo.cc:       // @_GLOBAL__sub_I_pocketfft_demo.cc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x19, .L_MergedGlobals
	add	x19, x19, :lo12:.L_MergedGlobals
	mov	x0, x19
	bl	_ZNSt8ios_base4InitC1Ev
	adrp	x0, :got:_ZNSt8ios_base4InitD1Ev
	adrp	x2, __dso_handle
	add	x2, x2, :lo12:__dso_handle
	mov	x1, x19
	ldr	x0, [x0, :got_lo12:_ZNSt8ios_base4InitD1Ev]
	bl	__cxa_atexit
	bl	_ZNSt6thread20hardware_concurrencyEv
	cmp	w0, #1
	csinc	w8, w0, wzr, hi
	str	x8, [x19, #8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end214:
	.size	_GLOBAL__sub_I_pocketfft_demo.cc, .Lfunc_end214-_GLOBAL__sub_I_pocketfft_demo.cc
	.cfi_endproc
                                        // -- End function
	.hidden	__dso_handle
	.type	.L.str,@object                  // @.str
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str:
	.asciz	"cannot create std::vector larger than max_size()"
	.size	.L.str, 49

	.type	.L.str.2,@object                // @.str.2
.L.str.2:
	.asciz	"vector::_M_realloc_insert"
	.size	.L.str.2, 26

	.type	.L.str.3,@object                // @.str.3
.L.str.3:
	.asciz	"bad axis number"
	.size	.L.str.3, 16

	.type	.L.str.4,@object                // @.str.4
.L.str.4:
	.asciz	"axis specified repeatedly"
	.size	.L.str.4, 26

	.type	.L.str.5,@object                // @.str.5
.L.str.5:
	.asciz	"ndim must be >= 1"
	.size	.L.str.5, 18

	.type	.L.str.6,@object                // @.str.6
.L.str.6:
	.asciz	"stride dimension mismatch"
	.size	.L.str.6, 26

	.type	.L.str.7,@object                // @.str.7
.L.str.7:
	.asciz	"stride mismatch"
	.size	.L.str.7, 16

	.type	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 101

	.type	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE, 52

	.type	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE, 47

	.type	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE, 16

	.type	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	.L.str.8,@object                // @.str.8
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.8:
	.asciz	"zero-length FFT requested"
	.size	.L.str.8, 26

	.type	_ZTSSt19_Sp_make_shared_tag,@object // @_ZTSSt19_Sp_make_shared_tag
	.section	.rodata._ZTSSt19_Sp_make_shared_tag,"aG",@progbits,_ZTSSt19_Sp_make_shared_tag,comdat
	.weak	_ZTSSt19_Sp_make_shared_tag
_ZTSSt19_Sp_make_shared_tag:
	.asciz	"St19_Sp_make_shared_tag"
	.size	_ZTSSt19_Sp_make_shared_tag, 24

	.type	_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag,@object // @_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	.section	.rodata._ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag,"aG",@progbits,_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag,comdat
	.weak	_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	.p2align	3
_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag:
	.zero	16
	.size	_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag, 16

	.type	.L.str.9,@object                // @.str.9
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.9:
	.asciz	"can't run with zero threads"
	.size	.L.str.9, 28

	.type	.L.str.10,@object               // @.str.10
.L.str.10:
	.asciz	"impossible share requested"
	.size	.L.str.10, 27

	.type	_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_,@object // @_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	.section	.tdata._ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_,"aGwT",@progbits,_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_,comdat
	.weak	_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_
	.p2align	3
_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_:
	.xword	1                               // 0x1
	.size	_ZZN9pocketfft6detail9threading11num_threadsEvE12num_threads_, 8

	.type	_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_,@object // @_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	.section	.tbss._ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_,"aGwT",@nobits,_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_,comdat
	.weak	_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_
	.p2align	3
_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_:
	.xword	0                               // 0x0
	.size	_ZZN9pocketfft6detail9threading9thread_idEvE10thread_id_, 8

	.type	.L.str.11,@object               // @.str.11
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.11:
	.asciz	"underrun"
	.size	.L.str.11, 9

	.type	_ZZN9pocketfft6detail9threading8get_poolEvE4pool,@object // @_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	.section	.bss._ZZN9pocketfft6detail9threading8get_poolEvE4pool,"aGw",@nobits,_ZZN9pocketfft6detail9threading8get_poolEvE4pool,comdat
	.weak	_ZZN9pocketfft6detail9threading8get_poolEvE4pool
	.p2align	3
_ZZN9pocketfft6detail9threading8get_poolEvE4pool:
	.zero	224
	.size	_ZZN9pocketfft6detail9threading8get_poolEvE4pool, 224

	.type	_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool,@object // @_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	.section	.bss._ZGVZN9pocketfft6detail9threading8get_poolEvE4pool,"aGw",@nobits,_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool,comdat
	.weak	_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	.p2align	3
_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool:
	.xword	0                               // 0x0
	.size	_ZGVZN9pocketfft6detail9threading8get_poolEvE4pool, 8

	.type	_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,@object // @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.section	.data.rel.ro._ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,"aGw",@progbits,_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,comdat
	.weak	_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.p2align	3
_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE:
	.xword	0
	.xword	_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.xword	_ZNSt6thread6_StateD2Ev
	.xword	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEED0Ev
	.xword	_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEE6_M_runEv
	.size	_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE, 40

	.type	_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,@object // @_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.section	.rodata._ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,"aG",@progbits,_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,comdat
	.weak	_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE:
	.asciz	"NSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE"
	.size	_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE, 120

	.type	_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,@object // @_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.section	.data.rel.ro._ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,"aGw",@progbits,_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE,comdat
	.weak	_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.p2align	3
_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.xword	_ZTINSt6thread6_StateE
	.size	_ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE, 24

	.type	.L.str.12,@object               // @.str.12
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.12:
	.asciz	"Work item submitted after shutdown"
	.size	.L.str.12, 35

	.type	.L.str.13,@object               // @.str.13
.L.str.13:
	.asciz	"cannot create std::deque larger than max_size()"
	.size	.L.str.13, 48

	.type	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,@object // @_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.section	.rodata._ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,"aG",@progbits,_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,comdat
	.weak	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_:
	.asciz	"ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_"
	.size	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_, 196

	.type	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,@object // @_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.section	.data.rel.ro._ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,"aGw",@progbits,_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,comdat
	.weak	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.p2align	3
_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.size	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_, 16

	.type	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 101

	.type	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,@object // @_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.section	.rodata._ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,"aG",@progbits,_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,comdat
	.weak	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_:
	.asciz	"ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_"
	.size	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_, 196

	.type	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,@object // @_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.section	.data.rel.ro._ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,"aGw",@progbits,_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,comdat
	.weak	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.p2align	3
_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.size	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_, 16

	.type	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 101

	.type	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,@object // @_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.section	.rodata._ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,"aG",@progbits,_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,comdat
	.weak	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_:
	.asciz	"ZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_"
	.size	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_, 196

	.type	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,@object // @_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.section	.data.rel.ro._ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,"aGw",@progbits,_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_,comdat
	.weak	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.p2align	3
_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.size	_ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_, 16

	.section	.init_array,"aw",@init_array
	.p2align	3
	.xword	_GLOBAL__sub_I_pocketfft_demo.cc
	.type	.L_MergedGlobals,@object        // @_MergedGlobals
	.local	.L_MergedGlobals
	.comm	.L_MergedGlobals,16,8
	.hidden	DW.ref.__gxx_personality_v0
	.weak	DW.ref.__gxx_personality_v0
	.section	.data.DW.ref.__gxx_personality_v0,"aGw",@progbits,DW.ref.__gxx_personality_v0,comdat
	.p2align	3
	.type	DW.ref.__gxx_personality_v0,@object
	.size	DW.ref.__gxx_personality_v0, 8
DW.ref.__gxx_personality_v0:
	.xword	__gxx_personality_v0
.set _ZStL8__ioinit, .L_MergedGlobals
	.size	_ZStL8__ioinit, 1
.set _ZN9pocketfft6detail9threadingL11max_threadsE, .L_MergedGlobals+8
	.size	_ZN9pocketfft6detail9threadingL11max_threadsE, 8
	.ident	"Ubuntu clang version 14.0.0-1ubuntu1"
	.section	".note.GNU-stack","",@progbits
	.addrsig
	.addrsig_sym __gxx_personality_v0
	.addrsig_sym _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.addrsig_sym _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIeEENS2_5cmplxIeEEeNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.addrsig_sym _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.addrsig_sym _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIdEENS2_5cmplxIdEEdNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.addrsig_sym _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E9_M_invokeERKSt9_Any_data
	.addrsig_sym _ZNSt17_Function_handlerIFvvEZN9pocketfft6detail9threading10thread_mapIZNS2_10general_ndINS2_11pocketfft_cIfEENS2_5cmplxIfEEfNS2_7ExecC2CEEEvRKNS2_6cndarrIT0_EERNS2_5ndarrISC_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_E10_M_managerERSt9_Any_dataRKSW_St18_Manager_operation
	.addrsig_sym _GLOBAL__sub_I_pocketfft_demo.cc
	.addrsig_sym _Unwind_Resume
	.addrsig_sym __dso_handle
	.addrsig_sym _ZSt4cout
	.addrsig_sym _ZTISt16invalid_argument
	.addrsig_sym _ZTISt13runtime_error
	.addrsig_sym _ZTVN10__cxxabiv120__si_class_type_infoE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTVN10__cxxabiv117__class_type_infoE
	.addrsig_sym _ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIeEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt9bad_alloc
	.addrsig_sym _ZTSSt19_Sp_make_shared_tag
	.addrsig_sym _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	.addrsig_sym _ZZN9pocketfft6detail9threading8get_poolEvE4pool
	.addrsig_sym _ZGVZN9pocketfft6detail9threading8get_poolEvE4pool
	.addrsig_sym _ZTSNSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.addrsig_sym _ZTINSt6thread6_StateE
	.addrsig_sym _ZTINSt6thread11_State_implINS_8_InvokerISt5tupleIJZN9pocketfft6detail9threading11thread_pool14create_threadsEvEUlvE_EEEEEE
	.addrsig_sym _ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.addrsig_sym _ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIeEENS0_5cmplxIeEEeNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIdEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.addrsig_sym _ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIdEENS0_5cmplxIdEEdNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceIN9pocketfft6detail11pocketfft_cIfEESaIS3_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.addrsig_sym _ZTIZN9pocketfft6detail9threading10thread_mapIZNS0_10general_ndINS0_11pocketfft_cIfEENS0_5cmplxIfEEfNS0_7ExecC2CEEEvRKNS0_6cndarrIT0_EERNS0_5ndarrISA_EERKSt6vectorImSaImEET1_mRKT2_bEUlvE_EEvmT_EUlvE_
	.addrsig_sym .L_MergedGlobals
