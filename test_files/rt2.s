	.text
	.file	"main.cc"
	.globl	_Z15surrounding_box4aabbS_      // -- Begin function _Z15surrounding_box4aabbS_
	.p2align	2
	.type	_Z15surrounding_box4aabbS_,@function
_Z15surrounding_box4aabbS_:             // @_Z15surrounding_box4aabbS_
	.cfi_startproc
// %bb.0:
	ldp	d0, d1, [x0]
	ldp	d2, d3, [x1]
	ldp	d4, d5, [x0, #16]
	fminnm	d0, d0, d2
	ldp	d16, d2, [x1, #16]
	fminnm	d1, d1, d3
	ldp	d6, d7, [x0, #32]
	str	d0, [x8]
	fminnm	d4, d4, d16
	ldp	d3, d16, [x1, #32]
	fmaxnm	d2, d5, d2
	str	d1, [x8, #8]
	str	d4, [x8, #16]
	fmaxnm	d3, d6, d3
	fmaxnm	d0, d7, d16
	str	d2, [x8, #24]
	str	d3, [x8, #32]
	str	d0, [x8, #40]
	ret
.Lfunc_end0:
	.size	_Z15surrounding_box4aabbS_, .Lfunc_end0-_Z15surrounding_box4aabbS_
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK9translate3hitERK3rayddR10hit_record // -- Begin function _ZNK9translate3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK9translate3hitERK3rayddR10hit_record,@function
_ZNK9translate3hitERK3rayddR10hit_record: // @_ZNK9translate3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #96
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	q2, [x1]
	mov	x20, x0
	ldr	d3, [x1, #16]
	mov	x19, x2
	ldur	q4, [x0, #24]
	ldr	d5, [x0, #40]
	ldr	x0, [x0, #8]
	fsub	v2.2d, v2.2d, v4.2d
	ldur	q4, [x1, #24]
	fsub	d3, d3, d5
	ldur	q5, [x1, #40]
	mov	x1, sp
	stur	q4, [sp, #24]
	str	q2, [sp]
	str	d3, [sp, #16]
	stur	q5, [sp, #40]
	ldr	x8, [x0]
	ldr	x8, [x8]
	blr	x8
	tbz	w0, #0, .LBB1_2
// %bb.1:
	ldp	d2, d5, [x19]
	ldr	d0, [x20, #24]
	ldp	d4, d1, [sp, #24]
	fadd	d0, d0, d2
	ldr	d6, [x19, #24]
	ldp	d3, d2, [x19, #32]
	str	d0, [x19]
	fmul	d1, d1, d3
	fneg	d7, d2
	fmadd	d0, d4, d6, d1
	ldr	d1, [x20, #32]
	ldr	d4, [sp, #40]
	fadd	d1, d1, d5
	fneg	d5, d6
	fmadd	d0, d4, d2, d0
	ldr	d4, [x19, #16]
	str	d1, [x19, #8]
	fneg	d1, d3
	fcmp	d0, #0.0
	ldr	d0, [x20, #40]
	fadd	d0, d0, d4
	fcsel	d4, d6, d5, mi
	fcsel	d1, d3, d1, mi
	fcsel	d2, d2, d7, mi
	cset	w8, mi
	stp	d0, d4, [x19, #16]
	strb	w8, [x19, #88]
	stp	d1, d2, [x19, #32]
.LBB1_2:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	and	w0, w0, #0x1
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #96
	ret
.Lfunc_end1:
	.size	_ZNK9translate3hitERK3rayddR10hit_record, .Lfunc_end1-_ZNK9translate3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK9translate12bounding_boxEddR4aabb // -- Begin function _ZNK9translate12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK9translate12bounding_boxEddR4aabb,@function
_ZNK9translate12bounding_boxEddR4aabb:  // @_ZNK9translate12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x20, x0
	ldr	x0, [x0, #8]
	mov	x19, x1
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
	blr	x8
	tbz	w0, #0, .LBB2_2
// %bb.1:
	ldur	q0, [x20, #24]
	ldr	d1, [x20, #40]
	ldp	q2, q3, [x19]
	dup	v4.2d, v0.d[1]
	zip1	v5.2d, v1.2d, v0.2d
	mov	v4.d[1], v1.d[0]
	fadd	v0.2d, v2.2d, v0.2d
	ldr	q1, [x19, #32]
	fadd	v2.2d, v5.2d, v3.2d
	fadd	v1.2d, v4.2d, v1.2d
	stp	q0, q2, [x19]
	str	q1, [x19, #32]
.LBB2_2:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	and	w0, w0, #0x1
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end2:
	.size	_ZNK9translate12bounding_boxEddR4aabb, .Lfunc_end2-_ZNK9translate12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZN8rotate_yC2ESt10shared_ptrI8hittableEd
.LCPI3_0:
	.xword	0x400921fb54442d18              // double 3.1415926535897931
	.text
	.globl	_ZN8rotate_yC2ESt10shared_ptrI8hittableEd
	.p2align	2
	.type	_ZN8rotate_yC2ESt10shared_ptrI8hittableEd,@function
_ZN8rotate_yC2ESt10shared_ptrI8hittableEd: // @_ZN8rotate_yC2ESt10shared_ptrI8hittableEd
.Lfunc_begin0:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception0
// %bb.0:
	str	d8, [sp, #-48]!                 // 8-byte Folded Spill
	stp	x29, x30, [sp, #8]              // 16-byte Folded Spill
	add	x29, sp, #8
	str	x21, [sp, #24]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 40
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w30, -32
	.cfi_offset w29, -40
	.cfi_offset b8, -48
	ldp	x10, x8, [x1]
	fmov	d8, d0
	adrp	x9, _ZTV8rotate_y+16
	mov	x19, x0
	add	x9, x9, :lo12:_ZTV8rotate_y+16
	mov	x20, x0
	str	x9, [x0]
	str	x10, [x20, #8]!
	str	x8, [x0, #16]
	cbz	x8, .LBB3_4
// %bb.1:
	adrp	x9, :got:__libc_single_threaded
	ldr	x9, [x9, :got_lo12:__libc_single_threaded]
	ldrb	w9, [x9]
	cbz	w9, .LBB3_3
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB3_4
.LBB3_3:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB3_4:
	adrp	x8, .LCPI3_0
	mov	x21, x19
	ldr	d0, [x8, :lo12:.LCPI3_0]
	mov	x8, #140737488355328
	movk	x8, #16486, lsl #48
	fmul	d0, d8, d0
	fmov	d1, x8
	fdiv	d8, d0, d1
	movi	v0.2d, #0000000000000000
	str	q0, [x21, #48]!
	stp	q0, q0, [x21, #16]
	fmov	d0, d8
	bl	sin
	stur	d0, [x21, #-24]
	fmov	d0, d8
	bl	cos
	ldur	x0, [x21, #-40]
	stur	d0, [x21, #-16]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp0:
	movi	d0, #0000000000000000
	fmov	d1, #1.00000000
	mov	x1, x21
	movi	d8, #0000000000000000
	blr	x8
.Ltmp1:
// %bb.5:
	ldp	d1, d2, [x19, #64]
	mov	x8, #9218868437227405312
	ldp	d26, d0, [x19, #80]
	ldp	d6, d5, [x19, #24]
	ldp	d3, d7, [x19, #48]
	fmadd	d4, d0, d8, d1
	fmul	d1, d1, d8
	ldp	x29, x30, [sp, #8]              // 16-byte Folded Reload
	fmadd	d16, d2, d8, d3
	fmul	d3, d3, d8
	fmul	d17, d6, d4
	fadd	d0, d0, d1
	fmul	d1, d5, d4
	fmov	d4, x8
	mov	x8, #-4503599627370496
	fmadd	d28, d26, d8, d7
	fadd	d2, d2, d3
	fmul	d7, d7, d8
	fmadd	d18, d5, d16, d17
	fmul	d19, d6, d0
	fmsub	d20, d6, d16, d1
	fmul	d0, d5, d0
	fmov	d21, x8
	and	w8, w0, #0x1
	fmadd	d17, d5, d2, d17
	fmsub	d1, d6, d2, d1
	fminnm	d22, d18, d4
	fmadd	d23, d5, d16, d19
	fminnm	d24, d20, d4
	fmsub	d16, d6, d16, d0
	fmaxnm	d25, d18, d21
	fmaxnm	d27, d20, d21
	fminnm	d4, d28, d4
	fadd	d7, d26, d7
	fminnm	d22, d22, d23
	fmaxnm	d21, d28, d21
	fminnm	d24, d24, d16
	fmadd	d5, d5, d2, d19
	fmaxnm	d25, d25, d23
	fmaxnm	d27, d27, d16
	fmsub	d0, d6, d2, d0
	fminnm	d4, d4, d7
	fminnm	d3, d22, d18
	strb	w8, [x19, #40]
	fminnm	d22, d24, d20
	ldr	x21, [sp, #24]                  // 8-byte Folded Reload
	fmaxnm	d18, d25, d18
	fmaxnm	d20, d27, d20
	fminnm	d4, d4, d28
	fminnm	d3, d3, d23
	fminnm	d22, d22, d16
	fmaxnm	d18, d18, d23
	fmaxnm	d16, d20, d16
	fminnm	d4, d4, d7
	fminnm	d3, d3, d17
	fminnm	d2, d22, d1
	fmaxnm	d6, d18, d17
	fmaxnm	d16, d16, d1
	fmaxnm	d18, d21, d7
	str	d4, [x19, #56]
	fminnm	d3, d3, d5
	fminnm	d2, d2, d0
	fmaxnm	d6, d6, d5
	fmaxnm	d16, d16, d0
	fmaxnm	d18, d18, d28
	fminnm	d3, d3, d17
	fminnm	d2, d2, d1
	fmaxnm	d6, d6, d17
	fmaxnm	d1, d16, d1
	fmaxnm	d7, d18, d7
	fminnm	d3, d3, d5
	fminnm	d2, d2, d0
	fmaxnm	d4, d6, d5
	fmaxnm	d0, d1, d0
	str	d7, [x19, #80]
	str	d3, [x19, #48]
	str	d2, [x19, #64]
	str	d4, [x19, #72]
	str	d0, [x19, #88]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	d8, [sp], #48                   // 8-byte Folded Reload
	ret
.LBB3_6:
.Ltmp2:
	mov	x19, x0
	mov	x0, x20
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end3:
	.size	_ZN8rotate_yC2ESt10shared_ptrI8hittableEd, .Lfunc_end3-_ZN8rotate_yC2ESt10shared_ptrI8hittableEd
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table3:
.Lexception0:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end0-.Lcst_begin0
.Lcst_begin0:
	.uleb128 .Lfunc_begin0-.Lfunc_begin0    // >> Call Site 1 <<
	.uleb128 .Ltmp0-.Lfunc_begin0           //   Call between .Lfunc_begin0 and .Ltmp0
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp0-.Lfunc_begin0           // >> Call Site 2 <<
	.uleb128 .Ltmp1-.Ltmp0                  //   Call between .Ltmp0 and .Ltmp1
	.uleb128 .Ltmp2-.Lfunc_begin0           //     jumps to .Ltmp2
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp1-.Lfunc_begin0           // >> Call Site 3 <<
	.uleb128 .Lfunc_end3-.Ltmp1             //   Call between .Ltmp1 and .Lfunc_end3
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end0:
	.p2align	2
                                        // -- End function
	.text
	.globl	_ZNK8rotate_y3hitERK3rayddR10hit_record // -- Begin function _ZNK8rotate_y3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK8rotate_y3hitERK3rayddR10hit_record,@function
_ZNK8rotate_y3hitERK3rayddR10hit_record: // @_ZNK8rotate_y3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #96
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldp	d2, d3, [x0, #24]
	mov	x20, x0
	mov	x19, x2
	ldp	d19, d4, [x1, #32]
	ldp	d6, d16, [x1, #16]
	fneg	d5, d2
	ldr	x0, [x0, #8]
	fmul	d7, d4, d3
	fmul	d17, d6, d5
	fmul	d6, d6, d3
	fmul	d4, d4, d5
	fmadd	d5, d2, d16, d7
	ldp	d18, d7, [x1]
	stp	d19, d5, [sp, #40]
	fmadd	d17, d3, d18, d17
	fmadd	d2, d2, d18, d6
	fmadd	d3, d3, d16, d4
	ldr	d4, [x1, #48]
	add	x1, sp, #8
	stp	d17, d7, [sp, #8]
	stp	d2, d3, [sp, #24]
	str	d4, [sp, #56]
	ldr	x8, [x0]
	ldr	x8, [x8]
	blr	x8
	tbz	w0, #0, .LBB4_2
// %bb.1:
	ldp	d2, d1, [x19, #32]
	ldp	d0, d3, [x20, #24]
	ldp	d18, d5, [x19, #16]
	ldp	d16, d6, [sp, #32]
	fmul	d4, d0, d1
	fmul	d1, d3, d1
	fneg	d20, d0
	ldr	d19, [x19]
	fmul	d6, d2, d6
	fmadd	d7, d3, d5, d4
	fmsub	d17, d0, d5, d1
	fnmadd	d4, d3, d5, d4
	fnmadd	d1, d20, d5, d1
	fmadd	d6, d16, d7, d6
	ldr	d16, [sp, #48]
	fmadd	d6, d16, d17, d6
	fmul	d16, d0, d18
	fmul	d18, d3, d18
	fcmp	d6, #0.0
	fneg	d6, d2
	fmadd	d3, d3, d19, d16
	fmsub	d0, d0, d19, d18
	fcsel	d4, d7, d4, mi
	fcsel	d1, d17, d1, mi
	fcsel	d2, d2, d6, mi
	cset	w8, mi
	str	d3, [x19]
	strb	w8, [x19, #88]
	stp	d0, d4, [x19, #16]
	stp	d2, d1, [x19, #32]
.LBB4_2:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	and	w0, w0, #0x1
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #96
	ret
.Lfunc_end4:
	.size	_ZNK8rotate_y3hitERK3rayddR10hit_record, .Lfunc_end4-_ZNK8rotate_y3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK7xy_rect3hitERK3rayddR10hit_record
.LCPI5_0:
	.xword	0x8000000000000000              // double -0
	.xword	0xbff0000000000000              // double -1
.LCPI5_1:
	.xword	0x0000000000000000              // double 0
	.xword	0x3ff0000000000000              // double 1
	.text
	.globl	_ZNK7xy_rect3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK7xy_rect3hitERK3rayddR10hit_record,@function
_ZNK7xy_rect3hitERK3rayddR10hit_record: // @_ZNK7xy_rect3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x23, [sp, #32]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	d2, [x1, #16]
	ldr	d3, [x0, #56]
	fsub	d2, d3, d2
	ldr	d3, [x1, #40]
	fdiv	d6, d2, d3
	fcmp	d6, d0
	fccmp	d6, d1, #0, pl
	b.gt	.LBB5_5
// %bb.1:
	ldr	d0, [x1, #24]
	mov	x19, x1
	ldr	d1, [x1]
	fmadd	d0, d6, d0, d1
	ldr	d1, [x0, #24]
	fcmp	d0, d1
	b.mi	.LBB5_5
// %bb.2:
	ldr	d2, [x0, #32]
	fcmp	d0, d2
	b.gt	.LBB5_5
// %bb.3:
	ldr	d3, [x19, #32]
	ldr	d4, [x19, #8]
	fmadd	d3, d6, d3, d4
	ldr	d4, [x0, #40]
	fcmp	d3, d4
	b.mi	.LBB5_5
// %bb.4:
	ldr	d5, [x0, #48]
	fcmp	d3, d5
	b.le	.LBB5_6
.LBB5_5:
	mov	w0, wzr
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB5_6:
	fsub	d3, d3, d4
	fsub	d4, d5, d4
	fsub	d0, d0, d1
	fsub	d1, d2, d1
	str	d6, [x2, #64]
	adrp	x9, .LCPI5_0
	adrp	x10, .LCPI5_1
	ldr	x21, [x2, #56]
	fdiv	d3, d3, d4
	mov	x20, x2
	fdiv	d0, d0, d1
	stp	d0, d3, [x2, #72]
	movi	d0, #0000000000000000
	ldp	d2, d1, [x19, #24]
	fmul	d1, d1, d0
	fmadd	d0, d2, d0, d1
	ldr	d1, [x19, #40]
	ldr	q2, [x10, :lo12:.LCPI5_1]
	fadd	d0, d1, d0
	ldr	q1, [x9, :lo12:.LCPI5_0]
	fcmp	d0, #0.0
	cset	w8, mi
	dup	v0.2s, w8
	strb	w8, [x2, #88]
	ushll	v0.2d, v0.2s, #0
	shl	v0.2d, v0.2d, #63
	cmlt	v0.2d, v0.2d, #0
	bsl	v0.16b, v2.16b, v1.16b
	str	d0, [x2, #24]
	str	q0, [x2, #32]
	ldp	x9, x22, [x0, #8]
	str	x9, [x2, #48]
	cmp	x22, x21
	b.eq	.LBB5_22
// %bb.7:
	adrp	x23, :got:__libc_single_threaded
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	cbz	x22, .LBB5_11
// %bb.8:
	ldrb	w8, [x23]
	cbz	w8, .LBB5_10
// %bb.9:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB5_11
.LBB5_10:
	add	x1, x22, #8
	mov	w0, #1
	str	q6, [sp]                        // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q6, [sp]                        // 16-byte Folded Reload
	ldr	x21, [x20, #56]
.LBB5_11:
	cbz	x21, .LBB5_21
// %bb.12:
	ldrb	w8, [x23]
	cbz	w8, .LBB5_14
// %bb.13:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	b	.LBB5_15
.LBB5_14:
	add	x1, x21, #8
	mov	w0, #-1
	str	q6, [sp]                        // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q6, [sp]                        // 16-byte Folded Reload
.LBB5_15:
	cmp	w0, #1
	b.ne	.LBB5_21
// %bb.16:
	ldr	x8, [x21]
	mov	x0, x21
	str	q6, [sp]                        // 16-byte Folded Spill
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB5_18
// %bb.17:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	b	.LBB5_19
.LBB5_18:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB5_19:
	ldr	q6, [sp]                        // 16-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB5_21
// %bb.20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	ldr	q6, [sp]                        // 16-byte Folded Reload
.LBB5_21:
	str	x22, [x20, #56]
.LBB5_22:
	ldur	q0, [x19, #24]
	mov	w0, #1
	ldr	d1, [x19, #40]
	ldr	q2, [x19]
	fmul	v0.2d, v0.2d, v6.d[0]
	ldr	d3, [x19, #16]
	fmul	d1, d6, d1
	fadd	v0.2d, v0.2d, v2.2d
	fadd	d1, d1, d3
	str	q0, [x20]
	str	d1, [x20, #16]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #80
	ret
.Lfunc_end5:
	.size	_ZNK7xy_rect3hitERK3rayddR10hit_record, .Lfunc_end5-_ZNK7xy_rect3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZNK7xz_rect3hitERK3rayddR10hit_record
.LCPI6_0:
	.xword	0x8000000000000000              // double -0
	.xword	0xbff0000000000000              // double -1
.LCPI6_1:
	.xword	0x0000000000000000              // double 0
	.xword	0x3ff0000000000000              // double 1
	.text
	.globl	_ZNK7xz_rect3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK7xz_rect3hitERK3rayddR10hit_record,@function
_ZNK7xz_rect3hitERK3rayddR10hit_record: // @_ZNK7xz_rect3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x23, [sp, #32]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	d2, [x1, #8]
	ldr	d3, [x0, #56]
	fsub	d2, d3, d2
	ldr	d3, [x1, #32]
	fdiv	d6, d2, d3
	fcmp	d6, d0
	fccmp	d6, d1, #0, pl
	b.gt	.LBB6_5
// %bb.1:
	ldr	d0, [x1, #24]
	mov	x19, x1
	ldr	d1, [x1]
	fmadd	d0, d6, d0, d1
	ldr	d1, [x0, #24]
	fcmp	d0, d1
	b.mi	.LBB6_5
// %bb.2:
	ldr	d2, [x0, #32]
	fcmp	d0, d2
	b.gt	.LBB6_5
// %bb.3:
	ldr	d3, [x19, #40]
	ldr	d4, [x19, #16]
	fmadd	d3, d6, d3, d4
	ldr	d4, [x0, #40]
	fcmp	d3, d4
	b.mi	.LBB6_5
// %bb.4:
	ldr	d5, [x0, #48]
	fcmp	d3, d5
	b.le	.LBB6_6
.LBB6_5:
	mov	w0, wzr
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB6_6:
	fsub	d3, d3, d4
	fsub	d4, d5, d4
	fsub	d0, d0, d1
	fsub	d1, d2, d1
	str	d6, [x2, #64]
	adrp	x9, .LCPI6_0
	adrp	x10, .LCPI6_1
	ldr	x21, [x2, #56]
	fdiv	d3, d3, d4
	mov	x20, x2
	fdiv	d0, d0, d1
	stp	d0, d3, [x2, #72]
	movi	d0, #0000000000000000
	ldp	d1, d2, [x19, #24]
	fmadd	d1, d1, d0, d2
	ldr	d2, [x19, #40]
	fmadd	d0, d2, d0, d1
	ldr	q1, [x9, :lo12:.LCPI6_0]
	ldr	q2, [x10, :lo12:.LCPI6_1]
	fcmp	d0, #0.0
	cset	w8, mi
	dup	v0.2s, w8
	strb	w8, [x2, #88]
	ushll	v0.2d, v0.2s, #0
	shl	v0.2d, v0.2d, #63
	cmlt	v0.2d, v0.2d, #0
	bsl	v0.16b, v2.16b, v1.16b
	stur	q0, [x2, #24]
	str	d0, [x2, #40]
	ldp	x9, x22, [x0, #8]
	str	x9, [x2, #48]
	cmp	x22, x21
	b.eq	.LBB6_22
// %bb.7:
	adrp	x23, :got:__libc_single_threaded
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	cbz	x22, .LBB6_11
// %bb.8:
	ldrb	w8, [x23]
	cbz	w8, .LBB6_10
// %bb.9:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB6_11
.LBB6_10:
	add	x1, x22, #8
	mov	w0, #1
	str	q6, [sp]                        // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q6, [sp]                        // 16-byte Folded Reload
	ldr	x21, [x20, #56]
.LBB6_11:
	cbz	x21, .LBB6_21
// %bb.12:
	ldrb	w8, [x23]
	cbz	w8, .LBB6_14
// %bb.13:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	b	.LBB6_15
.LBB6_14:
	add	x1, x21, #8
	mov	w0, #-1
	str	q6, [sp]                        // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q6, [sp]                        // 16-byte Folded Reload
.LBB6_15:
	cmp	w0, #1
	b.ne	.LBB6_21
// %bb.16:
	ldr	x8, [x21]
	mov	x0, x21
	str	q6, [sp]                        // 16-byte Folded Spill
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB6_18
// %bb.17:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	b	.LBB6_19
.LBB6_18:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB6_19:
	ldr	q6, [sp]                        // 16-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB6_21
// %bb.20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	ldr	q6, [sp]                        // 16-byte Folded Reload
.LBB6_21:
	str	x22, [x20, #56]
.LBB6_22:
	ldur	q0, [x19, #24]
	mov	w0, #1
	ldr	d1, [x19, #40]
	ldr	q2, [x19]
	fmul	v0.2d, v0.2d, v6.d[0]
	ldr	d3, [x19, #16]
	fmul	d1, d6, d1
	fadd	v0.2d, v0.2d, v2.2d
	fadd	d1, d1, d3
	str	q0, [x20]
	str	d1, [x20, #16]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #80
	ret
.Lfunc_end6:
	.size	_ZNK7xz_rect3hitERK3rayddR10hit_record, .Lfunc_end6-_ZNK7xz_rect3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK7yz_rect3hitERK3rayddR10hit_record // -- Begin function _ZNK7yz_rect3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK7yz_rect3hitERK3rayddR10hit_record,@function
_ZNK7yz_rect3hitERK3rayddR10hit_record: // @_ZNK7yz_rect3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x23, [sp, #32]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	d2, [x1]
	ldr	d3, [x0, #56]
	fsub	d2, d3, d2
	ldr	d3, [x1, #24]
	fdiv	d6, d2, d3
	fcmp	d6, d0
	fccmp	d6, d1, #0, pl
	b.gt	.LBB7_5
// %bb.1:
	ldr	d0, [x1, #32]
	mov	x19, x1
	ldr	d1, [x1, #8]
	fmadd	d0, d6, d0, d1
	ldr	d1, [x0, #24]
	fcmp	d0, d1
	b.mi	.LBB7_5
// %bb.2:
	ldr	d2, [x0, #32]
	fcmp	d0, d2
	b.gt	.LBB7_5
// %bb.3:
	ldr	d3, [x19, #40]
	ldr	d4, [x19, #16]
	fmadd	d3, d6, d3, d4
	ldr	d4, [x0, #40]
	fcmp	d3, d4
	b.mi	.LBB7_5
// %bb.4:
	ldr	d5, [x0, #48]
	fcmp	d3, d5
	b.le	.LBB7_6
.LBB7_5:
	mov	w0, wzr
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB7_6:
	fsub	d3, d3, d4
	fsub	d4, d5, d4
	fsub	d0, d0, d1
	fsub	d1, d2, d1
	str	d6, [x2, #64]
	mov	x8, #-9223372036854775808
	ldr	x21, [x2, #56]
	mov	x20, x2
	fdiv	d3, d3, d4
	fdiv	d0, d0, d1
	stp	d0, d3, [x2, #72]
	movi	d0, #0000000000000000
	ldp	d2, d1, [x19, #24]
	fmov	d3, #1.00000000
	fmul	d1, d1, d0
	fadd	d1, d2, d1
	ldr	d2, [x19, #40]
	fmadd	d1, d2, d0, d1
	fmov	d2, #-1.00000000
	fcmp	d1, #0.0
	fmov	d1, x8
	fcsel	d2, d3, d2, mi
	fcsel	d0, d0, d1, mi
	cset	w8, mi
	stp	d2, d0, [x2, #24]
	str	d0, [x2, #40]
	ldp	x9, x22, [x0, #8]
	strb	w8, [x2, #88]
	str	x9, [x2, #48]
	cmp	x22, x21
	b.eq	.LBB7_22
// %bb.7:
	adrp	x23, :got:__libc_single_threaded
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	cbz	x22, .LBB7_11
// %bb.8:
	ldrb	w8, [x23]
	cbz	w8, .LBB7_10
// %bb.9:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB7_11
.LBB7_10:
	add	x1, x22, #8
	mov	w0, #1
	str	q6, [sp]                        // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q6, [sp]                        // 16-byte Folded Reload
	ldr	x21, [x20, #56]
.LBB7_11:
	cbz	x21, .LBB7_21
// %bb.12:
	ldrb	w8, [x23]
	cbz	w8, .LBB7_14
// %bb.13:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	b	.LBB7_15
.LBB7_14:
	add	x1, x21, #8
	mov	w0, #-1
	str	q6, [sp]                        // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q6, [sp]                        // 16-byte Folded Reload
.LBB7_15:
	cmp	w0, #1
	b.ne	.LBB7_21
// %bb.16:
	ldr	x8, [x21]
	mov	x0, x21
	str	q6, [sp]                        // 16-byte Folded Spill
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB7_18
// %bb.17:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	b	.LBB7_19
.LBB7_18:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB7_19:
	ldr	q6, [sp]                        // 16-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB7_21
// %bb.20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	ldr	q6, [sp]                        // 16-byte Folded Reload
.LBB7_21:
	str	x22, [x20, #56]
.LBB7_22:
	ldur	q0, [x19, #24]
	mov	w0, #1
	ldr	d1, [x19, #40]
	ldr	q2, [x19]
	fmul	v0.2d, v0.2d, v6.d[0]
	ldr	d3, [x19, #16]
	fmul	d1, d6, d1
	fadd	v0.2d, v0.2d, v2.2d
	fadd	d1, d1, d3
	str	q0, [x20]
	str	d1, [x20, #16]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x23, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #80
	ret
.Lfunc_end7:
	.size	_ZNK7yz_rect3hitERK3rayddR10hit_record, .Lfunc_end7-_ZNK7yz_rect3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK13hittable_list3hitERK3rayddR10hit_record // -- Begin function _ZNK13hittable_list3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK13hittable_list3hitERK3rayddR10hit_record,@function
_ZNK13hittable_list3hitERK3rayddR10hit_record: // @_ZNK13hittable_list3hitERK3rayddR10hit_record
.Lfunc_begin1:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception1
// %bb.0:
	sub	sp, sp, #208
	stp	d9, d8, [sp, #96]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	str	x27, [sp, #128]                 // 8-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	ldp	x23, x24, [x0, #8]
	fmov	d8, d0
	movi	v0.2d, #0000000000000000
	cmp	x23, x24
	stp	q0, q0, [sp, #32]
	stp	q0, q0, [sp]
	b.eq	.LBB8_23
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	fmov	d9, d1
	mov	x8, sp
	mov	x19, x2
	mov	x20, x1
	mov	w21, wzr
	add	x25, x2, #64
	add	x26, x8, #64
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	b	.LBB8_5
.LBB8_2:                                //   in Loop: Header=BB8_5 Depth=1
	str	x27, [x19, #56]
.LBB8_3:                                //   in Loop: Header=BB8_5 Depth=1
	ldr	q0, [x26]
	mov	w21, #1
	ldur	q1, [x26, #9]
	str	q0, [x25]
	stur	q1, [x25, #9]
.LBB8_4:                                //   in Loop: Header=BB8_5 Depth=1
	add	x23, x23, #16
	cmp	x23, x24
	b.eq	.LBB8_20
.LBB8_5:                                // =>This Inner Loop Header: Depth=1
	ldr	x0, [x23]
	ldr	x8, [x0]
	ldr	x8, [x8]
.Ltmp3:
	fmov	d0, d8
	fmov	d1, d9
	mov	x2, sp
	mov	x1, x20
	blr	x8
.Ltmp4:
// %bb.6:                               //   in Loop: Header=BB8_5 Depth=1
	tbz	w0, #0, .LBB8_4
// %bb.7:                               //   in Loop: Header=BB8_5 Depth=1
	ldp	q0, q1, [sp]
	ldp	x8, x27, [sp, #48]
	stp	q0, q1, [x19]
	ldr	x21, [x19, #56]
	ldr	q2, [sp, #32]
	ldr	d9, [sp, #64]
	str	x8, [x19, #48]
	cmp	x27, x21
	str	q2, [x19, #32]
	b.eq	.LBB8_3
// %bb.8:                               //   in Loop: Header=BB8_5 Depth=1
	cbz	x27, .LBB8_11
// %bb.9:                               //   in Loop: Header=BB8_5 Depth=1
	ldrb	w8, [x22]
	cbz	w8, .LBB8_14
// %bb.10:                              //   in Loop: Header=BB8_5 Depth=1
	ldr	w8, [x27, #8]
	add	w8, w8, #1
	str	w8, [x27, #8]
.LBB8_11:                               //   in Loop: Header=BB8_5 Depth=1
	cbz	x21, .LBB8_2
.LBB8_12:                               //   in Loop: Header=BB8_5 Depth=1
	ldrb	w8, [x22]
	cbz	w8, .LBB8_15
// %bb.13:                              //   in Loop: Header=BB8_5 Depth=1
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.ne	.LBB8_2
	b	.LBB8_16
.LBB8_14:                               //   in Loop: Header=BB8_5 Depth=1
	add	x1, x27, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x21, [x19, #56]
	cbnz	x21, .LBB8_12
	b	.LBB8_2
.LBB8_15:                               //   in Loop: Header=BB8_5 Depth=1
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB8_2
.LBB8_16:                               //   in Loop: Header=BB8_5 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB8_18
// %bb.17:                              //   in Loop: Header=BB8_5 Depth=1
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB8_2
	b	.LBB8_19
.LBB8_18:                               //   in Loop: Header=BB8_5 Depth=1
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB8_2
.LBB8_19:                               //   in Loop: Header=BB8_5 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB8_2
.LBB8_20:
	ldr	x19, [sp, #56]
	cbz	x19, .LBB8_28
// %bb.21:
	ldrb	w8, [x22]
	cbz	w8, .LBB8_24
// %bb.22:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB8_25
	b	.LBB8_28
.LBB8_23:
	mov	w21, wzr
	b	.LBB8_28
.LBB8_24:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB8_28
.LBB8_25:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB8_29
// %bb.26:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB8_28
.LBB8_27:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB8_28:
	and	w0, w21, #0x1
	ldr	x27, [sp, #128]                 // 8-byte Folded Reload
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #96]               // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB8_29:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB8_27
	b	.LBB8_28
.LBB8_30:
.Ltmp5:
	mov	x19, x0
	mov	x0, sp
	bl	_ZN10hit_recordD2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end8:
	.size	_ZNK13hittable_list3hitERK3rayddR10hit_record, .Lfunc_end8-_ZNK13hittable_list3hitERK3rayddR10hit_record
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table8:
.Lexception1:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end1-.Lcst_begin1
.Lcst_begin1:
	.uleb128 .Ltmp3-.Lfunc_begin1           // >> Call Site 1 <<
	.uleb128 .Ltmp4-.Ltmp3                  //   Call between .Ltmp3 and .Ltmp4
	.uleb128 .Ltmp5-.Lfunc_begin1           //     jumps to .Ltmp5
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp4-.Lfunc_begin1           // >> Call Site 2 <<
	.uleb128 .Lfunc_end8-.Ltmp4             //   Call between .Ltmp4 and .Lfunc_end8
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end1:
	.p2align	2
                                        // -- End function
	.section	.text._ZN10hit_recordD2Ev,"axG",@progbits,_ZN10hit_recordD2Ev,comdat
	.weak	_ZN10hit_recordD2Ev             // -- Begin function _ZN10hit_recordD2Ev
	.p2align	2
	.type	_ZN10hit_recordD2Ev,@function
_ZN10hit_recordD2Ev:                    // @_ZN10hit_recordD2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #56]
	cbz	x19, .LBB9_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB9_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB9_4
	b	.LBB9_8
.LBB9_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB9_8
.LBB9_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB9_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB9_8
.LBB9_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB9_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB9_6
.LBB9_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end9:
	.size	_ZN10hit_recordD2Ev, .Lfunc_end9-_ZN10hit_recordD2Ev
	.cfi_endproc
                                        // -- End function
	.text
	.globl	_ZNK13hittable_list12bounding_boxEddR4aabb // -- Begin function _ZNK13hittable_list12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK13hittable_list12bounding_boxEddR4aabb,@function
_ZNK13hittable_list12bounding_boxEddR4aabb: // @_ZNK13hittable_list12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #112
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	ldp	x20, x21, [x0, #8]
	cmp	x20, x21
	b.eq	.LBB10_7
// %bb.1:
	fmov	d8, d1
	fmov	d9, d0
	movi	v0.2d, #0000000000000000
	mov	x19, x1
	mov	w22, #1
	stp	q0, q0, [sp, #16]
	str	q0, [sp]
	b	.LBB10_4
.LBB10_2:                               //   in Loop: Header=BB10_4 Depth=1
	ldp	d0, d2, [x19]
	ldp	d3, d5, [x19, #16]
	ldp	d6, d7, [x19, #32]
	ldp	d1, d4, [sp]
	ldp	d16, d17, [sp, #16]
	ldp	d18, d19, [sp, #32]
	fminnm	d1, d0, d1
	fminnm	d2, d2, d4
	fminnm	d4, d3, d16
	fmaxnm	d5, d5, d17
	fmaxnm	d3, d6, d18
	fmaxnm	d0, d7, d19
.LBB10_3:                               //   in Loop: Header=BB10_4 Depth=1
	mov	w22, wzr
	add	x20, x20, #16
	cmp	x20, x21
	str	d1, [x19]
	str	d2, [x19, #8]
	str	d4, [x19, #16]
	str	d5, [x19, #24]
	str	d3, [x19, #32]
	str	d0, [x19, #40]
	b.eq	.LBB10_8
.LBB10_4:                               // =>This Inner Loop Header: Depth=1
	ldr	x0, [x20]
	fmov	d0, d9
	fmov	d1, d8
	mov	x1, sp
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
	blr	x8
	tbz	w0, #0, .LBB10_8
// %bb.5:                               //   in Loop: Header=BB10_4 Depth=1
	tbz	w22, #0, .LBB10_2
// %bb.6:                               //   in Loop: Header=BB10_4 Depth=1
	ldp	d1, d2, [sp]
	ldp	d4, d5, [sp, #16]
	ldp	d3, d0, [sp, #32]
	b	.LBB10_3
.LBB10_7:
	mov	w0, wzr
.LBB10_8:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	and	w0, w0, #0x1
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	add	sp, sp, #112
	ret
.Lfunc_end10:
	.size	_ZNK13hittable_list12bounding_boxEddR4aabb, .Lfunc_end10-_ZNK13hittable_list12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.globl	_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE // -- Begin function _ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE
	.p2align	2
	.type	_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE,@function
_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE: // @_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE
.Lfunc_begin2:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception2
// %bb.0:
	sub	sp, sp, #256
	stp	x29, x30, [sp, #160]            // 16-byte Folded Spill
	add	x29, sp, #160
	stp	x28, x27, [sp, #176]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #192]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	adrp	x8, _ZTV3box+16
	adrp	x9, _ZTV13hittable_list+16
	movi	v0.2d, #0000000000000000
	add	x8, x8, :lo12:_ZTV3box+16
	mov	x19, x0
	add	x9, x9, :lo12:_ZTV13hittable_list+16
	mov	x21, x0
	stp	xzr, xzr, [x0, #72]
	str	x8, [x0]
	mov	x22, x3
	str	x9, [x19, #56]!
	stur	q0, [x0, #8]
	mov	x23, x2
	stur	q0, [x0, #24]
	mov	x20, x0
	stur	q0, [x0, #40]
	mov	x24, x1
	str	xzr, [x21, #64]!
	ldr	q0, [x1]
	ldr	x8, [x1, #16]
	stur	q0, [x0, #8]
	str	x8, [x0, #24]
	ldr	x8, [x2, #16]
	ldr	q0, [x2]
	str	x8, [x0, #48]
	str	q0, [x0, #32]
	ldp	d3, d2, [x1]
	ldp	d1, d0, [x2]
	stp	d1, d3, [x29, #-56]
	ldr	d1, [x2, #16]
	stp	d0, d2, [x29, #-72]
	str	d1, [sp, #80]
.Ltmp6:
	mov	w0, #80
	bl	_Znwm
.Ltmp7:
// %bb.1:
	movi	v0.2s, #1
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x26, x0, #16
	str	d0, [x0, #8]
	str	x28, [x0]
.Ltmp9:
	sub	x0, x29, #8
	sub	x2, x29, #48
	sub	x3, x29, #56
	sub	x4, x29, #64
	sub	x5, x29, #72
	add	x6, sp, #80
	mov	x1, x26
	mov	x7, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp10:
// %bb.2:
	ldp	x1, x8, [x20, #72]
	adrp	x27, :got:__libc_single_threaded
	stp	x26, x25, [x29, #-24]
	ldr	x27, [x27, :got_lo12:__libc_single_threaded]
	stp	xzr, xzr, [x29, #-40]
	cmp	x1, x8
	b.eq	.LBB11_5
// %bb.3:
	stp	x26, x25, [x1]
	ldrb	w8, [x27]
	cbz	w8, .LBB11_7
// %bb.4:
	ldr	w8, [x25, #8]
	add	w8, w8, #1
	str	w8, [x25, #8]
	b	.LBB11_8
.LBB11_5:
.Ltmp12:
	sub	x2, x29, #24
	mov	x0, x21
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp13:
// %bb.6:
	ldur	x25, [x29, #-16]
	cbnz	x25, .LBB11_9
	b	.LBB11_15
.LBB11_7:
	add	x1, x25, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20, #72]
.LBB11_8:
	add	x8, x1, #16
	str	x8, [x20, #72]
	ldur	x25, [x29, #-16]
	cbz	x25, .LBB11_15
.LBB11_9:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_11
// %bb.10:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_12
	b	.LBB11_15
.LBB11_11:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_15
.LBB11_12:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_133
// %bb.13:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_15
.LBB11_14:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_15:
	ldur	x25, [x29, #-32]
	cbz	x25, .LBB11_22
// %bb.16:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_18
// %bb.17:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_19
	b	.LBB11_22
.LBB11_18:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_22
.LBB11_19:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_134
// %bb.20:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_22
.LBB11_21:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_22:
	ldp	d0, d2, [x24]
	ldp	d1, d3, [x23]
	stp	d1, d0, [x29, #-56]
	ldr	d0, [x24, #16]
	stp	d3, d2, [x29, #-72]
	str	d0, [sp, #80]
.Ltmp15:
	mov	w0, #80
	bl	_Znwm
.Ltmp16:
// %bb.23:
	movi	v0.2s, #1
	mov	x25, x0
	add	x26, x0, #16
	str	x28, [x0]
	str	d0, [x0, #8]
.Ltmp18:
	sub	x0, x29, #8
	sub	x2, x29, #48
	sub	x3, x29, #56
	sub	x4, x29, #64
	sub	x5, x29, #72
	add	x6, sp, #80
	mov	x1, x26
	mov	x7, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp19:
// %bb.24:
	ldp	x1, x8, [x20, #72]
	stp	x26, x25, [sp, #64]
	stp	xzr, xzr, [x29, #-40]
	cmp	x1, x8
	b.eq	.LBB11_27
// %bb.25:
	stp	x26, x25, [x1]
	ldrb	w8, [x27]
	cbz	w8, .LBB11_29
// %bb.26:
	ldr	w8, [x25, #8]
	add	w8, w8, #1
	str	w8, [x25, #8]
	b	.LBB11_30
.LBB11_27:
.Ltmp21:
	add	x2, sp, #64
	mov	x0, x21
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp22:
// %bb.28:
	ldr	x25, [sp, #72]
	cbnz	x25, .LBB11_31
	b	.LBB11_37
.LBB11_29:
	add	x1, x25, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20, #72]
.LBB11_30:
	add	x8, x1, #16
	str	x8, [x20, #72]
	ldr	x25, [sp, #72]
	cbz	x25, .LBB11_37
.LBB11_31:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_33
// %bb.32:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_34
	b	.LBB11_37
.LBB11_33:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_37
.LBB11_34:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_135
// %bb.35:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_37
.LBB11_36:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_37:
	ldur	x25, [x29, #-32]
	cbz	x25, .LBB11_44
// %bb.38:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_40
// %bb.39:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_41
	b	.LBB11_44
.LBB11_40:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_44
.LBB11_41:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_136
// %bb.42:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_44
.LBB11_43:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_44:
	ldp	d1, d0, [x23]
	ldr	d4, [x24]
	ldr	d2, [x24, #16]
	ldr	d3, [x23, #16]
	stp	d1, d4, [x29, #-56]
	str	d0, [sp, #80]
	stp	d3, d2, [x29, #-72]
.Ltmp24:
	mov	w0, #80
	bl	_Znwm
.Ltmp25:
// %bb.45:
	movi	v0.2s, #1
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x26, x0, #16
	str	d0, [x0, #8]
	str	x28, [x0]
.Ltmp27:
	sub	x0, x29, #8
	sub	x2, x29, #48
	sub	x3, x29, #56
	sub	x4, x29, #64
	sub	x5, x29, #72
	add	x6, sp, #80
	mov	x1, x26
	mov	x7, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp28:
// %bb.46:
	ldp	x1, x8, [x20, #72]
	stp	x26, x25, [sp, #48]
	stp	xzr, xzr, [x29, #-40]
	cmp	x1, x8
	b.eq	.LBB11_49
// %bb.47:
	stp	x26, x25, [x1]
	ldrb	w8, [x27]
	cbz	w8, .LBB11_51
// %bb.48:
	ldr	w8, [x25, #8]
	add	w8, w8, #1
	str	w8, [x25, #8]
	b	.LBB11_52
.LBB11_49:
.Ltmp30:
	add	x2, sp, #48
	mov	x0, x21
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp31:
// %bb.50:
	ldr	x25, [sp, #56]
	cbnz	x25, .LBB11_53
	b	.LBB11_59
.LBB11_51:
	add	x1, x25, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20, #72]
.LBB11_52:
	add	x8, x1, #16
	str	x8, [x20, #72]
	ldr	x25, [sp, #56]
	cbz	x25, .LBB11_59
.LBB11_53:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_55
// %bb.54:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_56
	b	.LBB11_59
.LBB11_55:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_59
.LBB11_56:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_137
// %bb.57:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_59
.LBB11_58:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_59:
	ldur	x25, [x29, #-32]
	cbz	x25, .LBB11_66
// %bb.60:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_62
// %bb.61:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_63
	b	.LBB11_66
.LBB11_62:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_66
.LBB11_63:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_138
// %bb.64:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_66
.LBB11_65:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_66:
	ldp	d1, d3, [x24]
	ldr	d0, [x23]
	ldr	d2, [x24, #16]
	stp	d0, d1, [x29, #-56]
	ldr	d1, [x23, #16]
	str	d3, [sp, #80]
	stp	d1, d2, [x29, #-72]
.Ltmp33:
	mov	w0, #80
	bl	_Znwm
.Ltmp34:
// %bb.67:
	movi	v0.2s, #1
	mov	x25, x0
	add	x26, x0, #16
	str	x28, [x0]
	str	d0, [x0, #8]
.Ltmp36:
	sub	x0, x29, #8
	sub	x2, x29, #48
	sub	x3, x29, #56
	sub	x4, x29, #64
	sub	x5, x29, #72
	add	x6, sp, #80
	mov	x1, x26
	mov	x7, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp37:
// %bb.68:
	ldp	x1, x8, [x20, #72]
	stp	x26, x25, [sp, #32]
	stp	xzr, xzr, [x29, #-40]
	cmp	x1, x8
	b.eq	.LBB11_71
// %bb.69:
	stp	x26, x25, [x1]
	ldrb	w8, [x27]
	cbz	w8, .LBB11_73
// %bb.70:
	ldr	w8, [x25, #8]
	add	w8, w8, #1
	str	w8, [x25, #8]
	b	.LBB11_74
.LBB11_71:
.Ltmp39:
	add	x2, sp, #32
	mov	x0, x21
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp40:
// %bb.72:
	ldr	x25, [sp, #40]
	cbnz	x25, .LBB11_75
	b	.LBB11_81
.LBB11_73:
	add	x1, x25, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20, #72]
.LBB11_74:
	add	x8, x1, #16
	str	x8, [x20, #72]
	ldr	x25, [sp, #40]
	cbz	x25, .LBB11_81
.LBB11_75:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_77
// %bb.76:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_78
	b	.LBB11_81
.LBB11_77:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_81
.LBB11_78:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_139
// %bb.79:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_81
.LBB11_80:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_81:
	ldur	x25, [x29, #-32]
	cbz	x25, .LBB11_88
// %bb.82:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_84
// %bb.83:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_85
	b	.LBB11_88
.LBB11_84:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_88
.LBB11_85:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_140
// %bb.86:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_88
.LBB11_87:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_88:
	ldp	d0, d2, [x24, #8]
	ldp	d1, d3, [x23, #8]
	stp	d1, d0, [x29, #-56]
	ldr	d0, [x23]
	stp	d3, d2, [x29, #-72]
	str	d0, [sp, #80]
.Ltmp42:
	mov	w0, #80
	bl	_Znwm
.Ltmp43:
// %bb.89:
	movi	v0.2s, #1
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x26, x0, #16
	str	d0, [x0, #8]
	str	x28, [x0]
.Ltmp45:
	sub	x0, x29, #8
	sub	x2, x29, #48
	sub	x3, x29, #56
	sub	x4, x29, #64
	sub	x5, x29, #72
	add	x6, sp, #80
	mov	x1, x26
	mov	x7, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp46:
// %bb.90:
	ldp	x1, x8, [x20, #72]
	stp	x26, x25, [sp, #16]
	stp	xzr, xzr, [x29, #-40]
	cmp	x1, x8
	b.eq	.LBB11_93
// %bb.91:
	stp	x26, x25, [x1]
	ldrb	w8, [x27]
	cbz	w8, .LBB11_95
// %bb.92:
	ldr	w8, [x25, #8]
	add	w8, w8, #1
	str	w8, [x25, #8]
	b	.LBB11_96
.LBB11_93:
.Ltmp48:
	add	x2, sp, #16
	mov	x0, x21
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp49:
// %bb.94:
	ldr	x25, [sp, #24]
	cbnz	x25, .LBB11_97
	b	.LBB11_103
.LBB11_95:
	add	x1, x25, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20, #72]
.LBB11_96:
	add	x8, x1, #16
	str	x8, [x20, #72]
	ldr	x25, [sp, #24]
	cbz	x25, .LBB11_103
.LBB11_97:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_99
// %bb.98:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_100
	b	.LBB11_103
.LBB11_99:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_103
.LBB11_100:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_141
// %bb.101:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_103
.LBB11_102:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_103:
	ldur	x25, [x29, #-32]
	cbz	x25, .LBB11_110
// %bb.104:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_106
// %bb.105:
	ldr	w0, [x25, #8]
	sub	w8, w0, #1
	str	w8, [x25, #8]
	cmp	w0, #1
	b.eq	.LBB11_107
	b	.LBB11_110
.LBB11_106:
	add	x1, x25, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_110
.LBB11_107:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_142
// %bb.108:
	ldr	w0, [x25, #12]
	sub	w8, w0, #1
	str	w8, [x25, #12]
	cmp	w0, #1
	b.ne	.LBB11_110
.LBB11_109:
	ldr	x8, [x25]
	mov	x0, x25
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_110:
	ldp	d4, d2, [x24, #8]
	ldp	d0, d1, [x23, #8]
	ldr	d3, [x24]
	stp	d0, d4, [x29, #-56]
	stp	d1, d2, [x29, #-72]
	str	d3, [sp, #80]
.Ltmp51:
	mov	w0, #80
	bl	_Znwm
.Ltmp52:
// %bb.111:
	movi	v0.2s, #1
	mov	x23, x0
	add	x24, x0, #16
	str	x28, [x0]
	str	d0, [x0, #8]
.Ltmp54:
	sub	x0, x29, #8
	sub	x2, x29, #48
	sub	x3, x29, #56
	sub	x4, x29, #64
	sub	x5, x29, #72
	add	x6, sp, #80
	mov	x1, x24
	mov	x7, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp55:
// %bb.112:
	ldp	x1, x8, [x20, #72]
	stp	x24, x23, [sp]
	stp	xzr, xzr, [x29, #-40]
	cmp	x1, x8
	b.eq	.LBB11_115
// %bb.113:
	stp	x24, x23, [x1]
	ldrb	w8, [x27]
	cbz	w8, .LBB11_117
// %bb.114:
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
	b	.LBB11_118
.LBB11_115:
.Ltmp57:
	mov	x2, sp
	mov	x0, x21
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp58:
// %bb.116:
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB11_119
	b	.LBB11_125
.LBB11_117:
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20, #72]
.LBB11_118:
	add	x8, x1, #16
	str	x8, [x20, #72]
	ldr	x19, [sp, #8]
	cbz	x19, .LBB11_125
.LBB11_119:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_121
// %bb.120:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB11_122
	b	.LBB11_125
.LBB11_121:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_125
.LBB11_122:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_143
// %bb.123:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB11_125
.LBB11_124:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_125:
	ldur	x19, [x29, #-32]
	cbz	x19, .LBB11_132
// %bb.126:
	ldrb	w8, [x27]
	cbz	w8, .LBB11_128
// %bb.127:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB11_129
	b	.LBB11_132
.LBB11_128:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB11_132
.LBB11_129:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x27]
	cbz	w8, .LBB11_144
// %bb.130:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB11_132
.LBB11_131:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB11_132:
	ldp	x20, x19, [sp, #240]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #160]            // 16-byte Folded Reload
	add	sp, sp, #256
	ret
.LBB11_133:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_14
	b	.LBB11_15
.LBB11_134:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_21
	b	.LBB11_22
.LBB11_135:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_36
	b	.LBB11_37
.LBB11_136:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_43
	b	.LBB11_44
.LBB11_137:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_58
	b	.LBB11_59
.LBB11_138:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_65
	b	.LBB11_66
.LBB11_139:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_80
	b	.LBB11_81
.LBB11_140:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_87
	b	.LBB11_88
.LBB11_141:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_102
	b	.LBB11_103
.LBB11_142:
	add	x1, x25, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_109
	b	.LBB11_110
.LBB11_143:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_124
	b	.LBB11_125
.LBB11_144:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB11_131
	b	.LBB11_132
.LBB11_145:
.Ltmp59:
	mov	x20, x0
	mov	x0, sp
	b	.LBB11_147
.LBB11_146:
.Ltmp50:
	mov	x20, x0
	add	x0, sp, #16
.LBB11_147:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_148:
.Ltmp41:
	mov	x20, x0
	add	x0, sp, #32
	b	.LBB11_150
.LBB11_149:
.Ltmp32:
	mov	x20, x0
	add	x0, sp, #48
.LBB11_150:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_151:
.Ltmp23:
	mov	x20, x0
	add	x0, sp, #64
	b	.LBB11_153
.LBB11_152:
.Ltmp14:
	mov	x20, x0
	sub	x0, x29, #24
.LBB11_153:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_154:
.Ltmp56:
	mov	x20, x0
	mov	x0, x23
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_155:
.Ltmp53:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_156:
.Ltmp47:
	b	.LBB11_165
.LBB11_157:
.Ltmp44:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_158:
.Ltmp38:
	b	.LBB11_165
.LBB11_159:
.Ltmp35:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_160:
.Ltmp29:
	b	.LBB11_165
.LBB11_161:
.Ltmp26:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_162:
.Ltmp20:
	b	.LBB11_165
.LBB11_163:
.Ltmp17:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_164:
.Ltmp11:
.LBB11_165:
	mov	x20, x0
	mov	x0, x25
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB11_166:
.Ltmp8:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end11:
	.size	_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE, .Lfunc_end11-_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table11:
.Lexception2:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end2-.Lcst_begin2
.Lcst_begin2:
	.uleb128 .Ltmp6-.Lfunc_begin2           // >> Call Site 1 <<
	.uleb128 .Ltmp7-.Ltmp6                  //   Call between .Ltmp6 and .Ltmp7
	.uleb128 .Ltmp8-.Lfunc_begin2           //     jumps to .Ltmp8
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp9-.Lfunc_begin2           // >> Call Site 2 <<
	.uleb128 .Ltmp10-.Ltmp9                 //   Call between .Ltmp9 and .Ltmp10
	.uleb128 .Ltmp11-.Lfunc_begin2          //     jumps to .Ltmp11
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp12-.Lfunc_begin2          // >> Call Site 3 <<
	.uleb128 .Ltmp13-.Ltmp12                //   Call between .Ltmp12 and .Ltmp13
	.uleb128 .Ltmp14-.Lfunc_begin2          //     jumps to .Ltmp14
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp13-.Lfunc_begin2          // >> Call Site 4 <<
	.uleb128 .Ltmp15-.Ltmp13                //   Call between .Ltmp13 and .Ltmp15
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp15-.Lfunc_begin2          // >> Call Site 5 <<
	.uleb128 .Ltmp16-.Ltmp15                //   Call between .Ltmp15 and .Ltmp16
	.uleb128 .Ltmp17-.Lfunc_begin2          //     jumps to .Ltmp17
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp18-.Lfunc_begin2          // >> Call Site 6 <<
	.uleb128 .Ltmp19-.Ltmp18                //   Call between .Ltmp18 and .Ltmp19
	.uleb128 .Ltmp20-.Lfunc_begin2          //     jumps to .Ltmp20
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp21-.Lfunc_begin2          // >> Call Site 7 <<
	.uleb128 .Ltmp22-.Ltmp21                //   Call between .Ltmp21 and .Ltmp22
	.uleb128 .Ltmp23-.Lfunc_begin2          //     jumps to .Ltmp23
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp22-.Lfunc_begin2          // >> Call Site 8 <<
	.uleb128 .Ltmp24-.Ltmp22                //   Call between .Ltmp22 and .Ltmp24
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp24-.Lfunc_begin2          // >> Call Site 9 <<
	.uleb128 .Ltmp25-.Ltmp24                //   Call between .Ltmp24 and .Ltmp25
	.uleb128 .Ltmp26-.Lfunc_begin2          //     jumps to .Ltmp26
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp27-.Lfunc_begin2          // >> Call Site 10 <<
	.uleb128 .Ltmp28-.Ltmp27                //   Call between .Ltmp27 and .Ltmp28
	.uleb128 .Ltmp29-.Lfunc_begin2          //     jumps to .Ltmp29
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp30-.Lfunc_begin2          // >> Call Site 11 <<
	.uleb128 .Ltmp31-.Ltmp30                //   Call between .Ltmp30 and .Ltmp31
	.uleb128 .Ltmp32-.Lfunc_begin2          //     jumps to .Ltmp32
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp31-.Lfunc_begin2          // >> Call Site 12 <<
	.uleb128 .Ltmp33-.Ltmp31                //   Call between .Ltmp31 and .Ltmp33
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp33-.Lfunc_begin2          // >> Call Site 13 <<
	.uleb128 .Ltmp34-.Ltmp33                //   Call between .Ltmp33 and .Ltmp34
	.uleb128 .Ltmp35-.Lfunc_begin2          //     jumps to .Ltmp35
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp36-.Lfunc_begin2          // >> Call Site 14 <<
	.uleb128 .Ltmp37-.Ltmp36                //   Call between .Ltmp36 and .Ltmp37
	.uleb128 .Ltmp38-.Lfunc_begin2          //     jumps to .Ltmp38
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp39-.Lfunc_begin2          // >> Call Site 15 <<
	.uleb128 .Ltmp40-.Ltmp39                //   Call between .Ltmp39 and .Ltmp40
	.uleb128 .Ltmp41-.Lfunc_begin2          //     jumps to .Ltmp41
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp40-.Lfunc_begin2          // >> Call Site 16 <<
	.uleb128 .Ltmp42-.Ltmp40                //   Call between .Ltmp40 and .Ltmp42
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp42-.Lfunc_begin2          // >> Call Site 17 <<
	.uleb128 .Ltmp43-.Ltmp42                //   Call between .Ltmp42 and .Ltmp43
	.uleb128 .Ltmp44-.Lfunc_begin2          //     jumps to .Ltmp44
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp45-.Lfunc_begin2          // >> Call Site 18 <<
	.uleb128 .Ltmp46-.Ltmp45                //   Call between .Ltmp45 and .Ltmp46
	.uleb128 .Ltmp47-.Lfunc_begin2          //     jumps to .Ltmp47
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp48-.Lfunc_begin2          // >> Call Site 19 <<
	.uleb128 .Ltmp49-.Ltmp48                //   Call between .Ltmp48 and .Ltmp49
	.uleb128 .Ltmp50-.Lfunc_begin2          //     jumps to .Ltmp50
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp49-.Lfunc_begin2          // >> Call Site 20 <<
	.uleb128 .Ltmp51-.Ltmp49                //   Call between .Ltmp49 and .Ltmp51
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp51-.Lfunc_begin2          // >> Call Site 21 <<
	.uleb128 .Ltmp52-.Ltmp51                //   Call between .Ltmp51 and .Ltmp52
	.uleb128 .Ltmp53-.Lfunc_begin2          //     jumps to .Ltmp53
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp54-.Lfunc_begin2          // >> Call Site 22 <<
	.uleb128 .Ltmp55-.Ltmp54                //   Call between .Ltmp54 and .Ltmp55
	.uleb128 .Ltmp56-.Lfunc_begin2          //     jumps to .Ltmp56
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp57-.Lfunc_begin2          // >> Call Site 23 <<
	.uleb128 .Ltmp58-.Ltmp57                //   Call between .Ltmp57 and .Ltmp58
	.uleb128 .Ltmp59-.Lfunc_begin2          //     jumps to .Ltmp59
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp58-.Lfunc_begin2          // >> Call Site 24 <<
	.uleb128 .Lfunc_end11-.Ltmp58           //   Call between .Ltmp58 and .Lfunc_end11
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end2:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB12_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB12_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB12_4
	b	.LBB12_8
.LBB12_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB12_8
.LBB12_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB12_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB12_8
.LBB12_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB12_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB12_6
.LBB12_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end12:
	.size	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end12-_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB13_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB13_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB13_4
	b	.LBB13_8
.LBB13_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB13_8
.LBB13_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB13_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB13_8
.LBB13_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB13_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB13_6
.LBB13_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end13:
	.size	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end13-_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB14_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB14_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB14_4
	b	.LBB14_8
.LBB14_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB14_8
.LBB14_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB14_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB14_8
.LBB14_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB14_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB14_6
.LBB14_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end14:
	.size	_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end14-_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN13hittable_listD2Ev,"axG",@progbits,_ZN13hittable_listD2Ev,comdat
	.weak	_ZN13hittable_listD2Ev          // -- Begin function _ZN13hittable_listD2Ev
	.p2align	2
	.type	_ZN13hittable_listD2Ev,@function
_ZN13hittable_listD2Ev:                 // @_ZN13hittable_listD2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x19, x22, [x0, #8]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x22
	str	x8, [x0]
	b.eq	.LBB15_12
// %bb.1:
	adrp	x23, :got:__libc_single_threaded
	mov	x20, x0
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	b	.LBB15_3
.LBB15_2:                               //   in Loop: Header=BB15_3 Depth=1
	add	x19, x19, #16
	cmp	x19, x22
	b.eq	.LBB15_11
.LBB15_3:                               // =>This Inner Loop Header: Depth=1
	ldr	x21, [x19, #8]
	cbz	x21, .LBB15_2
// %bb.4:                               //   in Loop: Header=BB15_3 Depth=1
	ldrb	w8, [x23]
	cbz	w8, .LBB15_6
// %bb.5:                               //   in Loop: Header=BB15_3 Depth=1
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.ne	.LBB15_2
	b	.LBB15_7
.LBB15_6:                               //   in Loop: Header=BB15_3 Depth=1
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB15_2
.LBB15_7:                               //   in Loop: Header=BB15_3 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB15_9
// %bb.8:                               //   in Loop: Header=BB15_3 Depth=1
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB15_2
	b	.LBB15_10
.LBB15_9:                               //   in Loop: Header=BB15_3 Depth=1
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB15_2
.LBB15_10:                              //   in Loop: Header=BB15_3 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB15_2
.LBB15_11:
	ldr	x19, [x20, #8]
.LBB15_12:
	cbz	x19, .LBB15_14
// %bb.13:
	mov	x0, x19
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	b	_ZdlPv
.LBB15_14:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end15:
	.size	_ZN13hittable_listD2Ev, .Lfunc_end15-_ZN13hittable_listD2Ev
	.cfi_endproc
                                        // -- End function
	.text
	.globl	_ZNK3box3hitERK3rayddR10hit_record // -- Begin function _ZNK3box3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK3box3hitERK3rayddR10hit_record,@function
_ZNK3box3hitERK3rayddR10hit_record:     // @_ZNK3box3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	add	x0, x0, #56
	b	_ZNK13hittable_list3hitERK3rayddR10hit_record
.Lfunc_end16:
	.size	_ZNK3box3hitERK3rayddR10hit_record, .Lfunc_end16-_ZNK3box3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.globl	_Z13box_x_compareSt10shared_ptrI8hittableES1_ // -- Begin function _Z13box_x_compareSt10shared_ptrI8hittableES1_
	.p2align	2
	.type	_Z13box_x_compareSt10shared_ptrI8hittableES1_,@function
_Z13box_x_compareSt10shared_ptrI8hittableES1_: // @_Z13box_x_compareSt10shared_ptrI8hittableES1_
.Lfunc_begin3:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception3
// %bb.0:
	sub	sp, sp, #176
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	.cfi_offset b8, -40
	.cfi_offset b9, -48
	adrp	x20, :got:__libc_single_threaded
	mov	x19, x1
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x0]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB17_3
// %bb.1:
	ldrb	w9, [x20]
	cbz	w9, .LBB17_6
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB17_3:
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbz	x8, .LBB17_8
.LBB17_4:
	ldrb	w9, [x20]
	cbz	w9, .LBB17_7
// %bb.5:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB17_8
.LBB17_6:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB17_4
	b	.LBB17_8
.LBB17_7:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB17_8:
	movi	v0.2d, #0000000000000000
	ldr	x0, [sp, #16]
	stp	q0, q0, [x29, #-48]
	stur	q0, [x29, #-64]
	stp	q0, q0, [sp, #48]
	str	q0, [sp, #32]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp60:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	sub	x1, x29, #64
	blr	x8
.Ltmp61:
// %bb.9:
	tbz	w0, #0, .LBB17_12
// %bb.10:
	ldr	x0, [sp]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp62:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	add	x1, sp, #32
	blr	x8
.Ltmp63:
// %bb.11:
	tbnz	w0, #0, .LBB17_13
.LBB17_12:
.Ltmp64:
	adrp	x0, :got:_ZSt4cerr
	adrp	x1, .L.str
	add	x1, x1, :lo12:.L.str
	mov	w2, #41
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp65:
.LBB17_13:
	ldur	d8, [x29, #-64]
	ldr	x19, [sp, #8]
	ldr	d9, [sp, #32]
	cbz	x19, .LBB17_20
// %bb.14:
	ldrb	w8, [x20]
	cbz	w8, .LBB17_16
// %bb.15:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB17_17
	b	.LBB17_20
.LBB17_16:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB17_20
.LBB17_17:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB17_28
// %bb.18:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB17_20
.LBB17_19:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB17_20:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB17_27
// %bb.21:
	ldrb	w8, [x20]
	cbz	w8, .LBB17_23
// %bb.22:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB17_24
	b	.LBB17_27
.LBB17_23:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB17_27
.LBB17_24:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB17_29
// %bb.25:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB17_27
.LBB17_26:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB17_27:
	fcmp	d8, d9
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	cset	w0, mi
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB17_28:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB17_19
	b	.LBB17_20
.LBB17_29:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB17_26
	b	.LBB17_27
.LBB17_30:
.Ltmp66:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end17:
	.size	_Z13box_x_compareSt10shared_ptrI8hittableES1_, .Lfunc_end17-_Z13box_x_compareSt10shared_ptrI8hittableES1_
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table17:
.Lexception3:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end3-.Lcst_begin3
.Lcst_begin3:
	.uleb128 .Lfunc_begin3-.Lfunc_begin3    // >> Call Site 1 <<
	.uleb128 .Ltmp60-.Lfunc_begin3          //   Call between .Lfunc_begin3 and .Ltmp60
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp60-.Lfunc_begin3          // >> Call Site 2 <<
	.uleb128 .Ltmp65-.Ltmp60                //   Call between .Ltmp60 and .Ltmp65
	.uleb128 .Ltmp66-.Lfunc_begin3          //     jumps to .Ltmp66
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp65-.Lfunc_begin3          // >> Call Site 3 <<
	.uleb128 .Lfunc_end17-.Ltmp65           //   Call between .Ltmp65 and .Lfunc_end17
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end3:
	.p2align	2
                                        // -- End function
	.text
	.globl	_Z13box_y_compareSt10shared_ptrI8hittableES1_ // -- Begin function _Z13box_y_compareSt10shared_ptrI8hittableES1_
	.p2align	2
	.type	_Z13box_y_compareSt10shared_ptrI8hittableES1_,@function
_Z13box_y_compareSt10shared_ptrI8hittableES1_: // @_Z13box_y_compareSt10shared_ptrI8hittableES1_
.Lfunc_begin4:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception4
// %bb.0:
	sub	sp, sp, #176
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	.cfi_offset b8, -40
	.cfi_offset b9, -48
	adrp	x20, :got:__libc_single_threaded
	mov	x19, x1
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x0]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB18_3
// %bb.1:
	ldrb	w9, [x20]
	cbz	w9, .LBB18_6
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB18_3:
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbz	x8, .LBB18_8
.LBB18_4:
	ldrb	w9, [x20]
	cbz	w9, .LBB18_7
// %bb.5:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB18_8
.LBB18_6:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB18_4
	b	.LBB18_8
.LBB18_7:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB18_8:
	movi	v0.2d, #0000000000000000
	ldr	x0, [sp, #16]
	stp	q0, q0, [x29, #-48]
	stur	q0, [x29, #-64]
	stp	q0, q0, [sp, #48]
	str	q0, [sp, #32]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp67:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	sub	x1, x29, #64
	blr	x8
.Ltmp68:
// %bb.9:
	tbz	w0, #0, .LBB18_12
// %bb.10:
	ldr	x0, [sp]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp69:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	add	x1, sp, #32
	blr	x8
.Ltmp70:
// %bb.11:
	tbnz	w0, #0, .LBB18_13
.LBB18_12:
.Ltmp71:
	adrp	x0, :got:_ZSt4cerr
	adrp	x1, .L.str
	add	x1, x1, :lo12:.L.str
	mov	w2, #41
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp72:
.LBB18_13:
	ldur	d8, [x29, #-56]
	ldr	x19, [sp, #8]
	ldr	d9, [sp, #40]
	cbz	x19, .LBB18_20
// %bb.14:
	ldrb	w8, [x20]
	cbz	w8, .LBB18_16
// %bb.15:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB18_17
	b	.LBB18_20
.LBB18_16:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB18_20
.LBB18_17:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB18_28
// %bb.18:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB18_20
.LBB18_19:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB18_20:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB18_27
// %bb.21:
	ldrb	w8, [x20]
	cbz	w8, .LBB18_23
// %bb.22:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB18_24
	b	.LBB18_27
.LBB18_23:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB18_27
.LBB18_24:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB18_29
// %bb.25:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB18_27
.LBB18_26:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB18_27:
	fcmp	d8, d9
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	cset	w0, mi
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB18_28:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB18_19
	b	.LBB18_20
.LBB18_29:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB18_26
	b	.LBB18_27
.LBB18_30:
.Ltmp73:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end18:
	.size	_Z13box_y_compareSt10shared_ptrI8hittableES1_, .Lfunc_end18-_Z13box_y_compareSt10shared_ptrI8hittableES1_
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table18:
.Lexception4:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end4-.Lcst_begin4
.Lcst_begin4:
	.uleb128 .Lfunc_begin4-.Lfunc_begin4    // >> Call Site 1 <<
	.uleb128 .Ltmp67-.Lfunc_begin4          //   Call between .Lfunc_begin4 and .Ltmp67
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp67-.Lfunc_begin4          // >> Call Site 2 <<
	.uleb128 .Ltmp72-.Ltmp67                //   Call between .Ltmp67 and .Ltmp72
	.uleb128 .Ltmp73-.Lfunc_begin4          //     jumps to .Ltmp73
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp72-.Lfunc_begin4          // >> Call Site 3 <<
	.uleb128 .Lfunc_end18-.Ltmp72           //   Call between .Ltmp72 and .Lfunc_end18
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end4:
	.p2align	2
                                        // -- End function
	.text
	.globl	_Z13box_z_compareSt10shared_ptrI8hittableES1_ // -- Begin function _Z13box_z_compareSt10shared_ptrI8hittableES1_
	.p2align	2
	.type	_Z13box_z_compareSt10shared_ptrI8hittableES1_,@function
_Z13box_z_compareSt10shared_ptrI8hittableES1_: // @_Z13box_z_compareSt10shared_ptrI8hittableES1_
.Lfunc_begin5:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception5
// %bb.0:
	sub	sp, sp, #176
	stp	d9, d8, [sp, #128]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	.cfi_offset b8, -40
	.cfi_offset b9, -48
	adrp	x20, :got:__libc_single_threaded
	mov	x19, x1
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x0]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB19_3
// %bb.1:
	ldrb	w9, [x20]
	cbz	w9, .LBB19_6
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB19_3:
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbz	x8, .LBB19_8
.LBB19_4:
	ldrb	w9, [x20]
	cbz	w9, .LBB19_7
// %bb.5:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB19_8
.LBB19_6:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB19_4
	b	.LBB19_8
.LBB19_7:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB19_8:
	movi	v0.2d, #0000000000000000
	ldr	x0, [sp, #16]
	stp	q0, q0, [x29, #-48]
	stur	q0, [x29, #-64]
	stp	q0, q0, [sp, #48]
	str	q0, [sp, #32]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp74:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	sub	x1, x29, #64
	blr	x8
.Ltmp75:
// %bb.9:
	tbz	w0, #0, .LBB19_12
// %bb.10:
	ldr	x0, [sp]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp76:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	add	x1, sp, #32
	blr	x8
.Ltmp77:
// %bb.11:
	tbnz	w0, #0, .LBB19_13
.LBB19_12:
.Ltmp78:
	adrp	x0, :got:_ZSt4cerr
	adrp	x1, .L.str
	add	x1, x1, :lo12:.L.str
	mov	w2, #41
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp79:
.LBB19_13:
	ldur	d8, [x29, #-48]
	ldr	x19, [sp, #8]
	ldr	d9, [sp, #48]
	cbz	x19, .LBB19_20
// %bb.14:
	ldrb	w8, [x20]
	cbz	w8, .LBB19_16
// %bb.15:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB19_17
	b	.LBB19_20
.LBB19_16:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB19_20
.LBB19_17:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB19_28
// %bb.18:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB19_20
.LBB19_19:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB19_20:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB19_27
// %bb.21:
	ldrb	w8, [x20]
	cbz	w8, .LBB19_23
// %bb.22:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB19_24
	b	.LBB19_27
.LBB19_23:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB19_27
.LBB19_24:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB19_29
// %bb.25:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB19_27
.LBB19_26:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB19_27:
	fcmp	d8, d9
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	cset	w0, mi
	ldp	d9, d8, [sp, #128]              // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB19_28:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB19_19
	b	.LBB19_20
.LBB19_29:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB19_26
	b	.LBB19_27
.LBB19_30:
.Ltmp80:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end19:
	.size	_Z13box_z_compareSt10shared_ptrI8hittableES1_, .Lfunc_end19-_Z13box_z_compareSt10shared_ptrI8hittableES1_
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table19:
.Lexception5:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end5-.Lcst_begin5
.Lcst_begin5:
	.uleb128 .Lfunc_begin5-.Lfunc_begin5    // >> Call Site 1 <<
	.uleb128 .Ltmp74-.Lfunc_begin5          //   Call between .Lfunc_begin5 and .Ltmp74
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp74-.Lfunc_begin5          // >> Call Site 2 <<
	.uleb128 .Ltmp79-.Ltmp74                //   Call between .Ltmp74 and .Ltmp79
	.uleb128 .Ltmp80-.Lfunc_begin5          //     jumps to .Ltmp80
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp79-.Lfunc_begin5          // >> Call Site 3 <<
	.uleb128 .Lfunc_end19-.Ltmp79           //   Call between .Ltmp79 and .Lfunc_end19
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end5:
	.p2align	2
                                        // -- End function
	.text
	.globl	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd // -- Begin function _ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
	.p2align	2
	.type	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd,@function
_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd: // @_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.Lfunc_begin6:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception6
// %bb.0:
	sub	sp, sp, #288
	stp	d9, d8, [sp, #176]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            // 16-byte Folded Spill
	add	x29, sp, #192
	stp	x28, x27, [sp, #208]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	fmov	d9, d0
	adrp	x8, _ZTV8bvh_node+16
	movi	v0.2d, #0000000000000000
	add	x8, x8, :lo12:_ZTV8bvh_node+16
	mov	x9, x0
	mov	x10, x0
	fmov	d8, d1
	mov	x21, x0
	str	x8, [x0]
	mov	x23, x3
	str	q0, [x9, #8]!
	str	q0, [x10, #24]!
	stur	q0, [x0, #40]
	mov	x22, x2
	stur	q0, [x0, #56]
	stur	q0, [x0, #72]
	ldp	x20, x27, [x1]
	stp	x10, x9, [sp]                   // 16-byte Folded Spill
	subs	x25, x27, x20
	b.eq	.LBB20_4
// %bb.1:
	mov	x8, #-15
	movk	x8, #32767, lsl #48
	cmp	x25, x8
	b.hs	.LBB20_164
// %bb.2:
	mov	x26, x1
.Ltmp81:
	mov	x0, x25
	bl	_Znwm
.Ltmp82:
// %bb.3:
	ldp	x20, x27, [x26]
	mov	x24, x0
	b	.LBB20_5
.LBB20_4:
	mov	x24, xzr
.LBB20_5:
	adrp	x28, :got:__libc_single_threaded
	asr	x8, x25, #4
	cmp	x20, x27
	add	x8, x24, x8, lsl #4
	ldr	x28, [x28, :got_lo12:__libc_single_threaded]
	stp	x24, x24, [x29, #-48]
	stur	x8, [x29, #-32]
	b.ne	.LBB20_17
.LBB20_6:
	stur	x24, [x29, #-40]
	bl	rand
	mov	x8, #4467570830351532032
	scvtf	d0, w0
	movi	d2, #0000000000000000
	adrp	x9, _Z13box_z_compareSt10shared_ptrI8hittableES1_
	adrp	x10, _Z13box_y_compareSt10shared_ptrI8hittableES1_
	add	x9, x9, :lo12:_Z13box_z_compareSt10shared_ptrI8hittableES1_
	fmov	d1, x8
	add	x10, x10, :lo12:_Z13box_y_compareSt10shared_ptrI8hittableES1_
	adrp	x11, _Z13box_x_compareSt10shared_ptrI8hittableES1_
	sub	x20, x23, x22
	add	x11, x11, :lo12:_Z13box_x_compareSt10shared_ptrI8hittableES1_
	fmul	d0, d0, d1
	fmov	d1, #3.00000000
	fmadd	d0, d0, d1, d2
	fcvtzs	w8, d0
	cmp	w8, #1
	csel	x9, x10, x9, eq
	cmp	w8, #0
	csel	x24, x11, x9, eq
	cmp	x20, #2
	b.eq	.LBB20_20
// %bb.7:
	cmp	x20, #1
	b.ne	.LBB20_23
// %bb.8:
	ldur	x8, [x29, #-48]
	add	x9, x8, x22, lsl #4
	ldr	x22, [x21, #32]
	ldr	x8, [x9]
	str	x8, [x21, #24]
	ldr	x23, [x9, #8]
	cmp	x23, x22
	b.eq	.LBB20_90
// %bb.9:
	cbz	x23, .LBB20_12
// %bb.10:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_84
// %bb.11:
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
.LBB20_12:
	cbz	x22, .LBB20_89
.LBB20_13:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_85
// %bb.14:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB20_86
	b	.LBB20_89
.LBB20_15:                              //   in Loop: Header=BB20_17 Depth=1
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB20_16:                              //   in Loop: Header=BB20_17 Depth=1
	add	x24, x24, #16
	add	x20, x20, #16
	cmp	x20, x27
	b.eq	.LBB20_6
.LBB20_17:                              // =>This Inner Loop Header: Depth=1
	ldr	x8, [x20]
	str	x8, [x24]
	ldr	x8, [x20, #8]
	str	x8, [x24, #8]
	cbz	x8, .LBB20_16
// %bb.18:                              //   in Loop: Header=BB20_17 Depth=1
	ldrb	w9, [x28]
	cbnz	w9, .LBB20_15
// %bb.19:                              //   in Loop: Header=BB20_17 Depth=1
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB20_16
.LBB20_20:
	ldur	x8, [x29, #-48]
	add	x9, x8, x22, lsl #4
	ldr	x10, [x9]
	stur	x10, [x29, #-64]
	ldr	x9, [x9, #8]
	stur	x9, [x29, #-56]
	cbz	x9, .LBB20_38
// %bb.21:
	ldrb	w10, [x28]
	cbz	w10, .LBB20_37
// %bb.22:
	ldr	w10, [x9, #8]
	add	w10, w10, #1
	str	w10, [x9, #8]
	b	.LBB20_38
.LBB20_23:
	cmp	x23, x22
	b.eq	.LBB20_32
// %bb.24:
	ldur	x19, [x29, #-48]
	mov	w9, #126
	add	x26, x19, x22, lsl #4
	add	x25, x19, x23, lsl #4
	sub	x27, x25, x26
	asr	x8, x27, #4
	clz	x8, x8
	sub	x2, x9, x8, lsl #1
.Ltmp89:
	mov	x0, x26
	mov	x1, x25
	mov	x3, x24
	bl	_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_
.Ltmp90:
// %bb.25:
	cmp	x27, #257
	b.lt	.LBB20_31
// %bb.26:
	add	x27, x26, #256
.Ltmp93:
	mov	x0, x26
	mov	x1, x27
	mov	x2, x24
	bl	_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_
.Ltmp94:
// %bb.27:
	cmp	x27, x25
	b.eq	.LBB20_32
// %bb.28:
	lsl	x8, x23, #4
	lsl	x9, x22, #4
	sub	x8, x8, x9
	add	x9, x19, x9
	sub	x19, x8, #256
	add	x25, x9, #256
.LBB20_29:                              // =>This Inner Loop Header: Depth=1
.Ltmp96:
	mov	x0, x25
	mov	x1, x24
	bl	_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_
.Ltmp97:
// %bb.30:                              //   in Loop: Header=BB20_29 Depth=1
	subs	x19, x19, #16
	add	x25, x25, #16
	b.ne	.LBB20_29
	b	.LBB20_32
.LBB20_31:
.Ltmp91:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x24
	bl	_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_
.Ltmp92:
.LBB20_32:
.Ltmp99:
	mov	w0, #104
	bl	_Znwm
.Ltmp100:
// %bb.33:
	movi	v0.2s, #1
	adrp	x27, _ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x25, x0
	add	x27, x27, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x24, x22, x20, lsr #1
	add	x26, x0, #16
	str	d0, [x0, #8]
	str	x27, [x0]
.Ltmp102:
	fmov	d0, d9
	fmov	d1, d8
	sub	x1, x29, #48
	mov	x0, x26
	mov	x2, x22
	mov	x3, x24
	bl	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.Ltmp103:
// %bb.34:
	ldr	x22, [x21, #16]
	stp	x26, x25, [x21, #8]
	cbz	x22, .LBB20_76
// %bb.35:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_72
// %bb.36:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB20_73
	b	.LBB20_76
.LBB20_37:
	add	x1, x9, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x8, [x29, #-48]
.LBB20_38:
	add	x25, x22, #1
	add	x8, x8, x25, lsl #4
	ldr	x9, [x8]
	stur	x9, [x29, #-80]
	ldr	x8, [x8, #8]
	stur	x8, [x29, #-72]
	cbz	x8, .LBB20_42
// %bb.39:
	ldrb	w9, [x28]
	cbz	w9, .LBB20_41
// %bb.40:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB20_42
.LBB20_41:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB20_42:
.Ltmp86:
	sub	x0, x29, #64
	sub	x1, x29, #80
	blr	x24
.Ltmp87:
// %bb.43:
	mov	w23, w0
	ldur	x24, [x29, #-72]
	cbz	x24, .LBB20_50
// %bb.44:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_46
// %bb.45:
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB20_47
	b	.LBB20_50
.LBB20_46:
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_50
.LBB20_47:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_103
// %bb.48:
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB20_50
.LBB20_49:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_50:
	ldur	x24, [x29, #-56]
	cbz	x24, .LBB20_57
// %bb.51:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_53
// %bb.52:
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB20_54
	b	.LBB20_57
.LBB20_53:
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_57
.LBB20_54:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_104
// %bb.55:
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB20_57
.LBB20_56:
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_57:
	ldur	x8, [x29, #-48]
	tbz	w23, #0, .LBB20_65
// %bb.58:
	add	x9, x8, x22, lsl #4
	ldr	x22, [x21, #16]
	ldr	x10, [x9]
	str	x10, [x21, #8]
	ldr	x20, [x9, #8]
	cmp	x20, x22
	b.eq	.LBB20_122
// %bb.59:
	cbz	x20, .LBB20_62
// %bb.60:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_110
// %bb.61:
	ldr	w8, [x20, #8]
	add	w8, w8, #1
	str	w8, [x20, #8]
.LBB20_62:
	cbz	x22, .LBB20_121
.LBB20_63:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_111
// %bb.64:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB20_112
	b	.LBB20_121
.LBB20_65:
	add	x9, x8, x25, lsl #4
	ldr	x23, [x21, #16]
	ldr	x10, [x9]
	str	x10, [x21, #8]
	ldr	x20, [x9, #8]
	cmp	x20, x23
	b.eq	.LBB20_131
// %bb.66:
	cbz	x20, .LBB20_69
// %bb.67:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_114
// %bb.68:
	ldr	w8, [x20, #8]
	add	w8, w8, #1
	str	w8, [x20, #8]
.LBB20_69:
	cbz	x23, .LBB20_130
.LBB20_70:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_115
// %bb.71:
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.eq	.LBB20_116
	b	.LBB20_130
.LBB20_72:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_76
.LBB20_73:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_105
// %bb.74:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB20_76
.LBB20_75:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_76:
.Ltmp105:
	mov	w0, #104
	bl	_Znwm
.Ltmp106:
// %bb.77:
	movi	v0.2s, #1
	mov	x25, x0
	add	x26, x0, #16
	str	x27, [x0]
	str	d0, [x0, #8]
.Ltmp108:
	fmov	d0, d9
	fmov	d1, d8
	sub	x1, x29, #48
	mov	x0, x26
	mov	x2, x24
	mov	x3, x23
	bl	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.Ltmp109:
// %bb.78:
	ldr	x22, [x21, #32]
	stp	x26, x25, [x21, #24]
	cbz	x22, .LBB20_144
// %bb.79:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_81
// %bb.80:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB20_82
	b	.LBB20_144
.LBB20_81:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_144
.LBB20_82:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_106
// %bb.83:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.eq	.LBB20_107
	b	.LBB20_144
.LBB20_84:
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x22, [x21, #32]
	cbnz	x22, .LBB20_13
	b	.LBB20_89
.LBB20_85:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_89
.LBB20_86:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_108
// %bb.87:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB20_89
.LBB20_88:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_89:
	ldr	x8, [x21, #24]
	str	x23, [x21, #32]
.LBB20_90:
	ldr	x22, [x21, #16]
	str	x8, [x21, #8]
	cmp	x23, x22
	b.eq	.LBB20_144
// %bb.91:
	cbz	x23, .LBB20_94
// %bb.92:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_97
// %bb.93:
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
.LBB20_94:
	cbz	x22, .LBB20_102
.LBB20_95:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_98
// %bb.96:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB20_99
	b	.LBB20_102
.LBB20_97:
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x22, [x21, #16]
	cbnz	x22, .LBB20_95
	b	.LBB20_102
.LBB20_98:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_102
.LBB20_99:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_109
// %bb.100:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB20_102
.LBB20_101:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_102:
	str	x23, [x21, #16]
	b	.LBB20_144
.LBB20_103:
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB20_49
	b	.LBB20_50
.LBB20_104:
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB20_56
	b	.LBB20_57
.LBB20_105:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB20_75
	b	.LBB20_76
.LBB20_106:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_144
.LBB20_107:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB20_144
.LBB20_108:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB20_88
	b	.LBB20_89
.LBB20_109:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB20_101
	b	.LBB20_102
.LBB20_110:
	add	x1, x20, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x22, [x21, #16]
	cbnz	x22, .LBB20_63
	b	.LBB20_121
.LBB20_111:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_121
.LBB20_112:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_118
// %bb.113:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	b	.LBB20_119
.LBB20_114:
	add	x1, x20, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [x21, #16]
	cbnz	x23, .LBB20_70
	b	.LBB20_130
.LBB20_115:
	add	x1, x23, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_130
.LBB20_116:
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_127
// %bb.117:
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	b	.LBB20_128
.LBB20_118:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB20_119:
	cmp	w0, #1
	b.ne	.LBB20_121
// %bb.120:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_121:
	ldur	x8, [x29, #-48]
	str	x20, [x21, #16]
.LBB20_122:
	add	x8, x8, x25, lsl #4
	ldr	x22, [x21, #32]
	ldr	x9, [x8]
	str	x9, [x21, #24]
	ldr	x20, [x8, #8]
	cmp	x20, x22
	b.eq	.LBB20_144
// %bb.123:
	cbz	x20, .LBB20_136
// %bb.124:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_126
// %bb.125:
	ldr	w8, [x20, #8]
	add	w8, w8, #1
	str	w8, [x20, #8]
	b	.LBB20_136
.LBB20_126:
	add	x1, x20, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x22, [x21, #32]
	cbnz	x22, .LBB20_137
	b	.LBB20_143
.LBB20_127:
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB20_128:
	cmp	w0, #1
	b.ne	.LBB20_130
// %bb.129:
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_130:
	ldur	x8, [x29, #-48]
	str	x20, [x21, #16]
.LBB20_131:
	add	x8, x8, x22, lsl #4
	ldr	x22, [x21, #32]
	ldr	x9, [x8]
	str	x9, [x21, #24]
	ldr	x20, [x8, #8]
	cmp	x20, x22
	b.eq	.LBB20_144
// %bb.132:
	cbz	x20, .LBB20_136
// %bb.133:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_135
// %bb.134:
	ldr	w8, [x20, #8]
	add	w8, w8, #1
	str	w8, [x20, #8]
	cbnz	x22, .LBB20_137
	b	.LBB20_143
.LBB20_135:
	add	x1, x20, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x22, [x21, #32]
.LBB20_136:
	cbz	x22, .LBB20_143
.LBB20_137:
	ldrb	w8, [x28]
	cbz	w8, .LBB20_139
// %bb.138:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB20_140
	b	.LBB20_143
.LBB20_139:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_143
.LBB20_140:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_163
// %bb.141:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB20_143
.LBB20_142:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_143:
	str	x20, [x21, #32]
.LBB20_144:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	movi	v0.2d, #0000000000000000
	ldr	x0, [x8]
	stp	q0, q0, [sp, #80]
	stp	q0, q0, [sp, #48]
	stp	q0, q0, [sp, #16]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp111:
	fmov	d0, d9
	fmov	d1, d8
	add	x1, sp, #64
	blr	x8
.Ltmp112:
// %bb.145:
	tbz	w0, #0, .LBB20_148
// %bb.146:
	ldr	x8, [sp]                        // 8-byte Folded Reload
	ldr	x0, [x8]
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp113:
	fmov	d0, d9
	fmov	d1, d8
	add	x1, sp, #16
	blr	x8
.Ltmp114:
// %bb.147:
	tbnz	w0, #0, .LBB20_149
.LBB20_148:
.Ltmp115:
	adrp	x0, :got:_ZSt4cerr
	adrp	x1, .L.str
	add	x1, x1, :lo12:.L.str
	mov	w2, #41
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp116:
.LBB20_149:
	ldp	d0, d1, [sp, #64]
	ldp	d6, d7, [sp, #16]
	ldp	d2, d3, [sp, #80]
	ldp	d4, d5, [sp, #96]
	fminnm	d0, d0, d6
	fminnm	d1, d1, d7
	ldp	d16, d17, [sp, #32]
	ldp	d18, d6, [sp, #48]
	stp	d0, d1, [x21, #40]
	ldp	x19, x22, [x29, #-48]
	fminnm	d2, d2, d16
	fmaxnm	d3, d3, d17
	fmaxnm	d4, d4, d18
	fmaxnm	d5, d5, d6
	cmp	x19, x22
	stp	d2, d3, [x21, #56]
	stp	d4, d5, [x21, #72]
	b.ne	.LBB20_155
// %bb.150:
	cbz	x19, .LBB20_152
.LBB20_151:
	mov	x0, x19
	bl	_ZdlPv
.LBB20_152:
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #208]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #192]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #176]              // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.LBB20_153:                             //   in Loop: Header=BB20_155 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB20_154:                             //   in Loop: Header=BB20_155 Depth=1
	add	x19, x19, #16
	cmp	x19, x22
	b.eq	.LBB20_162
.LBB20_155:                             // =>This Inner Loop Header: Depth=1
	ldr	x20, [x19, #8]
	cbz	x20, .LBB20_154
// %bb.156:                             //   in Loop: Header=BB20_155 Depth=1
	ldrb	w8, [x28]
	cbz	w8, .LBB20_158
// %bb.157:                             //   in Loop: Header=BB20_155 Depth=1
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB20_154
	b	.LBB20_159
.LBB20_158:                             //   in Loop: Header=BB20_155 Depth=1
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_154
.LBB20_159:                             //   in Loop: Header=BB20_155 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x28]
	cbz	w8, .LBB20_161
// %bb.160:                             //   in Loop: Header=BB20_155 Depth=1
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB20_154
	b	.LBB20_153
.LBB20_161:                             //   in Loop: Header=BB20_155 Depth=1
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB20_154
	b	.LBB20_153
.LBB20_162:
	ldur	x19, [x29, #-48]
	cbnz	x19, .LBB20_151
	b	.LBB20_152
.LBB20_163:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB20_142
	b	.LBB20_143
.LBB20_164:
.Ltmp83:
	bl	_ZSt28__throw_bad_array_new_lengthv
.Ltmp84:
// %bb.165:
.LBB20_166:
.Ltmp110:
	b	.LBB20_169
.LBB20_167:
.Ltmp107:
	b	.LBB20_175
.LBB20_168:
.Ltmp104:
.LBB20_169:
	mov	x21, x0
	mov	x0, x25
	bl	_ZdlPv
	b	.LBB20_176
.LBB20_170:
.Ltmp101:
	b	.LBB20_175
.LBB20_171:
.Ltmp95:
	b	.LBB20_175
.LBB20_172:
.Ltmp88:
	mov	x21, x0
	sub	x0, x29, #80
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #64
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB20_176
.LBB20_173:
.Ltmp98:
	b	.LBB20_175
.LBB20_174:
.Ltmp117:
.LBB20_175:
	mov	x21, x0
.LBB20_176:
	sub	x0, x29, #48
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev
	b	.LBB20_178
.LBB20_177:
.Ltmp85:
	mov	x21, x0
.LBB20_178:
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x21
	bl	_Unwind_Resume
.Lfunc_end20:
	.size	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd, .Lfunc_end20-_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table20:
.Lexception6:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end6-.Lcst_begin6
.Lcst_begin6:
	.uleb128 .Ltmp81-.Lfunc_begin6          // >> Call Site 1 <<
	.uleb128 .Ltmp82-.Ltmp81                //   Call between .Ltmp81 and .Ltmp82
	.uleb128 .Ltmp85-.Lfunc_begin6          //     jumps to .Ltmp85
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp82-.Lfunc_begin6          // >> Call Site 2 <<
	.uleb128 .Ltmp89-.Ltmp82                //   Call between .Ltmp82 and .Ltmp89
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp89-.Lfunc_begin6          // >> Call Site 3 <<
	.uleb128 .Ltmp94-.Ltmp89                //   Call between .Ltmp89 and .Ltmp94
	.uleb128 .Ltmp95-.Lfunc_begin6          //     jumps to .Ltmp95
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp96-.Lfunc_begin6          // >> Call Site 4 <<
	.uleb128 .Ltmp97-.Ltmp96                //   Call between .Ltmp96 and .Ltmp97
	.uleb128 .Ltmp98-.Lfunc_begin6          //     jumps to .Ltmp98
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp91-.Lfunc_begin6          // >> Call Site 5 <<
	.uleb128 .Ltmp92-.Ltmp91                //   Call between .Ltmp91 and .Ltmp92
	.uleb128 .Ltmp95-.Lfunc_begin6          //     jumps to .Ltmp95
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp99-.Lfunc_begin6          // >> Call Site 6 <<
	.uleb128 .Ltmp100-.Ltmp99               //   Call between .Ltmp99 and .Ltmp100
	.uleb128 .Ltmp101-.Lfunc_begin6         //     jumps to .Ltmp101
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp102-.Lfunc_begin6         // >> Call Site 7 <<
	.uleb128 .Ltmp103-.Ltmp102              //   Call between .Ltmp102 and .Ltmp103
	.uleb128 .Ltmp104-.Lfunc_begin6         //     jumps to .Ltmp104
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp103-.Lfunc_begin6         // >> Call Site 8 <<
	.uleb128 .Ltmp86-.Ltmp103               //   Call between .Ltmp103 and .Ltmp86
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp86-.Lfunc_begin6          // >> Call Site 9 <<
	.uleb128 .Ltmp87-.Ltmp86                //   Call between .Ltmp86 and .Ltmp87
	.uleb128 .Ltmp88-.Lfunc_begin6          //     jumps to .Ltmp88
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp87-.Lfunc_begin6          // >> Call Site 10 <<
	.uleb128 .Ltmp105-.Ltmp87               //   Call between .Ltmp87 and .Ltmp105
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp105-.Lfunc_begin6         // >> Call Site 11 <<
	.uleb128 .Ltmp106-.Ltmp105              //   Call between .Ltmp105 and .Ltmp106
	.uleb128 .Ltmp107-.Lfunc_begin6         //     jumps to .Ltmp107
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp108-.Lfunc_begin6         // >> Call Site 12 <<
	.uleb128 .Ltmp109-.Ltmp108              //   Call between .Ltmp108 and .Ltmp109
	.uleb128 .Ltmp110-.Lfunc_begin6         //     jumps to .Ltmp110
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp109-.Lfunc_begin6         // >> Call Site 13 <<
	.uleb128 .Ltmp111-.Ltmp109              //   Call between .Ltmp109 and .Ltmp111
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp111-.Lfunc_begin6         // >> Call Site 14 <<
	.uleb128 .Ltmp116-.Ltmp111              //   Call between .Ltmp111 and .Ltmp116
	.uleb128 .Ltmp117-.Lfunc_begin6         //     jumps to .Ltmp117
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp116-.Lfunc_begin6         // >> Call Site 15 <<
	.uleb128 .Ltmp83-.Ltmp116               //   Call between .Ltmp116 and .Ltmp83
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp83-.Lfunc_begin6          // >> Call Site 16 <<
	.uleb128 .Ltmp84-.Ltmp83                //   Call between .Ltmp83 and .Ltmp84
	.uleb128 .Ltmp85-.Lfunc_begin6          //     jumps to .Ltmp85
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp84-.Lfunc_begin6          // >> Call Site 17 <<
	.uleb128 .Lfunc_end20-.Ltmp84           //   Call between .Ltmp84 and .Lfunc_end20
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end6:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB21_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB21_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB21_4
	b	.LBB21_8
.LBB21_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB21_8
.LBB21_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB21_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB21_8
.LBB21_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB21_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB21_6
.LBB21_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end21:
	.size	_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end21-_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev,"axG",@progbits,_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev,comdat
	.weak	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev // -- Begin function _ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev
	.p2align	2
	.type	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev,@function
_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev: // @_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x19, x22, [x0]
	cmp	x19, x22
	b.eq	.LBB22_12
// %bb.1:
	adrp	x23, :got:__libc_single_threaded
	mov	x20, x0
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	b	.LBB22_3
.LBB22_2:                               //   in Loop: Header=BB22_3 Depth=1
	add	x19, x19, #16
	cmp	x19, x22
	b.eq	.LBB22_11
.LBB22_3:                               // =>This Inner Loop Header: Depth=1
	ldr	x21, [x19, #8]
	cbz	x21, .LBB22_2
// %bb.4:                               //   in Loop: Header=BB22_3 Depth=1
	ldrb	w8, [x23]
	cbz	w8, .LBB22_6
// %bb.5:                               //   in Loop: Header=BB22_3 Depth=1
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.ne	.LBB22_2
	b	.LBB22_7
.LBB22_6:                               //   in Loop: Header=BB22_3 Depth=1
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB22_2
.LBB22_7:                               //   in Loop: Header=BB22_3 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB22_9
// %bb.8:                               //   in Loop: Header=BB22_3 Depth=1
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB22_2
	b	.LBB22_10
.LBB22_9:                               //   in Loop: Header=BB22_3 Depth=1
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB22_2
.LBB22_10:                              //   in Loop: Header=BB22_3 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB22_2
.LBB22_11:
	ldr	x19, [x20]
.LBB22_12:
	cbz	x19, .LBB22_14
// %bb.13:
	mov	x0, x19
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	b	_ZdlPv
.LBB22_14:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end22:
	.size	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev, .Lfunc_end22-_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev
	.cfi_endproc
                                        // -- End function
	.text
	.globl	_ZNK8bvh_node3hitERK3rayddR10hit_record // -- Begin function _ZNK8bvh_node3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK8bvh_node3hitERK3rayddR10hit_record,@function
_ZNK8bvh_node3hitERK3rayddR10hit_record: // @_ZNK8bvh_node3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	stp	d9, d8, [sp, #-64]!             // 16-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	fmov	d9, d1
	fmov	d8, d0
	ldr	d0, [x1]
	ldr	d1, [x0, #40]
	ldr	d3, [x0, #64]
	ldr	d2, [x1, #24]
	fsub	d1, d1, d0
	fsub	d0, d3, d0
	fdiv	d1, d1, d2
	fdiv	d0, d0, d2
	fminnm	d2, d1, d0
	fmaxnm	d1, d1, d0
	fmaxnm	d0, d2, d8
	fminnm	d1, d1, d9
	fcmp	d1, d0
	b.ls	.LBB23_4
// %bb.1:
	ldr	d2, [x1, #8]
	mov	x19, x1
	ldr	d3, [x0, #48]
	mov	x20, x0
	ldr	d5, [x0, #72]
	ldr	d4, [x1, #32]
	fsub	d3, d3, d2
	fsub	d2, d5, d2
	fdiv	d3, d3, d4
	fdiv	d2, d2, d4
	fminnm	d4, d3, d2
	fmaxnm	d2, d3, d2
	fmaxnm	d0, d4, d0
	fminnm	d1, d2, d1
	fcmp	d1, d0
	b.ls	.LBB23_4
// %bb.2:
	ldr	d2, [x19, #16]
	ldr	d3, [x20, #56]
	ldr	d5, [x20, #80]
	ldr	d4, [x19, #40]
	fsub	d3, d3, d2
	fsub	d2, d5, d2
	fdiv	d3, d3, d4
	fdiv	d2, d2, d4
	fminnm	d4, d3, d2
	fmaxnm	d2, d3, d2
	fmaxnm	d0, d4, d0
	fminnm	d1, d2, d1
	fcmp	d1, d0
	b.ls	.LBB23_4
// %bb.3:
	ldr	x0, [x20, #8]
	fmov	d0, d8
	fmov	d1, d9
	mov	x1, x19
	mov	x21, x2
	ldr	x8, [x0]
	ldr	x8, [x8]
	blr	x8
	mov	w22, w0
	ldr	x0, [x20, #24]
	ldr	d0, [x21, #64]
	tst	w22, #0x1
	mov	x1, x19
	mov	x2, x21
	ldr	x8, [x0]
	fcsel	d1, d0, d9, ne
	fmov	d0, d8
	ldr	x8, [x8]
	blr	x8
	orr	w8, w22, w0
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	and	w0, w8, #0x1
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldp	d9, d8, [sp], #64               // 16-byte Folded Reload
	ret
.LBB23_4:
	mov	w8, wzr
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	and	w0, w8, #0x1
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldp	d9, d8, [sp], #64               // 16-byte Folded Reload
	ret
.Lfunc_end23:
	.size	_ZNK8bvh_node3hitERK3rayddR10hit_record, .Lfunc_end23-_ZNK8bvh_node3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK8bvh_node12bounding_boxEddR4aabb // -- Begin function _ZNK8bvh_node12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK8bvh_node12bounding_boxEddR4aabb,@function
_ZNK8bvh_node12bounding_boxEddR4aabb:   // @_ZNK8bvh_node12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	mov	w0, #1
	ldur	q0, [x8, #72]
	ldur	q1, [x8, #56]
	ldur	q2, [x8, #40]
	stp	q1, q0, [x1, #16]
	str	q2, [x1]
	ret
.Lfunc_end24:
	.size	_ZNK8bvh_node12bounding_boxEddR4aabb, .Lfunc_end24-_ZNK8bvh_node12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _Z11write_colorRSo4vec3i
.LCPI25_0:
	.xword	0x3feff7ced916872b              // double 0.99899999999999999
	.text
	.globl	_Z11write_colorRSo4vec3i
	.p2align	2
	.type	_Z11write_colorRSo4vec3i,@function
_Z11write_colorRSo4vec3i:               // @_Z11write_colorRSo4vec3i
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #96
	str	d12, [sp, #32]                  // 8-byte Folded Spill
	stp	d11, d10, [sp, #40]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #56]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #72]             // 16-byte Folded Spill
	add	x29, sp, #72
	str	x19, [sp, #88]                  // 8-byte Folded Spill
	.cfi_def_cfa w29, 24
	.cfi_offset w19, -8
	.cfi_offset w30, -16
	.cfi_offset w29, -24
	.cfi_offset b8, -32
	.cfi_offset b9, -40
	.cfi_offset b10, -48
	.cfi_offset b11, -56
	.cfi_offset b12, -64
	scvtf	d3, w1
	fmov	d4, #1.00000000
	fcmp	d0, d0
	fdiv	d8, d4, d3
	movi	d4, #0000000000000000
	fcsel	d0, d0, d4, vc
	fcmp	d1, d1
	fcsel	d9, d1, d4, vc
	fcmp	d2, d2
	fcsel	d2, d2, d4, vc
	fmul	d3, d8, d0
	fsqrt	d0, d3
	fcmp	d0, d0
	b.vs	.LBB25_4
// %bb.1:
	fmul	d1, d8, d9
	fsqrt	d9, d1
	fcmp	d9, d9
	b.vs	.LBB25_5
.LBB25_2:
	fmul	d1, d8, d2
	fsqrt	d8, d1
	fcmp	d8, d8
	b.vs	.LBB25_6
.LBB25_3:
	adrp	x8, .LCPI25_0
	movi	d12, #0000000000000000
	fcmp	d0, #0.0
	ldr	d10, [x8, :lo12:.LCPI25_0]
	mov	x8, #4643211215818981376
	fmin	d1, d0, d10
	fmov	d11, x8
	fmul	d1, d1, d11
	fcsel	d0, d12, d1, mi
	fcvtzs	w1, d0
	bl	_ZNSolsEi
	mov	w19, #32
	add	x1, sp, #20
	mov	w2, #1
	strb	w19, [sp, #20]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
	fmin	d0, d9, d10
	fcmp	d9, #0.0
	fmul	d0, d0, d11
	fcsel	d0, d12, d0, mi
	fcvtzs	w1, d0
	bl	_ZNSolsEi
	add	x1, sp, #24
	mov	w2, #1
	strb	w19, [sp, #24]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
	fmin	d0, d8, d10
	fcmp	d8, #0.0
	fmul	d0, d0, d11
	fcsel	d0, d12, d0, mi
	fcvtzs	w1, d0
	bl	_ZNSolsEi
	mov	w8, #10
	add	x1, sp, #28
	mov	w2, #1
	strb	w8, [sp, #28]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
	ldp	x29, x30, [sp, #72]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #56]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #40]             // 16-byte Folded Reload
	ldr	x19, [sp, #88]                  // 8-byte Folded Reload
	ldr	d12, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB25_4:
	fmov	d0, d3
	str	x0, [sp, #8]                    // 8-byte Folded Spill
	str	d2, [sp]                        // 8-byte Folded Spill
	bl	sqrt
	ldr	d2, [sp]                        // 8-byte Folded Reload
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	fmul	d1, d8, d9
	fsqrt	d9, d1
	fcmp	d9, d9
	b.vc	.LBB25_2
.LBB25_5:
	str	d0, [sp]                        // 8-byte Folded Spill
	fmov	d0, d1
	str	x0, [sp, #8]                    // 8-byte Folded Spill
	fmov	d9, d2
	bl	sqrt
	fmov	d2, d9
	fmov	d9, d0
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	ldr	d0, [sp]                        // 8-byte Folded Reload
	fmul	d1, d8, d2
	fsqrt	d8, d1
	fcmp	d8, d8
	b.vc	.LBB25_3
.LBB25_6:
	str	d0, [sp]                        // 8-byte Folded Spill
	fmov	d0, d1
	str	x0, [sp, #8]                    // 8-byte Folded Spill
	bl	sqrt
	fmov	d8, d0
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	ldr	d0, [sp]                        // 8-byte Folded Reload
	b	.LBB25_3
.Lfunc_end25:
	.size	_Z11write_colorRSo4vec3i, .Lfunc_end25-_Z11write_colorRSo4vec3i
	.cfi_endproc
                                        // -- End function
	.globl	stbi_failure_reason             // -- Begin function stbi_failure_reason
	.p2align	2
	.type	stbi_failure_reason,@function
stbi_failure_reason:                    // @stbi_failure_reason
	.cfi_startproc
// %bb.0:
	adrp	x8, .L_MergedGlobals.126+8
	ldr	x0, [x8, :lo12:.L_MergedGlobals.126+8]
	ret
.Lfunc_end26:
	.size	stbi_failure_reason, .Lfunc_end26-stbi_failure_reason
	.cfi_endproc
                                        // -- End function
	.globl	stbi_image_free                 // -- Begin function stbi_image_free
	.p2align	2
	.type	stbi_image_free,@function
stbi_image_free:                        // @stbi_image_free
	.cfi_startproc
// %bb.0:
	b	free
.Lfunc_end27:
	.size	stbi_image_free, .Lfunc_end27-stbi_image_free
	.cfi_endproc
                                        // -- End function
	.globl	stbi_set_flip_vertically_on_load // -- Begin function stbi_set_flip_vertically_on_load
	.p2align	2
	.type	stbi_set_flip_vertically_on_load,@function
stbi_set_flip_vertically_on_load:       // @stbi_set_flip_vertically_on_load
	.cfi_startproc
// %bb.0:
	adrp	x8, .L_MergedGlobals.126
	str	w0, [x8, :lo12:.L_MergedGlobals.126]
	ret
.Lfunc_end28:
	.size	stbi_set_flip_vertically_on_load, .Lfunc_end28-stbi_set_flip_vertically_on_load
	.cfi_endproc
                                        // -- End function
	.globl	stbi_load                       // -- Begin function stbi_load
	.p2align	2
	.type	stbi_load,@function
stbi_load:                              // @stbi_load
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x22, x1
	adrp	x1, .L.str.1
	add	x1, x1, :lo12:.L.str.1
	mov	w19, w4
	mov	x20, x3
	mov	x21, x2
	bl	fopen
	cbz	x0, .LBB29_2
// %bb.1:
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	w4, w19
	mov	x23, x0
	bl	stbi_load_from_file
	mov	x19, x0
	mov	x0, x23
	bl	fclose
	mov	x0, x19
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB29_2:
	adrp	x9, .L.str.2
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.2
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end29:
	.size	stbi_load, .Lfunc_end29-stbi_load
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_load_from_file
.LCPI30_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_load_from_file
	.p2align	2
	.type	stbi_load_from_file,@function
stbi_load_from_file:                    // @stbi_load_from_file
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #320
	stp	x29, x30, [sp, #224]            // 16-byte Folded Spill
	add	x29, sp, #224
	stp	x28, x27, [sp, #240]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #256]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #272]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #288]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #304]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	adrp	x9, _ZL21stbi__stdio_callbacks
	adrp	x8, .LCPI30_0
	add	x9, x9, :lo12:_ZL21stbi__stdio_callbacks
	add	x25, sp, #8
	add	x21, x25, #56
	mov	x24, x2
	mov	x22, x1
	mov	x1, x21
	ldr	q0, [x9]
	mov	w2, #128
	ldr	x9, [x9, #16]
	mov	w20, w4
	mov	x23, x3
	mov	x19, x0
	stur	q0, [sp, #24]
	ldr	d0, [x8, :lo12:.LCPI30_0]
	ldr	x8, [sp, #24]
	stp	x9, x0, [sp, #40]
	str	x21, [sp, #208]
	str	d0, [sp, #56]
	blr	x8
	cbz	w0, .LBB30_2
// %bb.1:
	add	x8, x25, w0, sxtw
	add	x8, x8, #56
	b	.LBB30_3
.LBB30_2:
	add	x8, x25, #57
	str	wzr, [sp, #56]
	strb	wzr, [sp, #64]
.LBB30_3:
	add	x0, sp, #8
	mov	x1, x22
	mov	x2, x24
	mov	x3, x23
	mov	w4, w20
	stp	x21, x8, [sp, #192]
	bl	_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
	mov	x21, x0
	cbz	x0, .LBB30_29
// %bb.4:
	adrp	x8, .L_MergedGlobals.126
	ldr	w8, [x8, :lo12:.L_MergedGlobals.126]
	cbz	w8, .LBB30_29
// %bb.5:
	ldr	w8, [x24]
	cbnz	w20, .LBB30_7
// %bb.6:
	ldr	w20, [x23]
.LBB30_7:
	cmp	w8, #2
	b.lt	.LBB30_30
// %bb.8:
	ldr	w9, [x22]
	cmp	w9, #1
	b.lt	.LBB30_30
// %bb.9:
	cmp	w20, #1
	b.lt	.LBB30_30
// %bb.10:
	mov	w12, w20
	sub	w18, w8, #1
	add	x14, x21, #16
	and	x17, x12, #0xfffffff8
	mul	x15, x12, x9
	mov	x10, xzr
	mul	w18, w9, w18
	lsr	x11, x8, #1
	and	x13, x12, #0xffffffe0
	and	x16, x12, #0x18
	neg	x0, x17
	mov	x1, x21
	mov	x2, x14
	b	.LBB30_12
.LBB30_11:                              //   in Loop: Header=BB30_12 Depth=1
	add	x10, x10, #1
	add	x2, x2, x15
	sub	w18, w18, w9
	add	x1, x1, x15
	cmp	x10, x11
	b.eq	.LBB30_30
.LBB30_12:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB30_14 Depth 2
                                        //       Child Loop BB30_22 Depth 3
                                        //       Child Loop BB30_26 Depth 3
                                        //       Child Loop BB30_28 Depth 3
	mvn	w4, w10
	sxtw	x6, w18
	add	w4, w8, w4
	mov	x3, xzr
	mul	x22, x12, x6
	mov	x24, x1
	mul	w5, w9, w4
	mov	x25, x2
	mul	x4, x15, x10
	add	x7, x21, x22
	sxtw	x5, w5
	add	x22, x14, x22
	add	x6, x4, x12
	mul	x5, x12, x5
	add	x23, x12, x5
	b	.LBB30_14
.LBB30_13:                              //   in Loop: Header=BB30_14 Depth=2
	add	x3, x3, #1
	add	x25, x25, x12
	add	x22, x22, x12
	add	x24, x24, x12
	add	x7, x7, x12
	cmp	x3, x9
	b.eq	.LBB30_11
.LBB30_14:                              //   Parent Loop BB30_12 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB30_22 Depth 3
                                        //       Child Loop BB30_26 Depth 3
                                        //       Child Loop BB30_28 Depth 3
	cmp	w20, #8
	b.hs	.LBB30_16
// %bb.15:                              //   in Loop: Header=BB30_14 Depth=2
	mov	x26, xzr
	b	.LBB30_28
.LBB30_16:                              //   in Loop: Header=BB30_14 Depth=2
	mul	x26, x3, x12
	add	x27, x23, x26
	add	x28, x4, x26
	add	x27, x21, x27
	add	x28, x21, x28
	cmp	x28, x27
	b.hs	.LBB30_19
// %bb.17:                              //   in Loop: Header=BB30_14 Depth=2
	add	x27, x5, x26
	add	x26, x6, x26
	add	x27, x21, x27
	add	x26, x21, x26
	cmp	x27, x26
	b.hs	.LBB30_19
// %bb.18:                              //   in Loop: Header=BB30_14 Depth=2
	mov	x26, xzr
	b	.LBB30_28
.LBB30_19:                              //   in Loop: Header=BB30_14 Depth=2
	cmp	w20, #32
	b.hs	.LBB30_21
// %bb.20:                              //   in Loop: Header=BB30_14 Depth=2
	mov	x28, xzr
	b	.LBB30_25
.LBB30_21:                              //   in Loop: Header=BB30_14 Depth=2
	mov	x26, x22
	mov	x27, x25
	mov	x28, x13
.LBB30_22:                              //   Parent Loop BB30_12 Depth=1
                                        //     Parent Loop BB30_14 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x26, #-16]
	subs	x28, x28, #32
	ldp	q2, q3, [x27, #-16]
	stp	q0, q1, [x27, #-16]
	add	x27, x27, #32
	stp	q2, q3, [x26, #-16]
	add	x26, x26, #32
	b.ne	.LBB30_22
// %bb.23:                              //   in Loop: Header=BB30_14 Depth=2
	cmp	x13, x12
	b.eq	.LBB30_13
// %bb.24:                              //   in Loop: Header=BB30_14 Depth=2
	mov	x28, x13
	mov	x26, x13
	cbz	x16, .LBB30_28
.LBB30_25:                              //   in Loop: Header=BB30_14 Depth=2
	add	x26, x24, x28
	add	x27, x7, x28
	add	x28, x0, x28
.LBB30_26:                              //   Parent Loop BB30_12 Depth=1
                                        //     Parent Loop BB30_14 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x27]
	adds	x28, x28, #8
	ldr	d1, [x26]
	str	d0, [x26], #8
	str	d1, [x27], #8
	b.ne	.LBB30_26
// %bb.27:                              //   in Loop: Header=BB30_14 Depth=2
	mov	x26, x17
	cmp	x17, x12
	b.eq	.LBB30_13
.LBB30_28:                              //   Parent Loop BB30_12 Depth=1
                                        //     Parent Loop BB30_14 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w27, [x7, x26]
	ldrb	w28, [x24, x26]
	strb	w27, [x24, x26]
	strb	w28, [x7, x26]
	add	x26, x26, #1
	cmp	x12, x26
	b.ne	.LBB30_28
	b	.LBB30_13
.LBB30_29:
	cbz	x21, .LBB30_31
.LBB30_30:
	ldr	w8, [sp, #200]
	mov	x0, x19
	ldr	w9, [sp, #192]
	mov	w2, #1
	sub	w8, w9, w8
	sxtw	x1, w8
	bl	fseek
.LBB30_31:
	mov	x0, x21
	ldp	x20, x19, [sp, #304]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #288]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #272]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #256]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #240]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #224]            // 16-byte Folded Reload
	add	sp, sp, #320
	ret
.Lfunc_end30:
	.size	stbi_load_from_file, .Lfunc_end30-stbi_load_from_file
	.cfi_endproc
                                        // -- End function
	.globl	stbi_load_from_memory           // -- Begin function stbi_load_from_memory
	.p2align	2
	.type	stbi_load_from_memory,@function
stbi_load_from_memory:                  // @stbi_load_from_memory
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #304
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x27, [sp, #224]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #240]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #256]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #272]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #288]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	add	x8, x0, w1, sxtw
	mov	x21, x4
	mov	x22, x3
	mov	x20, x2
	str	x0, [sp, #184]
	mov	x1, x2
	stp	x8, x0, [sp, #192]
	mov	x0, sp
	mov	x2, x3
	mov	x3, x4
	mov	w4, w5
	mov	w19, w5
	str	xzr, [sp, #16]
	str	wzr, [sp, #48]
	bl	_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
	cbz	x0, .LBB31_26
// %bb.1:
	adrp	x8, .L_MergedGlobals.126
	ldr	w8, [x8, :lo12:.L_MergedGlobals.126]
	cbz	w8, .LBB31_26
// %bb.2:
	ldr	w8, [x22]
	cbnz	w19, .LBB31_4
// %bb.3:
	ldr	w19, [x21]
.LBB31_4:
	cmp	w8, #2
	b.lt	.LBB31_26
// %bb.5:
	ldr	w9, [x20]
	cmp	w9, #1
	b.lt	.LBB31_26
// %bb.6:
	cmp	w19, #1
	b.lt	.LBB31_26
// %bb.7:
	mov	w12, w19
	sub	w18, w8, #1
	add	x14, x0, #16
	and	x17, x12, #0xfffffff8
	mul	x15, x12, x9
	mov	x10, xzr
	mul	w18, w9, w18
	lsr	x11, x8, #1
	and	x13, x12, #0xffffffe0
	and	x16, x12, #0x18
	neg	x1, x17
	mov	x2, x0
	mov	x3, x14
	b	.LBB31_9
.LBB31_8:                               //   in Loop: Header=BB31_9 Depth=1
	add	x10, x10, #1
	add	x3, x3, x15
	sub	w18, w18, w9
	add	x2, x2, x15
	cmp	x10, x11
	b.eq	.LBB31_26
.LBB31_9:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB31_11 Depth 2
                                        //       Child Loop BB31_19 Depth 3
                                        //       Child Loop BB31_23 Depth 3
                                        //       Child Loop BB31_25 Depth 3
	mvn	w5, w10
	sxtw	x7, w18
	add	w5, w8, w5
	mov	x4, xzr
	mul	x21, x12, x7
	mov	x23, x2
	mul	w6, w9, w5
	mov	x24, x3
	mul	x5, x15, x10
	add	x20, x0, x21
	sxtw	x6, w6
	add	x21, x14, x21
	add	x7, x5, x12
	mul	x6, x12, x6
	add	x22, x12, x6
	b	.LBB31_11
.LBB31_10:                              //   in Loop: Header=BB31_11 Depth=2
	add	x4, x4, #1
	add	x24, x24, x12
	add	x21, x21, x12
	add	x23, x23, x12
	add	x20, x20, x12
	cmp	x4, x9
	b.eq	.LBB31_8
.LBB31_11:                              //   Parent Loop BB31_9 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB31_19 Depth 3
                                        //       Child Loop BB31_23 Depth 3
                                        //       Child Loop BB31_25 Depth 3
	cmp	w19, #8
	b.hs	.LBB31_13
// %bb.12:                              //   in Loop: Header=BB31_11 Depth=2
	mov	x25, xzr
	b	.LBB31_25
.LBB31_13:                              //   in Loop: Header=BB31_11 Depth=2
	mul	x25, x4, x12
	add	x26, x22, x25
	add	x27, x5, x25
	add	x26, x0, x26
	add	x27, x0, x27
	cmp	x27, x26
	b.hs	.LBB31_16
// %bb.14:                              //   in Loop: Header=BB31_11 Depth=2
	add	x26, x6, x25
	add	x25, x7, x25
	add	x26, x0, x26
	add	x25, x0, x25
	cmp	x26, x25
	b.hs	.LBB31_16
// %bb.15:                              //   in Loop: Header=BB31_11 Depth=2
	mov	x25, xzr
	b	.LBB31_25
.LBB31_16:                              //   in Loop: Header=BB31_11 Depth=2
	cmp	w19, #32
	b.hs	.LBB31_18
// %bb.17:                              //   in Loop: Header=BB31_11 Depth=2
	mov	x27, xzr
	b	.LBB31_22
.LBB31_18:                              //   in Loop: Header=BB31_11 Depth=2
	mov	x25, x21
	mov	x26, x24
	mov	x27, x13
.LBB31_19:                              //   Parent Loop BB31_9 Depth=1
                                        //     Parent Loop BB31_11 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x25, #-16]
	subs	x27, x27, #32
	ldp	q2, q3, [x26, #-16]
	stp	q0, q1, [x26, #-16]
	add	x26, x26, #32
	stp	q2, q3, [x25, #-16]
	add	x25, x25, #32
	b.ne	.LBB31_19
// %bb.20:                              //   in Loop: Header=BB31_11 Depth=2
	cmp	x13, x12
	b.eq	.LBB31_10
// %bb.21:                              //   in Loop: Header=BB31_11 Depth=2
	mov	x27, x13
	mov	x25, x13
	cbz	x16, .LBB31_25
.LBB31_22:                              //   in Loop: Header=BB31_11 Depth=2
	add	x25, x23, x27
	add	x26, x20, x27
	add	x27, x1, x27
.LBB31_23:                              //   Parent Loop BB31_9 Depth=1
                                        //     Parent Loop BB31_11 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x26]
	adds	x27, x27, #8
	ldr	d1, [x25]
	str	d0, [x25], #8
	str	d1, [x26], #8
	b.ne	.LBB31_23
// %bb.24:                              //   in Loop: Header=BB31_11 Depth=2
	mov	x25, x17
	cmp	x17, x12
	b.eq	.LBB31_10
.LBB31_25:                              //   Parent Loop BB31_9 Depth=1
                                        //     Parent Loop BB31_11 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w26, [x20, x25]
	ldrb	w27, [x23, x25]
	strb	w26, [x23, x25]
	strb	w27, [x20, x25]
	add	x25, x25, #1
	cmp	x12, x25
	b.ne	.LBB31_25
	b	.LBB31_10
.LBB31_26:
	ldp	x20, x19, [sp, #288]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #272]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #256]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #304
	ret
.Lfunc_end31:
	.size	stbi_load_from_memory, .Lfunc_end31-stbi_load_from_memory
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_load_from_callbacks
.LCPI32_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_load_from_callbacks
	.p2align	2
	.type	stbi_load_from_callbacks,@function
stbi_load_from_callbacks:               // @stbi_load_from_callbacks
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #304
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x27, [sp, #224]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #240]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #256]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #272]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #288]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	q0, [x0]
	adrp	x8, .LCPI32_0
	ldr	x9, [x0, #16]
	mov	x24, sp
	add	x23, x24, #56
	mov	x20, x2
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI32_0]
	stp	x9, x1, [sp, #32]
	ldr	x8, [sp, #16]
	mov	x0, x1
	mov	x1, x23
	mov	w2, #128
	mov	w19, w5
	mov	x21, x4
	mov	x22, x3
	str	d0, [sp, #48]
	str	x23, [sp, #200]
	blr	x8
	cbz	w0, .LBB32_2
// %bb.1:
	add	x8, x24, w0, sxtw
	add	x8, x8, #56
	b	.LBB32_3
.LBB32_2:
	add	x8, x24, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB32_3:
	mov	x0, sp
	mov	x1, x20
	mov	x2, x22
	mov	x3, x21
	mov	w4, w19
	stp	x23, x8, [sp, #184]
	bl	_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
	cbz	x0, .LBB32_29
// %bb.4:
	adrp	x8, .L_MergedGlobals.126
	ldr	w8, [x8, :lo12:.L_MergedGlobals.126]
	cbz	w8, .LBB32_29
// %bb.5:
	ldr	w8, [x22]
	cbnz	w19, .LBB32_7
// %bb.6:
	ldr	w19, [x21]
.LBB32_7:
	cmp	w8, #2
	b.lt	.LBB32_29
// %bb.8:
	ldr	w9, [x20]
	cmp	w9, #1
	b.lt	.LBB32_29
// %bb.9:
	cmp	w19, #1
	b.lt	.LBB32_29
// %bb.10:
	mov	w12, w19
	sub	w18, w8, #1
	add	x14, x0, #16
	and	x17, x12, #0xfffffff8
	mul	x15, x12, x9
	mov	x10, xzr
	mul	w18, w9, w18
	lsr	x11, x8, #1
	and	x13, x12, #0xffffffe0
	and	x16, x12, #0x18
	neg	x1, x17
	mov	x2, x0
	mov	x3, x14
	b	.LBB32_12
.LBB32_11:                              //   in Loop: Header=BB32_12 Depth=1
	add	x10, x10, #1
	add	x3, x3, x15
	sub	w18, w18, w9
	add	x2, x2, x15
	cmp	x10, x11
	b.eq	.LBB32_29
.LBB32_12:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB32_14 Depth 2
                                        //       Child Loop BB32_22 Depth 3
                                        //       Child Loop BB32_26 Depth 3
                                        //       Child Loop BB32_28 Depth 3
	mvn	w5, w10
	sxtw	x7, w18
	add	w5, w8, w5
	mov	x4, xzr
	mul	x21, x12, x7
	mov	x23, x2
	mul	w6, w9, w5
	mov	x24, x3
	mul	x5, x15, x10
	add	x20, x0, x21
	sxtw	x6, w6
	add	x21, x14, x21
	add	x7, x5, x12
	mul	x6, x12, x6
	add	x22, x12, x6
	b	.LBB32_14
.LBB32_13:                              //   in Loop: Header=BB32_14 Depth=2
	add	x4, x4, #1
	add	x24, x24, x12
	add	x21, x21, x12
	add	x23, x23, x12
	add	x20, x20, x12
	cmp	x4, x9
	b.eq	.LBB32_11
.LBB32_14:                              //   Parent Loop BB32_12 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB32_22 Depth 3
                                        //       Child Loop BB32_26 Depth 3
                                        //       Child Loop BB32_28 Depth 3
	cmp	w19, #8
	b.hs	.LBB32_16
// %bb.15:                              //   in Loop: Header=BB32_14 Depth=2
	mov	x25, xzr
	b	.LBB32_28
.LBB32_16:                              //   in Loop: Header=BB32_14 Depth=2
	mul	x25, x4, x12
	add	x26, x22, x25
	add	x27, x5, x25
	add	x26, x0, x26
	add	x27, x0, x27
	cmp	x27, x26
	b.hs	.LBB32_19
// %bb.17:                              //   in Loop: Header=BB32_14 Depth=2
	add	x26, x6, x25
	add	x25, x7, x25
	add	x26, x0, x26
	add	x25, x0, x25
	cmp	x26, x25
	b.hs	.LBB32_19
// %bb.18:                              //   in Loop: Header=BB32_14 Depth=2
	mov	x25, xzr
	b	.LBB32_28
.LBB32_19:                              //   in Loop: Header=BB32_14 Depth=2
	cmp	w19, #32
	b.hs	.LBB32_21
// %bb.20:                              //   in Loop: Header=BB32_14 Depth=2
	mov	x27, xzr
	b	.LBB32_25
.LBB32_21:                              //   in Loop: Header=BB32_14 Depth=2
	mov	x25, x21
	mov	x26, x24
	mov	x27, x13
.LBB32_22:                              //   Parent Loop BB32_12 Depth=1
                                        //     Parent Loop BB32_14 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x25, #-16]
	subs	x27, x27, #32
	ldp	q2, q3, [x26, #-16]
	stp	q0, q1, [x26, #-16]
	add	x26, x26, #32
	stp	q2, q3, [x25, #-16]
	add	x25, x25, #32
	b.ne	.LBB32_22
// %bb.23:                              //   in Loop: Header=BB32_14 Depth=2
	cmp	x13, x12
	b.eq	.LBB32_13
// %bb.24:                              //   in Loop: Header=BB32_14 Depth=2
	mov	x27, x13
	mov	x25, x13
	cbz	x16, .LBB32_28
.LBB32_25:                              //   in Loop: Header=BB32_14 Depth=2
	add	x25, x23, x27
	add	x26, x20, x27
	add	x27, x1, x27
.LBB32_26:                              //   Parent Loop BB32_12 Depth=1
                                        //     Parent Loop BB32_14 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x26]
	adds	x27, x27, #8
	ldr	d1, [x25]
	str	d0, [x25], #8
	str	d1, [x26], #8
	b.ne	.LBB32_26
// %bb.27:                              //   in Loop: Header=BB32_14 Depth=2
	mov	x25, x17
	cmp	x17, x12
	b.eq	.LBB32_13
.LBB32_28:                              //   Parent Loop BB32_12 Depth=1
                                        //     Parent Loop BB32_14 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w26, [x20, x25]
	ldrb	w27, [x23, x25]
	strb	w26, [x23, x25]
	strb	w27, [x20, x25]
	add	x25, x25, #1
	cmp	x12, x25
	b.ne	.LBB32_28
	b	.LBB32_13
.LBB32_29:
	ldp	x20, x19, [sp, #288]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #272]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #256]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #304
	ret
.Lfunc_end32:
	.size	stbi_load_from_callbacks, .Lfunc_end32-stbi_load_from_callbacks
	.cfi_endproc
                                        // -- End function
	.globl	stbi_loadf_from_memory          // -- Begin function stbi_loadf_from_memory
	.p2align	2
	.type	stbi_loadf_from_memory,@function
stbi_loadf_from_memory:                 // @stbi_loadf_from_memory
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #224
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	add	x8, x0, w1, sxtw
	str	x0, [sp, #184]
	mov	x1, x2
	mov	x2, x3
	mov	x3, x4
	mov	w4, w5
	stp	x8, x0, [sp, #192]
	mov	x0, sp
	str	xzr, [sp, #16]
	str	wzr, [sp, #48]
	bl	_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #224
	ret
.Lfunc_end33:
	.size	stbi_loadf_from_memory, .Lfunc_end33-stbi_loadf_from_memory
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	.type	_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i,@function
_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i: // @_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x28, x27, [sp, #64]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldp	x9, x8, [x0, #184]
	adrp	x27, .L.str.119
	mov	w19, w4
	mov	x23, x3
	mov	x20, x0
	mov	x24, x2
	mov	x22, x1
	mov	x25, xzr
	add	x21, x0, #56
	add	x26, x0, #57
	add	x27, x27, :lo12:.L.str.119
.LBB34_1:                               // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB34_3
// %bb.2:                               //   in Loop: Header=BB34_1 Depth=1
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB34_8
.LBB34_3:                               //   in Loop: Header=BB34_1 Depth=1
	ldr	w10, [x20, #48]
	cbz	w10, .LBB34_8
// %bb.4:                               //   in Loop: Header=BB34_1 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB34_6
// %bb.5:                               //   in Loop: Header=BB34_1 Depth=1
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB34_7
.LBB34_6:                               //   in Loop: Header=BB34_1 Depth=1
	mov	w10, wzr
	mov	x8, x26
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB34_7:                               //   in Loop: Header=BB34_1 Depth=1
	mov	x9, x26
	stp	x26, x8, [x20, #184]
.LBB34_8:                               //   in Loop: Header=BB34_1 Depth=1
	ldrb	w11, [x27, x25]
	cmp	w10, w11
	b.ne	.LBB34_30
// %bb.9:                               //   in Loop: Header=BB34_1 Depth=1
	add	x25, x25, #1
	cmp	x25, #11
	b.ne	.LBB34_1
// %bb.10:
	ldr	x8, [x20, #200]
	mov	x0, x20
	mov	x1, x22
	mov	x2, x24
	mov	x3, x23
	mov	w4, w19
	str	x8, [x20, #184]
	bl	_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i
	mov	x21, x0
	cbz	x0, .LBB34_83
// %bb.11:
	adrp	x8, .L_MergedGlobals.126
	ldr	w8, [x8, :lo12:.L_MergedGlobals.126]
	cbz	w8, .LBB34_83
// %bb.12:
	ldr	w8, [x24]
	cbnz	w19, .LBB34_14
// %bb.13:
	ldr	w19, [x23]
.LBB34_14:
	cmp	w8, #2
	b.lt	.LBB34_83
// %bb.15:
	ldr	w9, [x22]
	cmp	w9, #1
	b.lt	.LBB34_83
// %bb.16:
	cmp	w19, #1
	b.lt	.LBB34_83
// %bb.17:
	mov	w12, w19
	sub	w17, w8, #1
	add	x13, x21, #16
	mov	x10, xzr
	mul	x14, x12, x9
	mov	x11, xzr
	mul	w17, w9, w17
	lsr	x15, x8, #1
	and	x16, x12, #0xfffffff8
	lsl	x18, x14, #2
	lsl	x0, x12, #2
	mov	x1, x13
	b	.LBB34_19
.LBB34_18:                              //   in Loop: Header=BB34_19 Depth=1
	add	x11, x11, #1
	add	x1, x1, x18
	sub	w17, w17, w9
	add	x10, x10, x14
	cmp	x11, x15
	b.eq	.LBB34_83
.LBB34_19:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB34_21 Depth 2
                                        //       Child Loop BB34_28 Depth 3
                                        //       Child Loop BB34_26 Depth 3
	mvn	w3, w11
	sxtw	x4, w17
	add	w3, w8, w3
	mov	x2, xzr
	mov	x22, x10
	mov	x23, x1
	mul	w5, w9, w3
	mul	x3, x12, x4
	sxtw	x6, w5
	sbfiz	x5, x5, #2, #32
	add	x20, x5, #4
	mul	x4, x14, x11
	mul	x6, x12, x6
	add	x5, x13, x3, lsl #2
	mul	x20, x20, x12
	add	x7, x4, x12
	b	.LBB34_21
.LBB34_20:                              //   in Loop: Header=BB34_21 Depth=2
	add	x2, x2, #1
	add	x23, x23, x0
	add	x5, x5, x0
	add	x3, x3, x12
	add	x22, x22, x12
	cmp	x2, x9
	b.eq	.LBB34_18
.LBB34_21:                              //   Parent Loop BB34_19 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB34_28 Depth 3
                                        //       Child Loop BB34_26 Depth 3
	cmp	w19, #8
	b.lo	.LBB34_24
// %bb.22:                              //   in Loop: Header=BB34_21 Depth=2
	mul	x24, x2, x12
	add	x25, x4, x24
	add	x26, x21, x24, lsl #2
	add	x26, x26, x20
	add	x25, x21, x25, lsl #2
	cmp	x26, x25
	b.ls	.LBB34_27
// %bb.23:                              //   in Loop: Header=BB34_21 Depth=2
	add	x25, x6, x24
	add	x24, x7, x24
	add	x25, x21, x25, lsl #2
	add	x24, x21, x24, lsl #2
	cmp	x25, x24
	b.hs	.LBB34_27
.LBB34_24:                              //   in Loop: Header=BB34_21 Depth=2
	mov	x24, xzr
.LBB34_25:                              //   in Loop: Header=BB34_21 Depth=2
	add	x25, x24, x3
	add	x26, x24, x22
	sub	x24, x12, x24
	add	x25, x21, x25, lsl #2
	add	x26, x21, x26, lsl #2
.LBB34_26:                              //   Parent Loop BB34_19 Depth=1
                                        //     Parent Loop BB34_21 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	s0, [x25]
	subs	x24, x24, #1
	ldr	s1, [x26]
	str	s0, [x26], #4
	str	s1, [x25], #4
	b.ne	.LBB34_26
	b	.LBB34_20
.LBB34_27:                              //   in Loop: Header=BB34_21 Depth=2
	mov	x24, x5
	mov	x25, x23
	mov	x26, x16
.LBB34_28:                              //   Parent Loop BB34_19 Depth=1
                                        //     Parent Loop BB34_21 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x24, #-16]
	subs	x26, x26, #8
	ldp	q2, q3, [x25, #-16]
	stp	q0, q1, [x25, #-16]
	add	x25, x25, #32
	stp	q2, q3, [x24, #-16]
	add	x24, x24, #32
	b.ne	.LBB34_28
// %bb.29:                              //   in Loop: Header=BB34_21 Depth=2
	mov	x24, x16
	cmp	x16, x12
	b.eq	.LBB34_20
	b	.LBB34_25
.LBB34_30:
	ldr	x8, [x20, #200]
	mov	x0, x20
	mov	x1, x22
	mov	x2, x24
	mov	x3, x23
	mov	w4, w19
	str	x8, [x20, #184]
	bl	_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
	mov	x20, x0
	stp	x23, x22, [x29, #-16]           // 16-byte Folded Spill
	cbz	x0, .LBB34_56
// %bb.31:
	adrp	x8, .L_MergedGlobals.126
	ldr	w8, [x8, :lo12:.L_MergedGlobals.126]
	cbz	w8, .LBB34_56
// %bb.32:
	ldr	w8, [x24]
	mov	w9, w19
	cbnz	w19, .LBB34_34
// %bb.33:
	ldr	w9, [x23]
.LBB34_34:
	cmp	w8, #2
	b.lt	.LBB34_57
// %bb.35:
	ldur	x10, [x29, #-8]                 // 8-byte Folded Reload
	ldr	w10, [x10]
	cmp	w10, #1
	b.lt	.LBB34_57
// %bb.36:
	cmp	w9, #1
	b.lt	.LBB34_57
// %bb.37:
	mov	w13, w9
	sub	w14, w8, #1
	add	x15, x20, #16
	and	x18, x13, #0xfffffff8
	mul	x16, x13, x10
	mov	x11, xzr
	mul	w0, w10, w14
	lsr	x12, x8, #1
	and	x22, x13, #0xffffffe0
	and	x17, x13, #0x18
	neg	x1, x18
	mov	x2, x20
	mov	x3, x15
	b	.LBB34_39
.LBB34_38:                              //   in Loop: Header=BB34_39 Depth=1
	add	x11, x11, #1
	add	x3, x3, x16
	sub	w0, w0, w10
	add	x2, x2, x16
	cmp	x11, x12
	b.eq	.LBB34_57
.LBB34_39:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB34_41 Depth 2
                                        //       Child Loop BB34_49 Depth 3
                                        //       Child Loop BB34_53 Depth 3
                                        //       Child Loop BB34_55 Depth 3
	mvn	w14, w11
	sxtw	x6, w0
	add	w14, w8, w14
	mul	x5, x16, x11
	mul	x23, x13, x6
	mov	x4, xzr
	mul	w14, w10, w14
	add	x7, x5, x13
	add	x21, x20, x23
	add	x25, x15, x23
	sxtw	x14, w14
	mov	x27, x2
	mov	x28, x3
	mul	x6, x13, x14
	add	x26, x13, x6
	b	.LBB34_41
.LBB34_40:                              //   in Loop: Header=BB34_41 Depth=2
	add	x4, x4, #1
	add	x28, x28, x13
	add	x25, x25, x13
	add	x27, x27, x13
	add	x21, x21, x13
	cmp	x4, x10
	b.eq	.LBB34_38
.LBB34_41:                              //   Parent Loop BB34_39 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB34_49 Depth 3
                                        //       Child Loop BB34_53 Depth 3
                                        //       Child Loop BB34_55 Depth 3
	cmp	w9, #8
	b.hs	.LBB34_43
// %bb.42:                              //   in Loop: Header=BB34_41 Depth=2
	mov	x23, xzr
	b	.LBB34_55
.LBB34_43:                              //   in Loop: Header=BB34_41 Depth=2
	mul	x14, x4, x13
	add	x23, x26, x14
	add	x30, x5, x14
	add	x23, x20, x23
	add	x30, x20, x30
	cmp	x30, x23
	b.hs	.LBB34_46
// %bb.44:                              //   in Loop: Header=BB34_41 Depth=2
	add	x23, x6, x14
	add	x14, x7, x14
	add	x23, x20, x23
	add	x14, x20, x14
	cmp	x23, x14
	b.hs	.LBB34_46
// %bb.45:                              //   in Loop: Header=BB34_41 Depth=2
	mov	x23, xzr
	b	.LBB34_55
.LBB34_46:                              //   in Loop: Header=BB34_41 Depth=2
	cmp	w9, #32
	b.hs	.LBB34_48
// %bb.47:                              //   in Loop: Header=BB34_41 Depth=2
	mov	x14, xzr
	b	.LBB34_52
.LBB34_48:                              //   in Loop: Header=BB34_41 Depth=2
	mov	x30, x25
	mov	x23, x28
	mov	x14, x22
.LBB34_49:                              //   Parent Loop BB34_39 Depth=1
                                        //     Parent Loop BB34_41 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q0, q1, [x30, #-16]
	subs	x14, x14, #32
	ldp	q2, q3, [x23, #-16]
	stp	q0, q1, [x23, #-16]
	add	x23, x23, #32
	stp	q2, q3, [x30, #-16]
	add	x30, x30, #32
	b.ne	.LBB34_49
// %bb.50:                              //   in Loop: Header=BB34_41 Depth=2
	cmp	x22, x13
	b.eq	.LBB34_40
// %bb.51:                              //   in Loop: Header=BB34_41 Depth=2
	mov	x14, x22
	mov	x23, x22
	cbz	x17, .LBB34_55
.LBB34_52:                              //   in Loop: Header=BB34_41 Depth=2
	add	x30, x27, x14
	add	x23, x21, x14
	add	x14, x1, x14
.LBB34_53:                              //   Parent Loop BB34_39 Depth=1
                                        //     Parent Loop BB34_41 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x23]
	adds	x14, x14, #8
	ldr	d1, [x30]
	str	d0, [x30], #8
	str	d1, [x23], #8
	b.ne	.LBB34_53
// %bb.54:                              //   in Loop: Header=BB34_41 Depth=2
	mov	x23, x18
	cmp	x18, x13
	b.eq	.LBB34_40
.LBB34_55:                              //   Parent Loop BB34_39 Depth=1
                                        //     Parent Loop BB34_41 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w14, [x21, x23]
	ldrb	w30, [x27, x23]
	strb	w14, [x27, x23]
	strb	w30, [x21, x23]
	add	x23, x23, #1
	cmp	x13, x23
	b.ne	.LBB34_55
	b	.LBB34_40
.LBB34_56:
	cbz	x20, .LBB34_68
.LBB34_57:
	ldur	x8, [x29, #-8]                  // 8-byte Folded Reload
	ldr	w9, [x24]
	ldr	w8, [x8]
	cbz	w19, .LBB34_66
// %bb.58:
	mul	w22, w9, w8
	mul	w8, w19, w22
	sbfiz	x0, x8, #2, #32
	bl	malloc
	mov	x21, x0
	cbz	x0, .LBB34_67
.LBB34_59:
	cmp	w22, #1
	b.lt	.LBB34_82
// %bb.60:
	and	w8, w19, #0x1
	add	w8, w19, w8
	sub	w25, w8, #1
	cmp	w25, #1
	b.lt	.LBB34_70
// %bb.61:
	sxtw	x10, w19
	cmp	w25, w19
	mov	x19, xzr
	stp	x25, x22, [x29, #-16]           // 16-byte Folded Spill
	str	x10, [sp, #24]                  // 8-byte Folded Spill
	b.ge	.LBB34_73
// %bb.62:
	adrp	x22, .L_MergedGlobals
	lsl	x8, x10, #2
	mov	w26, #1132396544
	mov	x24, x20
	mov	x23, x21
	add	x22, x22, :lo12:.L_MergedGlobals
	str	x8, [sp, #8]                    // 8-byte Folded Spill
.LBB34_63:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB34_64 Depth 2
	mul	x8, x19, x10
	mov	x27, x24
	mov	x28, x23
	str	x8, [sp, #16]                   // 8-byte Folded Spill
.LBB34_64:                              //   Parent Loop BB34_63 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w8, [x27], #1
	fmov	s1, w26
	ucvtf	s0, w8
	fdiv	s0, s0, s1
	ldr	s1, [x22]
	bl	powf
	ldr	s1, [x22, #4]
	subs	x25, x25, #1
	fmul	s0, s0, s1
	str	s0, [x28], #4
	b.ne	.LBB34_64
// %bb.65:                              //   in Loop: Header=BB34_63 Depth=1
	ldp	x9, x8, [sp, #8]                // 16-byte Folded Reload
	fmov	s1, w26
	add	x19, x19, #1
	ldr	x10, [sp, #24]                  // 8-byte Folded Reload
	add	x23, x23, x9
	ldp	x25, x9, [x29, #-16]            // 16-byte Folded Reload
	add	x8, x8, x25
	add	x24, x24, x10
	cmp	x19, x9
	ldr	b0, [x20, x8]
	ucvtf	s0, s0
	fdiv	s0, s0, s1
	str	s0, [x21, x8, lsl #2]
	b.ne	.LBB34_63
	b	.LBB34_82
.LBB34_66:
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	ldr	w19, [x10]
	mul	w22, w9, w8
	mul	w8, w19, w22
	sbfiz	x0, x8, #2, #32
	bl	malloc
	mov	x21, x0
	cbnz	x0, .LBB34_59
.LBB34_67:
	mov	x0, x20
	bl	free
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	b	.LBB34_69
.LBB34_68:
	adrp	x9, .L.str.9
	adrp	x8, .L_MergedGlobals.126+8
	mov	x21, xzr
	add	x9, x9, :lo12:.L.str.9
.LBB34_69:
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB34_83
.LBB34_70:
	cmp	w19, #1
	b.lt	.LBB34_82
// %bb.71:
	mov	w8, w19
	cmp	w22, #2
	b.hs	.LBB34_77
// %bb.72:
	mov	x9, xzr
	b	.LBB34_80
.LBB34_73:
	adrp	x28, .L_MergedGlobals
	lsl	x8, x10, #2
	mov	w22, #1132396544
	mov	x26, x20
	mov	x27, x21
	add	x28, x28, :lo12:.L_MergedGlobals
	str	x8, [sp, #16]                   // 8-byte Folded Spill
.LBB34_74:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB34_75 Depth 2
	mov	x24, x26
	mov	x23, x27
.LBB34_75:                              //   Parent Loop BB34_74 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w8, [x24], #1
	fmov	s1, w22
	ucvtf	s0, w8
	fdiv	s0, s0, s1
	ldr	s1, [x28]
	bl	powf
	ldr	s1, [x28, #4]
	subs	x25, x25, #1
	fmul	s0, s0, s1
	str	s0, [x23], #4
	b.ne	.LBB34_75
// %bb.76:                              //   in Loop: Header=BB34_74 Depth=1
	ldr	x8, [sp, #16]                   // 8-byte Folded Reload
	add	x19, x19, #1
	add	x27, x27, x8
	ldr	x8, [sp, #24]                   // 8-byte Folded Reload
	add	x26, x26, x8
	ldp	x25, x8, [x29, #-16]            // 16-byte Folded Reload
	cmp	x19, x8
	b.ne	.LBB34_74
	b	.LBB34_82
.LBB34_77:
	and	x9, x22, #0xfffffffe
	mov	x10, xzr
	add	x11, x21, x8, lsl #2
	lsl	x12, x8, #1
	add	x13, x20, x8
	mov	w14, #1132396544
	mov	x15, x9
.LBB34_78:                              // =>This Inner Loop Header: Depth=1
	ldr	b0, [x20, x10]
	fmov	s1, w14
	ldr	b2, [x13, x10]
	lsl	x16, x10, #2
	add	x10, x10, x12
	subs	x15, x15, #2
	ucvtf	s0, s0
	ucvtf	s2, s2
	fdiv	s0, s0, s1
	fdiv	s1, s2, s1
	str	s0, [x21, x16]
	str	s1, [x11, x16]
	b.ne	.LBB34_78
// %bb.79:
	cmp	x9, x22
	b.eq	.LBB34_82
.LBB34_80:
	mul	x10, x9, x8
	sub	x9, x22, x9
	mov	w11, #1132396544
.LBB34_81:                              // =>This Inner Loop Header: Depth=1
	ldr	b0, [x20, x10]
	fmov	s1, w11
	subs	x9, x9, #1
	ucvtf	s0, s0
	fdiv	s0, s0, s1
	str	s0, [x21, x10, lsl #2]
	add	x10, x10, x8
	b.ne	.LBB34_81
.LBB34_82:
	mov	x0, x20
	bl	free
.LBB34_83:
	mov	x0, x21
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	add	sp, sp, #144
	ret
.Lfunc_end34:
	.size	_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i, .Lfunc_end34-_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_loadf_from_callbacks
.LCPI35_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_loadf_from_callbacks
	.p2align	2
	.type	stbi_loadf_from_callbacks,@function
stbi_loadf_from_callbacks:              // @stbi_loadf_from_callbacks
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	str	x28, [sp, #224]                 // 8-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w28, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldr	q0, [x0]
	adrp	x8, .LCPI35_0
	ldr	x9, [x0, #16]
	mov	x24, sp
	add	x23, x24, #56
	mov	x22, x2
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI35_0]
	stp	x9, x1, [sp, #32]
	ldr	x8, [sp, #16]
	mov	x0, x1
	mov	x1, x23
	mov	w2, #128
	mov	w19, w5
	mov	x20, x4
	mov	x21, x3
	str	d0, [sp, #48]
	str	x23, [sp, #200]
	blr	x8
	cbz	w0, .LBB35_2
// %bb.1:
	add	x8, x24, w0, sxtw
	add	x8, x8, #56
	b	.LBB35_3
.LBB35_2:
	add	x8, x24, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB35_3:
	mov	x0, sp
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	w4, w19
	stp	x23, x8, [sp, #184]
	bl	_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	ldr	x28, [sp, #224]                 // 8-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end35:
	.size	stbi_loadf_from_callbacks, .Lfunc_end35-stbi_loadf_from_callbacks
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_loadf
.LCPI36_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_loadf
	.p2align	2
	.type	stbi_loadf,@function
stbi_loadf:                             // @stbi_loadf
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w28, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	x23, x1
	adrp	x1, .L.str.1
	add	x1, x1, :lo12:.L.str.1
	mov	w19, w4
	mov	x20, x3
	mov	x21, x2
	bl	fopen
	cbz	x0, .LBB36_3
// %bb.1:
	adrp	x8, _ZL21stbi__stdio_callbacks
	adrp	x9, .LCPI36_0
	add	x8, x8, :lo12:_ZL21stbi__stdio_callbacks
	mov	x25, sp
	add	x24, x25, #56
	mov	w2, #128
	mov	x1, x24
	mov	x22, x0
	ldr	q0, [x8]
	ldr	x8, [x8, #16]
	str	x24, [sp, #200]
	str	q0, [sp, #16]
	ldr	d0, [x9, :lo12:.LCPI36_0]
	stp	x8, x0, [sp, #32]
	ldr	x8, [sp, #16]
	str	d0, [sp, #48]
	blr	x8
	cbz	w0, .LBB36_4
// %bb.2:
	add	x8, x25, w0, sxtw
	add	x8, x8, #56
	b	.LBB36_5
.LBB36_3:
	adrp	x9, .L.str.2
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.2
	mov	x19, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB36_6
.LBB36_4:
	add	x8, x25, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB36_5:
	mov	x0, sp
	mov	x1, x23
	mov	x2, x21
	mov	x3, x20
	mov	w4, w19
	stp	x24, x8, [sp, #184]
	bl	_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	mov	x19, x0
	mov	x0, x22
	bl	fclose
.LBB36_6:
	mov	x0, x19
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end36:
	.size	stbi_loadf, .Lfunc_end36-stbi_loadf
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_loadf_from_file
.LCPI37_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_loadf_from_file
	.p2align	2
	.type	stbi_loadf_from_file,@function
stbi_loadf_from_file:                   // @stbi_loadf_from_file
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	str	x28, [sp, #224]                 // 8-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w28, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	adrp	x9, _ZL21stbi__stdio_callbacks
	adrp	x8, .LCPI37_0
	add	x9, x9, :lo12:_ZL21stbi__stdio_callbacks
	mov	x24, sp
	add	x23, x24, #56
	mov	x21, x2
	mov	x22, x1
	mov	x1, x23
	ldr	q0, [x9]
	mov	w2, #128
	ldr	x9, [x9, #16]
	mov	w19, w4
	mov	x20, x3
	str	x23, [sp, #200]
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI37_0]
	ldr	x8, [sp, #16]
	stp	x9, x0, [sp, #32]
	str	d0, [sp, #48]
	blr	x8
	cbz	w0, .LBB37_2
// %bb.1:
	add	x8, x24, w0, sxtw
	add	x8, x8, #56
	b	.LBB37_3
.LBB37_2:
	add	x8, x24, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB37_3:
	mov	x0, sp
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	w4, w19
	stp	x23, x8, [sp, #184]
	bl	_ZL16stbi__loadf_mainP13stbi__contextPiS1_S1_i
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	ldr	x28, [sp, #224]                 // 8-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end37:
	.size	stbi_loadf_from_file, .Lfunc_end37-stbi_loadf_from_file
	.cfi_endproc
                                        // -- End function
	.globl	stbi_is_hdr_from_memory         // -- Begin function stbi_is_hdr_from_memory
	.p2align	2
	.type	stbi_is_hdr_from_memory,@function
stbi_is_hdr_from_memory:                // @stbi_is_hdr_from_memory
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #272
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x21, sp
	adrp	x23, .L.str.119
	mov	x20, xzr
	add	x8, x0, w1, sxtw
	add	x19, x21, #56
	add	x22, x21, #57
	add	x23, x23, :lo12:.L.str.119
	str	xzr, [sp, #16]
	str	wzr, [sp, #48]
	stp	x8, x0, [sp, #192]
	str	x0, [sp, #184]
.LBB38_1:                               // =>This Inner Loop Header: Depth=1
	cmp	x0, x8
	b.hs	.LBB38_3
// %bb.2:                               //   in Loop: Header=BB38_1 Depth=1
	add	x10, x0, #1
	str	x10, [sp, #184]
	ldrb	w9, [x0]
	mov	x0, x10
	b	.LBB38_8
.LBB38_3:                               //   in Loop: Header=BB38_1 Depth=1
	ldr	w9, [sp, #48]
	cbz	w9, .LBB38_8
// %bb.4:                               //   in Loop: Header=BB38_1 Depth=1
	ldr	x8, [sp, #16]
	mov	x1, x19
	ldr	x0, [sp, #40]
	ldr	w2, [sp, #52]
	blr	x8
	cbz	w0, .LBB38_6
// %bb.5:                               //   in Loop: Header=BB38_1 Depth=1
	add	x8, x21, #56
	ldrb	w9, [sp, #56]
	add	x8, x8, w0, sxtw
	b	.LBB38_7
.LBB38_6:                               //   in Loop: Header=BB38_1 Depth=1
	mov	w9, wzr
	mov	x8, x22
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB38_7:                               //   in Loop: Header=BB38_1 Depth=1
	mov	x0, x22
	stp	x22, x8, [sp, #184]
.LBB38_8:                               //   in Loop: Header=BB38_1 Depth=1
	ldrb	w10, [x23, x20]
	cmp	w9, w10
	b.ne	.LBB38_11
// %bb.9:                               //   in Loop: Header=BB38_1 Depth=1
	add	x20, x20, #1
	cmp	x20, #11
	b.ne	.LBB38_1
// %bb.10:
	mov	w0, #1
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.LBB38_11:
	mov	w0, wzr
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.Lfunc_end38:
	.size	stbi_is_hdr_from_memory, .Lfunc_end38-stbi_is_hdr_from_memory
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__hdr_testP13stbi__context
	.type	_ZL14stbi__hdr_testP13stbi__context,@function
_ZL14stbi__hdr_testP13stbi__context:    // @_ZL14stbi__hdr_testP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x9, x8, [x0, #184]
	adrp	x23, .L.str.119
	mov	x19, x0
	mov	x21, xzr
	add	x20, x0, #56
	add	x22, x0, #57
	add	x23, x23, :lo12:.L.str.119
.LBB39_1:                               // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB39_3
// %bb.2:                               //   in Loop: Header=BB39_1 Depth=1
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB39_8
.LBB39_3:                               //   in Loop: Header=BB39_1 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB39_8
// %bb.4:                               //   in Loop: Header=BB39_1 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB39_6
// %bb.5:                               //   in Loop: Header=BB39_1 Depth=1
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB39_7
.LBB39_6:                               //   in Loop: Header=BB39_1 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB39_7:                               //   in Loop: Header=BB39_1 Depth=1
	mov	x9, x22
	stp	x22, x8, [x19, #184]
.LBB39_8:                               //   in Loop: Header=BB39_1 Depth=1
	ldrb	w11, [x23, x21]
	cmp	w10, w11
	b.ne	.LBB39_11
// %bb.9:                               //   in Loop: Header=BB39_1 Depth=1
	add	x21, x21, #1
	cmp	x21, #11
	b.ne	.LBB39_1
// %bb.10:
	mov	w0, #1
	b	.LBB39_12
.LBB39_11:
	mov	w0, wzr
.LBB39_12:
	ldr	x8, [x19, #200]
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	str	x8, [x19, #184]
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end39:
	.size	_ZL14stbi__hdr_testP13stbi__context, .Lfunc_end39-_ZL14stbi__hdr_testP13stbi__context
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_is_hdr
.LCPI40_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_is_hdr
	.p2align	2
	.type	stbi_is_hdr,@function
stbi_is_hdr:                            // @stbi_is_hdr
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	str	x28, [sp, #224]                 // 8-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w28, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	adrp	x1, .L.str.1
	add	x1, x1, :lo12:.L.str.1
	bl	fopen
	cbz	x0, .LBB40_3
// %bb.1:
	adrp	x8, _ZL21stbi__stdio_callbacks
	adrp	x9, .LCPI40_0
	add	x8, x8, :lo12:_ZL21stbi__stdio_callbacks
	mov	x21, sp
	add	x20, x21, #56
	mov	w2, #128
	mov	x1, x20
	mov	x19, x0
	ldr	q0, [x8]
	ldr	x8, [x8, #16]
	str	x20, [sp, #200]
	str	q0, [sp, #16]
	ldr	d0, [x9, :lo12:.LCPI40_0]
	stp	x8, x0, [sp, #32]
	ldr	x8, [sp, #16]
	str	d0, [sp, #48]
	blr	x8
	cbz	w0, .LBB40_4
// %bb.2:
	add	x8, x21, w0, sxtw
	add	x8, x8, #56
	b	.LBB40_5
.LBB40_3:
	mov	w20, wzr
	b	.LBB40_18
.LBB40_4:
	add	x8, x21, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB40_5:
	mov	x22, sp
	adrp	x24, .L.str.119
	mov	x21, xzr
	add	x23, x22, #57
	mov	x9, x20
	add	x24, x24, :lo12:.L.str.119
	stp	x20, x8, [sp, #184]
.LBB40_6:                               // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB40_8
// %bb.7:                               //   in Loop: Header=BB40_6 Depth=1
	add	x11, x9, #1
	str	x11, [sp, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB40_13
.LBB40_8:                               //   in Loop: Header=BB40_6 Depth=1
	ldr	w10, [sp, #48]
	cbz	w10, .LBB40_13
// %bb.9:                               //   in Loop: Header=BB40_6 Depth=1
	ldr	x8, [sp, #16]
	mov	x1, x20
	ldr	x0, [sp, #40]
	ldr	w2, [sp, #52]
	blr	x8
	cbz	w0, .LBB40_11
// %bb.10:                              //   in Loop: Header=BB40_6 Depth=1
	add	x8, x22, #56
	ldrb	w10, [sp, #56]
	add	x8, x8, w0, sxtw
	b	.LBB40_12
.LBB40_11:                              //   in Loop: Header=BB40_6 Depth=1
	mov	w10, wzr
	mov	x8, x23
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB40_12:                              //   in Loop: Header=BB40_6 Depth=1
	mov	x9, x23
	stp	x23, x8, [sp, #184]
.LBB40_13:                              //   in Loop: Header=BB40_6 Depth=1
	ldrb	w11, [x24, x21]
	cmp	w10, w11
	b.ne	.LBB40_16
// %bb.14:                              //   in Loop: Header=BB40_6 Depth=1
	add	x21, x21, #1
	cmp	x21, #11
	b.ne	.LBB40_6
// %bb.15:
	mov	w20, #1
	b	.LBB40_17
.LBB40_16:
	mov	w20, wzr
.LBB40_17:
	mov	x0, x19
	bl	fclose
.LBB40_18:
	mov	w0, w20
	ldr	x28, [sp, #224]                 // 8-byte Folded Reload
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end40:
	.size	stbi_is_hdr, .Lfunc_end40-stbi_is_hdr
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_is_hdr_from_file
.LCPI41_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_is_hdr_from_file
	.p2align	2
	.type	stbi_is_hdr_from_file,@function
stbi_is_hdr_from_file:                  // @stbi_is_hdr_from_file
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #272
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	adrp	x9, _ZL21stbi__stdio_callbacks
	adrp	x8, .LCPI41_0
	add	x9, x9, :lo12:_ZL21stbi__stdio_callbacks
	mov	x20, sp
	add	x19, x20, #56
	mov	w2, #128
	mov	x1, x19
	ldr	q0, [x9]
	ldr	x9, [x9, #16]
	str	x19, [sp, #200]
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI41_0]
	ldr	x8, [sp, #16]
	stp	x9, x0, [sp, #32]
	str	d0, [sp, #48]
	blr	x8
	cbz	w0, .LBB41_2
// %bb.1:
	add	x8, x20, w0, sxtw
	add	x8, x8, #56
	b	.LBB41_3
.LBB41_2:
	add	x8, x20, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB41_3:
	mov	x21, sp
	adrp	x23, .L.str.119
	mov	x20, xzr
	add	x22, x21, #57
	mov	x9, x19
	add	x23, x23, :lo12:.L.str.119
	stp	x19, x8, [sp, #184]
.LBB41_4:                               // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB41_6
// %bb.5:                               //   in Loop: Header=BB41_4 Depth=1
	add	x11, x9, #1
	str	x11, [sp, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB41_11
.LBB41_6:                               //   in Loop: Header=BB41_4 Depth=1
	ldr	w10, [sp, #48]
	cbz	w10, .LBB41_11
// %bb.7:                               //   in Loop: Header=BB41_4 Depth=1
	ldr	x8, [sp, #16]
	mov	x1, x19
	ldr	x0, [sp, #40]
	ldr	w2, [sp, #52]
	blr	x8
	cbz	w0, .LBB41_9
// %bb.8:                               //   in Loop: Header=BB41_4 Depth=1
	add	x8, x21, #56
	ldrb	w10, [sp, #56]
	add	x8, x8, w0, sxtw
	b	.LBB41_10
.LBB41_9:                               //   in Loop: Header=BB41_4 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB41_10:                              //   in Loop: Header=BB41_4 Depth=1
	mov	x9, x22
	stp	x22, x8, [sp, #184]
.LBB41_11:                              //   in Loop: Header=BB41_4 Depth=1
	ldrb	w11, [x23, x20]
	cmp	w10, w11
	b.ne	.LBB41_14
// %bb.12:                              //   in Loop: Header=BB41_4 Depth=1
	add	x20, x20, #1
	cmp	x20, #11
	b.ne	.LBB41_4
// %bb.13:
	mov	w0, #1
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.LBB41_14:
	mov	w0, wzr
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.Lfunc_end41:
	.size	stbi_is_hdr_from_file, .Lfunc_end41-stbi_is_hdr_from_file
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_is_hdr_from_callbacks
.LCPI42_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_is_hdr_from_callbacks
	.p2align	2
	.type	stbi_is_hdr_from_callbacks,@function
stbi_is_hdr_from_callbacks:             // @stbi_is_hdr_from_callbacks
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #272
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	q0, [x0]
	adrp	x8, .LCPI42_0
	ldr	x9, [x0, #16]
	mov	x20, sp
	add	x19, x20, #56
	mov	x0, x1
	str	q0, [sp, #16]
	ldr	d1, [x8, :lo12:.LCPI42_0]
	stp	x9, x1, [sp, #32]
	ldr	x8, [sp, #16]
	mov	x1, x19
	mov	w2, #128
	str	d1, [sp, #48]
	str	x19, [sp, #200]
	blr	x8
	cbz	w0, .LBB42_2
// %bb.1:
	add	x8, x20, w0, sxtw
	add	x8, x8, #56
	b	.LBB42_3
.LBB42_2:
	add	x8, x20, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB42_3:
	mov	x21, sp
	adrp	x23, .L.str.119
	mov	x20, xzr
	add	x22, x21, #57
	mov	x9, x19
	add	x23, x23, :lo12:.L.str.119
	stp	x19, x8, [sp, #184]
.LBB42_4:                               // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB42_6
// %bb.5:                               //   in Loop: Header=BB42_4 Depth=1
	add	x11, x9, #1
	str	x11, [sp, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB42_11
.LBB42_6:                               //   in Loop: Header=BB42_4 Depth=1
	ldr	w10, [sp, #48]
	cbz	w10, .LBB42_11
// %bb.7:                               //   in Loop: Header=BB42_4 Depth=1
	ldr	x8, [sp, #16]
	mov	x1, x19
	ldr	x0, [sp, #40]
	ldr	w2, [sp, #52]
	blr	x8
	cbz	w0, .LBB42_9
// %bb.8:                               //   in Loop: Header=BB42_4 Depth=1
	add	x8, x21, #56
	ldrb	w10, [sp, #56]
	add	x8, x8, w0, sxtw
	b	.LBB42_10
.LBB42_9:                               //   in Loop: Header=BB42_4 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB42_10:                              //   in Loop: Header=BB42_4 Depth=1
	mov	x9, x22
	stp	x22, x8, [sp, #184]
.LBB42_11:                              //   in Loop: Header=BB42_4 Depth=1
	ldrb	w11, [x23, x20]
	cmp	w10, w11
	b.ne	.LBB42_14
// %bb.12:                              //   in Loop: Header=BB42_4 Depth=1
	add	x20, x20, #1
	cmp	x20, #11
	b.ne	.LBB42_4
// %bb.13:
	mov	w0, #1
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.LBB42_14:
	mov	w0, wzr
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.Lfunc_end42:
	.size	stbi_is_hdr_from_callbacks, .Lfunc_end42-stbi_is_hdr_from_callbacks
	.cfi_endproc
                                        // -- End function
	.globl	stbi_ldr_to_hdr_gamma           // -- Begin function stbi_ldr_to_hdr_gamma
	.p2align	2
	.type	stbi_ldr_to_hdr_gamma,@function
stbi_ldr_to_hdr_gamma:                  // @stbi_ldr_to_hdr_gamma
	.cfi_startproc
// %bb.0:
	adrp	x8, .L_MergedGlobals
	str	s0, [x8, :lo12:.L_MergedGlobals]
	ret
.Lfunc_end43:
	.size	stbi_ldr_to_hdr_gamma, .Lfunc_end43-stbi_ldr_to_hdr_gamma
	.cfi_endproc
                                        // -- End function
	.globl	stbi_ldr_to_hdr_scale           // -- Begin function stbi_ldr_to_hdr_scale
	.p2align	2
	.type	stbi_ldr_to_hdr_scale,@function
stbi_ldr_to_hdr_scale:                  // @stbi_ldr_to_hdr_scale
	.cfi_startproc
// %bb.0:
	adrp	x8, .L_MergedGlobals+4
	str	s0, [x8, :lo12:.L_MergedGlobals+4]
	ret
.Lfunc_end44:
	.size	stbi_ldr_to_hdr_scale, .Lfunc_end44-stbi_ldr_to_hdr_scale
	.cfi_endproc
                                        // -- End function
	.globl	stbi_hdr_to_ldr_gamma           // -- Begin function stbi_hdr_to_ldr_gamma
	.p2align	2
	.type	stbi_hdr_to_ldr_gamma,@function
stbi_hdr_to_ldr_gamma:                  // @stbi_hdr_to_ldr_gamma
	.cfi_startproc
// %bb.0:
	fmov	s1, #1.00000000
	adrp	x8, .L_MergedGlobals+8
	fdiv	s0, s1, s0
	str	s0, [x8, :lo12:.L_MergedGlobals+8]
	ret
.Lfunc_end45:
	.size	stbi_hdr_to_ldr_gamma, .Lfunc_end45-stbi_hdr_to_ldr_gamma
	.cfi_endproc
                                        // -- End function
	.globl	stbi_hdr_to_ldr_scale           // -- Begin function stbi_hdr_to_ldr_scale
	.p2align	2
	.type	stbi_hdr_to_ldr_scale,@function
stbi_hdr_to_ldr_scale:                  // @stbi_hdr_to_ldr_scale
	.cfi_startproc
// %bb.0:
	fmov	s1, #1.00000000
	adrp	x8, .L_MergedGlobals+12
	fdiv	s0, s1, s0
	str	s0, [x8, :lo12:.L_MergedGlobals+12]
	ret
.Lfunc_end46:
	.size	stbi_hdr_to_ldr_scale, .Lfunc_end46-stbi_hdr_to_ldr_scale
	.cfi_endproc
                                        // -- End function
	.globl	stbi_zlib_decode_malloc_guesssize // -- Begin function stbi_zlib_decode_malloc_guesssize
	.p2align	2
	.type	stbi_zlib_decode_malloc_guesssize,@function
stbi_zlib_decode_malloc_guesssize:      // @stbi_zlib_decode_malloc_guesssize
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x28, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	sub	sp, sp, #1, lsl #12             // =4096
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	w20, w2
	mov	x21, x0
	sxtw	x0, w20
	mov	x19, x3
	mov	w22, w1
	bl	malloc
	cbz	x0, .LBB47_4
// %bb.1:
	mov	x1, x0
	add	x8, x21, w22, sxtw
	mov	x0, sp
	mov	w2, w20
	mov	w3, #1
	mov	w4, #1
	stp	x21, x8, [sp]
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	cbz	w0, .LBB47_5
// %bb.2:
	cbz	x19, .LBB47_6
// %bb.3:
	ldr	w8, [sp, #24]
	ldr	x0, [sp, #32]
	sub	w8, w8, w0
	str	w8, [x19]
.LBB47_4:
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB47_5:
	ldr	x0, [sp, #32]
	bl	free
	mov	x0, xzr
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB47_6:
	ldr	x0, [sp, #32]
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end47:
	.size	stbi_zlib_decode_malloc_guesssize, .Lfunc_end47-stbi_zlib_decode_malloc_guesssize
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL13stbi__do_zlibP10stbi__zbufPciii
	.type	_ZL13stbi__do_zlibP10stbi__zbufPciii,@function
_ZL13stbi__do_zlibP10stbi__zbufPciii:   // @_ZL13stbi__do_zlibP10stbi__zbufPciii
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #2528
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x24, x1
	mov	x19, x0
	add	x8, x1, w2, sxtw
	stp	x1, x1, [x0, #24]
	str	w3, [x0, #48]
	str	x8, [x0, #40]
	cbz	w4, .LBB48_10
// %bb.1:
	ldp	x9, x10, [x19]
	cmp	x9, x10
	b.hs	.LBB48_4
// %bb.2:
	add	x11, x9, #1
	str	x11, [x19]
	ldrb	w8, [x9]
	mov	x9, x11
	cmp	x9, x10
	b.lo	.LBB48_5
.LBB48_3:
	mov	w9, wzr
	b	.LBB48_6
.LBB48_4:
	mov	w8, wzr
	cmp	x9, x10
	b.hs	.LBB48_3
.LBB48_5:
	add	x10, x9, #1
	str	x10, [x19]
	ldrb	w9, [x9]
.LBB48_6:
	mov	w10, w9
	mov	w11, #31711
	bfi	w10, w8, #8, #8
	movk	w11, #48623, lsl #16
	mul	w10, w10, w11
	mov	w11, #4228
	movk	w11, #2114, lsl #16
	cmp	w10, w11
	b.ls	.LBB48_8
// %bb.7:
	adrp	x8, .L.str.106
	add	x8, x8, :lo12:.L.str.106
	b	.LBB48_179
.LBB48_8:
	tbnz	w9, #5, .LBB48_174
// %bb.9:
	and	w8, w8, #0xf
	cmp	w8, #8
	b.ne	.LBB48_178
.LBB48_10:
	mov	x22, x19
	adrp	x16, _ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	mov	w23, wzr
	mov	w8, wzr
	add	x13, sp, #496
	adrp	x21, .L_MergedGlobals.126+47
	str	wzr, [x22, #16]!
	mov	x28, x22
	add	x9, x22, #2056
	add	x20, x22, #36
	add	x15, sp, #16
	add	x16, x16, :lo12:_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	str	wzr, [x28, #4]!
	cmp	w8, #0
	b.le	.LBB48_171
.LBB48_11:
	mov	w10, w8
.LBB48_12:
	lsr	w9, w23, #1
	sub	w11, w10, #1
	cmp	w11, #1
	str	w9, [x28]
	str	w11, [x22]
	b.hi	.LBB48_20
// %bb.13:
	sub	w8, w10, #9
	b	.LBB48_16
.LBB48_14:                              //   in Loop: Header=BB48_16 Depth=1
	add	x12, x11, #1
	str	x12, [x19]
	ldrb	w11, [x11]
.LBB48_15:                              //   in Loop: Header=BB48_16 Depth=1
	lsl	w10, w11, w10
	orr	w9, w10, w9
	add	w10, w8, #16
	add	w8, w8, #8
	cmp	w8, #17
	str	w9, [x28]
	str	w10, [x22]
	b.ge	.LBB48_19
.LBB48_16:                              // =>This Inner Loop Header: Depth=1
	add	w10, w8, #8
	lsr	w11, w9, w10
	cbnz	w11, .LBB48_190
// %bb.17:                              //   in Loop: Header=BB48_16 Depth=1
	ldp	x11, x12, [x19]
	cmp	x11, x12
	b.lo	.LBB48_14
// %bb.18:                              //   in Loop: Header=BB48_16 Depth=1
	mov	w11, wzr
	b	.LBB48_15
.LBB48_19:
	add	w11, w8, #8
.LBB48_20:
	lsr	w8, w9, #2
	and	w9, w9, #0x3
	sub	w10, w11, #2
	str	w8, [x28]
	str	w10, [x22]
	cbz	w9, .LBB48_30
// %bb.21:
	cmp	w9, #1
	b.eq	.LBB48_38
// %bb.22:
	cmp	w9, #3
	b.eq	.LBB48_176
// %bb.23:
	cmp	w10, #4
	b.hi	.LBB48_42
// %bb.24:
	sub	w9, w11, #10
	add	x21, sp, #40
	b	.LBB48_27
.LBB48_25:                              //   in Loop: Header=BB48_27 Depth=1
	add	x12, x11, #1
	str	x12, [x19]
	ldrb	w11, [x11]
.LBB48_26:                              //   in Loop: Header=BB48_27 Depth=1
	lsl	w10, w11, w10
	orr	w8, w10, w8
	add	w10, w9, #16
	add	w9, w9, #8
	cmp	w9, #17
	str	w8, [x28]
	str	w10, [x22]
	b.ge	.LBB48_49
.LBB48_27:                              // =>This Inner Loop Header: Depth=1
	add	w10, w9, #8
	lsr	w11, w8, w10
	cbnz	w11, .LBB48_190
// %bb.28:                              //   in Loop: Header=BB48_27 Depth=1
	ldp	x11, x12, [x19]
	cmp	x11, x12
	b.lo	.LBB48_25
// %bb.29:                              //   in Loop: Header=BB48_27 Depth=1
	mov	w11, wzr
	b	.LBB48_26
.LBB48_30:
	ands	w9, w10, #0x7
	b.eq	.LBB48_32
// %bb.31:
	lsr	w8, w8, w9
	and	w10, w10, #0xfffffff8
	str	w8, [x28]
	str	w10, [x22]
.LBB48_32:
	cbz	w10, .LBB48_153
// %bb.33:
	mov	x9, xzr
.LBB48_34:                              // =>This Inner Loop Header: Depth=1
	mov	x11, x9
	add	x9, x9, #1
	subs	w10, w10, #8
	strb	w8, [x13, x11]
	lsr	w8, w8, #8
	b.hi	.LBB48_34
// %bb.35:
	str	w8, [x28]
	str	w10, [x22]
	cbnz	w10, .LBB48_191
// %bb.36:
	cmp	w9, #3
	b.hi	.LBB48_158
// %bb.37:
	ldp	x10, x8, [x19]
	mov	w9, w9
	cmp	x10, x8
	b.lo	.LBB48_156
	b	.LBB48_154
.LBB48_38:
	ldrb	w8, [x21, :lo12:.L_MergedGlobals.126+47]
	cbnz	w8, .LBB48_40
// %bb.39:
	adrp	x8, .L_MergedGlobals.126+16
	mov	x10, #506381209866536711
	movi	v1.16b, #8
	add	x8, x8, :lo12:.L_MergedGlobals.126+16
	movi	v0.16b, #9
	mov	x9, #578721382704613384
	stp	x10, x10, [x8, #288]
	stp	q1, q1, [x8, #128]
	stp	q1, q0, [x8, #160]
	stp	q0, q0, [x8, #192]
	stp	q0, q0, [x8, #224]
	stp	q0, q0, [x8, #256]
	movi	v0.16b, #5
	stp	q1, q1, [x8, #96]
	stp	q1, q1, [x8, #64]
	stp	q1, q1, [x8, #32]
	stp	x10, x9, [x8, #304]
	stp	q0, q0, [x8]
.LBB48_40:
	adrp	x1, .L_MergedGlobals.126+48
	mov	x0, x20
	add	x1, x1, :lo12:.L_MergedGlobals.126+48
	mov	w2, #288
	bl	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	cbz	w0, .LBB48_180
// %bb.41:
	adrp	x1, .L_MergedGlobals.126+16
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	add	x1, x1, :lo12:.L_MergedGlobals.126+16
	mov	w2, #32
	bl	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	cbnz	w0, .LBB48_103
	b	.LBB48_180
.LBB48_42:
	add	x21, sp, #40
	lsr	w9, w8, #5
	sub	w11, w10, #5
	cmp	w11, #4
	str	w9, [x28]
	str	w11, [x22]
	b.hi	.LBB48_50
.LBB48_43:
	sub	w10, w10, #13
	b	.LBB48_46
.LBB48_44:                              //   in Loop: Header=BB48_46 Depth=1
	add	x13, x12, #1
	str	x13, [x19]
	ldrb	w12, [x12]
.LBB48_45:                              //   in Loop: Header=BB48_46 Depth=1
	lsl	w11, w12, w11
	orr	w9, w11, w9
	add	w11, w10, #16
	add	w10, w10, #8
	cmp	w10, #17
	str	w9, [x28]
	str	w11, [x22]
	b.ge	.LBB48_51
.LBB48_46:                              // =>This Inner Loop Header: Depth=1
	add	w11, w10, #8
	lsr	w12, w9, w11
	cbnz	w12, .LBB48_190
// %bb.47:                              //   in Loop: Header=BB48_46 Depth=1
	ldp	x12, x13, [x19]
	cmp	x12, x13
	b.lo	.LBB48_44
// %bb.48:                              //   in Loop: Header=BB48_46 Depth=1
	mov	w12, wzr
	b	.LBB48_45
.LBB48_49:
	add	w10, w9, #8
	lsr	w9, w8, #5
	sub	w11, w10, #5
	cmp	w11, #4
	str	w9, [x28]
	str	w11, [x22]
	b.ls	.LBB48_43
.LBB48_50:
	lsr	w13, w9, #5
	sub	w12, w11, #5
	cmp	w12, #3
	str	w13, [x28]
	str	w12, [x22]
	b.ls	.LBB48_52
	b	.LBB48_59
.LBB48_51:
	add	w11, w10, #8
	lsr	w13, w9, #5
	sub	w12, w11, #5
	cmp	w12, #3
	str	w13, [x28]
	str	w12, [x22]
	b.hi	.LBB48_59
.LBB48_52:
	sub	w10, w11, #13
	b	.LBB48_55
.LBB48_53:                              //   in Loop: Header=BB48_55 Depth=1
	add	x14, x12, #1
	str	x14, [x19]
	ldrb	w12, [x12]
.LBB48_54:                              //   in Loop: Header=BB48_55 Depth=1
	lsl	w11, w12, w11
	orr	w13, w11, w13
	add	w11, w10, #16
	add	w10, w10, #8
	cmp	w10, #17
	str	w13, [x28]
	str	w11, [x22]
	b.ge	.LBB48_58
.LBB48_55:                              // =>This Inner Loop Header: Depth=1
	add	w11, w10, #8
	lsr	w12, w13, w11
	cbnz	w12, .LBB48_190
// %bb.56:                              //   in Loop: Header=BB48_55 Depth=1
	ldp	x12, x14, [x19]
	cmp	x12, x14
	b.lo	.LBB48_53
// %bb.57:                              //   in Loop: Header=BB48_55 Depth=1
	mov	w12, wzr
	b	.LBB48_54
.LBB48_58:
	add	w12, w10, #8
.LBB48_59:
	and	w8, w8, #0x1f
	and	w9, w9, #0x1f
	add	w24, w8, #257
	and	w8, w13, #0xf
	mov	x10, xzr
	lsr	w11, w13, #4
	sub	w12, w12, #4
	add	w27, w9, #1
	add	w8, w8, #4
	stp	xzr, xzr, [sp, #16]
	str	w11, [x28]
	str	w12, [x22]
	stur	wzr, [sp, #31]
	b	.LBB48_61
.LBB48_60:                              //   in Loop: Header=BB48_61 Depth=1
	lsr	w13, w11, #3
	sub	w12, w9, #3
	ldrb	w9, [x16, x10]
	and	w14, w11, #0x7
	add	x10, x10, #1
	mov	w11, w13
	cmp	x10, x8
	str	w13, [x28]
	str	w12, [x22]
	strb	w14, [x15, x9]
	b.eq	.LBB48_68
.LBB48_61:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB48_65 Depth 2
	cmp	w12, #2
	b.ls	.LBB48_65
// %bb.62:                              //   in Loop: Header=BB48_61 Depth=1
	mov	w9, w12
	b	.LBB48_60
.LBB48_63:                              //   in Loop: Header=BB48_65 Depth=2
	add	x13, x9, #1
	str	x13, [x19]
	ldrb	w9, [x9]
.LBB48_64:                              //   in Loop: Header=BB48_65 Depth=2
	lsl	w13, w9, w12
	add	w9, w12, #8
	orr	w11, w13, w11
	cmp	w12, #17
	mov	w12, w9
	str	w9, [x22]
	str	w11, [x28]
	b.ge	.LBB48_60
.LBB48_65:                              //   Parent Loop BB48_61 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	lsr	w9, w11, w12
	cbnz	w9, .LBB48_190
// %bb.66:                              //   in Loop: Header=BB48_65 Depth=2
	ldp	x9, x13, [x19]
	cmp	x9, x13
	b.lo	.LBB48_63
// %bb.67:                              //   in Loop: Header=BB48_65 Depth=2
	mov	w9, wzr
	b	.LBB48_64
.LBB48_68:
	add	x0, sp, #496
	add	x1, sp, #16
	mov	w2, #19
	bl	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	cbz	w0, .LBB48_176
// %bb.69:
	mov	w25, wzr
	str	w24, [sp, #4]                   // 4-byte Folded Spill
	add	w24, w27, w24
	b	.LBB48_71
.LBB48_70:                              //   in Loop: Header=BB48_71 Depth=1
	add	w8, w25, #1
	strb	w0, [x21, w25, sxtw]
	mov	w25, w8
	cmp	w25, w24
	b.ge	.LBB48_100
.LBB48_71:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB48_97 Depth 2
                                        //     Child Loop BB48_80 Depth 2
                                        //     Child Loop BB48_88 Depth 2
	add	x1, sp, #496
	mov	x0, x19
	bl	_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman
	cmp	w0, #18
	b.hi	.LBB48_175
// %bb.72:                              //   in Loop: Header=BB48_71 Depth=1
	cmp	w0, #15
	b.ls	.LBB48_70
// %bb.73:                              //   in Loop: Header=BB48_71 Depth=1
	cmp	w0, #17
	b.eq	.LBB48_83
// %bb.74:                              //   in Loop: Header=BB48_71 Depth=1
	cmp	w0, #16
	b.ne	.LBB48_91
// %bb.75:                              //   in Loop: Header=BB48_71 Depth=1
	ldr	w9, [x22]
	ldr	w8, [x28]
	cmp	w9, #1
	b.le	.LBB48_80
// %bb.76:                              //   in Loop: Header=BB48_71 Depth=1
	mov	w10, w9
.LBB48_77:                              //   in Loop: Header=BB48_71 Depth=1
	add	x0, x21, w25, sxtw
	lsr	w9, w8, #2
	sub	w10, w10, #2
	and	w8, w8, #0x3
	add	w26, w8, #3
	ldurb	w1, [x0, #-1]
	str	w9, [x28]
	str	w10, [x22]
	mov	x2, x26
	bl	memset
	add	w25, w26, w25
	cmp	w25, w24
	b.lt	.LBB48_71
	b	.LBB48_100
.LBB48_78:                              //   in Loop: Header=BB48_80 Depth=2
	add	x11, x10, #1
	str	x11, [x19]
	ldrb	w10, [x10]
.LBB48_79:                              //   in Loop: Header=BB48_80 Depth=2
	lsl	w11, w10, w9
	add	w10, w9, #8
	orr	w8, w11, w8
	cmp	w9, #17
	mov	w9, w10
	str	w10, [x22]
	str	w8, [x28]
	b.ge	.LBB48_77
.LBB48_80:                              //   Parent Loop BB48_71 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	lsr	w10, w8, w9
	cbnz	w10, .LBB48_190
// %bb.81:                              //   in Loop: Header=BB48_80 Depth=2
	ldp	x10, x11, [x19]
	cmp	x10, x11
	b.lo	.LBB48_78
// %bb.82:                              //   in Loop: Header=BB48_80 Depth=2
	mov	w10, wzr
	b	.LBB48_79
.LBB48_83:                              //   in Loop: Header=BB48_71 Depth=1
	ldr	w9, [x22]
	ldr	w8, [x28]
	cmp	w9, #2
	b.le	.LBB48_88
// %bb.84:                              //   in Loop: Header=BB48_71 Depth=1
	mov	w10, w9
.LBB48_85:                              //   in Loop: Header=BB48_71 Depth=1
	lsr	w9, w8, #3
	and	w8, w8, #0x7
	sub	w10, w10, #3
	add	x0, x21, w25, sxtw
	add	w26, w8, #3
	b	.LBB48_94
.LBB48_86:                              //   in Loop: Header=BB48_88 Depth=2
	add	x11, x10, #1
	str	x11, [x19]
	ldrb	w10, [x10]
.LBB48_87:                              //   in Loop: Header=BB48_88 Depth=2
	lsl	w11, w10, w9
	add	w10, w9, #8
	orr	w8, w11, w8
	cmp	w9, #17
	mov	w9, w10
	str	w10, [x22]
	str	w8, [x28]
	b.ge	.LBB48_85
.LBB48_88:                              //   Parent Loop BB48_71 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	lsr	w10, w8, w9
	cbnz	w10, .LBB48_190
// %bb.89:                              //   in Loop: Header=BB48_88 Depth=2
	ldp	x10, x11, [x19]
	cmp	x10, x11
	b.lo	.LBB48_86
// %bb.90:                              //   in Loop: Header=BB48_88 Depth=2
	mov	w10, wzr
	b	.LBB48_87
.LBB48_91:                              //   in Loop: Header=BB48_71 Depth=1
	ldr	w9, [x22]
	ldr	w8, [x28]
	cmp	w9, #6
	b.le	.LBB48_97
// %bb.92:                              //   in Loop: Header=BB48_71 Depth=1
	mov	w10, w9
.LBB48_93:                              //   in Loop: Header=BB48_71 Depth=1
	lsr	w9, w8, #7
	and	w8, w8, #0x7f
	sub	w10, w10, #7
	add	x0, x21, w25, sxtw
	add	w26, w8, #11
.LBB48_94:                              //   in Loop: Header=BB48_71 Depth=1
	mov	w1, wzr
	str	w9, [x28]
	str	w10, [x22]
	mov	x2, x26
	bl	memset
	add	w25, w26, w25
	cmp	w25, w24
	b.lt	.LBB48_71
	b	.LBB48_100
.LBB48_95:                              //   in Loop: Header=BB48_97 Depth=2
	add	x11, x10, #1
	str	x11, [x19]
	ldrb	w10, [x10]
.LBB48_96:                              //   in Loop: Header=BB48_97 Depth=2
	lsl	w11, w10, w9
	add	w10, w9, #8
	orr	w8, w11, w8
	cmp	w9, #17
	mov	w9, w10
	str	w10, [x22]
	str	w8, [x28]
	b.ge	.LBB48_93
.LBB48_97:                              //   Parent Loop BB48_71 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	lsr	w10, w8, w9
	cbnz	w10, .LBB48_190
// %bb.98:                              //   in Loop: Header=BB48_97 Depth=2
	ldp	x10, x11, [x19]
	cmp	x10, x11
	b.lo	.LBB48_95
// %bb.99:                              //   in Loop: Header=BB48_97 Depth=2
	mov	w10, wzr
	b	.LBB48_96
.LBB48_100:
	b.ne	.LBB48_175
// %bb.101:
	ldr	w24, [sp, #4]                   // 4-byte Folded Reload
	add	x1, sp, #40
	mov	x0, x20
	mov	w2, w24
	bl	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	cbz	w0, .LBB48_176
// %bb.102:
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	add	x1, x21, w24, uxtw
	mov	w2, w27
	bl	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	cbz	w0, .LBB48_180
.LBB48_103:
	ldr	x24, [x19, #24]
	b	.LBB48_105
.LBB48_104:                             //   in Loop: Header=BB48_105 Depth=1
	strb	w25, [x24], #1
.LBB48_105:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB48_135 Depth 2
                                        //     Child Loop BB48_140 Depth 2
                                        //     Child Loop BB48_127 Depth 2
                                        //     Child Loop BB48_151 Depth 2
                                        //     Child Loop BB48_149 Depth 2
                                        //     Child Loop BB48_110 Depth 2
	mov	x0, x19
	mov	x1, x20
	bl	_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman
	mov	w25, w0
	cmp	w0, #255
	b.gt	.LBB48_113
// %bb.106:                             //   in Loop: Header=BB48_105 Depth=1
	tbnz	w25, #31, .LBB48_177
// %bb.107:                             //   in Loop: Header=BB48_105 Depth=1
	ldr	x8, [x19, #40]
	cmp	x24, x8
	b.lo	.LBB48_104
// %bb.108:                             //   in Loop: Header=BB48_105 Depth=1
	ldr	w9, [x19, #48]
	str	x24, [x19, #24]
	cbz	w9, .LBB48_181
// %bb.109:                             //   in Loop: Header=BB48_105 Depth=1
	ldr	x0, [x19, #32]
	sub	x21, x24, x0
	sub	w8, w8, w0
.LBB48_110:                             //   Parent Loop BB48_105 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov	w9, w8
	lsl	w8, w8, #1
	cmp	w9, w21
	b.le	.LBB48_110
// %bb.111:                             //   in Loop: Header=BB48_105 Depth=1
	sxtw	x26, w9
	mov	x1, x26
	bl	realloc
	cbz	x0, .LBB48_183
// %bb.112:                             //   in Loop: Header=BB48_105 Depth=1
	add	x24, x0, w21, sxtw
	add	x8, x0, x26
	stp	x24, x0, [x19, #24]
	str	x8, [x19, #40]
	b	.LBB48_104
.LBB48_113:                             //   in Loop: Header=BB48_105 Depth=1
	cmp	w25, #256
	b.eq	.LBB48_167
// %bb.114:                             //   in Loop: Header=BB48_105 Depth=1
	sub	w8, w25, #257
	adrp	x9, _ZL18stbi__zlength_base
	add	x9, x9, :lo12:_ZL18stbi__zlength_base
	ldr	w26, [x9, w8, uxtw #2]
	sub	x9, x8, #28
	cmn	x9, #20
	b.lo	.LBB48_118
// %bb.115:                             //   in Loop: Header=BB48_105 Depth=1
	adrp	x9, _ZL19stbi__zlength_extra
	ldr	w10, [x22]
	add	x9, x9, :lo12:_ZL19stbi__zlength_extra
	ldr	w8, [x9, x8, lsl #2]
	ldr	w9, [x28]
	cmp	w10, w8
	b.lt	.LBB48_135
// %bb.116:                             //   in Loop: Header=BB48_105 Depth=1
	mov	w11, w10
.LBB48_117:                             //   in Loop: Header=BB48_105 Depth=1
	mov	w10, #-1
	lsr	w12, w9, w8
	lsl	w10, w10, w8
	sub	w8, w11, w8
	bic	w9, w9, w10
	add	w26, w9, w26
	str	w12, [x28]
	str	w8, [x22]
.LBB48_118:                             //   in Loop: Header=BB48_105 Depth=1
	mov	x0, x19
	ldr	x1, [sp, #8]                    // 8-byte Folded Reload
	bl	_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman
	tbnz	w0, #31, .LBB48_177
// %bb.119:                             //   in Loop: Header=BB48_105 Depth=1
	adrp	x8, _ZL16stbi__zdist_base
	mov	w9, w0
	add	x8, x8, :lo12:_ZL16stbi__zdist_base
	sub	x10, x9, #30
	cmn	x10, #26
	ldr	w8, [x8, w0, uxtw #2]
	b.lo	.LBB48_123
// %bb.120:                             //   in Loop: Header=BB48_105 Depth=1
	adrp	x10, _ZL17stbi__zdist_extra
	ldr	w11, [x22]
	add	x10, x10, :lo12:_ZL17stbi__zdist_extra
	ldr	w9, [x10, x9, lsl #2]
	ldr	w10, [x28]
	cmp	w11, w9
	b.lt	.LBB48_140
// %bb.121:                             //   in Loop: Header=BB48_105 Depth=1
	mov	w12, w11
.LBB48_122:                             //   in Loop: Header=BB48_105 Depth=1
	mov	w11, #-1
	lsr	w13, w10, w9
	lsl	w11, w11, w9
	sub	w9, w12, w9
	bic	w10, w10, w11
	add	w8, w10, w8
	str	w13, [x28]
	str	w9, [x22]
.LBB48_123:                             //   in Loop: Header=BB48_105 Depth=1
	ldr	x0, [x19, #32]
	sxtw	x21, w8
	sub	x27, x24, x0
	cmp	x27, x21
	b.lt	.LBB48_182
// %bb.124:                             //   in Loop: Header=BB48_105 Depth=1
	ldr	x8, [x19, #40]
	add	x9, x24, w26, sxtw
	cmp	x9, x8
	b.ls	.LBB48_130
// %bb.125:                             //   in Loop: Header=BB48_105 Depth=1
	ldr	w9, [x19, #48]
	str	x24, [x19, #24]
	cbz	w9, .LBB48_181
// %bb.126:                             //   in Loop: Header=BB48_105 Depth=1
	sub	w8, w8, w0
	add	w9, w26, w27
.LBB48_127:                             //   Parent Loop BB48_105 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov	w10, w8
	lsl	w8, w8, #1
	cmp	w9, w10
	b.gt	.LBB48_127
// %bb.128:                             //   in Loop: Header=BB48_105 Depth=1
	sxtw	x25, w10
	mov	x1, x25
	bl	realloc
	cbz	x0, .LBB48_183
// %bb.129:                             //   in Loop: Header=BB48_105 Depth=1
	add	x24, x0, w27, sxtw
	add	x8, x0, x25
	stp	x24, x0, [x19, #24]
	str	x8, [x19, #40]
.LBB48_130:                             //   in Loop: Header=BB48_105 Depth=1
	sub	x8, x24, x21
	cmp	w21, #1
	b.ne	.LBB48_143
// %bb.131:                             //   in Loop: Header=BB48_105 Depth=1
	cbz	w26, .LBB48_105
// %bb.132:                             //   in Loop: Header=BB48_105 Depth=1
	mov	w2, w26
	ldrb	w1, [x8]
	mov	x0, x24
	bl	memset
	sub	w8, w26, #1
	add	x8, x24, x8
	add	x24, x8, #1
	b	.LBB48_105
.LBB48_133:                             //   in Loop: Header=BB48_135 Depth=2
	add	x12, x11, #1
	str	x12, [x19]
	ldrb	w11, [x11]
.LBB48_134:                             //   in Loop: Header=BB48_135 Depth=2
	lsl	w12, w11, w10
	add	w11, w10, #8
	orr	w9, w12, w9
	cmp	w10, #17
	mov	w10, w11
	str	w11, [x22]
	str	w9, [x28]
	b.ge	.LBB48_117
.LBB48_135:                             //   Parent Loop BB48_105 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	lsr	w11, w9, w10
	cbnz	w11, .LBB48_190
// %bb.136:                             //   in Loop: Header=BB48_135 Depth=2
	ldp	x11, x12, [x19]
	cmp	x11, x12
	b.lo	.LBB48_133
// %bb.137:                             //   in Loop: Header=BB48_135 Depth=2
	mov	w11, wzr
	b	.LBB48_134
.LBB48_138:                             //   in Loop: Header=BB48_140 Depth=2
	add	x13, x12, #1
	str	x13, [x19]
	ldrb	w12, [x12]
.LBB48_139:                             //   in Loop: Header=BB48_140 Depth=2
	lsl	w13, w12, w11
	add	w12, w11, #8
	orr	w10, w13, w10
	cmp	w11, #17
	mov	w11, w12
	str	w12, [x22]
	str	w10, [x28]
	b.ge	.LBB48_122
.LBB48_140:                             //   Parent Loop BB48_105 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	lsr	w12, w10, w11
	cbnz	w12, .LBB48_190
// %bb.141:                             //   in Loop: Header=BB48_140 Depth=2
	ldp	x12, x13, [x19]
	cmp	x12, x13
	b.lo	.LBB48_138
// %bb.142:                             //   in Loop: Header=BB48_140 Depth=2
	mov	w12, wzr
	b	.LBB48_139
.LBB48_143:                             //   in Loop: Header=BB48_105 Depth=1
	cbz	w26, .LBB48_105
// %bb.144:                             //   in Loop: Header=BB48_105 Depth=1
	sub	w9, w26, #1
	cmp	w9, #31
	b.lo	.LBB48_147
// %bb.145:                             //   in Loop: Header=BB48_105 Depth=1
	add	x10, x24, #1
	sub	x11, x9, x21
	add	x11, x10, x11
	cmp	x24, x11
	b.hs	.LBB48_150
// %bb.146:                             //   in Loop: Header=BB48_105 Depth=1
	add	x10, x10, x9
	cmp	x8, x10
	b.hs	.LBB48_150
.LBB48_147:                             //   in Loop: Header=BB48_105 Depth=1
	mov	x9, x24
.LBB48_148:                             //   in Loop: Header=BB48_105 Depth=1
	mov	x24, x9
.LBB48_149:                             //   Parent Loop BB48_105 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w9, [x8], #1
	subs	w26, w26, #1
	strb	w9, [x24], #1
	b.ne	.LBB48_149
	b	.LBB48_105
.LBB48_150:                             //   in Loop: Header=BB48_105 Depth=1
	add	x10, x9, #1
	neg	x12, x21
	and	x11, x10, #0x1ffffffe0
	add	x9, x24, x11
	add	x8, x8, x11
	sub	w26, w26, w11
	mov	x13, x11
.LBB48_151:                             //   Parent Loop BB48_105 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x14, x24, x12
	subs	x13, x13, #32
	ldp	q0, q1, [x14]
	stp	q0, q1, [x24], #32
	b.ne	.LBB48_151
// %bb.152:                             //   in Loop: Header=BB48_105 Depth=1
	mov	x24, x9
	cmp	x10, x11
	b.eq	.LBB48_105
	b	.LBB48_148
.LBB48_153:
	mov	w9, wzr
	ldp	x10, x8, [x19]
	mov	w9, w9
	cmp	x10, x8
	b.lo	.LBB48_156
.LBB48_154:
	mov	w8, #3
	add	x0, x13, x9
	sub	w8, w8, w9
	mov	w1, wzr
	add	x2, x8, #1
	bl	memset
	b	.LBB48_158
.LBB48_155:                             //   in Loop: Header=BB48_156 Depth=1
	add	x12, x10, #1
	str	x12, [x19]
	ldrb	w11, [x10]
	mov	x10, x12
	add	x12, x9, #1
	strb	w11, [x13, x9]
	mov	x9, x12
	cmp	x12, #4
	b.eq	.LBB48_158
.LBB48_156:                             // =>This Inner Loop Header: Depth=1
	cmp	x10, x8
	b.lo	.LBB48_155
// %bb.157:                             //   in Loop: Header=BB48_156 Depth=1
	mov	w11, wzr
	add	x12, x9, #1
	strb	w11, [x13, x9]
	mov	x9, x12
	cmp	x12, #4
	b.ne	.LBB48_156
.LBB48_158:
	ldrh	w25, [sp, #496]
	ldrh	w8, [sp, #498]
	eor	w9, w25, #0xffff
	cmp	w8, w9
	b.ne	.LBB48_185
// %bb.159:
	ldp	x1, x8, [x19]
	add	x9, x1, x25
	cmp	x9, x8
	b.hi	.LBB48_186
// %bb.160:
	ldr	x8, [x19, #40]
	add	x9, x24, x25
	cmp	x9, x8
	b.ls	.LBB48_166
// %bb.161:
	ldr	w9, [x19, #48]
	cbz	w9, .LBB48_187
// %bb.162:
	ldr	x0, [x19, #32]
	mov	x27, x21
	sub	x21, x24, x0
	sub	w8, w8, w0
	add	w9, w25, w21
.LBB48_163:                             // =>This Inner Loop Header: Depth=1
	mov	w10, w8
	lsl	w8, w8, #1
	cmp	w9, w10
	b.gt	.LBB48_163
// %bb.164:
	sxtw	x26, w10
	mov	x1, x26
	bl	realloc
	cbz	x0, .LBB48_188
// %bb.165:
	add	x24, x0, w21, sxtw
	add	x8, x0, x26
	ldr	x1, [x19]
	mov	x21, x27
	stp	x24, x0, [x19, #24]
	str	x8, [x19, #40]
.LBB48_166:
	mov	x0, x24
	mov	x2, x25
	bl	memcpy
	ldr	x8, [x19]
	ldr	x9, [x19, #24]
	add	x8, x8, x25
	add	x24, x9, x25
	str	x8, [x19]
	str	x24, [x19, #24]
	adrp	x16, _ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	add	x13, sp, #496
	add	x15, sp, #16
	add	x16, x16, :lo12:_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	tbz	w23, #0, .LBB48_168
	b	.LBB48_184
.LBB48_167:
	adrp	x21, .L_MergedGlobals.126+47
	str	x24, [x19, #24]
	adrp	x16, _ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	add	x13, sp, #496
	add	x15, sp, #16
	add	x16, x16, :lo12:_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	tbnz	w23, #0, .LBB48_184
.LBB48_168:
	ldr	w8, [x22]
	ldr	w23, [x28]
	cmp	w8, #0
	b.gt	.LBB48_11
	b	.LBB48_171
.LBB48_169:                             //   in Loop: Header=BB48_171 Depth=1
	add	x10, x9, #1
	str	x10, [x19]
	ldrb	w9, [x9]
.LBB48_170:                             //   in Loop: Header=BB48_171 Depth=1
	lsl	w9, w9, w8
	add	w10, w8, #8
	orr	w23, w9, w23
	cmp	w8, #17
	mov	w8, w10
	str	w10, [x22]
	str	w23, [x28]
	b.ge	.LBB48_12
.LBB48_171:                             // =>This Inner Loop Header: Depth=1
	lsr	w9, w23, w8
	cbnz	w9, .LBB48_190
// %bb.172:                             //   in Loop: Header=BB48_171 Depth=1
	ldp	x9, x10, [x19]
	cmp	x9, x10
	b.lo	.LBB48_169
// %bb.173:                             //   in Loop: Header=BB48_171 Depth=1
	mov	w9, wzr
	b	.LBB48_170
.LBB48_174:
	adrp	x8, .L.str.107
	add	x8, x8, :lo12:.L.str.107
	b	.LBB48_179
.LBB48_175:
	adrp	x9, .L.str.114
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.114
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB48_176:
	mov	w0, wzr
	b	.LBB48_180
.LBB48_177:
	adrp	x9, .L.str.36
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.36
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB48_180
.LBB48_178:
	adrp	x8, .L.str.91
	add	x8, x8, :lo12:.L.str.91
.LBB48_179:
	adrp	x9, .L_MergedGlobals.126+8
	mov	w0, wzr
	str	x8, [x9, :lo12:.L_MergedGlobals.126+8]
.LBB48_180:
	add	sp, sp, #2528
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB48_181:
	adrp	x9, .L.str.112
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.112
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB48_180
.LBB48_182:
	adrp	x9, .L.str.118
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.118
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB48_180
.LBB48_183:
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB48_180
.LBB48_184:
	mov	w0, #1
	b	.LBB48_180
.LBB48_185:
	adrp	x9, .L.str.110
	add	x9, x9, :lo12:.L.str.110
	b	.LBB48_189
.LBB48_186:
	adrp	x9, .L.str.111
	add	x9, x9, :lo12:.L.str.111
	b	.LBB48_189
.LBB48_187:
	adrp	x9, .L.str.112
	add	x9, x9, :lo12:.L.str.112
	b	.LBB48_189
.LBB48_188:
	adrp	x9, .L.str.28
	add	x9, x9, :lo12:.L.str.28
.LBB48_189:
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB48_180
.LBB48_190:
	adrp	x0, .L.str.108
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf
	add	x0, x0, :lo12:.L.str.108
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf
	mov	w2, #3545
	bl	__assert_fail
.LBB48_191:
	adrp	x0, .L.str.109
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL30stbi__parse_uncomperssed_blockP10stbi__zbuf
	add	x0, x0, :lo12:.L.str.109
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL30stbi__parse_uncomperssed_blockP10stbi__zbuf
	mov	w2, #3726
	bl	__assert_fail
.Lfunc_end48:
	.size	_ZL13stbi__do_zlibP10stbi__zbufPciii, .Lfunc_end48-_ZL13stbi__do_zlibP10stbi__zbufPciii
	.cfi_endproc
                                        // -- End function
	.globl	stbi_zlib_decode_malloc         // -- Begin function stbi_zlib_decode_malloc
	.p2align	2
	.type	stbi_zlib_decode_malloc,@function
stbi_zlib_decode_malloc:                // @stbi_zlib_decode_malloc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x28, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	sub	sp, sp, #1, lsl #12             // =4096
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w28, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x20, x0
	mov	w0, #16384
	mov	x19, x2
	mov	w21, w1
	bl	malloc
	cbz	x0, .LBB49_4
// %bb.1:
	mov	x1, x0
	add	x8, x20, w21, sxtw
	mov	x0, sp
	mov	w2, #16384
	mov	w3, #1
	mov	w4, #1
	stp	x20, x8, [sp]
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	cbz	w0, .LBB49_5
// %bb.2:
	cbz	x19, .LBB49_6
// %bb.3:
	ldr	w8, [sp, #24]
	ldr	x0, [sp, #32]
	sub	w8, w8, w0
	str	w8, [x19]
.LBB49_4:
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB49_5:
	ldr	x0, [sp, #32]
	bl	free
	mov	x0, xzr
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB49_6:
	ldr	x0, [sp, #32]
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end49:
	.size	stbi_zlib_decode_malloc, .Lfunc_end49-stbi_zlib_decode_malloc
	.cfi_endproc
                                        // -- End function
	.globl	stbi_zlib_decode_malloc_guesssize_headerflag // -- Begin function stbi_zlib_decode_malloc_guesssize_headerflag
	.p2align	2
	.type	stbi_zlib_decode_malloc_guesssize_headerflag,@function
stbi_zlib_decode_malloc_guesssize_headerflag: // @stbi_zlib_decode_malloc_guesssize_headerflag
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	stp	x28, x23, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	sub	sp, sp, #1, lsl #12             // =4096
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	w21, w2
	mov	x22, x0
	sxtw	x0, w21
	mov	w20, w4
	mov	x19, x3
	mov	w23, w1
	bl	malloc
	cbz	x0, .LBB50_4
// %bb.1:
	mov	x1, x0
	add	x8, x22, w23, sxtw
	mov	x0, sp
	mov	w2, w21
	mov	w3, #1
	mov	w4, w20
	stp	x22, x8, [sp]
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	cbz	w0, .LBB50_5
// %bb.2:
	cbz	x19, .LBB50_6
// %bb.3:
	ldr	w8, [sp, #24]
	ldr	x0, [sp, #32]
	sub	w8, w8, w0
	str	w8, [x19]
.LBB50_4:
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB50_5:
	ldr	x0, [sp, #32]
	bl	free
	mov	x0, xzr
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB50_6:
	ldr	x0, [sp, #32]
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end50:
	.size	stbi_zlib_decode_malloc_guesssize_headerflag, .Lfunc_end50-stbi_zlib_decode_malloc_guesssize_headerflag
	.cfi_endproc
                                        // -- End function
	.globl	stbi_zlib_decode_buffer         // -- Begin function stbi_zlib_decode_buffer
	.p2align	2
	.type	stbi_zlib_decode_buffer,@function
stbi_zlib_decode_buffer:                // @stbi_zlib_decode_buffer
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x28, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	sub	sp, sp, #1, lsl #12             // =4096
	.cfi_def_cfa w29, 32
	.cfi_offset w28, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	add	x9, x2, w3, sxtw
	mov	w8, w1
	mov	x1, x0
	mov	x0, sp
	mov	w3, wzr
	mov	w4, #1
	stp	x2, x9, [sp]
	mov	w2, w8
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	ldr	w8, [sp, #24]
	cmp	w0, #0
	ldr	w9, [sp, #32]
	sub	w8, w8, w9
	csinv	w0, w8, wzr, ne
	add	sp, sp, #1, lsl #12             // =4096
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end51:
	.size	stbi_zlib_decode_buffer, .Lfunc_end51-stbi_zlib_decode_buffer
	.cfi_endproc
                                        // -- End function
	.globl	stbi_zlib_decode_noheader_malloc // -- Begin function stbi_zlib_decode_noheader_malloc
	.p2align	2
	.type	stbi_zlib_decode_noheader_malloc,@function
stbi_zlib_decode_noheader_malloc:       // @stbi_zlib_decode_noheader_malloc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x28, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	sub	sp, sp, #1, lsl #12             // =4096
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w28, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x20, x0
	mov	w0, #16384
	mov	x19, x2
	mov	w21, w1
	bl	malloc
	cbz	x0, .LBB52_4
// %bb.1:
	mov	x1, x0
	add	x8, x20, w21, sxtw
	mov	x0, sp
	mov	w2, #16384
	mov	w3, #1
	mov	w4, wzr
	stp	x20, x8, [sp]
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	cbz	w0, .LBB52_5
// %bb.2:
	cbz	x19, .LBB52_6
// %bb.3:
	ldr	w8, [sp, #24]
	ldr	x0, [sp, #32]
	sub	w8, w8, w0
	str	w8, [x19]
.LBB52_4:
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB52_5:
	ldr	x0, [sp, #32]
	bl	free
	mov	x0, xzr
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB52_6:
	ldr	x0, [sp, #32]
	add	sp, sp, #1, lsl #12             // =4096
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end52:
	.size	stbi_zlib_decode_noheader_malloc, .Lfunc_end52-stbi_zlib_decode_noheader_malloc
	.cfi_endproc
                                        // -- End function
	.globl	stbi_zlib_decode_noheader_buffer // -- Begin function stbi_zlib_decode_noheader_buffer
	.p2align	2
	.type	stbi_zlib_decode_noheader_buffer,@function
stbi_zlib_decode_noheader_buffer:       // @stbi_zlib_decode_noheader_buffer
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x28, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	sub	sp, sp, #1, lsl #12             // =4096
	.cfi_def_cfa w29, 32
	.cfi_offset w28, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	add	x9, x2, w3, sxtw
	mov	w8, w1
	mov	x1, x0
	mov	x0, sp
	mov	w3, wzr
	mov	w4, wzr
	stp	x2, x9, [sp]
	mov	w2, w8
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	ldr	w8, [sp, #24]
	cmp	w0, #0
	ldr	w9, [sp, #32]
	sub	w8, w8, w9
	csinv	w0, w8, wzr, ne
	add	sp, sp, #1, lsl #12             // =4096
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end53:
	.size	stbi_zlib_decode_noheader_buffer, .Lfunc_end53-stbi_zlib_decode_noheader_buffer
	.cfi_endproc
                                        // -- End function
	.globl	stbi_set_unpremultiply_on_load  // -- Begin function stbi_set_unpremultiply_on_load
	.p2align	2
	.type	stbi_set_unpremultiply_on_load,@function
stbi_set_unpremultiply_on_load:         // @stbi_set_unpremultiply_on_load
	.cfi_startproc
// %bb.0:
	adrp	x8, _ZL27stbi__unpremultiply_on_load
	str	w0, [x8, :lo12:_ZL27stbi__unpremultiply_on_load]
	ret
.Lfunc_end54:
	.size	stbi_set_unpremultiply_on_load, .Lfunc_end54-stbi_set_unpremultiply_on_load
	.cfi_endproc
                                        // -- End function
	.globl	stbi_convert_iphone_png_to_rgb  // -- Begin function stbi_convert_iphone_png_to_rgb
	.p2align	2
	.type	stbi_convert_iphone_png_to_rgb,@function
stbi_convert_iphone_png_to_rgb:         // @stbi_convert_iphone_png_to_rgb
	.cfi_startproc
// %bb.0:
	adrp	x8, .L_MergedGlobals.126+4
	str	w0, [x8, :lo12:.L_MergedGlobals.126+4]
	ret
.Lfunc_end55:
	.size	stbi_convert_iphone_png_to_rgb, .Lfunc_end55-stbi_convert_iphone_png_to_rgb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_info
.LCPI56_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_info
	.p2align	2
	.type	stbi_info,@function
stbi_info:                              // @stbi_info
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w28, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	x22, x1
	adrp	x1, .L.str.1
	add	x1, x1, :lo12:.L.str.1
	mov	x20, x3
	mov	x21, x2
	bl	fopen
	cbz	x0, .LBB56_3
// %bb.1:
	mov	x19, x0
	bl	ftell
	adrp	x9, _ZL21stbi__stdio_callbacks
	adrp	x8, .LCPI56_0
	add	x9, x9, :lo12:_ZL21stbi__stdio_callbacks
	mov	x25, sp
	add	x24, x25, #56
	mov	x23, x0
	mov	x0, x19
	mov	x1, x24
	ldr	q0, [x9]
	mov	w2, #128
	ldr	x9, [x9, #16]
	str	x24, [sp, #200]
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI56_0]
	ldr	x8, [sp, #16]
	stp	x9, x19, [sp, #32]
	str	d0, [sp, #48]
	blr	x8
	cbz	w0, .LBB56_4
// %bb.2:
	add	x8, x25, w0, sxtw
	add	x8, x8, #56
	b	.LBB56_5
.LBB56_3:
	adrp	x9, .L.str.2
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.2
	mov	w20, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB56_6
.LBB56_4:
	add	x8, x25, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB56_5:
	mov	x0, sp
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	stp	x24, x8, [sp, #184]
	bl	_ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	mov	w20, w0
	mov	x0, x19
	mov	x1, x23
	mov	w2, wzr
	bl	fseek
	mov	x0, x19
	bl	fclose
.LBB56_6:
	mov	w0, w20
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end56:
	.size	stbi_info, .Lfunc_end56-stbi_info
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_info_from_file
.LCPI57_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_info_from_file
	.p2align	2
	.type	stbi_info_from_file,@function
stbi_info_from_file:                    // @stbi_info_from_file
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w28, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	x20, x3
	mov	x22, x2
	mov	x23, x1
	mov	x19, x0
	bl	ftell
	adrp	x9, _ZL21stbi__stdio_callbacks
	adrp	x8, .LCPI57_0
	add	x9, x9, :lo12:_ZL21stbi__stdio_callbacks
	mov	x25, sp
	add	x24, x25, #56
	mov	x21, x0
	mov	x0, x19
	mov	x1, x24
	ldr	q0, [x9]
	mov	w2, #128
	ldr	x9, [x9, #16]
	str	x24, [sp, #200]
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI57_0]
	ldr	x8, [sp, #16]
	stp	x9, x19, [sp, #32]
	str	d0, [sp, #48]
	blr	x8
	cbz	w0, .LBB57_2
// %bb.1:
	add	x8, x25, w0, sxtw
	add	x8, x8, #56
	b	.LBB57_3
.LBB57_2:
	add	x8, x25, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB57_3:
	mov	x0, sp
	mov	x1, x23
	mov	x2, x22
	mov	x3, x20
	stp	x24, x8, [sp, #184]
	bl	_ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	mov	w20, w0
	mov	x0, x19
	mov	x1, x21
	mov	w2, wzr
	bl	fseek
	mov	w0, w20
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.Lfunc_end57:
	.size	stbi_info_from_file, .Lfunc_end57-stbi_info_from_file
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	.type	_ZL15stbi__info_mainP13stbi__contextPiS1_S1_,@function
_ZL15stbi__info_mainP13stbi__contextPiS1_S1_: // @_ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	stp	x28, x23, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	sub	sp, sp, #4, lsl #12             // =16384
	sub	sp, sp, #2144
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x20, x0
	mov	x22, x1
	str	x0, [sp, #8]
	add	x0, sp, #8
	mov	w1, #2
	mov	x19, x3
	mov	x21, x2
	bl	_ZL24stbi__decode_jpeg_headerP10stbi__jpegi
	cbnz	w0, .LBB58_2
// %bb.1:
	ldr	x8, [sp, #8]
	add	x0, sp, #8
	mov	w1, #2
	mov	w2, wzr
	str	x20, [sp, #8]
	ldr	x9, [x8, #200]
	str	x9, [x8, #184]
	bl	_ZL20stbi__parse_png_fileP9stbi__pngii
	cbz	w0, .LBB58_10
.LBB58_2:
	cbz	x22, .LBB58_4
// %bb.3:
	ldr	x8, [sp, #8]
	ldr	w8, [x8]
	str	w8, [x22]
.LBB58_4:
	cbz	x21, .LBB58_6
// %bb.5:
	ldr	x8, [sp, #8]
	ldr	w8, [x8, #4]
	str	w8, [x21]
.LBB58_6:
	cbz	x19, .LBB58_8
// %bb.7:
	ldr	x8, [sp, #8]
	ldr	w8, [x8, #8]
	str	w8, [x19]
.LBB58_8:
	mov	w0, #1
.LBB58_9:
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2144
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB58_10:
	ldr	x8, [sp, #8]
	add	x1, sp, #8
	mov	x0, x20
	mov	x2, x19
	mov	w3, #1
	ldr	x9, [x8, #200]
	str	x9, [x8, #184]
	bl	_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii
	cbz	w0, .LBB58_15
// %bb.11:
	cbz	x22, .LBB58_13
// %bb.12:
	ldr	w8, [sp, #8]
	str	w8, [x22]
.LBB58_13:
	cbz	x21, .LBB58_8
// %bb.14:
	ldr	w8, [sp, #12]
	str	w8, [x21]
	b	.LBB58_8
.LBB58_15:
	ldp	x8, x9, [x20, #192]
	cmp	x9, x8
	str	x9, [x20, #184]
	b.hs	.LBB58_17
// %bb.16:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w9, [x9]
	cmp	w9, #66
	b.eq	.LBB58_22
	b	.LBB58_90
.LBB58_17:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB58_90
// %bb.18:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_20
// %bb.19:
	mov	x8, x20
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_21
.LBB58_20:
	mov	w9, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_21:
	add	x10, x20, #57
	stp	x10, x8, [x20, #184]
	cmp	w9, #66
	b.ne	.LBB58_90
.LBB58_22:
	cmp	x10, x8
	b.hs	.LBB58_24
// %bb.23:
	add	x9, x10, #1
	str	x9, [x20, #184]
	ldrb	w10, [x10]
	b	.LBB58_29
.LBB58_24:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB58_90
// %bb.25:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_27
// %bb.26:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_28
.LBB58_27:
	mov	w10, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_28:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_29:
	cmp	w10, #77
	b.ne	.LBB58_90
// %bb.30:
	ldr	x10, [x20, #16]
	cbz	x10, .LBB58_33
// %bb.31:
	sub	w10, w8, w9
	cmp	w10, #11
	b.gt	.LBB58_33
// %bb.32:
	mov	w11, #12
	ldr	x9, [x20, #24]
	ldr	x0, [x20, #40]
	sub	w1, w11, w10
	str	x8, [x20, #184]
	blr	x9
	b	.LBB58_34
.LBB58_33:
	add	x8, x9, #12
	str	x8, [x20, #184]
.LBB58_34:
	mov	x0, x20
	bl	_ZL13stbi__get32leP13stbi__context
	cmp	w0, #55
	b.le	.LBB58_38
// %bb.35:
	cmp	w0, #56
	b.eq	.LBB58_40
// %bb.36:
	cmp	w0, #108
	b.eq	.LBB58_40
// %bb.37:
	cmp	w0, #124
	b.eq	.LBB58_40
	b	.LBB58_90
.LBB58_38:
	cmp	w0, #12
	b.eq	.LBB58_41
// %bb.39:
	cmp	w0, #40
	b.ne	.LBB58_90
.LBB58_40:
	mov	x0, x20
	bl	_ZL13stbi__get32leP13stbi__context
	str	w0, [x22]
	mov	x0, x20
	bl	_ZL13stbi__get32leP13stbi__context
	ldp	x9, x8, [x20, #184]
	mov	w23, w0
	b	.LBB58_72
.LBB58_41:
	ldp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB58_43
// %bb.42:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	b	.LBB58_49
.LBB58_43:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_46
// %bb.44:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_47
// %bb.45:
	mov	x8, x20
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_48
.LBB58_46:
	mov	w23, wzr
	b	.LBB58_49
.LBB58_47:
	mov	w23, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_48:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_49:
	cmp	x9, x8
	b.hs	.LBB58_51
// %bb.50:
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB58_56
.LBB58_51:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_56
// %bb.52:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_54
// %bb.53:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_55
.LBB58_54:
	mov	w10, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_55:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_56:
	bfi	w23, w10, #8, #8
	cmp	x9, x8
	str	w23, [x22]
	b.hs	.LBB58_58
// %bb.57:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	b	.LBB58_64
.LBB58_58:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_61
// %bb.59:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_62
// %bb.60:
	mov	x8, x20
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_63
.LBB58_61:
	mov	w23, wzr
	b	.LBB58_64
.LBB58_62:
	mov	w23, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_63:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_64:
	cmp	x9, x8
	b.hs	.LBB58_66
// %bb.65:
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB58_71
.LBB58_66:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_71
// %bb.67:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_69
// %bb.68:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_70
.LBB58_69:
	mov	w10, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_70:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_71:
	bfi	w23, w10, #8, #8
.LBB58_72:
	cmp	x9, x8
	str	w23, [x21]
	b.hs	.LBB58_74
// %bb.73:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	b	.LBB58_80
.LBB58_74:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_77
// %bb.75:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_78
// %bb.76:
	mov	x8, x20
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_79
.LBB58_77:
	mov	w23, wzr
	b	.LBB58_80
.LBB58_78:
	mov	w23, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_79:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_80:
	cmp	x9, x8
	b.hs	.LBB58_82
// %bb.81:
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB58_87
.LBB58_82:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_87
// %bb.83:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_85
// %bb.84:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_86
.LBB58_85:
	mov	w10, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_86:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_87:
	bfi	w23, w10, #8, #8
	cmp	w23, #1
	b.ne	.LBB58_90
// %bb.88:
	cmp	x9, x8
	b.hs	.LBB58_96
// %bb.89:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	b	.LBB58_102
.LBB58_90:
	ldr	x8, [x20, #200]
	mov	x0, x20
	mov	x1, x22
	mov	x2, x21
	mov	x3, x19
	str	x8, [x20, #184]
	bl	_ZL14stbi__psd_infoP13stbi__contextPiS1_S1_
	cbnz	w0, .LBB58_8
// %bb.91:
	mov	x0, x20
	mov	x1, x22
	mov	x2, x21
	mov	x3, x19
	bl	_ZL14stbi__pic_infoP13stbi__contextPiS1_S1_
	cbnz	w0, .LBB58_8
// %bb.92:
	mov	x0, x20
	mov	x1, x22
	mov	x2, x21
	mov	x3, x19
	bl	_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_
	cbnz	w0, .LBB58_8
// %bb.93:
	mov	x0, x20
	mov	x1, x22
	mov	x2, x21
	mov	x3, x19
	bl	_ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_
	cbnz	w0, .LBB58_8
// %bb.94:
	mov	x0, x20
	mov	x1, x22
	mov	x2, x21
	mov	x3, x19
	bl	_ZL14stbi__tga_infoP13stbi__contextPiS1_S1_
	cbnz	w0, .LBB58_8
// %bb.95:
	adrp	x9, .L.str.9
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.9
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB58_9
.LBB58_96:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB58_99
// %bb.97:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_100
// %bb.98:
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB58_101
.LBB58_99:
	mov	w21, wzr
	b	.LBB58_102
.LBB58_100:
	mov	w21, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_101:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB58_102:
	cmp	x9, x8
	b.hs	.LBB58_104
// %bb.103:
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	b	.LBB58_109
.LBB58_104:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB58_109
// %bb.105:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB58_107
// %bb.106:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB58_108
.LBB58_107:
	mov	w8, wzr
	add	x9, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB58_108:
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
.LBB58_109:
	bfi	w21, w8, #8, #8
	mov	w0, #1
	lsr	w8, w21, #3
	str	w8, [x19]
	b	.LBB58_9
.Lfunc_end58:
	.size	_ZL15stbi__info_mainP13stbi__contextPiS1_S1_, .Lfunc_end58-_ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	.cfi_endproc
                                        // -- End function
	.globl	stbi_info_from_memory           // -- Begin function stbi_info_from_memory
	.p2align	2
	.type	stbi_info_from_memory,@function
stbi_info_from_memory:                  // @stbi_info_from_memory
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #224
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	add	x8, x0, w1, sxtw
	str	x0, [sp, #184]
	mov	x1, x2
	mov	x2, x3
	mov	x3, x4
	str	xzr, [sp, #16]
	stp	x8, x0, [sp, #192]
	mov	x0, sp
	str	wzr, [sp, #48]
	bl	_ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #224
	ret
.Lfunc_end59:
	.size	stbi_info_from_memory, .Lfunc_end59-stbi_info_from_memory
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function stbi_info_from_callbacks
.LCPI60_0:
	.word	1                               // 0x1
	.word	128                             // 0x80
	.text
	.globl	stbi_info_from_callbacks
	.p2align	2
	.type	stbi_info_from_callbacks,@function
stbi_info_from_callbacks:               // @stbi_info_from_callbacks
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #272
	stp	x29, x30, [sp, #208]            // 16-byte Folded Spill
	add	x29, sp, #208
	stp	x28, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	q0, [x0]
	adrp	x8, .LCPI60_0
	ldr	x9, [x0, #16]
	mov	x23, sp
	add	x22, x23, #56
	mov	x21, x2
	str	q0, [sp, #16]
	ldr	d0, [x8, :lo12:.LCPI60_0]
	stp	x9, x1, [sp, #32]
	ldr	x8, [sp, #16]
	mov	x0, x1
	mov	x1, x22
	mov	w2, #128
	mov	x19, x4
	mov	x20, x3
	str	d0, [sp, #48]
	str	x22, [sp, #200]
	blr	x8
	cbz	w0, .LBB60_2
// %bb.1:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB60_3
.LBB60_2:
	add	x8, x23, #57
	str	wzr, [sp, #48]
	strb	wzr, [sp, #56]
.LBB60_3:
	mov	x0, sp
	mov	x1, x21
	mov	x2, x20
	mov	x3, x19
	stp	x22, x8, [sp, #184]
	bl	_ZL15stbi__info_mainP13stbi__contextPiS1_S1_
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x28, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #272
	ret
.Lfunc_end60:
	.size	stbi_info_from_callbacks, .Lfunc_end60-stbi_info_from_callbacks
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK15constant_medium3hitERK3rayddR10hit_record
.LCPI61_0:
	.xword	0x3f1a36e2eb1c432d              // double 1.0E-4
	.text
	.globl	_ZNK15constant_medium3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK15constant_medium3hitERK3rayddR10hit_record,@function
_ZNK15constant_medium3hitERK3rayddR10hit_record: // @_ZNK15constant_medium3hitERK3rayddR10hit_record
.Lfunc_begin7:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception7
// %bb.0:
	sub	sp, sp, #272
	str	d10, [sp, #192]                 // 8-byte Folded Spill
	stp	d9, d8, [sp, #200]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #216]            // 16-byte Folded Spill
	add	x29, sp, #216
	str	x28, [sp, #232]                 // 8-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w28, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	fmov	d9, d0
	mov	x20, x0
	movi	v0.2d, #0000000000000000
	ldr	x0, [x0, #8]
	fmov	d8, d1
	mov	x19, x2
	mov	x21, x1
	stp	q0, q0, [sp, #128]
	stp	q0, q0, [sp, #96]
	stp	q0, q0, [sp, #32]
	stp	q0, q0, [sp]
	ldr	x8, [x0]
	ldr	x8, [x8]
.Ltmp118:
	mov	x9, #-4503599627370496
	mov	x10, #9218868437227405312
	add	x2, sp, #96
	fmov	d0, x9
	fmov	d1, x10
	blr	x8
.Ltmp119:
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	tbz	w0, #0, .LBB61_17
// %bb.2:
	adrp	x8, .LCPI61_0
	ldr	x0, [x20, #8]
	ldr	d0, [sp, #160]
	ldr	d1, [x8, :lo12:.LCPI61_0]
	ldr	x8, [x0]
	fadd	d0, d0, d1
	ldr	x8, [x8]
.Ltmp120:
	mov	x9, #9218868437227405312
	mov	x2, sp
	mov	x1, x21
	fmov	d1, x9
	blr	x8
.Ltmp121:
// %bb.3:
	tbz	w0, #0, .LBB61_17
// %bb.4:
	ldr	d0, [sp, #160]
	fcmp	d0, d9
	b.pl	.LBB61_15
// %bb.5:
	fmov	d0, d9
	str	d9, [sp, #160]
	ldr	d1, [sp, #64]
	fcmp	d1, d8
	b.gt	.LBB61_16
.LBB61_6:
	fcmp	d0, d1
	b.ge	.LBB61_17
.LBB61_7:
	fcmp	d0, #0.0
	b.pl	.LBB61_9
// %bb.8:
	str	xzr, [sp, #160]
.LBB61_9:
	ldp	d1, d0, [x21, #24]
	fmul	d0, d0, d0
	fmadd	d0, d1, d1, d0
	ldr	d1, [x21, #40]
	fmadd	d0, d1, d1, d0
	fsqrt	d8, d0
	fcmp	d8, d8
	b.vs	.LBB61_47
.LBB61_10:
	ldr	d0, [sp, #64]
	ldr	d1, [sp, #160]
	ldr	d10, [x20, #40]
	fsub	d0, d0, d1
	fmul	d9, d8, d0
	bl	rand
	mov	x8, #4467570830351532032
	scvtf	d0, w0
	fmov	d1, x8
	fmul	d0, d0, d1
	bl	log
	fmul	d10, d10, d0
	fcmp	d10, d9
	b.gt	.LBB61_37
// %bb.11:
	fdiv	d0, d10, d8
	ldr	d1, [sp, #160]
	mov	x8, #4607182418800017408
	mov	w9, #1
	fadd	d0, d0, d1
	str	d0, [x19, #64]
	ldur	q1, [x21, #24]
	ldr	d2, [x21, #40]
	ldr	q3, [x21]
	fmul	v1.2d, v1.2d, v0.d[0]
	fmul	d0, d0, d2
	ldr	d2, [x21, #16]
	stp	xzr, xzr, [x19, #32]
	str	x8, [x19, #24]
	fadd	v1.2d, v1.2d, v3.2d
	strb	w9, [x19, #88]
	fadd	d0, d0, d2
	str	q1, [x19]
	str	d0, [x19, #16]
	ldr	x8, [x20, #24]
	str	x8, [x19, #48]
	ldr	x21, [x20, #32]
	ldr	x20, [x19, #56]
	cmp	x21, x20
	b.eq	.LBB61_37
// %bb.12:
	cbz	x21, .LBB61_26
// %bb.13:
	ldrb	w8, [x22]
	cbz	w8, .LBB61_25
// %bb.14:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	b	.LBB61_26
.LBB61_15:
	ldr	d1, [sp, #64]
	fcmp	d1, d8
	b.le	.LBB61_6
.LBB61_16:
	fmov	d1, d8
	str	d8, [sp, #64]
	fcmp	d0, d1
	b.lt	.LBB61_7
.LBB61_17:
	mov	w19, wzr
	ldr	x20, [sp, #56]
	cbz	x20, .LBB61_38
.LBB61_18:
	ldrb	w8, [x22]
	cbz	w8, .LBB61_20
// %bb.19:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB61_21
	b	.LBB61_38
.LBB61_20:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB61_38
.LBB61_21:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB61_23
// %bb.22:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB61_38
	b	.LBB61_24
.LBB61_23:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB61_38
.LBB61_24:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB61_38
.LBB61_25:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x20, [x19, #56]
.LBB61_26:
	cbz	x20, .LBB61_36
// %bb.27:
	ldrb	w8, [x22]
	cbz	w8, .LBB61_29
// %bb.28:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	b	.LBB61_30
.LBB61_29:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB61_30:
	cmp	w0, #1
	b.ne	.LBB61_36
// %bb.31:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB61_33
// %bb.32:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	b	.LBB61_34
.LBB61_33:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
.LBB61_34:
	cmp	w0, #1
	b.ne	.LBB61_36
// %bb.35:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB61_36:
	str	x21, [x19, #56]
.LBB61_37:
	fcmp	d10, d9
	cset	w19, le
	ldr	x20, [sp, #56]
	cbnz	x20, .LBB61_18
.LBB61_38:
	ldr	x20, [sp, #152]
	cbz	x20, .LBB61_45
// %bb.39:
	ldrb	w8, [x22]
	cbz	w8, .LBB61_41
// %bb.40:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB61_42
	b	.LBB61_45
.LBB61_41:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB61_45
.LBB61_42:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB61_46
// %bb.43:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB61_45
.LBB61_44:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB61_45:
	mov	w0, w19
	ldr	x28, [sp, #232]                 // 8-byte Folded Reload
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #216]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #200]              // 16-byte Folded Reload
	ldr	d10, [sp, #192]                 // 8-byte Folded Reload
	add	sp, sp, #272
	ret
.LBB61_46:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB61_44
	b	.LBB61_45
.LBB61_47:
	bl	sqrt
	fmov	d8, d0
	b	.LBB61_10
.LBB61_48:
.Ltmp122:
	mov	x19, x0
	mov	x0, sp
	bl	_ZN10hit_recordD2Ev
	add	x0, sp, #96
	bl	_ZN10hit_recordD2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end61:
	.size	_ZNK15constant_medium3hitERK3rayddR10hit_record, .Lfunc_end61-_ZNK15constant_medium3hitERK3rayddR10hit_record
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table61:
.Lexception7:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end7-.Lcst_begin7
.Lcst_begin7:
	.uleb128 .Ltmp118-.Lfunc_begin7         // >> Call Site 1 <<
	.uleb128 .Ltmp121-.Ltmp118              //   Call between .Ltmp118 and .Ltmp121
	.uleb128 .Ltmp122-.Lfunc_begin7         //     jumps to .Ltmp122
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp121-.Lfunc_begin7         // >> Call Site 2 <<
	.uleb128 .Lfunc_end61-.Ltmp121          //   Call between .Ltmp121 and .Lfunc_end61
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end7:
	.p2align	2
                                        // -- End function
	.text
	.globl	_ZNK13moving_sphere6centerEd    // -- Begin function _ZNK13moving_sphere6centerEd
	.p2align	2
	.type	_ZNK13moving_sphere6centerEd,@function
_ZNK13moving_sphere6centerEd:           // @_ZNK13moving_sphere6centerEd
	.cfi_startproc
// %bb.0:
	ldp	d1, d2, [x0, #56]
	ldp	d3, d4, [x0, #40]
	fsub	d0, d0, d1
	fsub	d1, d2, d1
	ldp	d6, d5, [x0, #24]
	fdiv	d0, d0, d1
	ldp	d1, d2, [x0, #8]
	fsub	d4, d4, d6
	fsub	d5, d5, d1
	fsub	d3, d3, d2
	fmul	d5, d0, d5
	fmul	d3, d0, d3
	fmul	d4, d0, d4
	fadd	d0, d1, d5
	fadd	d1, d2, d3
	fadd	d2, d6, d4
	ret
.Lfunc_end62:
	.size	_ZNK13moving_sphere6centerEd, .Lfunc_end62-_ZNK13moving_sphere6centerEd
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK13moving_sphere12bounding_boxEddR4aabb // -- Begin function _ZNK13moving_sphere12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK13moving_sphere12bounding_boxEddR4aabb,@function
_ZNK13moving_sphere12bounding_boxEddR4aabb: // @_ZNK13moving_sphere12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	mov	w0, #1
	ldp	d2, d3, [x8, #56]
	ldp	d4, d5, [x8, #40]
	fsub	d0, d0, d2
	fsub	d1, d1, d2
	fsub	d3, d3, d2
	ldr	d18, [x8, #72]
	ldp	d7, d6, [x8, #24]
	fdiv	d0, d0, d3
	fsub	d5, d5, d7
	fdiv	d1, d1, d3
	ldp	d2, d3, [x8, #8]
	fsub	d6, d6, d2
	fsub	d4, d4, d3
	fmul	d16, d0, d6
	fmul	d17, d0, d4
	fmul	d0, d0, d5
	fadd	d0, d7, d0
	fmul	d6, d1, d6
	fmul	d4, d1, d4
	fmul	d1, d1, d5
	fadd	d5, d2, d16
	fadd	d16, d3, d17
	fadd	d2, d2, d6
	fadd	d3, d3, d4
	fadd	d1, d7, d1
	fsub	d4, d5, d18
	fsub	d6, d16, d18
	fsub	d7, d0, d18
	fadd	d5, d5, d18
	fadd	d16, d16, d18
	fsub	d17, d2, d18
	fsub	d19, d3, d18
	fsub	d20, d1, d18
	fadd	d0, d18, d0
	fadd	d2, d2, d18
	fadd	d3, d3, d18
	fadd	d1, d18, d1
	fminnm	d4, d4, d17
	fminnm	d6, d6, d19
	fminnm	d7, d7, d20
	fmaxnm	d2, d5, d2
	fmaxnm	d3, d16, d3
	fmaxnm	d0, d0, d1
	stp	d4, d6, [x1]
	stp	d7, d2, [x1, #16]
	stp	d3, d0, [x1, #32]
	ret
.Lfunc_end63:
	.size	_ZNK13moving_sphere12bounding_boxEddR4aabb, .Lfunc_end63-_ZNK13moving_sphere12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK13moving_sphere3hitERK3rayddR10hit_record // -- Begin function _ZNK13moving_sphere3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK13moving_sphere3hitERK3rayddR10hit_record,@function
_ZNK13moving_sphere3hitERK3rayddR10hit_record: // @_ZNK13moving_sphere3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	d3, d4, [x0, #56]
	ldr	d2, [x1, #48]
	ldp	d16, d7, [x0, #24]
	fsub	d2, d2, d3
	fsub	d3, d4, d3
	ldp	d4, d6, [x0, #40]
	fdiv	d2, d2, d3
	ldp	d5, d3, [x0, #8]
	fsub	d6, d6, d16
	fsub	d7, d7, d5
	fsub	d4, d4, d3
	fmul	d4, d2, d4
	fmul	d7, d2, d7
	fmul	d2, d2, d6
	fadd	d3, d3, d4
	fadd	d5, d5, d7
	ldp	d6, d4, [x1]
	fadd	d2, d16, d2
	fsub	d3, d4, d3
	fsub	d4, d6, d5
	ldp	d5, d16, [x1, #16]
	fmul	d6, d3, d3
	fsub	d2, d5, d2
	ldp	d7, d5, [x1, #32]
	fmadd	d18, d4, d4, d6
	fmul	d17, d7, d7
	fmul	d3, d3, d7
	fmadd	d7, d2, d2, d18
	fmadd	d6, d16, d16, d17
	ldr	d17, [x0, #72]
	fmadd	d3, d4, d16, d3
	fmsub	d7, d17, d17, d7
	fnmadd	d16, d5, d5, d6
	fmadd	d4, d2, d5, d3
	fmul	d2, d7, d16
	fmadd	d3, d4, d4, d2
	fcmp	d3, #0.0
	b.pl	.LBB64_2
// %bb.1:
	mov	w0, wzr
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB64_2:
	fsqrt	d2, d3
	fmadd	d5, d5, d5, d6
	mov	x19, x2
	fcmp	d2, d2
	b.vs	.LBB64_6
// %bb.3:
	fneg	d3, d4
	fsub	d3, d3, d2
	fdiv	d3, d3, d5
	fcmp	d3, d0
	fccmp	d3, d1, #0, pl
	b.le	.LBB64_7
.LBB64_4:
	fsub	d2, d2, d4
	fdiv	d3, d2, d5
	fcmp	d3, d0
	fccmp	d3, d1, #0, pl
	b.le	.LBB64_7
// %bb.5:
	mov	w0, wzr
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB64_6:
	stur	d0, [x29, #-8]                  // 8-byte Folded Spill
	fmov	d0, d3
	mov	x20, x0
	mov	x21, x1
	stp	d5, d1, [sp, #8]                // 16-byte Folded Spill
	str	d4, [sp]                        // 8-byte Folded Spill
	bl	sqrt
	ldp	d4, d5, [sp]                    // 16-byte Folded Reload
	fmov	d2, d0
	mov	x1, x21
	ldr	d1, [sp, #16]                   // 8-byte Folded Reload
	mov	x0, x20
	ldur	d0, [x29, #-8]                  // 8-byte Folded Reload
	fneg	d3, d4
	fsub	d3, d3, d2
	fdiv	d3, d3, d5
	fcmp	d3, d0
	fccmp	d3, d1, #0, pl
	b.gt	.LBB64_4
.LBB64_7:
	str	d3, [x19, #64]
	ldr	x20, [x19, #56]
	ldur	q0, [x1, #24]
	ldr	d1, [x1, #40]
	ldr	q2, [x1]
	fmul	v0.2d, v0.2d, v3.d[0]
	fmul	d1, d3, d1
	ldr	d3, [x1, #16]
	fadd	v0.2d, v0.2d, v2.2d
	fadd	d1, d1, d3
	str	q0, [x19]
	str	d1, [x19, #16]
	ldp	d7, d2, [x1, #40]
	ldp	d4, d3, [x0, #48]
	ldp	d5, d6, [x0, #64]
	ldr	d16, [x0, #24]
	fsub	d2, d2, d3
	fsub	d3, d5, d3
	ldr	q5, [x0, #32]
	fsub	d4, d4, d16
	fdiv	d2, d2, d3
	fmov	d3, #1.00000000
	fdiv	d3, d3, d6
	ldur	q6, [x0, #8]
	fsub	v5.2d, v5.2d, v6.2d
	fmul	v5.2d, v5.2d, v2.d[0]
	fmul	d2, d2, d4
	ldr	d4, [x1, #32]
	fadd	v5.2d, v6.2d, v5.2d
	fadd	d2, d16, d2
	fsub	v0.2d, v0.2d, v5.2d
	fsub	d1, d1, d2
	fmul	v0.2d, v0.2d, v3.d[0]
	fmul	d5, d1, d3
	fnmul	d1, d1, d3
	fmul	d2, d4, v0.d[1]
	ldr	d4, [x1, #24]
	fneg	v3.2d, v0.2d
	fmla	d2, d4, v0.d[0]
	fmadd	d2, d7, d5, d2
	fcmp	d2, #0.0
	cset	w8, mi
	fcsel	d1, d5, d1, mi
	dup	v2.2s, w8
	strb	w8, [x19, #88]
	str	d1, [x19, #40]
	ushll	v2.2d, v2.2s, #0
	shl	v2.2d, v2.2d, #63
	cmlt	v2.2d, v2.2d, #0
	bif	v0.16b, v3.16b, v2.16b
	stur	q0, [x19, #24]
	ldp	x9, x21, [x0, #80]
	str	x9, [x19, #48]
	cmp	x21, x20
	b.eq	.LBB64_14
// %bb.8:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	cbz	x21, .LBB64_11
// %bb.9:
	ldrb	w8, [x22]
	cbz	w8, .LBB64_15
// %bb.10:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
.LBB64_11:
	cbz	x20, .LBB64_20
.LBB64_12:
	ldrb	w8, [x22]
	cbz	w8, .LBB64_16
// %bb.13:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB64_17
	b	.LBB64_20
.LBB64_14:
	mov	w0, #1
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB64_15:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x20, [x19, #56]
	cbnz	x20, .LBB64_12
	b	.LBB64_20
.LBB64_16:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB64_20
.LBB64_17:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB64_21
// %bb.18:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB64_20
.LBB64_19:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB64_20:
	mov	w0, #1
	str	x21, [x19, #56]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB64_21:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB64_19
	b	.LBB64_20
.Lfunc_end64:
	.size	_ZNK13moving_sphere3hitERK3rayddR10hit_record, .Lfunc_end64-_ZNK13moving_sphere3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.globl	_ZNK6sphere12bounding_boxEddR4aabb // -- Begin function _ZNK6sphere12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK6sphere12bounding_boxEddR4aabb,@function
_ZNK6sphere12bounding_boxEddR4aabb:     // @_ZNK6sphere12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	mov	w0, #1
	ldp	d3, d0, [x8, #24]
	ldp	d1, d2, [x8, #8]
	fsub	d6, d3, d0
	fsub	d4, d1, d0
	fadd	d1, d0, d1
	fsub	d5, d2, d0
	fadd	d2, d0, d2
	fadd	d0, d0, d3
	stp	d6, d1, [x1, #16]
	stp	d4, d5, [x1]
	stp	d2, d0, [x1, #32]
	ret
.Lfunc_end65:
	.size	_ZNK6sphere12bounding_boxEddR4aabb, .Lfunc_end65-_ZNK6sphere12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK6sphere3hitERK3rayddR10hit_record
.LCPI66_0:
	.xword	0x400921fb54442d18              // double 3.1415926535897931
.LCPI66_1:
	.xword	0x401921fb54442d18              // double 6.2831853071795862
	.text
	.globl	_ZNK6sphere3hitERK3rayddR10hit_record
	.p2align	2
	.type	_ZNK6sphere3hitERK3rayddR10hit_record,@function
_ZNK6sphere3hitERK3rayddR10hit_record:  // @_ZNK6sphere3hitERK3rayddR10hit_record
	.cfi_startproc
// %bb.0:
	str	d10, [sp, #-80]!                // 8-byte Folded Spill
	stp	d9, d8, [sp, #16]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	.cfi_offset b10, -80
	ldp	d4, d2, [x1]
	ldp	d5, d3, [x0, #8]
	fsub	d6, d4, d5
	fsub	d2, d2, d3
	ldp	d3, d7, [x1, #16]
	ldp	d4, d17, [x0, #24]
	fmul	d5, d2, d2
	fsub	d3, d3, d4
	ldp	d16, d4, [x1, #32]
	fmadd	d19, d6, d6, d5
	fmul	d18, d16, d16
	fmul	d2, d2, d16
	fmadd	d16, d3, d3, d19
	fmadd	d5, d7, d7, d18
	fmadd	d2, d6, d7, d2
	fmsub	d6, d17, d17, d16
	fnmadd	d7, d4, d4, d5
	fmadd	d8, d3, d4, d2
	fmul	d2, d6, d7
	fmadd	d3, d8, d8, d2
	fcmp	d3, #0.0
	b.mi	.LBB66_4
// %bb.1:
	fsqrt	d2, d3
	fmadd	d9, d4, d4, d5
	mov	x19, x2
	mov	x20, x0
	fcmp	d2, d2
	b.vs	.LBB66_5
// %bb.2:
	fneg	d3, d8
	fsub	d3, d3, d2
	fdiv	d3, d3, d9
	fcmp	d3, d0
	fccmp	d3, d1, #0, pl
	b.le	.LBB66_6
.LBB66_3:
	fsub	d2, d2, d8
	fdiv	d3, d2, d9
	fcmp	d3, d0
	fccmp	d3, d1, #0, pl
	b.le	.LBB66_6
.LBB66_4:
	mov	w0, wzr
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #16]               // 16-byte Folded Reload
	ldr	d10, [sp], #80                  // 8-byte Folded Reload
	ret
.LBB66_5:
	str	d0, [sp, #8]                    // 8-byte Folded Spill
	fmov	d0, d3
	mov	x21, x1
	fmov	d10, d1
	bl	sqrt
	fmov	d1, d10
	fmov	d2, d0
	mov	x1, x21
	ldr	d0, [sp, #8]                    // 8-byte Folded Reload
	fneg	d3, d8
	fsub	d3, d3, d2
	fdiv	d3, d3, d9
	fcmp	d3, d0
	fccmp	d3, d1, #0, pl
	b.gt	.LBB66_3
.LBB66_6:
	str	d3, [x19, #64]
	ldur	q0, [x1, #24]
	ldr	d1, [x1, #40]
	ldr	q2, [x1]
	fmul	v0.2d, v0.2d, v3.d[0]
	fmul	d1, d3, d1
	ldr	d3, [x1, #16]
	fadd	v0.2d, v0.2d, v2.2d
	fmov	d2, #1.00000000
	fadd	d1, d1, d3
	str	q0, [x19]
	str	d1, [x19, #16]
	ldp	d5, d3, [x20, #24]
	ldr	d4, [x20, #16]
	ldr	d6, [x1, #32]
	fsub	d1, d1, d5
	fdiv	d2, d2, d3
	mov	d3, v0.d[1]
	fsub	d3, d3, d4
	ldr	d4, [x20, #8]
	fsub	d0, d0, d4
	fmul	d4, d3, d2
	fmul	d8, d0, d2
	fmul	d7, d1, d2
	fnmul	d9, d1, d2
	fmul	d5, d6, d4
	ldr	d6, [x1, #24]
	fmadd	d5, d6, d8, d5
	ldr	d6, [x1, #40]
	fmadd	d5, d6, d7, d5
	fnmul	d6, d0, d2
	fnmul	d0, d3, d2
	fcmp	d5, #0.0
	fcsel	d1, d8, d6, mi
	fcsel	d2, d4, d0, mi
	fcsel	d3, d7, d9, mi
	cset	w8, mi
	strb	w8, [x19, #88]
	stp	d1, d2, [x19, #24]
	str	d3, [x19, #40]
	bl	acos
	fmov	d10, d0
	fmov	d0, d9
	fmov	d1, d8
	bl	atan2
	adrp	x8, .LCPI66_0
	ldr	x21, [x19, #56]
	ldr	d1, [x8, :lo12:.LCPI66_0]
	adrp	x8, .LCPI66_1
	fadd	d0, d0, d1
	ldr	d2, [x8, :lo12:.LCPI66_1]
	fdiv	d1, d10, d1
	ldp	x8, x22, [x20, #40]
	str	x8, [x19, #48]
	cmp	x22, x21
	fdiv	d0, d0, d2
	stp	d0, d1, [x19, #72]
	b.eq	.LBB66_13
// %bb.7:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	cbz	x22, .LBB66_10
// %bb.8:
	ldrb	w8, [x20]
	cbz	w8, .LBB66_14
// %bb.9:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
.LBB66_10:
	cbz	x21, .LBB66_19
.LBB66_11:
	ldrb	w8, [x20]
	cbz	w8, .LBB66_15
// %bb.12:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB66_16
	b	.LBB66_19
.LBB66_13:
	mov	w0, #1
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #16]               // 16-byte Folded Reload
	ldr	d10, [sp], #80                  // 8-byte Folded Reload
	ret
.LBB66_14:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x21, [x19, #56]
	cbnz	x21, .LBB66_11
	b	.LBB66_19
.LBB66_15:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB66_19
.LBB66_16:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB66_20
// %bb.17:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB66_19
.LBB66_18:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB66_19:
	mov	w0, #1
	str	x22, [x19, #56]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #16]               // 16-byte Folded Reload
	ldr	d10, [sp], #80                  // 8-byte Folded Reload
	ret
.LBB66_20:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB66_18
	b	.LBB66_19
.Lfunc_end66:
	.size	_ZNK6sphere3hitERK3rayddR10hit_record, .Lfunc_end66-_ZNK6sphere3hitERK3rayddR10hit_record
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _Z9ray_colorRK3rayRK4vec3RK8hittablei
.LCPI67_0:
	.xword	0x3f50624dd2f1a9fc              // double 0.001
	.text
	.globl	_Z9ray_colorRK3rayRK4vec3RK8hittablei
	.p2align	2
	.type	_Z9ray_colorRK3rayRK4vec3RK8hittablei,@function
_Z9ray_colorRK3rayRK4vec3RK8hittablei:  // @_Z9ray_colorRK3rayRK4vec3RK8hittablei
.Lfunc_begin8:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception8
// %bb.0:
	sub	sp, sp, #272
	str	d10, [sp, #192]                 // 8-byte Folded Spill
	stp	d9, d8, [sp, #200]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #216]            // 16-byte Folded Spill
	add	x29, sp, #216
	str	x28, [sp, #232]                 // 8-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w28, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	movi	v0.2d, #0000000000000000
	subs	w21, w3, #1
	stp	q0, q0, [sp, #128]
	stp	q0, q0, [sp, #96]
	b.lt	.LBB67_8
// %bb.1:
	ldr	x8, [x2]
	mov	x20, x2
	mov	x19, x1
	mov	x22, x0
	ldr	x8, [x8]
.Ltmp123:
	adrp	x9, .LCPI67_0
	mov	x10, #9218868437227405312
	add	x2, sp, #96
	mov	x0, x20
	mov	x1, x22
	ldr	d0, [x9, :lo12:.LCPI67_0]
	fmov	d1, x10
	blr	x8
.Ltmp124:
// %bb.2:
	tbz	w0, #0, .LBB67_10
// %bb.3:
	movi	v0.2d, #0000000000000000
	ldr	x0, [sp, #144]
	stp	xzr, xzr, [sp, #8]
	str	xzr, [sp, #24]
	stp	q0, q0, [sp, #48]
	str	q0, [sp, #32]
	ldr	x8, [x0]
	ldp	d0, d1, [sp, #168]
	ldr	x8, [x8]
.Ltmp126:
	add	x1, sp, #96
	blr	x8
.Ltmp127:
// %bb.4:
	ldr	x0, [sp, #144]
	fmov	d8, d0
	fmov	d9, d1
	fmov	d10, d2
	ldr	x8, [x0]
	ldr	x8, [x8, #8]
.Ltmp128:
	add	x2, sp, #96
	add	x3, sp, #8
	add	x4, sp, #32
	mov	x1, x22
	blr	x8
.Ltmp129:
// %bb.5:
	tbz	w0, #0, .LBB67_9
// %bb.6:
.Ltmp131:
	add	x0, sp, #32
	mov	x1, x19
	mov	x2, x20
	mov	w3, w21
	bl	_Z9ray_colorRK3rayRK4vec3RK8hittablei
.Ltmp132:
// %bb.7:
	ldp	d3, d4, [sp, #8]
	ldr	d5, [sp, #24]
	fmul	d0, d0, d3
	fmul	d1, d1, d4
	fmul	d2, d2, d5
	fadd	d8, d8, d0
	fadd	d9, d9, d1
	fadd	d10, d10, d2
	ldr	x19, [sp, #152]
	cbnz	x19, .LBB67_11
	b	.LBB67_17
.LBB67_8:
	movi	d8, #0000000000000000
	movi	d9, #0000000000000000
	movi	d10, #0000000000000000
.LBB67_9:
	ldr	x19, [sp, #152]
	cbnz	x19, .LBB67_11
	b	.LBB67_17
.LBB67_10:
	ldp	d8, d9, [x19]
	ldr	d10, [x19, #16]
	ldr	x19, [sp, #152]
	cbz	x19, .LBB67_17
.LBB67_11:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB67_13
// %bb.12:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB67_14
	b	.LBB67_17
.LBB67_13:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB67_17
.LBB67_14:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB67_18
// %bb.15:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB67_17
.LBB67_16:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB67_17:
	fmov	d0, d8
	fmov	d1, d9
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	fmov	d2, d10
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #216]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #200]              // 16-byte Folded Reload
	ldr	x28, [sp, #232]                 // 8-byte Folded Reload
	ldr	d10, [sp, #192]                 // 8-byte Folded Reload
	add	sp, sp, #272
	ret
.LBB67_18:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB67_16
	b	.LBB67_17
.LBB67_19:
.Ltmp133:
	b	.LBB67_22
.LBB67_20:
.Ltmp130:
	b	.LBB67_22
.LBB67_21:
.Ltmp125:
.LBB67_22:
	mov	x19, x0
	add	x0, sp, #96
	bl	_ZN10hit_recordD2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end67:
	.size	_Z9ray_colorRK3rayRK4vec3RK8hittablei, .Lfunc_end67-_Z9ray_colorRK3rayRK4vec3RK8hittablei
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table67:
.Lexception8:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end8-.Lcst_begin8
.Lcst_begin8:
	.uleb128 .Ltmp123-.Lfunc_begin8         // >> Call Site 1 <<
	.uleb128 .Ltmp124-.Ltmp123              //   Call between .Ltmp123 and .Ltmp124
	.uleb128 .Ltmp125-.Lfunc_begin8         //     jumps to .Ltmp125
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp126-.Lfunc_begin8         // >> Call Site 2 <<
	.uleb128 .Ltmp129-.Ltmp126              //   Call between .Ltmp126 and .Ltmp129
	.uleb128 .Ltmp130-.Lfunc_begin8         //     jumps to .Ltmp130
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp131-.Lfunc_begin8         // >> Call Site 3 <<
	.uleb128 .Ltmp132-.Ltmp131              //   Call between .Ltmp131 and .Ltmp132
	.uleb128 .Ltmp133-.Lfunc_begin8         //     jumps to .Ltmp133
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp132-.Lfunc_begin8         // >> Call Site 4 <<
	.uleb128 .Lfunc_end67-.Ltmp132          //   Call between .Ltmp132 and .Lfunc_end67
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end8:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z12random_scenev
.LCPI68_0:
	.xword	0x3fc999999999999a              // double 0.20000000000000001
	.xword	0x3fd3333333333333              // double 0.29999999999999999
.LCPI68_1:
	.xword	0x0000000000000000              // double 0
	.xword	0xc08f400000000000              // double -1000
.LCPI68_2:
	.xword	0x0000000000000000              // double 0
	.xword	0x408f400000000000              // double 1000
.LCPI68_5:
	.xword	0x0000000000000000              // double 0
	.xword	0x3ff0000000000000              // double 1
.LCPI68_6:
	.xword	0x3fd999999999999a              // double 0.40000000000000002
	.xword	0x3fc999999999999a              // double 0.20000000000000001
.LCPI68_7:
	.xword	0xc010000000000000              // double -4
	.xword	0x3ff0000000000000              // double 1
.LCPI68_8:
	.xword	0x3fe6666666666666              // double 0.69999999999999996
	.xword	0x3fe3333333333333              // double 0.59999999999999998
.LCPI68_9:
	.xword	0x3fe0000000000000              // double 0.5
	.xword	0x0000000000000000              // double 0
.LCPI68_10:
	.xword	0x4010000000000000              // double 4
	.xword	0x3ff0000000000000              // double 1
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3
.LCPI68_3:
	.xword	0x3feccccccccccccd              // double 0.90000000000000002
.LCPI68_4:
	.xword	0x3fe999999999999a              // double 0.80000000000000004
	.text
	.globl	_Z12random_scenev
	.p2align	2
	.type	_Z12random_scenev,@function
_Z12random_scenev:                      // @_Z12random_scenev
.Lfunc_begin9:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception9
// %bb.0:
	stp	d15, d14, [sp, #-160]!          // 16-byte Folded Spill
	stp	d13, d12, [sp, #16]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x28, x27, [sp, #80]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            // 16-byte Folded Spill
	sub	sp, sp, #368
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	mov	x19, x8
	adrp	x8, .LCPI68_0
	mov	x9, #-7378697629483820647
	sub	x11, x29, #192
	movk	x9, #39322
	adrp	x10, _ZTV13hittable_list+16
	ldr	q0, [x8, :lo12:.LCPI68_0]
	mov	x8, #-3689348814741910324
	movk	x8, #52429
	movk	x9, #16313, lsl #48
	movk	x8, #16364, lsl #48
	add	x10, x10, :lo12:_ZTV13hittable_list+16
	str	q0, [x11, #32]
	stur	x9, [x29, #-144]
	dup	v0.2d, x8
	stp	x10, xzr, [x29, #-120]
	stp	xzr, xzr, [x29, #-104]
	str	q0, [x11]
	stur	x8, [x29, #-176]
.Ltmp134:
	mov	w0, #56
	bl	_Znwm
.Ltmp135:
// %bb.1:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x20, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp137:
	add	x0, sp, #208
	sub	x2, x29, #160
	sub	x3, x29, #192
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_
.Ltmp138:
// %bb.2:
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	stp	x22, x20, [x29, #-136]
	stur	xzr, [x29, #-192]
.Ltmp140:
	mov	w0, #40
	bl	_Znwm
.Ltmp141:
// %bb.3:
	adrp	x26, :got:__libc_single_threaded
	movi	v0.2s, #1
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x24, _ZTV10lambertian+16
	mov	x21, x0
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x26, [x26, :got_lo12:__libc_single_threaded]
	add	x19, x0, #16
	add	x24, x24, :lo12:_ZTV10lambertian+16
	str	d0, [x0, #8]
	str	x9, [x0]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_5
// %bb.4:
	ldr	w8, [x20, #8]
	stp	x24, x22, [x21, #16]
	str	x20, [x21, #32]
	add	w8, w8, #1
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB68_10
	b	.LBB68_13
.LBB68_5:
	add	x23, x20, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	stp	x24, x22, [x21, #16]
	str	x20, [x21, #32]
	cbz	w8, .LBB68_7
// %bb.6:
	ldr	w8, [x20, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB68_10
	b	.LBB68_13
.LBB68_7:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_9
// %bb.8:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB68_10
	b	.LBB68_13
.LBB68_9:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_13
.LBB68_10:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_18
// %bb.11:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB68_13
.LBB68_12:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_13:
	stp	x19, x21, [x29, #-192]
	stur	xzr, [x29, #-160]
.Ltmp143:
	mov	w0, #72
	bl	_Znwm
.Ltmp144:
// %bb.14:
	movi	v0.2s, #1
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x8, .LCPI68_1
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x20, x0
	mov	x22, x0
	sub	x24, x29, #120
	stp	xzr, xzr, [x29, #-192]
	str	d0, [x0, #8]
	ldr	q0, [x8, :lo12:.LCPI68_1]
	adrp	x8, _ZTV6sphere+16
	str	x9, [x0]
	adrp	x9, .LCPI68_2
	add	x8, x8, :lo12:_ZTV6sphere+16
	stur	q0, [x0, #24]
	stp	x19, x21, [x0, #56]
	str	x8, [x20, #16]!
	ldr	q0, [x9, :lo12:.LCPI68_2]
	ldrb	w8, [x26]
	stur	q0, [x0, #40]
	cbz	w8, .LBB68_16
// %bb.15:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	add	x8, x24, #8
	cmp	w0, #1
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	b.ne	.LBB68_23
	b	.LBB68_20
.LBB68_16:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_19
// %bb.17:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	add	x8, x24, #8
	cmp	w0, #1
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	b.ne	.LBB68_23
	b	.LBB68_20
.LBB68_18:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_12
	b	.LBB68_13
.LBB68_19:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	add	x8, x24, #8
	cmp	w0, #1
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	b.ne	.LBB68_23
.LBB68_20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_188
// %bb.21:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_23
.LBB68_22:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_23:
	ldp	x1, x8, [x29, #-104]
	stp	x20, x22, [x29, #-208]
	stp	xzr, xzr, [x29, #-160]
	cmp	x1, x8
	b.eq	.LBB68_26
// %bb.24:
	stp	x20, x22, [x1]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_30
// %bb.25:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldur	x21, [x29, #-200]
	cbnz	x21, .LBB68_28
	b	.LBB68_35
.LBB68_26:
.Ltmp146:
	sub	x2, x29, #208
	ldr	x0, [sp, #48]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp147:
// %bb.27:
	ldur	x21, [x29, #-200]
	cbz	x21, .LBB68_35
.LBB68_28:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_31
// %bb.29:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_32
	b	.LBB68_35
.LBB68_30:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x1, [x29, #-104]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldur	x21, [x29, #-200]
	cbnz	x21, .LBB68_28
	b	.LBB68_35
.LBB68_31:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_35
.LBB68_32:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_328
// %bb.33:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_35
.LBB68_34:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_35:
	ldur	x21, [x29, #-152]
	cbz	x21, .LBB68_42
// %bb.36:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_38
// %bb.37:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_39
	b	.LBB68_42
.LBB68_38:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_42
.LBB68_39:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_329
// %bb.40:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_42
.LBB68_41:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_42:
	ldur	x21, [x29, #-184]
	cbz	x21, .LBB68_49
// %bb.43:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_45
// %bb.44:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_46
	b	.LBB68_49
.LBB68_45:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_49
.LBB68_46:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_330
// %bb.47:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_49
.LBB68_48:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_49:
	adrp	x8, .LCPI68_3
	adrp	x9, .LCPI68_4
	mov	x20, #-7378697629483820647
	movi	d10, #0000000000000000
	movk	x20, #39322
	movi	v12.2s, #1
	mov	w10, #-11
	mov	x27, #4467570830351532032
	movk	x20, #16329, lsl #48
	ldr	d9, [x8, :lo12:.LCPI68_3]
	ldr	d11, [x9, :lo12:.LCPI68_4]
	b	.LBB68_51
.LBB68_50:                              //   in Loop: Header=BB68_51 Depth=1
	ldr	w10, [sp, #32]                  // 4-byte Folded Reload
	add	w10, w10, #1
	cmp	w10, #11
	b.eq	.LBB68_179
.LBB68_51:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB68_54 Depth 2
                                        //       Child Loop BB68_86 Depth 3
                                        //       Child Loop BB68_88 Depth 3
	scvtf	d15, w10
	mov	w28, #-11
	str	w10, [sp, #32]                  // 4-byte Folded Spill
	b	.LBB68_54
.LBB68_52:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_53:                              //   in Loop: Header=BB68_54 Depth=2
	add	w28, w28, #1
	cmp	w28, #11
	b.eq	.LBB68_50
.LBB68_54:                              //   Parent Loop BB68_51 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB68_86 Depth 3
                                        //       Child Loop BB68_88 Depth 3
	bl	rand
	mov	w21, w0
	fmov	d14, x27
	bl	rand
	scvtf	d0, w0
	scvtf	d13, w28
	fmul	d0, d0, d14
	fmadd	d8, d0, d9, d15
	bl	rand
	scvtf	d1, w0
	fmov	d0, #-4.00000000
	stur	d8, [x29, #-160]
	stur	x20, [x29, #-152]
	fadd	d0, d8, d0
	fmul	d1, d1, d14
	fmadd	d0, d0, d0, d10
	fmadd	d2, d1, d9, d13
	fmadd	d1, d2, d2, d0
	stur	d2, [x29, #-144]
	fsqrt	d0, d1
	fcmp	d0, d0
	b.vs	.LBB68_178
// %bb.55:                              //   in Loop: Header=BB68_54 Depth=2
	fcmp	d0, d9
	b.le	.LBB68_53
.LBB68_56:                              //   in Loop: Header=BB68_54 Depth=2
	scvtf	d0, w21
	stp	xzr, xzr, [sp, #208]
	fmul	d0, d0, d14
	fcmp	d0, d11
	b.pl	.LBB68_62
// %bb.57:                              //   in Loop: Header=BB68_54 Depth=2
	mov	x20, #4467570830351532032
	bl	rand
	mov	w24, w0
	bl	rand
	mov	w21, w0
	bl	rand
	mov	w23, w0
	bl	rand
	mov	w25, w0
	bl	rand
	mov	w26, w0
	bl	rand
	mov	w27, w0
.Ltmp167:
	mov	w0, #40
	bl	_Znwm
.Ltmp168:
// %bb.58:                              //   in Loop: Header=BB68_54 Depth=2
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x19, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	str	d12, [x0, #8]
	str	x8, [x0]
	adrp	x8, _ZTV10lambertian+16
	add	x8, x8, :lo12:_ZTV10lambertian+16
	str	x8, [x22, #16]!
.Ltmp170:
	mov	w0, #48
	bl	_Znwm
.Ltmp171:
// %bb.59:                              //   in Loop: Header=BB68_54 Depth=2
	scvtf	d0, w24
	scvtf	d2, w25
	scvtf	d3, w21
	scvtf	d4, w26
	scvtf	d5, w23
	scvtf	d6, w27
	fmov	d1, x20
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x8, x0
	adrp	x26, :got:__libc_single_threaded
	mov	x20, #-7378697629483820647
	fmul	d0, d0, d1
	fmul	d2, d2, d1
	fmul	d3, d3, d1
	fmul	d4, d4, d1
	fmul	d5, d5, d1
	fmul	d1, d6, d1
	str	x9, [x0]
	adrp	x9, _ZTV11solid_color+16
	fmul	d0, d0, d2
	add	x9, x9, :lo12:_ZTV11solid_color+16
	fmul	d2, d3, d4
	str	d12, [x0, #8]
	fmul	d1, d5, d1
	ldr	x21, [sp, #216]
	str	x9, [x8, #16]!
	stp	x8, x0, [x19, #24]
	movk	x20, #39322
	stp	d0, d2, [x0, #24]
	movk	x20, #16329, lsl #48
	str	d1, [x0, #40]
	stp	x22, x19, [sp, #208]
	ldr	x26, [x26, :got_lo12:__libc_single_threaded]
	cbz	x21, .LBB68_75
// %bb.60:                              //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_71
// %bb.61:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_72
	b	.LBB68_75
.LBB68_62:                              //   in Loop: Header=BB68_54 Depth=2
	mov	x8, #7378697629483820646
	movk	x8, #16366, lsl #48
	fmov	d1, x8
	fcmp	d0, d1
	b.pl	.LBB68_67
// %bb.63:                              //   in Loop: Header=BB68_54 Depth=2
	bl	rand
	mov	w21, w0
	bl	rand
	mov	w22, w0
	bl	rand
	mov	w23, w0
	bl	rand
	mov	w24, w0
.Ltmp158:
	mov	w0, #56
	bl	_Znwm
.Ltmp159:
// %bb.64:                              //   in Loop: Header=BB68_54 Depth=2
	scvtf	d0, w24
	fmov	d1, x27
	scvtf	d4, w22
	scvtf	d2, w21
	scvtf	d3, w23
	fmov	d5, #0.50000000
	adrp	x9, _ZTV5metal+16
	mov	x8, x0
	fmul	d0, d0, d1
	add	x9, x9, :lo12:_ZTV5metal+16
	fmul	d4, d4, d1
	fmul	d2, d2, d1
	fmul	d1, d3, d1
	ldr	x21, [sp, #216]
	str	x9, [x8, #16]!
	fmadd	d0, d0, d5, d10
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	fmadd	d3, d4, d5, d5
	fmov	d4, #1.00000000
	fmadd	d2, d2, d5, d5
	fmadd	d1, d1, d5, d5
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d12, [x0, #8]
	fminnm	d0, d0, d4
	stp	x8, x0, [sp, #208]
	str	x9, [x0]
	stp	d2, d3, [x0, #24]
	stp	d1, d0, [x0, #40]
	cbz	x21, .LBB68_106
// %bb.65:                              //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_102
// %bb.66:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_103
	b	.LBB68_106
.LBB68_67:                              //   in Loop: Header=BB68_54 Depth=2
.Ltmp149:
	mov	w0, #32
	bl	_Znwm
.Ltmp150:
// %bb.68:                              //   in Loop: Header=BB68_54 Depth=2
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x8, x0
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x21, [sp, #216]
	str	d12, [x0, #8]
	str	x9, [x0]
	mov	x9, #4609434218613702656
	str	x9, [x0, #24]
	adrp	x9, _ZTV10dielectric+16
	add	x9, x9, :lo12:_ZTV10dielectric+16
	str	x9, [x8, #16]!
	stp	x8, x0, [sp, #208]
	cbz	x21, .LBB68_114
// %bb.69:                              //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_110
// %bb.70:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_111
	b	.LBB68_114
.LBB68_71:                              //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_75
.LBB68_72:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_118
// %bb.73:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_75
.LBB68_74:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_75:                              //   in Loop: Header=BB68_54 Depth=2
	bl	rand
	mov	x27, #4467570830351532032
	scvtf	d2, w0
	movi	v1.2d, #0000000000000000
	sub	x8, x29, #192
	mov	x9, #4607182418800017408
	str	x20, [sp, #152]
	fmov	d0, x27
	stp	x9, xzr, [sp, #160]
	fmul	d0, d2, d0
	fmov	d2, #0.50000000
	fmadd	d0, d0, d2, d10
	ldur	d2, [x29, #-144]
	fadd	d2, d2, d10
	mov	v1.d[1], v0.d[0]
	ldr	q0, [x8, #32]
	stur	d2, [x29, #-176]
	fadd	v0.2d, v0.2d, v1.2d
	str	q0, [x8]
.Ltmp173:
	mov	w0, #112
	bl	_Znwm
.Ltmp174:
// %bb.76:                              //   in Loop: Header=BB68_54 Depth=2
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x23, x0
	add	x24, x0, #16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d12, [x0, #8]
	str	x8, [x0]
.Ltmp176:
	sub	x0, x29, #88
	sub	x2, x29, #160
	sub	x3, x29, #192
	add	x4, sp, #168
	add	x5, sp, #160
	add	x6, sp, #152
	add	x7, sp, #208
	mov	x1, x24
	bl	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
.Ltmp177:
// %bb.77:                              //   in Loop: Header=BB68_54 Depth=2
	ldp	x25, x8, [x29, #-104]
	stp	x24, x23, [sp, #192]
	stp	xzr, xzr, [sp, #176]
	cmp	x25, x8
	b.eq	.LBB68_80
// %bb.78:                              //   in Loop: Header=BB68_54 Depth=2
	stp	x24, x23, [x25]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_92
// %bb.79:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
	add	x8, x25, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #200]
	cbnz	x21, .LBB68_93
	b	.LBB68_99
.LBB68_80:                              //   in Loop: Header=BB68_54 Depth=2
	ldur	x21, [x29, #-112]
	mov	x8, #9223372036854775792
	sub	x27, x25, x21
	cmp	x27, x8
	b.eq	.LBB68_354
// %bb.81:                              //   in Loop: Header=BB68_54 Depth=2
	asr	x19, x27, #4
	cmp	x27, #0
	csinc	x8, x19, xzr, ne
	adds	x8, x8, x19
	lsr	x9, x8, #59
	cset	w10, hs
	cmp	x9, #0
	cset	w9, ne
	orr	w9, w10, w9
	cmp	w9, #0
	mov	x9, #576460752303423487
	csel	x26, x9, x8, ne
	lsl	x0, x26, #4
.Ltmp179:
	bl	_Znwm
.Ltmp180:
// %bb.82:                              //   in Loop: Header=BB68_54 Depth=2
	adrp	x9, :got:__libc_single_threaded
	mov	x22, x0
	movi	v4.2d, #0000000000000000
	add	x8, x0, x19, lsl #4
	ldr	x9, [x9, :got_lo12:__libc_single_threaded]
	stp	x24, x23, [x8]
	ldrb	w9, [x9]
	cbz	w9, .LBB68_100
// %bb.83:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
	cmp	x21, x25
	b.eq	.LBB68_101
.LBB68_84:                              //   in Loop: Header=BB68_54 Depth=2
	sub	x9, x27, #16
	mov	x23, x22
	mov	x8, x21
	mov	x27, #4467570830351532032
	cmp	x9, #48
	b.lo	.LBB68_88
// %bb.85:                              //   in Loop: Header=BB68_54 Depth=2
	lsr	x8, x9, #4
	add	x11, x22, #32
	add	x9, x8, #1
	add	x12, x21, #32
	and	x10, x9, #0x1ffffffffffffffc
	lsl	x8, x10, #4
	mov	x13, x10
	add	x23, x22, x8
	add	x8, x21, x8
.LBB68_86:                              //   Parent Loop BB68_51 Depth=1
                                        //     Parent Loop BB68_54 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q1, q0, [x12, #-32]
	subs	x13, x13, #4
	ldp	q3, q2, [x12]
	stp	q1, q0, [x11, #-32]
	stp	q3, q2, [x11], #64
	stp	q4, q4, [x12, #-32]
	stp	q4, q4, [x12], #64
	b.ne	.LBB68_86
// %bb.87:                              //   in Loop: Header=BB68_54 Depth=2
	cmp	x9, x10
	b.eq	.LBB68_89
.LBB68_88:                              //   Parent Loop BB68_51 Depth=1
                                        //     Parent Loop BB68_54 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	x9, [x8]
	str	x9, [x23]
	ldr	x9, [x8, #8]
	str	x9, [x23, #8]
	add	x23, x23, #16
	stp	xzr, xzr, [x8], #16
	cmp	x8, x25
	b.ne	.LBB68_88
.LBB68_89:                              //   in Loop: Header=BB68_54 Depth=2
	cbz	x21, .LBB68_91
.LBB68_90:                              //   in Loop: Header=BB68_54 Depth=2
	mov	x0, x21
	bl	_ZdlPv
.LBB68_91:                              //   in Loop: Header=BB68_54 Depth=2
	add	x8, x23, #16
	add	x9, x22, x26, lsl #4
	adrp	x26, :got:__libc_single_threaded
	stp	x22, x8, [x29, #-112]
	stur	x9, [x29, #-96]
	ldr	x26, [x26, :got_lo12:__libc_single_threaded]
	ldr	x21, [sp, #200]
	cbnz	x21, .LBB68_93
	b	.LBB68_99
.LBB68_92:                              //   in Loop: Header=BB68_54 Depth=2
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x25, [x29, #-104]
	add	x8, x25, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #200]
	cbz	x21, .LBB68_99
.LBB68_93:                              //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_95
// %bb.94:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_96
	b	.LBB68_99
.LBB68_95:                              //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_99
.LBB68_96:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_131
// %bb.97:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_99
.LBB68_98:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_99:                              //   in Loop: Header=BB68_54 Depth=2
	ldr	x21, [sp, #184]
	cbnz	x21, .LBB68_163
	b	.LBB68_169
.LBB68_100:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	movi	v4.2d, #0000000000000000
	cmp	x21, x25
	b.ne	.LBB68_84
.LBB68_101:                             //   in Loop: Header=BB68_54 Depth=2
	mov	x23, x22
	mov	x27, #4467570830351532032
	cbnz	x21, .LBB68_90
	b	.LBB68_91
.LBB68_102:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_106
.LBB68_103:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_132
// %bb.104:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_106
.LBB68_105:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_106:                             //   in Loop: Header=BB68_54 Depth=2
	stur	xzr, [x29, #-192]
.Ltmp161:
	mov	w0, #72
	bl	_Znwm
.Ltmp162:
// %bb.107:                             //   in Loop: Header=BB68_54 Depth=2
	sub	x8, x29, #192
	mov	x21, x0
	ldp	x19, x22, [sp, #208]
	str	d12, [x0, #8]
	ldr	q0, [x8, #32]
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldur	d14, [x29, #-144]
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	x8, [x0]
	cbz	x22, .LBB68_120
// %bb.108:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_119
// %bb.109:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB68_120
.LBB68_110:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_114
.LBB68_111:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_133
// %bb.112:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_114
.LBB68_113:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_114:                             //   in Loop: Header=BB68_54 Depth=2
	stur	xzr, [x29, #-192]
.Ltmp152:
	mov	w0, #72
	bl	_Znwm
.Ltmp153:
// %bb.115:                             //   in Loop: Header=BB68_54 Depth=2
	sub	x8, x29, #192
	mov	x21, x0
	ldp	x19, x22, [sp, #208]
	str	d12, [x0, #8]
	ldr	q0, [x8, #32]
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldur	d14, [x29, #-144]
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	x8, [x0]
	cbz	x22, .LBB68_124
// %bb.116:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_123
// %bb.117:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB68_124
.LBB68_118:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_74
	b	.LBB68_75
.LBB68_119:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x22, #8
	mov	w0, #1
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
.LBB68_120:                             //   in Loop: Header=BB68_54 Depth=2
	adrp	x8, _ZTV6sphere+16
	stur	q0, [x21, #24]
	add	x8, x8, :lo12:_ZTV6sphere+16
	str	d14, [x21, #40]
	stp	x20, x19, [x21, #48]
	str	x22, [x21, #64]
	str	x8, [x21, #16]
	cbz	x22, .LBB68_138
// %bb.121:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_127
// %bb.122:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB68_135
	b	.LBB68_138
.LBB68_123:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x22, #8
	mov	w0, #1
	str	q0, [sp, #16]                   // 16-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
.LBB68_124:                             //   in Loop: Header=BB68_54 Depth=2
	adrp	x8, _ZTV6sphere+16
	stur	q0, [x21, #24]
	add	x8, x8, :lo12:_ZTV6sphere+16
	str	d14, [x21, #40]
	stp	x20, x19, [x21, #48]
	str	x22, [x21, #64]
	str	x8, [x21, #16]
	cbz	x22, .LBB68_149
// %bb.125:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_129
// %bb.126:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB68_146
	b	.LBB68_149
.LBB68_127:                             //   in Loop: Header=BB68_54 Depth=2
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_134
// %bb.128:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB68_135
	b	.LBB68_138
.LBB68_129:                             //   in Loop: Header=BB68_54 Depth=2
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_145
// %bb.130:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB68_146
	b	.LBB68_149
.LBB68_131:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_98
	b	.LBB68_99
.LBB68_132:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_105
	b	.LBB68_106
.LBB68_133:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_113
	b	.LBB68_114
.LBB68_134:                             //   in Loop: Header=BB68_54 Depth=2
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_138
.LBB68_135:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_144
// %bb.136:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB68_138
.LBB68_137:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_138:                             //   in Loop: Header=BB68_54 Depth=2
	ldp	x1, x9, [x29, #-104]
	add	x8, x21, #16
	stp	xzr, xzr, [x29, #-192]
	stp	x8, x21, [sp, #136]
	cmp	x1, x9
	b.eq	.LBB68_141
// %bb.139:                             //   in Loop: Header=BB68_54 Depth=2
	stp	x8, x21, [x1]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_143
// %bb.140:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #144]
	cbnz	x21, .LBB68_154
	b	.LBB68_162
.LBB68_141:                             //   in Loop: Header=BB68_54 Depth=2
.Ltmp164:
	add	x2, sp, #136
	ldr	x0, [sp, #48]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp165:
// %bb.142:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x21, [sp, #144]
	cbnz	x21, .LBB68_154
	b	.LBB68_162
.LBB68_143:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x1, [x29, #-104]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #144]
	cbnz	x21, .LBB68_154
	b	.LBB68_162
.LBB68_144:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_137
	b	.LBB68_138
.LBB68_145:                             //   in Loop: Header=BB68_54 Depth=2
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_149
.LBB68_146:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_177
// %bb.147:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB68_149
.LBB68_148:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_149:                             //   in Loop: Header=BB68_54 Depth=2
	ldp	x1, x9, [x29, #-104]
	add	x8, x21, #16
	stp	xzr, xzr, [x29, #-192]
	stp	x8, x21, [sp, #120]
	cmp	x1, x9
	b.eq	.LBB68_152
// %bb.150:                             //   in Loop: Header=BB68_54 Depth=2
	stp	x8, x21, [x1]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_159
// %bb.151:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #128]
	cbnz	x21, .LBB68_154
	b	.LBB68_162
.LBB68_152:                             //   in Loop: Header=BB68_54 Depth=2
.Ltmp155:
	add	x2, sp, #120
	ldr	x0, [sp, #48]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp156:
// %bb.153:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x21, [sp, #128]
	cbz	x21, .LBB68_162
.LBB68_154:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_156
// %bb.155:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_157
	b	.LBB68_162
.LBB68_156:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_162
.LBB68_157:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_160
// %bb.158:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_162
	b	.LBB68_161
.LBB68_159:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x1, [x29, #-104]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #128]
	cbnz	x21, .LBB68_154
	b	.LBB68_162
.LBB68_160:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_162
.LBB68_161:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_162:                             //   in Loop: Header=BB68_54 Depth=2
	ldur	x21, [x29, #-184]
	cbz	x21, .LBB68_169
.LBB68_163:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_165
// %bb.164:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_166
	b	.LBB68_169
.LBB68_165:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_169
.LBB68_166:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_175
// %bb.167:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_169
.LBB68_168:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_169:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x21, [sp, #216]
	cbz	x21, .LBB68_53
// %bb.170:                             //   in Loop: Header=BB68_54 Depth=2
	ldrb	w8, [x26]
	cbz	w8, .LBB68_172
// %bb.171:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.ne	.LBB68_53
	b	.LBB68_173
.LBB68_172:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_53
.LBB68_173:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_176
// %bb.174:                             //   in Loop: Header=BB68_54 Depth=2
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_53
	b	.LBB68_52
.LBB68_175:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_168
	b	.LBB68_169
.LBB68_176:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_53
	b	.LBB68_52
.LBB68_177:                             //   in Loop: Header=BB68_54 Depth=2
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_148
	b	.LBB68_149
.LBB68_178:                             //   in Loop: Header=BB68_54 Depth=2
	fmov	d0, d1
	bl	sqrt
	fcmp	d0, d9
	b.gt	.LBB68_56
	b	.LBB68_53
.LBB68_179:
.Ltmp182:
	mov	w0, #32
	bl	_Znwm
.Ltmp183:
// %bb.180:
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	mov	x20, x0
	mov	x8, #4609434218613702656
	stur	xzr, [x29, #-192]
	str	x9, [x0]
	adrp	x9, _ZTV10dielectric+16
	add	x9, x9, :lo12:_ZTV10dielectric+16
	str	x8, [x0, #24]
	str	d8, [x0, #8]
	str	x9, [x20, #16]!
	stp	x20, x0, [x29, #-160]
.Ltmp185:
	mov	w0, #72
	bl	_Znwm
.Ltmp186:
	adrp	x24, _ZTV10lambertian+16
	add	x24, x24, :lo12:_ZTV10lambertian+16
// %bb.181:
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	ldrb	w8, [x26]
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x9, [x0]
	cbz	w8, .LBB68_183
// %bb.182:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB68_184
.LBB68_183:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB68_184:
	adrp	x8, .LCPI68_5
	add	x19, x21, #16
	stp	x20, x22, [x21, #56]
	ldr	q0, [x8, :lo12:.LCPI68_5]
	adrp	x8, _ZTV6sphere+16
	add	x8, x8, :lo12:_ZTV6sphere+16
	stur	q0, [x21, #24]
	str	x8, [x21, #16]
	ldrb	w8, [x26]
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	stur	q0, [x21, #40]
	cbz	w8, .LBB68_186
// %bb.185:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB68_190
	b	.LBB68_193
.LBB68_186:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_189
// %bb.187:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB68_190
	b	.LBB68_193
.LBB68_188:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_23
	b	.LBB68_22
.LBB68_189:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_193
.LBB68_190:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_222
// %bb.191:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB68_193
.LBB68_192:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_193:
	ldp	x1, x8, [x29, #-104]
	stp	x19, x21, [sp, #104]
	stp	xzr, xzr, [x29, #-192]
	cmp	x1, x8
	b.eq	.LBB68_196
// %bb.194:
	stp	x19, x21, [x1]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_200
// %bb.195:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #112]
	cbnz	x21, .LBB68_198
	b	.LBB68_205
.LBB68_196:
.Ltmp188:
	add	x2, sp, #104
	ldr	x0, [sp, #48]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp189:
// %bb.197:
	ldr	x21, [sp, #112]
	cbz	x21, .LBB68_205
.LBB68_198:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_201
// %bb.199:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_202
	b	.LBB68_205
.LBB68_200:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x1, [x29, #-104]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #112]
	cbnz	x21, .LBB68_198
	b	.LBB68_205
.LBB68_201:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_205
.LBB68_202:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_331
// %bb.203:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_205
.LBB68_204:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_205:
	ldur	x21, [x29, #-184]
	cbz	x21, .LBB68_212
// %bb.206:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_208
// %bb.207:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_209
	b	.LBB68_212
.LBB68_208:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_212
.LBB68_209:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_332
// %bb.210:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_212
.LBB68_211:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_212:
.Ltmp191:
	mov	w0, #40
	bl	_Znwm
.Ltmp192:
// %bb.213:
	movi	v8.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x20, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
	str	x24, [x20, #16]!
.Ltmp194:
	mov	w0, #48
	bl	_Znwm
.Ltmp195:
// %bb.214:
	adrp	x11, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x9, .LCPI68_6
	add	x11, x11, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x10, #-7378697629483820647
	movk	x10, #39322
	mov	x8, x0
	movk	x10, #16313, lsl #48
	ldr	q0, [x9, :lo12:.LCPI68_6]
	str	x11, [x0]
	adrp	x11, _ZTV11solid_color+16
	add	x11, x11, :lo12:_ZTV11solid_color+16
	str	d8, [x0, #8]
	str	x10, [x0, #40]
	stur	q0, [x0, #24]
	str	x11, [x8, #16]!
	stp	x8, x0, [x21, #24]
	stp	x20, x21, [x29, #-192]
	str	xzr, [sp, #208]
.Ltmp197:
	mov	w0, #72
	bl	_Znwm
.Ltmp198:
// %bb.215:
	movi	v0.2s, #1
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	ldrb	w8, [x26]
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d0, [x0, #8]
	str	x9, [x0]
	cbz	w8, .LBB68_217
// %bb.216:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	b	.LBB68_218
.LBB68_217:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB68_218:
	adrp	x8, .LCPI68_7
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	add	x19, x22, #16
	stp	x20, x21, [x22, #56]
	ldr	q0, [x8, :lo12:.LCPI68_7]
	adrp	x8, _ZTV6sphere+16
	add	x8, x8, :lo12:_ZTV6sphere+16
	stur	q1, [x22, #40]
	stur	q0, [x22, #24]
	str	x8, [x22, #16]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_220
// %bb.219:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_224
	b	.LBB68_227
.LBB68_220:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_223
// %bb.221:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_224
	b	.LBB68_227
.LBB68_222:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_192
	b	.LBB68_193
.LBB68_223:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_227
.LBB68_224:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_255
// %bb.225:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_227
.LBB68_226:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_227:
	ldp	x1, x8, [x29, #-104]
	stp	x19, x22, [sp, #88]
	stp	xzr, xzr, [sp, #208]
	cmp	x1, x8
	b.eq	.LBB68_230
// %bb.228:
	stp	x19, x22, [x1]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_234
// %bb.229:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #96]
	cbnz	x21, .LBB68_232
	b	.LBB68_239
.LBB68_230:
.Ltmp200:
	add	x2, sp, #88
	ldr	x0, [sp, #48]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp201:
// %bb.231:
	ldr	x21, [sp, #96]
	cbz	x21, .LBB68_239
.LBB68_232:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_235
// %bb.233:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_236
	b	.LBB68_239
.LBB68_234:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x1, [x29, #-104]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #96]
	cbnz	x21, .LBB68_232
	b	.LBB68_239
.LBB68_235:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_239
.LBB68_236:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_333
// %bb.237:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_239
.LBB68_238:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_239:
	ldr	x21, [sp, #216]
	cbz	x21, .LBB68_246
// %bb.240:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_242
// %bb.241:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_243
	b	.LBB68_246
.LBB68_242:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_246
.LBB68_243:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_334
// %bb.244:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_246
.LBB68_245:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_246:
.Ltmp203:
	mov	w0, #56
	bl	_Znwm
.Ltmp204:
// %bb.247:
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x8, .LCPI68_8
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	adrp	x10, _ZTV5metal+16
	mov	x21, x0
	mov	x20, x0
	add	x10, x10, :lo12:_ZTV5metal+16
	str	x9, [x0]
	adrp	x9, .LCPI68_9
	ldr	q0, [x8, :lo12:.LCPI68_8]
	str	d8, [x0, #8]
	str	x10, [x20, #16]!
	ldr	q1, [x9, :lo12:.LCPI68_9]
	stp	x20, x0, [sp, #208]
	stur	q0, [x0, #24]
	str	xzr, [sp, #176]
	stur	q1, [x0, #40]
.Ltmp206:
	mov	w0, #72
	bl	_Znwm
.Ltmp207:
// %bb.248:
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	ldrb	w8, [x26]
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x9, [x0]
	cbz	w8, .LBB68_250
// %bb.249:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	b	.LBB68_251
.LBB68_250:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB68_251:
	adrp	x8, .LCPI68_10
	ldr	q1, [sp, #32]                   // 16-byte Folded Reload
	add	x19, x22, #16
	stp	x20, x21, [x22, #56]
	ldr	q0, [x8, :lo12:.LCPI68_10]
	adrp	x8, _ZTV6sphere+16
	add	x8, x8, :lo12:_ZTV6sphere+16
	stur	q1, [x22, #40]
	stur	q0, [x22, #24]
	str	x8, [x22, #16]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_253
// %bb.252:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_257
	b	.LBB68_260
.LBB68_253:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	cbz	w8, .LBB68_256
// %bb.254:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_257
	b	.LBB68_260
.LBB68_255:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_226
	b	.LBB68_227
.LBB68_256:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_260
.LBB68_257:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_327
// %bb.258:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_260
.LBB68_259:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_260:
	ldp	x1, x8, [x29, #-104]
	stp	x19, x22, [sp, #72]
	stp	xzr, xzr, [sp, #176]
	cmp	x1, x8
	b.eq	.LBB68_263
// %bb.261:
	stp	x19, x22, [x1]
	ldrb	w8, [x26]
	cbz	w8, .LBB68_267
// %bb.262:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #80]
	cbnz	x21, .LBB68_265
	b	.LBB68_272
.LBB68_263:
.Ltmp209:
	add	x2, sp, #72
	ldr	x0, [sp, #48]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp210:
// %bb.264:
	ldr	x21, [sp, #80]
	cbz	x21, .LBB68_272
.LBB68_265:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_268
// %bb.266:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_269
	b	.LBB68_272
.LBB68_267:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x1, [x29, #-104]
	add	x8, x1, #16
	stur	x8, [x29, #-104]
	ldr	x21, [sp, #80]
	cbnz	x21, .LBB68_265
	b	.LBB68_272
.LBB68_268:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_272
.LBB68_269:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_335
// %bb.270:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_272
.LBB68_271:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_272:
	ldr	x21, [sp, #184]
	cbz	x21, .LBB68_279
// %bb.273:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_275
// %bb.274:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB68_276
	b	.LBB68_279
.LBB68_275:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_279
.LBB68_276:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_336
// %bb.277:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB68_279
.LBB68_278:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_279:
.Ltmp212:
	mov	w0, #104
	bl	_Znwm
.Ltmp213:
// %bb.280:
	ldp	x9, x8, [x29, #-112]
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	sub	x8, x8, x9
	str	d0, [x0, #8]
	asr	x3, x8, #4
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	x8, [x0]
.Ltmp215:
	movi	d0, #0000000000000000
	fmov	d1, #1.00000000
	mov	x0, x22
	ldr	x1, [sp, #48]                   // 8-byte Folded Reload
	mov	x2, xzr
	bl	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.Ltmp216:
// %bb.281:
	stp	x22, x21, [sp, #56]
	stp	xzr, xzr, [sp, #176]
.Ltmp218:
	add	x1, sp, #56
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	bl	_ZN13hittable_listC2ESt10shared_ptrI8hittableE
.Ltmp219:
// %bb.282:
	ldr	x19, [sp, #64]
	cbz	x19, .LBB68_289
// %bb.283:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_285
// %bb.284:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB68_286
	b	.LBB68_289
.LBB68_285:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_289
.LBB68_286:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_337
// %bb.287:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB68_289
.LBB68_288:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_289:
	ldr	x19, [sp, #184]
	cbz	x19, .LBB68_296
// %bb.290:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_292
// %bb.291:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB68_293
	b	.LBB68_296
.LBB68_292:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_296
.LBB68_293:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_338
// %bb.294:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB68_296
.LBB68_295:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_296:
	ldr	x19, [sp, #216]
	cbz	x19, .LBB68_303
// %bb.297:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_299
// %bb.298:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB68_300
	b	.LBB68_303
.LBB68_299:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_303
.LBB68_300:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_339
// %bb.301:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB68_303
.LBB68_302:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_303:
	ldur	x19, [x29, #-184]
	cbz	x19, .LBB68_310
// %bb.304:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_306
// %bb.305:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB68_307
	b	.LBB68_310
.LBB68_306:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_310
.LBB68_307:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_340
// %bb.308:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB68_310
.LBB68_309:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_310:
	ldur	x19, [x29, #-152]
	cbz	x19, .LBB68_317
// %bb.311:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_313
// %bb.312:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB68_314
	b	.LBB68_317
.LBB68_313:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_317
.LBB68_314:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_341
// %bb.315:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB68_317
.LBB68_316:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_317:
	ldur	x19, [x29, #-128]
	cbz	x19, .LBB68_323
// %bb.318:
	ldrb	w8, [x26]
	cbz	w8, .LBB68_320
// %bb.319:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB68_321
	b	.LBB68_323
.LBB68_320:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_323
.LBB68_321:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_342
// %bb.322:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB68_343
.LBB68_323:
	ldp	x19, x21, [x29, #-112]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	stur	x8, [x29, #-120]
	b.ne	.LBB68_346
.LBB68_324:
	cbz	x19, .LBB68_326
.LBB68_325:
	mov	x0, x19
	bl	_ZdlPv
.LBB68_326:
	add	sp, sp, #368
	ldp	x20, x19, [sp, #144]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #16]             // 16-byte Folded Reload
	ldp	d15, d14, [sp], #160            // 16-byte Folded Reload
	ret
.LBB68_327:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_259
	b	.LBB68_260
.LBB68_328:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_34
	b	.LBB68_35
.LBB68_329:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_41
	b	.LBB68_42
.LBB68_330:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_48
	b	.LBB68_49
.LBB68_331:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_204
	b	.LBB68_205
.LBB68_332:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_211
	b	.LBB68_212
.LBB68_333:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_238
	b	.LBB68_239
.LBB68_334:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_245
	b	.LBB68_246
.LBB68_335:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_271
	b	.LBB68_272
.LBB68_336:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_278
	b	.LBB68_279
.LBB68_337:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_288
	b	.LBB68_289
.LBB68_338:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_295
	b	.LBB68_296
.LBB68_339:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_302
	b	.LBB68_303
.LBB68_340:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_309
	b	.LBB68_310
.LBB68_341:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB68_316
	b	.LBB68_317
.LBB68_342:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_323
.LBB68_343:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x19, x21, [x29, #-112]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	stur	x8, [x29, #-120]
	b.ne	.LBB68_346
	b	.LBB68_324
.LBB68_344:                             //   in Loop: Header=BB68_346 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB68_345:                             //   in Loop: Header=BB68_346 Depth=1
	add	x19, x19, #16
	cmp	x19, x21
	b.eq	.LBB68_353
.LBB68_346:                             // =>This Inner Loop Header: Depth=1
	ldr	x20, [x19, #8]
	cbz	x20, .LBB68_345
// %bb.347:                             //   in Loop: Header=BB68_346 Depth=1
	ldrb	w8, [x26]
	cbz	w8, .LBB68_349
// %bb.348:                             //   in Loop: Header=BB68_346 Depth=1
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB68_345
	b	.LBB68_350
.LBB68_349:                             //   in Loop: Header=BB68_346 Depth=1
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_345
.LBB68_350:                             //   in Loop: Header=BB68_346 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB68_352
// %bb.351:                             //   in Loop: Header=BB68_346 Depth=1
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB68_345
	b	.LBB68_344
.LBB68_352:                             //   in Loop: Header=BB68_346 Depth=1
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB68_345
	b	.LBB68_344
.LBB68_353:
	ldur	x19, [x29, #-112]
	cbnz	x19, .LBB68_325
	b	.LBB68_326
.LBB68_354:
.Ltmp221:
	adrp	x0, .L.str.8
	add	x0, x0, :lo12:.L.str.8
	bl	_ZSt20__throw_length_errorPKc
.Ltmp222:
// %bb.355:
.LBB68_356:
.Ltmp211:
	mov	x22, x0
	add	x0, sp, #72
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #176
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_365
.LBB68_357:
.Ltmp202:
	mov	x22, x0
	add	x0, sp, #88
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #208
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_366
.LBB68_358:
.Ltmp190:
	mov	x22, x0
	add	x0, sp, #104
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #192
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_367
.LBB68_359:
.Ltmp148:
	mov	x22, x0
	sub	x0, x29, #208
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #160
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_375
.LBB68_360:
.Ltmp220:
	mov	x22, x0
	add	x0, sp, #56
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #176
	bl	_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_365
.LBB68_361:
.Ltmp217:
	mov	x22, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB68_365
.LBB68_362:
.Ltmp214:
	b	.LBB68_364
.LBB68_363:
.Ltmp208:
.LBB68_364:
	mov	x22, x0
.LBB68_365:
	add	x0, sp, #208
	bl	_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB68_366:
	sub	x0, x29, #192
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB68_367:
	sub	x0, x29, #160
	bl	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_395
.LBB68_368:
.Ltmp205:
	mov	x22, x0
	b	.LBB68_366
.LBB68_369:
.Ltmp199:
	mov	x22, x0
	b	.LBB68_366
.LBB68_370:
.Ltmp196:
	mov	x22, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB68_367
.LBB68_371:
.Ltmp193:
	mov	x22, x0
	b	.LBB68_367
.LBB68_372:
.Ltmp187:
	mov	x22, x0
	b	.LBB68_367
.LBB68_373:
.Ltmp184:
	mov	x22, x0
	b	.LBB68_395
.LBB68_374:
.Ltmp145:
	mov	x22, x0
.LBB68_375:
	sub	x0, x29, #192
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_395
.LBB68_376:
.Ltmp142:
	mov	x22, x0
	b	.LBB68_395
.LBB68_377:
.Ltmp139:
	mov	x22, x0
	mov	x0, x20
	bl	_ZdlPv
	b	.LBB68_396
.LBB68_378:
.Ltmp136:
	mov	x22, x0
	b	.LBB68_396
.LBB68_379:
.Ltmp166:
	mov	x22, x0
	add	x0, sp, #136
	b	.LBB68_381
.LBB68_380:
.Ltmp157:
	mov	x22, x0
	add	x0, sp, #120
.LBB68_381:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #192
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_394
.LBB68_382:
.Ltmp181:
	b	.LBB68_384
.LBB68_383:
.Ltmp223:
.LBB68_384:
	mov	x22, x0
	add	x0, sp, #192
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #176
	bl	_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB68_394
.LBB68_385:
.Ltmp163:
	mov	x22, x0
	b	.LBB68_394
.LBB68_386:
.Ltmp160:
	mov	x22, x0
	b	.LBB68_394
.LBB68_387:
.Ltmp151:
	mov	x22, x0
	b	.LBB68_394
.LBB68_388:
.Ltmp154:
	mov	x22, x0
	b	.LBB68_394
.LBB68_389:
.Ltmp169:
	mov	x22, x0
	b	.LBB68_394
.LBB68_390:
.Ltmp178:
	mov	x22, x0
	mov	x0, x23
	b	.LBB68_393
.LBB68_391:
.Ltmp175:
	mov	x22, x0
	b	.LBB68_394
.LBB68_392:
.Ltmp172:
	mov	x22, x0
	mov	x0, x19
.LBB68_393:
	bl	_ZdlPv
.LBB68_394:
	add	x0, sp, #208
	bl	_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB68_395:
	sub	x0, x29, #136
	bl	_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB68_396:
	sub	x0, x29, #120
	bl	_ZN13hittable_listD2Ev
	mov	x0, x22
	bl	_Unwind_Resume
.Lfunc_end68:
	.size	_Z12random_scenev, .Lfunc_end68-_Z12random_scenev
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table68:
.Lexception9:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end9-.Lcst_begin9
.Lcst_begin9:
	.uleb128 .Ltmp134-.Lfunc_begin9         // >> Call Site 1 <<
	.uleb128 .Ltmp135-.Ltmp134              //   Call between .Ltmp134 and .Ltmp135
	.uleb128 .Ltmp136-.Lfunc_begin9         //     jumps to .Ltmp136
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp137-.Lfunc_begin9         // >> Call Site 2 <<
	.uleb128 .Ltmp138-.Ltmp137              //   Call between .Ltmp137 and .Ltmp138
	.uleb128 .Ltmp139-.Lfunc_begin9         //     jumps to .Ltmp139
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp140-.Lfunc_begin9         // >> Call Site 3 <<
	.uleb128 .Ltmp141-.Ltmp140              //   Call between .Ltmp140 and .Ltmp141
	.uleb128 .Ltmp142-.Lfunc_begin9         //     jumps to .Ltmp142
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp141-.Lfunc_begin9         // >> Call Site 4 <<
	.uleb128 .Ltmp143-.Ltmp141              //   Call between .Ltmp141 and .Ltmp143
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp143-.Lfunc_begin9         // >> Call Site 5 <<
	.uleb128 .Ltmp144-.Ltmp143              //   Call between .Ltmp143 and .Ltmp144
	.uleb128 .Ltmp145-.Lfunc_begin9         //     jumps to .Ltmp145
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp144-.Lfunc_begin9         // >> Call Site 6 <<
	.uleb128 .Ltmp146-.Ltmp144              //   Call between .Ltmp144 and .Ltmp146
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp146-.Lfunc_begin9         // >> Call Site 7 <<
	.uleb128 .Ltmp147-.Ltmp146              //   Call between .Ltmp146 and .Ltmp147
	.uleb128 .Ltmp148-.Lfunc_begin9         //     jumps to .Ltmp148
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp147-.Lfunc_begin9         // >> Call Site 8 <<
	.uleb128 .Ltmp167-.Ltmp147              //   Call between .Ltmp147 and .Ltmp167
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp167-.Lfunc_begin9         // >> Call Site 9 <<
	.uleb128 .Ltmp168-.Ltmp167              //   Call between .Ltmp167 and .Ltmp168
	.uleb128 .Ltmp169-.Lfunc_begin9         //     jumps to .Ltmp169
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp170-.Lfunc_begin9         // >> Call Site 10 <<
	.uleb128 .Ltmp171-.Ltmp170              //   Call between .Ltmp170 and .Ltmp171
	.uleb128 .Ltmp172-.Lfunc_begin9         //     jumps to .Ltmp172
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp158-.Lfunc_begin9         // >> Call Site 11 <<
	.uleb128 .Ltmp159-.Ltmp158              //   Call between .Ltmp158 and .Ltmp159
	.uleb128 .Ltmp160-.Lfunc_begin9         //     jumps to .Ltmp160
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp149-.Lfunc_begin9         // >> Call Site 12 <<
	.uleb128 .Ltmp150-.Ltmp149              //   Call between .Ltmp149 and .Ltmp150
	.uleb128 .Ltmp151-.Lfunc_begin9         //     jumps to .Ltmp151
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp150-.Lfunc_begin9         // >> Call Site 13 <<
	.uleb128 .Ltmp173-.Ltmp150              //   Call between .Ltmp150 and .Ltmp173
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp173-.Lfunc_begin9         // >> Call Site 14 <<
	.uleb128 .Ltmp174-.Ltmp173              //   Call between .Ltmp173 and .Ltmp174
	.uleb128 .Ltmp175-.Lfunc_begin9         //     jumps to .Ltmp175
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp176-.Lfunc_begin9         // >> Call Site 15 <<
	.uleb128 .Ltmp177-.Ltmp176              //   Call between .Ltmp176 and .Ltmp177
	.uleb128 .Ltmp178-.Lfunc_begin9         //     jumps to .Ltmp178
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp179-.Lfunc_begin9         // >> Call Site 16 <<
	.uleb128 .Ltmp180-.Ltmp179              //   Call between .Ltmp179 and .Ltmp180
	.uleb128 .Ltmp181-.Lfunc_begin9         //     jumps to .Ltmp181
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp180-.Lfunc_begin9         // >> Call Site 17 <<
	.uleb128 .Ltmp161-.Ltmp180              //   Call between .Ltmp180 and .Ltmp161
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp161-.Lfunc_begin9         // >> Call Site 18 <<
	.uleb128 .Ltmp162-.Ltmp161              //   Call between .Ltmp161 and .Ltmp162
	.uleb128 .Ltmp163-.Lfunc_begin9         //     jumps to .Ltmp163
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp162-.Lfunc_begin9         // >> Call Site 19 <<
	.uleb128 .Ltmp152-.Ltmp162              //   Call between .Ltmp162 and .Ltmp152
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp152-.Lfunc_begin9         // >> Call Site 20 <<
	.uleb128 .Ltmp153-.Ltmp152              //   Call between .Ltmp152 and .Ltmp153
	.uleb128 .Ltmp154-.Lfunc_begin9         //     jumps to .Ltmp154
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp153-.Lfunc_begin9         // >> Call Site 21 <<
	.uleb128 .Ltmp164-.Ltmp153              //   Call between .Ltmp153 and .Ltmp164
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp164-.Lfunc_begin9         // >> Call Site 22 <<
	.uleb128 .Ltmp165-.Ltmp164              //   Call between .Ltmp164 and .Ltmp165
	.uleb128 .Ltmp166-.Lfunc_begin9         //     jumps to .Ltmp166
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp165-.Lfunc_begin9         // >> Call Site 23 <<
	.uleb128 .Ltmp155-.Ltmp165              //   Call between .Ltmp165 and .Ltmp155
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp155-.Lfunc_begin9         // >> Call Site 24 <<
	.uleb128 .Ltmp156-.Ltmp155              //   Call between .Ltmp155 and .Ltmp156
	.uleb128 .Ltmp157-.Lfunc_begin9         //     jumps to .Ltmp157
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp156-.Lfunc_begin9         // >> Call Site 25 <<
	.uleb128 .Ltmp182-.Ltmp156              //   Call between .Ltmp156 and .Ltmp182
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp182-.Lfunc_begin9         // >> Call Site 26 <<
	.uleb128 .Ltmp183-.Ltmp182              //   Call between .Ltmp182 and .Ltmp183
	.uleb128 .Ltmp184-.Lfunc_begin9         //     jumps to .Ltmp184
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp185-.Lfunc_begin9         // >> Call Site 27 <<
	.uleb128 .Ltmp186-.Ltmp185              //   Call between .Ltmp185 and .Ltmp186
	.uleb128 .Ltmp187-.Lfunc_begin9         //     jumps to .Ltmp187
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp186-.Lfunc_begin9         // >> Call Site 28 <<
	.uleb128 .Ltmp188-.Ltmp186              //   Call between .Ltmp186 and .Ltmp188
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp188-.Lfunc_begin9         // >> Call Site 29 <<
	.uleb128 .Ltmp189-.Ltmp188              //   Call between .Ltmp188 and .Ltmp189
	.uleb128 .Ltmp190-.Lfunc_begin9         //     jumps to .Ltmp190
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp189-.Lfunc_begin9         // >> Call Site 30 <<
	.uleb128 .Ltmp191-.Ltmp189              //   Call between .Ltmp189 and .Ltmp191
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp191-.Lfunc_begin9         // >> Call Site 31 <<
	.uleb128 .Ltmp192-.Ltmp191              //   Call between .Ltmp191 and .Ltmp192
	.uleb128 .Ltmp193-.Lfunc_begin9         //     jumps to .Ltmp193
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp194-.Lfunc_begin9         // >> Call Site 32 <<
	.uleb128 .Ltmp195-.Ltmp194              //   Call between .Ltmp194 and .Ltmp195
	.uleb128 .Ltmp196-.Lfunc_begin9         //     jumps to .Ltmp196
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp197-.Lfunc_begin9         // >> Call Site 33 <<
	.uleb128 .Ltmp198-.Ltmp197              //   Call between .Ltmp197 and .Ltmp198
	.uleb128 .Ltmp199-.Lfunc_begin9         //     jumps to .Ltmp199
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp198-.Lfunc_begin9         // >> Call Site 34 <<
	.uleb128 .Ltmp200-.Ltmp198              //   Call between .Ltmp198 and .Ltmp200
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp200-.Lfunc_begin9         // >> Call Site 35 <<
	.uleb128 .Ltmp201-.Ltmp200              //   Call between .Ltmp200 and .Ltmp201
	.uleb128 .Ltmp202-.Lfunc_begin9         //     jumps to .Ltmp202
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp201-.Lfunc_begin9         // >> Call Site 36 <<
	.uleb128 .Ltmp203-.Ltmp201              //   Call between .Ltmp201 and .Ltmp203
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp203-.Lfunc_begin9         // >> Call Site 37 <<
	.uleb128 .Ltmp204-.Ltmp203              //   Call between .Ltmp203 and .Ltmp204
	.uleb128 .Ltmp205-.Lfunc_begin9         //     jumps to .Ltmp205
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp206-.Lfunc_begin9         // >> Call Site 38 <<
	.uleb128 .Ltmp207-.Ltmp206              //   Call between .Ltmp206 and .Ltmp207
	.uleb128 .Ltmp208-.Lfunc_begin9         //     jumps to .Ltmp208
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp207-.Lfunc_begin9         // >> Call Site 39 <<
	.uleb128 .Ltmp209-.Ltmp207              //   Call between .Ltmp207 and .Ltmp209
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp209-.Lfunc_begin9         // >> Call Site 40 <<
	.uleb128 .Ltmp210-.Ltmp209              //   Call between .Ltmp209 and .Ltmp210
	.uleb128 .Ltmp211-.Lfunc_begin9         //     jumps to .Ltmp211
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp210-.Lfunc_begin9         // >> Call Site 41 <<
	.uleb128 .Ltmp212-.Ltmp210              //   Call between .Ltmp210 and .Ltmp212
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp212-.Lfunc_begin9         // >> Call Site 42 <<
	.uleb128 .Ltmp213-.Ltmp212              //   Call between .Ltmp212 and .Ltmp213
	.uleb128 .Ltmp214-.Lfunc_begin9         //     jumps to .Ltmp214
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp215-.Lfunc_begin9         // >> Call Site 43 <<
	.uleb128 .Ltmp216-.Ltmp215              //   Call between .Ltmp215 and .Ltmp216
	.uleb128 .Ltmp217-.Lfunc_begin9         //     jumps to .Ltmp217
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp218-.Lfunc_begin9         // >> Call Site 44 <<
	.uleb128 .Ltmp219-.Ltmp218              //   Call between .Ltmp218 and .Ltmp219
	.uleb128 .Ltmp220-.Lfunc_begin9         //     jumps to .Ltmp220
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp219-.Lfunc_begin9         // >> Call Site 45 <<
	.uleb128 .Ltmp221-.Ltmp219              //   Call between .Ltmp219 and .Ltmp221
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp221-.Lfunc_begin9         // >> Call Site 46 <<
	.uleb128 .Ltmp222-.Ltmp221              //   Call between .Ltmp221 and .Ltmp222
	.uleb128 .Ltmp223-.Lfunc_begin9         //     jumps to .Ltmp223
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp222-.Lfunc_begin9         // >> Call Site 47 <<
	.uleb128 .Lfunc_end68-.Ltmp222          //   Call between .Ltmp222 and .Lfunc_end68
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end9:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB69_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB69_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB69_4
	b	.LBB69_8
.LBB69_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB69_8
.LBB69_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB69_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB69_8
.LBB69_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB69_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB69_6
.LBB69_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end69:
	.size	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end69-_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB70_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB70_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB70_4
	b	.LBB70_8
.LBB70_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB70_8
.LBB70_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB70_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB70_8
.LBB70_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB70_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB70_6
.LBB70_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end70:
	.size	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end70-_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB71_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB71_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB71_4
	b	.LBB71_8
.LBB71_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB71_8
.LBB71_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB71_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB71_8
.LBB71_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB71_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB71_6
.LBB71_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end71:
	.size	_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end71-_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB72_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB72_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB72_4
	b	.LBB72_8
.LBB72_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB72_8
.LBB72_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB72_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB72_8
.LBB72_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB72_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB72_6
.LBB72_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end72:
	.size	_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end72-_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB73_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB73_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB73_4
	b	.LBB73_8
.LBB73_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB73_8
.LBB73_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB73_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB73_8
.LBB73_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB73_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB73_6
.LBB73_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end73:
	.size	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end73-_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB74_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB74_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB74_4
	b	.LBB74_8
.LBB74_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB74_8
.LBB74_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB74_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB74_8
.LBB74_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB74_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB74_6
.LBB74_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end74:
	.size	_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end74-_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN13hittable_listC2ESt10shared_ptrI8hittableE,"axG",@progbits,_ZN13hittable_listC2ESt10shared_ptrI8hittableE,comdat
	.weak	_ZN13hittable_listC2ESt10shared_ptrI8hittableE // -- Begin function _ZN13hittable_listC2ESt10shared_ptrI8hittableE
	.p2align	2
	.type	_ZN13hittable_listC2ESt10shared_ptrI8hittableE,@function
_ZN13hittable_listC2ESt10shared_ptrI8hittableE: // @_ZN13hittable_listC2ESt10shared_ptrI8hittableE
.Lfunc_begin10:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception10
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x21, [sp, #32]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	mov	x20, x0
	adrp	x9, _ZTV13hittable_list+16
	add	x9, x9, :lo12:_ZTV13hittable_list+16
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	stp	xzr, xzr, [x0, #16]
	str	xzr, [x20, #8]!
	ldp	x10, x8, [x1]
	str	x9, [x0]
	stp	x10, x8, [sp]
	cbz	x8, .LBB75_3
// %bb.1:
	ldrb	w9, [x21]
	cbz	w9, .LBB75_9
// %bb.2:
	ldr	w9, [x8, #8]
	mov	x1, xzr
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB75_4
.LBB75_3:
	mov	x1, xzr
.LBB75_4:
.Ltmp224:
	mov	x2, sp
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp225:
// %bb.5:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB75_8
.LBB75_6:
	ldrb	w8, [x21]
	cbz	w8, .LBB75_14
// %bb.7:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB75_15
.LBB75_8:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB75_9:
	mov	x19, x0
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x8, x1, [x19, #16]
	cmp	x8, x1
	b.eq	.LBB75_4
// %bb.10:
	ldp	x10, x9, [sp]
	stp	x10, x9, [x8]
	cbz	x9, .LBB75_13
// %bb.11:
	ldrb	w10, [x21]
	cbz	w10, .LBB75_19
// %bb.12:
	ldr	w10, [x9, #8]
	add	w10, w10, #1
	str	w10, [x9, #8]
.LBB75_13:
	add	x8, x8, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB75_6
	b	.LBB75_8
.LBB75_14:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB75_8
.LBB75_15:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB75_17
// %bb.16:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB75_8
	b	.LBB75_18
.LBB75_17:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB75_8
.LBB75_18:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB75_19:
	add	x1, x9, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x8, [x19, #16]
	add	x8, x8, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB75_6
	b	.LBB75_8
.LBB75_20:
.Ltmp226:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end75:
	.size	_ZN13hittable_listC2ESt10shared_ptrI8hittableE, .Lfunc_end75-_ZN13hittable_listC2ESt10shared_ptrI8hittableE
	.cfi_endproc
	.section	.gcc_except_table._ZN13hittable_listC2ESt10shared_ptrI8hittableE,"aG",@progbits,_ZN13hittable_listC2ESt10shared_ptrI8hittableE,comdat
	.p2align	2
GCC_except_table75:
.Lexception10:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end10-.Lcst_begin10
.Lcst_begin10:
	.uleb128 .Ltmp224-.Lfunc_begin10        // >> Call Site 1 <<
	.uleb128 .Ltmp225-.Ltmp224              //   Call between .Ltmp224 and .Ltmp225
	.uleb128 .Ltmp226-.Lfunc_begin10        //     jumps to .Ltmp226
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp225-.Lfunc_begin10        // >> Call Site 2 <<
	.uleb128 .Lfunc_end75-.Ltmp225          //   Call between .Ltmp225 and .Lfunc_end75
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end10:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB76_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB76_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB76_4
	b	.LBB76_8
.LBB76_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB76_8
.LBB76_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB76_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB76_8
.LBB76_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB76_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB76_6
.LBB76_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end76:
	.size	_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end76-_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z11two_spheresv
.LCPI77_0:
	.xword	0x3fc999999999999a              // double 0.20000000000000001
	.xword	0x3fd3333333333333              // double 0.29999999999999999
.LCPI77_1:
	.xword	0x0000000000000000              // double 0
	.xword	0xc024000000000000              // double -10
.LCPI77_2:
	.xword	0x0000000000000000              // double 0
	.xword	0x4024000000000000              // double 10
	.text
	.globl	_Z11two_spheresv
	.p2align	2
	.type	_Z11two_spheresv,@function
_Z11two_spheresv:                       // @_Z11two_spheresv
.Lfunc_begin11:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception11
// %bb.0:
	sub	sp, sp, #224
	stp	x29, x30, [sp, #128]            // 16-byte Folded Spill
	add	x29, sp, #128
	stp	x28, x27, [sp, #144]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #160]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #176]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x8
	adrp	x8, .LCPI77_0
	mov	x10, #-7378697629483820647
	adrp	x9, _ZTV13hittable_list+16
	movk	x10, #39322
	add	x9, x9, :lo12:_ZTV13hittable_list+16
	ldr	q0, [x8, :lo12:.LCPI77_0]
	mov	x8, #-3689348814741910324
	movk	x8, #52429
	movk	x10, #16313, lsl #48
	movk	x8, #16364, lsl #48
	mov	x20, x19
	stur	q0, [x29, #-48]
	str	x9, [x19]
	dup	v0.2d, x8
	stur	x10, [x29, #-32]
	str	xzr, [x20, #8]!
	stp	xzr, xzr, [x19, #16]
	str	q0, [sp, #48]
	str	x8, [sp, #64]
.Ltmp227:
	mov	w0, #56
	bl	_Znwm
.Ltmp228:
// %bb.1:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x23, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp230:
	sub	x0, x29, #8
	sub	x2, x29, #48
	add	x3, sp, #48
	mov	x1, x23
	bl	_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_
.Ltmp231:
// %bb.2:
	stp	x23, x22, [x29, #-24]
	str	xzr, [sp, #48]
.Ltmp233:
	mov	w0, #40
	bl	_Znwm
.Ltmp234:
// %bb.3:
	adrp	x25, :got:__libc_single_threaded
	movi	v0.2s, #1
	adrp	x27, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x28, _ZTV10lambertian+16
	mov	x21, x0
	add	x27, x27, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
	add	x26, x0, #16
	add	x28, x28, :lo12:_ZTV10lambertian+16
	str	d0, [x0, #8]
	str	x27, [x0]
	ldrb	w8, [x25]
	cbz	w8, .LBB77_5
// %bb.4:
	ldr	w8, [x22, #8]
	stp	x28, x23, [x21, #16]
	str	x22, [x21, #32]
	add	w8, w8, #1
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB77_10
	b	.LBB77_13
.LBB77_5:
	add	x24, x22, #8
	mov	w0, #1
	mov	x1, x24
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	stp	x28, x23, [x21, #16]
	str	x22, [x21, #32]
	cbz	w8, .LBB77_7
// %bb.6:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB77_10
	b	.LBB77_13
.LBB77_7:
	mov	w0, #1
	mov	x1, x24
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB77_9
// %bb.8:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB77_10
	b	.LBB77_13
.LBB77_9:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_13
.LBB77_10:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_18
// %bb.11:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB77_13
.LBB77_12:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_13:
	stp	x26, x21, [sp, #48]
	stur	xzr, [x29, #-48]
.Ltmp236:
	mov	w0, #72
	bl	_Znwm
.Ltmp237:
// %bb.14:
	movi	v0.2s, #1
	adrp	x8, .LCPI77_1
	adrp	x9, .LCPI77_2
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x28, _ZTV6sphere+16
	mov	x22, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x24, x0
	str	d0, [x0, #8]
	ldr	q0, [x8, :lo12:.LCPI77_1]
	add	x28, x28, :lo12:_ZTV6sphere+16
	ldrb	w8, [x25]
	str	x23, [x0]
	stur	q0, [x0, #24]
	ldr	q0, [x9, :lo12:.LCPI77_2]
	str	x28, [x24, #16]!
	stp	xzr, xzr, [sp, #48]
	str	q0, [sp]                        // 16-byte Folded Spill
	stur	q0, [x0, #40]
	stp	x26, x21, [x0, #56]
	cbz	w8, .LBB77_16
// %bb.15:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_20
	b	.LBB77_23
.LBB77_16:
	mov	x26, x23
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB77_19
// %bb.17:
	ldr	w0, [x21, #8]
	mov	x23, x26
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_20
	b	.LBB77_23
.LBB77_18:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_12
	b	.LBB77_13
.LBB77_19:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	mov	x23, x26
	cmp	w0, #1
	b.ne	.LBB77_23
.LBB77_20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_56
// %bb.21:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB77_23
.LBB77_22:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_23:
	ldp	x1, x8, [x19, #16]
	stp	x24, x22, [sp, #32]
	stp	xzr, xzr, [x29, #-48]
	cmp	x1, x8
	b.eq	.LBB77_26
// %bb.24:
	stp	x24, x22, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB77_30
// %bb.25:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #40]
	cbnz	x21, .LBB77_28
	b	.LBB77_35
.LBB77_26:
.Ltmp239:
	add	x2, sp, #32
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp240:
// %bb.27:
	ldr	x21, [sp, #40]
	cbz	x21, .LBB77_35
.LBB77_28:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_31
// %bb.29:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_32
	b	.LBB77_35
.LBB77_30:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #40]
	cbnz	x21, .LBB77_28
	b	.LBB77_35
.LBB77_31:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_35
.LBB77_32:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_57
// %bb.33:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB77_35
.LBB77_34:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_35:
	ldur	x21, [x29, #-40]
	cbz	x21, .LBB77_42
// %bb.36:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_38
// %bb.37:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_39
	b	.LBB77_42
.LBB77_38:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_42
.LBB77_39:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_58
// %bb.40:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB77_42
.LBB77_41:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_42:
	ldr	x21, [sp, #56]
	cbz	x21, .LBB77_49
// %bb.43:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_45
// %bb.44:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_46
	b	.LBB77_49
.LBB77_45:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_49
.LBB77_46:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_59
// %bb.47:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB77_49
.LBB77_48:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_49:
	str	xzr, [sp, #48]
.Ltmp242:
	mov	w0, #40
	bl	_Znwm
.Ltmp243:
// %bb.50:
	ldp	x24, x22, [x29, #-24]
	movi	v0.2s, #1
	mov	x21, x0
	add	x26, x0, #16
	str	x27, [x0]
	str	d0, [x0, #8]
	cbz	x22, .LBB77_53
// %bb.51:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_54
// %bb.52:
	ldr	w8, [x22, #8]
	adrp	x9, _ZTV10lambertian+16
	add	x9, x9, :lo12:_ZTV10lambertian+16
	str	x22, [x21, #32]
	add	w8, w8, #1
	stp	x9, x24, [x21, #16]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB77_63
	b	.LBB77_66
.LBB77_53:
	adrp	x8, _ZTV10lambertian+16
	str	xzr, [x21, #32]
	add	x8, x8, :lo12:_ZTV10lambertian+16
	stp	x8, x24, [x21, #16]
	b	.LBB77_66
.LBB77_54:
	mov	x27, x23
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV10lambertian+16
	ldrb	w8, [x25]
	add	x9, x9, :lo12:_ZTV10lambertian+16
	str	x22, [x21, #32]
	stp	x9, x24, [x21, #16]
	cbz	w8, .LBB77_60
// %bb.55:
	ldr	w8, [x22, #8]
	mov	x23, x27
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB77_63
	b	.LBB77_66
.LBB77_56:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_22
	b	.LBB77_23
.LBB77_57:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_34
	b	.LBB77_35
.LBB77_58:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_41
	b	.LBB77_42
.LBB77_59:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_48
	b	.LBB77_49
.LBB77_60:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB77_62
// %bb.61:
	ldr	w0, [x22, #8]
	mov	x23, x27
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB77_63
	b	.LBB77_66
.LBB77_62:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	mov	x23, x27
	cmp	w0, #1
	b.ne	.LBB77_66
.LBB77_63:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_110
// %bb.64:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB77_66
.LBB77_65:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_66:
	stp	x26, x21, [sp, #48]
	stur	xzr, [x29, #-48]
.Ltmp245:
	mov	w0, #72
	bl	_Znwm
.Ltmp246:
// %bb.67:
	movi	v0.2s, #1
	mov	x22, x0
	mov	x24, x0
	ldrb	w8, [x25]
	str	x23, [x0]
	stp	xzr, xzr, [sp, #48]
	str	d0, [x0, #8]
	ldr	q0, [sp]                        // 16-byte Folded Reload
	str	x28, [x24, #16]!
	stp	x26, x21, [x0, #56]
	stur	q0, [x0, #24]
	stur	q0, [x0, #40]
	cbz	w8, .LBB77_69
// %bb.68:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_72
	b	.LBB77_75
.LBB77_69:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB77_71
// %bb.70:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB77_72
	b	.LBB77_75
.LBB77_71:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_75
.LBB77_72:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_109
// %bb.73:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB77_75
.LBB77_74:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_75:
	ldp	x1, x8, [x19, #16]
	stp	x24, x22, [sp, #16]
	stp	xzr, xzr, [x29, #-48]
	cmp	x1, x8
	b.eq	.LBB77_78
// %bb.76:
	stp	x24, x22, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB77_82
// %bb.77:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #24]
	cbnz	x19, .LBB77_80
	b	.LBB77_87
.LBB77_78:
.Ltmp248:
	add	x2, sp, #16
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp249:
// %bb.79:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB77_87
.LBB77_80:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_83
// %bb.81:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB77_84
	b	.LBB77_87
.LBB77_82:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #24]
	cbnz	x19, .LBB77_80
	b	.LBB77_87
.LBB77_83:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_87
.LBB77_84:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_111
// %bb.85:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB77_87
.LBB77_86:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_87:
	ldur	x19, [x29, #-40]
	cbz	x19, .LBB77_94
// %bb.88:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_90
// %bb.89:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB77_91
	b	.LBB77_94
.LBB77_90:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_94
.LBB77_91:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_112
// %bb.92:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB77_94
.LBB77_93:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_94:
	ldr	x19, [sp, #56]
	cbz	x19, .LBB77_101
// %bb.95:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_97
// %bb.96:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB77_98
	b	.LBB77_101
.LBB77_97:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_101
.LBB77_98:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_113
// %bb.99:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB77_101
.LBB77_100:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_101:
	ldur	x19, [x29, #-16]
	cbz	x19, .LBB77_108
// %bb.102:
	ldrb	w8, [x25]
	cbz	w8, .LBB77_104
// %bb.103:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB77_105
	b	.LBB77_108
.LBB77_104:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB77_108
.LBB77_105:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB77_114
// %bb.106:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB77_108
.LBB77_107:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB77_108:
	ldp	x20, x19, [sp, #208]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #160]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #144]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #128]            // 16-byte Folded Reload
	add	sp, sp, #224
	ret
.LBB77_109:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_74
	b	.LBB77_75
.LBB77_110:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_65
	b	.LBB77_66
.LBB77_111:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_86
	b	.LBB77_87
.LBB77_112:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_93
	b	.LBB77_94
.LBB77_113:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_100
	b	.LBB77_101
.LBB77_114:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB77_107
	b	.LBB77_108
.LBB77_115:
.Ltmp250:
	mov	x20, x0
	add	x0, sp, #16
	b	.LBB77_117
.LBB77_116:
.Ltmp241:
	mov	x20, x0
	add	x0, sp, #32
.LBB77_117:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #48
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB77_122
.LBB77_118:
.Ltmp247:
	b	.LBB77_121
.LBB77_119:
.Ltmp244:
	b	.LBB77_124
.LBB77_120:
.Ltmp238:
.LBB77_121:
	mov	x20, x0
.LBB77_122:
	add	x0, sp, #48
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #24
	bl	_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB77_123:
.Ltmp235:
.LBB77_124:
	mov	x20, x0
	sub	x0, x29, #24
	bl	_ZNSt12__shared_ptrI15checker_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB77_125:
.Ltmp232:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB77_126:
.Ltmp229:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end77:
	.size	_Z11two_spheresv, .Lfunc_end77-_Z11two_spheresv
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table77:
.Lexception11:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end11-.Lcst_begin11
.Lcst_begin11:
	.uleb128 .Ltmp227-.Lfunc_begin11        // >> Call Site 1 <<
	.uleb128 .Ltmp228-.Ltmp227              //   Call between .Ltmp227 and .Ltmp228
	.uleb128 .Ltmp229-.Lfunc_begin11        //     jumps to .Ltmp229
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp230-.Lfunc_begin11        // >> Call Site 2 <<
	.uleb128 .Ltmp231-.Ltmp230              //   Call between .Ltmp230 and .Ltmp231
	.uleb128 .Ltmp232-.Lfunc_begin11        //     jumps to .Ltmp232
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp233-.Lfunc_begin11        // >> Call Site 3 <<
	.uleb128 .Ltmp234-.Ltmp233              //   Call between .Ltmp233 and .Ltmp234
	.uleb128 .Ltmp235-.Lfunc_begin11        //     jumps to .Ltmp235
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp234-.Lfunc_begin11        // >> Call Site 4 <<
	.uleb128 .Ltmp236-.Ltmp234              //   Call between .Ltmp234 and .Ltmp236
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp236-.Lfunc_begin11        // >> Call Site 5 <<
	.uleb128 .Ltmp237-.Ltmp236              //   Call between .Ltmp236 and .Ltmp237
	.uleb128 .Ltmp238-.Lfunc_begin11        //     jumps to .Ltmp238
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp237-.Lfunc_begin11        // >> Call Site 6 <<
	.uleb128 .Ltmp239-.Ltmp237              //   Call between .Ltmp237 and .Ltmp239
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp239-.Lfunc_begin11        // >> Call Site 7 <<
	.uleb128 .Ltmp240-.Ltmp239              //   Call between .Ltmp239 and .Ltmp240
	.uleb128 .Ltmp241-.Lfunc_begin11        //     jumps to .Ltmp241
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp240-.Lfunc_begin11        // >> Call Site 8 <<
	.uleb128 .Ltmp242-.Ltmp240              //   Call between .Ltmp240 and .Ltmp242
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp242-.Lfunc_begin11        // >> Call Site 9 <<
	.uleb128 .Ltmp243-.Ltmp242              //   Call between .Ltmp242 and .Ltmp243
	.uleb128 .Ltmp244-.Lfunc_begin11        //     jumps to .Ltmp244
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp243-.Lfunc_begin11        // >> Call Site 10 <<
	.uleb128 .Ltmp245-.Ltmp243              //   Call between .Ltmp243 and .Ltmp245
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp245-.Lfunc_begin11        // >> Call Site 11 <<
	.uleb128 .Ltmp246-.Ltmp245              //   Call between .Ltmp245 and .Ltmp246
	.uleb128 .Ltmp247-.Lfunc_begin11        //     jumps to .Ltmp247
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp246-.Lfunc_begin11        // >> Call Site 12 <<
	.uleb128 .Ltmp248-.Ltmp246              //   Call between .Ltmp246 and .Ltmp248
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp248-.Lfunc_begin11        // >> Call Site 13 <<
	.uleb128 .Ltmp249-.Ltmp248              //   Call between .Ltmp248 and .Ltmp249
	.uleb128 .Ltmp250-.Lfunc_begin11        //     jumps to .Ltmp250
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp249-.Lfunc_begin11        // >> Call Site 14 <<
	.uleb128 .Lfunc_end77-.Ltmp249          //   Call between .Ltmp249 and .Lfunc_end77
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end11:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z18two_perlin_spheresv
.LCPI78_0:
	.xword	0x0000000000000000              // double 0
	.xword	0xc08f400000000000              // double -1000
.LCPI78_1:
	.xword	0x0000000000000000              // double 0
	.xword	0x408f400000000000              // double 1000
.LCPI78_2:
	.xword	0x0000000000000000              // double 0
	.xword	0x4000000000000000              // double 2
	.text
	.globl	_Z18two_perlin_spheresv
	.p2align	2
	.type	_Z18two_perlin_spheresv,@function
_Z18two_perlin_spheresv:                // @_Z18two_perlin_spheresv
.Lfunc_begin12:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception12
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x8
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	mov	x20, x19
	stp	xzr, xzr, [x19, #16]
	str	x8, [x19]
	str	xzr, [x20, #8]!
.Ltmp251:
	mov	w0, #64
	bl	_Znwm
.Ltmp252:
// %bb.1:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x9, _ZTV13noise_texture+16
	mov	x22, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x9, x9, :lo12:_ZTV13noise_texture+16
	mov	x26, x0
	str	d0, [x22, #8]
	str	x8, [x0], #24
	str	x9, [x26, #16]!
.Ltmp254:
	bl	_ZN6perlinC2Ev
.Ltmp255:
// %bb.2:
	mov	x8, #4616189618054758400
	stp	x26, x22, [x29, #-16]
	str	xzr, [sp, #16]
	str	x8, [x22, #56]
.Ltmp257:
	mov	w0, #40
	bl	_Znwm
.Ltmp258:
// %bb.3:
	adrp	x24, :got:__libc_single_threaded
	movi	v0.2s, #1
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x27, _ZTV10lambertian+16
	mov	x21, x0
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	add	x25, x0, #16
	add	x27, x27, :lo12:_ZTV10lambertian+16
	str	d0, [x0, #8]
	str	x28, [x0]
	ldrb	w8, [x24]
	cbz	w8, .LBB78_5
// %bb.4:
	ldr	w8, [x22, #8]
	stp	x27, x26, [x21, #16]
	str	x22, [x21, #32]
	add	w8, w8, #1
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB78_10
	b	.LBB78_13
.LBB78_5:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	stp	x27, x26, [x21, #16]
	str	x22, [x21, #32]
	cbz	w8, .LBB78_7
// %bb.6:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB78_10
	b	.LBB78_13
.LBB78_7:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB78_9
// %bb.8:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB78_10
	b	.LBB78_13
.LBB78_9:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_13
.LBB78_10:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_18
// %bb.11:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB78_13
.LBB78_12:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_13:
	stp	x25, x21, [sp, #16]
	str	xzr, [sp, #32]
.Ltmp260:
	mov	w0, #72
	bl	_Znwm
.Ltmp261:
// %bb.14:
	movi	v0.2s, #1
	adrp	x8, .LCPI78_0
	adrp	x9, .LCPI78_1
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x27, _ZTV6sphere+16
	mov	x22, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x26, x0
	str	d0, [x0, #8]
	ldr	q0, [x8, :lo12:.LCPI78_0]
	add	x27, x27, :lo12:_ZTV6sphere+16
	ldrb	w8, [x24]
	str	x23, [x0]
	stur	q0, [x0, #24]
	ldr	q0, [x9, :lo12:.LCPI78_1]
	str	x27, [x26, #16]!
	stp	xzr, xzr, [sp, #16]
	stur	q0, [x0, #40]
	stp	x25, x21, [x0, #56]
	cbz	w8, .LBB78_16
// %bb.15:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_20
	b	.LBB78_23
.LBB78_16:
	mov	x25, x23
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB78_19
// %bb.17:
	ldr	w0, [x21, #8]
	mov	x23, x25
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_20
	b	.LBB78_23
.LBB78_18:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_12
	b	.LBB78_13
.LBB78_19:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	mov	x23, x25
	cmp	w0, #1
	b.ne	.LBB78_23
.LBB78_20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_56
// %bb.21:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB78_23
.LBB78_22:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_23:
	ldp	x1, x8, [x19, #16]
	stp	x26, x22, [x29, #-32]
	stp	xzr, xzr, [sp, #32]
	cmp	x1, x8
	b.eq	.LBB78_26
// %bb.24:
	stp	x26, x22, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB78_30
// %bb.25:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-24]
	cbnz	x21, .LBB78_28
	b	.LBB78_35
.LBB78_26:
.Ltmp263:
	sub	x2, x29, #32
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp264:
// %bb.27:
	ldur	x21, [x29, #-24]
	cbz	x21, .LBB78_35
.LBB78_28:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_31
// %bb.29:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_32
	b	.LBB78_35
.LBB78_30:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-24]
	cbnz	x21, .LBB78_28
	b	.LBB78_35
.LBB78_31:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_35
.LBB78_32:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_57
// %bb.33:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB78_35
.LBB78_34:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_35:
	ldr	x21, [sp, #40]
	cbz	x21, .LBB78_42
// %bb.36:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_38
// %bb.37:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_39
	b	.LBB78_42
.LBB78_38:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_42
.LBB78_39:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_58
// %bb.40:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB78_42
.LBB78_41:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_42:
	ldr	x21, [sp, #24]
	cbz	x21, .LBB78_49
// %bb.43:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_45
// %bb.44:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_46
	b	.LBB78_49
.LBB78_45:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_49
.LBB78_46:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_59
// %bb.47:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB78_49
.LBB78_48:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_49:
	str	xzr, [sp, #16]
.Ltmp266:
	mov	w0, #40
	bl	_Znwm
.Ltmp267:
// %bb.50:
	ldp	x26, x22, [x29, #-16]
	movi	v0.2s, #1
	mov	x21, x0
	add	x25, x0, #16
	str	x28, [x0]
	str	d0, [x0, #8]
	cbz	x22, .LBB78_53
// %bb.51:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_54
// %bb.52:
	ldr	w8, [x22, #8]
	adrp	x9, _ZTV10lambertian+16
	add	x9, x9, :lo12:_ZTV10lambertian+16
	str	x22, [x21, #32]
	add	w8, w8, #1
	stp	x9, x26, [x21, #16]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB78_63
	b	.LBB78_66
.LBB78_53:
	adrp	x8, _ZTV10lambertian+16
	str	xzr, [x21, #32]
	add	x8, x8, :lo12:_ZTV10lambertian+16
	stp	x8, x26, [x21, #16]
	b	.LBB78_66
.LBB78_54:
	mov	x28, x23
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV10lambertian+16
	ldrb	w8, [x24]
	add	x9, x9, :lo12:_ZTV10lambertian+16
	str	x22, [x21, #32]
	stp	x9, x26, [x21, #16]
	cbz	w8, .LBB78_60
// %bb.55:
	ldr	w8, [x22, #8]
	mov	x23, x28
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB78_63
	b	.LBB78_66
.LBB78_56:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_22
	b	.LBB78_23
.LBB78_57:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_34
	b	.LBB78_35
.LBB78_58:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_41
	b	.LBB78_42
.LBB78_59:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_48
	b	.LBB78_49
.LBB78_60:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB78_62
// %bb.61:
	ldr	w0, [x22, #8]
	mov	x23, x28
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB78_63
	b	.LBB78_66
.LBB78_62:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	mov	x23, x28
	cmp	w0, #1
	b.ne	.LBB78_66
.LBB78_63:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_110
// %bb.64:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB78_66
.LBB78_65:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_66:
	stp	x25, x21, [sp, #16]
	str	xzr, [sp, #32]
.Ltmp269:
	mov	w0, #72
	bl	_Znwm
.Ltmp270:
// %bb.67:
	adrp	x8, .LCPI78_2
	movi	v0.2s, #1
	mov	x22, x0
	mov	x26, x0
	str	x23, [x0]
	ldr	q1, [x8, :lo12:.LCPI78_2]
	stp	xzr, xzr, [sp, #16]
	ldrb	w8, [x24]
	str	d0, [x0, #8]
	str	x27, [x26, #16]!
	stur	q1, [x0, #24]
	stur	q1, [x0, #40]
	stp	x25, x21, [x0, #56]
	cbz	w8, .LBB78_69
// %bb.68:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_72
	b	.LBB78_75
.LBB78_69:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB78_71
// %bb.70:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB78_72
	b	.LBB78_75
.LBB78_71:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_75
.LBB78_72:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_109
// %bb.73:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB78_75
.LBB78_74:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_75:
	ldp	x1, x8, [x19, #16]
	stp	x26, x22, [sp]
	stp	xzr, xzr, [sp, #32]
	cmp	x1, x8
	b.eq	.LBB78_78
// %bb.76:
	stp	x26, x22, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB78_82
// %bb.77:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB78_80
	b	.LBB78_87
.LBB78_78:
.Ltmp272:
	mov	x2, sp
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp273:
// %bb.79:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB78_87
.LBB78_80:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_83
// %bb.81:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB78_84
	b	.LBB78_87
.LBB78_82:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB78_80
	b	.LBB78_87
.LBB78_83:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_87
.LBB78_84:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_111
// %bb.85:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB78_87
.LBB78_86:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_87:
	ldr	x19, [sp, #40]
	cbz	x19, .LBB78_94
// %bb.88:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_90
// %bb.89:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB78_91
	b	.LBB78_94
.LBB78_90:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_94
.LBB78_91:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_112
// %bb.92:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB78_94
.LBB78_93:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_94:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB78_101
// %bb.95:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_97
// %bb.96:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB78_98
	b	.LBB78_101
.LBB78_97:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_101
.LBB78_98:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_113
// %bb.99:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB78_101
.LBB78_100:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_101:
	ldur	x19, [x29, #-8]
	cbz	x19, .LBB78_108
// %bb.102:
	ldrb	w8, [x24]
	cbz	w8, .LBB78_104
// %bb.103:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB78_105
	b	.LBB78_108
.LBB78_104:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB78_108
.LBB78_105:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB78_114
// %bb.106:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB78_108
.LBB78_107:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB78_108:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.LBB78_109:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_74
	b	.LBB78_75
.LBB78_110:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_65
	b	.LBB78_66
.LBB78_111:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_86
	b	.LBB78_87
.LBB78_112:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_93
	b	.LBB78_94
.LBB78_113:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_100
	b	.LBB78_101
.LBB78_114:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB78_107
	b	.LBB78_108
.LBB78_115:
.Ltmp274:
	mov	x20, x0
	mov	x0, sp
	b	.LBB78_117
.LBB78_116:
.Ltmp265:
	mov	x20, x0
	sub	x0, x29, #32
.LBB78_117:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #32
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB78_122
.LBB78_118:
.Ltmp271:
	b	.LBB78_121
.LBB78_119:
.Ltmp268:
	b	.LBB78_124
.LBB78_120:
.Ltmp262:
.LBB78_121:
	mov	x20, x0
.LBB78_122:
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #16
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB78_123:
.Ltmp259:
.LBB78_124:
	mov	x20, x0
	sub	x0, x29, #16
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB78_125:
.Ltmp256:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB78_126:
.Ltmp253:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end78:
	.size	_Z18two_perlin_spheresv, .Lfunc_end78-_Z18two_perlin_spheresv
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table78:
.Lexception12:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end12-.Lcst_begin12
.Lcst_begin12:
	.uleb128 .Ltmp251-.Lfunc_begin12        // >> Call Site 1 <<
	.uleb128 .Ltmp252-.Ltmp251              //   Call between .Ltmp251 and .Ltmp252
	.uleb128 .Ltmp253-.Lfunc_begin12        //     jumps to .Ltmp253
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp254-.Lfunc_begin12        // >> Call Site 2 <<
	.uleb128 .Ltmp255-.Ltmp254              //   Call between .Ltmp254 and .Ltmp255
	.uleb128 .Ltmp256-.Lfunc_begin12        //     jumps to .Ltmp256
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp257-.Lfunc_begin12        // >> Call Site 3 <<
	.uleb128 .Ltmp258-.Ltmp257              //   Call between .Ltmp257 and .Ltmp258
	.uleb128 .Ltmp259-.Lfunc_begin12        //     jumps to .Ltmp259
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp258-.Lfunc_begin12        // >> Call Site 4 <<
	.uleb128 .Ltmp260-.Ltmp258              //   Call between .Ltmp258 and .Ltmp260
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp260-.Lfunc_begin12        // >> Call Site 5 <<
	.uleb128 .Ltmp261-.Ltmp260              //   Call between .Ltmp260 and .Ltmp261
	.uleb128 .Ltmp262-.Lfunc_begin12        //     jumps to .Ltmp262
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp261-.Lfunc_begin12        // >> Call Site 6 <<
	.uleb128 .Ltmp263-.Ltmp261              //   Call between .Ltmp261 and .Ltmp263
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp263-.Lfunc_begin12        // >> Call Site 7 <<
	.uleb128 .Ltmp264-.Ltmp263              //   Call between .Ltmp263 and .Ltmp264
	.uleb128 .Ltmp265-.Lfunc_begin12        //     jumps to .Ltmp265
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp264-.Lfunc_begin12        // >> Call Site 8 <<
	.uleb128 .Ltmp266-.Ltmp264              //   Call between .Ltmp264 and .Ltmp266
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp266-.Lfunc_begin12        // >> Call Site 9 <<
	.uleb128 .Ltmp267-.Ltmp266              //   Call between .Ltmp266 and .Ltmp267
	.uleb128 .Ltmp268-.Lfunc_begin12        //     jumps to .Ltmp268
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp267-.Lfunc_begin12        // >> Call Site 10 <<
	.uleb128 .Ltmp269-.Ltmp267              //   Call between .Ltmp267 and .Ltmp269
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp269-.Lfunc_begin12        // >> Call Site 11 <<
	.uleb128 .Ltmp270-.Ltmp269              //   Call between .Ltmp269 and .Ltmp270
	.uleb128 .Ltmp271-.Lfunc_begin12        //     jumps to .Ltmp271
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp270-.Lfunc_begin12        // >> Call Site 12 <<
	.uleb128 .Ltmp272-.Ltmp270              //   Call between .Ltmp270 and .Ltmp272
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp272-.Lfunc_begin12        // >> Call Site 13 <<
	.uleb128 .Ltmp273-.Ltmp272              //   Call between .Ltmp272 and .Ltmp273
	.uleb128 .Ltmp274-.Lfunc_begin12        //     jumps to .Ltmp274
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp273-.Lfunc_begin12        // >> Call Site 14 <<
	.uleb128 .Lfunc_end78-.Ltmp273          //   Call between .Ltmp273 and .Lfunc_end78
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end12:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB79_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB79_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB79_4
	b	.LBB79_8
.LBB79_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB79_8
.LBB79_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB79_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB79_8
.LBB79_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB79_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB79_6
.LBB79_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end79:
	.size	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end79-_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.text
	.globl	_Z5earthv                       // -- Begin function _Z5earthv
	.p2align	2
	.type	_Z5earthv,@function
_Z5earthv:                              // @_Z5earthv
.Lfunc_begin13:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception13
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	stp	x26, x25, [sp, #80]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	mov	w0, #48
	mov	x19, x8
	bl	_Znwm
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp275:
	adrp	x1, .L.str.3
	mov	x0, x22
	add	x1, x1, :lo12:.L.str.3
	bl	_ZN13image_textureC2EPKc
.Ltmp276:
// %bb.1:
	stp	x22, x21, [x29, #-16]
	str	xzr, [sp, #32]
.Ltmp278:
	mov	w0, #40
	bl	_Znwm
.Ltmp279:
// %bb.2:
	adrp	x24, :got:__libc_single_threaded
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x26, _ZTV10lambertian+16
	mov	x20, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	add	x25, x0, #16
	add	x26, x26, :lo12:_ZTV10lambertian+16
	str	d0, [x0, #8]
	str	x8, [x0]
	ldrb	w9, [x24]
	cbz	w9, .LBB80_4
// %bb.3:
	ldr	w8, [x21, #8]
	stp	x26, x22, [x20, #16]
	str	x21, [x20, #32]
	add	w8, w8, #1
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB80_9
	b	.LBB80_12
.LBB80_4:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	stp	x26, x22, [x20, #16]
	str	x21, [x20, #32]
	cbz	w8, .LBB80_6
// %bb.5:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB80_9
	b	.LBB80_12
.LBB80_6:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB80_8
// %bb.7:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB80_9
	b	.LBB80_12
.LBB80_8:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB80_12
.LBB80_9:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB80_20
// %bb.10:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB80_12
.LBB80_11:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB80_12:
	stp	x25, x20, [sp, #32]
	str	xzr, [sp, #16]
.Ltmp281:
	mov	w0, #72
	bl	_Znwm
.Ltmp282:
// %bb.13:
	movi	v0.2s, #1
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	ldrb	w8, [x24]
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d0, [x0, #8]
	str	x9, [x0]
	cbz	w8, .LBB80_15
// %bb.14:
	ldr	w8, [x20, #8]
	add	w8, w8, #1
	str	w8, [x20, #8]
	b	.LBB80_16
.LBB80_15:
	add	x1, x20, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB80_16:
	adrp	x8, _ZTV6sphere+16
	ldrb	w9, [x24]
	add	x8, x8, :lo12:_ZTV6sphere+16
	add	x23, x21, #16
	stp	xzr, xzr, [x21, #32]
	str	x20, [x21, #64]
	stp	x8, xzr, [x21, #16]
	mov	x8, #4611686018427387904
	stp	x8, x25, [x21, #48]
	cbz	w9, .LBB80_18
// %bb.17:
	ldr	w8, [x20, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB80_22
	b	.LBB80_25
.LBB80_18:
	add	x22, x20, #8
	mov	w0, #1
	mov	x1, x22
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB80_21
// %bb.19:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB80_22
	b	.LBB80_25
.LBB80_20:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB80_11
	b	.LBB80_12
.LBB80_21:
	mov	w0, #-1
	mov	x1, x22
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB80_25
.LBB80_22:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB80_58
// %bb.23:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB80_25
.LBB80_24:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB80_25:
	ldrb	w8, [x24]
	stp	x23, x21, [sp, #16]
	stp	x23, x21, [sp]
	cbz	w8, .LBB80_27
// %bb.26:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	b	.LBB80_28
.LBB80_27:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB80_28:
.Ltmp284:
	mov	x1, sp
	mov	x0, x19
	bl	_ZN13hittable_listC2ESt10shared_ptrI8hittableE
.Ltmp285:
// %bb.29:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB80_36
// %bb.30:
	ldrb	w8, [x24]
	cbz	w8, .LBB80_32
// %bb.31:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB80_33
	b	.LBB80_36
.LBB80_32:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB80_36
.LBB80_33:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB80_59
// %bb.34:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB80_36
.LBB80_35:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB80_36:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB80_43
// %bb.37:
	ldrb	w8, [x24]
	cbz	w8, .LBB80_39
// %bb.38:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB80_40
	b	.LBB80_43
.LBB80_39:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB80_43
.LBB80_40:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB80_60
// %bb.41:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB80_43
.LBB80_42:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB80_43:
	ldr	x19, [sp, #40]
	cbz	x19, .LBB80_50
// %bb.44:
	ldrb	w8, [x24]
	cbz	w8, .LBB80_46
// %bb.45:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB80_47
	b	.LBB80_50
.LBB80_46:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB80_50
.LBB80_47:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB80_61
// %bb.48:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB80_50
.LBB80_49:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB80_50:
	ldur	x19, [x29, #-8]
	cbz	x19, .LBB80_57
// %bb.51:
	ldrb	w8, [x24]
	cbz	w8, .LBB80_53
// %bb.52:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB80_54
	b	.LBB80_57
.LBB80_53:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB80_57
.LBB80_54:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB80_62
// %bb.55:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB80_57
.LBB80_56:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB80_57:
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	add	sp, sp, #144
	ret
.LBB80_58:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB80_24
	b	.LBB80_25
.LBB80_59:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB80_35
	b	.LBB80_36
.LBB80_60:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB80_42
	b	.LBB80_43
.LBB80_61:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB80_49
	b	.LBB80_50
.LBB80_62:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB80_56
	b	.LBB80_57
.LBB80_63:
.Ltmp286:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB80_65
.LBB80_64:
.Ltmp283:
	mov	x19, x0
.LBB80_65:
	add	x0, sp, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB80_67
.LBB80_66:
.Ltmp280:
	mov	x19, x0
.LBB80_67:
	sub	x0, x29, #16
	bl	_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.LBB80_68:
.Ltmp277:
	mov	x19, x0
	mov	x0, x21
	bl	_ZdlPv
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end80:
	.size	_Z5earthv, .Lfunc_end80-_Z5earthv
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table80:
.Lexception13:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end13-.Lcst_begin13
.Lcst_begin13:
	.uleb128 .Lfunc_begin13-.Lfunc_begin13  // >> Call Site 1 <<
	.uleb128 .Ltmp275-.Lfunc_begin13        //   Call between .Lfunc_begin13 and .Ltmp275
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp275-.Lfunc_begin13        // >> Call Site 2 <<
	.uleb128 .Ltmp276-.Ltmp275              //   Call between .Ltmp275 and .Ltmp276
	.uleb128 .Ltmp277-.Lfunc_begin13        //     jumps to .Ltmp277
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp278-.Lfunc_begin13        // >> Call Site 3 <<
	.uleb128 .Ltmp279-.Ltmp278              //   Call between .Ltmp278 and .Ltmp279
	.uleb128 .Ltmp280-.Lfunc_begin13        //     jumps to .Ltmp280
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp279-.Lfunc_begin13        // >> Call Site 4 <<
	.uleb128 .Ltmp281-.Ltmp279              //   Call between .Ltmp279 and .Ltmp281
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp281-.Lfunc_begin13        // >> Call Site 5 <<
	.uleb128 .Ltmp282-.Ltmp281              //   Call between .Ltmp281 and .Ltmp282
	.uleb128 .Ltmp283-.Lfunc_begin13        //     jumps to .Ltmp283
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp282-.Lfunc_begin13        // >> Call Site 6 <<
	.uleb128 .Ltmp284-.Ltmp282              //   Call between .Ltmp282 and .Ltmp284
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp284-.Lfunc_begin13        // >> Call Site 7 <<
	.uleb128 .Ltmp285-.Ltmp284              //   Call between .Ltmp284 and .Ltmp285
	.uleb128 .Ltmp286-.Lfunc_begin13        //     jumps to .Ltmp286
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp285-.Lfunc_begin13        // >> Call Site 8 <<
	.uleb128 .Lfunc_end80-.Ltmp285          //   Call between .Ltmp285 and .Lfunc_end80
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end13:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB81_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB81_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB81_4
	b	.LBB81_8
.LBB81_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB81_8
.LBB81_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB81_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB81_8
.LBB81_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB81_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB81_6
.LBB81_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end81:
	.size	_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end81-_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z12simple_lightv
.LCPI82_0:
	.xword	0x0000000000000000              // double 0
	.xword	0xc08f400000000000              // double -1000
.LCPI82_1:
	.xword	0x0000000000000000              // double 0
	.xword	0x408f400000000000              // double 1000
.LCPI82_2:
	.xword	0x0000000000000000              // double 0
	.xword	0x4000000000000000              // double 2
.LCPI82_3:
	.xword	0x0000000000000000              // double 0
	.xword	0x401c000000000000              // double 7
	.text
	.globl	_Z12simple_lightv
	.p2align	2
	.type	_Z12simple_lightv,@function
_Z12simple_lightv:                      // @_Z12simple_lightv
.Lfunc_begin14:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception14
// %bb.0:
	sub	sp, sp, #272
	str	d8, [sp, #160]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #176]            // 16-byte Folded Spill
	add	x29, sp, #176
	stp	x28, x27, [sp, #192]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #208]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #224]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	mov	x19, x8
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	mov	x20, x19
	stp	xzr, xzr, [x19, #16]
	str	x8, [x19]
	str	xzr, [x20, #8]!
.Ltmp287:
	mov	w0, #64
	bl	_Znwm
.Ltmp288:
// %bb.1:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x9, _ZTV13noise_texture+16
	mov	x22, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x9, x9, :lo12:_ZTV13noise_texture+16
	mov	x26, x0
	str	d0, [x22, #8]
	str	x8, [x0], #24
	str	x9, [x26, #16]!
.Ltmp290:
	bl	_ZN6perlinC2Ev
.Ltmp291:
// %bb.2:
	mov	x8, #4616189618054758400
	stp	x26, x22, [x29, #-40]
	str	xzr, [sp, #88]
	str	x8, [x22, #56]
.Ltmp293:
	mov	w0, #40
	bl	_Znwm
.Ltmp294:
// %bb.3:
	adrp	x24, :got:__libc_single_threaded
	movi	v0.2s, #1
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x27, _ZTV10lambertian+16
	mov	x21, x0
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	add	x25, x0, #16
	add	x27, x27, :lo12:_ZTV10lambertian+16
	str	d0, [x0, #8]
	str	x28, [x0]
	ldrb	w8, [x24]
	cbz	w8, .LBB82_5
// %bb.4:
	ldr	w8, [x22, #8]
	stp	x27, x26, [x21, #16]
	str	x22, [x21, #32]
	add	w8, w8, #1
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB82_10
	b	.LBB82_13
.LBB82_5:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	stp	x27, x26, [x21, #16]
	str	x22, [x21, #32]
	cbz	w8, .LBB82_7
// %bb.6:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB82_10
	b	.LBB82_13
.LBB82_7:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB82_9
// %bb.8:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB82_10
	b	.LBB82_13
.LBB82_9:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_13
.LBB82_10:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_18
// %bb.11:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB82_13
.LBB82_12:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_13:
	stp	x25, x21, [sp, #88]
	stur	xzr, [x29, #-72]
.Ltmp296:
	mov	w0, #72
	bl	_Znwm
.Ltmp297:
// %bb.14:
	movi	v0.2s, #1
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x8, .LCPI82_0
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x26, x0
	mov	x22, x0
	stp	xzr, xzr, [sp, #88]
	str	d0, [x0, #8]
	ldr	q0, [x8, :lo12:.LCPI82_0]
	adrp	x8, _ZTV6sphere+16
	str	x9, [x0]
	adrp	x9, .LCPI82_1
	add	x8, x8, :lo12:_ZTV6sphere+16
	stur	q0, [x0, #24]
	stp	x25, x21, [x0, #56]
	str	x8, [x26, #16]!
	ldr	q0, [x9, :lo12:.LCPI82_1]
	ldrb	w8, [x24]
	stur	q0, [x0, #40]
	cbz	w8, .LBB82_16
// %bb.15:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_20
	b	.LBB82_23
.LBB82_16:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB82_19
// %bb.17:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_20
	b	.LBB82_23
.LBB82_18:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_12
	b	.LBB82_13
.LBB82_19:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_23
.LBB82_20:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_59
// %bb.21:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_23
.LBB82_22:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_23:
	ldp	x1, x8, [x19, #16]
	stp	x26, x22, [x29, #-56]
	stp	xzr, xzr, [x29, #-72]
	cmp	x1, x8
	b.eq	.LBB82_26
// %bb.24:
	stp	x26, x22, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB82_30
// %bb.25:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-48]
	cbnz	x21, .LBB82_28
	b	.LBB82_35
.LBB82_26:
.Ltmp299:
	sub	x2, x29, #56
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp300:
// %bb.27:
	ldur	x21, [x29, #-48]
	cbz	x21, .LBB82_35
.LBB82_28:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_31
// %bb.29:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_32
	b	.LBB82_35
.LBB82_30:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-48]
	cbnz	x21, .LBB82_28
	b	.LBB82_35
.LBB82_31:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_35
.LBB82_32:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_60
// %bb.33:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_35
.LBB82_34:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_35:
	ldur	x21, [x29, #-64]
	cbz	x21, .LBB82_42
// %bb.36:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_38
// %bb.37:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_39
	b	.LBB82_42
.LBB82_38:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_42
.LBB82_39:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_61
// %bb.40:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_42
.LBB82_41:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_42:
	ldr	x21, [sp, #96]
	cbz	x21, .LBB82_49
// %bb.43:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_45
// %bb.44:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_46
	b	.LBB82_49
.LBB82_45:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_49
.LBB82_46:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_62
// %bb.47:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_49
.LBB82_48:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_49:
	str	xzr, [sp, #88]
.Ltmp302:
	mov	w0, #40
	bl	_Znwm
.Ltmp303:
// %bb.50:
	ldp	x26, x22, [x29, #-40]
	movi	v0.2s, #1
	mov	x21, x0
	add	x25, x0, #16
	str	x28, [x0]
	str	d0, [x0, #8]
	cbz	x22, .LBB82_53
// %bb.51:
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldrb	w8, [x24]
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	cbz	w8, .LBB82_54
// %bb.52:
	ldr	w8, [x22, #8]
	stp	x27, x26, [x21, #16]
	str	x22, [x21, #32]
	add	w8, w8, #1
	b	.LBB82_56
.LBB82_53:
	stp	x27, x26, [x21, #16]
	adrp	x27, _ZTV6sphere+16
	adrp	x28, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	xzr, [x21, #32]
	add	x27, x27, :lo12:_ZTV6sphere+16
	add	x28, x28, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	b	.LBB82_65
.LBB82_54:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	stp	x27, x26, [x21, #16]
	str	x22, [x21, #32]
	cbz	w8, .LBB82_116
// %bb.55:
	ldr	w8, [x22, #8]
.LBB82_56:
	adrp	x27, _ZTV6sphere+16
	add	w0, w8, #1
	add	x27, x27, :lo12:_ZTV6sphere+16
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.ne	.LBB82_65
.LBB82_57:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_63
// %bb.58:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.eq	.LBB82_64
	b	.LBB82_65
.LBB82_59:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_22
	b	.LBB82_23
.LBB82_60:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_34
	b	.LBB82_35
.LBB82_61:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_41
	b	.LBB82_42
.LBB82_62:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_48
	b	.LBB82_49
.LBB82_63:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_65
.LBB82_64:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_65:
	stp	x25, x21, [sp, #88]
	stur	xzr, [x29, #-72]
.Ltmp305:
	mov	w0, #72
	bl	_Znwm
.Ltmp306:
// %bb.66:
	adrp	x8, .LCPI82_2
	movi	v0.2s, #1
	mov	x22, x0
	mov	x26, x0
	str	x28, [x0]
	ldr	q1, [x8, :lo12:.LCPI82_2]
	stp	xzr, xzr, [sp, #88]
	ldrb	w8, [x24]
	str	d0, [x0, #8]
	str	x27, [x26, #16]!
	stur	q1, [x0, #24]
	str	q1, [sp]                        // 16-byte Folded Spill
	stur	q1, [x0, #40]
	stp	x25, x21, [x0, #56]
	cbz	w8, .LBB82_68
// %bb.67:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_71
	b	.LBB82_74
.LBB82_68:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB82_70
// %bb.69:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_71
	b	.LBB82_74
.LBB82_70:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_74
.LBB82_71:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_112
// %bb.72:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_74
.LBB82_73:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_74:
	ldp	x1, x8, [x19, #16]
	stp	x26, x22, [sp, #72]
	stp	xzr, xzr, [x29, #-72]
	cmp	x1, x8
	b.eq	.LBB82_77
// %bb.75:
	stp	x26, x22, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB82_81
// %bb.76:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #80]
	cbnz	x21, .LBB82_79
	b	.LBB82_86
.LBB82_77:
.Ltmp308:
	add	x2, sp, #72
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp309:
// %bb.78:
	ldr	x21, [sp, #80]
	cbz	x21, .LBB82_86
.LBB82_79:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_82
// %bb.80:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_83
	b	.LBB82_86
.LBB82_81:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #80]
	cbnz	x21, .LBB82_79
	b	.LBB82_86
.LBB82_82:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_86
.LBB82_83:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_113
// %bb.84:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_86
.LBB82_85:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_86:
	ldur	x21, [x29, #-64]
	cbz	x21, .LBB82_93
// %bb.87:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_89
// %bb.88:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_90
	b	.LBB82_93
.LBB82_89:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_93
.LBB82_90:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_114
// %bb.91:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_93
.LBB82_92:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_93:
	ldr	x21, [sp, #96]
	cbz	x21, .LBB82_100
// %bb.94:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_96
// %bb.95:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_97
	b	.LBB82_100
.LBB82_96:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_100
.LBB82_97:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_115
// %bb.98:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_100
.LBB82_99:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_100:
	stur	xzr, [x29, #-72]
.Ltmp311:
	mov	w0, #40
	bl	_Znwm
.Ltmp312:
// %bb.101:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x22, x0
	str	x8, [x0]
	adrp	x8, _ZTV13diffuse_light+16
	add	x8, x8, :lo12:_ZTV13diffuse_light+16
	str	d8, [x0, #8]
	str	x8, [x22, #16]!
.Ltmp314:
	mov	w0, #48
	bl	_Znwm
.Ltmp315:
// %bb.102:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x10, _ZTV11solid_color+16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x9, x0
	fmov	v0.2d, #4.00000000
	add	x10, x10, :lo12:_ZTV11solid_color+16
	str	d8, [x0, #8]
	str	x8, [x0]
	mov	x8, #4616189618054758400
	str	x10, [x9, #16]!
	stur	q0, [x0, #24]
	str	x8, [x0, #40]
	stp	x9, x0, [x21, #24]
	stp	x22, x21, [x29, #-72]
	str	xzr, [sp, #88]
.Ltmp317:
	mov	w0, #72
	bl	_Znwm
.Ltmp318:
// %bb.103:
	ldp	x23, x22, [x29, #-72]
	movi	v0.2s, #1
	mov	x21, x0
	add	x25, x0, #16
	str	x28, [x0]
	str	d0, [x0, #8]
	cbz	x22, .LBB82_107
// %bb.104:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_106
// %bb.105:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB82_107
.LBB82_106:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB82_107:
	adrp	x8, .LCPI82_3
	ldr	q1, [sp]                        // 16-byte Folded Reload
	str	x27, [x21, #16]
	stp	x23, x22, [x21, #56]
	ldr	q0, [x8, :lo12:.LCPI82_3]
	stur	q1, [x21, #40]
	stur	q0, [x21, #24]
	cbz	x22, .LBB82_122
// %bb.108:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_110
// %bb.109:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB82_119
	b	.LBB82_122
.LBB82_110:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB82_118
// %bb.111:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB82_119
	b	.LBB82_122
.LBB82_112:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_73
	b	.LBB82_74
.LBB82_113:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_85
	b	.LBB82_86
.LBB82_114:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_92
	b	.LBB82_93
.LBB82_115:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_99
	b	.LBB82_100
.LBB82_116:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	adrp	x27, _ZTV6sphere+16
	ldrb	w8, [x24]
	add	x27, x27, :lo12:_ZTV6sphere+16
	cbz	w8, .LBB82_184
// %bb.117:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB82_57
	b	.LBB82_65
.LBB82_118:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_122
.LBB82_119:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_177
// %bb.120:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB82_122
.LBB82_121:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_122:
	ldp	x1, x8, [x19, #16]
	stp	x25, x21, [sp, #56]
	stp	xzr, xzr, [sp, #88]
	cmp	x1, x8
	b.eq	.LBB82_125
// %bb.123:
	stp	x25, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB82_129
// %bb.124:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #64]
	cbnz	x21, .LBB82_127
	b	.LBB82_134
.LBB82_125:
.Ltmp320:
	add	x2, sp, #56
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp321:
// %bb.126:
	ldr	x21, [sp, #64]
	cbz	x21, .LBB82_134
.LBB82_127:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_130
// %bb.128:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_131
	b	.LBB82_134
.LBB82_129:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #64]
	cbnz	x21, .LBB82_127
	b	.LBB82_134
.LBB82_130:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_134
.LBB82_131:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_178
// %bb.132:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_134
.LBB82_133:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_134:
	ldr	x21, [sp, #96]
	cbz	x21, .LBB82_141
// %bb.135:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_137
// %bb.136:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB82_138
	b	.LBB82_141
.LBB82_137:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_141
.LBB82_138:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_179
// %bb.139:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB82_141
.LBB82_140:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_141:
	mov	w8, #3
	mov	w9, #5
	mov	w10, #1
	mov	w11, #-2
	stur	w8, [x29, #-4]
	stp	w10, w9, [sp, #32]
	stp	w11, w8, [sp, #24]
.Ltmp323:
	mov	w0, #80
	bl	_Znwm
.Ltmp324:
// %bb.142:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp326:
	sub	x0, x29, #8
	sub	x2, x29, #4
	add	x3, sp, #36
	add	x4, sp, #32
	add	x5, sp, #28
	add	x6, sp, #24
	sub	x7, x29, #72
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
.Ltmp327:
// %bb.143:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #40]
	stp	xzr, xzr, [sp, #88]
	cmp	x1, x8
	b.eq	.LBB82_146
// %bb.144:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB82_150
// %bb.145:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #48]
	cbnz	x19, .LBB82_148
	b	.LBB82_155
.LBB82_146:
.Ltmp329:
	add	x2, sp, #40
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp330:
// %bb.147:
	ldr	x19, [sp, #48]
	cbz	x19, .LBB82_155
.LBB82_148:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_151
// %bb.149:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB82_152
	b	.LBB82_155
.LBB82_150:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #48]
	cbnz	x19, .LBB82_148
	b	.LBB82_155
.LBB82_151:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_155
.LBB82_152:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_180
// %bb.153:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB82_155
.LBB82_154:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_155:
	ldr	x19, [sp, #96]
	cbz	x19, .LBB82_162
// %bb.156:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_158
// %bb.157:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB82_159
	b	.LBB82_162
.LBB82_158:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_162
.LBB82_159:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_181
// %bb.160:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB82_162
.LBB82_161:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_162:
	ldur	x19, [x29, #-64]
	cbz	x19, .LBB82_169
// %bb.163:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_165
// %bb.164:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB82_166
	b	.LBB82_169
.LBB82_165:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_169
.LBB82_166:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_182
// %bb.167:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB82_169
.LBB82_168:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_169:
	ldur	x19, [x29, #-32]
	cbz	x19, .LBB82_176
// %bb.170:
	ldrb	w8, [x24]
	cbz	w8, .LBB82_172
// %bb.171:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB82_173
	b	.LBB82_176
.LBB82_172:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB82_176
.LBB82_173:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB82_183
// %bb.174:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB82_176
.LBB82_175:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB82_176:
	ldp	x20, x19, [sp, #256]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #176]            // 16-byte Folded Reload
	ldr	d8, [sp, #160]                  // 8-byte Folded Reload
	add	sp, sp, #272
	ret
.LBB82_177:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_121
	b	.LBB82_122
.LBB82_178:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_133
	b	.LBB82_134
.LBB82_179:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_140
	b	.LBB82_141
.LBB82_180:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_154
	b	.LBB82_155
.LBB82_181:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_161
	b	.LBB82_162
.LBB82_182:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_168
	b	.LBB82_169
.LBB82_183:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_175
	b	.LBB82_176
.LBB82_184:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB82_57
	b	.LBB82_65
.LBB82_185:
.Ltmp331:
	mov	x20, x0
	add	x0, sp, #40
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #88
	bl	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB82_194
.LBB82_186:
.Ltmp322:
	mov	x20, x0
	add	x0, sp, #56
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #88
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB82_194
.LBB82_187:
.Ltmp310:
	mov	x20, x0
	add	x0, sp, #72
	b	.LBB82_189
.LBB82_188:
.Ltmp301:
	mov	x20, x0
	sub	x0, x29, #56
.LBB82_189:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #72
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB82_201
.LBB82_190:
.Ltmp328:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB82_194
.LBB82_191:
.Ltmp325:
	b	.LBB82_193
.LBB82_192:
.Ltmp319:
.LBB82_193:
	mov	x20, x0
.LBB82_194:
	sub	x0, x29, #72
	bl	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB82_195:
.Ltmp316:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB82_196:
.Ltmp313:
	b	.LBB82_203
.LBB82_197:
.Ltmp307:
	b	.LBB82_200
.LBB82_198:
.Ltmp304:
	b	.LBB82_203
.LBB82_199:
.Ltmp298:
.LBB82_200:
	mov	x20, x0
.LBB82_201:
	add	x0, sp, #88
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB82_202:
.Ltmp295:
.LBB82_203:
	mov	x20, x0
	sub	x0, x29, #40
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB82_204:
.Ltmp292:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB82_205:
.Ltmp289:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end82:
	.size	_Z12simple_lightv, .Lfunc_end82-_Z12simple_lightv
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table82:
.Lexception14:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end14-.Lcst_begin14
.Lcst_begin14:
	.uleb128 .Ltmp287-.Lfunc_begin14        // >> Call Site 1 <<
	.uleb128 .Ltmp288-.Ltmp287              //   Call between .Ltmp287 and .Ltmp288
	.uleb128 .Ltmp289-.Lfunc_begin14        //     jumps to .Ltmp289
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp290-.Lfunc_begin14        // >> Call Site 2 <<
	.uleb128 .Ltmp291-.Ltmp290              //   Call between .Ltmp290 and .Ltmp291
	.uleb128 .Ltmp292-.Lfunc_begin14        //     jumps to .Ltmp292
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp293-.Lfunc_begin14        // >> Call Site 3 <<
	.uleb128 .Ltmp294-.Ltmp293              //   Call between .Ltmp293 and .Ltmp294
	.uleb128 .Ltmp295-.Lfunc_begin14        //     jumps to .Ltmp295
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp294-.Lfunc_begin14        // >> Call Site 4 <<
	.uleb128 .Ltmp296-.Ltmp294              //   Call between .Ltmp294 and .Ltmp296
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp296-.Lfunc_begin14        // >> Call Site 5 <<
	.uleb128 .Ltmp297-.Ltmp296              //   Call between .Ltmp296 and .Ltmp297
	.uleb128 .Ltmp298-.Lfunc_begin14        //     jumps to .Ltmp298
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp297-.Lfunc_begin14        // >> Call Site 6 <<
	.uleb128 .Ltmp299-.Ltmp297              //   Call between .Ltmp297 and .Ltmp299
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp299-.Lfunc_begin14        // >> Call Site 7 <<
	.uleb128 .Ltmp300-.Ltmp299              //   Call between .Ltmp299 and .Ltmp300
	.uleb128 .Ltmp301-.Lfunc_begin14        //     jumps to .Ltmp301
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp300-.Lfunc_begin14        // >> Call Site 8 <<
	.uleb128 .Ltmp302-.Ltmp300              //   Call between .Ltmp300 and .Ltmp302
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp302-.Lfunc_begin14        // >> Call Site 9 <<
	.uleb128 .Ltmp303-.Ltmp302              //   Call between .Ltmp302 and .Ltmp303
	.uleb128 .Ltmp304-.Lfunc_begin14        //     jumps to .Ltmp304
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp303-.Lfunc_begin14        // >> Call Site 10 <<
	.uleb128 .Ltmp305-.Ltmp303              //   Call between .Ltmp303 and .Ltmp305
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp305-.Lfunc_begin14        // >> Call Site 11 <<
	.uleb128 .Ltmp306-.Ltmp305              //   Call between .Ltmp305 and .Ltmp306
	.uleb128 .Ltmp307-.Lfunc_begin14        //     jumps to .Ltmp307
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp306-.Lfunc_begin14        // >> Call Site 12 <<
	.uleb128 .Ltmp308-.Ltmp306              //   Call between .Ltmp306 and .Ltmp308
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp308-.Lfunc_begin14        // >> Call Site 13 <<
	.uleb128 .Ltmp309-.Ltmp308              //   Call between .Ltmp308 and .Ltmp309
	.uleb128 .Ltmp310-.Lfunc_begin14        //     jumps to .Ltmp310
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp309-.Lfunc_begin14        // >> Call Site 14 <<
	.uleb128 .Ltmp311-.Ltmp309              //   Call between .Ltmp309 and .Ltmp311
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp311-.Lfunc_begin14        // >> Call Site 15 <<
	.uleb128 .Ltmp312-.Ltmp311              //   Call between .Ltmp311 and .Ltmp312
	.uleb128 .Ltmp313-.Lfunc_begin14        //     jumps to .Ltmp313
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp314-.Lfunc_begin14        // >> Call Site 16 <<
	.uleb128 .Ltmp315-.Ltmp314              //   Call between .Ltmp314 and .Ltmp315
	.uleb128 .Ltmp316-.Lfunc_begin14        //     jumps to .Ltmp316
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp317-.Lfunc_begin14        // >> Call Site 17 <<
	.uleb128 .Ltmp318-.Ltmp317              //   Call between .Ltmp317 and .Ltmp318
	.uleb128 .Ltmp319-.Lfunc_begin14        //     jumps to .Ltmp319
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp318-.Lfunc_begin14        // >> Call Site 18 <<
	.uleb128 .Ltmp320-.Ltmp318              //   Call between .Ltmp318 and .Ltmp320
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp320-.Lfunc_begin14        // >> Call Site 19 <<
	.uleb128 .Ltmp321-.Ltmp320              //   Call between .Ltmp320 and .Ltmp321
	.uleb128 .Ltmp322-.Lfunc_begin14        //     jumps to .Ltmp322
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp321-.Lfunc_begin14        // >> Call Site 20 <<
	.uleb128 .Ltmp323-.Ltmp321              //   Call between .Ltmp321 and .Ltmp323
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp323-.Lfunc_begin14        // >> Call Site 21 <<
	.uleb128 .Ltmp324-.Ltmp323              //   Call between .Ltmp323 and .Ltmp324
	.uleb128 .Ltmp325-.Lfunc_begin14        //     jumps to .Ltmp325
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp326-.Lfunc_begin14        // >> Call Site 22 <<
	.uleb128 .Ltmp327-.Ltmp326              //   Call between .Ltmp326 and .Ltmp327
	.uleb128 .Ltmp328-.Lfunc_begin14        //     jumps to .Ltmp328
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp329-.Lfunc_begin14        // >> Call Site 23 <<
	.uleb128 .Ltmp330-.Ltmp329              //   Call between .Ltmp329 and .Ltmp330
	.uleb128 .Ltmp331-.Lfunc_begin14        //     jumps to .Ltmp331
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp330-.Lfunc_begin14        // >> Call Site 24 <<
	.uleb128 .Lfunc_end82-.Ltmp330          //   Call between .Ltmp330 and .Lfunc_end82
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end14:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB83_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB83_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB83_4
	b	.LBB83_8
.LBB83_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB83_8
.LBB83_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB83_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB83_8
.LBB83_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB83_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB83_6
.LBB83_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end83:
	.size	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end83-_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z11cornell_boxv
.LCPI84_0:
	.xword	0x3fe4cccccccccccd              // double 0.65000000000000002
	.xword	0x3fa999999999999a              // double 0.050000000000000003
.LCPI84_1:
	.xword	0x3fbeb851eb851eb8              // double 0.12
	.xword	0x3fdccccccccccccd              // double 0.45000000000000001
.LCPI84_2:
	.xword	0x4064a00000000000              // double 165
	.xword	0x4074a00000000000              // double 330
.LCPI84_3:
	.xword	0x4070900000000000              // double 265
	.xword	0x0000000000000000              // double 0
.LCPI84_4:
	.xword	0x4060400000000000              // double 130
	.xword	0x0000000000000000              // double 0
	.text
	.globl	_Z11cornell_boxv
	.p2align	2
	.type	_Z11cornell_boxv,@function
_Z11cornell_boxv:                       // @_Z11cornell_boxv
.Lfunc_begin15:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception15
// %bb.0:
	sub	sp, sp, #400
	str	d8, [sp, #304]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #312]            // 16-byte Folded Spill
	add	x29, sp, #312
	str	x28, [sp, #328]                 // 8-byte Folded Spill
	stp	x26, x25, [sp, #336]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #352]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #368]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #384]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 88
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w28, -72
	.cfi_offset w30, -80
	.cfi_offset w29, -88
	.cfi_offset b8, -96
	mov	x19, x8
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	mov	x20, x19
	stp	xzr, xzr, [x19, #16]
	str	x8, [x19]
	str	xzr, [x20, #8]!
.Ltmp332:
	mov	w0, #40
	bl	_Znwm
.Ltmp333:
// %bb.1:
	movi	v8.2s, #1
	adrp	x24, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x25, _ZTV10lambertian+16
	mov	x21, x0
	add	x24, x24, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x26, x0
	add	x25, x25, :lo12:_ZTV10lambertian+16
	str	d8, [x0, #8]
	str	x24, [x0]
	str	x25, [x26, #16]!
.Ltmp335:
	mov	w0, #48
	bl	_Znwm
.Ltmp336:
// %bb.2:
	adrp	x8, .LCPI84_0
	mov	x10, #-7378697629483820647
	adrp	x22, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movk	x10, #39322
	adrp	x23, _ZTV11solid_color+16
	add	x22, x22, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x9, x0
	movk	x10, #16297, lsl #48
	ldr	q0, [x8, :lo12:.LCPI84_0]
	add	x23, x23, :lo12:_ZTV11solid_color+16
	str	d8, [x0, #8]
	str	x22, [x0]
	str	x23, [x9, #16]!
	str	x10, [x0, #40]
	stur	q0, [x0, #24]
	stp	x9, x0, [x21, #24]
	stp	x26, x21, [x29, #-32]
	stur	xzr, [x29, #-48]
.Ltmp338:
	mov	w0, #40
	bl	_Znwm
.Ltmp339:
// %bb.3:
	movi	v8.2s, #1
	mov	x21, x0
	mov	x26, x0
	str	x24, [x0]
	str	d8, [x0, #8]
	str	x25, [x26, #16]!
.Ltmp341:
	mov	w0, #48
	bl	_Znwm
.Ltmp342:
// %bb.4:
	mov	x9, #36700
	mov	x8, x0
	movk	x9, #62914, lsl #16
	str	d8, [x0, #8]
	movk	x9, #23592, lsl #32
	str	x22, [x0]
	movk	x9, #16359, lsl #48
	stp	x26, x21, [x29, #-48]
	str	x23, [x8, #16]!
	stp	x8, x0, [x21, #24]
	dup	v0.2d, x9
	str	x9, [x0, #40]
	stur	xzr, [x29, #-64]
	stur	q0, [x0, #24]
.Ltmp344:
	mov	w0, #40
	bl	_Znwm
.Ltmp345:
// %bb.5:
	movi	v8.2s, #1
	mov	x21, x0
	mov	x26, x0
	str	x24, [x0]
	str	d8, [x0, #8]
	str	x25, [x26, #16]!
.Ltmp347:
	mov	w0, #48
	bl	_Znwm
.Ltmp348:
// %bb.6:
	adrp	x9, .LCPI84_1
	mov	x10, #3689348814741910323
	mov	x8, x0
	movk	x10, #16323, lsl #48
	str	d8, [x0, #8]
	ldr	q0, [x9, :lo12:.LCPI84_1]
	str	x22, [x0]
	str	x23, [x8, #16]!
	str	x10, [x0, #40]
	stp	x8, x0, [x21, #24]
	stur	q0, [x0, #24]
	stp	x26, x21, [x29, #-64]
	stur	xzr, [x29, #-80]
.Ltmp350:
	mov	w0, #40
	bl	_Znwm
.Ltmp351:
// %bb.7:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x24, x0
	str	x8, [x0]
	adrp	x8, _ZTV13diffuse_light+16
	add	x8, x8, :lo12:_ZTV13diffuse_light+16
	str	d8, [x0, #8]
	str	x8, [x24, #16]!
.Ltmp353:
	mov	w0, #48
	bl	_Znwm
.Ltmp354:
// %bb.8:
	mov	x8, x0
	mov	x9, #4624633867356078080
	fmov	v0.2d, #15.00000000
	str	d8, [x0, #8]
	str	x22, [x0]
	str	x23, [x8, #16]!
	stp	x8, x0, [x21, #24]
	mov	w8, #555
	str	x9, [x0, #40]
	stur	q0, [x0, #24]
	stp	x24, x21, [x29, #-80]
	str	wzr, [sp, #48]
	str	w8, [sp, #104]
	str	wzr, [sp, #16]
	stp	w8, w8, [x29, #-108]
.Ltmp356:
	mov	w0, #80
	bl	_Znwm
.Ltmp357:
// %bb.9:
	movi	v0.2s, #1
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x23, [x0]
.Ltmp359:
	sub	x0, x29, #16
	add	x2, sp, #48
	add	x3, sp, #104
	add	x4, sp, #16
	sub	x5, x29, #104
	sub	x6, x29, #108
	sub	x7, x29, #64
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp360:
// %bb.10:
	ldp	x1, x8, [x19, #16]
	adrp	x24, :got:__libc_single_threaded
	stp	x22, x21, [x29, #-96]
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	stp	xzr, xzr, [sp, #80]
	cmp	x1, x8
	b.eq	.LBB84_13
// %bb.11:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB84_17
// %bb.12:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-88]
	cbnz	x21, .LBB84_15
	b	.LBB84_22
.LBB84_13:
.Ltmp362:
	sub	x2, x29, #96
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp363:
// %bb.14:
	ldur	x21, [x29, #-88]
	cbz	x21, .LBB84_22
.LBB84_15:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_18
// %bb.16:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_19
	b	.LBB84_22
.LBB84_17:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-88]
	cbnz	x21, .LBB84_15
	b	.LBB84_22
.LBB84_18:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_22
.LBB84_19:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_177
// %bb.20:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_22
.LBB84_21:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_22:
	ldr	x21, [sp, #88]
	cbz	x21, .LBB84_29
// %bb.23:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_25
// %bb.24:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_26
	b	.LBB84_29
.LBB84_25:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_29
.LBB84_26:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_178
// %bb.27:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_29
.LBB84_28:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_29:
	mov	w8, #555
	str	wzr, [sp, #48]
	str	wzr, [sp, #16]
	str	w8, [sp, #104]
	stp	wzr, w8, [x29, #-108]
.Ltmp365:
	mov	w0, #80
	bl	_Znwm
.Ltmp366:
// %bb.30:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp368:
	sub	x0, x29, #16
	add	x2, sp, #48
	add	x3, sp, #104
	add	x4, sp, #16
	sub	x5, x29, #104
	sub	x6, x29, #108
	sub	x7, x29, #32
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp369:
// %bb.31:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x29, #-128]
	stp	xzr, xzr, [sp, #80]
	cmp	x1, x8
	b.eq	.LBB84_34
// %bb.32:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB84_38
// %bb.33:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-120]
	cbnz	x21, .LBB84_36
	b	.LBB84_43
.LBB84_34:
.Ltmp371:
	sub	x2, x29, #128
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp372:
// %bb.35:
	ldur	x21, [x29, #-120]
	cbz	x21, .LBB84_43
.LBB84_36:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_39
// %bb.37:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_40
	b	.LBB84_43
.LBB84_38:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-120]
	cbnz	x21, .LBB84_36
	b	.LBB84_43
.LBB84_39:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_43
.LBB84_40:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_179
// %bb.41:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_43
.LBB84_42:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_43:
	ldr	x21, [sp, #88]
	cbz	x21, .LBB84_50
// %bb.44:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_46
// %bb.45:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_47
	b	.LBB84_50
.LBB84_46:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_50
.LBB84_47:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_180
// %bb.48:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_50
.LBB84_49:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_50:
	mov	w8, #213
	mov	w9, #343
	mov	w10, #227
	mov	w11, #332
	str	w8, [sp, #48]
	mov	w8, #554
	str	w9, [sp, #104]
	str	w10, [sp, #16]
	stp	w8, w11, [x29, #-108]
.Ltmp374:
	mov	w0, #80
	bl	_Znwm
.Ltmp375:
// %bb.51:
	movi	v0.2s, #1
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x23, [x0]
.Ltmp377:
	sub	x0, x29, #16
	add	x2, sp, #48
	add	x3, sp, #104
	add	x4, sp, #16
	sub	x5, x29, #104
	sub	x6, x29, #108
	sub	x7, x29, #80
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
.Ltmp378:
// %bb.52:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x29, #-144]
	stp	xzr, xzr, [sp, #80]
	cmp	x1, x8
	b.eq	.LBB84_55
// %bb.53:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB84_59
// %bb.54:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-136]
	cbnz	x21, .LBB84_57
	b	.LBB84_64
.LBB84_55:
.Ltmp380:
	sub	x2, x29, #144
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp381:
// %bb.56:
	ldur	x21, [x29, #-136]
	cbz	x21, .LBB84_64
.LBB84_57:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_60
// %bb.58:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_61
	b	.LBB84_64
.LBB84_59:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-136]
	cbnz	x21, .LBB84_57
	b	.LBB84_64
.LBB84_60:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_64
.LBB84_61:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_181
// %bb.62:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_64
.LBB84_63:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_64:
	ldr	x21, [sp, #88]
	cbz	x21, .LBB84_71
// %bb.65:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_67
// %bb.66:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_68
	b	.LBB84_71
.LBB84_67:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_71
.LBB84_68:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_182
// %bb.69:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_71
.LBB84_70:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_71:
	mov	w8, #555
	str	wzr, [sp, #48]
	str	wzr, [sp, #16]
	str	w8, [sp, #104]
	stp	w8, w8, [x29, #-108]
.Ltmp383:
	mov	w0, #80
	bl	_Znwm
.Ltmp384:
// %bb.72:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp386:
	sub	x0, x29, #16
	add	x2, sp, #48
	add	x3, sp, #104
	add	x4, sp, #16
	sub	x5, x29, #104
	sub	x6, x29, #108
	sub	x7, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp387:
// %bb.73:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #152]
	stp	xzr, xzr, [sp, #80]
	cmp	x1, x8
	b.eq	.LBB84_76
// %bb.74:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB84_80
// %bb.75:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #160]
	cbnz	x21, .LBB84_78
	b	.LBB84_85
.LBB84_76:
.Ltmp389:
	add	x2, sp, #152
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp390:
// %bb.77:
	ldr	x21, [sp, #160]
	cbz	x21, .LBB84_85
.LBB84_78:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_81
// %bb.79:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_82
	b	.LBB84_85
.LBB84_80:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #160]
	cbnz	x21, .LBB84_78
	b	.LBB84_85
.LBB84_81:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_85
.LBB84_82:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_183
// %bb.83:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_85
.LBB84_84:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_85:
	ldr	x21, [sp, #88]
	cbz	x21, .LBB84_92
// %bb.86:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_88
// %bb.87:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_89
	b	.LBB84_92
.LBB84_88:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_92
.LBB84_89:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_184
// %bb.90:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_92
.LBB84_91:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_92:
	mov	w8, #555
	str	wzr, [sp, #48]
	str	wzr, [sp, #16]
	str	w8, [sp, #104]
	stp	wzr, w8, [x29, #-108]
.Ltmp392:
	mov	w0, #80
	bl	_Znwm
.Ltmp393:
// %bb.93:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp395:
	sub	x0, x29, #16
	add	x2, sp, #48
	add	x3, sp, #104
	add	x4, sp, #16
	sub	x5, x29, #104
	sub	x6, x29, #108
	sub	x7, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp396:
// %bb.94:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #136]
	stp	xzr, xzr, [sp, #80]
	cmp	x1, x8
	b.eq	.LBB84_97
// %bb.95:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB84_101
// %bb.96:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #144]
	cbnz	x21, .LBB84_99
	b	.LBB84_106
.LBB84_97:
.Ltmp398:
	add	x2, sp, #136
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp399:
// %bb.98:
	ldr	x21, [sp, #144]
	cbz	x21, .LBB84_106
.LBB84_99:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_102
// %bb.100:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_103
	b	.LBB84_106
.LBB84_101:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #144]
	cbnz	x21, .LBB84_99
	b	.LBB84_106
.LBB84_102:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_106
.LBB84_103:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_185
// %bb.104:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_106
.LBB84_105:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_106:
	ldr	x21, [sp, #88]
	cbz	x21, .LBB84_113
// %bb.107:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_109
// %bb.108:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_110
	b	.LBB84_113
.LBB84_109:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_113
.LBB84_110:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_186
// %bb.111:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_113
.LBB84_112:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_113:
	mov	w8, #555
	str	wzr, [sp, #48]
	str	wzr, [sp, #16]
	str	w8, [sp, #104]
	stp	w8, w8, [x29, #-108]
.Ltmp401:
	mov	w0, #80
	bl	_Znwm
.Ltmp402:
// %bb.114:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp404:
	sub	x0, x29, #16
	add	x2, sp, #48
	add	x3, sp, #104
	add	x4, sp, #16
	sub	x5, x29, #104
	sub	x6, x29, #108
	sub	x7, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp405:
// %bb.115:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #120]
	stp	xzr, xzr, [sp, #80]
	cmp	x1, x8
	b.eq	.LBB84_118
// %bb.116:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB84_122
// %bb.117:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #128]
	cbnz	x21, .LBB84_120
	b	.LBB84_127
.LBB84_118:
.Ltmp407:
	add	x2, sp, #120
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp408:
// %bb.119:
	ldr	x21, [sp, #128]
	cbz	x21, .LBB84_127
.LBB84_120:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_123
// %bb.121:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_124
	b	.LBB84_127
.LBB84_122:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #128]
	cbnz	x21, .LBB84_120
	b	.LBB84_127
.LBB84_123:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_127
.LBB84_124:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_187
// %bb.125:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_127
.LBB84_126:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_127:
	ldr	x21, [sp, #88]
	cbz	x21, .LBB84_134
// %bb.128:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_130
// %bb.129:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_131
	b	.LBB84_134
.LBB84_130:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_134
.LBB84_131:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_188
// %bb.132:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_134
.LBB84_133:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_134:
	adrp	x8, .LCPI84_2
	stp	xzr, xzr, [sp, #80]
	str	xzr, [sp, #96]
	ldr	q0, [x8, :lo12:.LCPI84_2]
	mov	x8, #175921860444160
	movk	x8, #16484, lsl #48
	str	q0, [sp, #48]
	str	x8, [sp, #64]
.Ltmp410:
	mov	w0, #104
	bl	_Znwm
.Ltmp411:
// %bb.135:
	movi	v0.2s, #1
	adrp	x25, _ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x25, x25, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x25, [x0]
.Ltmp413:
	add	x0, sp, #16
	add	x2, sp, #80
	add	x3, sp, #48
	sub	x4, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp414:
// %bb.136:
	mov	w8, #15
	stp	x22, x21, [sp, #104]
	str	w8, [sp, #80]
.Ltmp416:
	mov	w0, #112
	bl	_Znwm
.Ltmp417:
// %bb.137:
	movi	v0.2s, #1
	adrp	x26, _ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	add	x26, x26, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x23, x0, #16
	str	d0, [x0, #8]
	str	x26, [x0]
.Ltmp419:
	add	x0, sp, #48
	add	x2, sp, #104
	add	x3, sp, #80
	mov	x1, x23
	bl	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
.Ltmp420:
// %bb.138:
	ldr	x21, [sp, #112]
	stp	x23, x22, [sp, #104]
	cbz	x21, .LBB84_145
// %bb.139:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_141
// %bb.140:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_142
	b	.LBB84_145
.LBB84_141:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_145
.LBB84_142:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_189
// %bb.143:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_145
.LBB84_144:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_145:
	adrp	x8, .LCPI84_3
	mov	x9, #123145302310912
	movk	x9, #16498, lsl #48
	str	xzr, [sp, #48]
	ldr	q0, [x8, :lo12:.LCPI84_3]
	add	x8, sp, #48
	add	x0, x8, #8
	str	x9, [sp, #96]
	str	q0, [sp, #80]
.Ltmp422:
	add	x1, sp, #48
	add	x2, sp, #16
	add	x3, sp, #104
	add	x4, sp, #80
	bl	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
.Ltmp423:
// %bb.146:
	ldp	x8, x9, [sp, #48]
	stp	xzr, xzr, [sp, #48]
	ldr	x21, [sp, #112]
	stp	x8, x9, [sp, #104]
	cbz	x21, .LBB84_153
// %bb.147:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_149
// %bb.148:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_150
	b	.LBB84_153
.LBB84_149:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_153
.LBB84_150:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_190
// %bb.151:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_153
.LBB84_152:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_153:
	ldr	x21, [sp, #56]
	cbz	x21, .LBB84_160
// %bb.154:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_156
// %bb.155:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_157
	b	.LBB84_160
.LBB84_156:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_160
.LBB84_157:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_191
// %bb.158:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_160
.LBB84_159:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_160:
	ldp	x9, x8, [sp, #104]
	stp	x9, x8, [sp, #32]
	cbz	x8, .LBB84_163
// %bb.161:
	ldrb	w9, [x24]
	cbz	w9, .LBB84_168
// %bb.162:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB84_163:
	ldp	x1, x8, [x19, #16]
	cmp	x1, x8
	b.eq	.LBB84_169
.LBB84_164:
	ldr	x8, [sp, #32]
	str	x8, [x1]
	ldr	x8, [sp, #40]
	str	x8, [x1, #8]
	cbz	x8, .LBB84_167
// %bb.165:
	ldrb	w9, [x24]
	cbz	w9, .LBB84_176
// %bb.166:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB84_167:
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #40]
	cbnz	x21, .LBB84_171
	b	.LBB84_194
.LBB84_168:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x1, x8, [x19, #16]
	cmp	x1, x8
	b.ne	.LBB84_164
.LBB84_169:
.Ltmp425:
	add	x2, sp, #32
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp426:
// %bb.170:
	ldr	x21, [sp, #40]
	cbz	x21, .LBB84_194
.LBB84_171:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_173
// %bb.172:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_174
	b	.LBB84_194
.LBB84_173:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_194
.LBB84_174:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_192
// %bb.175:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_194
	b	.LBB84_193
.LBB84_176:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #40]
	cbnz	x21, .LBB84_171
	b	.LBB84_194
.LBB84_177:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_21
	b	.LBB84_22
.LBB84_178:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_28
	b	.LBB84_29
.LBB84_179:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_42
	b	.LBB84_43
.LBB84_180:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_49
	b	.LBB84_50
.LBB84_181:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_63
	b	.LBB84_64
.LBB84_182:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_70
	b	.LBB84_71
.LBB84_183:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_84
	b	.LBB84_85
.LBB84_184:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_91
	b	.LBB84_92
.LBB84_185:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_105
	b	.LBB84_106
.LBB84_186:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_112
	b	.LBB84_113
.LBB84_187:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_126
	b	.LBB84_127
.LBB84_188:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_133
	b	.LBB84_134
.LBB84_189:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_144
	b	.LBB84_145
.LBB84_190:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_152
	b	.LBB84_153
.LBB84_191:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_159
	b	.LBB84_160
.LBB84_192:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_194
.LBB84_193:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_194:
	mov	x8, #175921860444160
	stp	xzr, xzr, [sp, #80]
	movk	x8, #16484, lsl #48
	str	xzr, [sp, #96]
	dup	v0.2d, x8
	str	x8, [sp, #64]
	str	q0, [sp, #48]
.Ltmp428:
	mov	w0, #104
	bl	_Znwm
.Ltmp429:
// %bb.195:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x25, [x0]
	str	d0, [x0, #8]
.Ltmp431:
	sub	x0, x29, #104
	add	x2, sp, #80
	add	x3, sp, #48
	sub	x4, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp432:
// %bb.196:
	mov	w8, #-18
	stp	x22, x21, [sp, #16]
	str	w8, [sp, #80]
.Ltmp434:
	mov	w0, #112
	bl	_Znwm
.Ltmp435:
// %bb.197:
	movi	v0.2s, #1
	mov	x22, x0
	add	x23, x0, #16
	str	x26, [x0]
	str	d0, [x0, #8]
.Ltmp437:
	add	x0, sp, #48
	add	x2, sp, #16
	add	x3, sp, #80
	mov	x1, x23
	bl	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
.Ltmp438:
// %bb.198:
	ldr	x21, [sp, #24]
	stp	x23, x22, [sp, #16]
	cbz	x21, .LBB84_205
// %bb.199:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_201
// %bb.200:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_202
	b	.LBB84_205
.LBB84_201:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_205
.LBB84_202:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_237
// %bb.203:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_205
.LBB84_204:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_205:
	adrp	x8, .LCPI84_4
	mov	x9, #70368744177664
	movk	x9, #16464, lsl #48
	str	xzr, [sp, #48]
	ldr	q0, [x8, :lo12:.LCPI84_4]
	add	x8, sp, #48
	add	x0, x8, #8
	str	x9, [sp, #96]
	str	q0, [sp, #80]
.Ltmp440:
	add	x1, sp, #48
	sub	x2, x29, #104
	add	x3, sp, #16
	add	x4, sp, #80
	bl	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
.Ltmp441:
// %bb.206:
	ldp	x8, x9, [sp, #48]
	stp	xzr, xzr, [sp, #48]
	ldr	x21, [sp, #24]
	stp	x8, x9, [sp, #16]
	cbz	x21, .LBB84_213
// %bb.207:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_209
// %bb.208:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_210
	b	.LBB84_213
.LBB84_209:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_213
.LBB84_210:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_238
// %bb.211:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_213
.LBB84_212:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_213:
	ldr	x21, [sp, #56]
	cbz	x21, .LBB84_220
// %bb.214:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_216
// %bb.215:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB84_217
	b	.LBB84_220
.LBB84_216:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_220
.LBB84_217:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_239
// %bb.218:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB84_220
.LBB84_219:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_220:
	ldp	x9, x8, [sp, #16]
	stp	x9, x8, [sp]
	cbz	x8, .LBB84_223
// %bb.221:
	ldrb	w9, [x24]
	cbz	w9, .LBB84_228
// %bb.222:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB84_223:
	ldp	x1, x8, [x19, #16]
	cmp	x1, x8
	b.eq	.LBB84_229
.LBB84_224:
	ldr	x8, [sp]
	str	x8, [x1]
	ldr	x8, [sp, #8]
	str	x8, [x1, #8]
	cbz	x8, .LBB84_227
// %bb.225:
	ldrb	w9, [x24]
	cbz	w9, .LBB84_236
// %bb.226:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB84_227:
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB84_231
	b	.LBB84_242
.LBB84_228:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x1, x8, [x19, #16]
	cmp	x1, x8
	b.ne	.LBB84_224
.LBB84_229:
.Ltmp443:
	mov	x2, sp
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp444:
// %bb.230:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB84_242
.LBB84_231:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_233
// %bb.232:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_234
	b	.LBB84_242
.LBB84_233:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_242
.LBB84_234:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_240
// %bb.235:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_242
	b	.LBB84_241
.LBB84_236:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #8]
	cbnz	x19, .LBB84_231
	b	.LBB84_242
.LBB84_237:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_204
	b	.LBB84_205
.LBB84_238:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_212
	b	.LBB84_213
.LBB84_239:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_219
	b	.LBB84_220
.LBB84_240:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_242
.LBB84_241:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_242:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB84_249
// %bb.243:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_245
// %bb.244:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_246
	b	.LBB84_249
.LBB84_245:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_249
.LBB84_246:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_285
// %bb.247:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_249
.LBB84_248:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_249:
	ldr	x19, [sp, #112]
	cbz	x19, .LBB84_256
// %bb.250:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_252
// %bb.251:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_253
	b	.LBB84_256
.LBB84_252:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_256
.LBB84_253:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_286
// %bb.254:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_256
.LBB84_255:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_256:
	ldur	x19, [x29, #-72]
	cbz	x19, .LBB84_263
// %bb.257:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_259
// %bb.258:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_260
	b	.LBB84_263
.LBB84_259:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_263
.LBB84_260:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_287
// %bb.261:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_263
.LBB84_262:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_263:
	ldur	x19, [x29, #-56]
	cbz	x19, .LBB84_270
// %bb.264:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_266
// %bb.265:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_267
	b	.LBB84_270
.LBB84_266:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_270
.LBB84_267:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_288
// %bb.268:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_270
.LBB84_269:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_270:
	ldur	x19, [x29, #-40]
	cbz	x19, .LBB84_277
// %bb.271:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_273
// %bb.272:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_274
	b	.LBB84_277
.LBB84_273:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_277
.LBB84_274:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_289
// %bb.275:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_277
.LBB84_276:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_277:
	ldur	x19, [x29, #-24]
	cbz	x19, .LBB84_284
// %bb.278:
	ldrb	w8, [x24]
	cbz	w8, .LBB84_280
// %bb.279:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB84_281
	b	.LBB84_284
.LBB84_280:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB84_284
.LBB84_281:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB84_290
// %bb.282:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB84_284
.LBB84_283:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB84_284:
	ldp	x20, x19, [sp, #384]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #368]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #352]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #336]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #312]            // 16-byte Folded Reload
	ldr	x28, [sp, #328]                 // 8-byte Folded Reload
	ldr	d8, [sp, #304]                  // 8-byte Folded Reload
	add	sp, sp, #400
	ret
.LBB84_285:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_248
	b	.LBB84_249
.LBB84_286:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_255
	b	.LBB84_256
.LBB84_287:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_262
	b	.LBB84_263
.LBB84_288:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_269
	b	.LBB84_270
.LBB84_289:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_276
	b	.LBB84_277
.LBB84_290:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB84_283
	b	.LBB84_284
.LBB84_291:
.Ltmp445:
	mov	x20, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB84_305
.LBB84_292:
.Ltmp427:
	mov	x20, x0
	add	x0, sp, #32
	b	.LBB84_306
.LBB84_293:
.Ltmp409:
	mov	x20, x0
	add	x0, sp, #120
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #80
	bl	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB84_328
.LBB84_294:
.Ltmp400:
	mov	x20, x0
	add	x0, sp, #136
	b	.LBB84_297
.LBB84_295:
.Ltmp391:
	mov	x20, x0
	add	x0, sp, #152
	b	.LBB84_297
.LBB84_296:
.Ltmp382:
	mov	x20, x0
	sub	x0, x29, #144
.LBB84_297:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #80
	bl	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB84_328
.LBB84_298:
.Ltmp373:
	mov	x20, x0
	sub	x0, x29, #128
	b	.LBB84_300
.LBB84_299:
.Ltmp364:
	mov	x20, x0
	sub	x0, x29, #96
.LBB84_300:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #80
	bl	_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB84_328
.LBB84_301:
.Ltmp442:
	b	.LBB84_304
.LBB84_302:
.Ltmp439:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB84_305
.LBB84_303:
.Ltmp436:
.LBB84_304:
	mov	x20, x0
.LBB84_305:
	add	x0, sp, #16
.LBB84_306:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB84_313
.LBB84_307:
.Ltmp433:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB84_313
.LBB84_308:
.Ltmp430:
	b	.LBB84_312
.LBB84_309:
.Ltmp424:
	b	.LBB84_312
.LBB84_310:
.Ltmp421:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB84_313
.LBB84_311:
.Ltmp418:
.LBB84_312:
	mov	x20, x0
.LBB84_313:
	add	x0, sp, #104
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB84_328
.LBB84_314:
.Ltmp415:
	b	.LBB84_327
.LBB84_315:
.Ltmp412:
	mov	x20, x0
	b	.LBB84_328
.LBB84_316:
.Ltmp406:
	b	.LBB84_327
.LBB84_317:
.Ltmp403:
	mov	x20, x0
	b	.LBB84_328
.LBB84_318:
.Ltmp397:
	b	.LBB84_327
.LBB84_319:
.Ltmp394:
	mov	x20, x0
	b	.LBB84_328
.LBB84_320:
.Ltmp388:
	b	.LBB84_327
.LBB84_321:
.Ltmp385:
	mov	x20, x0
	b	.LBB84_328
.LBB84_322:
.Ltmp379:
	b	.LBB84_327
.LBB84_323:
.Ltmp376:
	mov	x20, x0
	b	.LBB84_328
.LBB84_324:
.Ltmp370:
	b	.LBB84_327
.LBB84_325:
.Ltmp367:
	mov	x20, x0
	b	.LBB84_328
.LBB84_326:
.Ltmp361:
.LBB84_327:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
.LBB84_328:
	sub	x0, x29, #80
	bl	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB84_329:
	sub	x0, x29, #64
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB84_330:
	sub	x0, x29, #48
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB84_331:
.Ltmp358:
	mov	x20, x0
	b	.LBB84_328
.LBB84_332:
.Ltmp355:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB84_329
.LBB84_333:
.Ltmp352:
	mov	x20, x0
	b	.LBB84_329
.LBB84_334:
.Ltmp349:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB84_330
.LBB84_335:
.Ltmp346:
	mov	x20, x0
	b	.LBB84_330
.LBB84_336:
.Ltmp343:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB84_337:
.Ltmp340:
	mov	x20, x0
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB84_338:
.Ltmp337:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB84_339:
.Ltmp334:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end84:
	.size	_Z11cornell_boxv, .Lfunc_end84-_Z11cornell_boxv
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table84:
.Lexception15:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end15-.Lcst_begin15
.Lcst_begin15:
	.uleb128 .Ltmp332-.Lfunc_begin15        // >> Call Site 1 <<
	.uleb128 .Ltmp333-.Ltmp332              //   Call between .Ltmp332 and .Ltmp333
	.uleb128 .Ltmp334-.Lfunc_begin15        //     jumps to .Ltmp334
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp335-.Lfunc_begin15        // >> Call Site 2 <<
	.uleb128 .Ltmp336-.Ltmp335              //   Call between .Ltmp335 and .Ltmp336
	.uleb128 .Ltmp337-.Lfunc_begin15        //     jumps to .Ltmp337
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp338-.Lfunc_begin15        // >> Call Site 3 <<
	.uleb128 .Ltmp339-.Ltmp338              //   Call between .Ltmp338 and .Ltmp339
	.uleb128 .Ltmp340-.Lfunc_begin15        //     jumps to .Ltmp340
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp341-.Lfunc_begin15        // >> Call Site 4 <<
	.uleb128 .Ltmp342-.Ltmp341              //   Call between .Ltmp341 and .Ltmp342
	.uleb128 .Ltmp343-.Lfunc_begin15        //     jumps to .Ltmp343
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp344-.Lfunc_begin15        // >> Call Site 5 <<
	.uleb128 .Ltmp345-.Ltmp344              //   Call between .Ltmp344 and .Ltmp345
	.uleb128 .Ltmp346-.Lfunc_begin15        //     jumps to .Ltmp346
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp347-.Lfunc_begin15        // >> Call Site 6 <<
	.uleb128 .Ltmp348-.Ltmp347              //   Call between .Ltmp347 and .Ltmp348
	.uleb128 .Ltmp349-.Lfunc_begin15        //     jumps to .Ltmp349
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp350-.Lfunc_begin15        // >> Call Site 7 <<
	.uleb128 .Ltmp351-.Ltmp350              //   Call between .Ltmp350 and .Ltmp351
	.uleb128 .Ltmp352-.Lfunc_begin15        //     jumps to .Ltmp352
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp353-.Lfunc_begin15        // >> Call Site 8 <<
	.uleb128 .Ltmp354-.Ltmp353              //   Call between .Ltmp353 and .Ltmp354
	.uleb128 .Ltmp355-.Lfunc_begin15        //     jumps to .Ltmp355
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp356-.Lfunc_begin15        // >> Call Site 9 <<
	.uleb128 .Ltmp357-.Ltmp356              //   Call between .Ltmp356 and .Ltmp357
	.uleb128 .Ltmp358-.Lfunc_begin15        //     jumps to .Ltmp358
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp359-.Lfunc_begin15        // >> Call Site 10 <<
	.uleb128 .Ltmp360-.Ltmp359              //   Call between .Ltmp359 and .Ltmp360
	.uleb128 .Ltmp361-.Lfunc_begin15        //     jumps to .Ltmp361
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp362-.Lfunc_begin15        // >> Call Site 11 <<
	.uleb128 .Ltmp363-.Ltmp362              //   Call between .Ltmp362 and .Ltmp363
	.uleb128 .Ltmp364-.Lfunc_begin15        //     jumps to .Ltmp364
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp363-.Lfunc_begin15        // >> Call Site 12 <<
	.uleb128 .Ltmp365-.Ltmp363              //   Call between .Ltmp363 and .Ltmp365
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp365-.Lfunc_begin15        // >> Call Site 13 <<
	.uleb128 .Ltmp366-.Ltmp365              //   Call between .Ltmp365 and .Ltmp366
	.uleb128 .Ltmp367-.Lfunc_begin15        //     jumps to .Ltmp367
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp368-.Lfunc_begin15        // >> Call Site 14 <<
	.uleb128 .Ltmp369-.Ltmp368              //   Call between .Ltmp368 and .Ltmp369
	.uleb128 .Ltmp370-.Lfunc_begin15        //     jumps to .Ltmp370
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp371-.Lfunc_begin15        // >> Call Site 15 <<
	.uleb128 .Ltmp372-.Ltmp371              //   Call between .Ltmp371 and .Ltmp372
	.uleb128 .Ltmp373-.Lfunc_begin15        //     jumps to .Ltmp373
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp372-.Lfunc_begin15        // >> Call Site 16 <<
	.uleb128 .Ltmp374-.Ltmp372              //   Call between .Ltmp372 and .Ltmp374
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp374-.Lfunc_begin15        // >> Call Site 17 <<
	.uleb128 .Ltmp375-.Ltmp374              //   Call between .Ltmp374 and .Ltmp375
	.uleb128 .Ltmp376-.Lfunc_begin15        //     jumps to .Ltmp376
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp377-.Lfunc_begin15        // >> Call Site 18 <<
	.uleb128 .Ltmp378-.Ltmp377              //   Call between .Ltmp377 and .Ltmp378
	.uleb128 .Ltmp379-.Lfunc_begin15        //     jumps to .Ltmp379
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp380-.Lfunc_begin15        // >> Call Site 19 <<
	.uleb128 .Ltmp381-.Ltmp380              //   Call between .Ltmp380 and .Ltmp381
	.uleb128 .Ltmp382-.Lfunc_begin15        //     jumps to .Ltmp382
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp381-.Lfunc_begin15        // >> Call Site 20 <<
	.uleb128 .Ltmp383-.Ltmp381              //   Call between .Ltmp381 and .Ltmp383
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp383-.Lfunc_begin15        // >> Call Site 21 <<
	.uleb128 .Ltmp384-.Ltmp383              //   Call between .Ltmp383 and .Ltmp384
	.uleb128 .Ltmp385-.Lfunc_begin15        //     jumps to .Ltmp385
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp386-.Lfunc_begin15        // >> Call Site 22 <<
	.uleb128 .Ltmp387-.Ltmp386              //   Call between .Ltmp386 and .Ltmp387
	.uleb128 .Ltmp388-.Lfunc_begin15        //     jumps to .Ltmp388
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp389-.Lfunc_begin15        // >> Call Site 23 <<
	.uleb128 .Ltmp390-.Ltmp389              //   Call between .Ltmp389 and .Ltmp390
	.uleb128 .Ltmp391-.Lfunc_begin15        //     jumps to .Ltmp391
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp390-.Lfunc_begin15        // >> Call Site 24 <<
	.uleb128 .Ltmp392-.Ltmp390              //   Call between .Ltmp390 and .Ltmp392
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp392-.Lfunc_begin15        // >> Call Site 25 <<
	.uleb128 .Ltmp393-.Ltmp392              //   Call between .Ltmp392 and .Ltmp393
	.uleb128 .Ltmp394-.Lfunc_begin15        //     jumps to .Ltmp394
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp395-.Lfunc_begin15        // >> Call Site 26 <<
	.uleb128 .Ltmp396-.Ltmp395              //   Call between .Ltmp395 and .Ltmp396
	.uleb128 .Ltmp397-.Lfunc_begin15        //     jumps to .Ltmp397
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp398-.Lfunc_begin15        // >> Call Site 27 <<
	.uleb128 .Ltmp399-.Ltmp398              //   Call between .Ltmp398 and .Ltmp399
	.uleb128 .Ltmp400-.Lfunc_begin15        //     jumps to .Ltmp400
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp399-.Lfunc_begin15        // >> Call Site 28 <<
	.uleb128 .Ltmp401-.Ltmp399              //   Call between .Ltmp399 and .Ltmp401
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp401-.Lfunc_begin15        // >> Call Site 29 <<
	.uleb128 .Ltmp402-.Ltmp401              //   Call between .Ltmp401 and .Ltmp402
	.uleb128 .Ltmp403-.Lfunc_begin15        //     jumps to .Ltmp403
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp404-.Lfunc_begin15        // >> Call Site 30 <<
	.uleb128 .Ltmp405-.Ltmp404              //   Call between .Ltmp404 and .Ltmp405
	.uleb128 .Ltmp406-.Lfunc_begin15        //     jumps to .Ltmp406
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp407-.Lfunc_begin15        // >> Call Site 31 <<
	.uleb128 .Ltmp408-.Ltmp407              //   Call between .Ltmp407 and .Ltmp408
	.uleb128 .Ltmp409-.Lfunc_begin15        //     jumps to .Ltmp409
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp408-.Lfunc_begin15        // >> Call Site 32 <<
	.uleb128 .Ltmp410-.Ltmp408              //   Call between .Ltmp408 and .Ltmp410
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp410-.Lfunc_begin15        // >> Call Site 33 <<
	.uleb128 .Ltmp411-.Ltmp410              //   Call between .Ltmp410 and .Ltmp411
	.uleb128 .Ltmp412-.Lfunc_begin15        //     jumps to .Ltmp412
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp413-.Lfunc_begin15        // >> Call Site 34 <<
	.uleb128 .Ltmp414-.Ltmp413              //   Call between .Ltmp413 and .Ltmp414
	.uleb128 .Ltmp415-.Lfunc_begin15        //     jumps to .Ltmp415
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp416-.Lfunc_begin15        // >> Call Site 35 <<
	.uleb128 .Ltmp417-.Ltmp416              //   Call between .Ltmp416 and .Ltmp417
	.uleb128 .Ltmp418-.Lfunc_begin15        //     jumps to .Ltmp418
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp419-.Lfunc_begin15        // >> Call Site 36 <<
	.uleb128 .Ltmp420-.Ltmp419              //   Call between .Ltmp419 and .Ltmp420
	.uleb128 .Ltmp421-.Lfunc_begin15        //     jumps to .Ltmp421
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp420-.Lfunc_begin15        // >> Call Site 37 <<
	.uleb128 .Ltmp422-.Ltmp420              //   Call between .Ltmp420 and .Ltmp422
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp422-.Lfunc_begin15        // >> Call Site 38 <<
	.uleb128 .Ltmp423-.Ltmp422              //   Call between .Ltmp422 and .Ltmp423
	.uleb128 .Ltmp424-.Lfunc_begin15        //     jumps to .Ltmp424
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp423-.Lfunc_begin15        // >> Call Site 39 <<
	.uleb128 .Ltmp425-.Ltmp423              //   Call between .Ltmp423 and .Ltmp425
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp425-.Lfunc_begin15        // >> Call Site 40 <<
	.uleb128 .Ltmp426-.Ltmp425              //   Call between .Ltmp425 and .Ltmp426
	.uleb128 .Ltmp427-.Lfunc_begin15        //     jumps to .Ltmp427
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp426-.Lfunc_begin15        // >> Call Site 41 <<
	.uleb128 .Ltmp428-.Ltmp426              //   Call between .Ltmp426 and .Ltmp428
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp428-.Lfunc_begin15        // >> Call Site 42 <<
	.uleb128 .Ltmp429-.Ltmp428              //   Call between .Ltmp428 and .Ltmp429
	.uleb128 .Ltmp430-.Lfunc_begin15        //     jumps to .Ltmp430
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp431-.Lfunc_begin15        // >> Call Site 43 <<
	.uleb128 .Ltmp432-.Ltmp431              //   Call between .Ltmp431 and .Ltmp432
	.uleb128 .Ltmp433-.Lfunc_begin15        //     jumps to .Ltmp433
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp434-.Lfunc_begin15        // >> Call Site 44 <<
	.uleb128 .Ltmp435-.Ltmp434              //   Call between .Ltmp434 and .Ltmp435
	.uleb128 .Ltmp436-.Lfunc_begin15        //     jumps to .Ltmp436
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp437-.Lfunc_begin15        // >> Call Site 45 <<
	.uleb128 .Ltmp438-.Ltmp437              //   Call between .Ltmp437 and .Ltmp438
	.uleb128 .Ltmp439-.Lfunc_begin15        //     jumps to .Ltmp439
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp438-.Lfunc_begin15        // >> Call Site 46 <<
	.uleb128 .Ltmp440-.Ltmp438              //   Call between .Ltmp438 and .Ltmp440
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp440-.Lfunc_begin15        // >> Call Site 47 <<
	.uleb128 .Ltmp441-.Ltmp440              //   Call between .Ltmp440 and .Ltmp441
	.uleb128 .Ltmp442-.Lfunc_begin15        //     jumps to .Ltmp442
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp441-.Lfunc_begin15        // >> Call Site 48 <<
	.uleb128 .Ltmp443-.Ltmp441              //   Call between .Ltmp441 and .Ltmp443
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp443-.Lfunc_begin15        // >> Call Site 49 <<
	.uleb128 .Ltmp444-.Ltmp443              //   Call between .Ltmp443 and .Ltmp444
	.uleb128 .Ltmp445-.Lfunc_begin15        //     jumps to .Ltmp445
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp444-.Lfunc_begin15        // >> Call Site 50 <<
	.uleb128 .Lfunc_end84-.Ltmp444          //   Call between .Ltmp444 and .Lfunc_end84
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end15:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB85_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB85_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB85_4
	b	.LBB85_8
.LBB85_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB85_8
.LBB85_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB85_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB85_8
.LBB85_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB85_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB85_6
.LBB85_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end85:
	.size	_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end85-_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB86_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB86_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB86_4
	b	.LBB86_8
.LBB86_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB86_8
.LBB86_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB86_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB86_8
.LBB86_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB86_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB86_6
.LBB86_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end86:
	.size	_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end86-_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB87_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB87_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB87_4
	b	.LBB87_8
.LBB87_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB87_8
.LBB87_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB87_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB87_8
.LBB87_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB87_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB87_6
.LBB87_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end87:
	.size	_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end87-_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z13cornell_smokev
.LCPI88_0:
	.xword	0x3fe4cccccccccccd              // double 0.65000000000000002
	.xword	0x3fa999999999999a              // double 0.050000000000000003
.LCPI88_1:
	.xword	0x3fbeb851eb851eb8              // double 0.12
	.xword	0x3fdccccccccccccd              // double 0.45000000000000001
.LCPI88_2:
	.xword	0x4064a00000000000              // double 165
	.xword	0x4074a00000000000              // double 330
.LCPI88_3:
	.xword	0x4070900000000000              // double 265
	.xword	0x0000000000000000              // double 0
.LCPI88_4:
	.xword	0x4060400000000000              // double 130
	.xword	0x0000000000000000              // double 0
	.text
	.globl	_Z13cornell_smokev
	.p2align	2
	.type	_Z13cornell_smokev,@function
_Z13cornell_smokev:                     // @_Z13cornell_smokev
.Lfunc_begin16:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception16
// %bb.0:
	sub	sp, sp, #416
	str	d8, [sp, #320]                  // 8-byte Folded Spill
	stp	x29, x30, [sp, #328]            // 16-byte Folded Spill
	add	x29, sp, #328
	str	x28, [sp, #344]                 // 8-byte Folded Spill
	stp	x26, x25, [sp, #352]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #368]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #384]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #400]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 88
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w28, -72
	.cfi_offset w30, -80
	.cfi_offset w29, -88
	.cfi_offset b8, -96
	mov	x19, x8
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	mov	x20, x19
	stp	xzr, xzr, [x19, #16]
	str	x8, [x19]
	str	xzr, [x20, #8]!
.Ltmp446:
	mov	w0, #40
	bl	_Znwm
.Ltmp447:
// %bb.1:
	movi	v8.2s, #1
	adrp	x24, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x25, _ZTV10lambertian+16
	mov	x21, x0
	add	x24, x24, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x26, x0
	add	x25, x25, :lo12:_ZTV10lambertian+16
	str	d8, [x0, #8]
	str	x24, [x0]
	str	x25, [x26, #16]!
.Ltmp449:
	mov	w0, #48
	bl	_Znwm
.Ltmp450:
// %bb.2:
	adrp	x8, .LCPI88_0
	mov	x10, #-7378697629483820647
	adrp	x22, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movk	x10, #39322
	adrp	x23, _ZTV11solid_color+16
	add	x22, x22, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x9, x0
	movk	x10, #16297, lsl #48
	ldr	q0, [x8, :lo12:.LCPI88_0]
	add	x23, x23, :lo12:_ZTV11solid_color+16
	str	d8, [x0, #8]
	str	x22, [x0]
	str	x23, [x9, #16]!
	str	x10, [x0, #40]
	stur	q0, [x0, #24]
	stp	x9, x0, [x21, #24]
	stp	x26, x21, [x29, #-32]
	stur	xzr, [x29, #-48]
.Ltmp452:
	mov	w0, #40
	bl	_Znwm
.Ltmp453:
// %bb.3:
	movi	v8.2s, #1
	mov	x21, x0
	mov	x26, x0
	str	x24, [x0]
	str	d8, [x0, #8]
	str	x25, [x26, #16]!
.Ltmp455:
	mov	w0, #48
	bl	_Znwm
.Ltmp456:
// %bb.4:
	mov	x9, #36700
	mov	x8, x0
	movk	x9, #62914, lsl #16
	str	d8, [x0, #8]
	movk	x9, #23592, lsl #32
	str	x22, [x0]
	movk	x9, #16359, lsl #48
	stp	x26, x21, [x29, #-48]
	str	x23, [x8, #16]!
	stp	x8, x0, [x21, #24]
	dup	v0.2d, x9
	str	x9, [x0, #40]
	stur	xzr, [x29, #-64]
	stur	q0, [x0, #24]
.Ltmp458:
	mov	w0, #40
	bl	_Znwm
.Ltmp459:
// %bb.5:
	movi	v8.2s, #1
	mov	x21, x0
	mov	x26, x0
	str	x24, [x0]
	str	d8, [x0, #8]
	str	x25, [x26, #16]!
.Ltmp461:
	mov	w0, #48
	bl	_Znwm
.Ltmp462:
// %bb.6:
	adrp	x9, .LCPI88_1
	mov	x10, #3689348814741910323
	mov	x8, x0
	movk	x10, #16323, lsl #48
	str	d8, [x0, #8]
	ldr	q0, [x9, :lo12:.LCPI88_1]
	str	x22, [x0]
	str	x23, [x8, #16]!
	str	x10, [x0, #40]
	stp	x8, x0, [x21, #24]
	stur	q0, [x0, #24]
	stp	x26, x21, [x29, #-64]
	stur	xzr, [x29, #-80]
.Ltmp464:
	mov	w0, #40
	bl	_Znwm
.Ltmp465:
// %bb.7:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x24, x0
	str	x8, [x0]
	adrp	x8, _ZTV13diffuse_light+16
	add	x8, x8, :lo12:_ZTV13diffuse_light+16
	str	d8, [x0, #8]
	str	x8, [x24, #16]!
.Ltmp467:
	mov	w0, #48
	bl	_Znwm
.Ltmp468:
// %bb.8:
	mov	x8, x0
	mov	x9, #4619567317775286272
	fmov	v0.2d, #7.00000000
	str	d8, [x0, #8]
	str	x22, [x0]
	str	x23, [x8, #16]!
	stp	x8, x0, [x21, #24]
	mov	w8, #555
	str	x9, [x0, #40]
	stur	q0, [x0, #24]
	stp	x24, x21, [x29, #-80]
	str	wzr, [sp, #64]
	str	w8, [sp, #128]
	str	wzr, [sp, #48]
	str	w8, [sp, #24]
	stur	w8, [x29, #-104]
.Ltmp470:
	mov	w0, #80
	bl	_Znwm
.Ltmp471:
// %bb.9:
	movi	v0.2s, #1
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x23, [x0]
.Ltmp473:
	sub	x0, x29, #16
	add	x2, sp, #64
	add	x3, sp, #128
	add	x4, sp, #48
	add	x5, sp, #24
	sub	x6, x29, #104
	sub	x7, x29, #64
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp474:
// %bb.10:
	ldp	x1, x8, [x19, #16]
	adrp	x24, :got:__libc_single_threaded
	stp	x22, x21, [x29, #-96]
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	stp	xzr, xzr, [sp, #96]
	cmp	x1, x8
	b.eq	.LBB88_13
// %bb.11:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_17
// %bb.12:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-88]
	cbnz	x21, .LBB88_15
	b	.LBB88_22
.LBB88_13:
.Ltmp476:
	sub	x2, x29, #96
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp477:
// %bb.14:
	ldur	x21, [x29, #-88]
	cbz	x21, .LBB88_22
.LBB88_15:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_18
// %bb.16:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_19
	b	.LBB88_22
.LBB88_17:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-88]
	cbnz	x21, .LBB88_15
	b	.LBB88_22
.LBB88_18:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_22
.LBB88_19:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_271
// %bb.20:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_22
.LBB88_21:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_22:
	ldr	x21, [sp, #104]
	cbz	x21, .LBB88_29
// %bb.23:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_25
// %bb.24:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_26
	b	.LBB88_29
.LBB88_25:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_29
.LBB88_26:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_272
// %bb.27:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_29
.LBB88_28:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_29:
	mov	w8, #555
	str	wzr, [sp, #64]
	str	wzr, [sp, #48]
	stur	wzr, [x29, #-104]
	str	w8, [sp, #128]
	str	w8, [sp, #24]
.Ltmp479:
	mov	w0, #80
	bl	_Znwm
.Ltmp480:
// %bb.30:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp482:
	sub	x0, x29, #16
	add	x2, sp, #64
	add	x3, sp, #128
	add	x4, sp, #48
	add	x5, sp, #24
	sub	x6, x29, #104
	sub	x7, x29, #32
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp483:
// %bb.31:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x29, #-120]
	stp	xzr, xzr, [sp, #96]
	cmp	x1, x8
	b.eq	.LBB88_34
// %bb.32:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_38
// %bb.33:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-112]
	cbnz	x21, .LBB88_36
	b	.LBB88_43
.LBB88_34:
.Ltmp485:
	sub	x2, x29, #120
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp486:
// %bb.35:
	ldur	x21, [x29, #-112]
	cbz	x21, .LBB88_43
.LBB88_36:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_39
// %bb.37:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_40
	b	.LBB88_43
.LBB88_38:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-112]
	cbnz	x21, .LBB88_36
	b	.LBB88_43
.LBB88_39:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_43
.LBB88_40:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_273
// %bb.41:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_43
.LBB88_42:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_43:
	ldr	x21, [sp, #104]
	cbz	x21, .LBB88_50
// %bb.44:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_46
// %bb.45:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_47
	b	.LBB88_50
.LBB88_46:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_50
.LBB88_47:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_274
// %bb.48:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_50
.LBB88_49:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_50:
	mov	w8, #113
	mov	w9, #443
	mov	w10, #127
	mov	w11, #432
	str	w8, [sp, #64]
	mov	w8, #554
	str	w9, [sp, #128]
	str	w10, [sp, #48]
	str	w11, [sp, #24]
	stur	w8, [x29, #-104]
.Ltmp488:
	mov	w0, #80
	bl	_Znwm
.Ltmp489:
// %bb.51:
	movi	v0.2s, #1
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x23, [x0]
.Ltmp491:
	sub	x0, x29, #16
	add	x2, sp, #64
	add	x3, sp, #128
	add	x4, sp, #48
	add	x5, sp, #24
	sub	x6, x29, #104
	sub	x7, x29, #80
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
.Ltmp492:
// %bb.52:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x29, #-136]
	stp	xzr, xzr, [sp, #96]
	cmp	x1, x8
	b.eq	.LBB88_55
// %bb.53:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_59
// %bb.54:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-128]
	cbnz	x21, .LBB88_57
	b	.LBB88_64
.LBB88_55:
.Ltmp494:
	sub	x2, x29, #136
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp495:
// %bb.56:
	ldur	x21, [x29, #-128]
	cbz	x21, .LBB88_64
.LBB88_57:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_60
// %bb.58:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_61
	b	.LBB88_64
.LBB88_59:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-128]
	cbnz	x21, .LBB88_57
	b	.LBB88_64
.LBB88_60:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_64
.LBB88_61:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_275
// %bb.62:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_64
.LBB88_63:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_64:
	ldr	x21, [sp, #104]
	cbz	x21, .LBB88_71
// %bb.65:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_67
// %bb.66:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_68
	b	.LBB88_71
.LBB88_67:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_71
.LBB88_68:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_276
// %bb.69:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_71
.LBB88_70:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_71:
	mov	w8, #555
	str	wzr, [sp, #64]
	str	wzr, [sp, #48]
	str	w8, [sp, #128]
	str	w8, [sp, #24]
	stur	w8, [x29, #-104]
.Ltmp497:
	mov	w0, #80
	bl	_Znwm
.Ltmp498:
// %bb.72:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp500:
	sub	x0, x29, #16
	add	x2, sp, #64
	add	x3, sp, #128
	add	x4, sp, #48
	add	x5, sp, #24
	sub	x6, x29, #104
	sub	x7, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp501:
// %bb.73:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x29, #-152]
	stp	xzr, xzr, [sp, #96]
	cmp	x1, x8
	b.eq	.LBB88_76
// %bb.74:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_80
// %bb.75:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-144]
	cbnz	x21, .LBB88_78
	b	.LBB88_85
.LBB88_76:
.Ltmp503:
	sub	x2, x29, #152
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp504:
// %bb.77:
	ldur	x21, [x29, #-144]
	cbz	x21, .LBB88_85
.LBB88_78:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_81
// %bb.79:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_82
	b	.LBB88_85
.LBB88_80:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldur	x21, [x29, #-144]
	cbnz	x21, .LBB88_78
	b	.LBB88_85
.LBB88_81:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_85
.LBB88_82:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_277
// %bb.83:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_85
.LBB88_84:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_85:
	ldr	x21, [sp, #104]
	cbz	x21, .LBB88_92
// %bb.86:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_88
// %bb.87:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_89
	b	.LBB88_92
.LBB88_88:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_92
.LBB88_89:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_278
// %bb.90:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_92
.LBB88_91:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_92:
	mov	w8, #555
	str	wzr, [sp, #64]
	str	wzr, [sp, #48]
	stur	wzr, [x29, #-104]
	str	w8, [sp, #128]
	str	w8, [sp, #24]
.Ltmp506:
	mov	w0, #80
	bl	_Znwm
.Ltmp507:
// %bb.93:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp509:
	sub	x0, x29, #16
	add	x2, sp, #64
	add	x3, sp, #128
	add	x4, sp, #48
	add	x5, sp, #24
	sub	x6, x29, #104
	sub	x7, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp510:
// %bb.94:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #160]
	stp	xzr, xzr, [sp, #96]
	cmp	x1, x8
	b.eq	.LBB88_97
// %bb.95:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_101
// %bb.96:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #168]
	cbnz	x21, .LBB88_99
	b	.LBB88_106
.LBB88_97:
.Ltmp512:
	add	x2, sp, #160
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp513:
// %bb.98:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB88_106
.LBB88_99:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_102
// %bb.100:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_103
	b	.LBB88_106
.LBB88_101:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #168]
	cbnz	x21, .LBB88_99
	b	.LBB88_106
.LBB88_102:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_106
.LBB88_103:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_279
// %bb.104:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_106
.LBB88_105:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_106:
	ldr	x21, [sp, #104]
	cbz	x21, .LBB88_113
// %bb.107:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_109
// %bb.108:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_110
	b	.LBB88_113
.LBB88_109:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_113
.LBB88_110:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_280
// %bb.111:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_113
.LBB88_112:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_113:
	mov	w8, #555
	str	wzr, [sp, #64]
	str	wzr, [sp, #48]
	str	w8, [sp, #128]
	str	w8, [sp, #24]
	stur	w8, [x29, #-104]
.Ltmp515:
	mov	w0, #80
	bl	_Znwm
.Ltmp516:
// %bb.114:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp518:
	sub	x0, x29, #16
	add	x2, sp, #64
	add	x3, sp, #128
	add	x4, sp, #48
	add	x5, sp, #24
	sub	x6, x29, #104
	sub	x7, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp519:
// %bb.115:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #144]
	stp	xzr, xzr, [sp, #96]
	cmp	x1, x8
	b.eq	.LBB88_118
// %bb.116:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_122
// %bb.117:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #152]
	cbnz	x21, .LBB88_120
	b	.LBB88_127
.LBB88_118:
.Ltmp521:
	add	x2, sp, #144
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp522:
// %bb.119:
	ldr	x21, [sp, #152]
	cbz	x21, .LBB88_127
.LBB88_120:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_123
// %bb.121:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_124
	b	.LBB88_127
.LBB88_122:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #152]
	cbnz	x21, .LBB88_120
	b	.LBB88_127
.LBB88_123:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_127
.LBB88_124:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_281
// %bb.125:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_127
.LBB88_126:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_127:
	ldr	x21, [sp, #104]
	cbz	x21, .LBB88_134
// %bb.128:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_130
// %bb.129:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_131
	b	.LBB88_134
.LBB88_130:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_134
.LBB88_131:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_282
// %bb.132:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_134
.LBB88_133:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_134:
	adrp	x8, .LCPI88_2
	stp	xzr, xzr, [sp, #96]
	str	xzr, [sp, #112]
	ldr	q0, [x8, :lo12:.LCPI88_2]
	mov	x8, #175921860444160
	movk	x8, #16484, lsl #48
	str	q0, [sp, #64]
	str	x8, [sp, #80]
.Ltmp524:
	mov	w0, #104
	bl	_Znwm
.Ltmp525:
// %bb.135:
	movi	v0.2s, #1
	adrp	x25, _ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x25, x25, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x25, [x0]
.Ltmp527:
	add	x0, sp, #48
	add	x2, sp, #96
	add	x3, sp, #64
	sub	x4, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp528:
// %bb.136:
	mov	w8, #15
	stp	x22, x21, [sp, #128]
	str	w8, [sp, #96]
.Ltmp530:
	mov	w0, #112
	bl	_Znwm
.Ltmp531:
// %bb.137:
	movi	v0.2s, #1
	adrp	x26, _ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	add	x26, x26, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x23, x0, #16
	str	d0, [x0, #8]
	str	x26, [x0]
.Ltmp533:
	add	x0, sp, #64
	add	x2, sp, #128
	add	x3, sp, #96
	mov	x1, x23
	bl	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
.Ltmp534:
// %bb.138:
	ldr	x21, [sp, #136]
	stp	x23, x22, [sp, #128]
	cbz	x21, .LBB88_145
// %bb.139:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_141
// %bb.140:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_142
	b	.LBB88_145
.LBB88_141:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_145
.LBB88_142:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_283
// %bb.143:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_145
.LBB88_144:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_145:
	adrp	x8, .LCPI88_3
	mov	x9, #123145302310912
	movk	x9, #16498, lsl #48
	str	xzr, [sp, #64]
	ldr	q0, [x8, :lo12:.LCPI88_3]
	add	x8, sp, #64
	add	x0, x8, #8
	str	x9, [sp, #112]
	str	q0, [sp, #96]
.Ltmp536:
	add	x1, sp, #64
	add	x2, sp, #48
	add	x3, sp, #128
	add	x4, sp, #96
	bl	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
.Ltmp537:
// %bb.146:
	ldp	x8, x9, [sp, #64]
	stp	xzr, xzr, [sp, #64]
	ldr	x21, [sp, #136]
	stp	x8, x9, [sp, #128]
	cbz	x21, .LBB88_153
// %bb.147:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_149
// %bb.148:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_150
	b	.LBB88_153
.LBB88_149:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_153
.LBB88_150:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_284
// %bb.151:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_153
.LBB88_152:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_153:
	ldr	x21, [sp, #72]
	cbz	x21, .LBB88_160
// %bb.154:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_156
// %bb.155:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_157
	b	.LBB88_160
.LBB88_156:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_160
.LBB88_157:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_285
// %bb.158:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_160
.LBB88_159:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_160:
	mov	x8, #175921860444160
	stp	xzr, xzr, [sp, #96]
	movk	x8, #16484, lsl #48
	str	xzr, [sp, #112]
	dup	v0.2d, x8
	str	x8, [sp, #80]
	str	q0, [sp, #64]
.Ltmp539:
	mov	w0, #104
	bl	_Znwm
.Ltmp540:
// %bb.161:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x25, [x0]
	str	d0, [x0, #8]
.Ltmp542:
	add	x0, sp, #24
	add	x2, sp, #96
	add	x3, sp, #64
	sub	x4, x29, #48
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp543:
// %bb.162:
	mov	w8, #-18
	stp	x22, x21, [sp, #48]
	str	w8, [sp, #96]
.Ltmp545:
	mov	w0, #112
	bl	_Znwm
.Ltmp546:
// %bb.163:
	movi	v0.2s, #1
	mov	x22, x0
	add	x23, x0, #16
	str	x26, [x0]
	str	d0, [x0, #8]
.Ltmp548:
	add	x0, sp, #64
	add	x2, sp, #48
	add	x3, sp, #96
	mov	x1, x23
	bl	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
.Ltmp549:
// %bb.164:
	ldr	x21, [sp, #56]
	stp	x23, x22, [sp, #48]
	cbz	x21, .LBB88_171
// %bb.165:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_167
// %bb.166:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_168
	b	.LBB88_171
.LBB88_167:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_171
.LBB88_168:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_286
// %bb.169:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_171
.LBB88_170:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_171:
	adrp	x8, .LCPI88_4
	mov	x9, #70368744177664
	movk	x9, #16464, lsl #48
	str	xzr, [sp, #64]
	ldr	q0, [x8, :lo12:.LCPI88_4]
	add	x8, sp, #64
	add	x0, x8, #8
	str	x9, [sp, #112]
	str	q0, [sp, #96]
.Ltmp551:
	add	x1, sp, #64
	add	x2, sp, #24
	add	x3, sp, #48
	add	x4, sp, #96
	bl	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
.Ltmp552:
// %bb.172:
	ldp	x8, x9, [sp, #64]
	stp	xzr, xzr, [sp, #64]
	ldr	x21, [sp, #56]
	stp	x8, x9, [sp, #48]
	cbz	x21, .LBB88_179
// %bb.173:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_175
// %bb.174:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_176
	b	.LBB88_179
.LBB88_175:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_179
.LBB88_176:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_287
// %bb.177:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_179
.LBB88_178:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_179:
	ldr	x21, [sp, #72]
	cbz	x21, .LBB88_186
// %bb.180:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_182
// %bb.181:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_183
	b	.LBB88_186
.LBB88_182:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_186
.LBB88_183:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_288
// %bb.184:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_186
.LBB88_185:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_186:
	mov	x8, #5243
	stp	xzr, xzr, [sp, #96]
	movk	x8, #18350, lsl #16
	str	xzr, [sp, #112]
	movk	x8, #31457, lsl #32
	movk	x8, #16260, lsl #48
	str	x8, [sp, #24]
.Ltmp554:
	mov	w0, #64
	bl	_Znwm
.Ltmp555:
// %bb.187:
	movi	v0.2s, #1
	adrp	x23, _ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x23, x23, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x23, [x0]
.Ltmp557:
	sub	x0, x29, #104
	add	x2, sp, #128
	add	x3, sp, #24
	add	x4, sp, #96
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_
.Ltmp558:
// %bb.188:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #32]
	stp	xzr, xzr, [sp, #64]
	cmp	x1, x8
	b.eq	.LBB88_191
// %bb.189:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_195
// %bb.190:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #40]
	cbnz	x21, .LBB88_193
	b	.LBB88_200
.LBB88_191:
.Ltmp560:
	add	x2, sp, #32
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp561:
// %bb.192:
	ldr	x21, [sp, #40]
	cbz	x21, .LBB88_200
.LBB88_193:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_196
// %bb.194:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_197
	b	.LBB88_200
.LBB88_195:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x21, [sp, #40]
	cbnz	x21, .LBB88_193
	b	.LBB88_200
.LBB88_196:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_200
.LBB88_197:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_289
// %bb.198:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_200
.LBB88_199:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_200:
	ldr	x21, [sp, #72]
	cbz	x21, .LBB88_207
// %bb.201:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_203
// %bb.202:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB88_204
	b	.LBB88_207
.LBB88_203:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_207
.LBB88_204:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_290
// %bb.205:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB88_207
.LBB88_206:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_207:
	mov	x8, #5243
	mov	x9, #4607182418800017408
	movk	x8, #18350, lsl #16
	movk	x8, #31457, lsl #32
	fmov	v0.2d, #1.00000000
	movk	x8, #16260, lsl #48
	str	x9, [sp, #112]
	str	x8, [sp, #24]
	str	q0, [sp, #96]
.Ltmp563:
	mov	w0, #64
	bl	_Znwm
.Ltmp564:
// %bb.208:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x23, [x0]
	str	d0, [x0, #8]
.Ltmp566:
	sub	x0, x29, #104
	add	x2, sp, #48
	add	x3, sp, #24
	add	x4, sp, #96
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_
.Ltmp567:
// %bb.209:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [sp, #8]
	stp	xzr, xzr, [sp, #64]
	cmp	x1, x8
	b.eq	.LBB88_212
// %bb.210:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB88_216
// %bb.211:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #16]
	cbnz	x19, .LBB88_214
	b	.LBB88_221
.LBB88_212:
.Ltmp569:
	add	x2, sp, #8
	mov	x0, x20
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp570:
// %bb.213:
	ldr	x19, [sp, #16]
	cbz	x19, .LBB88_221
.LBB88_214:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_217
// %bb.215:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_218
	b	.LBB88_221
.LBB88_216:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x19, #16]
	add	x8, x1, #16
	str	x8, [x19, #16]
	ldr	x19, [sp, #16]
	cbnz	x19, .LBB88_214
	b	.LBB88_221
.LBB88_217:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_221
.LBB88_218:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_291
// %bb.219:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_221
.LBB88_220:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_221:
	ldr	x19, [sp, #72]
	cbz	x19, .LBB88_228
// %bb.222:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_224
// %bb.223:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_225
	b	.LBB88_228
.LBB88_224:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_228
.LBB88_225:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_292
// %bb.226:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_228
.LBB88_227:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_228:
	ldr	x19, [sp, #56]
	cbz	x19, .LBB88_235
// %bb.229:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_231
// %bb.230:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_232
	b	.LBB88_235
.LBB88_231:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_235
.LBB88_232:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_293
// %bb.233:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_235
.LBB88_234:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_235:
	ldr	x19, [sp, #136]
	cbz	x19, .LBB88_242
// %bb.236:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_238
// %bb.237:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_239
	b	.LBB88_242
.LBB88_238:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_242
.LBB88_239:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_294
// %bb.240:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_242
.LBB88_241:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_242:
	ldur	x19, [x29, #-72]
	cbz	x19, .LBB88_249
// %bb.243:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_245
// %bb.244:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_246
	b	.LBB88_249
.LBB88_245:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_249
.LBB88_246:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_295
// %bb.247:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_249
.LBB88_248:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_249:
	ldur	x19, [x29, #-56]
	cbz	x19, .LBB88_256
// %bb.250:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_252
// %bb.251:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_253
	b	.LBB88_256
.LBB88_252:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_256
.LBB88_253:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_296
// %bb.254:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_256
.LBB88_255:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_256:
	ldur	x19, [x29, #-40]
	cbz	x19, .LBB88_263
// %bb.257:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_259
// %bb.258:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_260
	b	.LBB88_263
.LBB88_259:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_263
.LBB88_260:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_297
// %bb.261:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_263
.LBB88_262:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_263:
	ldur	x19, [x29, #-24]
	cbz	x19, .LBB88_270
// %bb.264:
	ldrb	w8, [x24]
	cbz	w8, .LBB88_266
// %bb.265:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB88_267
	b	.LBB88_270
.LBB88_266:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB88_270
.LBB88_267:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB88_298
// %bb.268:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB88_270
.LBB88_269:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB88_270:
	ldp	x20, x19, [sp, #400]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #384]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #368]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #352]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #328]            // 16-byte Folded Reload
	ldr	x28, [sp, #344]                 // 8-byte Folded Reload
	ldr	d8, [sp, #320]                  // 8-byte Folded Reload
	add	sp, sp, #416
	ret
.LBB88_271:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_21
	b	.LBB88_22
.LBB88_272:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_28
	b	.LBB88_29
.LBB88_273:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_42
	b	.LBB88_43
.LBB88_274:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_49
	b	.LBB88_50
.LBB88_275:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_63
	b	.LBB88_64
.LBB88_276:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_70
	b	.LBB88_71
.LBB88_277:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_84
	b	.LBB88_85
.LBB88_278:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_91
	b	.LBB88_92
.LBB88_279:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_105
	b	.LBB88_106
.LBB88_280:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_112
	b	.LBB88_113
.LBB88_281:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_126
	b	.LBB88_127
.LBB88_282:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_133
	b	.LBB88_134
.LBB88_283:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_144
	b	.LBB88_145
.LBB88_284:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_152
	b	.LBB88_153
.LBB88_285:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_159
	b	.LBB88_160
.LBB88_286:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_170
	b	.LBB88_171
.LBB88_287:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_178
	b	.LBB88_179
.LBB88_288:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_185
	b	.LBB88_186
.LBB88_289:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_199
	b	.LBB88_200
.LBB88_290:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_206
	b	.LBB88_207
.LBB88_291:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_220
	b	.LBB88_221
.LBB88_292:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_227
	b	.LBB88_228
.LBB88_293:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_234
	b	.LBB88_235
.LBB88_294:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_241
	b	.LBB88_242
.LBB88_295:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_248
	b	.LBB88_249
.LBB88_296:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_255
	b	.LBB88_256
.LBB88_297:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_262
	b	.LBB88_263
.LBB88_298:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB88_269
	b	.LBB88_270
.LBB88_299:
.Ltmp571:
	mov	x20, x0
	add	x0, sp, #8
	b	.LBB88_301
.LBB88_300:
.Ltmp562:
	mov	x20, x0
	add	x0, sp, #32
.LBB88_301:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #64
	bl	_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB88_319
.LBB88_302:
.Ltmp523:
	mov	x20, x0
	add	x0, sp, #144
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #96
	bl	_ZNSt12__shared_ptrI7xy_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB88_340
.LBB88_303:
.Ltmp514:
	mov	x20, x0
	add	x0, sp, #160
	b	.LBB88_306
.LBB88_304:
.Ltmp505:
	mov	x20, x0
	sub	x0, x29, #152
	b	.LBB88_306
.LBB88_305:
.Ltmp496:
	mov	x20, x0
	sub	x0, x29, #136
.LBB88_306:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #96
	bl	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB88_340
.LBB88_307:
.Ltmp487:
	mov	x20, x0
	sub	x0, x29, #120
	b	.LBB88_309
.LBB88_308:
.Ltmp478:
	mov	x20, x0
	sub	x0, x29, #96
.LBB88_309:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #96
	bl	_ZNSt12__shared_ptrI7yz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB88_340
.LBB88_310:
.Ltmp568:
	b	.LBB88_313
.LBB88_311:
.Ltmp565:
	b	.LBB88_318
.LBB88_312:
.Ltmp559:
.LBB88_313:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB88_319
.LBB88_314:
.Ltmp556:
	b	.LBB88_318
.LBB88_315:
.Ltmp553:
	b	.LBB88_318
.LBB88_316:
.Ltmp550:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB88_319
.LBB88_317:
.Ltmp547:
.LBB88_318:
	mov	x20, x0
.LBB88_319:
	add	x0, sp, #48
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB88_320:
	add	x0, sp, #128
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB88_340
.LBB88_321:
.Ltmp544:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB88_320
.LBB88_322:
.Ltmp541:
	mov	x20, x0
	b	.LBB88_320
.LBB88_323:
.Ltmp538:
	mov	x20, x0
	b	.LBB88_320
.LBB88_324:
.Ltmp535:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB88_320
.LBB88_325:
.Ltmp532:
	mov	x20, x0
	b	.LBB88_320
.LBB88_326:
.Ltmp529:
	b	.LBB88_339
.LBB88_327:
.Ltmp526:
	mov	x20, x0
	b	.LBB88_340
.LBB88_328:
.Ltmp520:
	b	.LBB88_339
.LBB88_329:
.Ltmp517:
	mov	x20, x0
	b	.LBB88_340
.LBB88_330:
.Ltmp511:
	b	.LBB88_339
.LBB88_331:
.Ltmp508:
	mov	x20, x0
	b	.LBB88_340
.LBB88_332:
.Ltmp502:
	b	.LBB88_339
.LBB88_333:
.Ltmp499:
	mov	x20, x0
	b	.LBB88_340
.LBB88_334:
.Ltmp493:
	b	.LBB88_339
.LBB88_335:
.Ltmp490:
	mov	x20, x0
	b	.LBB88_340
.LBB88_336:
.Ltmp484:
	b	.LBB88_339
.LBB88_337:
.Ltmp481:
	mov	x20, x0
	b	.LBB88_340
.LBB88_338:
.Ltmp475:
.LBB88_339:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
.LBB88_340:
	sub	x0, x29, #80
	bl	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB88_341:
	sub	x0, x29, #64
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB88_342:
	sub	x0, x29, #48
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB88_343:
.Ltmp472:
	mov	x20, x0
	b	.LBB88_340
.LBB88_344:
.Ltmp469:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB88_341
.LBB88_345:
.Ltmp466:
	mov	x20, x0
	b	.LBB88_341
.LBB88_346:
.Ltmp463:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB88_342
.LBB88_347:
.Ltmp460:
	mov	x20, x0
	b	.LBB88_342
.LBB88_348:
.Ltmp457:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB88_349:
.Ltmp454:
	mov	x20, x0
	sub	x0, x29, #32
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB88_350:
.Ltmp451:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.LBB88_351:
.Ltmp448:
	mov	x20, x0
	mov	x0, x19
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end88:
	.size	_Z13cornell_smokev, .Lfunc_end88-_Z13cornell_smokev
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table88:
.Lexception16:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end16-.Lcst_begin16
.Lcst_begin16:
	.uleb128 .Ltmp446-.Lfunc_begin16        // >> Call Site 1 <<
	.uleb128 .Ltmp447-.Ltmp446              //   Call between .Ltmp446 and .Ltmp447
	.uleb128 .Ltmp448-.Lfunc_begin16        //     jumps to .Ltmp448
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp449-.Lfunc_begin16        // >> Call Site 2 <<
	.uleb128 .Ltmp450-.Ltmp449              //   Call between .Ltmp449 and .Ltmp450
	.uleb128 .Ltmp451-.Lfunc_begin16        //     jumps to .Ltmp451
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp452-.Lfunc_begin16        // >> Call Site 3 <<
	.uleb128 .Ltmp453-.Ltmp452              //   Call between .Ltmp452 and .Ltmp453
	.uleb128 .Ltmp454-.Lfunc_begin16        //     jumps to .Ltmp454
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp455-.Lfunc_begin16        // >> Call Site 4 <<
	.uleb128 .Ltmp456-.Ltmp455              //   Call between .Ltmp455 and .Ltmp456
	.uleb128 .Ltmp457-.Lfunc_begin16        //     jumps to .Ltmp457
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp458-.Lfunc_begin16        // >> Call Site 5 <<
	.uleb128 .Ltmp459-.Ltmp458              //   Call between .Ltmp458 and .Ltmp459
	.uleb128 .Ltmp460-.Lfunc_begin16        //     jumps to .Ltmp460
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp461-.Lfunc_begin16        // >> Call Site 6 <<
	.uleb128 .Ltmp462-.Ltmp461              //   Call between .Ltmp461 and .Ltmp462
	.uleb128 .Ltmp463-.Lfunc_begin16        //     jumps to .Ltmp463
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp464-.Lfunc_begin16        // >> Call Site 7 <<
	.uleb128 .Ltmp465-.Ltmp464              //   Call between .Ltmp464 and .Ltmp465
	.uleb128 .Ltmp466-.Lfunc_begin16        //     jumps to .Ltmp466
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp467-.Lfunc_begin16        // >> Call Site 8 <<
	.uleb128 .Ltmp468-.Ltmp467              //   Call between .Ltmp467 and .Ltmp468
	.uleb128 .Ltmp469-.Lfunc_begin16        //     jumps to .Ltmp469
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp470-.Lfunc_begin16        // >> Call Site 9 <<
	.uleb128 .Ltmp471-.Ltmp470              //   Call between .Ltmp470 and .Ltmp471
	.uleb128 .Ltmp472-.Lfunc_begin16        //     jumps to .Ltmp472
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp473-.Lfunc_begin16        // >> Call Site 10 <<
	.uleb128 .Ltmp474-.Ltmp473              //   Call between .Ltmp473 and .Ltmp474
	.uleb128 .Ltmp475-.Lfunc_begin16        //     jumps to .Ltmp475
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp476-.Lfunc_begin16        // >> Call Site 11 <<
	.uleb128 .Ltmp477-.Ltmp476              //   Call between .Ltmp476 and .Ltmp477
	.uleb128 .Ltmp478-.Lfunc_begin16        //     jumps to .Ltmp478
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp477-.Lfunc_begin16        // >> Call Site 12 <<
	.uleb128 .Ltmp479-.Ltmp477              //   Call between .Ltmp477 and .Ltmp479
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp479-.Lfunc_begin16        // >> Call Site 13 <<
	.uleb128 .Ltmp480-.Ltmp479              //   Call between .Ltmp479 and .Ltmp480
	.uleb128 .Ltmp481-.Lfunc_begin16        //     jumps to .Ltmp481
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp482-.Lfunc_begin16        // >> Call Site 14 <<
	.uleb128 .Ltmp483-.Ltmp482              //   Call between .Ltmp482 and .Ltmp483
	.uleb128 .Ltmp484-.Lfunc_begin16        //     jumps to .Ltmp484
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp485-.Lfunc_begin16        // >> Call Site 15 <<
	.uleb128 .Ltmp486-.Ltmp485              //   Call between .Ltmp485 and .Ltmp486
	.uleb128 .Ltmp487-.Lfunc_begin16        //     jumps to .Ltmp487
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp486-.Lfunc_begin16        // >> Call Site 16 <<
	.uleb128 .Ltmp488-.Ltmp486              //   Call between .Ltmp486 and .Ltmp488
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp488-.Lfunc_begin16        // >> Call Site 17 <<
	.uleb128 .Ltmp489-.Ltmp488              //   Call between .Ltmp488 and .Ltmp489
	.uleb128 .Ltmp490-.Lfunc_begin16        //     jumps to .Ltmp490
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp491-.Lfunc_begin16        // >> Call Site 18 <<
	.uleb128 .Ltmp492-.Ltmp491              //   Call between .Ltmp491 and .Ltmp492
	.uleb128 .Ltmp493-.Lfunc_begin16        //     jumps to .Ltmp493
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp494-.Lfunc_begin16        // >> Call Site 19 <<
	.uleb128 .Ltmp495-.Ltmp494              //   Call between .Ltmp494 and .Ltmp495
	.uleb128 .Ltmp496-.Lfunc_begin16        //     jumps to .Ltmp496
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp495-.Lfunc_begin16        // >> Call Site 20 <<
	.uleb128 .Ltmp497-.Ltmp495              //   Call between .Ltmp495 and .Ltmp497
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp497-.Lfunc_begin16        // >> Call Site 21 <<
	.uleb128 .Ltmp498-.Ltmp497              //   Call between .Ltmp497 and .Ltmp498
	.uleb128 .Ltmp499-.Lfunc_begin16        //     jumps to .Ltmp499
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp500-.Lfunc_begin16        // >> Call Site 22 <<
	.uleb128 .Ltmp501-.Ltmp500              //   Call between .Ltmp500 and .Ltmp501
	.uleb128 .Ltmp502-.Lfunc_begin16        //     jumps to .Ltmp502
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp503-.Lfunc_begin16        // >> Call Site 23 <<
	.uleb128 .Ltmp504-.Ltmp503              //   Call between .Ltmp503 and .Ltmp504
	.uleb128 .Ltmp505-.Lfunc_begin16        //     jumps to .Ltmp505
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp504-.Lfunc_begin16        // >> Call Site 24 <<
	.uleb128 .Ltmp506-.Ltmp504              //   Call between .Ltmp504 and .Ltmp506
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp506-.Lfunc_begin16        // >> Call Site 25 <<
	.uleb128 .Ltmp507-.Ltmp506              //   Call between .Ltmp506 and .Ltmp507
	.uleb128 .Ltmp508-.Lfunc_begin16        //     jumps to .Ltmp508
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp509-.Lfunc_begin16        // >> Call Site 26 <<
	.uleb128 .Ltmp510-.Ltmp509              //   Call between .Ltmp509 and .Ltmp510
	.uleb128 .Ltmp511-.Lfunc_begin16        //     jumps to .Ltmp511
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp512-.Lfunc_begin16        // >> Call Site 27 <<
	.uleb128 .Ltmp513-.Ltmp512              //   Call between .Ltmp512 and .Ltmp513
	.uleb128 .Ltmp514-.Lfunc_begin16        //     jumps to .Ltmp514
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp513-.Lfunc_begin16        // >> Call Site 28 <<
	.uleb128 .Ltmp515-.Ltmp513              //   Call between .Ltmp513 and .Ltmp515
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp515-.Lfunc_begin16        // >> Call Site 29 <<
	.uleb128 .Ltmp516-.Ltmp515              //   Call between .Ltmp515 and .Ltmp516
	.uleb128 .Ltmp517-.Lfunc_begin16        //     jumps to .Ltmp517
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp518-.Lfunc_begin16        // >> Call Site 30 <<
	.uleb128 .Ltmp519-.Ltmp518              //   Call between .Ltmp518 and .Ltmp519
	.uleb128 .Ltmp520-.Lfunc_begin16        //     jumps to .Ltmp520
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp521-.Lfunc_begin16        // >> Call Site 31 <<
	.uleb128 .Ltmp522-.Ltmp521              //   Call between .Ltmp521 and .Ltmp522
	.uleb128 .Ltmp523-.Lfunc_begin16        //     jumps to .Ltmp523
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp522-.Lfunc_begin16        // >> Call Site 32 <<
	.uleb128 .Ltmp524-.Ltmp522              //   Call between .Ltmp522 and .Ltmp524
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp524-.Lfunc_begin16        // >> Call Site 33 <<
	.uleb128 .Ltmp525-.Ltmp524              //   Call between .Ltmp524 and .Ltmp525
	.uleb128 .Ltmp526-.Lfunc_begin16        //     jumps to .Ltmp526
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp527-.Lfunc_begin16        // >> Call Site 34 <<
	.uleb128 .Ltmp528-.Ltmp527              //   Call between .Ltmp527 and .Ltmp528
	.uleb128 .Ltmp529-.Lfunc_begin16        //     jumps to .Ltmp529
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp530-.Lfunc_begin16        // >> Call Site 35 <<
	.uleb128 .Ltmp531-.Ltmp530              //   Call between .Ltmp530 and .Ltmp531
	.uleb128 .Ltmp532-.Lfunc_begin16        //     jumps to .Ltmp532
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp533-.Lfunc_begin16        // >> Call Site 36 <<
	.uleb128 .Ltmp534-.Ltmp533              //   Call between .Ltmp533 and .Ltmp534
	.uleb128 .Ltmp535-.Lfunc_begin16        //     jumps to .Ltmp535
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp534-.Lfunc_begin16        // >> Call Site 37 <<
	.uleb128 .Ltmp536-.Ltmp534              //   Call between .Ltmp534 and .Ltmp536
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp536-.Lfunc_begin16        // >> Call Site 38 <<
	.uleb128 .Ltmp537-.Ltmp536              //   Call between .Ltmp536 and .Ltmp537
	.uleb128 .Ltmp538-.Lfunc_begin16        //     jumps to .Ltmp538
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp537-.Lfunc_begin16        // >> Call Site 39 <<
	.uleb128 .Ltmp539-.Ltmp537              //   Call between .Ltmp537 and .Ltmp539
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp539-.Lfunc_begin16        // >> Call Site 40 <<
	.uleb128 .Ltmp540-.Ltmp539              //   Call between .Ltmp539 and .Ltmp540
	.uleb128 .Ltmp541-.Lfunc_begin16        //     jumps to .Ltmp541
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp542-.Lfunc_begin16        // >> Call Site 41 <<
	.uleb128 .Ltmp543-.Ltmp542              //   Call between .Ltmp542 and .Ltmp543
	.uleb128 .Ltmp544-.Lfunc_begin16        //     jumps to .Ltmp544
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp545-.Lfunc_begin16        // >> Call Site 42 <<
	.uleb128 .Ltmp546-.Ltmp545              //   Call between .Ltmp545 and .Ltmp546
	.uleb128 .Ltmp547-.Lfunc_begin16        //     jumps to .Ltmp547
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp548-.Lfunc_begin16        // >> Call Site 43 <<
	.uleb128 .Ltmp549-.Ltmp548              //   Call between .Ltmp548 and .Ltmp549
	.uleb128 .Ltmp550-.Lfunc_begin16        //     jumps to .Ltmp550
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp549-.Lfunc_begin16        // >> Call Site 44 <<
	.uleb128 .Ltmp551-.Ltmp549              //   Call between .Ltmp549 and .Ltmp551
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp551-.Lfunc_begin16        // >> Call Site 45 <<
	.uleb128 .Ltmp552-.Ltmp551              //   Call between .Ltmp551 and .Ltmp552
	.uleb128 .Ltmp553-.Lfunc_begin16        //     jumps to .Ltmp553
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp552-.Lfunc_begin16        // >> Call Site 46 <<
	.uleb128 .Ltmp554-.Ltmp552              //   Call between .Ltmp552 and .Ltmp554
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp554-.Lfunc_begin16        // >> Call Site 47 <<
	.uleb128 .Ltmp555-.Ltmp554              //   Call between .Ltmp554 and .Ltmp555
	.uleb128 .Ltmp556-.Lfunc_begin16        //     jumps to .Ltmp556
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp557-.Lfunc_begin16        // >> Call Site 48 <<
	.uleb128 .Ltmp558-.Ltmp557              //   Call between .Ltmp557 and .Ltmp558
	.uleb128 .Ltmp559-.Lfunc_begin16        //     jumps to .Ltmp559
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp560-.Lfunc_begin16        // >> Call Site 49 <<
	.uleb128 .Ltmp561-.Ltmp560              //   Call between .Ltmp560 and .Ltmp561
	.uleb128 .Ltmp562-.Lfunc_begin16        //     jumps to .Ltmp562
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp561-.Lfunc_begin16        // >> Call Site 50 <<
	.uleb128 .Ltmp563-.Ltmp561              //   Call between .Ltmp561 and .Ltmp563
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp563-.Lfunc_begin16        // >> Call Site 51 <<
	.uleb128 .Ltmp564-.Ltmp563              //   Call between .Ltmp563 and .Ltmp564
	.uleb128 .Ltmp565-.Lfunc_begin16        //     jumps to .Ltmp565
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp566-.Lfunc_begin16        // >> Call Site 52 <<
	.uleb128 .Ltmp567-.Ltmp566              //   Call between .Ltmp566 and .Ltmp567
	.uleb128 .Ltmp568-.Lfunc_begin16        //     jumps to .Ltmp568
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp569-.Lfunc_begin16        // >> Call Site 53 <<
	.uleb128 .Ltmp570-.Ltmp569              //   Call between .Ltmp569 and .Ltmp570
	.uleb128 .Ltmp571-.Lfunc_begin16        //     jumps to .Ltmp571
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp570-.Lfunc_begin16        // >> Call Site 54 <<
	.uleb128 .Lfunc_end88-.Ltmp570          //   Call between .Ltmp570 and .Lfunc_end88
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end16:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB89_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB89_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB89_4
	b	.LBB89_8
.LBB89_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB89_8
.LBB89_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB89_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB89_8
.LBB89_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB89_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB89_6
.LBB89_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end89:
	.size	_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end89-_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _Z11final_scenev
.LCPI90_0:
	.xword	0x3fdeb851eb851eb8              // double 0.47999999999999998
	.xword	0x3fea8f5c28f5c28f              // double 0.82999999999999996
.LCPI90_1:
	.xword	0x407ae00000000000              // double 430
	.xword	0x4079000000000000              // double 400
.LCPI90_2:
	.xword	0x3fe6666666666666              // double 0.69999999999999996
	.xword	0x3fd3333333333333              // double 0.29999999999999999
.LCPI90_3:
	.xword	0x4070400000000000              // double 260
	.xword	0x4062c00000000000              // double 150
.LCPI90_4:
	.xword	0x4046800000000000              // double 45
	.xword	0x4049000000000000              // double 50
.LCPI90_5:
	.xword	0x3feccccccccccccd              // double 0.90000000000000002
	.xword	0x3ff0000000000000              // double 1
.LCPI90_6:
	.xword	0x0000000000000000              // double 0
	.xword	0x4062c00000000000              // double 150
.LCPI90_7:
	.xword	0x4062200000000000              // double 145
	.xword	0x4049000000000000              // double 50
.LCPI90_8:
	.xword	0x4076800000000000              // double 360
	.xword	0x4062c00000000000              // double 150
.LCPI90_9:
	.xword	0x4062200000000000              // double 145
	.xword	0x4051800000000000              // double 70
.LCPI90_10:
	.xword	0x3fc999999999999a              // double 0.20000000000000001
	.xword	0x3fd999999999999a              // double 0.40000000000000002
.LCPI90_11:
	.xword	0x4079000000000000              // double 400
	.xword	0x4069000000000000              // double 200
.LCPI90_12:
	.xword	0x4079000000000000              // double 400
	.xword	0x4059000000000000              // double 100
.LCPI90_13:
	.xword	0x406b800000000000              // double 220
	.xword	0x4071800000000000              // double 280
.LCPI90_14:
	.xword	0x4072c00000000000              // double 300
	.xword	0x4054000000000000              // double 80
.LCPI90_15:
	.xword	0xc059000000000000              // double -100
	.xword	0x4070e00000000000              // double 270
	.text
	.globl	_Z11final_scenev
	.p2align	2
	.type	_Z11final_scenev,@function
_Z11final_scenev:                       // @_Z11final_scenev
.Lfunc_begin17:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception17
// %bb.0:
	stp	d13, d12, [sp, #-144]!          // 16-byte Folded Spill
	stp	d11, d10, [sp, #16]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #32]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x28, x27, [sp, #64]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	sub	sp, sp, #592
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	adrp	x8, _ZTV13hittable_list+16
	add	x28, sp, #208
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	stp	x8, xzr, [x28, #328]
	stp	xzr, xzr, [x28, #344]
.Ltmp572:
	mov	w0, #40
	bl	_Znwm
.Ltmp573:
// %bb.1:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	mov	x19, x0
	str	x8, [x0]
	adrp	x8, _ZTV10lambertian+16
	add	x8, x8, :lo12:_ZTV10lambertian+16
	str	d8, [x0, #8]
	str	x8, [x19, #16]!
.Ltmp575:
	mov	w0, #48
	bl	_Znwm
.Ltmp576:
// %bb.2:
	adrp	x8, .LCPI90_0
	adrp	x10, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x10, x10, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x11, _ZTV11solid_color+16
	add	x11, x11, :lo12:_ZTV11solid_color+16
	mov	x9, x0
	ldr	q0, [x8, :lo12:.LCPI90_0]
	mov	x8, #10486
	movk	x8, #36700, lsl #16
	str	x10, [x0]
	movk	x8, #62914, lsl #32
	sub	x10, x29, #104
	movk	x8, #16352, lsl #48
	adrp	x25, :got:__libc_single_threaded
	str	d8, [x0, #8]
	mov	x21, #70368744177664
	str	x11, [x9, #16]!
	str	x8, [x0, #40]
	add	x8, x10, #8
	stur	q0, [x0, #24]
	movk	x21, #49295, lsl #48
	stp	x9, x0, [x22, #24]
	mov	x26, #4636737291354636288
	str	x8, [sp, #32]                   // 8-byte Folded Spill
	mov	w8, wzr
	fmov	d9, #1.00000000
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
	stp	x19, x22, [x28, #312]
	mov	x22, #4467570830351532032
	mov	w12, wzr
	b	.LBB90_4
.LBB90_3:                               //   in Loop: Header=BB90_4 Depth=1
	ldr	w8, [sp, #48]                   // 4-byte Folded Reload
	add	w8, w8, #1
	cmp	w8, #20
	b.eq	.LBB90_41
.LBB90_4:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB90_7 Depth 2
                                        //       Child Loop BB90_18 Depth 3
                                        //       Child Loop BB90_20 Depth 3
	scvtf	d0, w8
	fmov	d1, x21
	fmov	d2, x26
	mov	w19, wzr
	str	w8, [sp, #48]                   // 4-byte Folded Spill
	fmadd	d10, d0, d2, d1
	fadd	d11, d10, d2
	b	.LBB90_7
.LBB90_5:                               //   in Loop: Header=BB90_7 Depth=2
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_6:                               //   in Loop: Header=BB90_7 Depth=2
	add	w19, w19, #1
	cmp	w19, #20
	b.eq	.LBB90_3
.LBB90_7:                               //   Parent Loop BB90_4 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB90_18 Depth 3
                                        //       Child Loop BB90_20 Depth 3
	scvtf	d0, w19
	fmov	d1, x21
	fmov	d12, x26
	fmadd	d13, d0, d12, d1
	bl	rand
	scvtf	d0, w0
	fmov	d1, x22
	str	d10, [sp, #160]
	str	xzr, [sp, #168]
	str	d13, [sp, #176]
	fmul	d0, d0, d1
	fadd	d1, d13, d12
	str	d11, [x28, #272]
	fmadd	d0, d0, d12, d9
	str	d1, [x28, #288]
	str	d0, [x28, #280]
.Ltmp578:
	mov	w0, #104
	bl	_Znwm
.Ltmp579:
// %bb.8:                               //   in Loop: Header=BB90_7 Depth=2
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x23, x0
	add	x24, x0, #16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
.Ltmp581:
	sub	x0, x29, #192
	add	x2, sp, #160
	sub	x3, x29, #160
	sub	x4, x29, #120
	mov	x1, x24
	bl	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp582:
// %bb.9:                               //   in Loop: Header=BB90_7 Depth=2
	ldp	x27, x8, [x28, #344]
	stp	x24, x23, [x28, #296]
	stp	xzr, xzr, [x28, #192]
	cmp	x27, x8
	b.eq	.LBB90_12
// %bb.10:                              //   in Loop: Header=BB90_7 Depth=2
	stp	x24, x23, [x27]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_24
// %bb.11:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
	add	x8, x27, #16
	str	x8, [x28, #344]
	ldr	x20, [x28, #304]
	cbnz	x20, .LBB90_25
	b	.LBB90_31
.LBB90_12:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	x20, [x28, #336]
	mov	x8, #9223372036854775792
	sub	x28, x27, x20
	cmp	x28, x8
	b.eq	.LBB90_588
// %bb.13:                              //   in Loop: Header=BB90_7 Depth=2
	asr	x25, x28, #4
	cmp	x28, #0
	csinc	x8, x25, xzr, ne
	adds	x8, x8, x25
	lsr	x9, x8, #59
	cset	w10, hs
	cmp	x9, #0
	cset	w9, ne
	orr	w9, w10, w9
	cmp	w9, #0
	mov	x9, #576460752303423487
	csel	x21, x9, x8, ne
	lsl	x0, x21, #4
.Ltmp584:
	bl	_Znwm
.Ltmp585:
// %bb.14:                              //   in Loop: Header=BB90_7 Depth=2
	add	x8, x0, x25, lsl #4
	adrp	x25, :got:__libc_single_threaded
	mov	x22, x0
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
	stp	x24, x23, [x8]
	ldrb	w9, [x25]
	cbz	w9, .LBB90_37
// %bb.15:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
	movi	v4.2d, #0000000000000000
	cmp	x20, x27
	b.eq	.LBB90_38
.LBB90_16:                              //   in Loop: Header=BB90_7 Depth=2
	sub	x9, x28, #16
	mov	x23, x22
	mov	x8, x20
	add	x28, sp, #208
	cmp	x9, #48
	b.lo	.LBB90_20
// %bb.17:                              //   in Loop: Header=BB90_7 Depth=2
	lsr	x8, x9, #4
	add	x11, x22, #32
	add	x9, x8, #1
	add	x12, x20, #32
	and	x10, x9, #0x1ffffffffffffffc
	lsl	x8, x10, #4
	mov	x13, x10
	add	x23, x22, x8
	add	x8, x20, x8
.LBB90_18:                              //   Parent Loop BB90_4 Depth=1
                                        //     Parent Loop BB90_7 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldp	q1, q0, [x12, #-32]
	subs	x13, x13, #4
	ldp	q3, q2, [x12]
	stp	q1, q0, [x11, #-32]
	stp	q3, q2, [x11], #64
	stp	q4, q4, [x12, #-32]
	stp	q4, q4, [x12], #64
	b.ne	.LBB90_18
// %bb.19:                              //   in Loop: Header=BB90_7 Depth=2
	cmp	x9, x10
	b.eq	.LBB90_21
.LBB90_20:                              //   Parent Loop BB90_4 Depth=1
                                        //     Parent Loop BB90_7 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	x9, [x8]
	str	x9, [x23]
	ldr	x9, [x8, #8]
	str	x9, [x23, #8]
	add	x23, x23, #16
	stp	xzr, xzr, [x8], #16
	cmp	x8, x27
	b.ne	.LBB90_20
.LBB90_21:                              //   in Loop: Header=BB90_7 Depth=2
	cbz	x20, .LBB90_23
.LBB90_22:                              //   in Loop: Header=BB90_7 Depth=2
	mov	x0, x20
	bl	_ZdlPv
.LBB90_23:                              //   in Loop: Header=BB90_7 Depth=2
	add	x8, x23, #16
	add	x9, x22, x21, lsl #4
	mov	x21, #70368744177664
	movk	x21, #49295, lsl #48
	stp	x22, x8, [x28, #336]
	mov	x22, #4467570830351532032
	str	x9, [x28, #352]
	ldr	x20, [x28, #304]
	cbnz	x20, .LBB90_25
	b	.LBB90_31
.LBB90_24:                              //   in Loop: Header=BB90_7 Depth=2
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x27, [x28, #344]
	add	x8, x27, #16
	str	x8, [x28, #344]
	ldr	x20, [x28, #304]
	cbz	x20, .LBB90_31
.LBB90_25:                              //   in Loop: Header=BB90_7 Depth=2
	ldrb	w8, [x25]
	cbz	w8, .LBB90_27
// %bb.26:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB90_28
	b	.LBB90_31
.LBB90_27:                              //   in Loop: Header=BB90_7 Depth=2
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_31
.LBB90_28:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_39
// %bb.29:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB90_31
.LBB90_30:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_31:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	x20, [x28, #200]
	cbz	x20, .LBB90_6
// %bb.32:                              //   in Loop: Header=BB90_7 Depth=2
	ldrb	w8, [x25]
	cbz	w8, .LBB90_34
// %bb.33:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB90_6
	b	.LBB90_35
.LBB90_34:                              //   in Loop: Header=BB90_7 Depth=2
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_6
.LBB90_35:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_40
// %bb.36:                              //   in Loop: Header=BB90_7 Depth=2
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB90_6
	b	.LBB90_5
.LBB90_37:                              //   in Loop: Header=BB90_7 Depth=2
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	movi	v4.2d, #0000000000000000
	cmp	x20, x27
	b.ne	.LBB90_16
.LBB90_38:                              //   in Loop: Header=BB90_7 Depth=2
	mov	x23, x22
	add	x28, sp, #208
	cbnz	x20, .LBB90_22
	b	.LBB90_23
.LBB90_39:                              //   in Loop: Header=BB90_7 Depth=2
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_30
	b	.LBB90_31
.LBB90_40:                              //   in Loop: Header=BB90_7 Depth=2
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_6
	b	.LBB90_5
.LBB90_41:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	mov	x9, x19
	stp	xzr, xzr, [x19, #16]
	str	x8, [x19]
	str	xzr, [x9, #8]!
	str	x9, [sp]                        // 8-byte Folded Spill
.Ltmp587:
	mov	w0, #104
	bl	_Znwm
.Ltmp588:
// %bb.42:
	ldp	x9, x8, [x28, #336]
	movi	v0.2s, #1
	mov	x22, x0
	add	x23, x0, #16
	sub	x8, x8, x9
	str	d0, [x0, #8]
	asr	x3, x8, #4
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	x8, [x0]
.Ltmp590:
	movi	d0, #0000000000000000
	fmov	d1, #1.00000000
	mov	x0, x23
	ldr	x1, [sp, #32]                   // 8-byte Folded Reload
	mov	x2, xzr
	bl	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.Ltmp591:
	adrp	x20, _ZTV10lambertian+16
	add	x20, x20, :lo12:_ZTV10lambertian+16
// %bb.43:
	ldp	x1, x8, [x19, #16]!
	str	x19, [sp, #8]                   // 8-byte Folded Spill
	stp	x23, x22, [x28, #256]
	stp	xzr, xzr, [sp, #160]
	cmp	x1, x8
	b.eq	.LBB90_46
// %bb.44:
	stp	x23, x22, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_50
// %bb.45:
	ldr	w8, [x22, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #264]
	cbnz	x21, .LBB90_48
	b	.LBB90_55
.LBB90_46:
.Ltmp593:
	sub	x2, x29, #176
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp594:
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
// %bb.47:
	ldr	x21, [x28, #264]
	cbz	x21, .LBB90_55
.LBB90_48:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_51
// %bb.49:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_52
	b	.LBB90_55
.LBB90_50:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #264]
	cbnz	x21, .LBB90_48
	b	.LBB90_55
.LBB90_51:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_55
.LBB90_52:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_217
// %bb.53:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_55
.LBB90_54:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_55:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_62
// %bb.56:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_58
// %bb.57:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_59
	b	.LBB90_62
.LBB90_58:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_62
.LBB90_59:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_218
// %bb.60:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_62
.LBB90_61:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_62:
	str	xzr, [x28, #240]
.Ltmp596:
	mov	w0, #40
	bl	_Znwm
.Ltmp597:
// %bb.63:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v8.2s, #1
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x19, x0
	str	x8, [x0]
	adrp	x8, _ZTV13diffuse_light+16
	add	x8, x8, :lo12:_ZTV13diffuse_light+16
	str	d8, [x0, #8]
	str	x8, [x19, #16]!
.Ltmp599:
	mov	w0, #48
	bl	_Znwm
.Ltmp600:
// %bb.64:
	adrp	x10, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x8, x0
	add	x10, x10, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x9, #4619567317775286272
	fmov	v0.2d, #7.00000000
	str	d8, [x0, #8]
	stp	x19, x21, [x28, #240]
	str	x10, [x0]
	adrp	x10, _ZTV11solid_color+16
	add	x10, x10, :lo12:_ZTV11solid_color+16
	str	x9, [x0, #40]
	mov	w9, #423
	stur	q0, [x0, #24]
	str	x10, [x8, #16]!
	stp	x8, x0, [x21, #24]
	mov	w8, #123
	mov	w10, #147
	stur	w9, [x29, #-240]
	mov	w9, #554
	stur	w8, [x29, #-160]
	mov	w8, #412
	stur	w10, [x29, #-256]
	str	w9, [sp, #272]
	str	w8, [sp, #336]
.Ltmp602:
	mov	w0, #80
	bl	_Znwm
.Ltmp603:
// %bb.65:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp605:
	add	x0, sp, #224
	sub	x2, x29, #160
	sub	x3, x29, #240
	sub	x4, x29, #256
	add	x5, sp, #336
	add	x6, sp, #272
	sub	x7, x29, #192
	mov	x1, x22
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	bl	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
.Ltmp606:
// %bb.66:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x28, #224]
	stp	xzr, xzr, [sp, #160]
	cmp	x1, x8
	b.eq	.LBB90_69
// %bb.67:
	stp	x22, x21, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_73
// %bb.68:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #232]
	cbnz	x21, .LBB90_71
	b	.LBB90_78
.LBB90_69:
.Ltmp608:
	sub	x2, x29, #208
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp609:
// %bb.70:
	ldr	x21, [x28, #232]
	cbz	x21, .LBB90_78
.LBB90_71:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_74
// %bb.72:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_75
	b	.LBB90_78
.LBB90_73:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #232]
	cbnz	x21, .LBB90_71
	b	.LBB90_78
.LBB90_74:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_78
.LBB90_75:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_219
// %bb.76:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_78
.LBB90_77:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_78:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_85
// %bb.79:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_81
// %bb.80:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_82
	b	.LBB90_85
.LBB90_81:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_85
.LBB90_82:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_220
// %bb.83:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_85
.LBB90_84:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_85:
	adrp	x10, .LCPI90_1
	mov	x8, #4645744490609377280
	mov	x9, #4641240890982006784
	str	xzr, [x28, #176]
	ldr	q1, [x10, :lo12:.LCPI90_1]
	dup	v0.2d, x8
	str	x9, [x28, #288]
	str	x9, [x28, #208]
	str	q0, [x28, #272]
	str	q1, [x28, #192]
.Ltmp611:
	mov	w0, #40
	bl	_Znwm
.Ltmp612:
// %bb.86:
	movi	v8.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x19, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
	str	x20, [x19, #16]!
.Ltmp614:
	mov	w0, #48
	bl	_Znwm
.Ltmp615:
// %bb.87:
	adrp	x11, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x8, x0
	add	x11, x11, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x9, .LCPI90_2
	mov	x10, #-7378697629483820647
	str	d8, [x0, #8]
	movk	x10, #39322
	stp	x19, x21, [x28, #176]
	str	x11, [x0]
	adrp	x11, _ZTV11solid_color+16
	add	x11, x11, :lo12:_ZTV11solid_color+16
	movk	x10, #16313, lsl #48
	ldr	q0, [x9, :lo12:.LCPI90_2]
	mov	w9, #50
	str	wzr, [sp, #336]
	str	x11, [x8, #16]!
	stp	x8, x0, [x21, #24]
	mov	w8, #1
	str	x10, [x0, #40]
	stur	q0, [x0, #24]
	str	w8, [sp, #272]
	str	w9, [sp, #224]
.Ltmp617:
	mov	w0, #112
	bl	_Znwm
.Ltmp618:
// %bb.88:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp620:
	add	x0, sp, #192
	sub	x2, x29, #160
	sub	x3, x29, #240
	add	x4, sp, #336
	add	x5, sp, #272
	add	x6, sp, #224
	sub	x7, x29, #256
	mov	x1, x22
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	bl	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Ltmp621:
// %bb.89:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x28, #160]
	stp	xzr, xzr, [sp, #160]
	cmp	x1, x8
	b.eq	.LBB90_92
// %bb.90:
	stp	x22, x21, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_96
// %bb.91:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #168]
	cbnz	x21, .LBB90_94
	b	.LBB90_101
.LBB90_92:
.Ltmp623:
	add	x2, sp, #368
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp624:
// %bb.93:
	ldr	x21, [x28, #168]
	cbz	x21, .LBB90_101
.LBB90_94:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_97
// %bb.95:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_98
	b	.LBB90_101
.LBB90_96:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #168]
	cbnz	x21, .LBB90_94
	b	.LBB90_101
.LBB90_97:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_101
.LBB90_98:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_221
// %bb.99:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_101
.LBB90_100:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_101:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_108
// %bb.102:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_104
// %bb.103:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_105
	b	.LBB90_108
.LBB90_104:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_108
.LBB90_105:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_222
// %bb.106:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_108
.LBB90_107:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_108:
.Ltmp626:
	mov	w0, #32
	bl	_Znwm
.Ltmp627:
// %bb.109:
	movi	v8.2s, #1
	adrp	x24, _ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x26, _ZTV10dielectric+16
	mov	x22, x0
	add	x24, x24, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x26, x26, :lo12:_ZTV10dielectric+16
	mov	x20, x0
	mov	x8, #4609434218613702656
	str	d8, [x0, #8]
	str	x24, [x0]
	str	x26, [x20, #16]!
	str	x8, [x0, #24]
	stp	x20, x0, [x28, #128]
	str	xzr, [sp, #160]
.Ltmp629:
	mov	w0, #72
	bl	_Znwm
.Ltmp630:
// %bb.110:
	adrp	x8, .LCPI90_3
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x19, x0
	mov	x21, x0
	str	d8, [x0, #8]
	ldr	q0, [x8, :lo12:.LCPI90_3]
	adrp	x8, _ZTV6sphere+16
	str	x9, [x0]
	adrp	x9, .LCPI90_4
	add	x8, x8, :lo12:_ZTV6sphere+16
	stp	xzr, xzr, [x28, #128]
	stur	q0, [x0, #24]
	ldr	q0, [x9, :lo12:.LCPI90_4]
	stp	x20, x22, [x0, #56]
	str	x8, [x19, #16]!
	ldrb	w8, [x25]
	stur	q0, [x0, #40]
	cbz	w8, .LBB90_112
// %bb.111:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_115
	b	.LBB90_118
.LBB90_112:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB90_114
// %bb.113:
	ldr	w0, [x22, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_115
	b	.LBB90_118
.LBB90_114:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_118
.LBB90_115:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_150
// %bb.116:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB90_118
.LBB90_117:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_118:
	ldr	x8, [sp, #16]                   // 8-byte Folded Reload
	stp	x19, x21, [x28, #144]
	stp	xzr, xzr, [sp, #160]
	ldp	x1, x8, [x8, #16]
	cmp	x1, x8
	b.eq	.LBB90_121
// %bb.119:
	stp	x19, x21, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_125
// %bb.120:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #152]
	cbnz	x21, .LBB90_123
	b	.LBB90_130
.LBB90_121:
.Ltmp632:
	add	x2, sp, #352
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp633:
// %bb.122:
	ldr	x21, [x28, #152]
	cbz	x21, .LBB90_130
.LBB90_123:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_126
// %bb.124:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_127
	b	.LBB90_130
.LBB90_125:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #152]
	cbnz	x21, .LBB90_123
	b	.LBB90_130
.LBB90_126:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_130
.LBB90_127:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_223
// %bb.128:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_130
.LBB90_129:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_130:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_137
// %bb.131:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_133
// %bb.132:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_134
	b	.LBB90_137
.LBB90_133:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_137
.LBB90_134:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_224
// %bb.135:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_137
.LBB90_136:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_137:
	ldr	x21, [x28, #136]
	cbz	x21, .LBB90_144
// %bb.138:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_140
// %bb.139:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_141
	b	.LBB90_144
.LBB90_140:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_144
.LBB90_141:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_225
// %bb.142:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_144
.LBB90_143:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_144:
.Ltmp635:
	mov	w0, #56
	bl	_Znwm
.Ltmp636:
// %bb.145:
	mov	x8, #-7378697629483820647
	movi	v8.2s, #1
	movk	x8, #39322
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movk	x8, #16361, lsl #48
	mov	x21, x0
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x20, x0
	str	d8, [x0, #8]
	dup	v0.2d, x8
	adrp	x8, .LCPI90_5
	str	x9, [x0]
	stur	q0, [x0, #24]
	ldr	q0, [x8, :lo12:.LCPI90_5]
	adrp	x8, _ZTV5metal+16
	add	x8, x8, :lo12:_ZTV5metal+16
	str	xzr, [sp, #160]
	stur	q0, [x0, #40]
	str	x8, [x20, #16]!
	stp	x20, x0, [x28, #128]
.Ltmp638:
	mov	w0, #72
	bl	_Znwm
.Ltmp639:
// %bb.146:
	adrp	x8, .LCPI90_6
	adrp	x9, .LCPI90_7
	mov	x19, x0
	adrp	x10, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	add	x10, x10, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	q0, [x8, :lo12:.LCPI90_6]
	adrp	x8, _ZTV6sphere+16
	add	x8, x8, :lo12:_ZTV6sphere+16
	ldr	q1, [x9, :lo12:.LCPI90_7]
	str	d8, [x0, #8]
	str	x10, [x0]
	str	x8, [x19, #16]!
	ldrb	w8, [x25]
	stp	xzr, xzr, [x28, #128]
	stur	q0, [x0, #24]
	stur	q1, [x0, #40]
	stp	x20, x21, [x0, #56]
	cbz	w8, .LBB90_148
// %bb.147:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_152
	b	.LBB90_155
.LBB90_148:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB90_151
// %bb.149:
	ldr	w0, [x21, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_152
	b	.LBB90_155
.LBB90_150:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_117
	b	.LBB90_118
.LBB90_151:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_155
.LBB90_152:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_187
// %bb.153:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_155
.LBB90_154:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_155:
	ldr	x8, [sp, #16]                   // 8-byte Folded Reload
	stp	x19, x22, [x28, #112]
	stp	xzr, xzr, [sp, #160]
	ldp	x1, x8, [x8, #16]
	cmp	x1, x8
	b.eq	.LBB90_158
// %bb.156:
	stp	x19, x22, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_162
// %bb.157:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #120]
	cbnz	x21, .LBB90_160
	b	.LBB90_167
.LBB90_158:
.Ltmp641:
	add	x2, sp, #320
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp642:
// %bb.159:
	ldr	x21, [x28, #120]
	cbz	x21, .LBB90_167
.LBB90_160:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_163
// %bb.161:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_164
	b	.LBB90_167
.LBB90_162:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #120]
	cbnz	x21, .LBB90_160
	b	.LBB90_167
.LBB90_163:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_167
.LBB90_164:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_226
// %bb.165:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_167
.LBB90_166:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_167:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_174
// %bb.168:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_170
// %bb.169:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_171
	b	.LBB90_174
.LBB90_170:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_174
.LBB90_171:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_227
// %bb.172:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_174
.LBB90_173:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_174:
	ldr	x21, [x28, #136]
	cbz	x21, .LBB90_181
// %bb.175:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_177
// %bb.176:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_178
	b	.LBB90_181
.LBB90_177:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_181
.LBB90_178:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_228
// %bb.179:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_181
.LBB90_180:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_181:
.Ltmp644:
	mov	w0, #32
	bl	_Znwm
.Ltmp645:
// %bb.182:
	movi	v8.2s, #1
	mov	x21, x0
	mov	x20, x0
	mov	x8, #4609434218613702656
	str	x24, [x0]
	str	xzr, [x28, #128]
	str	x26, [x20, #16]!
	str	x8, [x0, #24]
	str	d8, [x0, #8]
	stp	x20, x0, [sp, #160]
.Ltmp647:
	mov	w0, #72
	bl	_Znwm
.Ltmp648:
// %bb.183:
	adrp	x8, .LCPI90_8
	adrp	x9, .LCPI90_9
	mov	x19, x0
	adrp	x10, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	add	x10, x10, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	q0, [x8, :lo12:.LCPI90_8]
	adrp	x8, _ZTV6sphere+16
	add	x8, x8, :lo12:_ZTV6sphere+16
	ldr	q1, [x9, :lo12:.LCPI90_9]
	str	d8, [x0, #8]
	str	x10, [x0]
	str	x8, [x19, #16]!
	ldrb	w8, [x25]
	stp	xzr, xzr, [sp, #160]
	stur	q0, [x0, #24]
	stur	q1, [x0, #40]
	stp	x20, x21, [x0, #56]
	cbz	w8, .LBB90_185
// %bb.184:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_189
	b	.LBB90_192
.LBB90_185:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB90_188
// %bb.186:
	ldr	w0, [x21, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_189
	b	.LBB90_192
.LBB90_187:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_154
	b	.LBB90_155
.LBB90_188:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_192
.LBB90_189:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_215
// %bb.190:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_192
.LBB90_191:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_192:
	ldr	x21, [sp, #168]
	stp	x19, x22, [x28, #128]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	cbz	x21, .LBB90_199
// %bb.193:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_195
// %bb.194:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_196
	b	.LBB90_199
.LBB90_195:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_199
.LBB90_196:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_229
// %bb.197:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_199
.LBB90_198:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_199:
	ldp	x9, x8, [x28, #128]
	stp	x9, x8, [x28, #96]
	cbz	x8, .LBB90_202
// %bb.200:
	ldrb	w9, [x25]
	cbz	w9, .LBB90_207
// %bb.201:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB90_202:
	ldp	x1, x8, [x19, #16]
	cmp	x1, x8
	b.eq	.LBB90_208
.LBB90_203:
	ldr	x8, [x28, #96]
	str	x8, [x1]
	ldr	x8, [x28, #104]
	str	x8, [x1, #8]
	cbz	x8, .LBB90_206
// %bb.204:
	ldrb	w9, [x25]
	cbz	w9, .LBB90_216
// %bb.205:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB90_206:
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #104]
	cbnz	x21, .LBB90_210
	b	.LBB90_232
.LBB90_207:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x1, x8, [x19, #16]
	cmp	x1, x8
	b.ne	.LBB90_203
.LBB90_208:
.Ltmp650:
	add	x2, sp, #304
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp651:
// %bb.209:
	ldr	x21, [x28, #104]
	cbz	x21, .LBB90_232
.LBB90_210:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_212
// %bb.211:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_213
	b	.LBB90_232
.LBB90_212:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_232
.LBB90_213:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_230
// %bb.214:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_232
	b	.LBB90_231
.LBB90_215:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_191
	b	.LBB90_192
.LBB90_216:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #104]
	cbnz	x21, .LBB90_210
	b	.LBB90_232
.LBB90_217:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_54
	b	.LBB90_55
.LBB90_218:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_61
	b	.LBB90_62
.LBB90_219:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_77
	b	.LBB90_78
.LBB90_220:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_84
	b	.LBB90_85
.LBB90_221:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_100
	b	.LBB90_101
.LBB90_222:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_107
	b	.LBB90_108
.LBB90_223:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_129
	b	.LBB90_130
.LBB90_224:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_136
	b	.LBB90_137
.LBB90_225:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_143
	b	.LBB90_144
.LBB90_226:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_166
	b	.LBB90_167
.LBB90_227:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_173
	b	.LBB90_174
.LBB90_228:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_180
	b	.LBB90_181
.LBB90_229:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_198
	b	.LBB90_199
.LBB90_230:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_232
.LBB90_231:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_232:
	adrp	x8, .LCPI90_10
	mov	x9, #-7378697629483820647
	movk	x9, #39322
	movk	x9, #16329, lsl #48
	ldr	q0, [x8, :lo12:.LCPI90_10]
	mov	x8, #-3689348814741910324
	movk	x8, #52429
	movk	x8, #16364, lsl #48
	str	x9, [x28, #16]
	str	q0, [sp, #160]
	str	x8, [sp, #176]
.Ltmp653:
	mov	w0, #64
	bl	_Znwm
.Ltmp654:
// %bb.233:
	movi	v0.2s, #1
	adrp	x25, _ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x25, x25, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x22, x0, #16
	str	d0, [x0, #8]
	str	x25, [x0]
.Ltmp656:
	add	x0, sp, #192
	add	x2, sp, #336
	add	x3, sp, #224
	add	x4, sp, #160
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_
.Ltmp657:
// %bb.234:
	ldp	x1, x8, [x19, #16]
	stp	x22, x21, [x28, #80]
	stp	xzr, xzr, [x28, #64]
	cmp	x1, x8
	b.eq	.LBB90_237
// %bb.235:
	adrp	x8, :got:__libc_single_threaded
	str	x22, [x1]
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	str	x21, [x1, #8]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_241
// %bb.236:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #88]
	cbnz	x21, .LBB90_239
	b	.LBB90_246
.LBB90_237:
.Ltmp659:
	add	x2, sp, #288
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp660:
// %bb.238:
	ldr	x21, [x28, #88]
	cbz	x21, .LBB90_246
.LBB90_239:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_242
// %bb.240:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_243
	b	.LBB90_246
.LBB90_241:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #88]
	cbnz	x21, .LBB90_239
	b	.LBB90_246
.LBB90_242:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_246
.LBB90_243:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_328
// %bb.244:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_246
.LBB90_245:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_246:
	ldr	x21, [x28, #72]
	cbz	x21, .LBB90_253
// %bb.247:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_249
// %bb.248:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_250
	b	.LBB90_253
.LBB90_249:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_253
.LBB90_250:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_329
// %bb.251:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_253
.LBB90_252:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_253:
.Ltmp662:
	mov	w0, #32
	bl	_Znwm
.Ltmp663:
// %bb.254:
	movi	v8.2s, #1
	mov	x21, x0
	mov	x20, x0
	mov	x8, #4609434218613702656
	str	x24, [x0]
	str	x26, [x20, #16]!
	str	x8, [x0, #24]
	str	d8, [x0, #8]
	stp	x20, x0, [sp, #160]
.Ltmp665:
	mov	w0, #72
	bl	_Znwm
.Ltmp666:
// %bb.255:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x19, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x24, :got:__libc_single_threaded
	str	d8, [x0, #8]
	adrp	x26, _ZTV10lambertian+16
	stp	xzr, xzr, [sp, #160]
	mov	x22, x0
	str	x8, [x0]
	adrp	x8, _ZTV6sphere+16
	add	x8, x8, :lo12:_ZTV6sphere+16
	stp	xzr, xzr, [x0, #24]
	add	x26, x26, :lo12:_ZTV10lambertian+16
	str	x8, [x19, #16]!
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	mov	x8, #149533581377536
	movk	x8, #16563, lsl #48
	stp	x20, x21, [x0, #56]
	ldrb	w9, [x24]
	stp	xzr, x8, [x0, #40]
	cbz	w9, .LBB90_257
// %bb.256:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_260
	b	.LBB90_263
.LBB90_257:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB90_259
// %bb.258:
	ldr	w0, [x21, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_260
	b	.LBB90_263
.LBB90_259:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_263
.LBB90_260:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_305
// %bb.261:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_263
.LBB90_262:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_263:
	ldr	x21, [x28, #136]
	stp	x19, x22, [x28, #128]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	cbz	x21, .LBB90_270
// %bb.264:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_266
// %bb.265:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_267
	b	.LBB90_270
.LBB90_266:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_270
.LBB90_267:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_330
// %bb.268:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_270
.LBB90_269:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_270:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_277
// %bb.271:
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_273
// %bb.272:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_274
	b	.LBB90_277
.LBB90_273:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_277
.LBB90_274:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_331
// %bb.275:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_277
.LBB90_276:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_277:
	mov	x8, #17197
	mov	x9, #4607182418800017408
	movk	x8, #60188, lsl #16
	movk	x8, #14050, lsl #32
	fmov	v0.2d, #1.00000000
	movk	x8, #16154, lsl #48
	str	x9, [sp, #176]
	str	x8, [x28, #16]
	str	q0, [sp, #160]
.Ltmp668:
	mov	w0, #64
	bl	_Znwm
.Ltmp669:
// %bb.278:
	movi	v0.2s, #1
	mov	x21, x0
	add	x22, x0, #16
	str	x25, [x0]
	str	d0, [x0, #8]
.Ltmp671:
	add	x0, sp, #192
	add	x2, sp, #336
	add	x3, sp, #224
	add	x4, sp, #160
	mov	x1, x22
	bl	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_
.Ltmp672:
// %bb.279:
	ldp	x1, x8, [x19, #16]
	adrp	x24, :got:__libc_single_threaded
	stp	x22, x21, [x28, #48]
	stp	xzr, xzr, [x28, #64]
	adrp	x25, _ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x25, x25, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	cmp	x1, x8
	b.eq	.LBB90_282
// %bb.280:
	stp	x22, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB90_286
// %bb.281:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #56]
	cbnz	x21, .LBB90_284
	b	.LBB90_291
.LBB90_282:
.Ltmp674:
	add	x2, sp, #256
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp675:
// %bb.283:
	ldr	x21, [x28, #56]
	cbz	x21, .LBB90_291
.LBB90_284:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_287
// %bb.285:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_288
	b	.LBB90_291
.LBB90_286:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #56]
	cbnz	x21, .LBB90_284
	b	.LBB90_291
.LBB90_287:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_291
.LBB90_288:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_332
// %bb.289:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_291
.LBB90_290:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_291:
	ldr	x21, [x28, #72]
	cbz	x21, .LBB90_298
// %bb.292:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_294
// %bb.293:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_295
	b	.LBB90_298
.LBB90_294:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_298
.LBB90_295:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_333
// %bb.296:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_298
.LBB90_297:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_298:
.Ltmp677:
	mov	w0, #48
	bl	_Znwm
.Ltmp678:
// %bb.299:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x23, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp680:
	adrp	x1, .L.str.3
	mov	x0, x23
	add	x1, x1, :lo12:.L.str.3
	bl	_ZN13image_textureC2EPKc
.Ltmp681:
// %bb.300:
	stp	x23, x21, [sp, #160]
	str	xzr, [x28, #64]
.Ltmp683:
	mov	w0, #40
	bl	_Znwm
.Ltmp684:
// %bb.301:
	movi	v0.2s, #1
	mov	x22, x0
	mov	x19, x0
	ldrb	w8, [x24]
	str	x25, [x0]
	stp	xzr, xzr, [sp, #160]
	str	x26, [x19, #16]!
	str	d0, [x0, #8]
	stp	x23, x21, [x0, #24]
	cbz	w8, .LBB90_303
// %bb.302:
	ldr	w8, [x21, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.eq	.LBB90_307
	b	.LBB90_310
.LBB90_303:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB90_306
// %bb.304:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.eq	.LBB90_307
	b	.LBB90_310
.LBB90_305:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_262
	b	.LBB90_263
.LBB90_306:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_310
.LBB90_307:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_327
// %bb.308:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_310
.LBB90_309:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_310:
	ldr	x21, [sp, #168]
	stp	x19, x22, [x28, #64]
	cbz	x21, .LBB90_317
// %bb.311:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_313
// %bb.312:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_314
	b	.LBB90_317
.LBB90_313:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_317
.LBB90_314:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_334
// %bb.315:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_317
.LBB90_316:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_317:
	str	xzr, [sp, #160]
.Ltmp686:
	mov	w0, #72
	bl	_Znwm
.Ltmp687:
// %bb.318:
	ldp	x20, x22, [x28, #64]
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x19, x0, #16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d0, [x0, #8]
	str	x8, [x0]
	cbz	x22, .LBB90_322
// %bb.319:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_321
// %bb.320:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	b	.LBB90_322
.LBB90_321:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB90_322:
	adrp	x8, .LCPI90_11
	adrp	x9, .LCPI90_12
	stp	x20, x22, [x21, #56]
	ldr	q0, [x8, :lo12:.LCPI90_11]
	adrp	x8, _ZTV6sphere+16
	ldr	q1, [x9, :lo12:.LCPI90_12]
	add	x8, x8, :lo12:_ZTV6sphere+16
	stur	q0, [x21, #24]
	str	x8, [x21, #16]
	stur	q1, [x21, #40]
	cbz	x22, .LBB90_339
// %bb.323:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_325
// %bb.324:
	ldr	w8, [x22, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_336
	b	.LBB90_339
.LBB90_325:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB90_335
// %bb.326:
	ldr	w0, [x22, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_336
	b	.LBB90_339
.LBB90_327:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_309
	b	.LBB90_310
.LBB90_328:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_245
	b	.LBB90_246
.LBB90_329:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_252
	b	.LBB90_253
.LBB90_330:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_269
	b	.LBB90_270
.LBB90_331:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_276
	b	.LBB90_277
.LBB90_332:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_290
	b	.LBB90_291
.LBB90_333:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_297
	b	.LBB90_298
.LBB90_334:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_316
	b	.LBB90_317
.LBB90_335:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_339
.LBB90_336:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_367
// %bb.337:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB90_339
.LBB90_338:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_339:
	ldr	x8, [sp, #16]                   // 8-byte Folded Reload
	stp	x19, x21, [x28, #32]
	stp	xzr, xzr, [sp, #160]
	ldp	x1, x8, [x8, #16]
	cmp	x1, x8
	b.eq	.LBB90_342
// %bb.340:
	stp	x19, x21, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB90_346
// %bb.341:
	ldr	w8, [x21, #8]
	add	w8, w8, #1
	str	w8, [x21, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #40]
	cbnz	x21, .LBB90_344
	b	.LBB90_351
.LBB90_342:
.Ltmp689:
	add	x2, sp, #240
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp690:
// %bb.343:
	ldr	x21, [x28, #40]
	cbz	x21, .LBB90_351
.LBB90_344:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_347
// %bb.345:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_348
	b	.LBB90_351
.LBB90_346:
	add	x1, x21, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #40]
	cbnz	x21, .LBB90_344
	b	.LBB90_351
.LBB90_347:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_351
.LBB90_348:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_368
// %bb.349:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_351
.LBB90_350:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_351:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_358
// %bb.352:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_354
// %bb.353:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_355
	b	.LBB90_358
.LBB90_354:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_358
.LBB90_355:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_369
// %bb.356:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_358
.LBB90_357:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_358:
.Ltmp692:
	mov	w0, #64
	bl	_Znwm
.Ltmp693:
// %bb.359:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x9, _ZTV13noise_texture+16
	mov	x22, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x9, x9, :lo12:_ZTV13noise_texture+16
	mov	x20, x0
	str	d0, [x22, #8]
	str	x8, [x0], #24
	str	x9, [x20, #16]!
.Ltmp695:
	bl	_ZN6perlinC2Ev
.Ltmp696:
// %bb.360:
	mov	x8, #-7378697629483820647
	stp	x20, x22, [x28, #16]
	movk	x8, #39322
	str	xzr, [sp, #192]
	movk	x8, #16313, lsl #48
	str	x8, [x22, #56]
.Ltmp698:
	mov	w0, #40
	bl	_Znwm
.Ltmp699:
// %bb.361:
	movi	v0.2s, #1
	mov	x21, x0
	ldrb	w8, [x24]
	add	x19, x0, #16
	str	x25, [x0]
	str	d0, [x0, #8]
	cbz	w8, .LBB90_363
// %bb.362:
	ldr	w8, [x22, #8]
	stp	x26, x20, [x21, #16]
	str	x22, [x21, #32]
	add	w8, w8, #1
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_371
	b	.LBB90_374
.LBB90_363:
	add	x23, x22, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	stp	x26, x20, [x21, #16]
	str	x22, [x21, #32]
	cbz	w8, .LBB90_365
// %bb.364:
	ldr	w8, [x22, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_371
	b	.LBB90_374
.LBB90_365:
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	cbz	w8, .LBB90_370
// %bb.366:
	ldr	w0, [x22, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_371
	b	.LBB90_374
.LBB90_367:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_338
	b	.LBB90_339
.LBB90_368:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_350
	b	.LBB90_351
.LBB90_369:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_357
	b	.LBB90_358
.LBB90_370:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_374
.LBB90_371:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_379
// %bb.372:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB90_374
.LBB90_373:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_374:
	stp	x19, x21, [sp, #192]
	str	xzr, [sp, #160]
.Ltmp701:
	mov	w0, #72
	bl	_Znwm
.Ltmp702:
// %bb.375:
	adrp	x8, .LCPI90_13
	adrp	x9, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v0.2s, #1
	add	x9, x9, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	mov	x20, x0
	ldr	q1, [x8, :lo12:.LCPI90_13]
	adrp	x8, .LCPI90_14
	str	x9, [x0]
	adrp	x9, _ZTV6sphere+16
	str	d0, [x0, #8]
	add	x9, x9, :lo12:_ZTV6sphere+16
	ldr	q0, [x8, :lo12:.LCPI90_14]
	stur	q1, [x0, #24]
	ldrb	w8, [x24]
	stp	xzr, xzr, [sp, #192]
	str	x9, [x20, #16]!
	stur	q0, [x0, #40]
	stp	x19, x21, [x0, #56]
	cbz	w8, .LBB90_377
// %bb.376:
	ldr	w8, [x21, #8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_381
	b	.LBB90_384
.LBB90_377:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x24]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	cbz	w8, .LBB90_380
// %bb.378:
	ldr	w0, [x21, #8]
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_381
	b	.LBB90_384
.LBB90_379:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_373
	b	.LBB90_374
.LBB90_380:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x23, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_384
.LBB90_381:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_459
// %bb.382:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_384
.LBB90_383:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_384:
	ldp	x1, x8, [x19, #16]
	stp	x20, x22, [x28]
	stp	xzr, xzr, [sp, #160]
	cmp	x1, x8
	b.eq	.LBB90_387
// %bb.385:
	stp	x20, x22, [x1]
	ldrb	w8, [x24]
	cbz	w8, .LBB90_391
// %bb.386:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #8]
	cbnz	x21, .LBB90_389
	b	.LBB90_396
.LBB90_387:
.Ltmp704:
	add	x2, sp, #208
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp705:
// %bb.388:
	ldr	x21, [x28, #8]
	cbz	x21, .LBB90_396
.LBB90_389:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_392
// %bb.390:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_393
	b	.LBB90_396
.LBB90_391:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x23]
	add	x8, x1, #16
	str	x8, [x23]
	ldr	x21, [x28, #8]
	cbnz	x21, .LBB90_389
	b	.LBB90_396
.LBB90_392:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_396
.LBB90_393:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_552
// %bb.394:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_396
.LBB90_395:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_396:
	ldr	x21, [sp, #168]
	cbz	x21, .LBB90_403
// %bb.397:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_399
// %bb.398:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_400
	b	.LBB90_403
.LBB90_399:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_403
.LBB90_400:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_553
// %bb.401:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_403
.LBB90_402:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_403:
	ldr	x21, [sp, #200]
	cbz	x21, .LBB90_410
// %bb.404:
	ldrb	w8, [x24]
	cbz	w8, .LBB90_406
// %bb.405:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.eq	.LBB90_407
	b	.LBB90_410
.LBB90_406:
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_410
.LBB90_407:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB90_554
// %bb.408:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_410
.LBB90_409:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_410:
	adrp	x8, _ZTV13hittable_list+16
	stp	xzr, xzr, [sp, #176]
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	stp	x8, xzr, [sp, #160]
.Ltmp707:
	mov	w0, #40
	bl	_Znwm
.Ltmp708:
// %bb.411:
	movi	v8.2s, #1
	mov	x22, x0
	mov	x23, x0
	str	x25, [x0]
	str	d8, [x0, #8]
	str	x26, [x23, #16]!
.Ltmp710:
	mov	w0, #48
	bl	_Znwm
.Ltmp711:
// %bb.412:
	adrp	x10, _ZTV11solid_color+16
	mov	x8, x0
	add	x10, x10, :lo12:_ZTV11solid_color+16
	mov	x9, #36700
	movk	x9, #62914, lsl #16
	mov	x20, #175921860444160
	movk	x9, #23592, lsl #32
	mov	x28, #4467570830351532032
	str	x10, [x8, #16]!
	adrp	x10, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movk	x9, #16359, lsl #48
	add	x10, x10, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movk	x20, #16484, lsl #48
	movi	d9, #0000000000000000
	mov	w19, #1000
	dup	v0.2d, x9
	str	x9, [x0, #40]
	str	x10, [x0]
	add	x10, sp, #160
	add	x9, x10, #8
	mov	x21, #4621819117588971520
	stur	q0, [x0, #24]
	dup	v1.2d, x28
	dup	v0.2d, x20
	str	d8, [x0, #8]
	str	x9, [sp, #24]                   // 8-byte Folded Spill
	stp	x8, x0, [x22, #24]
	stp	q0, q1, [sp, #32]               // 32-byte Folded Spill
	stp	x23, x22, [sp, #192]
	b	.LBB90_415
.LBB90_413:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_414:                             //   in Loop: Header=BB90_415 Depth=1
	subs	w19, w19, #1
	b.eq	.LBB90_450
.LBB90_415:                             // =>This Inner Loop Header: Depth=1
	bl	rand
	mov	w25, w0
	bl	rand
	mov	w26, w0
	bl	rand
	mov	w24, w0
	str	xzr, [sp, #128]
.Ltmp713:
	mov	w0, #72
	bl	_Znwm
.Ltmp714:
// %bb.416:                             //   in Loop: Header=BB90_415 Depth=1
	ldp	x27, x23, [sp, #192]
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x22, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	d8, [x0, #8]
	str	x8, [x0]
	cbz	x23, .LBB90_420
// %bb.417:                             //   in Loop: Header=BB90_415 Depth=1
	adrp	x8, :got:__libc_single_threaded
	ldr	x8, [x8, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x8]
	cbz	w8, .LBB90_419
// %bb.418:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w8, [x23, #8]
	add	w8, w8, #1
	str	w8, [x23, #8]
	b	.LBB90_420
.LBB90_419:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x23, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB90_420:                             //   in Loop: Header=BB90_415 Depth=1
	fmov	s0, w25
	scvtf	d1, w24
	fmov	d2, x28
	movi	v3.2d, #0000000000000000
	adrp	x8, _ZTV6sphere+16
	mov	v0.s[1], w26
	add	x8, x8, :lo12:_ZTV6sphere+16
	fmul	d1, d1, d2
	fmov	d2, x20
	adrp	x25, :got:__libc_single_threaded
	stp	x21, x27, [x22, #48]
	str	x8, [x22, #16]
	sshll	v0.2d, v0.2s, #0
	str	x23, [x22, #64]
	fmadd	d1, d1, d2, d9
	ldp	q2, q4, [sp, #32]               // 32-byte Folded Reload
	scvtf	v0.2d, v0.2d
	str	d1, [x22, #40]
	fmul	v0.2d, v0.2d, v4.2d
	fmla	v3.2d, v2.2d, v0.2d
	stur	q3, [x22, #24]
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
	cbz	x23, .LBB90_429
// %bb.421:                             //   in Loop: Header=BB90_415 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB90_423
// %bb.422:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w8, [x23, #8]
	add	w0, w8, #1
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.eq	.LBB90_426
	b	.LBB90_429
.LBB90_423:                             //   in Loop: Header=BB90_415 Depth=1
	add	x24, x23, #8
	mov	w0, #1
	mov	x1, x24
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x25]
	cbz	w8, .LBB90_425
// %bb.424:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.eq	.LBB90_426
	b	.LBB90_429
.LBB90_425:                             //   in Loop: Header=BB90_415 Depth=1
	mov	w0, #-1
	mov	x1, x24
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_429
.LBB90_426:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_447
// %bb.427:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	cmp	w0, #1
	b.ne	.LBB90_429
.LBB90_428:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_429:                             //   in Loop: Header=BB90_415 Depth=1
	ldp	x1, x9, [sp, #176]
	add	x8, x22, #16
	stp	xzr, xzr, [sp, #128]
	stp	x8, x22, [sp, #144]
	cmp	x1, x9
	b.eq	.LBB90_432
// %bb.430:                             //   in Loop: Header=BB90_415 Depth=1
	stp	x8, x22, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_436
// %bb.431:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [sp, #176]
	ldr	x22, [sp, #152]
	cbnz	x22, .LBB90_434
	b	.LBB90_441
.LBB90_432:                             //   in Loop: Header=BB90_415 Depth=1
.Ltmp716:
	add	x2, sp, #144
	ldr	x0, [sp, #24]                   // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp717:
// %bb.433:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x22, [sp, #152]
	cbz	x22, .LBB90_441
.LBB90_434:                             //   in Loop: Header=BB90_415 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB90_437
// %bb.435:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB90_438
	b	.LBB90_441
.LBB90_436:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [sp, #176]
	add	x8, x1, #16
	str	x8, [sp, #176]
	ldr	x22, [sp, #152]
	cbnz	x22, .LBB90_434
	b	.LBB90_441
.LBB90_437:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_441
.LBB90_438:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_448
// %bb.439:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB90_441
.LBB90_440:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_441:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x22, [sp, #136]
	cbz	x22, .LBB90_414
// %bb.442:                             //   in Loop: Header=BB90_415 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB90_444
// %bb.443:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.ne	.LBB90_414
	b	.LBB90_445
.LBB90_444:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_414
.LBB90_445:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_449
// %bb.446:                             //   in Loop: Header=BB90_415 Depth=1
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB90_414
	b	.LBB90_413
.LBB90_447:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_428
	b	.LBB90_429
.LBB90_448:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_440
	b	.LBB90_441
.LBB90_449:                             //   in Loop: Header=BB90_415 Depth=1
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_414
	b	.LBB90_413
.LBB90_450:
	str	xzr, [sp, #80]
.Ltmp719:
	mov	w0, #104
	bl	_Znwm
.Ltmp720:
// %bb.451:
	ldp	x9, x8, [sp, #168]
	movi	v0.2s, #1
	mov	x22, x0
	add	x23, x0, #16
	sub	x8, x8, x9
	str	d0, [x0, #8]
	asr	x3, x8, #4
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	str	x8, [x0]
.Ltmp722:
	movi	d0, #0000000000000000
	fmov	d1, #1.00000000
	mov	x0, x23
	ldr	x1, [sp, #24]                   // 8-byte Folded Reload
	mov	x2, xzr
	bl	_ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.Ltmp723:
	add	x24, sp, #208
// %bb.452:
	mov	w8, #15
	stp	x23, x22, [sp, #80]
	str	xzr, [sp, #96]
	str	w8, [sp, #76]
.Ltmp725:
	mov	w0, #112
	bl	_Znwm
.Ltmp726:
// %bb.453:
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x23, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
.Ltmp728:
	sub	x0, x29, #72
	add	x2, sp, #80
	add	x3, sp, #76
	mov	x1, x23
	bl	_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_
.Ltmp729:
// %bb.454:
	stp	x23, x21, [sp, #96]
	str	xzr, [sp, #128]
.Ltmp731:
	mov	w0, #64
	bl	_Znwm
.Ltmp732:
// %bb.455:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x19, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v0.2s, #1
	mov	x22, x0
	stp	xzr, xzr, [sp, #96]
	stp	x23, x21, [x0, #24]
	str	x8, [x0]
	adrp	x8, _ZTV9translate+16
	add	x8, x8, :lo12:_ZTV9translate+16
	str	d0, [x0, #8]
	str	x8, [x19, #16]!
	ldrb	w8, [x25]
	cbz	w8, .LBB90_457
// %bb.456:
	ldr	w8, [x21, #8]
	adrp	x9, .LCPI90_15
	add	w0, w8, #1
	mov	x8, #193514046488576
	ldr	q0, [x9, :lo12:.LCPI90_15]
	movk	x8, #16504, lsl #48
	str	w0, [x21, #8]
	stur	q0, [x22, #40]
	str	x8, [x22, #56]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	ldr	x20, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.eq	.LBB90_461
	b	.LBB90_464
.LBB90_457:
	add	x23, x21, #8
	mov	w0, #1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	adrp	x8, .LCPI90_15
	mov	x9, #193514046488576
	movk	x9, #16504, lsl #48
	ldr	q0, [x8, :lo12:.LCPI90_15]
	ldrb	w8, [x25]
	str	x9, [x22, #56]
	stur	q0, [x22, #40]
	cbz	w8, .LBB90_460
// %bb.458:
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	ldr	x20, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.eq	.LBB90_461
	b	.LBB90_464
.LBB90_459:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_383
	b	.LBB90_384
.LBB90_460:
	mov	w0, #-1
	mov	x1, x23
	bl	__aarch64_ldadd4_acq_rel
	ldr	x20, [sp, #8]                   // 8-byte Folded Reload
	cmp	w0, #1
	b.ne	.LBB90_464
.LBB90_461:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_551
// %bb.462:
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB90_464
.LBB90_463:
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_464:
	ldr	x8, [sp, #16]                   // 8-byte Folded Reload
	stp	x19, x22, [sp, #112]
	stp	xzr, xzr, [sp, #128]
	ldp	x1, x8, [x8, #16]
	cmp	x1, x8
	b.eq	.LBB90_467
// %bb.465:
	stp	x19, x22, [x1]
	ldrb	w8, [x25]
	cbz	w8, .LBB90_471
// %bb.466:
	ldr	w8, [x22, #8]
	add	w8, w8, #1
	str	w8, [x22, #8]
	add	x8, x1, #16
	str	x8, [x20]
	ldr	x19, [sp, #120]
	cbnz	x19, .LBB90_469
	b	.LBB90_476
.LBB90_467:
.Ltmp734:
	add	x2, sp, #112
	ldr	x0, [sp]                        // 8-byte Folded Reload
	bl	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
.Ltmp735:
// %bb.468:
	ldr	x19, [sp, #120]
	cbz	x19, .LBB90_476
.LBB90_469:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_472
// %bb.470:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_473
	b	.LBB90_476
.LBB90_471:
	add	x1, x22, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldr	x1, [x20]
	add	x8, x1, #16
	str	x8, [x20]
	ldr	x19, [sp, #120]
	cbnz	x19, .LBB90_469
	b	.LBB90_476
.LBB90_472:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_476
.LBB90_473:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_555
// %bb.474:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_476
.LBB90_475:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_476:
	ldr	x19, [sp, #136]
	cbz	x19, .LBB90_483
// %bb.477:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_479
// %bb.478:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_480
	b	.LBB90_483
.LBB90_479:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_483
.LBB90_480:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_556
// %bb.481:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_483
.LBB90_482:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_483:
	ldr	x19, [sp, #104]
	cbz	x19, .LBB90_490
// %bb.484:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_486
// %bb.485:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_487
	b	.LBB90_490
.LBB90_486:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_490
.LBB90_487:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_557
// %bb.488:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_490
.LBB90_489:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_490:
	ldr	x19, [sp, #88]
	cbz	x19, .LBB90_497
// %bb.491:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_493
// %bb.492:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_494
	b	.LBB90_497
.LBB90_493:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_497
.LBB90_494:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_558
// %bb.495:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_497
.LBB90_496:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_497:
	ldr	x19, [sp, #200]
	cbz	x19, .LBB90_503
// %bb.498:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_500
// %bb.499:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_501
	b	.LBB90_503
.LBB90_500:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_503
.LBB90_501:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_559
// %bb.502:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB90_560
.LBB90_503:
	ldp	x19, x21, [sp, #168]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	str	x8, [sp, #160]
	b.ne	.LBB90_563
.LBB90_504:
	cbz	x19, .LBB90_506
.LBB90_505:
	mov	x0, x19
	bl	_ZdlPv
.LBB90_506:
	ldr	x19, [x24, #24]
	cbz	x19, .LBB90_513
// %bb.507:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_509
// %bb.508:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_510
	b	.LBB90_513
.LBB90_509:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_513
.LBB90_510:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_571
// %bb.511:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_513
.LBB90_512:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_513:
	ldr	x19, [x24, #72]
	cbz	x19, .LBB90_520
// %bb.514:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_516
// %bb.515:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_517
	b	.LBB90_520
.LBB90_516:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_520
.LBB90_517:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_572
// %bb.518:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_520
.LBB90_519:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_520:
	ldr	x19, [x24, #136]
	cbz	x19, .LBB90_527
// %bb.521:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_523
// %bb.522:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_524
	b	.LBB90_527
.LBB90_523:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_527
.LBB90_524:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_573
// %bb.525:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_527
.LBB90_526:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_527:
	ldr	x19, [x24, #184]
	cbz	x19, .LBB90_534
// %bb.528:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_530
// %bb.529:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_531
	b	.LBB90_534
.LBB90_530:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_534
.LBB90_531:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_574
// %bb.532:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_534
.LBB90_533:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_534:
	ldr	x19, [x24, #248]
	cbz	x19, .LBB90_541
// %bb.535:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_537
// %bb.536:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_538
	b	.LBB90_541
.LBB90_537:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_541
.LBB90_538:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_575
// %bb.539:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB90_541
.LBB90_540:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_541:
	ldr	x19, [x24, #320]
	cbz	x19, .LBB90_547
// %bb.542:
	ldrb	w8, [x25]
	cbz	w8, .LBB90_544
// %bb.543:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB90_545
	b	.LBB90_547
.LBB90_544:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_547
.LBB90_545:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_576
// %bb.546:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB90_577
.LBB90_547:
	ldp	x19, x21, [x24, #336]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	str	x8, [x24, #328]
	b.ne	.LBB90_580
.LBB90_548:
	cbz	x19, .LBB90_550
.LBB90_549:
	mov	x0, x19
	bl	_ZdlPv
.LBB90_550:
	add	sp, sp, #592
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #32]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #16]             // 16-byte Folded Reload
	ldp	d13, d12, [sp], #144            // 16-byte Folded Reload
	ret
.LBB90_551:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_463
	b	.LBB90_464
.LBB90_552:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_395
	b	.LBB90_396
.LBB90_553:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_402
	b	.LBB90_403
.LBB90_554:
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_409
	b	.LBB90_410
.LBB90_555:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_475
	b	.LBB90_476
.LBB90_556:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_482
	b	.LBB90_483
.LBB90_557:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_489
	b	.LBB90_490
.LBB90_558:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_496
	b	.LBB90_497
.LBB90_559:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_503
.LBB90_560:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x19, x21, [sp, #168]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	str	x8, [sp, #160]
	b.ne	.LBB90_563
	b	.LBB90_504
.LBB90_561:                             //   in Loop: Header=BB90_563 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_562:                             //   in Loop: Header=BB90_563 Depth=1
	add	x19, x19, #16
	cmp	x19, x21
	b.eq	.LBB90_570
.LBB90_563:                             // =>This Inner Loop Header: Depth=1
	ldr	x20, [x19, #8]
	cbz	x20, .LBB90_562
// %bb.564:                             //   in Loop: Header=BB90_563 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB90_566
// %bb.565:                             //   in Loop: Header=BB90_563 Depth=1
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB90_562
	b	.LBB90_567
.LBB90_566:                             //   in Loop: Header=BB90_563 Depth=1
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_562
.LBB90_567:                             //   in Loop: Header=BB90_563 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_569
// %bb.568:                             //   in Loop: Header=BB90_563 Depth=1
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB90_562
	b	.LBB90_561
.LBB90_569:                             //   in Loop: Header=BB90_563 Depth=1
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_562
	b	.LBB90_561
.LBB90_570:
	ldr	x19, [sp, #168]
	cbnz	x19, .LBB90_505
	b	.LBB90_506
.LBB90_571:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_512
	b	.LBB90_513
.LBB90_572:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_519
	b	.LBB90_520
.LBB90_573:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_526
	b	.LBB90_527
.LBB90_574:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_533
	b	.LBB90_534
.LBB90_575:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB90_540
	b	.LBB90_541
.LBB90_576:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_547
.LBB90_577:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x19, x21, [x24, #336]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	str	x8, [x24, #328]
	b.ne	.LBB90_580
	b	.LBB90_548
.LBB90_578:                             //   in Loop: Header=BB90_580 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB90_579:                             //   in Loop: Header=BB90_580 Depth=1
	add	x19, x19, #16
	cmp	x19, x21
	b.eq	.LBB90_587
.LBB90_580:                             // =>This Inner Loop Header: Depth=1
	ldr	x20, [x19, #8]
	cbz	x20, .LBB90_579
// %bb.581:                             //   in Loop: Header=BB90_580 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB90_583
// %bb.582:                             //   in Loop: Header=BB90_580 Depth=1
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB90_579
	b	.LBB90_584
.LBB90_583:                             //   in Loop: Header=BB90_580 Depth=1
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_579
.LBB90_584:                             //   in Loop: Header=BB90_580 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB90_586
// %bb.585:                             //   in Loop: Header=BB90_580 Depth=1
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB90_579
	b	.LBB90_578
.LBB90_586:                             //   in Loop: Header=BB90_580 Depth=1
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB90_579
	b	.LBB90_578
.LBB90_587:
	ldr	x19, [x24, #336]
	cbnz	x19, .LBB90_549
	b	.LBB90_550
.LBB90_588:
.Ltmp737:
	adrp	x0, .L.str.8
	add	x0, x0, :lo12:.L.str.8
	bl	_ZSt20__throw_length_errorPKc
.Ltmp738:
// %bb.589:
.LBB90_590:
.Ltmp736:
	mov	x20, x0
	add	x0, sp, #112
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #128
	bl	_ZNSt12__shared_ptrI9translateLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_603
.LBB90_591:
.Ltmp706:
	mov	x20, x0
	add	x0, sp, #208
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_612
.LBB90_592:
.Ltmp691:
	mov	x20, x0
	add	x0, sp, #240
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_654
.LBB90_593:
.Ltmp676:
	mov	x20, x0
	add	x0, sp, #256
	b	.LBB90_595
.LBB90_594:
.Ltmp661:
	mov	x20, x0
	add	x0, sp, #288
.LBB90_595:
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #272
	bl	_ZNSt12__shared_ptrI15constant_mediumLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_655
.LBB90_596:
.Ltmp652:
	mov	x20, x0
	add	x0, sp, #304
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_655
.LBB90_597:
.Ltmp643:
	mov	x20, x0
	add	x0, sp, #320
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_630
.LBB90_598:
.Ltmp634:
	mov	x20, x0
	add	x0, sp, #352
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_633
.LBB90_599:
.Ltmp625:
	mov	x20, x0
	add	x0, sp, #368
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI13moving_sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_656
.LBB90_600:
.Ltmp610:
	mov	x20, x0
	sub	x0, x29, #208
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI7xz_rectLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_657
.LBB90_601:
.Ltmp595:
	mov	x20, x0
	sub	x0, x29, #176
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_658
.LBB90_602:
.Ltmp733:
	mov	x20, x0
.LBB90_603:
	add	x0, sp, #96
	bl	_ZNSt12__shared_ptrI8rotate_yLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_606
.LBB90_604:
.Ltmp730:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB90_606
.LBB90_605:
.Ltmp727:
	mov	x20, x0
.LBB90_606:
	add	x0, sp, #80
	bl	_ZNSt12__shared_ptrI8bvh_nodeLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_651
.LBB90_607:
.Ltmp724:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB90_651
.LBB90_608:
.Ltmp721:
	b	.LBB90_650
.LBB90_609:
.Ltmp712:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB90_652
.LBB90_610:
.Ltmp709:
	mov	x20, x0
	b	.LBB90_652
.LBB90_611:
.Ltmp703:
	mov	x20, x0
.LBB90_612:
	add	x0, sp, #192
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_653
.LBB90_613:
.Ltmp700:
	mov	x20, x0
	b	.LBB90_653
.LBB90_614:
.Ltmp697:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB90_654
.LBB90_615:
.Ltmp694:
	mov	x20, x0
	b	.LBB90_654
.LBB90_616:
.Ltmp688:
	mov	x20, x0
	b	.LBB90_654
.LBB90_617:
.Ltmp685:
	mov	x20, x0
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI13image_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_655
.LBB90_618:
.Ltmp682:
	b	.LBB90_625
.LBB90_619:
.Ltmp679:
	mov	x20, x0
	b	.LBB90_655
.LBB90_620:
.Ltmp673:
	b	.LBB90_625
.LBB90_621:
.Ltmp670:
	mov	x20, x0
	b	.LBB90_655
.LBB90_622:
.Ltmp667:
	mov	x20, x0
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_655
.LBB90_623:
.Ltmp664:
	mov	x20, x0
	b	.LBB90_655
.LBB90_624:
.Ltmp658:
.LBB90_625:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB90_655
.LBB90_626:
.Ltmp655:
	mov	x20, x0
	b	.LBB90_655
.LBB90_627:
.Ltmp649:
	mov	x20, x0
	add	x0, sp, #160
	bl	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_656
.LBB90_628:
.Ltmp646:
	mov	x20, x0
	b	.LBB90_656
.LBB90_629:
.Ltmp640:
	mov	x20, x0
.LBB90_630:
	add	x0, sp, #336
	bl	_ZNSt12__shared_ptrI5metalLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_656
.LBB90_631:
.Ltmp637:
	mov	x20, x0
	b	.LBB90_656
.LBB90_632:
.Ltmp631:
	mov	x20, x0
.LBB90_633:
	add	x0, sp, #336
	bl	_ZNSt12__shared_ptrI10dielectricLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_656
.LBB90_634:
.Ltmp628:
	mov	x20, x0
	b	.LBB90_656
.LBB90_635:
.Ltmp622:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB90_656
.LBB90_636:
.Ltmp619:
	mov	x20, x0
	b	.LBB90_656
.LBB90_637:
.Ltmp616:
	b	.LBB90_640
.LBB90_638:
.Ltmp613:
	mov	x20, x0
	b	.LBB90_657
.LBB90_639:
.Ltmp607:
.LBB90_640:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB90_657
.LBB90_641:
.Ltmp604:
	mov	x20, x0
	b	.LBB90_657
.LBB90_642:
.Ltmp601:
	mov	x20, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB90_658
.LBB90_643:
.Ltmp598:
	mov	x20, x0
	b	.LBB90_658
.LBB90_644:
.Ltmp592:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB90_658
.LBB90_645:
.Ltmp589:
	mov	x20, x0
	b	.LBB90_658
.LBB90_646:
.Ltmp577:
	mov	x20, x0
	mov	x0, x22
	bl	_ZdlPv
	b	.LBB90_665
.LBB90_647:
.Ltmp574:
	mov	x20, x0
	b	.LBB90_665
.LBB90_648:
.Ltmp718:
	mov	x20, x0
	add	x0, sp, #144
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #128
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_651
.LBB90_649:
.Ltmp715:
.LBB90_650:
	mov	x20, x0
.LBB90_651:
	add	x0, sp, #192
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_652:
	add	x0, sp, #160
	bl	_ZN13hittable_listD2Ev
.LBB90_653:
	add	x0, sp, #224
	bl	_ZNSt12__shared_ptrI13noise_textureLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_654:
	add	x0, sp, #272
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_655:
	add	x0, sp, #336
	bl	_ZNSt12__shared_ptrI6sphereLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_656:
	sub	x0, x29, #256
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_657:
	sub	x0, x29, #192
	bl	_ZNSt12__shared_ptrI13diffuse_lightLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_658:
	ldr	x0, [sp, #16]                   // 8-byte Folded Reload
	bl	_ZN13hittable_listD2Ev
	b	.LBB90_664
.LBB90_659:
.Ltmp739:
	b	.LBB90_661
.LBB90_660:
.Ltmp586:
.LBB90_661:
	mov	x20, x0
	sub	x0, x29, #136
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	sub	x0, x29, #240
	bl	_ZNSt12__shared_ptrI3boxLN9__gnu_cxx12_Lock_policyE2EED2Ev
	b	.LBB90_664
.LBB90_662:
.Ltmp583:
	mov	x20, x0
	mov	x0, x23
	bl	_ZdlPv
	b	.LBB90_664
.LBB90_663:
.Ltmp580:
	mov	x20, x0
.LBB90_664:
	sub	x0, x29, #120
	bl	_ZNSt12__shared_ptrI10lambertianLN9__gnu_cxx12_Lock_policyE2EED2Ev
.LBB90_665:
	sub	x0, x29, #104
	bl	_ZN13hittable_listD2Ev
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end90:
	.size	_Z11final_scenev, .Lfunc_end90-_Z11final_scenev
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table90:
.Lexception17:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end17-.Lcst_begin17
.Lcst_begin17:
	.uleb128 .Ltmp572-.Lfunc_begin17        // >> Call Site 1 <<
	.uleb128 .Ltmp573-.Ltmp572              //   Call between .Ltmp572 and .Ltmp573
	.uleb128 .Ltmp574-.Lfunc_begin17        //     jumps to .Ltmp574
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp575-.Lfunc_begin17        // >> Call Site 2 <<
	.uleb128 .Ltmp576-.Ltmp575              //   Call between .Ltmp575 and .Ltmp576
	.uleb128 .Ltmp577-.Lfunc_begin17        //     jumps to .Ltmp577
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp576-.Lfunc_begin17        // >> Call Site 3 <<
	.uleb128 .Ltmp578-.Ltmp576              //   Call between .Ltmp576 and .Ltmp578
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp578-.Lfunc_begin17        // >> Call Site 4 <<
	.uleb128 .Ltmp579-.Ltmp578              //   Call between .Ltmp578 and .Ltmp579
	.uleb128 .Ltmp580-.Lfunc_begin17        //     jumps to .Ltmp580
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp581-.Lfunc_begin17        // >> Call Site 5 <<
	.uleb128 .Ltmp582-.Ltmp581              //   Call between .Ltmp581 and .Ltmp582
	.uleb128 .Ltmp583-.Lfunc_begin17        //     jumps to .Ltmp583
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp584-.Lfunc_begin17        // >> Call Site 6 <<
	.uleb128 .Ltmp585-.Ltmp584              //   Call between .Ltmp584 and .Ltmp585
	.uleb128 .Ltmp586-.Lfunc_begin17        //     jumps to .Ltmp586
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp585-.Lfunc_begin17        // >> Call Site 7 <<
	.uleb128 .Ltmp587-.Ltmp585              //   Call between .Ltmp585 and .Ltmp587
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp587-.Lfunc_begin17        // >> Call Site 8 <<
	.uleb128 .Ltmp588-.Ltmp587              //   Call between .Ltmp587 and .Ltmp588
	.uleb128 .Ltmp589-.Lfunc_begin17        //     jumps to .Ltmp589
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp590-.Lfunc_begin17        // >> Call Site 9 <<
	.uleb128 .Ltmp591-.Ltmp590              //   Call between .Ltmp590 and .Ltmp591
	.uleb128 .Ltmp592-.Lfunc_begin17        //     jumps to .Ltmp592
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp593-.Lfunc_begin17        // >> Call Site 10 <<
	.uleb128 .Ltmp594-.Ltmp593              //   Call between .Ltmp593 and .Ltmp594
	.uleb128 .Ltmp595-.Lfunc_begin17        //     jumps to .Ltmp595
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp594-.Lfunc_begin17        // >> Call Site 11 <<
	.uleb128 .Ltmp596-.Ltmp594              //   Call between .Ltmp594 and .Ltmp596
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp596-.Lfunc_begin17        // >> Call Site 12 <<
	.uleb128 .Ltmp597-.Ltmp596              //   Call between .Ltmp596 and .Ltmp597
	.uleb128 .Ltmp598-.Lfunc_begin17        //     jumps to .Ltmp598
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp599-.Lfunc_begin17        // >> Call Site 13 <<
	.uleb128 .Ltmp600-.Ltmp599              //   Call between .Ltmp599 and .Ltmp600
	.uleb128 .Ltmp601-.Lfunc_begin17        //     jumps to .Ltmp601
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp602-.Lfunc_begin17        // >> Call Site 14 <<
	.uleb128 .Ltmp603-.Ltmp602              //   Call between .Ltmp602 and .Ltmp603
	.uleb128 .Ltmp604-.Lfunc_begin17        //     jumps to .Ltmp604
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp605-.Lfunc_begin17        // >> Call Site 15 <<
	.uleb128 .Ltmp606-.Ltmp605              //   Call between .Ltmp605 and .Ltmp606
	.uleb128 .Ltmp607-.Lfunc_begin17        //     jumps to .Ltmp607
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp608-.Lfunc_begin17        // >> Call Site 16 <<
	.uleb128 .Ltmp609-.Ltmp608              //   Call between .Ltmp608 and .Ltmp609
	.uleb128 .Ltmp610-.Lfunc_begin17        //     jumps to .Ltmp610
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp609-.Lfunc_begin17        // >> Call Site 17 <<
	.uleb128 .Ltmp611-.Ltmp609              //   Call between .Ltmp609 and .Ltmp611
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp611-.Lfunc_begin17        // >> Call Site 18 <<
	.uleb128 .Ltmp612-.Ltmp611              //   Call between .Ltmp611 and .Ltmp612
	.uleb128 .Ltmp613-.Lfunc_begin17        //     jumps to .Ltmp613
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp614-.Lfunc_begin17        // >> Call Site 19 <<
	.uleb128 .Ltmp615-.Ltmp614              //   Call between .Ltmp614 and .Ltmp615
	.uleb128 .Ltmp616-.Lfunc_begin17        //     jumps to .Ltmp616
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp617-.Lfunc_begin17        // >> Call Site 20 <<
	.uleb128 .Ltmp618-.Ltmp617              //   Call between .Ltmp617 and .Ltmp618
	.uleb128 .Ltmp619-.Lfunc_begin17        //     jumps to .Ltmp619
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp620-.Lfunc_begin17        // >> Call Site 21 <<
	.uleb128 .Ltmp621-.Ltmp620              //   Call between .Ltmp620 and .Ltmp621
	.uleb128 .Ltmp622-.Lfunc_begin17        //     jumps to .Ltmp622
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp623-.Lfunc_begin17        // >> Call Site 22 <<
	.uleb128 .Ltmp624-.Ltmp623              //   Call between .Ltmp623 and .Ltmp624
	.uleb128 .Ltmp625-.Lfunc_begin17        //     jumps to .Ltmp625
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp624-.Lfunc_begin17        // >> Call Site 23 <<
	.uleb128 .Ltmp626-.Ltmp624              //   Call between .Ltmp624 and .Ltmp626
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp626-.Lfunc_begin17        // >> Call Site 24 <<
	.uleb128 .Ltmp627-.Ltmp626              //   Call between .Ltmp626 and .Ltmp627
	.uleb128 .Ltmp628-.Lfunc_begin17        //     jumps to .Ltmp628
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp629-.Lfunc_begin17        // >> Call Site 25 <<
	.uleb128 .Ltmp630-.Ltmp629              //   Call between .Ltmp629 and .Ltmp630
	.uleb128 .Ltmp631-.Lfunc_begin17        //     jumps to .Ltmp631
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp630-.Lfunc_begin17        // >> Call Site 26 <<
	.uleb128 .Ltmp632-.Ltmp630              //   Call between .Ltmp630 and .Ltmp632
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp632-.Lfunc_begin17        // >> Call Site 27 <<
	.uleb128 .Ltmp633-.Ltmp632              //   Call between .Ltmp632 and .Ltmp633
	.uleb128 .Ltmp634-.Lfunc_begin17        //     jumps to .Ltmp634
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp633-.Lfunc_begin17        // >> Call Site 28 <<
	.uleb128 .Ltmp635-.Ltmp633              //   Call between .Ltmp633 and .Ltmp635
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp635-.Lfunc_begin17        // >> Call Site 29 <<
	.uleb128 .Ltmp636-.Ltmp635              //   Call between .Ltmp635 and .Ltmp636
	.uleb128 .Ltmp637-.Lfunc_begin17        //     jumps to .Ltmp637
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp638-.Lfunc_begin17        // >> Call Site 30 <<
	.uleb128 .Ltmp639-.Ltmp638              //   Call between .Ltmp638 and .Ltmp639
	.uleb128 .Ltmp640-.Lfunc_begin17        //     jumps to .Ltmp640
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp639-.Lfunc_begin17        // >> Call Site 31 <<
	.uleb128 .Ltmp641-.Ltmp639              //   Call between .Ltmp639 and .Ltmp641
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp641-.Lfunc_begin17        // >> Call Site 32 <<
	.uleb128 .Ltmp642-.Ltmp641              //   Call between .Ltmp641 and .Ltmp642
	.uleb128 .Ltmp643-.Lfunc_begin17        //     jumps to .Ltmp643
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp642-.Lfunc_begin17        // >> Call Site 33 <<
	.uleb128 .Ltmp644-.Ltmp642              //   Call between .Ltmp642 and .Ltmp644
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp644-.Lfunc_begin17        // >> Call Site 34 <<
	.uleb128 .Ltmp645-.Ltmp644              //   Call between .Ltmp644 and .Ltmp645
	.uleb128 .Ltmp646-.Lfunc_begin17        //     jumps to .Ltmp646
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp647-.Lfunc_begin17        // >> Call Site 35 <<
	.uleb128 .Ltmp648-.Ltmp647              //   Call between .Ltmp647 and .Ltmp648
	.uleb128 .Ltmp649-.Lfunc_begin17        //     jumps to .Ltmp649
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp648-.Lfunc_begin17        // >> Call Site 36 <<
	.uleb128 .Ltmp650-.Ltmp648              //   Call between .Ltmp648 and .Ltmp650
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp650-.Lfunc_begin17        // >> Call Site 37 <<
	.uleb128 .Ltmp651-.Ltmp650              //   Call between .Ltmp650 and .Ltmp651
	.uleb128 .Ltmp652-.Lfunc_begin17        //     jumps to .Ltmp652
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp651-.Lfunc_begin17        // >> Call Site 38 <<
	.uleb128 .Ltmp653-.Ltmp651              //   Call between .Ltmp651 and .Ltmp653
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp653-.Lfunc_begin17        // >> Call Site 39 <<
	.uleb128 .Ltmp654-.Ltmp653              //   Call between .Ltmp653 and .Ltmp654
	.uleb128 .Ltmp655-.Lfunc_begin17        //     jumps to .Ltmp655
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp656-.Lfunc_begin17        // >> Call Site 40 <<
	.uleb128 .Ltmp657-.Ltmp656              //   Call between .Ltmp656 and .Ltmp657
	.uleb128 .Ltmp658-.Lfunc_begin17        //     jumps to .Ltmp658
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp659-.Lfunc_begin17        // >> Call Site 41 <<
	.uleb128 .Ltmp660-.Ltmp659              //   Call between .Ltmp659 and .Ltmp660
	.uleb128 .Ltmp661-.Lfunc_begin17        //     jumps to .Ltmp661
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp660-.Lfunc_begin17        // >> Call Site 42 <<
	.uleb128 .Ltmp662-.Ltmp660              //   Call between .Ltmp660 and .Ltmp662
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp662-.Lfunc_begin17        // >> Call Site 43 <<
	.uleb128 .Ltmp663-.Ltmp662              //   Call between .Ltmp662 and .Ltmp663
	.uleb128 .Ltmp664-.Lfunc_begin17        //     jumps to .Ltmp664
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp665-.Lfunc_begin17        // >> Call Site 44 <<
	.uleb128 .Ltmp666-.Ltmp665              //   Call between .Ltmp665 and .Ltmp666
	.uleb128 .Ltmp667-.Lfunc_begin17        //     jumps to .Ltmp667
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp666-.Lfunc_begin17        // >> Call Site 45 <<
	.uleb128 .Ltmp668-.Ltmp666              //   Call between .Ltmp666 and .Ltmp668
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp668-.Lfunc_begin17        // >> Call Site 46 <<
	.uleb128 .Ltmp669-.Ltmp668              //   Call between .Ltmp668 and .Ltmp669
	.uleb128 .Ltmp670-.Lfunc_begin17        //     jumps to .Ltmp670
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp671-.Lfunc_begin17        // >> Call Site 47 <<
	.uleb128 .Ltmp672-.Ltmp671              //   Call between .Ltmp671 and .Ltmp672
	.uleb128 .Ltmp673-.Lfunc_begin17        //     jumps to .Ltmp673
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp674-.Lfunc_begin17        // >> Call Site 48 <<
	.uleb128 .Ltmp675-.Ltmp674              //   Call between .Ltmp674 and .Ltmp675
	.uleb128 .Ltmp676-.Lfunc_begin17        //     jumps to .Ltmp676
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp675-.Lfunc_begin17        // >> Call Site 49 <<
	.uleb128 .Ltmp677-.Ltmp675              //   Call between .Ltmp675 and .Ltmp677
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp677-.Lfunc_begin17        // >> Call Site 50 <<
	.uleb128 .Ltmp678-.Ltmp677              //   Call between .Ltmp677 and .Ltmp678
	.uleb128 .Ltmp679-.Lfunc_begin17        //     jumps to .Ltmp679
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp680-.Lfunc_begin17        // >> Call Site 51 <<
	.uleb128 .Ltmp681-.Ltmp680              //   Call between .Ltmp680 and .Ltmp681
	.uleb128 .Ltmp682-.Lfunc_begin17        //     jumps to .Ltmp682
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp683-.Lfunc_begin17        // >> Call Site 52 <<
	.uleb128 .Ltmp684-.Ltmp683              //   Call between .Ltmp683 and .Ltmp684
	.uleb128 .Ltmp685-.Lfunc_begin17        //     jumps to .Ltmp685
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp684-.Lfunc_begin17        // >> Call Site 53 <<
	.uleb128 .Ltmp686-.Ltmp684              //   Call between .Ltmp684 and .Ltmp686
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp686-.Lfunc_begin17        // >> Call Site 54 <<
	.uleb128 .Ltmp687-.Ltmp686              //   Call between .Ltmp686 and .Ltmp687
	.uleb128 .Ltmp688-.Lfunc_begin17        //     jumps to .Ltmp688
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp687-.Lfunc_begin17        // >> Call Site 55 <<
	.uleb128 .Ltmp689-.Ltmp687              //   Call between .Ltmp687 and .Ltmp689
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp689-.Lfunc_begin17        // >> Call Site 56 <<
	.uleb128 .Ltmp690-.Ltmp689              //   Call between .Ltmp689 and .Ltmp690
	.uleb128 .Ltmp691-.Lfunc_begin17        //     jumps to .Ltmp691
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp690-.Lfunc_begin17        // >> Call Site 57 <<
	.uleb128 .Ltmp692-.Ltmp690              //   Call between .Ltmp690 and .Ltmp692
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp692-.Lfunc_begin17        // >> Call Site 58 <<
	.uleb128 .Ltmp693-.Ltmp692              //   Call between .Ltmp692 and .Ltmp693
	.uleb128 .Ltmp694-.Lfunc_begin17        //     jumps to .Ltmp694
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp695-.Lfunc_begin17        // >> Call Site 59 <<
	.uleb128 .Ltmp696-.Ltmp695              //   Call between .Ltmp695 and .Ltmp696
	.uleb128 .Ltmp697-.Lfunc_begin17        //     jumps to .Ltmp697
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp698-.Lfunc_begin17        // >> Call Site 60 <<
	.uleb128 .Ltmp699-.Ltmp698              //   Call between .Ltmp698 and .Ltmp699
	.uleb128 .Ltmp700-.Lfunc_begin17        //     jumps to .Ltmp700
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp699-.Lfunc_begin17        // >> Call Site 61 <<
	.uleb128 .Ltmp701-.Ltmp699              //   Call between .Ltmp699 and .Ltmp701
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp701-.Lfunc_begin17        // >> Call Site 62 <<
	.uleb128 .Ltmp702-.Ltmp701              //   Call between .Ltmp701 and .Ltmp702
	.uleb128 .Ltmp703-.Lfunc_begin17        //     jumps to .Ltmp703
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp702-.Lfunc_begin17        // >> Call Site 63 <<
	.uleb128 .Ltmp704-.Ltmp702              //   Call between .Ltmp702 and .Ltmp704
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp704-.Lfunc_begin17        // >> Call Site 64 <<
	.uleb128 .Ltmp705-.Ltmp704              //   Call between .Ltmp704 and .Ltmp705
	.uleb128 .Ltmp706-.Lfunc_begin17        //     jumps to .Ltmp706
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp705-.Lfunc_begin17        // >> Call Site 65 <<
	.uleb128 .Ltmp707-.Ltmp705              //   Call between .Ltmp705 and .Ltmp707
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp707-.Lfunc_begin17        // >> Call Site 66 <<
	.uleb128 .Ltmp708-.Ltmp707              //   Call between .Ltmp707 and .Ltmp708
	.uleb128 .Ltmp709-.Lfunc_begin17        //     jumps to .Ltmp709
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp710-.Lfunc_begin17        // >> Call Site 67 <<
	.uleb128 .Ltmp711-.Ltmp710              //   Call between .Ltmp710 and .Ltmp711
	.uleb128 .Ltmp712-.Lfunc_begin17        //     jumps to .Ltmp712
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp711-.Lfunc_begin17        // >> Call Site 68 <<
	.uleb128 .Ltmp713-.Ltmp711              //   Call between .Ltmp711 and .Ltmp713
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp713-.Lfunc_begin17        // >> Call Site 69 <<
	.uleb128 .Ltmp714-.Ltmp713              //   Call between .Ltmp713 and .Ltmp714
	.uleb128 .Ltmp715-.Lfunc_begin17        //     jumps to .Ltmp715
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp714-.Lfunc_begin17        // >> Call Site 70 <<
	.uleb128 .Ltmp716-.Ltmp714              //   Call between .Ltmp714 and .Ltmp716
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp716-.Lfunc_begin17        // >> Call Site 71 <<
	.uleb128 .Ltmp717-.Ltmp716              //   Call between .Ltmp716 and .Ltmp717
	.uleb128 .Ltmp718-.Lfunc_begin17        //     jumps to .Ltmp718
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp717-.Lfunc_begin17        // >> Call Site 72 <<
	.uleb128 .Ltmp719-.Ltmp717              //   Call between .Ltmp717 and .Ltmp719
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp719-.Lfunc_begin17        // >> Call Site 73 <<
	.uleb128 .Ltmp720-.Ltmp719              //   Call between .Ltmp719 and .Ltmp720
	.uleb128 .Ltmp721-.Lfunc_begin17        //     jumps to .Ltmp721
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp722-.Lfunc_begin17        // >> Call Site 74 <<
	.uleb128 .Ltmp723-.Ltmp722              //   Call between .Ltmp722 and .Ltmp723
	.uleb128 .Ltmp724-.Lfunc_begin17        //     jumps to .Ltmp724
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp725-.Lfunc_begin17        // >> Call Site 75 <<
	.uleb128 .Ltmp726-.Ltmp725              //   Call between .Ltmp725 and .Ltmp726
	.uleb128 .Ltmp727-.Lfunc_begin17        //     jumps to .Ltmp727
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp728-.Lfunc_begin17        // >> Call Site 76 <<
	.uleb128 .Ltmp729-.Ltmp728              //   Call between .Ltmp728 and .Ltmp729
	.uleb128 .Ltmp730-.Lfunc_begin17        //     jumps to .Ltmp730
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp731-.Lfunc_begin17        // >> Call Site 77 <<
	.uleb128 .Ltmp732-.Ltmp731              //   Call between .Ltmp731 and .Ltmp732
	.uleb128 .Ltmp733-.Lfunc_begin17        //     jumps to .Ltmp733
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp732-.Lfunc_begin17        // >> Call Site 78 <<
	.uleb128 .Ltmp734-.Ltmp732              //   Call between .Ltmp732 and .Ltmp734
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp734-.Lfunc_begin17        // >> Call Site 79 <<
	.uleb128 .Ltmp735-.Ltmp734              //   Call between .Ltmp734 and .Ltmp735
	.uleb128 .Ltmp736-.Lfunc_begin17        //     jumps to .Ltmp736
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp735-.Lfunc_begin17        // >> Call Site 80 <<
	.uleb128 .Ltmp737-.Ltmp735              //   Call between .Ltmp735 and .Ltmp737
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp737-.Lfunc_begin17        // >> Call Site 81 <<
	.uleb128 .Ltmp738-.Ltmp737              //   Call between .Ltmp737 and .Ltmp738
	.uleb128 .Ltmp739-.Lfunc_begin17        //     jumps to .Ltmp739
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp738-.Lfunc_begin17        // >> Call Site 82 <<
	.uleb128 .Lfunc_end90-.Ltmp738          //   Call between .Ltmp738 and .Lfunc_end90
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end17:
	.p2align	2
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function main
.LCPI91_0:
	.xword	0x401d1e1c43074389              // double 7.2794046853240468
.LCPI91_1:
	.xword	0x40719a3c38860e87              // double 281.63970234266202
.LCPI91_2:
	.xword	0x407125c3c779f179              // double 274.36029765733798
.LCPI91_3:
	.xword	0x3f747ae147ae147b              // double 0.0050000000000000001
.LCPI91_4:
	.xword	0x3feff7ced916872b              // double 0.99899999999999999
	.text
	.globl	main
	.p2align	2
	.type	main,@function
main:                                   // @main
.Lfunc_begin18:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception18
// %bb.0:
	sub	sp, sp, #368
	stp	d15, d14, [sp, #208]            // 16-byte Folded Spill
	stp	d13, d12, [sp, #224]            // 16-byte Folded Spill
	stp	d11, d10, [sp, #240]            // 16-byte Folded Spill
	stp	d9, d8, [sp, #256]              // 16-byte Folded Spill
	stp	x29, x30, [sp, #272]            // 16-byte Folded Spill
	add	x29, sp, #272
	stp	x28, x27, [sp, #288]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #304]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #320]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #336]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #352]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	.cfi_offset b10, -120
	.cfi_offset b11, -128
	.cfi_offset b12, -136
	.cfi_offset b13, -144
	.cfi_offset b14, -152
	.cfi_offset b15, -160
	adrp	x21, _ZTV13hittable_list+16
	stp	xzr, xzr, [x29, #-88]
	add	x21, x21, :lo12:_ZTV13hittable_list+16
	stp	xzr, xzr, [x29, #-128]
	stur	xzr, [x29, #-112]
	stp	x21, xzr, [x29, #-104]
.Ltmp740:
	add	x8, sp, #88
	bl	_Z11cornell_boxv
.Ltmp741:
// %bb.1:
	ldur	q0, [sp, #96]
	ldr	x8, [sp, #112]
	stur	q0, [x29, #-96]
	stur	x8, [x29, #-80]
.Ltmp743:
	adrp	x0, :got:_ZSt4cout
	adrp	x1, .L.str.4
	add	x1, x1, :lo12:.L.str.4
	mov	w2, #3
	ldr	x0, [x0, :got_lo12:_ZSt4cout]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp744:
// %bb.2:
.Ltmp745:
	adrp	x0, :got:_ZSt4cout
	mov	w1, #600
	ldr	x0, [x0, :got_lo12:_ZSt4cout]
	bl	_ZNSolsEi
.Ltmp746:
// %bb.3:
	mov	w8, #32
	strb	w8, [sp, #88]
.Ltmp747:
	add	x1, sp, #88
	mov	w2, #1
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp748:
// %bb.4:
.Ltmp749:
	mov	w1, #600
	bl	_ZNSolsEi
.Ltmp750:
// %bb.5:
.Ltmp751:
	adrp	x1, .L.str.5
	mov	w2, #5
	add	x1, x1, :lo12:.L.str.5
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp752:
// %bb.6:
	adrp	x9, .LCPI91_0
	adrp	x20, :got:_ZSt4cerr
	adrp	x10, .LCPI91_1
	adrp	x11, .LCPI91_2
	movi	d9, #0000000000000000
	mov	x26, #202310139510784
	ldr	d0, [x9, :lo12:.LCPI91_0]
	adrp	x9, .LCPI91_3
	ldr	x20, [x20, :got_lo12:_ZSt4cerr]
	mov	x27, #105553116266496
	mov	x23, #193514046488576
	mov	x21, #105553116266496
	str	d0, [sp, #40]                   // 8-byte Folded Spill
	ldr	d0, [x10, :lo12:.LCPI91_1]
	adrp	x10, .LCPI91_4
	mov	w8, #599
	mov	w24, #32
	mov	x25, #4467570830351532032
	fmov	d11, #-1.00000000
	fmov	d12, #2.00000000
	fmov	d13, #1.00000000
	movk	x26, #16514, lsl #48
	movk	x27, #16497, lsl #48
	mov	x28, #-4573123946618028032
	str	d0, [sp, #32]                   // 8-byte Folded Spill
	ldr	d0, [x11, :lo12:.LCPI91_2]
	movk	x23, #49288, lsl #48
	movk	x21, #49265, lsl #48
	ldr	d14, [x9, :lo12:.LCPI91_3]
	mov	x19, #4650248090236747776
	ldr	d8, [x10, :lo12:.LCPI91_4]
	mov	x22, #4643211215818981376
	str	d0, [sp, #24]                   // 8-byte Folded Spill
	stp	d8, d14, [sp, #8]               // 16-byte Folded Spill
	b	.LBB91_8
.LBB91_7:                               //   in Loop: Header=BB91_8 Depth=1
	ldr	w9, [sp, #4]                    // 4-byte Folded Reload
	adrp	x20, :got:_ZSt4cerr
	sub	w8, w9, #1
	ldr	x20, [x20, :got_lo12:_ZSt4cerr]
	cbz	w9, .LBB91_31
.LBB91_8:                               // =>This Loop Header: Depth=1
                                        //     Child Loop BB91_13 Depth 2
                                        //       Child Loop BB91_14 Depth 3
                                        //         Child Loop BB91_15 Depth 4
.Ltmp753:
	adrp	x1, .L.str.6
	mov	x0, x20
	add	x1, x1, :lo12:.L.str.6
	mov	w2, #22
	str	w8, [sp, #4]                    // 4-byte Folded Spill
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp754:
// %bb.9:                               //   in Loop: Header=BB91_8 Depth=1
.Ltmp755:
	mov	x0, x20
	ldr	w1, [sp, #4]                    // 4-byte Folded Reload
	bl	_ZNSolsEi
.Ltmp756:
// %bb.10:                              //   in Loop: Header=BB91_8 Depth=1
	strb	w24, [sp, #88]
.Ltmp757:
	add	x1, sp, #88
	mov	w2, #1
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp758:
// %bb.11:                              //   in Loop: Header=BB91_8 Depth=1
.Ltmp759:
	bl	_ZNSo5flushEv
.Ltmp760:
// %bb.12:                              //   in Loop: Header=BB91_8 Depth=1
	ldr	w8, [sp, #4]                    // 4-byte Folded Reload
	mov	w20, wzr
	scvtf	d0, w8
	str	d0, [sp, #48]                   // 8-byte Folded Spill
.LBB91_13:                              //   Parent Loop BB91_8 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB91_14 Depth 3
                                        //         Child Loop BB91_15 Depth 4
	scvtf	d0, w20
	movi	d3, #0000000000000000
	movi	d1, #0000000000000000
	movi	d2, #0000000000000000
	mov	w24, wzr
	str	d0, [sp, #56]                   // 8-byte Folded Spill
.LBB91_14:                              //   Parent Loop BB91_8 Depth=1
                                        //     Parent Loop BB91_13 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB91_15 Depth 4
	stp	d3, d2, [sp, #64]               // 16-byte Folded Spill
	str	d1, [sp, #80]                   // 8-byte Folded Spill
	bl	rand
	scvtf	d0, w0
	fmov	d15, x25
	ldr	d1, [sp, #56]                   // 8-byte Folded Reload
	fmul	d0, d0, d15
	fadd	d10, d0, d1
	bl	rand
	scvtf	d0, w0
	ldr	d1, [sp, #48]                   // 8-byte Folded Reload
	fmul	d0, d0, d15
	fadd	d14, d0, d1
.LBB91_15:                              //   Parent Loop BB91_8 Depth=1
                                        //     Parent Loop BB91_13 Depth=2
                                        //       Parent Loop BB91_14 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	bl	rand
	scvtf	d0, w0
	fmov	d8, x25
	fmul	d0, d0, d8
	fmadd	d15, d0, d12, d11
	bl	rand
	scvtf	d0, w0
	fmul	d0, d0, d8
	fmadd	d0, d0, d12, d11
	fmul	d1, d0, d0
	fmadd	d1, d15, d15, d1
	fadd	d1, d1, d9
	fcmp	d1, d13
	b.ge	.LBB91_15
// %bb.16:                              //   in Loop: Header=BB91_14 Depth=3
	fmov	d1, x26
	fmov	d6, x23
	ldp	d7, d17, [sp, #32]              // 16-byte Folded Reload
	fmul	d0, d0, d9
	fmul	d4, d15, d9
	fdiv	d2, d10, d1
	fmov	d18, x28
	fmul	d5, d0, d9
	fdiv	d1, d14, d1
	fmul	d3, d2, d17
	fmul	d2, d2, d9
	fsub	d3, d7, d3
	ldr	d7, [sp, #24]                   // 8-byte Folded Reload
	fadd	d7, d2, d7
	fadd	d2, d2, d6
	fmul	d6, d4, d9
	fsub	d4, d5, d4
	fadd	d0, d6, d0
	fadd	d5, d6, d5
	fmul	d16, d1, d9
	fmul	d1, d1, d17
	fmov	d17, x27
	fadd	d9, d5, d18
	fadd	d3, d3, d16
	fadd	d1, d7, d1
	fadd	d2, d2, d16
	fmov	d7, x21
	fmov	d16, x19
	fadd	d8, d4, d17
	fadd	d15, d0, d17
	fadd	d3, d3, d7
	fadd	d1, d1, d7
	fadd	d2, d2, d16
	fsub	d10, d3, d4
	fsub	d14, d1, d0
	fsub	d13, d2, d5
	bl	rand
	scvtf	d0, w0
	fmov	d1, x25
	stp	d8, d15, [sp, #88]
	stp	d9, d10, [sp, #104]
	stp	d14, d13, [sp, #120]
	fmul	d0, d0, d1
	movi	d1, #0000000000000000
	fadd	d0, d0, d1
	str	d0, [sp, #136]
.Ltmp762:
	add	x0, sp, #88
	sub	x1, x29, #128
	sub	x2, x29, #104
	mov	w3, #50
	bl	_Z9ray_colorRK3rayRK4vec3RK8hittablei
.Ltmp763:
// %bb.17:                              //   in Loop: Header=BB91_14 Depth=3
	ldr	d3, [sp, #64]                   // 8-byte Folded Reload
	movi	d9, #0000000000000000
	add	w24, w24, #1
	fmov	d13, #1.00000000
	cmp	w24, #200
	fadd	d3, d3, d0
	ldr	d0, [sp, #80]                   // 8-byte Folded Reload
	fadd	d1, d0, d1
	ldr	d0, [sp, #72]                   // 8-byte Folded Reload
	fadd	d2, d0, d2
	b.ne	.LBB91_14
// %bb.18:                              //   in Loop: Header=BB91_13 Depth=2
	fcmp	d3, d3
	ldr	d14, [sp, #16]                  // 8-byte Folded Reload
	fcsel	d0, d3, d9, vc
	fcmp	d1, d1
	fcsel	d10, d1, d9, vc
	fcmp	d2, d2
	fmul	d0, d0, d14
	fcsel	d8, d2, d9, vc
	fsqrt	d3, d0
	fcmp	d3, d3
	b.vs	.LBB91_28
// %bb.19:                              //   in Loop: Header=BB91_13 Depth=2
	fmul	d0, d10, d14
	mov	w24, #32
	fsqrt	d15, d0
	fcmp	d15, d15
	b.vs	.LBB91_29
.LBB91_20:                              //   in Loop: Header=BB91_13 Depth=2
	fmul	d0, d8, d14
	fsqrt	d10, d0
	fcmp	d10, d10
	b.vs	.LBB91_30
.LBB91_21:                              //   in Loop: Header=BB91_13 Depth=2
	ldr	d8, [sp, #8]                    // 8-byte Folded Reload
	fmov	d1, x22
	fcmp	d3, #0.0
	fmin	d0, d3, d8
	fmul	d0, d0, d1
	fcsel	d0, d9, d0, mi
	fcvtzs	w1, d0
.Ltmp765:
	adrp	x0, :got:_ZSt4cout
	ldr	x0, [x0, :got_lo12:_ZSt4cout]
	bl	_ZNSolsEi
.Ltmp766:
// %bb.22:                              //   in Loop: Header=BB91_13 Depth=2
	strb	w24, [sp, #88]
.Ltmp767:
	add	x1, sp, #88
	mov	w2, #1
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp768:
// %bb.23:                              //   in Loop: Header=BB91_13 Depth=2
	fmin	d0, d15, d8
	fmov	d1, x22
	fcmp	d15, #0.0
	fmul	d0, d0, d1
	fcsel	d0, d9, d0, mi
	fcvtzs	w1, d0
.Ltmp769:
	bl	_ZNSolsEi
.Ltmp770:
// %bb.24:                              //   in Loop: Header=BB91_13 Depth=2
	strb	w24, [sp, #88]
.Ltmp771:
	add	x1, sp, #88
	mov	w2, #1
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp772:
// %bb.25:                              //   in Loop: Header=BB91_13 Depth=2
	fmin	d0, d10, d8
	fmov	d1, x22
	fcmp	d10, #0.0
	fmul	d0, d0, d1
	fcsel	d0, d9, d0, mi
	fcvtzs	w1, d0
.Ltmp773:
	bl	_ZNSolsEi
.Ltmp774:
// %bb.26:                              //   in Loop: Header=BB91_13 Depth=2
	mov	w8, #10
	strb	w8, [sp, #88]
.Ltmp775:
	add	x1, sp, #88
	mov	w2, #1
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp776:
// %bb.27:                              //   in Loop: Header=BB91_13 Depth=2
	add	w20, w20, #1
	cmp	w20, #600
	b.ne	.LBB91_13
	b	.LBB91_7
.LBB91_28:                              //   in Loop: Header=BB91_13 Depth=2
	bl	sqrt
	fmov	d3, d0
	fmul	d0, d10, d14
	mov	w24, #32
	fsqrt	d15, d0
	fcmp	d15, d15
	b.vc	.LBB91_20
.LBB91_29:                              //   in Loop: Header=BB91_13 Depth=2
	fmov	d10, d3
	bl	sqrt
	fmov	d3, d10
	fmov	d15, d0
	fmul	d0, d8, d14
	fsqrt	d10, d0
	fcmp	d10, d10
	b.vc	.LBB91_21
.LBB91_30:                              //   in Loop: Header=BB91_13 Depth=2
	fmov	d8, d3
	bl	sqrt
	fmov	d3, d8
	fmov	d10, d0
	b	.LBB91_21
.LBB91_31:
.Ltmp778:
	adrp	x0, :got:_ZSt4cerr
	adrp	x1, .L.str.7
	add	x1, x1, :lo12:.L.str.7
	mov	w2, #7
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
.Ltmp779:
// %bb.32:
	ldp	x19, x21, [x29, #-96]
	adrp	x8, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV13hittable_list+16
	cmp	x19, x21
	stur	x8, [x29, #-104]
	b.eq	.LBB91_44
// %bb.33:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	b	.LBB91_35
.LBB91_34:                              //   in Loop: Header=BB91_35 Depth=1
	add	x19, x19, #16
	cmp	x19, x21
	b.eq	.LBB91_43
.LBB91_35:                              // =>This Inner Loop Header: Depth=1
	ldr	x20, [x19, #8]
	cbz	x20, .LBB91_34
// %bb.36:                              //   in Loop: Header=BB91_35 Depth=1
	ldrb	w8, [x22]
	cbz	w8, .LBB91_38
// %bb.37:                              //   in Loop: Header=BB91_35 Depth=1
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB91_34
	b	.LBB91_39
.LBB91_38:                              //   in Loop: Header=BB91_35 Depth=1
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB91_34
.LBB91_39:                              //   in Loop: Header=BB91_35 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB91_41
// %bb.40:                              //   in Loop: Header=BB91_35 Depth=1
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB91_34
	b	.LBB91_42
.LBB91_41:                              //   in Loop: Header=BB91_35 Depth=1
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB91_34
.LBB91_42:                              //   in Loop: Header=BB91_35 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB91_34
.LBB91_43:
	ldur	x19, [x29, #-96]
.LBB91_44:
	cbz	x19, .LBB91_46
// %bb.45:
	mov	x0, x19
	bl	_ZdlPv
.LBB91_46:
	ldp	x20, x19, [sp, #352]            // 16-byte Folded Reload
	mov	w0, wzr
	ldp	x22, x21, [sp, #336]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #320]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #304]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #288]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #272]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #256]              // 16-byte Folded Reload
	ldp	d11, d10, [sp, #240]            // 16-byte Folded Reload
	ldp	d13, d12, [sp, #224]            // 16-byte Folded Reload
	ldp	d15, d14, [sp, #208]            // 16-byte Folded Reload
	add	sp, sp, #368
	ret
.LBB91_47:
.Ltmp742:
	mov	x19, x0
	b	.LBB91_53
.LBB91_48:
.Ltmp780:
	b	.LBB91_52
.LBB91_49:
.Ltmp761:
	b	.LBB91_52
.LBB91_50:
.Ltmp777:
	b	.LBB91_52
.LBB91_51:
.Ltmp764:
.LBB91_52:
	adrp	x21, _ZTV13hittable_list+16
	mov	x19, x0
	add	x21, x21, :lo12:_ZTV13hittable_list+16
.LBB91_53:
	ldp	x20, x22, [x29, #-96]
	stur	x21, [x29, #-104]
	cmp	x20, x22
	b.ne	.LBB91_56
// %bb.54:
	cbnz	x20, .LBB91_67
.LBB91_55:
	mov	x0, x19
	bl	_Unwind_Resume
.LBB91_56:
	adrp	x23, :got:__libc_single_threaded
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	b	.LBB91_58
.LBB91_57:                              //   in Loop: Header=BB91_58 Depth=1
	add	x20, x20, #16
	cmp	x20, x22
	b.eq	.LBB91_66
.LBB91_58:                              // =>This Inner Loop Header: Depth=1
	ldr	x21, [x20, #8]
	cbz	x21, .LBB91_57
// %bb.59:                              //   in Loop: Header=BB91_58 Depth=1
	ldrb	w8, [x23]
	cbz	w8, .LBB91_61
// %bb.60:                              //   in Loop: Header=BB91_58 Depth=1
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.ne	.LBB91_57
	b	.LBB91_62
.LBB91_61:                              //   in Loop: Header=BB91_58 Depth=1
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB91_57
.LBB91_62:                              //   in Loop: Header=BB91_58 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB91_64
// %bb.63:                              //   in Loop: Header=BB91_58 Depth=1
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB91_57
	b	.LBB91_65
.LBB91_64:                              //   in Loop: Header=BB91_58 Depth=1
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB91_57
.LBB91_65:                              //   in Loop: Header=BB91_58 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB91_57
.LBB91_66:
	ldur	x20, [x29, #-96]
	cbz	x20, .LBB91_55
.LBB91_67:
	mov	x0, x20
	bl	_ZdlPv
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end91:
	.size	main, .Lfunc_end91-main
	.cfi_endproc
	.section	.gcc_except_table,"a",@progbits
	.p2align	2
GCC_except_table91:
.Lexception18:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end18-.Lcst_begin18
.Lcst_begin18:
	.uleb128 .Ltmp740-.Lfunc_begin18        // >> Call Site 1 <<
	.uleb128 .Ltmp741-.Ltmp740              //   Call between .Ltmp740 and .Ltmp741
	.uleb128 .Ltmp742-.Lfunc_begin18        //     jumps to .Ltmp742
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp743-.Lfunc_begin18        // >> Call Site 2 <<
	.uleb128 .Ltmp752-.Ltmp743              //   Call between .Ltmp743 and .Ltmp752
	.uleb128 .Ltmp780-.Lfunc_begin18        //     jumps to .Ltmp780
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp753-.Lfunc_begin18        // >> Call Site 3 <<
	.uleb128 .Ltmp760-.Ltmp753              //   Call between .Ltmp753 and .Ltmp760
	.uleb128 .Ltmp761-.Lfunc_begin18        //     jumps to .Ltmp761
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp762-.Lfunc_begin18        // >> Call Site 4 <<
	.uleb128 .Ltmp763-.Ltmp762              //   Call between .Ltmp762 and .Ltmp763
	.uleb128 .Ltmp764-.Lfunc_begin18        //     jumps to .Ltmp764
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp765-.Lfunc_begin18        // >> Call Site 5 <<
	.uleb128 .Ltmp776-.Ltmp765              //   Call between .Ltmp765 and .Ltmp776
	.uleb128 .Ltmp777-.Lfunc_begin18        //     jumps to .Ltmp777
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp778-.Lfunc_begin18        // >> Call Site 6 <<
	.uleb128 .Ltmp779-.Ltmp778              //   Call between .Ltmp778 and .Ltmp779
	.uleb128 .Ltmp780-.Lfunc_begin18        //     jumps to .Ltmp780
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp779-.Lfunc_begin18        // >> Call Site 7 <<
	.uleb128 .Lfunc_end91-.Ltmp779          //   Call between .Ltmp779 and .Lfunc_end91
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end18:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK8rotate_y12bounding_boxEddR4aabb,"axG",@progbits,_ZNK8rotate_y12bounding_boxEddR4aabb,comdat
	.weak	_ZNK8rotate_y12bounding_boxEddR4aabb // -- Begin function _ZNK8rotate_y12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK8rotate_y12bounding_boxEddR4aabb,@function
_ZNK8rotate_y12bounding_boxEddR4aabb:   // @_ZNK8rotate_y12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	ldp	q1, q0, [x0, #64]
	ldr	q2, [x0, #48]
	stp	q1, q0, [x1, #16]
	str	q2, [x1]
	ldrb	w0, [x0, #40]
	ret
.Lfunc_end92:
	.size	_ZNK8rotate_y12bounding_boxEddR4aabb, .Lfunc_end92-_ZNK8rotate_y12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK7xy_rect12bounding_boxEddR4aabb
.LCPI93_0:
	.xword	0xbf1a36e2eb1c432d              // double -1.0E-4
.LCPI93_1:
	.xword	0x3f1a36e2eb1c432d              // double 1.0E-4
	.section	.text._ZNK7xy_rect12bounding_boxEddR4aabb,"axG",@progbits,_ZNK7xy_rect12bounding_boxEddR4aabb,comdat
	.weak	_ZNK7xy_rect12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK7xy_rect12bounding_boxEddR4aabb,@function
_ZNK7xy_rect12bounding_boxEddR4aabb:    // @_ZNK7xy_rect12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	adrp	x8, .LCPI93_0
	ldr	d5, [x0, #40]
	ldp	d6, d1, [x0, #48]
	ldr	d0, [x8, :lo12:.LCPI93_0]
	adrp	x8, .LCPI93_1
	ldp	d2, d3, [x0, #24]
	mov	w0, #1
	str	d5, [x1, #8]
	ldr	d4, [x8, :lo12:.LCPI93_1]
	fadd	d0, d1, d0
	str	d6, [x1, #32]
	str	d2, [x1]
	fadd	d1, d1, d4
	str	d3, [x1, #24]
	str	d0, [x1, #16]
	str	d1, [x1, #40]
	ret
.Lfunc_end93:
	.size	_ZNK7xy_rect12bounding_boxEddR4aabb, .Lfunc_end93-_ZNK7xy_rect12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK7xz_rect12bounding_boxEddR4aabb
.LCPI94_0:
	.xword	0xbf1a36e2eb1c432d              // double -1.0E-4
.LCPI94_1:
	.xword	0x3f1a36e2eb1c432d              // double 1.0E-4
	.section	.text._ZNK7xz_rect12bounding_boxEddR4aabb,"axG",@progbits,_ZNK7xz_rect12bounding_boxEddR4aabb,comdat
	.weak	_ZNK7xz_rect12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK7xz_rect12bounding_boxEddR4aabb,@function
_ZNK7xz_rect12bounding_boxEddR4aabb:    // @_ZNK7xz_rect12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	adrp	x8, .LCPI94_0
	ldr	q3, [x0, #32]
	ldp	d5, d2, [x0, #48]
	ldr	d0, [x8, :lo12:.LCPI94_0]
	adrp	x8, .LCPI94_1
	ext	v3.16b, v3.16b, v3.16b, #8
	ldr	d1, [x0, #24]
	mov	w0, #1
	ldr	d4, [x8, :lo12:.LCPI94_1]
	fadd	d0, d2, d0
	str	q3, [x1, #16]
	fadd	d2, d2, d4
	stp	d1, d0, [x1]
	stp	d2, d5, [x1, #32]
	ret
.Lfunc_end94:
	.size	_ZNK7xz_rect12bounding_boxEddR4aabb, .Lfunc_end94-_ZNK7xz_rect12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK7yz_rect12bounding_boxEddR4aabb
.LCPI95_0:
	.xword	0xbf1a36e2eb1c432d              // double -1.0E-4
.LCPI95_1:
	.xword	0x3f1a36e2eb1c432d              // double 1.0E-4
	.section	.text._ZNK7yz_rect12bounding_boxEddR4aabb,"axG",@progbits,_ZNK7yz_rect12bounding_boxEddR4aabb,comdat
	.weak	_ZNK7yz_rect12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK7yz_rect12bounding_boxEddR4aabb,@function
_ZNK7yz_rect12bounding_boxEddR4aabb:    // @_ZNK7yz_rect12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	adrp	x8, .LCPI95_0
	adrp	x9, .LCPI95_1
	ldr	d1, [x0, #56]
	ldp	d3, d4, [x0, #24]
	ldr	d0, [x8, :lo12:.LCPI95_0]
	ldr	d2, [x9, :lo12:.LCPI95_1]
	fadd	d0, d1, d0
	fadd	d1, d1, d2
	ldp	d5, d2, [x0, #40]
	mov	w0, #1
	str	d3, [x1, #8]
	str	d4, [x1, #32]
	str	d0, [x1]
	str	d5, [x1, #16]
	str	d1, [x1, #24]
	str	d2, [x1, #40]
	ret
.Lfunc_end95:
	.size	_ZNK7yz_rect12bounding_boxEddR4aabb, .Lfunc_end95-_ZNK7yz_rect12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK3box12bounding_boxEddR4aabb,"axG",@progbits,_ZNK3box12bounding_boxEddR4aabb,comdat
	.weak	_ZNK3box12bounding_boxEddR4aabb // -- Begin function _ZNK3box12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK3box12bounding_boxEddR4aabb,@function
_ZNK3box12bounding_boxEddR4aabb:        // @_ZNK3box12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	mov	x8, x0
	mov	w0, #1
	ldr	x9, [x8, #24]
	ldr	q0, [x8, #32]
	ldr	x10, [x8, #48]
	str	x9, [sp, #16]
	ldur	q1, [x8, #8]
	stur	q0, [sp, #24]
	str	x10, [sp, #40]
	ldp	q0, q2, [sp, #16]
	stp	q1, q0, [x1]
	str	q2, [x1, #32]
	add	sp, sp, #48
	ret
.Lfunc_end96:
	.size	_ZNK3box12bounding_boxEddR4aabb, .Lfunc_end96-_ZNK3box12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK15constant_medium12bounding_boxEddR4aabb,"axG",@progbits,_ZNK15constant_medium12bounding_boxEddR4aabb,comdat
	.weak	_ZNK15constant_medium12bounding_boxEddR4aabb // -- Begin function _ZNK15constant_medium12bounding_boxEddR4aabb
	.p2align	2
	.type	_ZNK15constant_medium12bounding_boxEddR4aabb,@function
_ZNK15constant_medium12bounding_boxEddR4aabb: // @_ZNK15constant_medium12bounding_boxEddR4aabb
	.cfi_startproc
// %bb.0:
	ldr	x0, [x0, #8]
	ldr	x8, [x0]
	ldr	x2, [x8, #8]
	br	x2
.Lfunc_end97:
	.size	_ZNK15constant_medium12bounding_boxEddR4aabb, .Lfunc_end97-_ZNK15constant_medium12bounding_boxEddR4aabb
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_,"axG",@progbits,_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_,comdat
	.weak	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_ // -- Begin function _ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
	.p2align	2
	.type	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_,@function
_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_: // @_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	stp	x26, x25, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x20, x24, [x0]
	mov	x9, #9223372036854775792
	sub	x8, x24, x20
	cmp	x8, x9
	b.eq	.LBB98_21
// %bb.1:
	asr	x9, x8, #4
	cmp	x8, #0
	csinc	x8, x9, xzr, ne
	mov	x19, x0
	adds	x8, x8, x9
	mov	x23, x2
	lsr	x9, x8, #59
	cset	w10, hs
	cmp	x9, #0
	mov	x22, x1
	cset	w9, ne
	sub	x26, x1, x20
	orr	w9, w10, w9
	cmp	w9, #0
	mov	x9, #576460752303423487
	csel	x25, x9, x8, ne
	lsl	x0, x25, #4
	bl	_Znwm
	ldp	x9, x8, [x23]
	mov	x21, x0
	add	x10, x0, x26
	stp	x9, x8, [x10]
	cbz	x8, .LBB98_4
// %bb.2:
	adrp	x9, :got:__libc_single_threaded
	ldr	x9, [x9, :got_lo12:__libc_single_threaded]
	ldrb	w9, [x9]
	cbz	w9, .LBB98_11
// %bb.3:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB98_4:
	cmp	x20, x22
	b.eq	.LBB98_12
.LBB98_5:
	sub	x10, x26, #16
	mov	x8, x21
	mov	x9, x20
	cmp	x10, #48
	b.lo	.LBB98_9
// %bb.6:
	lsr	x8, x10, #4
	add	x12, x21, #32
	add	x10, x8, #1
	add	x13, x20, #32
	and	x11, x10, #0x1ffffffffffffffc
	lsl	x9, x11, #4
	mov	x14, x11
	movi	v0.2d, #0000000000000000
	add	x8, x21, x9
	add	x9, x20, x9
.LBB98_7:                               // =>This Inner Loop Header: Depth=1
	ldp	q2, q1, [x13, #-32]
	subs	x14, x14, #4
	stp	q0, q0, [x13, #-32]
	ldp	q4, q3, [x13]
	stp	q2, q1, [x12, #-32]
	stp	q0, q0, [x13], #64
	stp	q4, q3, [x12], #64
	b.ne	.LBB98_7
// %bb.8:
	cmp	x10, x11
	b.eq	.LBB98_10
.LBB98_9:                               // =>This Inner Loop Header: Depth=1
	ldp	x10, x11, [x9]
	stp	x10, x11, [x8], #16
	stp	xzr, xzr, [x9], #16
	cmp	x9, x22
	b.ne	.LBB98_9
.LBB98_10:
	add	x23, x8, #16
	subs	x9, x24, x22
	b.ne	.LBB98_13
	b	.LBB98_18
.LBB98_11:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	cmp	x20, x22
	b.ne	.LBB98_5
.LBB98_12:
	mov	x8, x21
	add	x23, x8, #16
	subs	x9, x24, x22
	b.eq	.LBB98_18
.LBB98_13:
	sub	x10, x9, #16
	mov	x9, x22
	cmp	x10, #48
	b.lo	.LBB98_17
// %bb.14:
	lsr	x9, x10, #4
	add	x12, x22, #32
	add	x10, x9, #1
	add	x8, x8, #48
	and	x11, x10, #0x1ffffffffffffffc
	lsl	x9, x11, #4
	mov	x13, x11
	movi	v0.2d, #0000000000000000
	add	x23, x23, x9
	add	x9, x22, x9
.LBB98_15:                              // =>This Inner Loop Header: Depth=1
	ldp	q2, q1, [x12, #-32]
	subs	x13, x13, #4
	stp	q0, q0, [x12, #-32]
	stp	q2, q1, [x8, #-32]
	ldp	q2, q1, [x12]
	stp	q0, q0, [x12], #64
	stp	q2, q1, [x8], #64
	b.ne	.LBB98_15
// %bb.16:
	cmp	x10, x11
	b.eq	.LBB98_18
.LBB98_17:                              // =>This Inner Loop Header: Depth=1
	ldp	x8, x10, [x9]
	stp	x8, x10, [x23], #16
	stp	xzr, xzr, [x9], #16
	cmp	x9, x24
	b.ne	.LBB98_17
.LBB98_18:
	cbz	x20, .LBB98_20
// %bb.19:
	mov	x0, x20
	bl	_ZdlPv
.LBB98_20:
	add	x8, x21, x25, lsl #4
	stp	x21, x23, [x19]
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB98_21:
	adrp	x0, .L.str.8
	add	x0, x0, :lo12:.L.str.8
	bl	_ZSt20__throw_length_errorPKc
.Lfunc_end98:
	.size	_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_, .Lfunc_end98-_ZNSt6vectorISt10shared_ptrI8hittableESaIS2_EE17_M_realloc_insertIJRKS2_EEEvN9__gnu_cxx17__normal_iteratorIPS2_S4_EEDpOT_
	.cfi_endproc
                                        // -- End function
	.text
	.p2align	2                               // -- Begin function _ZL16stbi__stdio_readPvPci
	.type	_ZL16stbi__stdio_readPvPci,@function
_ZL16stbi__stdio_readPvPci:             // @_ZL16stbi__stdio_readPvPci
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-16]!           // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
                                        // kill: def $w2 killed $w2 def $x2
	mov	x3, x0
	mov	x0, x1
	sxtw	x2, w2
	mov	w1, #1
	bl	fread
                                        // kill: def $w0 killed $w0 killed $x0
	ldp	x29, x30, [sp], #16             // 16-byte Folded Reload
	ret
.Lfunc_end99:
	.size	_ZL16stbi__stdio_readPvPci, .Lfunc_end99-_ZL16stbi__stdio_readPvPci
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL16stbi__stdio_skipPvi
	.type	_ZL16stbi__stdio_skipPvi,@function
_ZL16stbi__stdio_skipPvi:               // @_ZL16stbi__stdio_skipPvi
	.cfi_startproc
// %bb.0:
                                        // kill: def $w1 killed $w1 def $x1
	mov	w2, #1
	sxtw	x1, w1
	b	fseek
.Lfunc_end100:
	.size	_ZL16stbi__stdio_skipPvi, .Lfunc_end100-_ZL16stbi__stdio_skipPvi
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL15stbi__stdio_eofPv
	.type	_ZL15stbi__stdio_eofPv,@function
_ZL15stbi__stdio_eofPv:                 // @_ZL15stbi__stdio_eofPv
	.cfi_startproc
// %bb.0:
	b	feof
.Lfunc_end101:
	.size	_ZL15stbi__stdio_eofPv, .Lfunc_end101-_ZL15stbi__stdio_eofPv
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
.LCPI102_0:
	.word	0                               // 0x0
	.word	1                               // 0x1
	.word	2                               // 0x2
	.word	3                               // 0x3
	.text
	.p2align	2
	.type	_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i,@function
_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i: // @_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #4, lsl #12             // =16384
	sub	sp, sp, #2800
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x28, x0
	mov	w26, w4
	mov	x27, x3
	mov	x23, x0
	mov	x21, x2
	mov	x22, x1
	ldr	x10, [x28, #184]!
	mov	x25, x28
	add	x19, sp, #656
	ldr	x8, [x25, #8]!
	cmp	x10, x8
	b.hs	.LBB102_2
// %bb.1:
	add	x9, x10, #1
	str	x9, [x28]
	ldrb	w10, [x10]
	cmp	w10, #255
	b.eq	.LBB102_6
	b	.LBB102_16
.LBB102_2:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_16
// %bb.3:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_5
// %bb.4:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	w10, #255
	b.ne	.LBB102_16
	b	.LBB102_6
.LBB102_5:
	mov	w10, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	w10, #255
	b.ne	.LBB102_16
.LBB102_6:
	mov	w10, #17800
	add	x24, x23, #56
	add	x10, x19, x10
	add	x20, x23, #57
	str	x10, [sp, #400]                 // 8-byte Folded Spill
	b	.LBB102_8
.LBB102_7:                              //   in Loop: Header=BB102_8 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	cmp	w10, #255
	b.ne	.LBB102_13
.LBB102_8:                              // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.lo	.LBB102_7
// %bb.9:                               //   in Loop: Header=BB102_8 Depth=1
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_16
// %bb.10:                              //   in Loop: Header=BB102_8 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x24
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_12
// %bb.11:                              //   in Loop: Header=BB102_8 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x20
	str	x8, [x25]
	str	x20, [x28]
	cmp	w10, #255
	b.eq	.LBB102_8
	b	.LBB102_13
.LBB102_12:                             //   in Loop: Header=BB102_8 Depth=1
	mov	w10, wzr
	mov	x8, x20
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	mov	x9, x20
	str	x8, [x25]
	str	x20, [x28]
	cmp	w10, #255
	b.eq	.LBB102_8
.LBB102_13:
	cmp	w10, #216
	b.ne	.LBB102_16
// %bb.14:
	adrp	x8, _ZL16stbi__idct_blockPhiPs
	ldr	x9, [x23, #200]
	add	x8, x8, :lo12:_ZL16stbi__idct_blockPhiPs
	cmp	w26, #5
	str	x23, [sp, #656]
	str	x9, [x23, #184]
	str	x8, [sp, #18936]
	adrp	x8, _ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii
	add	x8, x8, :lo12:_ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii
	str	wzr, [x23, #8]
	str	x8, [sp, #18944]
	adrp	x8, _ZL23stbi__resample_row_hv_2PhS_S_ii
	add	x8, x8, :lo12:_ZL23stbi__resample_row_hv_2PhS_S_ii
	str	x8, [sp, #18952]
	b.lo	.LBB102_30
// %bb.15:
	adrp	x9, .L.str.29
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.29
	mov	x24, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB102_791
.LBB102_16:
	adrp	x9, .L.str.10
	adrp	x20, .L_MergedGlobals.126+8
	ldr	x8, [x23, #200]
	add	x9, x9, :lo12:.L.str.10
	mov	x0, x23
	str	x9, [x20, :lo12:.L_MergedGlobals.126+8]
	str	x8, [x23, #184]
	bl	_ZL22stbi__check_png_headerP13stbi__context
	ldr	x9, [x23, #200]
	str	x9, [x23, #184]
	cbz	w0, .LBB102_20
// %bb.17:
	cmp	w26, #5
	str	x23, [sp, #656]
	b.lo	.LBB102_22
// %bb.18:
	adrp	x8, .L.str.29
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.29
.LBB102_19:
	str	x8, [x20, :lo12:.L_MergedGlobals.126+8]
	b	.LBB102_791
.LBB102_20:
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_26
// %bb.21:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	cmp	w9, #66
	b.eq	.LBB102_40
	b	.LBB102_52
.LBB102_22:
	add	x0, sp, #656
	mov	w1, wzr
	mov	w2, w26
	bl	_ZL20stbi__parse_png_fileP9stbi__pngii
	mov	w8, w0
	ldr	x0, [sp, #680]
	cbz	w8, .LBB102_29
// %bb.23:
	ldr	x19, [sp, #656]
	cbz	w26, .LBB102_25
// %bb.24:
	ldr	w1, [x19, #12]
	cmp	w1, w26
	b.ne	.LBB102_34
.LBB102_25:
	mov	x24, x0
	b	.LBB102_35
.LBB102_26:
	ldr	w9, [x23, #48]
	cbz	w9, .LBB102_52
// %bb.27:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_39
// %bb.28:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #66
	b.eq	.LBB102_40
	b	.LBB102_52
.LBB102_29:
	mov	x24, xzr
	b	.LBB102_38
.LBB102_30:
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
	add	x0, sp, #656
	mov	w1, wzr
	stp	x21, x27, [sp, #336]            // 16-byte Folded Spill
	str	x22, [sp, #312]                 // 8-byte Folded Spill
	str	wzr, [x28, #468]
	str	xzr, [sp, #18544]
	str	xzr, [sp, #18536]
	str	xzr, [sp, #18640]
	str	xzr, [sp, #18632]
	str	xzr, [sp, #18736]
	str	xzr, [sp, #18728]
	str	xzr, [sp, #18832]
	str	xzr, [sp, #18824]
	bl	_ZL24stbi__decode_jpeg_headerP10stbi__jpegi
	cbz	w0, .LBB102_781
// %bb.31:
	ldrb	w1, [x28, #416]
	cmp	w1, #255
	b.ne	.LBB102_50
// %bb.32:
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_54
// %bb.33:
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB102_126
.LBB102_34:
	ldp	w3, w4, [x19]
	mov	w2, w26
	bl	_ZL20stbi__convert_formatPhiijj
	mov	x24, x0
	str	w26, [x19, #12]
	cbz	x0, .LBB102_791
.LBB102_35:
	ldr	w8, [x19]
	str	w8, [x22]
	ldr	w8, [x19, #4]
	str	w8, [x21]
	cbz	x27, .LBB102_37
// %bb.36:
	ldr	w8, [x19, #12]
	mov	x0, xzr
	str	w8, [x27]
	b	.LBB102_38
.LBB102_37:
	mov	x0, xzr
.LBB102_38:
	bl	free
	ldr	x0, [sp, #672]
	bl	free
	ldr	x0, [sp, #664]
	bl	free
	b	.LBB102_791
.LBB102_39:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #66
	b.ne	.LBB102_52
.LBB102_40:
	cmp	x10, x8
	b.hs	.LBB102_42
// %bb.41:
	add	x9, x10, #1
	str	x9, [x28]
	ldrb	w9, [x10]
	cmp	w9, #77
	b.eq	.LBB102_45
	b	.LBB102_52
.LBB102_42:
	ldr	w9, [x23, #48]
	cbz	w9, .LBB102_52
// %bb.43:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_51
// %bb.44:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #77
	b.ne	.LBB102_52
.LBB102_45:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB102_47
// %bb.46:
	add	x9, x9, #1
	b	.LBB102_59
.LBB102_47:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_60
// %bb.48:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_57
// %bb.49:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_58
.LBB102_50:
	mov	w8, #255
	strb	w8, [x28, #416]
	b	.LBB102_128
.LBB102_51:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #77
	b.eq	.LBB102_45
.LBB102_52:
	ldr	x9, [x23, #200]
	str	x9, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB102_95
.LBB102_53:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	cmp	w9, #71
	b.eq	.LBB102_99
	b	.LBB102_539
.LBB102_54:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_127
// %bb.55:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_124
// %bb.56:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_125
.LBB102_57:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_58:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_59:
	str	x9, [x28]
.LBB102_60:
	cmp	x9, x8
	b.hs	.LBB102_62
// %bb.61:
	add	x9, x9, #1
	b	.LBB102_67
.LBB102_62:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_68
// %bb.63:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_65
// %bb.64:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_66
.LBB102_65:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_66:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_67:
	str	x9, [x28]
.LBB102_68:
	cmp	x9, x8
	b.hs	.LBB102_70
// %bb.69:
	add	x9, x9, #1
	b	.LBB102_75
.LBB102_70:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_76
// %bb.71:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_73
// %bb.72:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_74
.LBB102_73:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_74:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_75:
	str	x9, [x28]
.LBB102_76:
	cmp	x9, x8
	b.hs	.LBB102_78
// %bb.77:
	add	x9, x9, #1
	b	.LBB102_83
.LBB102_78:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_84
// %bb.79:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_81
// %bb.80:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_82
.LBB102_81:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_82:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_83:
	str	x9, [x28]
.LBB102_84:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	cmp	w0, #56
	b.hi	.LBB102_86
// %bb.85:
	mov	w8, w0
	mov	w9, #1
	lsl	x8, x9, x8
	mov	x9, #4096
	movk	x9, #256, lsl #32
	movk	x9, #256, lsl #48
	tst	x8, x9
	b.ne	.LBB102_87
.LBB102_86:
	cmp	w0, #108
	b.ne	.LBB102_93
.LBB102_87:
	ldr	x9, [x23, #200]
	str	x9, [x23, #184]
.LBB102_88:
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_90
// %bb.89:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	cmp	w9, #66
	b.eq	.LBB102_112
	b	.LBB102_452
.LBB102_90:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_452
// %bb.91:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_110
// %bb.92:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_111
.LBB102_93:
	ldr	x9, [x23, #200]
	cmp	w0, #124
	str	x9, [x23, #184]
	b.eq	.LBB102_88
// %bb.94:
	ldr	x8, [x25]
	cmp	x9, x8
	b.lo	.LBB102_53
.LBB102_95:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_539
// %bb.96:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_98
// %bb.97:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #71
	b.ne	.LBB102_539
	b	.LBB102_99
.LBB102_98:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #71
	b.ne	.LBB102_539
.LBB102_99:
	cmp	x10, x8
	b.hs	.LBB102_101
// %bb.100:
	add	x11, x10, #1
	str	x11, [x28]
	ldrb	w9, [x10]
	cmp	w9, #73
	b.ne	.LBB102_539
	b	.LBB102_105
.LBB102_101:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_539
// %bb.102:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_104
// %bb.103:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x11, x23, #57
	stp	x11, x8, [x23, #184]
	cmp	w9, #73
	b.ne	.LBB102_539
	b	.LBB102_105
.LBB102_104:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x11, x23, #57
	stp	x11, x8, [x23, #184]
	cmp	w9, #73
	b.ne	.LBB102_539
.LBB102_105:
	cmp	x11, x8
	b.hs	.LBB102_107
// %bb.106:
	add	x10, x11, #1
	str	x10, [x28]
	ldrb	w9, [x11]
	cmp	w9, #70
	b.ne	.LBB102_539
	b	.LBB102_119
.LBB102_107:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_539
// %bb.108:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_117
// %bb.109:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_118
.LBB102_110:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_111:
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #66
	b.ne	.LBB102_452
.LBB102_112:
	cmp	x10, x8
	b.hs	.LBB102_114
// %bb.113:
	add	x8, x10, #1
	str	x8, [x28]
	ldrb	w8, [x10]
	b	.LBB102_449
.LBB102_114:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_452
// %bb.115:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_447
// %bb.116:
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_448
.LBB102_117:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_118:
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
	cmp	w9, #70
	b.ne	.LBB102_539
.LBB102_119:
	cmp	x10, x8
	b.hs	.LBB102_121
// %bb.120:
	add	x11, x10, #1
	str	x11, [x28]
	ldrb	w9, [x10]
	b	.LBB102_458
.LBB102_121:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_539
// %bb.122:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_456
// %bb.123:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_457
.LBB102_124:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_125:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB102_126:
	cmp	w8, #255
	b.eq	.LBB102_438
.LBB102_127:
	mov	w1, #255
.LBB102_128:
	mov	w8, #17824
	add	x27, sp, #656
	adrp	x23, .L.str.31
	adrp	x25, .L.str.32
	add	x24, x28, #412
	add	x23, x23, :lo12:.L.str.31
	add	x25, x25, :lo12:.L.str.32
	add	x8, x27, x8
	str	x8, [sp, #424]                  // 8-byte Folded Spill
.LBB102_129:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_165 Depth 2
                                        //       Child Loop BB102_179 Depth 3
                                        //     Child Loop BB102_336 Depth 2
                                        //       Child Loop BB102_338 Depth 3
                                        //         Child Loop BB102_342 Depth 4
                                        //           Child Loop BB102_347 Depth 5
                                        //             Child Loop BB102_350 Depth 6
                                        //     Child Loop BB102_234 Depth 2
                                        //       Child Loop BB102_238 Depth 3
                                        //         Child Loop BB102_244 Depth 4
                                        //         Child Loop BB102_275 Depth 4
                                        //           Child Loop BB102_293 Depth 5
                                        //         Child Loop BB102_262 Depth 4
                                        //     Child Loop BB102_379 Depth 2
                                        //       Child Loop BB102_381 Depth 3
                                        //         Child Loop BB102_385 Depth 4
                                        //           Child Loop BB102_389 Depth 5
                                        //             Child Loop BB102_391 Depth 6
                                        //     Child Loop BB102_324 Depth 2
                                        //       Child Loop BB102_328 Depth 3
                                        //     Child Loop BB102_413 Depth 2
                                        //     Child Loop BB102_194 Depth 2
	cmp	w1, #218
	b.eq	.LBB102_135
// %bb.130:                             //   in Loop: Header=BB102_129 Depth=1
	cmp	w1, #217
	b.eq	.LBB102_464
// %bb.131:                             //   in Loop: Header=BB102_129 Depth=1
	add	x0, sp, #656
	bl	_ZL20stbi__process_markerP10stbi__jpegi
	cbz	w0, .LBB102_781
.LBB102_132:                            //   in Loop: Header=BB102_129 Depth=1
	ldrb	w1, [x28, #416]
	cmp	w1, #255
	b.ne	.LBB102_433
.LBB102_133:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_140
// %bb.134:                             //   in Loop: Header=BB102_129 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB102_192
.LBB102_135:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	x19, [sp, #656]
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB102_137
// %bb.136:                             //   in Loop: Header=BB102_129 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	b	.LBB102_146
.LBB102_137:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB102_143
// %bb.138:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_144
// %bb.139:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_145
.LBB102_140:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w8, [x19, #48]
	mov	w1, #255
	cbz	w8, .LBB102_129
// %bb.141:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_190
// %bb.142:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_191
.LBB102_143:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w20, wzr
	b	.LBB102_146
.LBB102_144:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_145:                            //   in Loop: Header=BB102_129 Depth=1
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB102_146:                            //   in Loop: Header=BB102_129 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_148
// %bb.147:                             //   in Loop: Header=BB102_129 Depth=1
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w21, [x9]
	b	.LBB102_154
.LBB102_148:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_151
// %bb.149:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_152
// %bb.150:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x8, x19
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_153
.LBB102_151:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w21, wzr
	b	.LBB102_154
.LBB102_152:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w21, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_153:                            //   in Loop: Header=BB102_129 Depth=1
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB102_154:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_156
// %bb.155:                             //   in Loop: Header=BB102_129 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB102_161
.LBB102_156:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_553
// %bb.157:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_159
// %bb.158:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_160
.LBB102_159:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_160:                            //   in Loop: Header=BB102_129 Depth=1
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB102_161:                            //   in Loop: Header=BB102_129 Depth=1
	sub	w9, w8, #5
	str	w8, [x28, #448]
	cmn	w9, #4
	b.lo	.LBB102_444
// %bb.162:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x19, [sp, #656]
	ldr	w9, [x19, #8]
	cmp	w9, w8
	b.lt	.LBB102_444
// %bb.163:                             //   in Loop: Header=BB102_129 Depth=1
	lsl	w8, w8, #1
	bfi	w21, w20, #8, #8
	add	w8, w8, #6
	cmp	w21, w8
	b.ne	.LBB102_490
// %bb.164:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x20, xzr
	ldr	x21, [sp, #424]                 // 8-byte Folded Reload
.LBB102_165:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_179 Depth 3
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_168
// %bb.166:                             //   in Loop: Header=BB102_165 Depth=2
	add	x10, x8, #1
	str	x10, [x19, #184]
	ldrb	w22, [x8]
	mov	x8, x10
	cmp	x8, x9
	b.hs	.LBB102_174
.LBB102_167:                            //   in Loop: Header=BB102_165 Depth=2
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB102_177
.LBB102_168:                            //   in Loop: Header=BB102_165 Depth=2
	ldr	w10, [x19, #48]
	cbz	w10, .LBB102_171
// %bb.169:                             //   in Loop: Header=BB102_165 Depth=2
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_172
// %bb.170:                             //   in Loop: Header=BB102_165 Depth=2
	mov	x8, x19
	ldrb	w22, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_173
.LBB102_171:                            //   in Loop: Header=BB102_165 Depth=2
	mov	w22, wzr
	cmp	x8, x9
	b.lo	.LBB102_167
	b	.LBB102_174
.LBB102_172:                            //   in Loop: Header=BB102_165 Depth=2
	mov	w22, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_173:                            //   in Loop: Header=BB102_165 Depth=2
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB102_167
.LBB102_174:                            //   in Loop: Header=BB102_165 Depth=2
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_177
// %bb.175:                             //   in Loop: Header=BB102_165 Depth=2
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_181
// %bb.176:                             //   in Loop: Header=BB102_165 Depth=2
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_182
.LBB102_177:                            //   in Loop: Header=BB102_165 Depth=2
	ldr	w10, [x19, #8]
	cmp	w10, #1
	b.lt	.LBB102_183
.LBB102_178:                            //   in Loop: Header=BB102_165 Depth=2
	mov	x9, xzr
	mov	x11, x21
.LBB102_179:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_165 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	w12, [x11]
	cmp	w12, w22
	b.eq	.LBB102_184
// %bb.180:                             //   in Loop: Header=BB102_179 Depth=3
	add	x9, x9, #1
	add	x11, x11, #96
	cmp	x10, x9
	b.ne	.LBB102_179
	b	.LBB102_781
.LBB102_181:                            //   in Loop: Header=BB102_165 Depth=2
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_182:                            //   in Loop: Header=BB102_165 Depth=2
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
	ldr	x19, [sp, #656]
	ldr	w10, [x19, #8]
	cmp	w10, #1
	b.ge	.LBB102_178
.LBB102_183:                            //   in Loop: Header=BB102_165 Depth=2
	mov	w9, wzr
.LBB102_184:                            //   in Loop: Header=BB102_165 Depth=2
	cmp	w9, w10
	b.eq	.LBB102_781
// %bb.185:                             //   in Loop: Header=BB102_165 Depth=2
	mov	w22, #96
	mov	w12, #17840
	lsr	w11, w8, #4
	cmp	w8, #63
	umaddl	x10, w9, w22, x27
	str	w11, [x10, x12]
	b.hi	.LBB102_445
// %bb.186:                             //   in Loop: Header=BB102_165 Depth=2
	mov	w10, w9
	mov	w11, #17844
	and	w8, w8, #0xf
	madd	x10, x10, x22, x27
	cmp	w8, #3
	str	w8, [x10, x11]
	b.hi	.LBB102_446
// %bb.187:                             //   in Loop: Header=BB102_165 Depth=2
	ldrsw	x8, [x28, #448]
	add	x10, x27, x20, lsl #2
	add	x20, x20, #1
	cmp	x20, x8
	mov	w8, #18252
	str	w9, [x10, x8]
	b.lt	.LBB102_165
// %bb.188:                             //   in Loop: Header=BB102_129 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_200
// %bb.189:                             //   in Loop: Header=BB102_129 Depth=1
	add	x11, x8, #1
	str	x11, [x19, #184]
	ldrb	w10, [x8]
	mov	x8, x11
	b	.LBB102_205
.LBB102_190:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_191:                            //   in Loop: Header=BB102_129 Depth=1
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB102_192:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w1, #255
	cmp	w8, #255
	b.ne	.LBB102_129
	b	.LBB102_194
.LBB102_193:                            //   in Loop: Header=BB102_194 Depth=2
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w1, [x8]
	cmp	w1, #255
	b.ne	.LBB102_129
.LBB102_194:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB102_193
// %bb.195:                             //   in Loop: Header=BB102_194 Depth=2
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_199
// %bb.196:                             //   in Loop: Header=BB102_194 Depth=2
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_198
// %bb.197:                             //   in Loop: Header=BB102_194 Depth=2
	mov	x8, x19
	ldrb	w1, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w1, #255
	b.eq	.LBB102_194
	b	.LBB102_129
.LBB102_198:                            //   in Loop: Header=BB102_194 Depth=2
	mov	w1, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w1, #255
	b.eq	.LBB102_194
	b	.LBB102_129
.LBB102_199:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w1, wzr
	b	.LBB102_129
.LBB102_200:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB102_205
// %bb.201:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_203
// %bb.202:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_204
.LBB102_203:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_204:                            //   in Loop: Header=BB102_129 Depth=1
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
.LBB102_205:                            //   in Loop: Header=BB102_129 Depth=1
	cmp	x8, x9
	str	w10, [x28, #428]
	b.hs	.LBB102_207
// %bb.206:                             //   in Loop: Header=BB102_129 Depth=1
	add	x11, x8, #1
	str	x11, [x19, #184]
	ldrb	w10, [x8]
	mov	x8, x11
	b	.LBB102_212
.LBB102_207:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB102_212
// %bb.208:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_210
// %bb.209:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_211
.LBB102_210:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_211:                            //   in Loop: Header=BB102_129 Depth=1
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
.LBB102_212:                            //   in Loop: Header=BB102_129 Depth=1
	cmp	x8, x9
	str	w10, [x28, #432]
	b.hs	.LBB102_214
// %bb.213:                             //   in Loop: Header=BB102_129 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB102_219
.LBB102_214:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_219
// %bb.215:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_217
// %bb.216:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_218
.LBB102_217:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_218:                            //   in Loop: Header=BB102_129 Depth=1
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB102_219:                            //   in Loop: Header=BB102_129 Depth=1
	lsr	w10, w8, #4
	and	w11, w8, #0xf
	ldr	w9, [x28, #424]
	ldr	w12, [x28, #428]
	str	w10, [x28, #436]
	str	w11, [x28, #440]
	cbz	w9, .LBB102_225
// %bb.220:                             //   in Loop: Header=BB102_129 Depth=1
	cmp	w12, #63
	b.gt	.LBB102_1008
// %bb.221:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	w13, [x28, #432]
	adrp	x10, .L.str.35
	add	x10, x10, :lo12:.L.str.35
	cmp	w13, #63
	b.gt	.LBB102_780
// %bb.222:                             //   in Loop: Header=BB102_129 Depth=1
	cmp	w12, w13
	b.gt	.LBB102_780
// %bb.223:                             //   in Loop: Header=BB102_129 Depth=1
	adrp	x10, .L.str.35
	cmp	w8, #223
	add	x10, x10, :lo12:.L.str.35
	b.hi	.LBB102_780
// %bb.224:                             //   in Loop: Header=BB102_129 Depth=1
	cmp	w11, #13
	b.ls	.LBB102_229
	b	.LBB102_780
.LBB102_225:                            //   in Loop: Header=BB102_129 Depth=1
	adrp	x10, .L.str.35
	add	x10, x10, :lo12:.L.str.35
	cbnz	w12, .LBB102_780
// %bb.226:                             //   in Loop: Header=BB102_129 Depth=1
	cmp	w8, #15
	b.hi	.LBB102_780
// %bb.227:                             //   in Loop: Header=BB102_129 Depth=1
	cbnz	w11, .LBB102_780
// %bb.228:                             //   in Loop: Header=BB102_129 Depth=1
	mov	w8, #63
	str	w8, [x28, #432]
.LBB102_229:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w8, [x28, #468]
	mov	w10, #2147483647
	movi	v0.2d, #0000000000000000
	str	wzr, [x28, #420]
	str	wzr, [x28, #240]
	cmp	w8, #0
	str	wzr, [x28, #144]
	csel	w8, w10, w8, eq
	mov	w10, #255
	str	d0, [sp, #18864]
	str	wzr, [x28, #48]
	strb	w10, [x28, #416]
	ldr	w10, [x28, #448]
	str	w8, [x28, #472]
	str	wzr, [x28, #444]
	cmp	w10, #1
	cbz	w9, .LBB102_320
// %bb.230:                             //   in Loop: Header=BB102_129 Depth=1
	b.ne	.LBB102_333
// %bb.231:                             //   in Loop: Header=BB102_129 Depth=1
	ldrsw	x8, [x28, #452]
	mov	w9, #17856
	madd	x10, x8, x22, x27
	ldr	w9, [x10, x9]
	cmp	w9, #1
	b.lt	.LBB102_410
// %bb.232:                             //   in Loop: Header=BB102_129 Depth=1
	mov	w11, #17852
	ldr	w10, [x10, x11]
	cmp	w10, #1
	b.lt	.LBB102_410
// %bb.233:                             //   in Loop: Header=BB102_129 Depth=1
	mov	w12, #96
	mov	w13, #17904
	add	w10, w10, #7
	add	w9, w9, #7
	madd	x11, x8, x12, x27
	asr	w10, w10, #3
	asr	w9, w9, #3
	cmp	w10, #1
	add	x13, x11, x13
	csinc	w10, w10, wzr, gt
	cmp	w9, #1
	madd	x8, x8, x12, x27
	csinc	w9, w9, wzr, gt
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	str	x13, [sp, #296]                 // 8-byte Folded Spill
	mov	w13, #17912
	add	x13, x11, x13
	str	w10, [sp, #272]                 // 4-byte Folded Spill
	str	w9, [sp, #236]                  // 4-byte Folded Spill
	mov	w9, #17848
	add	x8, x8, x9
	str	x13, [sp, #288]                 // 8-byte Folded Spill
	mov	w13, #17844
	add	x13, x11, x13
	str	x13, [sp, #264]                 // 8-byte Folded Spill
	mov	w13, #17840
	add	x11, x11, x13
	stp	x8, x11, [sp, #248]             // 16-byte Folded Spill
.LBB102_234:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_238 Depth 3
                                        //         Child Loop BB102_244 Depth 4
                                        //         Child Loop BB102_275 Depth 4
                                        //           Child Loop BB102_293 Depth 5
                                        //         Child Loop BB102_262 Depth 4
	mov	w22, wzr
	b	.LBB102_238
.LBB102_235:                            //   in Loop: Header=BB102_238 Depth=3
	ldrb	w8, [x28, #416]
	and	w9, w8, #0xf8
	cmp	w9, #208
	b.ne	.LBB102_434
// %bb.236:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x28, #468]
	mov	w9, #2147483647
	movi	v0.2d, #0000000000000000
	str	wzr, [x28, #420]
	str	wzr, [x28, #240]
	cmp	w8, #0
	str	wzr, [x28, #144]
	csel	w8, w9, w8, eq
	mov	w9, #255
	str	d0, [sp, #18864]
	str	wzr, [x28, #48]
	strb	w9, [x28, #416]
	str	w8, [x28, #472]
	str	wzr, [x28, #444]
.LBB102_237:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [sp, #272]                  // 4-byte Folded Reload
	add	w22, w22, #1
	cmp	w22, w8
	b.eq	.LBB102_319
.LBB102_238:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_234 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB102_244 Depth 4
                                        //         Child Loop BB102_275 Depth 4
                                        //           Child Loop BB102_293 Depth 5
                                        //         Child Loop BB102_262 Depth 4
	ldr	x8, [sp, #288]                  // 8-byte Folded Reload
	str	w22, [sp, #352]                 // 4-byte Folded Spill
	ldr	w9, [sp, #320]                  // 4-byte Folded Reload
	ldr	w23, [x28, #428]
	ldr	w8, [x8]
	madd	w8, w8, w9, w22
	ldr	x9, [sp, #296]                  // 8-byte Folded Reload
	lsl	w8, w8, #6
	ldr	x9, [x9]
	add	x19, x9, w8, sxtw #1
	cbz	w23, .LBB102_250
// %bb.239:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	x8, [sp, #264]                  // 8-byte Folded Reload
	mov	w10, #6728
	ldr	w9, [x28, #436]
	ldr	w21, [x28, #440]
	ldrsw	x20, [x8]
	mov	w8, #1680
	madd	x8, x20, x8, x27
	add	x8, x8, x10
	str	x8, [sp, #384]                  // 8-byte Folded Spill
	cbz	w9, .LBB102_258
// %bb.240:                             //   in Loop: Header=BB102_238 Depth=3
	mov	w9, #1
	ldr	w8, [x28, #444]
	lsl	w9, w9, w21
	str	w9, [sp, #368]                  // 4-byte Folded Spill
	cbz	w8, .LBB102_272
// %bb.241:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w9, [x28, #432]
	sub	w8, w8, #1
	cmp	w23, w9
	str	w8, [x28, #444]
	b.gt	.LBB102_310
// %bb.242:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [sp, #368]                  // 4-byte Folded Reload
                                        // kill: def $w23 killed $w23 killed $x23 def $x23
	sxtw	x20, w23
	sxth	w21, w8
	neg	w22, w8
	b	.LBB102_244
.LBB102_243:                            //   in Loop: Header=BB102_244 Depth=4
	ldrsw	x9, [x28, #432]
	add	x8, x20, #1
	cmp	x20, x9
	mov	x20, x8
	b.ge	.LBB102_310
.LBB102_244:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_234 Depth=2
                                        //       Parent Loop BB102_238 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	adrp	x8, _ZL19stbi__jpeg_dezigzag
	add	x8, x8, :lo12:_ZL19stbi__jpeg_dezigzag
	ldrb	w23, [x8, x20]
	ldrh	w8, [x19, x23, lsl #1]
	cbz	w8, .LBB102_243
// %bb.245:                             //   in Loop: Header=BB102_244 Depth=4
	ldr	w8, [x24]
	cmp	w8, #0
	b.gt	.LBB102_247
// %bb.246:                             //   in Loop: Header=BB102_244 Depth=4
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w8, [x24]
.LBB102_247:                            //   in Loop: Header=BB102_244 Depth=4
	ldr	w9, [x28, #408]
	sub	w8, w8, #1
	lsl	w10, w9, #1
	str	w8, [x28, #412]
	str	w10, [x28, #408]
	tbz	w9, #31, .LBB102_243
// %bb.248:                             //   in Loop: Header=BB102_244 Depth=4
	ldrsh	w8, [x19, x23, lsl #1]
	tst	w21, w8
	b.ne	.LBB102_243
// %bb.249:                             //   in Loop: Header=BB102_244 Depth=4
	ldr	w9, [sp, #368]                  // 4-byte Folded Reload
	cmp	w8, #0
	csel	w9, w9, w22, gt
	add	w8, w9, w8
	strh	w8, [x19, x23, lsl #1]
	b	.LBB102_243
.LBB102_250:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x28, #432]
	cbnz	w8, .LBB102_1009
// %bb.251:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	x9, [sp, #256]                  // 8-byte Folded Reload
	ldr	w8, [x24]
	ldrsw	x20, [x9]
	cmp	w8, #15
	b.gt	.LBB102_253
// %bb.252:                             //   in Loop: Header=BB102_238 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB102_253:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x28, #436]
	cbz	w8, .LBB102_303
// %bb.254:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x24]
	cmp	w8, #0
	b.gt	.LBB102_256
// %bb.255:                             //   in Loop: Header=BB102_238 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w8, [x24]
.LBB102_256:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w9, [x28, #408]
	sub	w8, w8, #1
	lsl	w10, w9, #1
	str	w8, [x28, #412]
	str	w10, [x28, #408]
	tbz	w9, #31, .LBB102_310
// %bb.257:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x28, #440]
	mov	w10, #65536
	ldrh	w9, [x19]
	lsl	w8, w10, w8
	add	w8, w9, w8, lsr #16
	strh	w8, [x19]
	b	.LBB102_310
.LBB102_258:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x28, #444]
	cbz	w8, .LBB102_262
.LBB102_259:                            //   in Loop: Header=BB102_238 Depth=3
	sub	w8, w8, #1
	str	w8, [x28, #444]
	b	.LBB102_310
.LBB102_260:                            //   in Loop: Header=BB102_262 Depth=4
	ldr	w8, [x28, #408]
	add	x10, x27, x20, lsl #10
	lsr	x9, x8, #22
	and	x9, x9, #0x3fe
	add	x9, x10, x9
	mov	w10, #13704
	ldrsh	w9, [x9, x10]
	cbz	w9, .LBB102_264
// %bb.261:                             //   in Loop: Header=BB102_262 Depth=4
	and	w10, w9, #0xf
	ldr	w12, [x28, #412]
	ubfx	x11, x9, #4, #4
	asr	w9, w9, #8
	add	x11, x11, w23, sxtw
	lsl	w8, w8, w10
	sub	w10, w12, w10
	adrp	x12, _ZL19stbi__jpeg_dezigzag
	add	w23, w11, #1
	add	x12, x12, :lo12:_ZL19stbi__jpeg_dezigzag
	str	w8, [x28, #408]
	lsl	w8, w9, w21
	ldrb	w12, [x12, x11]
	str	w10, [x28, #412]
	strh	w8, [x19, x12, lsl #1]
	ldr	w8, [x28, #432]
	cmp	w23, w8
	b.gt	.LBB102_310
.LBB102_262:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_234 Depth=2
                                        //       Parent Loop BB102_238 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	ldr	w8, [x24]
	cmp	w8, #15
	b.gt	.LBB102_260
// %bb.263:                             //   in Loop: Header=BB102_262 Depth=4
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	b	.LBB102_260
.LBB102_264:                            //   in Loop: Header=BB102_262 Depth=4
	add	x0, sp, #656
	ldr	x1, [sp, #384]                  // 8-byte Folded Reload
	mov	x22, x25
	mov	x25, x24
	bl	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	tbnz	w0, #31, .LBB102_779
// %bb.265:                             //   in Loop: Header=BB102_262 Depth=4
	ands	w24, w0, #0xf
	lsr	w10, w0, #4
	b.eq	.LBB102_269
// %bb.266:                             //   in Loop: Header=BB102_262 Depth=4
	ldr	w8, [x25]
	cmp	w8, w24
	b.ge	.LBB102_268
// %bb.267:                             //   in Loop: Header=BB102_262 Depth=4
	add	x0, sp, #656
	str	x10, [sp, #368]                 // 8-byte Folded Spill
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	x10, [sp, #368]                 // 8-byte Folded Reload
	ldr	w8, [x25]
.LBB102_268:                            //   in Loop: Header=BB102_262 Depth=4
	lsl	x9, x24, #2
	adrp	x13, _ZL11stbi__bmask
	adrp	x14, _ZL11stbi__jbias
	add	x13, x13, :lo12:_ZL11stbi__bmask
	add	x14, x14, :lo12:_ZL11stbi__jbias
	ldr	w11, [x28, #408]
	neg	w12, w24
	ldr	w13, [x13, x9]
	ldr	w9, [x14, x9]
	add	x10, x10, w23, sxtw
	adrp	x14, _ZL19stbi__jpeg_dezigzag
	cmp	w11, #0
	add	x14, x14, :lo12:_ZL19stbi__jpeg_dezigzag
	ror	w12, w11, w12
	bic	w11, w12, w13
	and	w12, w13, w12
	ldrb	w14, [x14, x10]
	csel	w9, wzr, w9, lt
	sub	w8, w8, w24
	add	w9, w9, w12
	lsl	w9, w9, w21
	add	w23, w10, #1
	str	w11, [x28, #408]
	str	w8, [x28, #412]
	strh	w9, [x19, x14, lsl #1]
	b	.LBB102_271
.LBB102_269:                            //   in Loop: Header=BB102_262 Depth=4
	cmp	w0, #240
	b.lo	.LBB102_313
// %bb.270:                             //   in Loop: Header=BB102_262 Depth=4
	add	w23, w23, #16
.LBB102_271:                            //   in Loop: Header=BB102_262 Depth=4
	mov	x24, x25
	mov	x25, x22
	ldr	w8, [x28, #432]
	cmp	w23, w8
	b.le	.LBB102_262
	b	.LBB102_310
.LBB102_272:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [sp, #368]                  // 4-byte Folded Reload
	sxth	w22, w8
	neg	w8, w22
	str	w8, [sp, #280]                  // 4-byte Folded Spill
	b	.LBB102_275
.LBB102_273:                            //   in Loop: Header=BB102_275 Depth=4
                                        // kill: def $w23 killed $w23 killed $x23 def $x23
.LBB102_274:                            //   in Loop: Header=BB102_275 Depth=4
	mov	x25, x20
	cmp	w23, w8
	b.gt	.LBB102_310
.LBB102_275:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_234 Depth=2
                                        //       Parent Loop BB102_238 Depth=3
                                        // =>      This Loop Header: Depth=4
                                        //           Child Loop BB102_293 Depth 5
	add	x0, sp, #656
	ldr	x1, [sp, #384]                  // 8-byte Folded Reload
	mov	x20, x25
	bl	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	tbnz	w0, #31, .LBB102_779
// %bb.276:                             //   in Loop: Header=BB102_275 Depth=4
	ands	w8, w0, #0xf
	lsr	w25, w0, #4
	b.eq	.LBB102_281
// %bb.277:                             //   in Loop: Header=BB102_275 Depth=4
	cmp	w8, #1
	b.ne	.LBB102_779
// %bb.278:                             //   in Loop: Header=BB102_275 Depth=4
	ldr	w8, [x24]
	cmp	w8, #0
	b.gt	.LBB102_280
// %bb.279:                             //   in Loop: Header=BB102_275 Depth=4
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w8, [x24]
.LBB102_280:                            //   in Loop: Header=BB102_275 Depth=4
	ldr	w9, [x28, #408]
	sub	w8, w8, #1
	lsl	w10, w9, #1
	cmp	w9, #0
	ldr	w9, [sp, #280]                  // 4-byte Folded Reload
	str	w8, [x28, #412]
	str	w10, [x28, #408]
	csel	w13, w9, w22, ge
	b	.LBB102_288
.LBB102_281:                            //   in Loop: Header=BB102_275 Depth=4
	cmp	w0, #239
	b.hi	.LBB102_284
// %bb.282:                             //   in Loop: Header=BB102_275 Depth=4
	mov	w8, #-1
	cmp	w0, #16
	lsl	w8, w8, w25
	mvn	w8, w8
	str	w8, [x28, #444]
	b.hs	.LBB102_285
// %bb.283:                             //   in Loop: Header=BB102_275 Depth=4
	mov	w13, wzr
	mov	w25, #64
	b	.LBB102_288
.LBB102_284:                            //   in Loop: Header=BB102_275 Depth=4
	mov	w13, wzr
	mov	w25, #15
	b	.LBB102_288
.LBB102_285:                            //   in Loop: Header=BB102_275 Depth=4
	ldr	w9, [x24]
	cmp	w9, w25
	b.ge	.LBB102_287
// %bb.286:                             //   in Loop: Header=BB102_275 Depth=4
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w9, [x28, #412]
	ldr	w8, [x28, #444]
.LBB102_287:                            //   in Loop: Header=BB102_275 Depth=4
	adrp	x12, _ZL11stbi__bmask
	ldr	w10, [x28, #408]
	add	x12, x12, :lo12:_ZL11stbi__bmask
	neg	w11, w25
	mov	w13, wzr
	sub	w9, w9, w25
	ldr	w12, [x12, w25, uxtw #2]
	mov	w25, #64
	ror	w10, w10, w11
	str	w9, [x28, #412]
	bic	w11, w10, w12
	and	w10, w10, w12
	add	w8, w10, w8
	str	w11, [x28, #408]
	str	w8, [x28, #444]
.LBB102_288:                            //   in Loop: Header=BB102_275 Depth=4
	ldr	w8, [x28, #432]
	cmp	w23, w8
	b.gt	.LBB102_274
// %bb.289:                             //   in Loop: Header=BB102_275 Depth=4
	sxtw	x23, w23
	str	w13, [sp, #304]                 // 4-byte Folded Spill
	b	.LBB102_293
.LBB102_290:                            //   in Loop: Header=BB102_293 Depth=5
	ldr	w9, [sp, #368]                  // 4-byte Folded Reload
	sub	w8, w8, w9
.LBB102_291:                            //   in Loop: Header=BB102_293 Depth=5
	strh	w8, [x19, x21, lsl #1]
.LBB102_292:                            //   in Loop: Header=BB102_293 Depth=5
	ldrsw	x8, [x28, #432]
	add	x23, x23, #1
	sub	x9, x23, #1
	cmp	x9, x8
	b.ge	.LBB102_273
.LBB102_293:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_234 Depth=2
                                        //       Parent Loop BB102_238 Depth=3
                                        //         Parent Loop BB102_275 Depth=4
                                        // =>        This Inner Loop Header: Depth=5
	adrp	x9, _ZL19stbi__jpeg_dezigzag
	add	x9, x9, :lo12:_ZL19stbi__jpeg_dezigzag
	ldrb	w21, [x9, x23]
	ldrh	w9, [x19, x21, lsl #1]
	cbz	w9, .LBB102_300
// %bb.294:                             //   in Loop: Header=BB102_293 Depth=5
	ldr	w8, [x24]
	cmp	w8, #0
	b.gt	.LBB102_296
// %bb.295:                             //   in Loop: Header=BB102_293 Depth=5
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w8, [x24]
.LBB102_296:                            //   in Loop: Header=BB102_293 Depth=5
	ldr	w9, [x28, #408]
	sub	w8, w8, #1
	lsl	w10, w9, #1
	str	w8, [x28, #412]
	str	w10, [x28, #408]
	tbz	w9, #31, .LBB102_292
// %bb.297:                             //   in Loop: Header=BB102_293 Depth=5
	ldrsh	w8, [x19, x21, lsl #1]
	tst	w22, w8
	b.ne	.LBB102_292
// %bb.298:                             //   in Loop: Header=BB102_293 Depth=5
	cmp	w8, #0
	b.le	.LBB102_290
// %bb.299:                             //   in Loop: Header=BB102_293 Depth=5
	ldr	w9, [sp, #368]                  // 4-byte Folded Reload
	add	w8, w8, w9
	b	.LBB102_291
.LBB102_300:                            //   in Loop: Header=BB102_293 Depth=5
	cbz	w25, .LBB102_302
// %bb.301:                             //   in Loop: Header=BB102_293 Depth=5
	sub	w25, w25, #1
	b	.LBB102_292
.LBB102_302:                            //   in Loop: Header=BB102_275 Depth=4
	add	w23, w23, #1
	ldr	w9, [sp, #304]                  // 4-byte Folded Reload
	strh	w9, [x19, x21, lsl #1]
	b	.LBB102_274
.LBB102_303:                            //   in Loop: Header=BB102_238 Depth=3
	mov	w8, #1680
	add	x0, sp, #656
	movi	v0.2d, #0000000000000000
	madd	x8, x20, x8, x27
	add	x1, x8, #8
	stp	q0, q0, [x19, #96]
	stp	q0, q0, [x19, #64]
	stp	q0, q0, [x19, #32]
	stp	q0, q0, [x19]
	bl	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	cbz	w0, .LBB102_308
// %bb.304:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x24]
	mov	w23, w0
	cmp	w8, w0
	b.ge	.LBB102_306
// %bb.305:                             //   in Loop: Header=BB102_238 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB102_306:                            //   in Loop: Header=BB102_238 Depth=3
	cmp	w23, #17
	b.hs	.LBB102_1168
// %bb.307:                             //   in Loop: Header=BB102_238 Depth=3
	mov	w8, w23
	adrp	x12, _ZL11stbi__bmask
	lsl	x8, x8, #2
	adrp	x13, _ZL11stbi__jbias
	add	x12, x12, :lo12:_ZL11stbi__bmask
	add	x13, x13, :lo12:_ZL11stbi__jbias
	ldr	w9, [x28, #408]
	neg	w11, w23
	ldr	w12, [x12, x8]
	ldr	w8, [x13, x8]
	ldr	w10, [x28, #412]
	ror	w11, w9, w11
	cmp	w9, #0
	bic	w9, w11, w12
	and	w11, w12, w11
	csel	w8, wzr, w8, lt
	sub	w10, w10, w23
	add	w8, w8, w11
	str	w9, [x28, #408]
	str	w10, [x28, #412]
	b	.LBB102_309
.LBB102_308:                            //   in Loop: Header=BB102_238 Depth=3
	mov	w8, wzr
.LBB102_309:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	x11, [sp, #248]                 // 8-byte Folded Reload
	ldr	w10, [x28, #440]
	ldr	w9, [x11]
	add	w8, w9, w8
	lsl	w9, w8, w10
	str	w8, [x11]
	strh	w9, [x19]
.LBB102_310:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x28, #472]
	ldr	w22, [sp, #352]                 // 4-byte Folded Reload
	subs	w8, w8, #1
	str	w8, [x28, #472]
	b.gt	.LBB102_237
// %bb.311:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	w8, [x24]
	cmp	w8, #23
	b.gt	.LBB102_235
// %bb.312:                             //   in Loop: Header=BB102_238 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	b	.LBB102_235
.LBB102_313:                            //   in Loop: Header=BB102_238 Depth=3
	mov	w8, #1
	cmp	w0, #16
	lsl	w8, w8, w10
	str	w8, [x28, #444]
	b.hs	.LBB102_315
// %bb.314:                             //   in Loop: Header=BB102_238 Depth=3
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
	b	.LBB102_318
.LBB102_315:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	w9, [x25]
	mov	x19, x10
	cmp	w9, w19
	b.ge	.LBB102_317
// %bb.316:                             //   in Loop: Header=BB102_238 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	x8, [sp, #400]                  // 8-byte Folded Reload
	ldr	w9, [x8, #412]
	ldr	w8, [x8, #444]
.LBB102_317:                            //   in Loop: Header=BB102_238 Depth=3
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
	adrp	x12, _ZL11stbi__bmask
	add	x12, x12, :lo12:_ZL11stbi__bmask
	neg	w11, w19
	sub	w9, w9, w19
	ldr	w10, [x28, #408]
	ldr	w12, [x12, w19, uxtw #2]
	str	w9, [x28, #412]
	ror	w10, w10, w11
	bic	w11, w10, w12
	and	w10, w10, w12
	add	w8, w10, w8
	str	w11, [x28, #408]
.LBB102_318:                            //   in Loop: Header=BB102_238 Depth=3
	mov	x24, x25
	mov	x25, x22
	b	.LBB102_259
.LBB102_319:                            //   in Loop: Header=BB102_234 Depth=2
	ldr	w8, [sp, #320]                  // 4-byte Folded Reload
	adrp	x23, .L.str.31
	ldr	w9, [sp, #236]                  // 4-byte Folded Reload
	add	x23, x23, :lo12:.L.str.31
	add	w8, w8, #1
	cmp	w8, w9
	str	w8, [sp, #320]                  // 4-byte Folded Spill
	b.ne	.LBB102_234
	b	.LBB102_410
.LBB102_320:                            //   in Loop: Header=BB102_129 Depth=1
	b.ne	.LBB102_376
// %bb.321:                             //   in Loop: Header=BB102_129 Depth=1
	ldrsw	x23, [x28, #452]
	mov	w8, #17856
	str	w26, [sp, #28]                  // 4-byte Folded Spill
	madd	x9, x23, x22, x27
	ldr	w8, [x9, x8]
	cmp	w8, #1
	b.lt	.LBB102_402
// %bb.322:                             //   in Loop: Header=BB102_129 Depth=1
	mov	w10, #17852
	ldr	w9, [x9, x10]
	cmp	w9, #1
	b.lt	.LBB102_402
// %bb.323:                             //   in Loop: Header=BB102_129 Depth=1
	madd	x10, x23, x22, x27
	mov	w11, #17844
	add	w9, w9, #7
	add	w8, w8, #7
	add	x11, x10, x11
	asr	w9, w9, #3
	asr	w8, w8, #3
	cmp	w9, #1
	csinc	w9, w9, wzr, gt
	cmp	w8, #1
	str	x11, [sp, #384]                 // 8-byte Folded Spill
	mov	w11, #17840
	add	x22, x10, x11
	mov	w11, #17836
	add	x25, x10, x11
	mov	w11, #17872
	add	x26, x10, x11
	mov	w11, #17860
	mov	w19, wzr
	add	x20, x10, x11
	csinc	w8, w8, wzr, gt
	lsl	x21, x9, #3
	str	wzr, [sp, #368]                 // 4-byte Folded Spill
	str	w8, [sp, #352]                  // 4-byte Folded Spill
.LBB102_324:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_328 Depth 3
	mov	x28, x24
	mov	x24, xzr
	b	.LBB102_328
.LBB102_325:                            //   in Loop: Header=BB102_328 Depth=3
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldrb	w8, [x9, #416]
	and	w8, w8, #0xf8
	cmp	w8, #208
	b.ne	.LBB102_405
// %bb.326:                             //   in Loop: Header=BB102_328 Depth=3
	ldr	w8, [x9, #468]
	mov	w10, #2147483647
	movi	v0.2d, #0000000000000000
	str	wzr, [x9, #420]
	str	wzr, [x9, #240]
	cmp	w8, #0
	str	wzr, [x9, #144]
	csel	w8, w10, w8, eq
	mov	w10, #255
	str	d0, [sp, #18864]
	str	wzr, [x9, #48]
	strb	w10, [x9, #416]
	str	w8, [x9, #472]
	str	wzr, [x9, #444]
.LBB102_327:                            //   in Loop: Header=BB102_328 Depth=3
	add	x24, x24, #8
	cmp	x21, x24
	b.eq	.LBB102_332
.LBB102_328:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_324 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	mov	w11, #1680
	ldrsw	x8, [x22]
	add	x0, sp, #656
	ldrsw	x10, [x25]
	add	x1, sp, #432
	ldrsw	x9, [x9]
	mov	w5, w23
	madd	x8, x8, x11, x27
	add	x10, x27, x10, lsl #6
	madd	x11, x9, x11, x27
	add	x2, x8, #8
	mov	w8, #6728
	add	x9, x27, x9, lsl #10
	add	x3, x11, x8
	mov	w8, #13704
	add	x4, x9, x8
	mov	w8, #13448
	add	x6, x10, x8
	bl	_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh
	cbz	w0, .LBB102_404
// %bb.329:                             //   in Loop: Header=BB102_328 Depth=3
	ldr	w1, [x20]
	add	x2, sp, #432
	ldr	x8, [x26]
	mul	w9, w19, w1
	add	x8, x8, w9, sxtw
	ldr	x9, [sp, #18936]
	add	x0, x8, x24
	blr	x9
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	w8, [x9, #472]
	subs	w8, w8, #1
	str	w8, [x9, #472]
	b.gt	.LBB102_327
// %bb.330:                             //   in Loop: Header=BB102_328 Depth=3
	ldr	w8, [x28]
	cmp	w8, #23
	b.gt	.LBB102_325
// %bb.331:                             //   in Loop: Header=BB102_328 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	b	.LBB102_325
.LBB102_332:                            //   in Loop: Header=BB102_324 Depth=2
	ldr	w8, [sp, #368]                  // 4-byte Folded Reload
	add	w19, w19, #8
	ldr	w10, [sp, #352]                 // 4-byte Folded Reload
	mov	w9, #1
	mov	x24, x28
	add	w8, w8, #1
	cmp	w8, w10
	str	w8, [sp, #368]                  // 4-byte Folded Spill
	b.ne	.LBB102_324
	b	.LBB102_407
.LBB102_333:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w10, [x28, #12]
	cmp	w10, #1
	b.lt	.LBB102_410
// %bb.334:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	w9, [x28, #8]
	cmp	w9, #1
	b.lt	.LBB102_410
// %bb.335:                             //   in Loop: Header=BB102_129 Depth=1
	str	wzr, [sp, #368]                 // 4-byte Folded Spill
.LBB102_336:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_338 Depth 3
                                        //         Child Loop BB102_342 Depth 4
                                        //           Child Loop BB102_347 Depth 5
                                        //             Child Loop BB102_350 Depth 6
	cmp	w9, #1
	b.lt	.LBB102_375
// %bb.337:                             //   in Loop: Header=BB102_336 Depth=2
	mov	w22, #96
	str	wzr, [sp, #384]                 // 4-byte Folded Spill
.LBB102_338:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_336 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB102_342 Depth 4
                                        //           Child Loop BB102_347 Depth 5
                                        //             Child Loop BB102_350 Depth 6
	ldr	w10, [x28, #448]
	cmp	w10, #1
	b.lt	.LBB102_368
// %bb.339:                             //   in Loop: Header=BB102_338 Depth=3
	mov	x12, xzr
	b	.LBB102_342
.LBB102_340:                            //   in Loop: Header=BB102_342 Depth=4
	ldr	w10, [x28, #448]
	ldr	x12, [sp, #272]                 // 8-byte Folded Reload
.LBB102_341:                            //   in Loop: Header=BB102_342 Depth=4
	add	x12, x12, #1
	cmp	x12, w10, sxtw
	b.ge	.LBB102_367
.LBB102_342:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_336 Depth=2
                                        //       Parent Loop BB102_338 Depth=3
                                        // =>      This Loop Header: Depth=4
                                        //           Child Loop BB102_347 Depth 5
                                        //             Child Loop BB102_350 Depth 6
	mov	w9, #18252
	add	x8, x27, x12, lsl #2
	mov	w11, #17832
	ldrsw	x9, [x8, x9]
	madd	x8, x9, x22, x27
	add	x8, x8, x11
	str	x8, [sp, #352]                  // 8-byte Folded Spill
	ldr	w8, [x8]
	cmp	w8, #1
	b.lt	.LBB102_341
// %bb.343:                             //   in Loop: Header=BB102_342 Depth=4
	madd	x11, x9, x22, x27
	mov	w9, #17828
	add	x9, x11, x9
	str	x9, [sp, #296]                  // 8-byte Folded Spill
	ldr	w9, [x9]
	cmp	w9, #1
	b.lt	.LBB102_341
// %bb.344:                             //   in Loop: Header=BB102_342 Depth=4
	mov	w10, #17904
	mov	w20, wzr
	add	x10, x11, x10
	str	x10, [sp, #320]                 // 8-byte Folded Spill
	mov	w10, #17912
	add	x10, x11, x10
	str	x10, [sp, #304]                 // 8-byte Folded Spill
	mov	w10, #17840
	add	x10, x11, x10
	str	x10, [sp, #288]                 // 8-byte Folded Spill
	mov	w10, #17848
	add	x10, x11, x10
	stp	x12, x10, [sp, #272]            // 16-byte Folded Spill
	b	.LBB102_347
.LBB102_345:                            //   in Loop: Header=BB102_347 Depth=5
	adrp	x25, .L.str.32
	add	x25, x25, :lo12:.L.str.32
.LBB102_346:                            //   in Loop: Header=BB102_347 Depth=5
	add	w20, w20, #1
	cmp	w20, w8
	b.ge	.LBB102_340
.LBB102_347:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_336 Depth=2
                                        //       Parent Loop BB102_338 Depth=3
                                        //         Parent Loop BB102_342 Depth=4
                                        // =>        This Loop Header: Depth=5
                                        //             Child Loop BB102_350 Depth 6
	cmp	w9, #1
	b.lt	.LBB102_346
// %bb.348:                             //   in Loop: Header=BB102_347 Depth=5
	ldr	w10, [x28, #432]
	cbnz	w10, .LBB102_1009
// %bb.349:                             //   in Loop: Header=BB102_347 Depth=5
	ldr	w11, [sp, #368]                 // 4-byte Folded Reload
	mov	w25, #1
	ldr	x10, [sp, #304]                 // 8-byte Folded Reload
	madd	w8, w8, w11, w20
	ldr	w11, [sp, #384]                 // 4-byte Folded Reload
	ldr	w10, [x10]
	mul	w9, w9, w11
	madd	w8, w10, w8, w9
	ldr	x9, [sp, #320]                  // 8-byte Folded Reload
	lsl	w8, w8, #6
	ldr	x9, [x9]
	add	x19, x9, w8, sxtw #1
.LBB102_350:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_336 Depth=2
                                        //       Parent Loop BB102_338 Depth=3
                                        //         Parent Loop BB102_342 Depth=4
                                        //           Parent Loop BB102_347 Depth=5
                                        // =>          This Inner Loop Header: Depth=6
	ldr	x9, [sp, #288]                  // 8-byte Folded Reload
	ldr	w8, [x24]
	ldrsw	x21, [x9]
	cmp	w8, #15
	b.gt	.LBB102_352
// %bb.351:                             //   in Loop: Header=BB102_350 Depth=6
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB102_352:                            //   in Loop: Header=BB102_350 Depth=6
	ldr	w8, [x28, #436]
	cbz	w8, .LBB102_356
// %bb.353:                             //   in Loop: Header=BB102_350 Depth=6
	ldr	w8, [x24]
	cmp	w8, #0
	b.le	.LBB102_361
// %bb.354:                             //   in Loop: Header=BB102_350 Depth=6
	ldr	w9, [x28, #408]
	sub	w8, w8, #1
	lsl	w10, w9, #1
	str	w8, [x28, #412]
	str	w10, [x28, #408]
	tbnz	w9, #31, .LBB102_362
.LBB102_355:                            //   in Loop: Header=BB102_350 Depth=6
	ldr	x8, [sp, #296]                  // 8-byte Folded Reload
	ldr	w9, [x8]
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	cmp	w25, w9
	ldr	w8, [x8]
	b.lt	.LBB102_366
	b	.LBB102_345
.LBB102_356:                            //   in Loop: Header=BB102_350 Depth=6
	mov	w8, #1680
	add	x0, sp, #656
	movi	v0.2d, #0000000000000000
	mov	x22, x23
	madd	x8, x21, x8, x27
	add	x1, x8, #8
	stp	q0, q0, [x19, #96]
	stp	q0, q0, [x19, #64]
	stp	q0, q0, [x19, #32]
	stp	q0, q0, [x19]
	bl	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	cbz	w0, .LBB102_363
// %bb.357:                             //   in Loop: Header=BB102_350 Depth=6
	ldr	w8, [x24]
	mov	w23, w0
	cmp	w8, w0
	b.ge	.LBB102_359
// %bb.358:                             //   in Loop: Header=BB102_350 Depth=6
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB102_359:                            //   in Loop: Header=BB102_350 Depth=6
	cmp	w23, #17
	b.hs	.LBB102_1168
// %bb.360:                             //   in Loop: Header=BB102_350 Depth=6
	mov	w8, w23
	adrp	x12, _ZL11stbi__bmask
	lsl	x8, x8, #2
	adrp	x13, _ZL11stbi__jbias
	add	x12, x12, :lo12:_ZL11stbi__bmask
	add	x13, x13, :lo12:_ZL11stbi__jbias
	ldr	w9, [x28, #408]
	neg	w11, w23
	ldr	w12, [x12, x8]
	ldr	w8, [x13, x8]
	ldr	w10, [x28, #412]
	ror	w11, w9, w11
	cmp	w9, #0
	bic	w9, w11, w12
	and	w11, w12, w11
	csel	w8, wzr, w8, lt
	sub	w10, w10, w23
	add	w8, w8, w11
	str	w9, [x28, #408]
	str	w10, [x28, #412]
	b	.LBB102_364
.LBB102_361:                            //   in Loop: Header=BB102_350 Depth=6
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w8, [x24]
	ldr	w9, [x28, #408]
	sub	w8, w8, #1
	lsl	w10, w9, #1
	str	w8, [x28, #412]
	str	w10, [x28, #408]
	tbz	w9, #31, .LBB102_355
.LBB102_362:                            //   in Loop: Header=BB102_350 Depth=6
	ldr	w8, [x28, #440]
	mov	w10, #65536
	ldrh	w9, [x19]
	lsl	w8, w10, w8
	add	w8, w9, w8, lsr #16
	b	.LBB102_365
.LBB102_363:                            //   in Loop: Header=BB102_350 Depth=6
	mov	w8, wzr
.LBB102_364:                            //   in Loop: Header=BB102_350 Depth=6
	ldr	x11, [sp, #280]                 // 8-byte Folded Reload
	mov	x23, x22
	ldr	w10, [x28, #440]
	mov	w22, #96
	ldr	w9, [x11]
	add	w9, w9, w8
	lsl	w8, w9, w10
	str	w9, [x11]
.LBB102_365:                            //   in Loop: Header=BB102_350 Depth=6
	strh	w8, [x19]
	ldr	x8, [sp, #296]                  // 8-byte Folded Reload
	ldr	w9, [x8]
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	cmp	w25, w9
	ldr	w8, [x8]
	b.ge	.LBB102_345
.LBB102_366:                            //   in Loop: Header=BB102_350 Depth=6
	ldr	x10, [sp, #304]                 // 8-byte Folded Reload
	ldr	w11, [sp, #368]                 // 4-byte Folded Reload
	ldr	w10, [x10]
	madd	w8, w11, w8, w20
	ldr	w11, [x28, #432]
	mul	w8, w10, w8
	ldr	w10, [sp, #384]                 // 4-byte Folded Reload
	madd	w8, w10, w9, w8
	ldr	x9, [sp, #320]                  // 8-byte Folded Reload
	adrp	x10, .L.str.40
	add	w8, w25, w8
	add	w25, w25, #1
	ldr	x9, [x9]
	lsl	w8, w8, #6
	add	x10, x10, :lo12:.L.str.40
	add	x19, x9, w8, sxtw #1
	cbz	w11, .LBB102_350
	b	.LBB102_780
.LBB102_367:                            //   in Loop: Header=BB102_338 Depth=3
	ldr	w8, [x28, #472]
.LBB102_368:                            //   in Loop: Header=BB102_338 Depth=3
	subs	w8, w8, #1
	str	w8, [x28, #472]
	b.gt	.LBB102_373
// %bb.369:                             //   in Loop: Header=BB102_338 Depth=3
	ldr	w8, [x24]
	mov	x19, x24
	cmp	w8, #23
	b.gt	.LBB102_371
// %bb.370:                             //   in Loop: Header=BB102_338 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB102_371:                            //   in Loop: Header=BB102_338 Depth=3
	ldrb	w8, [x28, #416]
	and	w9, w8, #0xf8
	cmp	w9, #208
	b.ne	.LBB102_435
// %bb.372:                             //   in Loop: Header=BB102_338 Depth=3
	ldr	w8, [x28, #468]
	mov	w9, #2147483647
	movi	v0.2d, #0000000000000000
	mov	x24, x19
	mov	w22, #96
	str	wzr, [x28, #420]
	cmp	w8, #0
	str	wzr, [x28, #240]
	csel	w8, w9, w8, eq
	mov	w9, #255
	str	d0, [sp, #18864]
	str	wzr, [x28, #144]
	str	wzr, [x28, #48]
	strb	w9, [x28, #416]
	str	w8, [x28, #472]
	str	wzr, [x28, #444]
.LBB102_373:                            //   in Loop: Header=BB102_338 Depth=3
	ldr	w10, [sp, #384]                 // 4-byte Folded Reload
	ldr	w9, [x28, #8]
	add	w10, w10, #1
	cmp	w10, w9
	str	w10, [sp, #384]                 // 4-byte Folded Spill
	b.lt	.LBB102_338
// %bb.374:                             //   in Loop: Header=BB102_336 Depth=2
	ldr	w10, [x28, #12]
.LBB102_375:                            //   in Loop: Header=BB102_336 Depth=2
	ldr	w11, [sp, #368]                 // 4-byte Folded Reload
	add	w11, w11, #1
	cmp	w11, w10
	str	w11, [sp, #368]                 // 4-byte Folded Spill
	b.lt	.LBB102_336
	b	.LBB102_410
.LBB102_376:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w11, [x28, #12]
	mov	w9, #1
	cmp	w11, #1
	b.lt	.LBB102_409
// %bb.377:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	w10, [x28, #8]
	cmp	w10, #1
	b.lt	.LBB102_409
// %bb.378:                             //   in Loop: Header=BB102_129 Depth=1
	str	wzr, [sp, #352]                 // 4-byte Folded Spill
	str	w26, [sp, #28]                  // 4-byte Folded Spill
	str	x24, [sp, #240]                 // 8-byte Folded Spill
.LBB102_379:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_381 Depth 3
                                        //         Child Loop BB102_385 Depth 4
                                        //           Child Loop BB102_389 Depth 5
                                        //             Child Loop BB102_391 Depth 6
	cmp	w10, #1
	b.lt	.LBB102_401
// %bb.380:                             //   in Loop: Header=BB102_379 Depth=2
	str	wzr, [sp, #368]                 // 4-byte Folded Spill
.LBB102_381:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_379 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB102_385 Depth 4
                                        //           Child Loop BB102_389 Depth 5
                                        //             Child Loop BB102_391 Depth 6
	ldr	w9, [x28, #448]
	cmp	w9, #1
	b.lt	.LBB102_394
// %bb.382:                             //   in Loop: Header=BB102_381 Depth=3
	mov	x11, xzr
	b	.LBB102_385
.LBB102_383:                            //   in Loop: Header=BB102_385 Depth=4
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
	adrp	x25, .L.str.32
	ldr	w26, [sp, #28]                  // 4-byte Folded Reload
	add	x25, x25, :lo12:.L.str.32
	ldr	x24, [sp, #240]                 // 8-byte Folded Reload
	mov	w22, #96
	ldr	w9, [x28, #448]
	ldr	x11, [sp, #296]                 // 8-byte Folded Reload
.LBB102_384:                            //   in Loop: Header=BB102_385 Depth=4
	add	x11, x11, #1
	cmp	x11, w9, sxtw
	b.ge	.LBB102_393
.LBB102_385:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_379 Depth=2
                                        //       Parent Loop BB102_381 Depth=3
                                        // =>      This Loop Header: Depth=4
                                        //           Child Loop BB102_389 Depth 5
                                        //             Child Loop BB102_391 Depth 6
	mov	w10, #18252
	add	x8, x27, x11, lsl #2
	ldrsw	x23, [x8, x10]
	mov	w10, #17832
	madd	x8, x23, x22, x27
	add	x8, x8, x10
	ldr	w20, [x8]
	str	x8, [sp, #384]                  // 8-byte Folded Spill
	cmp	w20, #1
	b.lt	.LBB102_384
// %bb.386:                             //   in Loop: Header=BB102_385 Depth=4
	madd	x8, x23, x22, x27
	mov	w10, #17828
	add	x10, x8, x10
	ldr	w19, [x10]
	str	x10, [sp, #304]                 // 8-byte Folded Spill
	cmp	w19, #1
	b.lt	.LBB102_384
// %bb.387:                             //   in Loop: Header=BB102_385 Depth=4
	mov	w9, #17844
	mov	w26, wzr
	add	x9, x8, x9
	str	x11, [sp, #296]                 // 8-byte Folded Spill
	str	x9, [sp, #320]                  // 8-byte Folded Spill
	mov	w9, #17840
	add	x25, x8, x9
	mov	w9, #17836
	add	x21, x8, x9
	mov	w9, #17872
	add	x24, x8, x9
	mov	w9, #17860
	add	x28, x8, x9
	b	.LBB102_389
.LBB102_388:                            //   in Loop: Header=BB102_389 Depth=5
	add	w26, w26, #1
	cmp	w26, w20
	b.ge	.LBB102_383
.LBB102_389:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_379 Depth=2
                                        //       Parent Loop BB102_381 Depth=3
                                        //         Parent Loop BB102_385 Depth=4
                                        // =>        This Loop Header: Depth=5
                                        //             Child Loop BB102_391 Depth 6
	cmp	w19, #1
	b.lt	.LBB102_388
// %bb.390:                             //   in Loop: Header=BB102_389 Depth=5
	mov	w22, wzr
.LBB102_391:                            //   Parent Loop BB102_129 Depth=1
                                        //     Parent Loop BB102_379 Depth=2
                                        //       Parent Loop BB102_381 Depth=3
                                        //         Parent Loop BB102_385 Depth=4
                                        //           Parent Loop BB102_389 Depth=5
                                        // =>          This Inner Loop Header: Depth=6
	ldr	x9, [sp, #320]                  // 8-byte Folded Reload
	mov	w11, #1680
	ldrsw	x8, [x25]
	add	x0, sp, #656
	ldrsw	x10, [x21]
	add	x1, sp, #432
	ldrsw	x9, [x9]
	mov	w5, w23
	madd	x8, x8, x11, x27
	add	x10, x27, x10, lsl #6
	madd	x11, x9, x11, x27
	add	x2, x8, #8
	mov	w8, #6728
	add	x9, x27, x9, lsl #10
	add	x3, x11, x8
	mov	w8, #13704
	add	x4, x9, x8
	mov	w8, #13448
	add	x6, x10, x8
	bl	_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh
	cbz	w0, .LBB102_403
// %bb.392:                             //   in Loop: Header=BB102_391 Depth=6
	ldr	w8, [sp, #352]                  // 4-byte Folded Reload
	add	x2, sp, #432
	ldr	w1, [x28]
	ldr	w9, [sp, #368]                  // 4-byte Folded Reload
	madd	w8, w20, w8, w26
	ldr	x10, [x24]
	madd	w9, w9, w19, w22
	mul	w8, w8, w1
	lsl	w9, w9, #3
	lsl	w8, w8, #3
	add	x8, x10, w8, sxtw
	ldr	x10, [sp, #18936]
	add	x0, x8, w9, sxtw
	blr	x10
	ldr	x8, [sp, #304]                  // 8-byte Folded Reload
	add	w22, w22, #1
	ldr	w19, [x8]
	ldr	x8, [sp, #384]                  // 8-byte Folded Reload
	cmp	w22, w19
	ldr	w20, [x8]
	b.lt	.LBB102_391
	b	.LBB102_388
.LBB102_393:                            //   in Loop: Header=BB102_381 Depth=3
	adrp	x23, .L.str.31
	ldr	w8, [x28, #472]
	add	x23, x23, :lo12:.L.str.31
.LBB102_394:                            //   in Loop: Header=BB102_381 Depth=3
	subs	w8, w8, #1
	str	w8, [x28, #472]
	b.gt	.LBB102_399
// %bb.395:                             //   in Loop: Header=BB102_381 Depth=3
	ldr	w8, [x24]
	mov	x19, x24
	cmp	w8, #23
	b.gt	.LBB102_397
// %bb.396:                             //   in Loop: Header=BB102_381 Depth=3
	add	x0, sp, #656
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB102_397:                            //   in Loop: Header=BB102_381 Depth=3
	ldrb	w8, [x28, #416]
	and	w8, w8, #0xf8
	cmp	w8, #208
	b.ne	.LBB102_436
// %bb.398:                             //   in Loop: Header=BB102_381 Depth=3
	ldr	w8, [x28, #468]
	mov	w9, #2147483647
	movi	v0.2d, #0000000000000000
	mov	x24, x19
	mov	w22, #96
	str	wzr, [x28, #420]
	cmp	w8, #0
	str	wzr, [x28, #240]
	csel	w8, w9, w8, eq
	mov	w9, #255
	str	d0, [sp, #18864]
	str	wzr, [x28, #144]
	str	wzr, [x28, #48]
	strb	w9, [x28, #416]
	str	w8, [x28, #472]
	str	wzr, [x28, #444]
.LBB102_399:                            //   in Loop: Header=BB102_381 Depth=3
	ldr	w9, [sp, #368]                  // 4-byte Folded Reload
	ldr	w10, [x28, #8]
	add	w9, w9, #1
	cmp	w9, w10
	str	w9, [sp, #368]                  // 4-byte Folded Spill
	b.lt	.LBB102_381
// %bb.400:                             //   in Loop: Header=BB102_379 Depth=2
	ldr	w11, [x28, #12]
.LBB102_401:                            //   in Loop: Header=BB102_379 Depth=2
	ldr	w12, [sp, #352]                 // 4-byte Folded Reload
	mov	w9, #1
	add	w12, w12, #1
	cmp	w12, w11
	str	w12, [sp, #352]                 // 4-byte Folded Spill
	b.lt	.LBB102_379
	b	.LBB102_409
.LBB102_402:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w9, #1
	b	.LBB102_407
.LBB102_403:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w26, [sp, #28]                  // 4-byte Folded Reload
	mov	w9, wzr
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
	ldr	x24, [sp, #240]                 // 8-byte Folded Reload
	b	.LBB102_408
.LBB102_404:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w9, wzr
	b	.LBB102_406
.LBB102_405:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w9, #1
.LBB102_406:                            //   in Loop: Header=BB102_129 Depth=1
	mov	x24, x28
.LBB102_407:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w26, [sp, #28]                  // 4-byte Folded Reload
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
.LBB102_408:                            //   in Loop: Header=BB102_129 Depth=1
	adrp	x23, .L.str.31
	adrp	x25, .L.str.32
	add	x23, x23, :lo12:.L.str.31
	add	x25, x25, :lo12:.L.str.32
.LBB102_409:                            //   in Loop: Header=BB102_129 Depth=1
	cbz	w9, .LBB102_781
.LBB102_410:                            //   in Loop: Header=BB102_129 Depth=1
	ldrb	w8, [x28, #416]
.LBB102_411:                            //   in Loop: Header=BB102_129 Depth=1
	cmp	w8, #255
	b.eq	.LBB102_413
	b	.LBB102_132
.LBB102_412:                            //   in Loop: Header=BB102_413 Depth=2
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	cbnz	w8, .LBB102_423
.LBB102_413:                            //   Parent Loop BB102_129 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x19, [sp, #656]
	ldr	x8, [x19, #16]
	cbz	x8, .LBB102_416
// %bb.414:                             //   in Loop: Header=BB102_413 Depth=2
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB102_417
// %bb.415:                             //   in Loop: Header=BB102_413 Depth=2
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_132
.LBB102_416:                            //   in Loop: Header=BB102_413 Depth=2
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_132
.LBB102_417:                            //   in Loop: Header=BB102_413 Depth=2
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB102_412
// %bb.418:                             //   in Loop: Header=BB102_413 Depth=2
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_413
// %bb.419:                             //   in Loop: Header=BB102_413 Depth=2
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_421
// %bb.420:                             //   in Loop: Header=BB102_413 Depth=2
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_422
.LBB102_421:                            //   in Loop: Header=BB102_413 Depth=2
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_422:                            //   in Loop: Header=BB102_413 Depth=2
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
	cbz	w8, .LBB102_413
.LBB102_423:                            //   in Loop: Header=BB102_129 Depth=1
	cmp	w8, #255
	b.ne	.LBB102_776
// %bb.424:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB102_426
// %bb.425:                             //   in Loop: Header=BB102_129 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w1, [x8]
	b	.LBB102_432
.LBB102_426:                            //   in Loop: Header=BB102_129 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_429
// %bb.427:                             //   in Loop: Header=BB102_129 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_430
// %bb.428:                             //   in Loop: Header=BB102_129 Depth=1
	mov	x8, x19
	ldrb	w1, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_431
.LBB102_429:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w1, wzr
	b	.LBB102_432
.LBB102_430:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w1, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB102_431:                            //   in Loop: Header=BB102_129 Depth=1
	add	x9, x19, #57
	ldr	x28, [sp, #400]                 // 8-byte Folded Reload
	stp	x9, x8, [x19, #184]
.LBB102_432:                            //   in Loop: Header=BB102_129 Depth=1
	strb	w1, [x28, #416]
	cmp	w1, #255
	b.eq	.LBB102_133
.LBB102_433:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w8, #255
	strb	w8, [x28, #416]
	b	.LBB102_129
.LBB102_434:                            //   in Loop: Header=BB102_129 Depth=1
	adrp	x23, .L.str.31
	add	x23, x23, :lo12:.L.str.31
	b	.LBB102_411
.LBB102_435:                            //   in Loop: Header=BB102_129 Depth=1
	mov	x24, x19
	b	.LBB102_411
.LBB102_436:                            //   in Loop: Header=BB102_129 Depth=1
	mov	w9, #1
	mov	x24, x19
	cbnz	w9, .LBB102_410
	b	.LBB102_781
.LBB102_437:                            //   in Loop: Header=BB102_438 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w1, [x8]
	cmp	w1, #255
	b.ne	.LBB102_128
.LBB102_438:                            // =>This Inner Loop Header: Depth=1
	ldr	x19, [sp, #656]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB102_437
// %bb.439:                             //   in Loop: Header=BB102_438 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB102_443
// %bb.440:                             //   in Loop: Header=BB102_438 Depth=1
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB102_442
// %bb.441:                             //   in Loop: Header=BB102_438 Depth=1
	mov	x8, x19
	ldrb	w1, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w1, #255
	b.eq	.LBB102_438
	b	.LBB102_128
.LBB102_442:                            //   in Loop: Header=BB102_438 Depth=1
	mov	w1, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w1, #255
	b.eq	.LBB102_438
	b	.LBB102_128
.LBB102_443:
	mov	w1, wzr
	b	.LBB102_128
.LBB102_444:
	mov	x10, x23
	b	.LBB102_780
.LBB102_445:
	adrp	x10, .L.str.33
	add	x10, x10, :lo12:.L.str.33
	b	.LBB102_780
.LBB102_446:
	adrp	x10, .L.str.34
	add	x10, x10, :lo12:.L.str.34
	b	.LBB102_780
.LBB102_447:
	mov	w8, wzr
	add	x9, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_448:
	add	x10, x23, #57
	stp	x10, x9, [x23, #184]
.LBB102_449:
	cmp	w8, #77
	b.ne	.LBB102_452
// %bb.450:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB102_453
// %bb.451:
	add	x9, x9, #1
	b	.LBB102_493
.LBB102_452:
	adrp	x8, .L.str.69
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.69
	b	.LBB102_19
.LBB102_453:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_494
// %bb.454:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_491
// %bb.455:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_492
.LBB102_456:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_457:
	add	x11, x23, #57
	stp	x11, x8, [x23, #184]
.LBB102_458:
	cmp	w9, #56
	b.ne	.LBB102_539
// %bb.459:
	cmp	x11, x8
	b.hs	.LBB102_461
// %bb.460:
	add	x10, x11, #1
	str	x10, [x28]
	ldrb	w9, [x11]
	b	.LBB102_532
.LBB102_461:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_539
// %bb.462:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_530
// %bb.463:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_531
.LBB102_464:
	ldr	x19, [sp, #656]
	ldr	w8, [x28, #424]
	ldr	w28, [x19, #8]
	cbz	w8, .LBB102_479
// %bb.465:
	cmp	w28, #1
	b.lt	.LBB102_479
// %bb.466:
	mov	w8, #13448
	add	x9, sp, #656
	mov	x10, xzr
	add	x8, x9, x8
	mov	w12, #96
	mov	w13, #17856
	mov	w27, #13512
	str	w26, [sp, #28]                  // 4-byte Folded Spill
	str	x8, [sp, #424]                  // 8-byte Folded Spill
	b	.LBB102_469
.LBB102_467:                            //   in Loop: Header=BB102_469 Depth=1
	ldr	x19, [sp, #656]
	mov	w12, #96
	ldr	w26, [sp, #28]                  // 4-byte Folded Reload
	mov	w13, #17856
	ldr	x10, [sp, #368]                 // 8-byte Folded Reload
.LBB102_468:                            //   in Loop: Header=BB102_469 Depth=1
	ldrsw	x28, [x19, #8]
	add	x10, x10, #1
	cmp	x10, x28
	b.ge	.LBB102_479
.LBB102_469:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_473 Depth 2
                                        //       Child Loop BB102_476 Depth 3
                                        //         Child Loop BB102_478 Depth 4
	add	x8, sp, #656
	madd	x9, x10, x12, x8
	ldr	w8, [x9, x13]
	cmp	w8, #1
	b.lt	.LBB102_468
// %bb.470:                             //   in Loop: Header=BB102_469 Depth=1
	mov	w11, #17852
	ldr	w9, [x9, x11]
	cmp	w9, #1
	b.lt	.LBB102_468
// %bb.471:                             //   in Loop: Header=BB102_469 Depth=1
	add	x11, sp, #656
	str	x10, [sp, #368]                 // 8-byte Folded Spill
	madd	x10, x10, x12, x11
	add	w9, w9, #7
	mov	w11, #17904
	asr	w9, w9, #3
	add	w8, w8, #7
	add	x28, x10, x11
	mov	w11, #17912
	asr	w8, w8, #3
	add	x25, x10, x11
	mov	w11, #17836
	cmp	w9, #1
	add	x21, x10, x11
	mov	w11, #17872
	csinc	w20, w9, wzr, gt
	cmp	w8, #1
	mov	w9, #17860
	mov	w19, wzr
	add	x26, x10, x11
	add	x22, x10, x9
	csinc	w8, w8, wzr, gt
	str	w8, [sp, #384]                  // 4-byte Folded Spill
	b	.LBB102_473
.LBB102_472:                            //   in Loop: Header=BB102_473 Depth=2
	ldr	w8, [sp, #384]                  // 4-byte Folded Reload
	add	w19, w19, #1
	cmp	w19, w8
	b.eq	.LBB102_467
.LBB102_473:                            //   Parent Loop BB102_469 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_476 Depth 3
                                        //         Child Loop BB102_478 Depth 4
	mov	x23, xzr
	lsl	w24, w19, #3
	b	.LBB102_476
.LBB102_474:                            //   in Loop: Header=BB102_476 Depth=3
	ldr	d0, [x8, #13448]
	ldp	q1, q2, [x2]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v1.8h, v0.8h
	str	q0, [x2]
	ldr	d0, [x8, #13456]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v2.8h, v0.8h
	ldp	q1, q2, [x2, #32]
	str	q0, [x2, #16]
	ldr	d0, [x8, #13464]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v1.8h, v0.8h
	str	q0, [x2, #32]
	ldr	d0, [x8, #13472]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v2.8h, v0.8h
	ldp	q1, q2, [x2, #64]
	str	q0, [x2, #48]
	ldr	d0, [x8, #13480]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v1.8h, v0.8h
	str	q0, [x2, #64]
	ldr	d0, [x8, #13488]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v2.8h, v0.8h
	ldp	q1, q2, [x2, #96]
	str	q0, [x2, #80]
	ldr	d0, [x8, #13496]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v1.8h, v0.8h
	str	q0, [x2, #96]
	ldr	d0, [x8, #13504]
	ushll	v0.8h, v0.8b, #0
	mul	v0.8h, v2.8h, v0.8h
	str	q0, [x2, #112]
.LBB102_475:                            //   in Loop: Header=BB102_476 Depth=3
	ldr	w1, [x22]
	ldr	x8, [x26]
	mul	w9, w24, w1
	add	x8, x8, w9, sxtw
	ldr	x9, [sp, #18936]
	add	x0, x8, x23, lsl #3
	blr	x9
	add	x23, x23, #1
	cmp	x23, x20
	b.eq	.LBB102_472
.LBB102_476:                            //   Parent Loop BB102_469 Depth=1
                                        //     Parent Loop BB102_473 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB102_478 Depth 4
	ldr	w10, [x25]
	mov	w14, #13448
	ldrsw	x11, [x21]
	ldr	x9, [x28]
	madd	w8, w10, w19, w23
	lsl	w12, w8, #6
	add	x8, sp, #656
	add	x8, x8, x11, lsl #6
	add	x2, x9, w12, sxtw #1
	add	x12, x8, x27
	add	x13, x2, #128
	add	x14, x8, x14
	cmp	x12, x2
	ccmp	x14, x13, #2, hi
	b.hs	.LBB102_474
// %bb.477:                             //   in Loop: Header=BB102_476 Depth=3
	madd	w10, w19, w10, w23
	mov	x8, xzr
	lsl	w10, w10, #6
	add	x9, x9, w10, sxtw #1
	ldr	x10, [sp, #424]                 // 8-byte Folded Reload
	add	x10, x10, x11, lsl #6
.LBB102_478:                            //   Parent Loop BB102_469 Depth=1
                                        //     Parent Loop BB102_473 Depth=2
                                        //       Parent Loop BB102_476 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	lsl	x11, x8, #1
	ldrb	w12, [x10, x8]
	add	x8, x8, #1
	cmp	x8, #64
	ldrh	w13, [x9, x11]
	mul	w12, w13, w12
	strh	w12, [x9, x11]
	b.ne	.LBB102_478
	b	.LBB102_475
.LBB102_479:
	cmp	w26, #0
	csel	w27, w28, w26, eq
	cmp	w27, #3
	ccmp	w28, #3, #0, lt
	str	x27, [sp, #352]                 // 8-byte Folded Spill
	csinc	w24, w28, wzr, ne
	cmp	w24, #0
	str	x24, [sp, #320]                 // 8-byte Folded Spill
	b.le	.LBB102_555
// %bb.480:
	add	x8, sp, #432
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	add	x22, x8, #24
	ldr	x8, [sp, #18952]
	ldr	w10, [x19]
	adrp	x27, _ZL26stbi__resample_row_genericPhS_S_ii
	ldp	w20, w21, [x9]
	str	x8, [sp, #400]                  // 8-byte Folded Spill
	mov	w8, #17828
	add	x9, sp, #656
	add	w23, w10, #3
	sub	w25, w10, #1
	add	x27, x27, :lo12:_ZL26stbi__resample_row_genericPhS_S_ii
	add	x26, x9, x8
	str	w10, [sp, #424]                 // 4-byte Folded Spill
	b	.LBB102_483
.LBB102_481:                            //   in Loop: Header=BB102_483 Depth=1
	mov	x9, x27
.LBB102_482:                            //   in Loop: Header=BB102_483 Depth=1
	stur	x9, [x22, #-24]
	subs	x24, x24, #1
	add	x22, x22, #48
	add	x26, x26, #96
	b.eq	.LBB102_565
.LBB102_483:                            // =>This Inner Loop Header: Depth=1
	mov	x0, x23
	bl	malloc
	stur	x0, [x26, #68]
	cbz	x0, .LBB102_556
// %bb.484:                             //   in Loop: Header=BB102_483 Depth=1
	ldp	w8, w10, [x26]
	str	wzr, [x22, #16]
	sdiv	w9, w20, w8
	cmp	w9, #2
	sdiv	w8, w21, w10
	add	w10, w25, w9
	asr	w11, w8, #1
	udiv	w10, w10, w9
	stp	w9, w8, [x22]
	stp	w10, w11, [x22, #8]
	ldur	x10, [x26, #44]
	stp	x10, x10, [x22, #-16]
	b.eq	.LBB102_487
// %bb.485:                             //   in Loop: Header=BB102_483 Depth=1
	cmp	w9, #1
	b.ne	.LBB102_481
// %bb.486:                             //   in Loop: Header=BB102_483 Depth=1
	adrp	x9, _ZL22stbi__resample_row_v_2PhS_S_ii
	cmp	w8, #2
	add	x9, x9, :lo12:_ZL22stbi__resample_row_v_2PhS_S_ii
	csel	x9, x9, x27, eq
	cmp	w8, #1
	adrp	x8, _ZL14resample_row_1PhS_S_ii
	add	x8, x8, :lo12:_ZL14resample_row_1PhS_S_ii
	csel	x9, x8, x9, eq
	b	.LBB102_482
.LBB102_487:                            //   in Loop: Header=BB102_483 Depth=1
	cmp	w8, #1
	b.eq	.LBB102_489
// %bb.488:                             //   in Loop: Header=BB102_483 Depth=1
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	cmp	w8, #2
	b.eq	.LBB102_482
	b	.LBB102_481
.LBB102_489:                            //   in Loop: Header=BB102_483 Depth=1
	adrp	x9, _ZL22stbi__resample_row_h_2PhS_S_ii
	add	x9, x9, :lo12:_ZL22stbi__resample_row_h_2PhS_S_ii
	b	.LBB102_482
.LBB102_490:
	mov	x10, x25
	b	.LBB102_780
.LBB102_491:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_492:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_493:
	str	x9, [x28]
.LBB102_494:
	cmp	x9, x8
	b.hs	.LBB102_496
// %bb.495:
	add	x9, x9, #1
	b	.LBB102_501
.LBB102_496:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_502
// %bb.497:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_499
// %bb.498:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_500
.LBB102_499:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_500:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_501:
	str	x9, [x28]
.LBB102_502:
	cmp	x9, x8
	b.hs	.LBB102_504
// %bb.503:
	add	x9, x9, #1
	b	.LBB102_509
.LBB102_504:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_510
// %bb.505:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_507
// %bb.506:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_508
.LBB102_507:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_508:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_509:
	str	x9, [x28]
.LBB102_510:
	cmp	x9, x8
	b.hs	.LBB102_512
// %bb.511:
	add	x9, x9, #1
	b	.LBB102_517
.LBB102_512:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_518
// %bb.513:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_515
// %bb.514:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_516
.LBB102_515:
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_516:
	add	x9, x23, #57
	str	x8, [x23, #192]
.LBB102_517:
	str	x9, [x28]
.LBB102_518:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	w24, w0
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	cmp	w0, #56
	b.hi	.LBB102_520
// %bb.519:
	mov	w8, w0
	mov	w9, #1
	lsl	x8, x9, x8
	mov	x9, #4096
	movk	x9, #256, lsl #32
	movk	x9, #256, lsl #48
	tst	x8, x9
	b.ne	.LBB102_522
.LBB102_520:
	cmp	w0, #108
	b.eq	.LBB102_522
// %bb.521:
	cmp	w0, #124
	b.ne	.LBB102_529
.LBB102_522:
	cmp	w0, #12
	str	w0, [sp, #400]                  // 4-byte Folded Spill
	b.ne	.LBB102_525
// %bb.523:
	ldr	x9, [x28]
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_526
// %bb.524:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	b	.LBB102_703
.LBB102_525:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	str	w0, [x23]
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldp	x9, x8, [x23, #184]
	str	w0, [x23, #4]
	b	.LBB102_726
.LBB102_526:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_554
// %bb.527:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_701
// %bb.528:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_702
.LBB102_529:
	adrp	x8, .L.str.70
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.70
	b	.LBB102_19
.LBB102_530:
	mov	w9, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_531:
	add	x10, x23, #57
	stp	x10, x8, [x23, #184]
.LBB102_532:
	cmp	w9, #57
	b.eq	.LBB102_534
// %bb.533:
	cmp	w9, #55
	b.ne	.LBB102_539
.LBB102_534:
	cmp	x10, x8
	b.hs	.LBB102_536
// %bb.535:
	add	x8, x10, #1
	str	x8, [x28]
	ldrb	w8, [x10]
	b	.LBB102_604
.LBB102_536:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_539
// %bb.537:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_602
// %bb.538:
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_603
.LBB102_539:
	ldr	x8, [x23, #200]
	str	x8, [x23, #184]
.LBB102_540:
	mov	x0, x23
	bl	_ZL13stbi__get32beP13stbi__context
	ldr	x8, [x23, #200]
	mov	w9, #20563
	movk	w9, #14402, lsl #16
	cmp	w0, w9
	str	x8, [x23, #184]
	b.ne	.LBB102_542
// %bb.541:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x27
	mov	w4, w26
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2800
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	_ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i
.LBB102_542:
	mov	x0, x23
	bl	_ZL14stbi__pic_testP13stbi__context
	cbz	w0, .LBB102_544
// %bb.543:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x27
	mov	w4, w26
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2800
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	_ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i
.LBB102_544:
	mov	x0, x23
	bl	_ZL14stbi__pnm_testP13stbi__context
	cbz	w0, .LBB102_546
// %bb.545:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x27
	mov	w4, w26
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2800
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	_ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i
.LBB102_546:
	mov	x0, x23
	bl	_ZL14stbi__hdr_testP13stbi__context
	cbz	w0, .LBB102_550
// %bb.547:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x27
	mov	w4, w26
	bl	_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i
	ldr	w1, [x22]
	ldr	w2, [x21]
	cbnz	w26, .LBB102_549
// %bb.548:
	ldr	w26, [x27]
.LBB102_549:
	mov	w3, w26
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2800
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	_ZL16stbi__hdr_to_ldrPfiii
.LBB102_550:
	mov	x0, x23
	bl	_ZL14stbi__tga_testP13stbi__context
	cbz	w0, .LBB102_552
// %bb.551:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x27
	mov	w4, w26
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2800
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	b	_ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i
.LBB102_552:
	adrp	x8, .L.str.9
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.9
	b	.LBB102_19
.LBB102_553:
	adrp	x10, .L.str.31
	str	wzr, [x28, #448]
	add	x10, x10, :lo12:.L.str.31
	b	.LBB102_780
.LBB102_554:
	mov	w19, wzr
	b	.LBB102_703
.LBB102_555:
	ldr	w8, [x19]
	b	.LBB102_566
.LBB102_556:
	cmp	w28, #1
	b.lt	.LBB102_700
// %bb.557:
	mov	w8, #17904
	add	x9, sp, #656
	mov	x19, xzr
	add	x20, x9, x8
	b	.LBB102_559
.LBB102_558:                            //   in Loop: Header=BB102_559 Depth=1
	ldr	x8, [sp, #656]
	add	x19, x19, #1
	add	x20, x20, #96
	ldrsw	x8, [x8, #8]
	cmp	x19, x8
	b.ge	.LBB102_700
.LBB102_559:                            // =>This Inner Loop Header: Depth=1
	ldur	x0, [x20, #-24]
	cbz	x0, .LBB102_561
// %bb.560:                             //   in Loop: Header=BB102_559 Depth=1
	bl	free
	stp	xzr, xzr, [x20, #-32]
.LBB102_561:                            //   in Loop: Header=BB102_559 Depth=1
	ldur	x0, [x20, #-16]
	cbz	x0, .LBB102_563
// %bb.562:                             //   in Loop: Header=BB102_559 Depth=1
	bl	free
	stur	xzr, [x20, #-16]
	str	xzr, [x20]
.LBB102_563:                            //   in Loop: Header=BB102_559 Depth=1
	ldur	x0, [x20, #-8]
	cbz	x0, .LBB102_558
// %bb.564:                             //   in Loop: Header=BB102_559 Depth=1
	bl	free
	stur	xzr, [x20, #-8]
	b	.LBB102_558
.LBB102_565:
	ldr	x27, [sp, #352]                 // 8-byte Folded Reload
	ldr	w8, [sp, #424]                  // 4-byte Folded Reload
.LBB102_566:
	str	w8, [sp, #424]                  // 4-byte Folded Spill
	mul	w8, w8, w27
	ldr	w20, [x19, #4]
	orr	w9, wzr, #0x1
	madd	w0, w8, w20, w9
	bl	malloc
	ldp	x22, x26, [sp, #336]            // 16-byte Folded Reload
	cbz	x0, .LBB102_691
// %bb.567:
	mov	x24, x0
	cbz	w20, .LBB102_591
// %bb.568:
	ldr	x28, [sp, #320]                 // 8-byte Folded Reload
	mov	w8, #48
	mov	w9, #17856
	mov	w11, wzr
	mov	w12, wzr
	sxtw	x13, w27
	umull	x25, w28, w8
	add	x8, sp, #656
	add	x8, x8, x9
	mov	w20, #16
	mov	w21, #8
	mov	w14, #255
	ldr	w9, [sp, #424]                  // 4-byte Folded Reload
                                        // implicit-def: $x23
	str	x13, [sp, #368]                 // 8-byte Folded Spill
	str	x8, [sp, #304]                  // 8-byte Folded Spill
	add	x8, x24, #3
	str	x8, [sp, #296]                  // 8-byte Folded Spill
	cmp	w28, #1
	b.ge	.LBB102_570
	b	.LBB102_576
.LBB102_569:                            //   in Loop: Header=BB102_576 Depth=1
	ldr	w9, [x19]
	add	w11, w11, w27
	cmp	w28, #1
	b.lt	.LBB102_576
.LBB102_570:
	mov	x19, xzr
	add	x23, sp, #624
	ldr	x28, [sp, #304]                 // 8-byte Folded Reload
	str	w12, [sp, #384]                 // 4-byte Folded Spill
	str	w11, [sp, #400]                 // 4-byte Folded Spill
	str	w9, [sp, #424]                  // 4-byte Folded Spill
	b	.LBB102_572
.LBB102_571:                            //   in Loop: Header=BB102_572 Depth=1
	add	x19, x19, #48
	add	x28, x28, #96
	add	x23, x23, #8
	cmp	x25, x19
	b.eq	.LBB102_575
.LBB102_572:                            // =>This Inner Loop Header: Depth=1
	add	x8, sp, #432
	ldr	x0, [x28, #40]
	add	x22, x8, x19
	ldp	w27, w3, [x22, #28]
	ldr	w26, [x22, #36]
	ldr	w4, [x22, #24]
	ldr	x10, [x22]
	cmp	w26, w27, asr #1
	csel	x8, x21, x20, lt
	csel	x9, x20, x21, lt
	ldr	x1, [x22, x8]
	ldr	x2, [x22, x9]
	blr	x10
	add	w8, w26, #1
	str	x0, [x23]
	cmp	w8, w27
	str	w8, [x22, #36]
	b.lt	.LBB102_571
// %bb.573:                             //   in Loop: Header=BB102_572 Depth=1
	ldr	w9, [x22, #40]
	ldr	w10, [x28]
	ldr	x8, [x22, #16]
	add	w9, w9, #1
	cmp	w9, w10
	str	x8, [x22, #8]
	stp	wzr, w9, [x22, #36]
	b.ge	.LBB102_571
// %bb.574:                             //   in Loop: Header=BB102_572 Depth=1
	ldrsw	x9, [x28, #4]
	add	x8, x8, x9
	str	x8, [x22, #16]
	b	.LBB102_571
.LBB102_575:
	ldp	x22, x26, [sp, #336]            // 16-byte Folded Reload
	mov	w14, #255
	ldr	x23, [sp, #624]
	ldr	x19, [sp, #656]
	ldr	x27, [sp, #352]                 // 8-byte Folded Reload
	ldr	x28, [sp, #320]                 // 8-byte Folded Reload
	ldr	w9, [sp, #424]                  // 4-byte Folded Reload
	ldr	w11, [sp, #400]                 // 4-byte Folded Reload
	ldr	w12, [sp, #384]                 // 4-byte Folded Reload
	ldr	x13, [sp, #368]                 // 8-byte Folded Reload
.LBB102_576:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_588 Depth 2
                                        //     Child Loop BB102_582 Depth 2
                                        //     Child Loop BB102_585 Depth 2
	mul	w8, w9, w27
	cmp	w27, #3
	mul	w8, w8, w12
	add	x0, x24, x8
	b.lt	.LBB102_579
// %bb.577:                             //   in Loop: Header=BB102_576 Depth=1
	ldr	w8, [x19, #8]
	cmp	w8, #3
	b.ne	.LBB102_583
// %bb.578:                             //   in Loop: Header=BB102_576 Depth=1
	ldr	x8, [sp, #18944]
	mov	x1, x23
	ldr	x2, [sp, #632]
	mov	w5, w27
	ldr	x3, [sp, #640]
	mov	x26, x22
	ldr	w4, [x19]
	mov	w19, w11
	mov	w22, w12
	blr	x8
	ldr	x13, [sp, #368]                 // 8-byte Folded Reload
	mov	w12, w22
	mov	x22, x26
	ldr	x26, [sp, #344]                 // 8-byte Folded Reload
	mov	w11, w19
	ldr	x19, [sp, #656]
	mov	w14, #255
	b	.LBB102_589
.LBB102_579:                            //   in Loop: Header=BB102_576 Depth=1
	ldr	w8, [x19]
	cmp	w27, #1
	b.ne	.LBB102_586
// %bb.580:                             //   in Loop: Header=BB102_576 Depth=1
	cbz	w8, .LBB102_589
// %bb.581:                             //   in Loop: Header=BB102_576 Depth=1
	mul	w9, w9, w11
	mov	x8, xzr
	add	x9, x24, x9
.LBB102_582:                            //   Parent Loop BB102_576 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w10, [x23, x8]
	strb	w10, [x9, x8]
	add	x8, x8, #1
	ldr	w10, [x19]
	cmp	x8, x10
	b.lo	.LBB102_582
	b	.LBB102_589
.LBB102_583:                            //   in Loop: Header=BB102_576 Depth=1
	ldr	w8, [x19]
	cbz	w8, .LBB102_589
// %bb.584:                             //   in Loop: Header=BB102_576 Depth=1
	ldr	x10, [sp, #296]                 // 8-byte Folded Reload
	mul	w9, w9, w11
	mov	x8, xzr
	add	x9, x10, x9
.LBB102_585:                            //   Parent Loop BB102_576 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w10, [x23, x8]
	strb	w14, [x9]
	add	x8, x8, #1
	sturb	w10, [x9, #-1]
	sturb	w10, [x9, #-2]
	sturb	w10, [x9, #-3]
	add	x9, x9, x13
	ldr	w10, [x19]
	cmp	x8, x10
	b.lo	.LBB102_585
	b	.LBB102_589
.LBB102_586:                            //   in Loop: Header=BB102_576 Depth=1
	cbz	w8, .LBB102_589
// %bb.587:                             //   in Loop: Header=BB102_576 Depth=1
	mov	x8, xzr
.LBB102_588:                            //   Parent Loop BB102_576 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w9, [x23, x8]
	strb	w14, [x0, #1]
	add	x8, x8, #1
	strb	w9, [x0], #2
	ldr	w9, [x19]
	cmp	x8, x9
	b.lo	.LBB102_588
.LBB102_589:                            //   in Loop: Header=BB102_576 Depth=1
	ldr	w8, [x19, #4]
	add	w12, w12, #1
	cmp	w12, w8
	b.lo	.LBB102_569
// %bb.590:
	ldr	w28, [x19, #8]
.LBB102_591:
	cmp	w28, #1
	b.lt	.LBB102_600
// %bb.592:
	mov	w8, #17904
	add	x9, sp, #656
	mov	x20, xzr
	add	x21, x9, x8
	b	.LBB102_594
.LBB102_593:                            //   in Loop: Header=BB102_594 Depth=1
	ldr	x19, [sp, #656]
	add	x20, x20, #1
	add	x21, x21, #96
	ldrsw	x8, [x19, #8]
	cmp	x20, x8
	b.ge	.LBB102_600
.LBB102_594:                            // =>This Inner Loop Header: Depth=1
	ldur	x0, [x21, #-24]
	cbz	x0, .LBB102_596
// %bb.595:                             //   in Loop: Header=BB102_594 Depth=1
	bl	free
	stp	xzr, xzr, [x21, #-32]
.LBB102_596:                            //   in Loop: Header=BB102_594 Depth=1
	ldur	x0, [x21, #-16]
	cbz	x0, .LBB102_598
// %bb.597:                             //   in Loop: Header=BB102_594 Depth=1
	bl	free
	stur	xzr, [x21, #-16]
	str	xzr, [x21]
.LBB102_598:                            //   in Loop: Header=BB102_594 Depth=1
	ldur	x0, [x21, #-8]
	cbz	x0, .LBB102_593
// %bb.599:                             //   in Loop: Header=BB102_594 Depth=1
	bl	free
	stur	xzr, [x21, #-8]
	b	.LBB102_593
.LBB102_600:
	ldr	w8, [x19]
	ldr	x9, [sp, #312]                  // 8-byte Folded Reload
	str	w8, [x9]
	ldr	w8, [x19, #4]
	str	w8, [x22]
	cbz	x26, .LBB102_791
// %bb.601:
	ldr	w8, [x19, #8]
	str	w8, [x26]
	b	.LBB102_791
.LBB102_602:
	mov	w8, wzr
	add	x9, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_603:
	str	x9, [x25]
.LBB102_604:
	ldr	x9, [x23, #200]
	cmp	w8, #97
	str	x9, [x23, #184]
	b.ne	.LBB102_540
// %bb.605:
	add	x0, sp, #656
	mov	w1, wzr
	mov	w2, #18520
	bl	memset
	add	x1, sp, #656
	mov	x0, x23
	mov	x2, x27
	mov	w3, wzr
	bl	_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii
	cbz	w0, .LBB102_686
// %bb.606:
	ldr	w27, [sp, #656]
	ldr	w8, [sp, #660]
	str	w8, [sp, #368]                  // 4-byte Folded Spill
	mul	w8, w27, w8
	lsl	w24, w8, #2
	sxtw	x0, w24
	bl	malloc
	str	x0, [sp, #664]
	cbz	x0, .LBB102_774
// %bb.607:
	mov	w8, #18480
	cmp	w24, #1
	add	x8, x19, x8
	str	w27, [sp, #352]                 // 4-byte Folded Spill
	str	x8, [sp, #344]                  // 8-byte Folded Spill
	b.lt	.LBB102_614
// %bb.608:
	ldrsw	x8, [sp, #676]
	add	x9, sp, #656
	cmp	w24, #5
	add	x8, x9, x8, lsl #2
	add	x9, x8, #36
	ldrb	w12, [x8, #38]!
	mov	x10, x8
	mov	x11, x8
	ldrb	w14, [x9]
	strb	w12, [x0]
	ldrb	w15, [x10, #-1]!
	ldrb	w13, [x11, #1]!
	strb	w14, [x0, #2]
	strb	w15, [x0, #1]
	strb	w13, [x0, #3]
	b.lo	.LBB102_614
// %bb.609:
	cmp	w24, #9
	strb	w12, [x0, #4]
	strb	w15, [x0, #5]
	strb	w14, [x0, #6]
	strb	w13, [x0, #7]
	b.lo	.LBB102_614
// %bb.610:
	ldr	w15, [sp, #656]
	strb	w12, [x0, #8]
	ldr	w16, [sp, #660]
	ldrb	w13, [x10]
	str	w15, [sp, #352]                 // 4-byte Folded Spill
	ldrb	w14, [x9]
	mul	w15, w15, w16
	ldrb	w12, [x11]
	strb	w13, [x0, #9]
	lsl	w13, w15, #2
	str	w16, [sp, #368]                 // 4-byte Folded Spill
	cmp	w13, #13
	strb	w14, [x0, #10]
	strb	w12, [x0, #11]
	b.lt	.LBB102_614
// %bb.611:
	mov	x12, xzr
.LBB102_612:                            // =>This Inner Loop Header: Depth=1
	ldr	x13, [sp, #664]
	add	x15, x12, #16
	ldrb	w14, [x8]
	add	x13, x13, x12
	strb	w14, [x13, #12]
	ldrb	w14, [x10]
	strb	w14, [x13, #13]
	ldrb	w14, [x9]
	strb	w14, [x13, #14]
	ldrb	w14, [x11]
	strb	w14, [x13, #15]
	add	x14, x12, #4
	ldr	w16, [sp, #656]
	mov	x12, x14
	ldr	w17, [sp, #660]
	mul	w13, w16, w17
	lsl	w13, w13, #2
	cmp	x15, w13, sxtw
	b.lt	.LBB102_612
// %bb.613:
	str	w17, [sp, #368]                 // 4-byte Folded Spill
	str	w16, [sp, #352]                 // 4-byte Folded Spill
.LBB102_614:
	str	w26, [sp, #28]                  // 4-byte Folded Spill
	add	x26, x23, #48
	str	x22, [sp, #312]                 // 8-byte Folded Spill
	add	x24, x23, #16
	str	x21, [sp, #336]                 // 8-byte Folded Spill
	add	x19, x23, #40
	add	x21, x23, #56
	add	x27, x23, #52
	add	x22, x23, #57
	b	.LBB102_616
.LBB102_615:                            //   in Loop: Header=BB102_616 Depth=1
	add	x8, x9, w10, uxtw
	str	x8, [x28]
.LBB102_616:                            // =>This Inner Loop Header: Depth=1
	ldr	x10, [x28]
	ldr	x8, [x25]
	cmp	x10, x8
	b.hs	.LBB102_618
// %bb.617:                             //   in Loop: Header=BB102_616 Depth=1
	add	x9, x10, #1
	str	x9, [x28]
	ldrb	w10, [x10]
	b	.LBB102_623
.LBB102_618:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w8, [x26]
	cbz	w8, .LBB102_775
// %bb.619:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_621
// %bb.620:                             //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_622
.LBB102_621:                            //   in Loop: Header=BB102_616 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_622:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_623:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	w10, #33
	b.ne	.LBB102_687
// %bb.624:                             //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_626
// %bb.625:                             //   in Loop: Header=BB102_616 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_631
.LBB102_626:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w10, [x26]
	cbz	w10, .LBB102_675
// %bb.627:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_629
// %bb.628:                             //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_630
.LBB102_629:                            //   in Loop: Header=BB102_616 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_630:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_631:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	w10, #249
	b.ne	.LBB102_675
// %bb.632:                             //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_634
// %bb.633:                             //   in Loop: Header=BB102_616 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_639
.LBB102_634:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w10, [x26]
	cbz	w10, .LBB102_642
// %bb.635:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_637
// %bb.636:                             //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_638
.LBB102_637:                            //   in Loop: Header=BB102_616 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_638:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_639:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	w10, #4
	b.ne	.LBB102_642
// %bb.640:                             //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_645
// %bb.641:                             //   in Loop: Header=BB102_616 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_650
.LBB102_642:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	x11, [x24]
	cbz	x11, .LBB102_615
// %bb.643:                             //   in Loop: Header=BB102_616 Depth=1
	sub	w11, w8, w9
	subs	w1, w10, w11
	b.le	.LBB102_615
// %bb.644:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x9, [x23, #24]
	str	x8, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x9
	b	.LBB102_616
.LBB102_645:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w10, [x26]
	cbz	w10, .LBB102_650
// %bb.646:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_648
// %bb.647:                             //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_649
.LBB102_648:                            //   in Loop: Header=BB102_616 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_649:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_650:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	str	w10, [sp, #688]
	b.hs	.LBB102_652
// %bb.651:                             //   in Loop: Header=BB102_616 Depth=1
	add	x9, x9, #1
	b	.LBB102_657
.LBB102_652:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w10, [x26]
	cbz	w10, .LBB102_658
// %bb.653:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_655
// %bb.654:                             //   in Loop: Header=BB102_616 Depth=1
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_656
.LBB102_655:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_656:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
.LBB102_657:                            //   in Loop: Header=BB102_616 Depth=1
	str	x9, [x28]
.LBB102_658:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_660
// %bb.659:                             //   in Loop: Header=BB102_616 Depth=1
	add	x9, x9, #1
	b	.LBB102_665
.LBB102_660:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w10, [x26]
	cbz	w10, .LBB102_666
// %bb.661:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_663
// %bb.662:                             //   in Loop: Header=BB102_616 Depth=1
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB102_664
.LBB102_663:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_664:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
.LBB102_665:                            //   in Loop: Header=BB102_616 Depth=1
	str	x9, [x28]
.LBB102_666:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_668
// %bb.667:                             //   in Loop: Header=BB102_616 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_673
.LBB102_668:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w10, [x26]
	cbz	w10, .LBB102_673
// %bb.669:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_671
// %bb.670:                             //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_672
.LBB102_671:                            //   in Loop: Header=BB102_616 Depth=1
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_672:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_673:                            //   in Loop: Header=BB102_616 Depth=1
	str	w10, [sp, #684]
	cmp	x9, x8
	b.lo	.LBB102_676
	b	.LBB102_677
.LBB102_674:                            //   in Loop: Header=BB102_616 Depth=1
	add	x9, x10, w9, uxtw
	str	x9, [x28]
.LBB102_675:                            //   in Loop: Header=BB102_616 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_677
.LBB102_676:                            //   in Loop: Header=BB102_616 Depth=1
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	b	.LBB102_682
.LBB102_677:                            //   in Loop: Header=BB102_616 Depth=1
	ldr	w8, [x26]
	cbz	w8, .LBB102_616
// %bb.678:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_680
// %bb.679:                             //   in Loop: Header=BB102_616 Depth=1
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_681
.LBB102_680:                            //   in Loop: Header=BB102_616 Depth=1
	mov	w9, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x21]
.LBB102_681:                            //   in Loop: Header=BB102_616 Depth=1
	mov	x10, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_682:                            //   in Loop: Header=BB102_616 Depth=1
	cbz	w9, .LBB102_616
// %bb.683:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x11, [x24]
	cbz	x11, .LBB102_674
// %bb.684:                             //   in Loop: Header=BB102_616 Depth=1
	sub	w11, w8, w10
	subs	w1, w9, w11
	b.le	.LBB102_674
// %bb.685:                             //   in Loop: Header=BB102_616 Depth=1
	ldr	x9, [x23, #24]
	str	x8, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x9
	ldp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB102_677
	b	.LBB102_676
.LBB102_686:
	mov	x0, xzr
	b	.LBB102_1086
.LBB102_687:
	cmp	w10, #59
	b.eq	.LBB102_792
// %bb.688:
	cmp	w10, #44
	b.ne	.LBB102_775
// %bb.689:
	cmp	x9, x8
	str	x19, [sp, #400]                 // 8-byte Folded Spill
	str	x21, [sp, #424]                 // 8-byte Folded Spill
	str	x27, [sp, #384]                 // 8-byte Folded Spill
	b.hs	.LBB102_793
// %bb.690:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	str	w9, [sp, #304]                  // 4-byte Folded Spill
	mov	x9, x10
	b	.LBB102_1013
.LBB102_691:
	cmp	w28, #1
	b.lt	.LBB102_700
// %bb.692:
	mov	w8, #17904
	add	x9, sp, #656
	mov	x19, xzr
	add	x20, x9, x8
	b	.LBB102_694
.LBB102_693:                            //   in Loop: Header=BB102_694 Depth=1
	ldr	x8, [sp, #656]
	add	x19, x19, #1
	add	x20, x20, #96
	ldrsw	x8, [x8, #8]
	cmp	x19, x8
	b.ge	.LBB102_700
.LBB102_694:                            // =>This Inner Loop Header: Depth=1
	ldur	x0, [x20, #-24]
	cbz	x0, .LBB102_696
// %bb.695:                             //   in Loop: Header=BB102_694 Depth=1
	bl	free
	stp	xzr, xzr, [x20, #-32]
.LBB102_696:                            //   in Loop: Header=BB102_694 Depth=1
	ldur	x0, [x20, #-16]
	cbz	x0, .LBB102_698
// %bb.697:                             //   in Loop: Header=BB102_694 Depth=1
	bl	free
	stur	xzr, [x20, #-16]
	str	xzr, [x20]
.LBB102_698:                            //   in Loop: Header=BB102_694 Depth=1
	ldur	x0, [x20, #-8]
	cbz	x0, .LBB102_693
// %bb.699:                             //   in Loop: Header=BB102_694 Depth=1
	bl	free
	stur	xzr, [x20, #-8]
	b	.LBB102_693
.LBB102_700:
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	mov	x24, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB102_791
.LBB102_701:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_702:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_703:
	cmp	x9, x8
	b.hs	.LBB102_705
// %bb.704:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_710
.LBB102_705:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_710
// %bb.706:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_708
// %bb.707:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_709
.LBB102_708:
	mov	w10, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_709:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_710:
	bfi	w19, w10, #8, #8
	cmp	x9, x8
	str	w19, [x23]
	b.hs	.LBB102_712
// %bb.711:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	b	.LBB102_718
.LBB102_712:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_715
// %bb.713:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_716
// %bb.714:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_717
.LBB102_715:
	mov	w19, wzr
	b	.LBB102_718
.LBB102_716:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_717:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_718:
	cmp	x9, x8
	b.hs	.LBB102_720
// %bb.719:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_725
.LBB102_720:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_725
// %bb.721:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_723
// %bb.722:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_724
.LBB102_723:
	mov	w10, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_724:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_725:
	bfi	w19, w10, #8, #8
	str	w19, [x23, #4]
.LBB102_726:
	cmp	x9, x8
	b.hs	.LBB102_728
// %bb.727:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	b	.LBB102_734
.LBB102_728:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_731
// %bb.729:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_732
// %bb.730:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_733
.LBB102_731:
	mov	w19, wzr
	b	.LBB102_734
.LBB102_732:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_733:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_734:
	cmp	x9, x8
	b.hs	.LBB102_736
// %bb.735:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_741
.LBB102_736:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_741
// %bb.737:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_739
// %bb.738:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_740
.LBB102_739:
	mov	w10, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_740:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_741:
	bfi	w19, w10, #8, #8
	cmp	w19, #1
	b.ne	.LBB102_1006
// %bb.742:
	cmp	x9, x8
	b.hs	.LBB102_744
// %bb.743:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	b	.LBB102_750
.LBB102_744:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_747
// %bb.745:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_748
// %bb.746:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_749
.LBB102_747:
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	mov	w19, wzr
	b	.LBB102_750
.LBB102_748:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_749:
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB102_750:
	cmp	x9, x8
	b.hs	.LBB102_752
// %bb.751:
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
	b	.LBB102_757
.LBB102_752:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_757
// %bb.753:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB102_755
// %bb.754:
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_756
.LBB102_755:
	mov	w8, wzr
	add	x9, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_756:
	add	x10, x23, #57
	stp	x10, x9, [x23, #184]
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
.LBB102_757:
	bfi	w19, w8, #8, #8
	cmp	w19, #1
	str	w19, [sp, #304]                 // 4-byte Folded Spill
	b.ne	.LBB102_759
// %bb.758:
	adrp	x8, .L.str.72
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.72
	b	.LBB102_19
.LBB102_759:
	ldr	w8, [x23, #4]
	str	w24, [sp, #352]                 // 4-byte Folded Spill
	cmp	w8, #0
	str	w8, [sp, #4]                    // 4-byte Folded Spill
	cneg	w8, w8, mi
	cmp	w10, #12
	str	w8, [x23, #4]
	b.ne	.LBB102_762
// %bb.760:
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	cmp	w8, #23
	b.hi	.LBB102_764
// %bb.761:
	mov	w9, #21846
	sub	w8, w24, #38
	movk	w9, #21845, lsl #16
	mov	w19, wzr
	str	wzr, [sp, #288]                 // 4-byte Folded Spill
	smull	x8, w8, w9
	str	wzr, [sp, #280]                 // 4-byte Folded Spill
	str	wzr, [sp, #272]                 // 4-byte Folded Spill
	lsr	x9, x8, #63
	lsr	x8, x8, #32
	add	w8, w8, w9
	b	.LBB102_799
.LBB102_762:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	sub	w8, w0, #1
	cmp	w8, #1
	b.hi	.LBB102_765
// %bb.763:
	adrp	x8, .L.str.73
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.73
	b	.LBB102_19
.LBB102_764:
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	mov	w19, wzr
	str	wzr, [sp, #288]                 // 4-byte Folded Spill
	str	wzr, [sp, #280]                 // 4-byte Folded Spill
	str	wzr, [sp, #272]                 // 4-byte Folded Spill
	b	.LBB102_800
.LBB102_765:
	mov	w24, w0
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	and	w8, w10, #0xffffffef
	cmp	w8, #108
	b.eq	.LBB102_777
// %bb.766:
	cmp	w8, #40
	b.ne	.LBB102_1169
// %bb.767:
	cmp	w10, #56
	b.ne	.LBB102_769
// %bb.768:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
.LBB102_769:
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	cmp	w8, #32
	b.eq	.LBB102_771
// %bb.770:
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	cmp	w8, #16
	b.ne	.LBB102_796
.LBB102_771:
	cmp	w24, #3
	b.eq	.LBB102_1004
// %bb.772:
	cbnz	w24, .LBB102_1006
// %bb.773:
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	mov	w9, #31
	mov	w10, #255
	mov	w11, #16711680
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	cmp	w8, #32
	mov	w8, #-16777216
	csel	w19, w8, wzr, eq
	csel	w8, w10, w9, eq
	mov	w9, #65280
	mov	w10, #31744
	str	w8, [sp, #288]                  // 4-byte Folded Spill
	mov	w8, #992
	csel	w8, w9, w8, eq
	str	w8, [sp, #280]                  // 4-byte Folded Spill
	csel	w8, w11, w10, eq
	str	w8, [sp, #272]                  // 4-byte Folded Spill
	b	.LBB102_800
.LBB102_774:
	adrp	x8, .L.str.28
	add	x8, x8, :lo12:.L.str.28
	str	x8, [x20, :lo12:.L_MergedGlobals.126+8]
	b	.LBB102_1086
.LBB102_775:
	adrp	x8, .L.str.80
	mov	x0, xzr
	add	x8, x8, :lo12:.L.str.80
	b	.LBB102_1084
.LBB102_776:
	adrp	x10, .L.str.30
	add	x10, x10, :lo12:.L.str.30
	b	.LBB102_780
.LBB102_777:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	str	w0, [sp, #272]                  // 4-byte Folded Spill
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	str	w0, [sp, #280]                  // 4-byte Folded Spill
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	str	w0, [sp, #288]                  // 4-byte Folded Spill
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	w19, w0
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	cmp	w10, #124
	b.ne	.LBB102_797
// %bb.778:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	b	.LBB102_797
.LBB102_779:
	adrp	x10, .L.str.36
	add	x10, x10, :lo12:.L.str.36
.LBB102_780:
	adrp	x8, .L_MergedGlobals.126+8
	str	x10, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB102_781:
	ldr	x8, [sp, #656]
	ldr	w8, [x8, #8]
	cmp	w8, #1
	b.lt	.LBB102_790
// %bb.782:
	mov	w8, #17904
	add	x9, sp, #656
	mov	x19, xzr
	add	x20, x9, x8
	b	.LBB102_784
.LBB102_783:                            //   in Loop: Header=BB102_784 Depth=1
	ldr	x8, [sp, #656]
	add	x19, x19, #1
	add	x20, x20, #96
	ldrsw	x8, [x8, #8]
	cmp	x19, x8
	b.ge	.LBB102_790
.LBB102_784:                            // =>This Inner Loop Header: Depth=1
	ldur	x0, [x20, #-24]
	cbz	x0, .LBB102_786
// %bb.785:                             //   in Loop: Header=BB102_784 Depth=1
	bl	free
	stp	xzr, xzr, [x20, #-32]
.LBB102_786:                            //   in Loop: Header=BB102_784 Depth=1
	ldur	x0, [x20, #-16]
	cbz	x0, .LBB102_788
// %bb.787:                             //   in Loop: Header=BB102_784 Depth=1
	bl	free
	stur	xzr, [x20, #-16]
	str	xzr, [x20]
.LBB102_788:                            //   in Loop: Header=BB102_784 Depth=1
	ldur	x0, [x20, #-8]
	cbz	x0, .LBB102_783
// %bb.789:                             //   in Loop: Header=BB102_784 Depth=1
	bl	free
	stur	xzr, [x20, #-8]
	b	.LBB102_783
.LBB102_790:
	mov	x24, xzr
.LBB102_791:
	mov	x0, x24
	add	sp, sp, #4, lsl #12             // =16384
	add	sp, sp, #2800
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB102_792:
	mov	x0, x23
	b	.LBB102_1085
.LBB102_793:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1010
// %bb.794:
	ldr	x8, [x24]
	mov	x1, x21
	ldr	x0, [x19]
	ldr	w2, [x27]
	blr	x8
	cbz	w0, .LBB102_1011
// %bb.795:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	str	w9, [sp, #304]                  // 4-byte Folded Spill
	b	.LBB102_1012
.LBB102_796:
	mov	w19, wzr
	str	wzr, [sp, #288]                 // 4-byte Folded Spill
	str	wzr, [sp, #280]                 // 4-byte Folded Spill
	str	wzr, [sp, #272]                 // 4-byte Folded Spill
.LBB102_797:
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	ldr	w9, [sp, #352]                  // 4-byte Folded Reload
	cmp	w8, #15
	b.hi	.LBB102_845
// %bb.798:
	sub	w8, w9, w10
	sub	w8, w8, #14
	asr	w8, w8, #2
.LBB102_799:
	str	w8, [sp, #320]                  // 4-byte Folded Spill
.LBB102_800:
	cmp	w19, #0
	mov	w8, #3
	ldp	w9, w10, [x23]
	cinc	w8, w8, ne
	cmp	w26, #2
	csel	w11, w26, w8, gt
	str	w19, [sp, #264]                 // 4-byte Folded Spill
	mul	w9, w9, w11
	str	w8, [x23, #8]
	str	w11, [sp, #424]                 // 4-byte Folded Spill
	mul	w0, w9, w10
	bl	malloc
	mov	x24, x0
	cbz	x0, .LBB102_837
// %bb.801:
	ldr	w19, [sp, #304]                 // 4-byte Folded Reload
	cmp	w19, #15
	b.hi	.LBB102_838
// %bb.802:
	ldr	w8, [sp, #320]                  // 4-byte Folded Reload
	cbz	w8, .LBB102_842
// %bb.803:
	cmp	w8, #256
	b.gt	.LBB102_842
// %bb.804:
	cmp	w8, #1
	str	w26, [sp, #28]                  // 4-byte Folded Spill
	b.lt	.LBB102_843
// %bb.805:
	add	x8, x23, #56
	add	x10, sp, #656
	orr	x26, x10, #0x3
	str	x8, [sp, #384]                  // 8-byte Folded Spill
	add	x8, x23, #57
	str	x8, [sp, #368]                  // 8-byte Folded Spill
	ldr	w8, [sp, #320]                  // 4-byte Folded Reload
	mov	w19, w8
	ldp	x9, x8, [x23, #184]
	b	.LBB102_809
.LBB102_806:                            //   in Loop: Header=BB102_809 Depth=1
	add	x9, x9, #1
.LBB102_807:                            //   in Loop: Header=BB102_809 Depth=1
	str	x9, [x28]
.LBB102_808:                            //   in Loop: Header=BB102_809 Depth=1
	subs	x19, x19, #1
	mov	w10, #255
	strb	w10, [x26], #4
	b.eq	.LBB102_843
.LBB102_809:                            // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB102_811
// %bb.810:                             //   in Loop: Header=BB102_809 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_816
.LBB102_811:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_816
// %bb.812:                             //   in Loop: Header=BB102_809 Depth=1
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #384]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_814
// %bb.813:                             //   in Loop: Header=BB102_809 Depth=1
	mov	x8, x23
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_815
.LBB102_814:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	mov	w10, wzr
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	mov	x8, x11
.LBB102_815:                            //   in Loop: Header=BB102_809 Depth=1
	mov	x9, x11
	str	x8, [x25]
	str	x11, [x28]
.LBB102_816:                            //   in Loop: Header=BB102_809 Depth=1
	cmp	x9, x8
	sturb	w10, [x26, #-1]
	b.hs	.LBB102_818
// %bb.817:                             //   in Loop: Header=BB102_809 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_823
.LBB102_818:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_823
// %bb.819:                             //   in Loop: Header=BB102_809 Depth=1
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #384]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_821
// %bb.820:                             //   in Loop: Header=BB102_809 Depth=1
	mov	x8, x23
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_822
.LBB102_821:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	mov	w10, wzr
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	mov	x8, x11
.LBB102_822:                            //   in Loop: Header=BB102_809 Depth=1
	mov	x9, x11
	str	x8, [x25]
	str	x11, [x28]
.LBB102_823:                            //   in Loop: Header=BB102_809 Depth=1
	cmp	x9, x8
	sturb	w10, [x26, #-2]
	b.hs	.LBB102_825
// %bb.824:                             //   in Loop: Header=BB102_809 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_830
.LBB102_825:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_830
// %bb.826:                             //   in Loop: Header=BB102_809 Depth=1
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #384]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_828
// %bb.827:                             //   in Loop: Header=BB102_809 Depth=1
	mov	x8, x23
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_829
.LBB102_828:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	mov	w10, wzr
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	mov	x8, x11
.LBB102_829:                            //   in Loop: Header=BB102_809 Depth=1
	mov	x9, x11
	str	x8, [x25]
	str	x11, [x28]
.LBB102_830:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	w11, [sp, #400]                 // 4-byte Folded Reload
	sturb	w10, [x26, #-3]
	cmp	w11, #12
	b.eq	.LBB102_808
// %bb.831:                             //   in Loop: Header=BB102_809 Depth=1
	cmp	x9, x8
	b.lo	.LBB102_806
// %bb.832:                             //   in Loop: Header=BB102_809 Depth=1
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_808
// %bb.833:                             //   in Loop: Header=BB102_809 Depth=1
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #384]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_835
// %bb.834:                             //   in Loop: Header=BB102_809 Depth=1
	add	x8, x23, w0, sxtw
	ldr	x9, [sp, #368]                  // 8-byte Folded Reload
	add	x8, x8, #56
	b	.LBB102_836
.LBB102_835:                            //   in Loop: Header=BB102_809 Depth=1
	ldr	x9, [sp, #368]                  // 8-byte Folded Reload
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	mov	x8, x9
.LBB102_836:                            //   in Loop: Header=BB102_809 Depth=1
	str	x8, [x25]
	b	.LBB102_807
.LBB102_837:
	adrp	x8, .L.str.28
	add	x8, x8, :lo12:.L.str.28
	b	.LBB102_19
.LBB102_838:
	ldr	w8, [sp, #352]                  // 4-byte Folded Reload
	mov	x0, x23
	ldr	w9, [sp, #400]                  // 4-byte Folded Reload
	sub	w8, w8, w9
	sub	w1, w8, #14
	bl	_ZL10stbi__skipP13stbi__contexti
	cmp	w19, #32
	b.eq	.LBB102_846
// %bb.839:
	cmp	w19, #24
	b.eq	.LBB102_857
// %bb.840:
	cmp	w19, #16
	b.ne	.LBB102_851
// %bb.841:
	ldr	w8, [x23]
	neg	w8, w8, lsl #1
	and	w8, w8, #0x2
	str	w8, [sp, #16]                   // 4-byte Folded Spill
	b	.LBB102_852
.LBB102_842:
	mov	x0, x24
	bl	free
	adrp	x8, .L.str.75
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.75
	b	.LBB102_19
.LBB102_843:
	ldr	w10, [sp, #400]                 // 4-byte Folded Reload
	mov	w8, #-4
	ldr	w9, [sp, #352]                  // 4-byte Folded Reload
	mov	x0, x23
	cmp	w10, #12
	sub	w9, w9, w10
	ldr	w10, [sp, #320]                 // 4-byte Folded Reload
	cinc	w8, w8, eq
	madd	w8, w10, w8, w9
	sub	w1, w8, #14
	bl	_ZL10stbi__skipP13stbi__contexti
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	str	x21, [sp, #336]                 // 8-byte Folded Spill
	str	x22, [sp, #312]                 // 8-byte Folded Spill
	cmp	w8, #4
	b.ne	.LBB102_943
// %bb.844:
	ldr	w8, [x23]
	add	w9, w8, #1
	lsr	w9, w9, #1
	b	.LBB102_945
.LBB102_845:
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	b	.LBB102_800
.LBB102_846:
	ldr	w9, [sp, #264]                  // 4-byte Folded Reload
	mov	w8, #-16777216
	cmp	w9, w8
	b.ne	.LBB102_851
// %bb.847:
	ldr	w8, [sp, #288]                  // 4-byte Folded Reload
	cmp	w8, #255
	b.ne	.LBB102_851
// %bb.848:
	ldr	w9, [sp, #280]                  // 4-byte Folded Reload
	mov	w8, #65280
	cmp	w9, w8
	b.ne	.LBB102_851
// %bb.849:
	ldr	w8, [sp, #272]                  // 4-byte Folded Reload
	cmp	w8, #4080, lsl #12              // =16711680
	b.ne	.LBB102_851
// %bb.850:
	mov	w8, #1
	str	xzr, [sp, #16]                  // 8-byte Folded Spill
	str	wzr, [sp, #256]                 // 4-byte Folded Spill
	str	wzr, [sp, #240]                 // 4-byte Folded Spill
	str	xzr, [sp, #232]                 // 8-byte Folded Spill
	stp	wzr, wzr, [sp, #204]            // 8-byte Folded Spill
	str	wzr, [sp, #248]                 // 4-byte Folded Spill
	stp	w8, wzr, [sp, #224]             // 8-byte Folded Spill
	b	.LBB102_858
.LBB102_851:
	str	wzr, [sp, #16]                  // 4-byte Folded Spill
.LBB102_852:
	ldr	w8, [sp, #288]                  // 4-byte Folded Reload
	cbz	w8, .LBB102_856
// %bb.853:
	ldr	w8, [sp, #280]                  // 4-byte Folded Reload
	cbz	w8, .LBB102_856
// %bb.854:
	ldr	w8, [sp, #272]                  // 4-byte Folded Reload
	cbz	w8, .LBB102_856
// %bb.855:
	ldr	w19, [sp, #272]                 // 4-byte Folded Reload
	mov	w0, w19
	bl	_ZL14stbi__high_bitj
	sub	w8, w0, #7
	mov	w0, w19
	str	w8, [sp, #256]                  // 4-byte Folded Spill
	bl	_ZL14stbi__bitcountj
	ldr	w19, [sp, #280]                 // 4-byte Folded Reload
	str	w0, [sp, #248]                  // 4-byte Folded Spill
	mov	w0, w19
	bl	_ZL14stbi__high_bitj
	sub	w8, w0, #7
	mov	w0, w19
	str	w8, [sp, #240]                  // 4-byte Folded Spill
	bl	_ZL14stbi__bitcountj
	ldr	w19, [sp, #288]                 // 4-byte Folded Reload
	str	w0, [sp, #236]                  // 4-byte Folded Spill
	mov	w0, w19
	bl	_ZL14stbi__high_bitj
	sub	w8, w0, #7
	mov	w0, w19
	str	w8, [sp, #232]                  // 4-byte Folded Spill
	bl	_ZL14stbi__bitcountj
	ldr	w19, [sp, #264]                 // 4-byte Folded Reload
	str	w0, [sp, #228]                  // 4-byte Folded Spill
	mov	w0, w19
	bl	_ZL14stbi__high_bitj
	sub	w8, w0, #7
	mov	w0, w19
	str	w8, [sp, #208]                  // 4-byte Folded Spill
	bl	_ZL14stbi__bitcountj
	mov	w8, #1
	str	w0, [sp, #204]                  // 4-byte Folded Spill
	str	wzr, [sp, #224]                 // 4-byte Folded Spill
	str	w8, [sp, #20]                   // 4-byte Folded Spill
	b	.LBB102_858
.LBB102_856:
	mov	x0, x24
	bl	free
	adrp	x8, .L.str.77
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.77
	b	.LBB102_19
.LBB102_857:
	ldr	w8, [x23]
	stp	xzr, xzr, [sp, #224]            // 16-byte Folded Spill
	str	wzr, [sp, #256]                 // 4-byte Folded Spill
	str	wzr, [sp, #240]                 // 4-byte Folded Spill
	and	w8, w8, #0x3
	stp	wzr, wzr, [sp, #204]            // 8-byte Folded Spill
	str	wzr, [sp, #248]                 // 4-byte Folded Spill
	stp	w8, wzr, [sp, #16]              // 8-byte Folded Spill
.LBB102_858:
	ldr	w4, [x23, #4]
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	cmp	w4, #1
	b.lt	.LBB102_979
// %bb.859:
	ldr	w2, [sp, #204]                  // 4-byte Folded Reload
	mov	w11, #8
	ldr	w1, [sp, #228]                  // 4-byte Folded Reload
	add	x17, x23, #56
	ldr	w0, [sp, #236]                  // 4-byte Folded Reload
	str	x22, [sp, #312]                 // 8-byte Folded Spill
	lsl	w8, w2, #1
	ldr	w18, [sp, #248]                 // 4-byte Folded Reload
	cmp	w8, #8
	lsl	w10, w1, #1
	csel	w9, w8, w11, hi
	cmp	w2, #4
	cset	w8, lo
	cmp	w10, #8
	csel	w12, w10, w11, hi
	cmp	w1, #4
	lsl	w13, w0, #1
	cset	w10, lo
	cmp	w13, #8
	lsl	w16, w18, #1
	csel	w13, w13, w11, hi
	cmp	w0, #4
	cset	w14, lo
	cmp	w16, #8
	mov	w15, w14
	csel	w11, w16, w11, hi
	bfi	w15, w0, #1, #8
	cmp	w18, #4
	sub	w13, w13, w15
	cset	w15, lo
	mov	w16, w15
	str	x17, [sp, #296]                 // 8-byte Folded Spill
	bfi	w16, w18, #1, #8
	ldr	w17, [sp, #256]                 // 4-byte Folded Reload
	sub	w11, w11, w16
	mov	w16, w10
	bfi	w16, w1, #1, #8
	dup	v1.4s, w18
	sub	w12, w12, w16
	adrp	x16, .LCPI102_0
	neg	w17, w17
	udiv	w13, w13, w0
	dup	v2.4s, w1
	str	x21, [sp, #336]                 // 8-byte Folded Spill
	ldr	q0, [x16, :lo12:.LCPI102_0]
	lsl	w16, w18, #2
	str	w17, [sp, #220]                 // 4-byte Folded Spill
	mov	w17, w8
	bfi	w17, w2, #1, #8
	mov	w22, wzr
	mla	v1.4s, v1.4s, v0.4s
	sub	w9, w9, w17
	dup	v5.4s, w16
	ldr	w16, [sp, #232]                 // 4-byte Folded Reload
	mla	v2.4s, v2.4s, v0.4s
	add	w14, w13, w14
	udiv	w11, w11, w18
	ldr	w18, [sp, #240]                 // 4-byte Folded Reload
	str	q1, [sp, #176]                  // 16-byte Folded Spill
	dup	v1.4s, w0
	neg	w16, w16
	str	q0, [sp, #320]                  // 16-byte Folded Spill
	mla	v1.4s, v1.4s, v0.4s
	neg	w18, w18
	lsl	w17, w0, #2
	lsl	w13, w2, #2
	mov	w19, wzr
	add	x21, x23, #57
	add	w15, w11, w15
	stp	w16, w18, [sp, #212]            // 8-byte Folded Spill
	stp	q2, q1, [sp, #144]              // 32-byte Folded Spill
	dup	v1.4s, w2
	udiv	w12, w12, w1
	ldr	w16, [sp, #208]                 // 4-byte Folded Reload
	mla	v1.4s, v1.4s, v0.4s
	dup	v2.4s, w15
	dup	v0.4s, w14
	lsl	w11, w1, #2
	neg	w16, w16
	dup	v6.4s, w17
	stp	q0, q2, [sp, #96]               // 32-byte Folded Spill
	dup	v16.4s, w13
	dup	v7.4s, w11
	stp	w14, w15, [sp, #136]            // 8-byte Folded Spill
	add	w12, w12, w10
	ldr	w10, [sp, #16]                  // 4-byte Folded Reload
	str	w16, [sp, #200]                 // 4-byte Folded Spill
	udiv	w9, w9, w2
	stp	q6, q5, [sp, #384]              // 32-byte Folded Spill
	dup	v0.4s, w12
	mov	w10, w10
	str	w12, [sp, #132]                 // 4-byte Folded Spill
	stp	q1, q0, [sp, #64]               // 32-byte Folded Spill
	str	x10, [sp, #8]                   // 8-byte Folded Spill
	stp	q16, q7, [sp, #352]             // 32-byte Folded Spill
	add	w8, w9, w8
	dup	v0.4s, w8
	str	w8, [sp, #60]                   // 4-byte Folded Spill
	str	q0, [sp, #32]                   // 16-byte Folded Spill
	b	.LBB102_861
.LBB102_860:                            //   in Loop: Header=BB102_861 Depth=1
	ldr	x8, [x23, #24]
	str	x9, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x8
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	ldr	w4, [x23, #4]
	add	w19, w19, #1
	cmp	w19, w4
	b.ge	.LBB102_942
.LBB102_861:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_906 Depth 2
                                        //     Child Loop BB102_865 Depth 2
                                        //       Child Loop BB102_885 Depth 3
                                        //       Child Loop BB102_889 Depth 3
                                        //       Child Loop BB102_893 Depth 3
                                        //       Child Loop BB102_898 Depth 3
	ldr	w8, [x23]
	str	w19, [sp, #24]                  // 4-byte Folded Spill
	ldr	w9, [sp, #20]                   // 4-byte Folded Reload
	cmp	w8, #1
	tbz	w9, #0, .LBB102_903
// %bb.862:                             //   in Loop: Header=BB102_861 Depth=1
	b.lt	.LBB102_938
// %bb.863:                             //   in Loop: Header=BB102_861 Depth=1
	mov	w19, wzr
	mov	w20, w22
	b	.LBB102_865
.LBB102_864:                            //   in Loop: Header=BB102_865 Depth=2
	ldr	w8, [x23]
	add	w19, w19, #1
	mov	w20, w22
	cmp	w19, w8
	b.ge	.LBB102_938
.LBB102_865:                            //   Parent Loop BB102_861 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB102_885 Depth 3
                                        //       Child Loop BB102_889 Depth 3
                                        //       Child Loop BB102_893 Depth 3
                                        //       Child Loop BB102_898 Depth 3
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	cmp	w8, #16
	b.ne	.LBB102_868
// %bb.866:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	x9, [x28]
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_869
// %bb.867:                             //   in Loop: Header=BB102_865 Depth=2
	add	x10, x9, #1
	mov	w22, w26
	str	x10, [x28]
	ldrb	w26, [x9]
	mov	x9, x10
	b	.LBB102_875
.LBB102_868:                            //   in Loop: Header=BB102_865 Depth=2
	mov	x0, x23
	mov	w22, w26
	bl	_ZL13stbi__get32leP13stbi__context
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	mov	w26, w0
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	b	.LBB102_883
.LBB102_869:                            //   in Loop: Header=BB102_865 Depth=2
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_872
// %bb.870:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	x8, [x23, #16]
	mov	w22, w26
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #296]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_873
// %bb.871:                             //   in Loop: Header=BB102_865 Depth=2
	mov	x8, x23
	ldrb	w26, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_874
.LBB102_872:                            //   in Loop: Header=BB102_865 Depth=2
	mov	w22, w26
	mov	w26, wzr
	b	.LBB102_875
.LBB102_873:                            //   in Loop: Header=BB102_865 Depth=2
	mov	w26, wzr
	mov	x8, x21
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_874:                            //   in Loop: Header=BB102_865 Depth=2
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	mov	x9, x21
	str	x8, [x25]
	str	x21, [x28]
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
.LBB102_875:                            //   in Loop: Header=BB102_865 Depth=2
	cmp	x9, x8
	b.hs	.LBB102_877
// %bb.876:                             //   in Loop: Header=BB102_865 Depth=2
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
	b	.LBB102_882
.LBB102_877:                            //   in Loop: Header=BB102_865 Depth=2
	ldr	w8, [x23, #48]
	cbz	w8, .LBB102_882
// %bb.878:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #296]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_880
// %bb.879:                             //   in Loop: Header=BB102_865 Depth=2
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_881
.LBB102_880:                            //   in Loop: Header=BB102_865 Depth=2
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_881:                            //   in Loop: Header=BB102_865 Depth=2
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	str	x9, [x25]
	str	x21, [x28]
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
.LBB102_882:                            //   in Loop: Header=BB102_865 Depth=2
	bfi	w26, w8, #8, #8
.LBB102_883:                            //   in Loop: Header=BB102_865 Depth=2
	ldr	w8, [sp, #272]                  // 4-byte Folded Reload
	ldr	w9, [sp, #220]                  // 4-byte Folded Reload
	ldr	w10, [sp, #256]                 // 4-byte Folded Reload
	and	w8, w26, w8
	lsl	w9, w8, w9
	asr	w8, w8, w10
	cmp	w10, #0
	csel	w9, w9, w8, lt
	ldr	w8, [sp, #248]                  // 4-byte Folded Reload
	cmp	w8, #7
	b.hi	.LBB102_887
// %bb.884:                             //   in Loop: Header=BB102_865 Depth=2
	movi	v0.2d, #0000000000000000
	ldr	w8, [sp, #140]                  // 4-byte Folded Reload
	mov	w10, #-4
	ldr	q1, [sp, #176]                  // 16-byte Folded Reload
	dup	v2.4s, w9
	add	w8, w8, #4
	mov	v0.s[0], w9
	and	w8, w8, #0xfffffffc
.LBB102_885:                            //   Parent Loop BB102_861 Depth=1
                                        //     Parent Loop BB102_865 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	neg	v3.4s, v1.4s
	add	w9, w10, #4
	add	v1.4s, v1.4s, v5.4s
	add	w11, w10, #8
	mov	w10, w9
	cmp	w11, w8
	sshl	v4.4s, v2.4s, v3.4s
	mov	v3.16b, v0.16b
	add	v0.4s, v4.4s, v0.4s
	b.ne	.LBB102_885
// %bb.886:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	q2, [sp, #320]                  // 16-byte Folded Reload
	dup	v1.4s, w9
	orr	v1.16b, v1.16b, v2.16b
	ldr	q2, [sp, #112]                  // 16-byte Folded Reload
	cmhi	v1.4s, v1.4s, v2.4s
	bit	v0.16b, v3.16b, v1.16b
	addv	s0, v0.4s
	fmov	w9, s0
.LBB102_887:                            //   in Loop: Header=BB102_865 Depth=2
	ldr	w8, [sp, #280]                  // 4-byte Folded Reload
	ldr	w11, [sp, #216]                 // 4-byte Folded Reload
	ldr	w12, [sp, #240]                 // 4-byte Folded Reload
	and	w10, w26, w8
	sxtw	x8, w20
	lsl	w11, w10, w11
	asr	w10, w10, w12
	cmp	w12, #0
	csel	w10, w11, w10, lt
	ldr	w11, [sp, #236]                 // 4-byte Folded Reload
	strb	w9, [x24, x8]
	cmp	w11, #7
	b.hi	.LBB102_891
// %bb.888:                             //   in Loop: Header=BB102_865 Depth=2
	movi	v0.2d, #0000000000000000
	ldr	w9, [sp, #136]                  // 4-byte Folded Reload
	mov	w11, #-4
	ldr	q1, [sp, #160]                  // 16-byte Folded Reload
	dup	v2.4s, w10
	add	w9, w9, #4
	mov	v0.s[0], w10
	and	w9, w9, #0xfffffffc
.LBB102_889:                            //   Parent Loop BB102_861 Depth=1
                                        //     Parent Loop BB102_865 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	neg	v3.4s, v1.4s
	add	w10, w11, #4
	add	v1.4s, v1.4s, v6.4s
	add	w12, w11, #8
	mov	w11, w10
	cmp	w12, w9
	sshl	v4.4s, v2.4s, v3.4s
	mov	v3.16b, v0.16b
	add	v0.4s, v4.4s, v0.4s
	b.ne	.LBB102_889
// %bb.890:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	q2, [sp, #320]                  // 16-byte Folded Reload
	dup	v1.4s, w10
	orr	v1.16b, v1.16b, v2.16b
	ldr	q2, [sp, #96]                   // 16-byte Folded Reload
	cmhi	v1.4s, v1.4s, v2.4s
	bit	v0.16b, v3.16b, v1.16b
	addv	s0, v0.4s
	fmov	w10, s0
.LBB102_891:                            //   in Loop: Header=BB102_865 Depth=2
	ldr	w9, [sp, #288]                  // 4-byte Folded Reload
	add	x12, x8, #1
	ldr	w11, [sp, #212]                 // 4-byte Folded Reload
	ldr	w13, [sp, #232]                 // 4-byte Folded Reload
	and	w9, w26, w9
	strb	w10, [x24, x12]
	lsl	w11, w9, w11
	asr	w9, w9, w13
	cmp	w13, #0
	csel	w11, w11, w9, lt
	ldr	w9, [sp, #228]                  // 4-byte Folded Reload
	cmp	w9, #7
	b.hi	.LBB102_895
// %bb.892:                             //   in Loop: Header=BB102_865 Depth=2
	movi	v0.2d, #0000000000000000
	ldr	w9, [sp, #132]                  // 4-byte Folded Reload
	mov	w10, #-4
	ldr	q1, [sp, #144]                  // 16-byte Folded Reload
	dup	v2.4s, w11
	add	w9, w9, #4
	mov	v0.s[0], w11
	and	w9, w9, #0xfffffffc
.LBB102_893:                            //   Parent Loop BB102_861 Depth=1
                                        //     Parent Loop BB102_865 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	neg	v3.4s, v1.4s
	add	w11, w10, #4
	add	v1.4s, v1.4s, v7.4s
	add	w12, w10, #8
	mov	w10, w11
	cmp	w12, w9
	sshl	v4.4s, v2.4s, v3.4s
	mov	v3.16b, v0.16b
	add	v0.4s, v4.4s, v0.4s
	b.ne	.LBB102_893
// %bb.894:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	q2, [sp, #320]                  // 16-byte Folded Reload
	dup	v1.4s, w11
	orr	v1.16b, v1.16b, v2.16b
	ldr	q2, [sp, #80]                   // 16-byte Folded Reload
	cmhi	v1.4s, v1.4s, v2.4s
	bit	v0.16b, v3.16b, v1.16b
	addv	s0, v0.4s
	fmov	w11, s0
.LBB102_895:                            //   in Loop: Header=BB102_865 Depth=2
	add	x9, x8, #2
	strb	w11, [x24, x9]
	ldr	w9, [sp, #264]                  // 4-byte Folded Reload
	cbz	w9, .LBB102_901
// %bb.896:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	w10, [sp, #200]                 // 4-byte Folded Reload
	and	w9, w26, w9
	ldr	w11, [sp, #208]                 // 4-byte Folded Reload
	mov	w26, w22
	lsl	w10, w9, w10
	asr	w9, w9, w11
	cmp	w11, #0
	csel	w9, w10, w9, lt
	ldr	w10, [sp, #204]                 // 4-byte Folded Reload
	cmp	w10, #7
	b.hi	.LBB102_900
// %bb.897:                             //   in Loop: Header=BB102_865 Depth=2
	movi	v0.2d, #0000000000000000
	ldr	w10, [sp, #60]                  // 4-byte Folded Reload
	mov	w11, #-4
	ldr	q1, [sp, #64]                   // 16-byte Folded Reload
	dup	v2.4s, w9
	add	w10, w10, #4
	mov	v0.s[0], w9
	and	w10, w10, #0xfffffffc
.LBB102_898:                            //   Parent Loop BB102_861 Depth=1
                                        //     Parent Loop BB102_865 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	neg	v3.4s, v1.4s
	add	w9, w11, #4
	add	v1.4s, v1.4s, v16.4s
	add	w12, w11, #8
	mov	w11, w9
	cmp	w12, w10
	sshl	v4.4s, v2.4s, v3.4s
	mov	v3.16b, v0.16b
	add	v0.4s, v4.4s, v0.4s
	b.ne	.LBB102_898
// %bb.899:                             //   in Loop: Header=BB102_865 Depth=2
	ldr	q2, [sp, #320]                  // 16-byte Folded Reload
	dup	v1.4s, w9
	orr	v1.16b, v1.16b, v2.16b
	ldr	q2, [sp, #32]                   // 16-byte Folded Reload
	cmhi	v1.4s, v1.4s, v2.4s
	bit	v0.16b, v3.16b, v1.16b
	addv	s0, v0.4s
	fmov	w9, s0
	add	x22, x8, #3
	cmp	w7, #4
	b.ne	.LBB102_864
	b	.LBB102_902
.LBB102_900:                            //   in Loop: Header=BB102_865 Depth=2
	add	x22, x8, #3
	cmp	w7, #4
	b.ne	.LBB102_864
	b	.LBB102_902
.LBB102_901:                            //   in Loop: Header=BB102_865 Depth=2
	mov	w9, #255
	mov	w26, w22
	add	x22, x8, #3
	cmp	w7, #4
	b.ne	.LBB102_864
.LBB102_902:                            //   in Loop: Header=BB102_865 Depth=2
	add	w8, w20, #4
	strb	w9, [x24, x22]
	mov	w22, w8
	b	.LBB102_864
.LBB102_903:                            //   in Loop: Header=BB102_861 Depth=1
	b.lt	.LBB102_938
// %bb.904:                             //   in Loop: Header=BB102_861 Depth=1
	mov	w19, wzr
	ldr	x9, [x28]
	ldr	x8, [x25]
	mov	w20, w22
	b	.LBB102_906
.LBB102_905:                            //   in Loop: Header=BB102_906 Depth=2
	ldr	w10, [x23]
	add	w19, w19, #1
	mov	w20, w22
	cmp	w19, w10
	b.ge	.LBB102_938
.LBB102_906:                            //   Parent Loop BB102_861 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	x9, x8
	b.hs	.LBB102_908
// %bb.907:                             //   in Loop: Header=BB102_906 Depth=2
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_913
.LBB102_908:                            //   in Loop: Header=BB102_906 Depth=2
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_913
// %bb.909:                             //   in Loop: Header=BB102_906 Depth=2
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #296]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_911
// %bb.910:                             //   in Loop: Header=BB102_906 Depth=2
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_912
.LBB102_911:                            //   in Loop: Header=BB102_906 Depth=2
	mov	w10, wzr
	mov	x8, x21
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_912:                            //   in Loop: Header=BB102_906 Depth=2
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	mov	x9, x21
	str	x8, [x25]
	str	x21, [x28]
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
.LBB102_913:                            //   in Loop: Header=BB102_906 Depth=2
	sxtw	x22, w20
	cmp	x9, x8
	add	x11, x22, x24
	strb	w10, [x11, #2]
	b.hs	.LBB102_915
// %bb.914:                             //   in Loop: Header=BB102_906 Depth=2
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_920
.LBB102_915:                            //   in Loop: Header=BB102_906 Depth=2
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_920
// %bb.916:                             //   in Loop: Header=BB102_906 Depth=2
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #296]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_918
// %bb.917:                             //   in Loop: Header=BB102_906 Depth=2
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_919
.LBB102_918:                            //   in Loop: Header=BB102_906 Depth=2
	mov	w10, wzr
	mov	x8, x21
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_919:                            //   in Loop: Header=BB102_906 Depth=2
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	mov	x9, x21
	str	x8, [x25]
	str	x21, [x28]
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
.LBB102_920:                            //   in Loop: Header=BB102_906 Depth=2
	add	x11, x22, x24
	cmp	x9, x8
	strb	w10, [x11, #1]
	b.hs	.LBB102_922
// %bb.921:                             //   in Loop: Header=BB102_906 Depth=2
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_927
.LBB102_922:                            //   in Loop: Header=BB102_906 Depth=2
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_927
// %bb.923:                             //   in Loop: Header=BB102_906 Depth=2
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #296]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_925
// %bb.924:                             //   in Loop: Header=BB102_906 Depth=2
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_926
.LBB102_925:                            //   in Loop: Header=BB102_906 Depth=2
	mov	w10, wzr
	mov	x8, x21
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_926:                            //   in Loop: Header=BB102_906 Depth=2
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	mov	x9, x21
	str	x8, [x25]
	str	x21, [x28]
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
.LBB102_927:                            //   in Loop: Header=BB102_906 Depth=2
	strb	w10, [x24, x22]
	ldr	w10, [sp, #224]                 // 4-byte Folded Reload
	cbz	w10, .LBB102_930
// %bb.928:                             //   in Loop: Header=BB102_906 Depth=2
	cmp	x9, x8
	b.hs	.LBB102_931
// %bb.929:                             //   in Loop: Header=BB102_906 Depth=2
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_936
.LBB102_930:                            //   in Loop: Header=BB102_906 Depth=2
	mov	w10, #255
	b	.LBB102_936
.LBB102_931:                            //   in Loop: Header=BB102_906 Depth=2
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_936
// %bb.932:                             //   in Loop: Header=BB102_906 Depth=2
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #296]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_934
// %bb.933:                             //   in Loop: Header=BB102_906 Depth=2
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_935
.LBB102_934:                            //   in Loop: Header=BB102_906 Depth=2
	mov	w10, wzr
	mov	x8, x21
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_935:                            //   in Loop: Header=BB102_906 Depth=2
	ldp	q6, q5, [sp, #384]              // 32-byte Folded Reload
	mov	x9, x21
	str	x8, [x25]
	str	x21, [x28]
	ldp	q16, q7, [sp, #352]             // 32-byte Folded Reload
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
.LBB102_936:                            //   in Loop: Header=BB102_906 Depth=2
	add	x22, x22, #3
	cmp	w7, #4
	b.ne	.LBB102_905
// %bb.937:                             //   in Loop: Header=BB102_906 Depth=2
	add	w11, w20, #4
	strb	w10, [x24, x22]
	mov	w22, w11
	b	.LBB102_905
.LBB102_938:                            //   in Loop: Header=BB102_861 Depth=1
	ldr	x8, [x23, #16]
	ldr	w19, [sp, #24]                  // 4-byte Folded Reload
	cbz	x8, .LBB102_940
// %bb.939:                             //   in Loop: Header=BB102_861 Depth=1
	ldr	x9, [x25]
	ldr	x8, [x28]
	ldr	w11, [sp, #16]                  // 4-byte Folded Reload
	sub	w10, w9, w8
	subs	w1, w11, w10
	b.le	.LBB102_941
	b	.LBB102_860
.LBB102_940:                            //   in Loop: Header=BB102_861 Depth=1
	ldr	x8, [x28]
.LBB102_941:                            //   in Loop: Header=BB102_861 Depth=1
	ldr	x9, [sp, #8]                    // 8-byte Folded Reload
	add	x8, x8, x9
	str	x8, [x28]
	ldr	w4, [x23, #4]
	add	w19, w19, #1
	cmp	w19, w4
	b.lt	.LBB102_861
.LBB102_942:
	ldr	x21, [sp, #336]                 // 8-byte Folded Reload
	ldr	x22, [sp, #312]                 // 8-byte Folded Reload
	b	.LBB102_979
.LBB102_943:
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	cmp	w8, #8
	b.ne	.LBB102_1007
// %bb.944:
	ldr	w8, [x23]
	mov	w9, w8
.LBB102_945:
	ldr	w4, [x23, #4]
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	cmp	w4, #1
	b.lt	.LBB102_978
// %bb.946:
	neg	w9, w9
	mov	w19, wzr
	and	w9, w9, #0x3
	mov	w10, wzr
	add	x20, x23, #57
	add	x15, sp, #656
	str	x9, [sp, #368]                  // 8-byte Folded Spill
	add	x9, x23, #56
	str	x9, [sp, #400]                  // 8-byte Folded Spill
	cmp	w8, #1
	str	w10, [sp, #384]                 // 4-byte Folded Spill
	b.ge	.LBB102_949
	b	.LBB102_948
.LBB102_947:
	ldr	w8, [x23]
	mov	w19, w22
	cmp	w8, #1
	str	w10, [sp, #384]                 // 4-byte Folded Spill
	b.ge	.LBB102_949
.LBB102_948:
	mov	w22, w19
	b	.LBB102_972
.LBB102_949:
	mov	w26, wzr
	ldr	x9, [x28]
	ldr	x8, [x25]
	b	.LBB102_951
.LBB102_950:                            //   in Loop: Header=BB102_951 Depth=1
	ldr	w10, [x23]
	add	w26, w26, #2
	mov	w19, w22
	cmp	w26, w10
	b.ge	.LBB102_972
.LBB102_951:                            // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.hs	.LBB102_953
// %bb.952:                             //   in Loop: Header=BB102_951 Depth=1
	add	x11, x9, #1
	ldr	w22, [sp, #304]                 // 4-byte Folded Reload
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_958
.LBB102_953:                            //   in Loop: Header=BB102_951 Depth=1
	ldr	w10, [x23, #48]
	ldr	w22, [sp, #304]                 // 4-byte Folded Reload
	cbz	w10, .LBB102_958
// %bb.954:                             //   in Loop: Header=BB102_951 Depth=1
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #400]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_956
// %bb.955:                             //   in Loop: Header=BB102_951 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_957
.LBB102_956:                            //   in Loop: Header=BB102_951 Depth=1
	mov	w10, wzr
	mov	x8, x20
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_957:                            //   in Loop: Header=BB102_951 Depth=1
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	add	x15, sp, #656
	mov	x9, x20
	str	x8, [x25]
	str	x20, [x28]
.LBB102_958:                            //   in Loop: Header=BB102_951 Depth=1
	lsr	w11, w10, #4
	cmp	w22, #4
	csel	w11, w11, w10, eq
	sxtw	x12, w19
	and	w10, w10, #0xf
	add	x13, x24, x12
	add	x11, x15, w11, uxtw #2
	csel	w10, w10, wzr, eq
	add	x21, x12, #3
	cmp	w7, #4
	ldrb	w14, [x11]
	ldurh	w11, [x11, #1]
	strb	w14, [x13]
	sturh	w11, [x13, #1]
	b.ne	.LBB102_960
// %bb.959:                             //   in Loop: Header=BB102_951 Depth=1
	mov	w12, #255
	add	w11, w19, #4
	strb	w12, [x24, x21]
	mov	w21, w11
.LBB102_960:                            //   in Loop: Header=BB102_951 Depth=1
	ldr	w11, [x23]
	add	w12, w26, #1
	cmp	w12, w11
	b.eq	.LBB102_971
// %bb.961:                             //   in Loop: Header=BB102_951 Depth=1
	cmp	w22, #8
	b.ne	.LBB102_969
// %bb.962:                             //   in Loop: Header=BB102_951 Depth=1
	cmp	x9, x8
	b.hs	.LBB102_964
// %bb.963:                             //   in Loop: Header=BB102_951 Depth=1
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_969
.LBB102_964:                            //   in Loop: Header=BB102_951 Depth=1
	ldr	w10, [x23, #48]
	cbz	w10, .LBB102_969
// %bb.965:                             //   in Loop: Header=BB102_951 Depth=1
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	ldr	x1, [sp, #400]                  // 8-byte Folded Reload
	blr	x8
	cbz	w0, .LBB102_967
// %bb.966:                             //   in Loop: Header=BB102_951 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_968
.LBB102_967:                            //   in Loop: Header=BB102_951 Depth=1
	mov	w10, wzr
	mov	x8, x20
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB102_968:                            //   in Loop: Header=BB102_951 Depth=1
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	add	x15, sp, #656
	mov	x9, x20
	str	x8, [x25]
	str	x20, [x28]
.LBB102_969:                            //   in Loop: Header=BB102_951 Depth=1
	add	x10, x15, w10, uxtw #2
	mov	w11, w21
	sxtw	x11, w11
	cmp	w7, #4
	add	x12, x24, x11
	add	x22, x11, #3
	ldrb	w13, [x10]
	ldurh	w10, [x10, #1]
	strb	w13, [x12]
	sturh	w10, [x12, #1]
	b.ne	.LBB102_950
// %bb.970:                             //   in Loop: Header=BB102_951 Depth=1
	mov	w11, #255
	add	w10, w21, #4
	strb	w11, [x24, x22]
	mov	w22, w10
	b	.LBB102_950
.LBB102_971:
	mov	w22, w21
.LBB102_972:
	ldr	x8, [x23, #16]
	cbz	x8, .LBB102_975
// %bb.973:
	ldr	x9, [x25]
	ldr	x8, [x28]
	ldr	x11, [sp, #368]                 // 8-byte Folded Reload
	sub	w10, w9, w8
	subs	w1, w11, w10
	b.le	.LBB102_976
// %bb.974:
	ldr	x8, [x23, #24]
	str	x9, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x8
	add	x15, sp, #656
	ldr	w7, [sp, #424]                  // 4-byte Folded Reload
	b	.LBB102_977
.LBB102_975:
	ldr	x8, [x28]
.LBB102_976:
	ldr	x9, [sp, #368]                  // 8-byte Folded Reload
	add	x8, x8, x9
	str	x8, [x28]
.LBB102_977:
	ldr	w10, [sp, #384]                 // 4-byte Folded Reload
	ldr	w4, [x23, #4]
	add	w10, w10, #1
	cmp	w10, w4
	b.lt	.LBB102_947
.LBB102_978:
	ldr	x21, [sp, #336]                 // 8-byte Folded Reload
	ldr	x22, [sp, #312]                 // 8-byte Folded Reload
	ldr	w26, [sp, #28]                  // 4-byte Folded Reload
.LBB102_979:
	ldr	w8, [sp, #4]                    // 4-byte Folded Reload
	cmp	w8, #1
	b.lt	.LBB102_999
// %bb.980:
	cmp	w4, #2
	b.lt	.LBB102_999
// %bb.981:
	ldr	w10, [x23]
	mul	w8, w10, w7
	cmp	w8, #1
	b.lt	.LBB102_999
// %bb.982:
	mul	w10, w7, w10
	sub	w16, w4, #1
	asr	w11, w4, #1
	and	x15, x8, #0xfffffff8
	cmp	w11, #1
	mov	w0, wzr
	mul	w18, w10, w16
	mov	x9, xzr
	csinc	w11, w11, wzr, gt
	add	x12, x24, x8
	and	x13, x8, #0xffffffe0
	and	x14, x8, #0x18
	add	x16, x24, #16
	neg	x17, x15
	b	.LBB102_984
.LBB102_983:                            //   in Loop: Header=BB102_984 Depth=1
	add	x9, x9, #1
	add	w0, w0, w8
	sub	w18, w18, w8
	cmp	x9, x11
	b.eq	.LBB102_999
.LBB102_984:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_993 Depth 2
                                        //     Child Loop BB102_997 Depth 2
                                        //     Child Loop BB102_989 Depth 2
	mov	w18, w18
	mov	w0, w0
	cmp	w8, #8
	b.lo	.LBB102_987
// %bb.985:                             //   in Loop: Header=BB102_984 Depth=1
	mvn	w1, w9
	add	w2, w4, w1
	mul	w1, w8, w9
	mul	w2, w10, w2
	add	x5, x24, x1
	add	x3, x12, x2
	cmp	x5, x3
	b.hs	.LBB102_990
// %bb.986:                             //   in Loop: Header=BB102_984 Depth=1
	add	x2, x24, x2
	add	x1, x12, x1
	cmp	x2, x1
	b.hs	.LBB102_990
.LBB102_987:                            //   in Loop: Header=BB102_984 Depth=1
	mov	x2, xzr
.LBB102_988:                            //   in Loop: Header=BB102_984 Depth=1
	add	x3, x2, x18
	add	x5, x2, x0
	sub	x1, x8, x2
	add	x2, x24, x3
	add	x3, x24, x5
.LBB102_989:                            //   Parent Loop BB102_984 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w5, [x2]
	subs	x1, x1, #1
	ldrb	w6, [x3]
	strb	w5, [x3], #1
	strb	w6, [x2], #1
	b.ne	.LBB102_989
	b	.LBB102_983
.LBB102_990:                            //   in Loop: Header=BB102_984 Depth=1
	cmp	w8, #32
	b.hs	.LBB102_992
// %bb.991:                             //   in Loop: Header=BB102_984 Depth=1
	mov	x3, xzr
	b	.LBB102_996
.LBB102_992:                            //   in Loop: Header=BB102_984 Depth=1
	add	x1, x16, x0
	add	x2, x16, x18
	mov	x3, x13
.LBB102_993:                            //   Parent Loop BB102_984 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x2, #-16]
	subs	x3, x3, #32
	ldp	q2, q3, [x1, #-16]
	stp	q0, q1, [x1, #-16]
	add	x1, x1, #32
	stp	q2, q3, [x2, #-16]
	add	x2, x2, #32
	b.ne	.LBB102_993
// %bb.994:                             //   in Loop: Header=BB102_984 Depth=1
	cmp	x13, x8
	b.eq	.LBB102_983
// %bb.995:                             //   in Loop: Header=BB102_984 Depth=1
	mov	x3, x13
	mov	x2, x13
	cbz	x14, .LBB102_988
.LBB102_996:                            //   in Loop: Header=BB102_984 Depth=1
	add	x1, x3, x0
	add	x2, x3, x18
	add	x1, x24, x1
	add	x2, x24, x2
	add	x3, x17, x3
.LBB102_997:                            //   Parent Loop BB102_984 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x2]
	adds	x3, x3, #8
	ldr	d1, [x1]
	str	d0, [x1], #8
	str	d1, [x2], #8
	b.ne	.LBB102_997
// %bb.998:                             //   in Loop: Header=BB102_984 Depth=1
	mov	x2, x15
	cmp	x15, x8
	b.eq	.LBB102_983
	b	.LBB102_988
.LBB102_999:
	cbz	w26, .LBB102_1002
// %bb.1000:
	cmp	w7, w26
	b.eq	.LBB102_1002
// %bb.1001:
	ldr	w3, [x23]
	mov	x0, x24
	mov	w1, w7
	mov	w2, w26
	bl	_ZL20stbi__convert_formatPhiijj
	mov	x24, x0
	cbz	x0, .LBB102_791
.LBB102_1002:
	ldr	w8, [x23]
	str	w8, [x22]
	ldr	w8, [x23, #4]
	str	w8, [x21]
	cbz	x27, .LBB102_791
// %bb.1003:
	ldr	w8, [x23, #8]
	str	w8, [x27]
	b	.LBB102_791
.LBB102_1004:
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	w19, w0
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	mov	w24, w0
	mov	x0, x23
	bl	_ZL13stbi__get32leP13stbi__context
	cmp	w19, w24
	str	w0, [sp, #288]                  // 4-byte Folded Spill
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	str	w19, [sp, #272]                 // 4-byte Folded Spill
	str	w24, [sp, #280]                 // 4-byte Folded Spill
	b.ne	.LBB102_1078
// %bb.1005:
	ldr	w8, [sp, #280]                  // 4-byte Folded Reload
	ldr	w9, [sp, #288]                  // 4-byte Folded Reload
	ldr	w19, [sp, #320]                 // 4-byte Folded Reload
	cmp	w8, w9
	b.ne	.LBB102_800
.LBB102_1006:
	adrp	x8, .L.str.71
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.71
	b	.LBB102_19
.LBB102_1007:
	mov	x0, x24
	bl	free
	adrp	x8, .L.str.76
	mov	x24, xzr
	add	x8, x8, :lo12:.L.str.76
	b	.LBB102_19
.LBB102_1008:
	adrp	x10, .L.str.35
	add	x10, x10, :lo12:.L.str.35
	b	.LBB102_780
.LBB102_1009:
	adrp	x10, .L.str.40
	add	x10, x10, :lo12:.L.str.40
	b	.LBB102_780
.LBB102_1010:
	str	wzr, [sp, #304]                 // 4-byte Folded Spill
	b	.LBB102_1013
.LBB102_1011:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	str	wzr, [sp, #304]                 // 4-byte Folded Spill
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1012:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1013:
	cmp	x9, x8
	b.hs	.LBB102_1015
// %bb.1014:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	b	.LBB102_1021
.LBB102_1015:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1018
// %bb.1016:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1019
// %bb.1017:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1020
.LBB102_1018:
	mov	w19, wzr
	b	.LBB102_1021
.LBB102_1019:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	mov	w19, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1020:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1021:
	cmp	x9, x8
	b.hs	.LBB102_1023
// %bb.1022:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	str	w9, [sp, #296]                  // 4-byte Folded Spill
	mov	x9, x10
	b	.LBB102_1029
.LBB102_1023:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1026
// %bb.1024:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1027
// %bb.1025:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	str	w9, [sp, #296]                  // 4-byte Folded Spill
	b	.LBB102_1028
.LBB102_1026:
	str	wzr, [sp, #296]                 // 4-byte Folded Spill
	b	.LBB102_1029
.LBB102_1027:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	str	wzr, [sp, #296]                 // 4-byte Folded Spill
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1028:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1029:
	cmp	x9, x8
	b.hs	.LBB102_1031
// %bb.1030:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	str	w9, [sp, #288]                  // 4-byte Folded Spill
	mov	x9, x10
	b	.LBB102_1037
.LBB102_1031:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1034
// %bb.1032:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1035
// %bb.1033:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	str	w9, [sp, #288]                  // 4-byte Folded Spill
	b	.LBB102_1036
.LBB102_1034:
	str	wzr, [sp, #288]                 // 4-byte Folded Spill
	b	.LBB102_1037
.LBB102_1035:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	str	wzr, [sp, #288]                 // 4-byte Folded Spill
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1036:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1037:
	cmp	x9, x8
	b.hs	.LBB102_1039
// %bb.1038:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
	str	w9, [sp, #320]                  // 4-byte Folded Spill
	mov	x9, x10
	b	.LBB102_1045
.LBB102_1039:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1042
// %bb.1040:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1043
// %bb.1041:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	str	w9, [sp, #320]                  // 4-byte Folded Spill
	b	.LBB102_1044
.LBB102_1042:
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	b	.LBB102_1045
.LBB102_1043:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	str	wzr, [sp, #320]                 // 4-byte Folded Spill
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1044:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1045:
	cmp	x9, x8
	b.hs	.LBB102_1047
// %bb.1046:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w27, [x9]
	mov	x9, x10
	b	.LBB102_1053
.LBB102_1047:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1050
// %bb.1048:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1051
// %bb.1049:
	mov	x8, x23
	ldrb	w27, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1052
.LBB102_1050:
	mov	w27, wzr
	b	.LBB102_1053
.LBB102_1051:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	mov	w27, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1052:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1053:
	cmp	x9, x8
	b.hs	.LBB102_1055
// %bb.1054:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w21, [x9]
	mov	x9, x10
	b	.LBB102_1061
.LBB102_1055:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1058
// %bb.1056:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1059
// %bb.1057:
	mov	x8, x23
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1060
.LBB102_1058:
	mov	w21, wzr
	b	.LBB102_1061
.LBB102_1059:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	mov	w21, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1060:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1061:
	ldr	w14, [sp, #304]                 // 4-byte Folded Reload
	lsl	w27, w27, #8
	cmp	x9, x8
	bfi	w14, w19, #8, #8
	b.hs	.LBB102_1063
// %bb.1062:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_1069
.LBB102_1063:
	mov	w19, w14
	ldr	w10, [x26]
	cbz	w10, .LBB102_1068
// %bb.1064:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1066
// %bb.1065:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1067
.LBB102_1066:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1067:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1068:
	mov	w14, w19
.LBB102_1069:
	ldr	w11, [sp, #320]                 // 4-byte Folded Reload
	ldr	w12, [sp, #352]                 // 4-byte Folded Reload
	ldr	w15, [sp, #296]                 // 4-byte Folded Reload
	add	w11, w14, w11
	add	w11, w11, w27
	cmp	w11, w12
	b.gt	.LBB102_1073
// %bb.1070:
	ldr	w13, [sp, #288]                 // 4-byte Folded Reload
	bfi	w21, w10, #8, #8
	bfi	w15, w13, #8, #8
	ldr	w13, [sp, #368]                 // 4-byte Folded Reload
	add	w10, w21, w15
	cmp	w10, w13
	b.gt	.LBB102_1073
// %bb.1071:
	lsl	w27, w12, #2
	lsl	w10, w14, #2
	lsl	w11, w11, #2
	ldr	x14, [sp, #344]                 // 8-byte Folded Reload
	mul	w12, w15, w27
	cmp	x9, x8
	madd	w13, w21, w27, w12
	str	w10, [x14, #28]
	stp	w12, w27, [x14, #32]
	stp	w10, w12, [x14, #12]
	stp	w11, w13, [x14, #20]
	b.hs	.LBB102_1074
// %bb.1072:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB102_1081
.LBB102_1073:
	adrp	x8, .L.str.78
	mov	x0, xzr
	add	x8, x8, :lo12:.L.str.78
	b	.LBB102_1084
.LBB102_1074:
	ldr	w10, [x26]
	cbz	w10, .LBB102_1077
// %bb.1075:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1079
// %bb.1076:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1080
.LBB102_1077:
	ldr	x10, [sp, #344]                 // 8-byte Folded Reload
	stp	w27, wzr, [x10, #4]
	str	wzr, [x10]
	b	.LBB102_1082
.LBB102_1078:
	ldr	w19, [sp, #320]                 // 4-byte Folded Reload
	b	.LBB102_800
.LBB102_1079:
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1080:
	mov	x9, x22
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1081:
	ldr	w11, [sp, #352]                 // 4-byte Folded Reload
	tst	w10, #0x40
	sbfx	w12, w10, #6, #1
	ldr	x13, [sp, #344]                 // 8-byte Folded Reload
	and	w12, w12, #0x3
	lsl	w11, w11, #5
	csel	w11, w27, w11, eq
	str	w12, [x13]
	stp	w11, w10, [x13, #4]
	tbnz	w10, #7, .LBB102_1088
.LBB102_1082:
	ldrb	w10, [sp, #672]
	tbnz	w10, #7, .LBB102_1089
// %bb.1083:
	adrp	x8, .L.str.79
	mov	x0, xzr
	add	x8, x8, :lo12:.L.str.79
.LBB102_1084:
	str	x8, [x20, :lo12:.L_MergedGlobals.126+8]
.LBB102_1085:
	ldr	x21, [sp, #336]                 // 8-byte Folded Reload
	ldr	x22, [sp, #312]                 // 8-byte Folded Reload
.LBB102_1086:
	cmp	x0, x23
	csel	x24, xzr, x0, eq
	cbz	x24, .LBB102_791
// %bb.1087:
	ldr	w8, [sp, #656]
	ldr	w9, [sp, #660]
	str	w8, [x22]
	str	w9, [x21]
	b	.LBB102_791
.LBB102_1088:
	ldr	w9, [sp, #688]
	and	w10, w10, #0x7
	ldr	w11, [sp, #684]
	add	x8, sp, #656
	add	x19, x8, #1060
	mov	w8, #2
	tst	w9, #0x1
	lsl	w2, w8, w10
	csinv	w3, w11, wzr, ne
	mov	x0, x23
	mov	x1, x19
	bl	_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii
	ldp	x9, x8, [x23, #184]
	b	.LBB102_1095
.LBB102_1089:
	mov	x10, xzr
	add	x11, sp, #656
	mov	w12, #255
.LBB102_1090:                           // =>This Inner Loop Header: Depth=1
	add	x13, x11, x10
	add	x10, x10, #8
	cmp	x10, #1024
	strb	w12, [x13, #39]
	strb	w12, [x13, #43]
	b.ne	.LBB102_1090
// %bb.1091:
	ldr	w10, [sp, #684]
	tbnz	w10, #31, .LBB102_1094
// %bb.1092:
	ldrb	w11, [sp, #688]
	tbz	w11, #0, .LBB102_1094
// %bb.1093:
	add	x11, sp, #656
	add	x10, x11, x10, lsl #2
	strb	wzr, [x10, #39]
.LBB102_1094:
	add	x10, sp, #656
	add	x19, x10, #36
.LBB102_1095:
	cmp	x9, x8
	str	x19, [sp, #19128]
	b.hs	.LBB102_1097
// %bb.1096:
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
	b	.LBB102_1103
.LBB102_1097:
	ldr	w8, [x26]
	cbz	w8, .LBB102_1100
// %bb.1098:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1101
// %bb.1099:
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_1102
.LBB102_1100:
	mov	w8, #1
	str	w8, [sp, #296]                  // 4-byte Folded Spill
	mov	w8, #1
	str	w8, [sp, #288]                  // 4-byte Folded Spill
	mov	w8, #1
	str	w8, [sp, #320]                  // 4-byte Folded Spill
	b	.LBB102_1106
.LBB102_1101:
	ldr	x10, [sp, #424]                 // 8-byte Folded Reload
	mov	w8, wzr
	mov	x9, x22
	str	wzr, [x26]
	strb	wzr, [x10]
.LBB102_1102:
	str	x9, [x25]
	str	x22, [x28]
.LBB102_1103:
	cmp	w8, #12
	b.ls	.LBB102_1105
// %bb.1104:
	mov	x0, xzr
	b	.LBB102_1085
.LBB102_1105:
	mov	w9, #1
	mov	w10, #2
	lsl	w9, w9, w8
	str	w9, [sp, #320]                  // 4-byte Folded Spill
	lsl	w9, w10, w8
	add	w8, w8, #1
	str	w8, [sp, #288]                  // 4-byte Folded Spill
	sub	w8, w9, #1
	str	w8, [sp, #296]                  // 4-byte Folded Spill
.LBB102_1106:
	ldr	w8, [sp, #320]                  // 4-byte Folded Reload
	cmp	w8, #1
	csinc	w8, w8, wzr, gt
	cmp	w8, #2
	b.hs	.LBB102_1108
// %bb.1107:
	mov	x9, xzr
	b	.LBB102_1111
.LBB102_1108:
	add	x11, sp, #656
	mov	x10, xzr
	and	x9, x8, #0x7ffffffe
	add	x11, x11, #2091
	mov	w12, #65535
.LBB102_1109:                           // =>This Inner Loop Header: Depth=1
	orr	w13, w10, #0x1
	sturb	w10, [x11, #-5]
	sturb	w10, [x11, #-4]
	add	x10, x10, #2
	cmp	x9, x10
	sturh	w12, [x11, #-7]
	sturh	w12, [x11, #-3]
	sturb	w13, [x11, #-1]
	strb	w13, [x11], #8
	b.ne	.LBB102_1109
// %bb.1110:
	cmp	x9, x8
	b.eq	.LBB102_1113
.LBB102_1111:
	add	x10, sp, #656
	mov	w11, #65535
	add	x10, x10, x9, lsl #2
	add	x10, x10, #2087
.LBB102_1112:                           // =>This Inner Loop Header: Depth=1
	sturb	w9, [x10, #-1]
	strb	w9, [x10]
	add	x9, x9, #1
	sturh	w11, [x10, #-3]
	add	x10, x10, #4
	cmp	x8, x9
	b.ne	.LBB102_1112
.LBB102_1113:
	ldr	w9, [sp, #320]                  // 4-byte Folded Reload
	mov	w8, wzr
	mov	w14, wzr
	mov	w21, wzr
	mov	w19, wzr
	ldr	w10, [sp, #296]                 // 4-byte Folded Reload
	add	w12, w9, #2
	add	w9, w9, #1
	mov	w11, #-1
	str	w9, [sp, #264]                  // 4-byte Folded Spill
	add	x9, sp, #656
	add	x9, x9, #2084
	str	w12, [sp, #272]                 // 4-byte Folded Spill
	str	x9, [sp, #248]                  // 8-byte Folded Spill
	ldr	w9, [sp, #288]                  // 4-byte Folded Reload
.LBB102_1114:                           // =>This Loop Header: Depth=1
                                        //     Child Loop BB102_1117 Depth 2
	str	w11, [sp, #304]                 // 4-byte Folded Spill
	mov	w11, w12
	mov	w27, w21
	str	w10, [sp, #344]                 // 4-byte Folded Spill
	str	w8, [sp, #280]                  // 4-byte Folded Spill
	str	x11, [sp, #352]                 // 8-byte Folded Spill
	mov	w11, w9
	str	w9, [sp, #368]                  // 4-byte Folded Spill
	b	.LBB102_1117
.LBB102_1115:                           //   in Loop: Header=BB102_1117 Depth=2
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
.LBB102_1116:                           //   in Loop: Header=BB102_1117 Depth=2
	lsl	w8, w8, w27
	add	w27, w27, #8
	orr	w14, w8, w14
.LBB102_1117:                           //   Parent Loop BB102_1114 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	subs	w21, w27, w11
	b.ge	.LBB102_1133
// %bb.1118:                            //   in Loop: Header=BB102_1117 Depth=2
	ldr	x9, [x28]
	ldr	x8, [x25]
	cbnz	w19, .LBB102_1127
// %bb.1119:                            //   in Loop: Header=BB102_1117 Depth=2
	cmp	x9, x8
	b.hs	.LBB102_1121
// %bb.1120:                            //   in Loop: Header=BB102_1117 Depth=2
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	b	.LBB102_1126
.LBB102_1121:                           //   in Loop: Header=BB102_1117 Depth=2
	ldr	w8, [x26]
	cbz	w8, .LBB102_1165
// %bb.1122:                            //   in Loop: Header=BB102_1117 Depth=2
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	mov	w21, w14
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1124
// %bb.1123:                            //   in Loop: Header=BB102_1117 Depth=2
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1125
.LBB102_1124:                           //   in Loop: Header=BB102_1117 Depth=2
	ldr	x9, [sp, #424]                  // 8-byte Folded Reload
	mov	w19, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x9]
.LBB102_1125:                           //   in Loop: Header=BB102_1117 Depth=2
	mov	x9, x22
	mov	w14, w21
	ldr	w11, [sp, #368]                 // 4-byte Folded Reload
	str	x8, [x25]
	str	x22, [x28]
.LBB102_1126:                           //   in Loop: Header=BB102_1117 Depth=2
	cbz	w19, .LBB102_1165
.LBB102_1127:                           //   in Loop: Header=BB102_1117 Depth=2
	sub	w19, w19, #1
	cmp	x9, x8
	b.lo	.LBB102_1115
// %bb.1128:                            //   in Loop: Header=BB102_1117 Depth=2
	ldr	w8, [x26]
	cbz	w8, .LBB102_1116
// %bb.1129:                            //   in Loop: Header=BB102_1117 Depth=2
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	mov	w21, w14
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1131
// %bb.1130:                            //   in Loop: Header=BB102_1117 Depth=2
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB102_1132
.LBB102_1131:                           //   in Loop: Header=BB102_1117 Depth=2
	ldr	x10, [sp, #424]                 // 8-byte Folded Reload
	mov	w8, wzr
	mov	x9, x22
	str	wzr, [x26]
	strb	wzr, [x10]
.LBB102_1132:                           //   in Loop: Header=BB102_1117 Depth=2
	mov	w14, w21
	ldr	w11, [sp, #368]                 // 4-byte Folded Reload
	str	x9, [x25]
	str	x22, [x28]
	b	.LBB102_1116
.LBB102_1133:                           //   in Loop: Header=BB102_1114 Depth=1
	ldr	w8, [sp, #344]                  // 4-byte Folded Reload
	ldr	w13, [sp, #320]                 // 4-byte Folded Reload
	ldr	w9, [sp, #288]                  // 4-byte Folded Reload
	and	w15, w14, w8
	asr	w14, w14, w11
	mov	w11, #-1
	mov	w8, #1
	ldr	w10, [sp, #296]                 // 4-byte Folded Reload
	cmp	w15, w13
	ldr	w12, [sp, #272]                 // 4-byte Folded Reload
	b.eq	.LBB102_1114
// %bb.1134:                            //   in Loop: Header=BB102_1114 Depth=1
	ldr	w8, [sp, #264]                  // 4-byte Folded Reload
	mov	w27, w15
	str	w14, [sp, #256]                 // 4-byte Folded Spill
	cmp	w15, w8
	b.eq	.LBB102_1145
// %bb.1135:                            //   in Loop: Header=BB102_1114 Depth=1
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	cmp	w27, w8
	b.gt	.LBB102_1144
// %bb.1136:                            //   in Loop: Header=BB102_1114 Depth=1
	ldr	w8, [sp, #280]                  // 4-byte Folded Reload
	tbz	w8, #0, .LBB102_1149
// %bb.1137:                            //   in Loop: Header=BB102_1114 Depth=1
	ldr	w8, [sp, #304]                  // 4-byte Folded Reload
	tbnz	w8, #31, .LBB102_1142
// %bb.1138:                            //   in Loop: Header=BB102_1114 Depth=1
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	cmp	w8, #1, lsl #12                 // =4096
	b.ge	.LBB102_1150
// %bb.1139:                            //   in Loop: Header=BB102_1114 Depth=1
	ldr	x10, [sp, #248]                 // 8-byte Folded Reload
	ldr	w13, [sp, #304]                 // 4-byte Folded Reload
	ldr	x12, [sp, #352]                 // 8-byte Folded Reload
	add	x9, x10, w13, uxtw #2
	sxtw	x8, w12
	add	x11, x10, x8, lsl #2
	ldrb	w10, [x9, #2]
	add	w9, w12, #1
	cmp	w27, w9
	strh	w13, [x11]
	strb	w10, [x11, #2]
	b.eq	.LBB102_1141
// %bb.1140:                            //   in Loop: Header=BB102_1114 Depth=1
	add	x10, sp, #656
	add	x10, x10, w27, sxtw #2
	ldrb	w10, [x10, #2086]
.LBB102_1141:                           //   in Loop: Header=BB102_1114 Depth=1
	add	x11, sp, #656
                                        // kill: def $w9 killed $w9 def $x9
	str	x9, [sp, #352]                  // 8-byte Folded Spill
	add	x8, x11, x8, lsl #2
	strb	w10, [x8, #2087]
	b	.LBB102_1143
.LBB102_1142:                           //   in Loop: Header=BB102_1114 Depth=1
	ldr	x8, [sp, #352]                  // 8-byte Folded Reload
	cmp	w27, w8
	b.eq	.LBB102_1144
.LBB102_1143:                           //   in Loop: Header=BB102_1114 Depth=1
	add	x0, sp, #656
	mov	w1, w27
	bl	_ZL18stbi__out_gif_codeP9stbi__gift
	ldr	w13, [sp, #344]                 // 4-byte Folded Reload
	mov	w12, #-1
	ldr	x15, [sp, #352]                 // 8-byte Folded Reload
	mov	w8, #1
	ldr	w14, [sp, #368]                 // 4-byte Folded Reload
	tst	w15, w13
	add	w9, w14, #1
	cset	w10, eq
	cmp	w15, #1, lsl #12                // =4096
	cset	w11, lt
	tst	w11, w10
	lsl	w12, w12, w9
	cinc	w9, w14, ne
	ldr	w14, [sp, #256]                 // 4-byte Folded Reload
	csinv	w10, w13, w12, eq
	mov	w12, w15
	mov	w11, w27
	b	.LBB102_1114
.LBB102_1144:
	adrp	x8, .L.str.85
	mov	x0, xzr
	add	x8, x8, :lo12:.L.str.85
	b	.LBB102_1084
.LBB102_1145:
	tbnz	w19, #31, .LBB102_1151
// %bb.1146:
	ldr	x8, [x24]
	cbz	x8, .LBB102_1152
// %bb.1147:
	ldr	x9, [x25]
	ldr	x8, [x28]
	sub	w10, w9, w8
	subs	w1, w19, w10
	b.le	.LBB102_1153
// %bb.1148:
	ldr	x8, [x23, #24]
	str	x9, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x8
	ldr	x9, [x28]
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_1157
	b	.LBB102_1163
.LBB102_1149:
	adrp	x8, .L.str.83
	mov	x0, xzr
	add	x8, x8, :lo12:.L.str.83
	b	.LBB102_1084
.LBB102_1150:
	adrp	x8, .L.str.84
	mov	x0, xzr
	add	x8, x8, :lo12:.L.str.84
	b	.LBB102_1084
.LBB102_1151:
	ldr	x8, [x25]
	str	x8, [x28]
	mov	x9, x8
	ldr	x8, [x25]
	cmp	x9, x8
	b.lo	.LBB102_1163
	b	.LBB102_1157
.LBB102_1152:
	ldr	x8, [x28]
.LBB102_1153:
	add	x8, x8, w19, uxtw
	str	x8, [x28]
	mov	x9, x8
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_1157
	b	.LBB102_1163
.LBB102_1154:
	ldr	x11, [x24]
	cbz	x11, .LBB102_1162
// %bb.1155:
	sub	w11, w8, w10
	subs	w1, w9, w11
	b.le	.LBB102_1162
// %bb.1156:
	ldr	x9, [x23, #24]
	str	x8, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x9
	ldr	x9, [x28]
	ldr	x8, [x25]
	cmp	x9, x8
	b.lo	.LBB102_1163
.LBB102_1157:
	ldr	w8, [x26]
	cbz	w8, .LBB102_1165
// %bb.1158:
	ldr	x9, [sp, #400]                  // 8-byte Folded Reload
	ldr	x8, [x24]
	ldr	x1, [sp, #424]                  // 8-byte Folded Reload
	ldr	x0, [x9]
	ldr	x9, [sp, #384]                  // 8-byte Folded Reload
	ldr	w2, [x9]
	blr	x8
	cbz	w0, .LBB102_1160
// %bb.1159:
	mov	x8, x23
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB102_1161
.LBB102_1160:
	ldr	x10, [sp, #424]                 // 8-byte Folded Reload
	mov	w9, wzr
	mov	x8, x22
	str	wzr, [x26]
	strb	wzr, [x10]
.LBB102_1161:
	mov	x10, x22
	str	x8, [x25]
	str	x22, [x28]
	b	.LBB102_1164
.LBB102_1162:
	add	x8, x10, w9, uxtw
	str	x8, [x28]
	mov	x9, x8
	ldr	x8, [x25]
	cmp	x9, x8
	b.hs	.LBB102_1157
.LBB102_1163:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w9, [x9]
.LBB102_1164:
	cbnz	w9, .LBB102_1154
.LBB102_1165:
	ldr	x0, [sp, #664]
	cbz	x0, .LBB102_1085
// %bb.1166:
	ldr	w8, [sp, #28]                   // 4-byte Folded Reload
	tst	w8, #0xfffffffb
	b.eq	.LBB102_1085
// %bb.1167:
	ldr	w3, [sp, #656]
	mov	w1, #4
	ldr	w4, [sp, #660]
	ldr	w2, [sp, #28]                   // 4-byte Folded Reload
	bl	_ZL20stbi__convert_formatPhiijj
	b	.LBB102_1085
.LBB102_1168:
	adrp	x0, .L.str.39
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi
	add	x0, x0, :lo12:.L.str.39
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi
	mov	w2, #1649
	bl	__assert_fail
.LBB102_1169:
	adrp	x0, .L.str.74
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL14stbi__bmp_loadP13stbi__contextPiS1_S1_i
	add	x0, x0, :lo12:.L.str.74
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL14stbi__bmp_loadP13stbi__contextPiS1_S1_i
	mov	w2, #4650
	bl	__assert_fail
.Lfunc_end102:
	.size	_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i, .Lfunc_end102-_ZL15stbi__load_mainP13stbi__contextPiS1_S1_i
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i
	.type	_ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i,@function
_ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i: // @_ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #208
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x28, x27, [sp, #128]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	w21, w4
	mov	x20, x3
	mov	x24, x2
	mov	x22, x1
	mov	x23, x0
	bl	_ZL13stbi__get32beP13stbi__context
	mov	w8, #20563
	movk	w8, #14402, lsl #16
	cmp	w0, w8
	b.ne	.LBB103_4
// %bb.1:
	mov	x28, x23
	ldp	x9, x8, [x28, #184]!
	cmp	x9, x8
	b.hs	.LBB103_5
// %bb.2:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB103_10
.LBB103_3:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB103_14
.LBB103_4:
	adrp	x9, .L.str.86
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.86
	mov	x25, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_5:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_8
// %bb.6:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_9
// %bb.7:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB103_10
	b	.LBB103_3
.LBB103_8:
	mov	w19, wzr
	cmp	x9, x8
	b.lo	.LBB103_3
	b	.LBB103_10
.LBB103_9:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.lo	.LBB103_3
.LBB103_10:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_14
// %bb.11:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_34
// %bb.12:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	bfi	w10, w19, #8, #8
	cmp	w10, #1
	b.eq	.LBB103_15
.LBB103_13:
	adrp	x9, .L.str.87
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.87
	mov	x25, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_14:
	bfi	w10, w19, #8, #8
	cmp	w10, #1
	b.ne	.LBB103_13
.LBB103_15:
	ldr	x10, [x23, #16]
	cbz	x10, .LBB103_27
// %bb.16:
	sub	w10, w8, w9
	cmp	w10, #5
	b.gt	.LBB103_27
// %bb.17:
	mov	w11, #6
	ldr	x9, [x23, #24]
	ldr	x0, [x23, #40]
	sub	w1, w11, w10
	str	x8, [x23, #184]
	blr	x9
	ldp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.lo	.LBB103_28
.LBB103_18:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_35
// %bb.19:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_37
// %bb.20:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.lo	.LBB103_29
.LBB103_21:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_36
// %bb.22:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_38
// %bb.23:
	mov	x8, x23
	ldrb	w27, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	bfi	w27, w19, #8, #8
	cmp	w27, #17
	b.hs	.LBB103_30
.LBB103_24:
	mov	x0, x23
	bl	_ZL13stbi__get32beP13stbi__context
	mov	w25, w0
	mov	x0, x23
	bl	_ZL13stbi__get32beP13stbi__context
	ldp	x9, x8, [x23, #184]
	mov	w26, w0
	cmp	x9, x8
	b.hs	.LBB103_31
// %bb.25:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB103_42
.LBB103_26:
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB103_46
.LBB103_27:
	add	x9, x9, #6
	str	x9, [x28]
	cmp	x9, x8
	b.hs	.LBB103_18
.LBB103_28:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB103_21
.LBB103_29:
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w27, [x9]
	bfi	w27, w19, #8, #8
	cmp	w27, #17
	b.lo	.LBB103_24
.LBB103_30:
	adrp	x9, .L.str.88
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.88
	mov	x25, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_31:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_39
// %bb.32:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_40
// %bb.33:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB103_41
.LBB103_34:
	mov	w10, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	bfi	w10, w19, #8, #8
	cmp	w10, #1
	b.eq	.LBB103_15
	b	.LBB103_13
.LBB103_35:
	mov	w19, wzr
	cmp	x9, x8
	b.lo	.LBB103_29
	b	.LBB103_21
.LBB103_36:
	mov	w27, wzr
	bfi	w27, w19, #8, #8
	cmp	w27, #17
	b.hs	.LBB103_30
	b	.LBB103_24
.LBB103_37:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB103_21
	b	.LBB103_29
.LBB103_38:
	mov	w27, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	bfi	w27, w19, #8, #8
	cmp	w27, #17
	b.hs	.LBB103_30
	b	.LBB103_24
.LBB103_39:
	mov	w19, wzr
	cmp	x9, x8
	b.lo	.LBB103_26
	b	.LBB103_42
.LBB103_40:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_41:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.lo	.LBB103_26
.LBB103_42:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_46
// %bb.43:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_52
// %bb.44:
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	bfi	w10, w19, #8, #8
	cmp	w10, #8
	b.eq	.LBB103_47
.LBB103_45:
	adrp	x9, .L.str.89
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.89
	mov	x25, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_46:
	bfi	w10, w19, #8, #8
	cmp	w10, #8
	b.ne	.LBB103_45
.LBB103_47:
	cmp	x9, x8
	b.hs	.LBB103_49
// %bb.48:
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w19, [x9]
	mov	x9, x10
	b	.LBB103_56
.LBB103_49:
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_53
// %bb.50:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_54
// %bb.51:
	mov	x8, x23
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB103_55
.LBB103_52:
	mov	w10, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
	bfi	w10, w19, #8, #8
	cmp	w10, #8
	b.eq	.LBB103_47
	b	.LBB103_45
.LBB103_53:
	mov	w19, wzr
	b	.LBB103_56
.LBB103_54:
	mov	w19, wzr
	add	x8, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_55:
	add	x9, x23, #57
	stp	x9, x8, [x23, #184]
.LBB103_56:
	cmp	x9, x8
	b.hs	.LBB103_58
// %bb.57:
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
	b	.LBB103_63
.LBB103_58:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_63
// %bb.59:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_61
// %bb.60:
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB103_62
.LBB103_61:
	mov	w8, wzr
	add	x9, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_62:
	add	x10, x23, #57
	stp	x10, x9, [x23, #184]
.LBB103_63:
	bfi	w8, w19, #8, #8
	cmp	w8, #3
	b.ne	.LBB103_68
// %bb.64:
	mov	x0, x23
	bl	_ZL13stbi__get32beP13stbi__context
	tbnz	w0, #31, .LBB103_69
// %bb.65:
	ldr	x8, [x23, #16]
	cbz	x8, .LBB103_70
// %bb.66:
	ldp	x8, x9, [x23, #184]
	sub	w10, w9, w8
	subs	w1, w0, w10
	b.le	.LBB103_71
// %bb.67:
	ldr	x8, [x23, #24]
	str	x9, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x8
	b	.LBB103_72
.LBB103_68:
	adrp	x9, .L.str.90
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.90
	mov	x25, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_69:
	ldr	x8, [x23, #192]
	str	x8, [x23, #184]
	b	.LBB103_72
.LBB103_70:
	ldr	x8, [x28]
.LBB103_71:
	add	x8, x8, w0, uxtw
	str	x8, [x28]
.LBB103_72:
	mov	x0, x23
	bl	_ZL13stbi__get32beP13stbi__context
	tbnz	w0, #31, .LBB103_76
// %bb.73:
	ldr	x8, [x23, #16]
	cbz	x8, .LBB103_77
// %bb.74:
	ldp	x8, x9, [x23, #184]
	sub	w10, w9, w8
	subs	w1, w0, w10
	b.le	.LBB103_78
// %bb.75:
	ldr	x8, [x23, #24]
	str	x9, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x8
	b	.LBB103_79
.LBB103_76:
	ldr	x8, [x23, #192]
	str	x8, [x23, #184]
	b	.LBB103_79
.LBB103_77:
	ldr	x8, [x28]
.LBB103_78:
	add	x8, x8, w0, uxtw
	str	x8, [x28]
.LBB103_79:
	mov	x0, x23
	bl	_ZL13stbi__get32beP13stbi__context
	stur	w25, [x29, #-44]                // 4-byte Folded Spill
	str	w21, [sp, #36]                  // 4-byte Folded Spill
	stur	x27, [x29, #-16]                // 8-byte Folded Spill
	tbnz	w0, #31, .LBB103_83
// %bb.80:
	ldr	x8, [x23, #16]
	cbz	x8, .LBB103_84
// %bb.81:
	ldp	x8, x9, [x23, #184]
	sub	w10, w9, w8
	subs	w1, w0, w10
	b.le	.LBB103_85
// %bb.82:
	ldr	x8, [x23, #24]
	str	x9, [x23, #184]
	ldr	x0, [x23, #40]
	blr	x8
	ldr	x19, [x23, #184]
	b	.LBB103_86
.LBB103_83:
	ldr	x19, [x23, #192]
	str	x19, [x23, #184]
	b	.LBB103_86
.LBB103_84:
	ldr	x8, [x28]
.LBB103_85:
	add	x19, x8, w0, uxtw
	str	x19, [x28]
.LBB103_86:
	ldr	x27, [x23, #192]
	str	x20, [sp, #40]                  // 8-byte Folded Spill
	cmp	x19, x27
	b.hs	.LBB103_88
// %bb.87:
	add	x8, x19, #1
	str	x8, [x28]
	ldrb	w20, [x19]
	mov	x19, x8
	b	.LBB103_94
.LBB103_88:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_91
// %bb.89:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_92
// %bb.90:
	mov	x8, x23
	ldrb	w20, [x8, #56]!
	add	x27, x8, w0, sxtw
	b	.LBB103_93
.LBB103_91:
	mov	w20, wzr
	b	.LBB103_94
.LBB103_92:
	mov	w20, wzr
	add	x27, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_93:
	add	x19, x23, #57
	stp	x19, x27, [x23, #184]
.LBB103_94:
	cmp	x19, x27
	b.hs	.LBB103_96
// %bb.95:
	add	x8, x19, #1
	str	x8, [x28]
	ldrb	w21, [x19]
	mov	x19, x8
	b	.LBB103_102
.LBB103_96:
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_99
// %bb.97:
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_100
// %bb.98:
	mov	x8, x23
	ldrb	w21, [x8, #56]!
	add	x27, x8, w0, sxtw
	b	.LBB103_101
.LBB103_99:
	mov	w21, wzr
	b	.LBB103_102
.LBB103_100:
	mov	w21, wzr
	add	x27, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_101:
	add	x19, x23, #57
	stp	x19, x27, [x23, #184]
.LBB103_102:
	bfi	w21, w20, #8, #8
	cmp	w21, #2
	b.lo	.LBB103_104
// %bb.103:
	adrp	x9, .L.str.91
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.91
	mov	x25, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_104:
	ldur	w20, [x29, #-44]                // 4-byte Folded Reload
	mul	w8, w20, w26
	lsl	w8, w8, #2
	sxtw	x0, w8
	bl	malloc
	mov	x25, x0
	cbz	x0, .LBB103_149
// %bb.105:
	stp	x24, x22, [sp, #16]             // 16-byte Folded Spill
	mul	w24, w26, w20
	str	w26, [sp, #12]                  // 4-byte Folded Spill
	cbz	w21, .LBB103_150
// %bb.106:
	ldur	x8, [x29, #-16]                 // 8-byte Folded Reload
	mov	x0, x23
	mul	w8, w8, w20
	lsl	w1, w8, #1
	bl	_ZL10stbi__skipP13stbi__contexti
	subs	w8, w24, #1
	stur	x8, [x29, #-40]                 // 8-byte Folded Spill
	b.lt	.LBB103_190
// %bb.107:
	ldur	x8, [x29, #-40]                 // 8-byte Folded Reload
	mov	x19, xzr
	add	x27, x23, #56
	add	x20, x23, #57
	stur	x25, [x29, #-24]                // 8-byte Folded Spill
	add	x8, x8, #1
	str	x8, [sp, #56]                   // 8-byte Folded Spill
	and	x8, x8, #0x1fffffffe
	stur	x8, [x29, #-32]                 // 8-byte Folded Spill
	lsl	x8, x8, #2
	str	x8, [sp, #48]                   // 8-byte Folded Spill
	add	x8, x25, #4
	stur	x8, [x29, #-8]                  // 8-byte Folded Spill
	b	.LBB103_109
.LBB103_108:                            //   in Loop: Header=BB103_109 Depth=1
	ldur	x8, [x29, #-8]                  // 8-byte Folded Reload
	add	x19, x19, #1
	ldur	x25, [x29, #-24]                // 8-byte Folded Reload
	cmp	x19, #4
	add	x8, x8, #1
	stur	x8, [x29, #-8]                  // 8-byte Folded Spill
	b.eq	.LBB103_190
.LBB103_109:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB103_145 Depth 2
                                        //     Child Loop BB103_148 Depth 2
                                        //     Child Loop BB103_113 Depth 2
                                        //       Child Loop BB103_139 Depth 3
                                        //       Child Loop BB103_142 Depth 3
	ldur	x8, [x29, #-16]                 // 8-byte Folded Reload
	add	x22, x25, x19
	cmp	x19, x8
	b.hs	.LBB103_143
// %bb.110:                             //   in Loop: Header=BB103_109 Depth=1
	mov	w25, wzr
	b	.LBB103_113
.LBB103_111:                            //   in Loop: Header=BB103_113 Depth=2
	mov	x22, x9
.LBB103_112:                            //   in Loop: Header=BB103_113 Depth=2
	cmp	w25, w24
	b.ge	.LBB103_108
.LBB103_113:                            //   Parent Loop BB103_109 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB103_139 Depth 3
                                        //       Child Loop BB103_142 Depth 3
	ldp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB103_115
// %bb.114:                             //   in Loop: Header=BB103_113 Depth=2
	add	x10, x9, #1
	str	x10, [x28]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	w21, #128
	b.eq	.LBB103_112
	b	.LBB103_120
.LBB103_115:                            //   in Loop: Header=BB103_113 Depth=2
	ldr	w10, [x23, #48]
	cbz	w10, .LBB103_118
// %bb.116:                             //   in Loop: Header=BB103_113 Depth=2
	ldr	x8, [x23, #16]
	mov	x1, x27
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_119
// %bb.117:                             //   in Loop: Header=BB103_113 Depth=2
	mov	x8, x23
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x20
	stp	x20, x8, [x23, #184]
	cmp	w21, #128
	b.eq	.LBB103_112
	b	.LBB103_120
.LBB103_118:                            //   in Loop: Header=BB103_113 Depth=2
	mov	w21, wzr
	add	w26, w21, #1
	add	x22, x22, #4
	cmp	x9, x8
	b.lo	.LBB103_128
	b	.LBB103_123
.LBB103_119:                            //   in Loop: Header=BB103_113 Depth=2
	mov	w21, wzr
	mov	x8, x20
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	mov	x9, x20
	stp	x20, x8, [x23, #184]
	cmp	w21, #128
	b.eq	.LBB103_112
.LBB103_120:                            //   in Loop: Header=BB103_113 Depth=2
	tbnz	w21, #7, .LBB103_131
// %bb.121:                             //   in Loop: Header=BB103_113 Depth=2
	add	w26, w21, #1
	add	x22, x22, #4
	cmp	x9, x8
	b.hs	.LBB103_123
	b	.LBB103_128
.LBB103_122:                            //   in Loop: Header=BB103_113 Depth=2
	ldp	x9, x8, [x23, #184]
	add	x22, x22, #4
	sub	w21, w21, #1
	cmp	x9, x8
	b.lo	.LBB103_128
.LBB103_123:                            //   in Loop: Header=BB103_113 Depth=2
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_129
// %bb.124:                             //   in Loop: Header=BB103_113 Depth=2
	ldr	x8, [x23, #16]
	mov	x1, x27
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_126
// %bb.125:                             //   in Loop: Header=BB103_113 Depth=2
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB103_127
.LBB103_126:                            //   in Loop: Header=BB103_113 Depth=2
	mov	w8, wzr
	mov	x9, x20
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_127:                            //   in Loop: Header=BB103_113 Depth=2
	stp	x20, x9, [x23, #184]
	b	.LBB103_129
.LBB103_128:                            //   in Loop: Header=BB103_113 Depth=2
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
.LBB103_129:                            //   in Loop: Header=BB103_113 Depth=2
	sturb	w8, [x22, #-4]
	cbnz	w21, .LBB103_122
// %bb.130:                             //   in Loop: Header=BB103_113 Depth=2
	add	w25, w26, w25
	b	.LBB103_112
.LBB103_131:                            //   in Loop: Header=BB103_113 Depth=2
	mov	w10, #257
	cmp	x9, x8
	sub	w26, w10, w21
	b.hs	.LBB103_133
// %bb.132:                             //   in Loop: Header=BB103_113 Depth=2
	add	x8, x9, #1
	str	x8, [x28]
	ldrb	w8, [x9]
	b	.LBB103_138
.LBB103_133:                            //   in Loop: Header=BB103_113 Depth=2
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_138
// %bb.134:                             //   in Loop: Header=BB103_113 Depth=2
	ldr	x8, [x23, #16]
	mov	x1, x27
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_136
// %bb.135:                             //   in Loop: Header=BB103_113 Depth=2
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB103_137
.LBB103_136:                            //   in Loop: Header=BB103_113 Depth=2
	mov	w8, wzr
	mov	x9, x20
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_137:                            //   in Loop: Header=BB103_113 Depth=2
	stp	x20, x9, [x23, #184]
.LBB103_138:                            //   in Loop: Header=BB103_113 Depth=2
	and	x10, x26, #0x1fe
	add	w25, w26, w25
	add	x11, x22, #4
	mov	x12, x10
	add	x9, x22, x10, lsl #2
.LBB103_139:                            //   Parent Loop BB103_109 Depth=1
                                        //     Parent Loop BB103_113 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	subs	x12, x12, #2
	sturb	w8, [x11, #-4]
	strb	w8, [x11], #8
	b.ne	.LBB103_139
// %bb.140:                             //   in Loop: Header=BB103_113 Depth=2
	cmp	x10, x26
	b.eq	.LBB103_111
// %bb.141:                             //   in Loop: Header=BB103_113 Depth=2
	add	w10, w10, w21
	sub	w10, w10, #257
.LBB103_142:                            //   Parent Loop BB103_109 Depth=1
                                        //     Parent Loop BB103_113 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	adds	w10, w10, #1
	strb	w8, [x9], #4
	b.lo	.LBB103_142
	b	.LBB103_111
.LBB103_143:                            //   in Loop: Header=BB103_109 Depth=1
	cmp	x19, #3
	ldur	x9, [x29, #-40]                 // 8-byte Folded Reload
	csetm	w8, eq
	cbz	w9, .LBB103_147
// %bb.144:                             //   in Loop: Header=BB103_109 Depth=1
	ldr	x9, [sp, #48]                   // 8-byte Folded Reload
	ldur	x10, [x29, #-8]                 // 8-byte Folded Reload
	add	x22, x22, x9
	ldur	x9, [x29, #-32]                 // 8-byte Folded Reload
.LBB103_145:                            //   Parent Loop BB103_109 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	subs	x9, x9, #2
	sturb	w8, [x10, #-4]
	strb	w8, [x10], #8
	b.ne	.LBB103_145
// %bb.146:                             //   in Loop: Header=BB103_109 Depth=1
	ldur	x11, [x29, #-32]                // 8-byte Folded Reload
	ldr	x10, [sp, #56]                  // 8-byte Folded Reload
	mov	w9, w11
	cmp	x10, x11
	b.eq	.LBB103_108
.LBB103_147:                            //   in Loop: Header=BB103_109 Depth=1
	sub	w9, w24, w9
.LBB103_148:                            //   Parent Loop BB103_109 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	subs	w9, w9, #1
	strb	w8, [x22], #4
	b.ne	.LBB103_148
	b	.LBB103_108
.LBB103_149:
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB103_204
.LBB103_150:
	cmp	w24, #1
	b.lt	.LBB103_190
// %bb.151:
	add	x22, x23, #56
	add	x26, x23, #57
	mov	w20, w24
	mov	x21, x25
	b	.LBB103_154
.LBB103_152:                            //   in Loop: Header=BB103_154 Depth=1
	add	x9, x19, #1
	str	x9, [x28]
	ldrb	w8, [x19]
	mov	x19, x9
.LBB103_153:                            //   in Loop: Header=BB103_154 Depth=1
	subs	w20, w20, #1
	strb	w8, [x21], #4
	b.eq	.LBB103_160
.LBB103_154:                            // =>This Inner Loop Header: Depth=1
	cmp	x19, x27
	b.lo	.LBB103_152
// %bb.155:                             //   in Loop: Header=BB103_154 Depth=1
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_153
// %bb.156:                             //   in Loop: Header=BB103_154 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_158
// %bb.157:                             //   in Loop: Header=BB103_154 Depth=1
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x27, x9, w0, sxtw
	b	.LBB103_159
.LBB103_158:                            //   in Loop: Header=BB103_154 Depth=1
	mov	w8, wzr
	mov	x27, x26
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_159:                            //   in Loop: Header=BB103_154 Depth=1
	mov	x19, x26
	stp	x26, x27, [x23, #184]
	b	.LBB103_153
.LBB103_160:
	add	x20, x25, #1
	ldur	x8, [x29, #-16]                 // 8-byte Folded Reload
	cbz	w8, .LBB103_170
// %bb.161:
	mov	w21, w24
	b	.LBB103_164
.LBB103_162:                            //   in Loop: Header=BB103_164 Depth=1
	add	x9, x19, #1
	str	x9, [x28]
	ldrb	w8, [x19]
	mov	x19, x9
.LBB103_163:                            //   in Loop: Header=BB103_164 Depth=1
	subs	w21, w21, #1
	strb	w8, [x20], #4
	b.eq	.LBB103_176
.LBB103_164:                            // =>This Inner Loop Header: Depth=1
	cmp	x19, x27
	b.lo	.LBB103_162
// %bb.165:                             //   in Loop: Header=BB103_164 Depth=1
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_163
// %bb.166:                             //   in Loop: Header=BB103_164 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_168
// %bb.167:                             //   in Loop: Header=BB103_164 Depth=1
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x27, x9, w0, sxtw
	b	.LBB103_169
.LBB103_168:                            //   in Loop: Header=BB103_164 Depth=1
	mov	w8, wzr
	mov	x27, x26
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_169:                            //   in Loop: Header=BB103_164 Depth=1
	mov	x19, x26
	stp	x26, x27, [x23, #184]
	b	.LBB103_163
.LBB103_170:
	subs	w8, w24, #1
	b.eq	.LBB103_174
// %bb.171:
	add	x9, x8, #1
	add	x10, x25, #5
	and	x8, x9, #0x1fffffffe
	mov	x11, x8
	add	x20, x20, x8, lsl #2
.LBB103_172:                            // =>This Inner Loop Header: Depth=1
	subs	x11, x11, #2
	sturb	wzr, [x10, #-4]
	strb	wzr, [x10], #8
	b.ne	.LBB103_172
// %bb.173:
	cmp	x9, x8
	b.eq	.LBB103_176
.LBB103_174:
	sub	w8, w24, w8
.LBB103_175:                            // =>This Inner Loop Header: Depth=1
	subs	w8, w8, #1
	strb	wzr, [x20], #4
	b.ne	.LBB103_175
.LBB103_176:
	ldur	x8, [x29, #-16]                 // 8-byte Folded Reload
	add	x20, x25, #2
	cmp	w8, #2
	b.hs	.LBB103_205
// %bb.177:
	subs	w8, w24, #1
	b.eq	.LBB103_181
// %bb.178:
	add	x9, x8, #1
	add	x10, x25, #6
	and	x8, x9, #0x1fffffffe
	mov	x11, x8
	add	x20, x20, x8, lsl #2
.LBB103_179:                            // =>This Inner Loop Header: Depth=1
	subs	x11, x11, #2
	sturb	wzr, [x10, #-4]
	strb	wzr, [x10], #8
	b.ne	.LBB103_179
// %bb.180:
	cmp	x9, x8
	b.eq	.LBB103_183
.LBB103_181:
	sub	w8, w24, w8
.LBB103_182:                            // =>This Inner Loop Header: Depth=1
	subs	w8, w8, #1
	strb	wzr, [x20], #4
	b.ne	.LBB103_182
.LBB103_183:
	ldur	x8, [x29, #-16]                 // 8-byte Folded Reload
	add	x20, x25, #3
	cmp	w8, #3
	b.hs	.LBB103_194
// %bb.184:
	subs	w8, w24, #1
	b.eq	.LBB103_188
// %bb.185:
	add	x9, x8, #1
	add	x10, x25, #7
	and	x8, x9, #0x1fffffffe
	mov	w11, #255
	mov	x12, x8
	add	x20, x20, x8, lsl #2
.LBB103_186:                            // =>This Inner Loop Header: Depth=1
	subs	x12, x12, #2
	sturb	w11, [x10, #-4]
	strb	w11, [x10], #8
	b.ne	.LBB103_186
// %bb.187:
	cmp	x9, x8
	b.eq	.LBB103_190
.LBB103_188:
	sub	w8, w24, w8
	mov	w9, #255
.LBB103_189:                            // =>This Inner Loop Header: Depth=1
	subs	w8, w8, #1
	strb	w9, [x20], #4
	b.ne	.LBB103_189
.LBB103_190:
	ldr	w2, [sp, #36]                   // 4-byte Folded Reload
	tst	w2, #0xfffffffb
	b.eq	.LBB103_200
// %bb.191:
	ldr	w20, [sp, #12]                  // 4-byte Folded Reload
	mov	x0, x25
	ldur	w19, [x29, #-44]                // 4-byte Folded Reload
	mov	w1, #4
	mov	w3, w20
	mov	w4, w19
	bl	_ZL20stbi__convert_formatPhiijj
	ldp	x10, x9, [sp, #16]              // 16-byte Folded Reload
	mov	x25, x0
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	cbnz	x0, .LBB103_201
	b	.LBB103_204
.LBB103_192:                            //   in Loop: Header=BB103_194 Depth=1
	add	x9, x19, #1
	str	x9, [x28]
	ldrb	w8, [x19]
	mov	x19, x9
.LBB103_193:                            //   in Loop: Header=BB103_194 Depth=1
	subs	w24, w24, #1
	strb	w8, [x20], #4
	b.eq	.LBB103_190
.LBB103_194:                            // =>This Inner Loop Header: Depth=1
	cmp	x19, x27
	b.lo	.LBB103_192
// %bb.195:                             //   in Loop: Header=BB103_194 Depth=1
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_193
// %bb.196:                             //   in Loop: Header=BB103_194 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_198
// %bb.197:                             //   in Loop: Header=BB103_194 Depth=1
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x27, x9, w0, sxtw
	b	.LBB103_199
.LBB103_198:                            //   in Loop: Header=BB103_194 Depth=1
	mov	w8, wzr
	mov	x27, x26
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_199:                            //   in Loop: Header=BB103_194 Depth=1
	mov	x19, x26
	stp	x26, x27, [x23, #184]
	b	.LBB103_193
.LBB103_200:
	ldp	x10, x9, [sp, #16]              // 16-byte Folded Reload
	ldr	x11, [sp, #40]                  // 8-byte Folded Reload
	ldur	w19, [x29, #-44]                // 4-byte Folded Reload
	ldr	w20, [sp, #12]                  // 4-byte Folded Reload
.LBB103_201:
	cbz	x11, .LBB103_203
// %bb.202:
	mov	w8, #4
	str	w8, [x11]
.LBB103_203:
	str	w19, [x10]
	str	w20, [x9]
.LBB103_204:
	mov	x0, x25
	ldp	x20, x19, [sp, #192]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	add	sp, sp, #208
	ret
.LBB103_205:
	mov	w21, w24
	b	.LBB103_208
.LBB103_206:                            //   in Loop: Header=BB103_208 Depth=1
	add	x9, x19, #1
	str	x9, [x28]
	ldrb	w8, [x19]
	mov	x19, x9
.LBB103_207:                            //   in Loop: Header=BB103_208 Depth=1
	subs	w21, w21, #1
	strb	w8, [x20], #4
	b.eq	.LBB103_183
.LBB103_208:                            // =>This Inner Loop Header: Depth=1
	cmp	x19, x27
	b.lo	.LBB103_206
// %bb.209:                             //   in Loop: Header=BB103_208 Depth=1
	ldr	w8, [x23, #48]
	cbz	w8, .LBB103_207
// %bb.210:                             //   in Loop: Header=BB103_208 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB103_212
// %bb.211:                             //   in Loop: Header=BB103_208 Depth=1
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x27, x9, w0, sxtw
	b	.LBB103_213
.LBB103_212:                            //   in Loop: Header=BB103_208 Depth=1
	mov	w8, wzr
	mov	x27, x26
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
.LBB103_213:                            //   in Loop: Header=BB103_208 Depth=1
	mov	x19, x26
	stp	x26, x27, [x23, #184]
	b	.LBB103_207
.Lfunc_end103:
	.size	_ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i, .Lfunc_end103-_ZL14stbi__psd_loadP13stbi__contextPiS1_S1_i
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__pic_testP13stbi__context
	.type	_ZL14stbi__pic_testP13stbi__context,@function
_ZL14stbi__pic_testP13stbi__context:    // @_ZL14stbi__pic_testP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x1, .L.str.92
	mov	x19, x0
	add	x1, x1, :lo12:.L.str.92
	bl	_ZL13stbi__pic_is4P13stbi__contextPKc
	cbz	w0, .LBB104_12
// %bb.1:
	ldp	x9, x8, [x19, #184]
	add	x20, x19, #56
	add	x21, x19, #57
	mov	w22, #84
	b	.LBB104_5
.LBB104_2:                              //   in Loop: Header=BB104_5 Depth=1
	add	x9, x9, #1
.LBB104_3:                              //   in Loop: Header=BB104_5 Depth=1
	str	x9, [x19, #184]
.LBB104_4:                              //   in Loop: Header=BB104_5 Depth=1
	subs	w22, w22, #1
	b.eq	.LBB104_11
.LBB104_5:                              // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.lo	.LBB104_2
// %bb.6:                               //   in Loop: Header=BB104_5 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB104_4
// %bb.7:                               //   in Loop: Header=BB104_5 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB104_9
// %bb.8:                               //   in Loop: Header=BB104_5 Depth=1
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB104_10
.LBB104_9:                              //   in Loop: Header=BB104_5 Depth=1
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB104_10:                             //   in Loop: Header=BB104_5 Depth=1
	mov	x9, x21
	str	x8, [x19, #192]
	b	.LBB104_3
.LBB104_11:
	adrp	x1, .L.str.93
	mov	x0, x19
	add	x1, x1, :lo12:.L.str.93
	bl	_ZL13stbi__pic_is4P13stbi__contextPKc
.LBB104_12:
	ldr	x8, [x19, #200]
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	str	x8, [x19, #184]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end104:
	.size	_ZL14stbi__pic_testP13stbi__context, .Lfunc_end104-_ZL14stbi__pic_testP13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i
	.type	_ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i,@function
_ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i: // @_ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #240
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	stp	x28, x27, [sp, #160]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #176]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #192]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #208]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #224]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x21, x0
	mov	w25, w4
	mov	x26, x3
	mov	x23, x0
	mov	x28, x2
	mov	w20, #92
	ldr	x9, [x21, #184]!
	mov	x24, x21
	sub	x19, x21, #136
	sub	x22, x21, #128
	sub	x27, x21, #127
	str	x1, [sp, #72]                   // 8-byte Folded Spill
	ldr	x8, [x24, #8]!
	b	.LBB105_4
.LBB105_1:                              //   in Loop: Header=BB105_4 Depth=1
	add	x9, x9, #1
.LBB105_2:                              //   in Loop: Header=BB105_4 Depth=1
	str	x9, [x21]
.LBB105_3:                              //   in Loop: Header=BB105_4 Depth=1
	subs	w20, w20, #1
	b.eq	.LBB105_10
.LBB105_4:                              // =>This Inner Loop Header: Depth=1
	cmp	x9, x8
	b.lo	.LBB105_1
// %bb.5:                               //   in Loop: Header=BB105_4 Depth=1
	ldr	w10, [x19]
	cbz	w10, .LBB105_3
// %bb.6:                               //   in Loop: Header=BB105_4 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_8
// %bb.7:                               //   in Loop: Header=BB105_4 Depth=1
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB105_9
.LBB105_8:                              //   in Loop: Header=BB105_4 Depth=1
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_9:                              //   in Loop: Header=BB105_4 Depth=1
	mov	x9, x27
	str	x8, [x24]
	b	.LBB105_2
.LBB105_10:
	cmp	x9, x8
	stur	x28, [x29, #-64]                // 8-byte Folded Spill
	b.hs	.LBB105_12
// %bb.11:
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w28, [x9]
	mov	x9, x10
	cmp	x9, x8
	str	w25, [sp, #60]                  // 4-byte Folded Spill
	b.hs	.LBB105_16
	b	.LBB105_22
.LBB105_12:
	ldr	w10, [x19]
	cbz	w10, .LBB105_15
// %bb.13:
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_20
// %bb.14:
	mov	x8, x23
	ldrb	w28, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_21
.LBB105_15:
	mov	w28, wzr
	cmp	x9, x8
	str	w25, [sp, #60]                  // 4-byte Folded Spill
	b.lo	.LBB105_22
.LBB105_16:
	ldr	w10, [x19]
	cbz	w10, .LBB105_19
// %bb.17:
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_24
// %bb.18:
	mov	x8, x23
	ldrb	w25, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_25
.LBB105_19:
	mov	w25, wzr
	cmp	x9, x8
	stur	x24, [x29, #-48]                // 8-byte Folded Spill
	b.lo	.LBB105_23
	b	.LBB105_26
.LBB105_20:
	mov	w28, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_21:
	mov	x9, x27
	str	x8, [x24]
	str	x27, [x21]
	cmp	x9, x8
	str	w25, [sp, #60]                  // 4-byte Folded Spill
	b.hs	.LBB105_16
.LBB105_22:
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w25, [x9]
	mov	x9, x10
	cmp	x9, x8
	stur	x24, [x29, #-48]                // 8-byte Folded Spill
	b.hs	.LBB105_26
.LBB105_23:
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w24, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB105_30
	b	.LBB105_36
.LBB105_24:
	mov	w25, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_25:
	mov	x9, x27
	str	x8, [x24]
	str	x27, [x21]
	cmp	x9, x8
	stur	x24, [x29, #-48]                // 8-byte Folded Spill
	b.lo	.LBB105_23
.LBB105_26:
	ldr	w10, [x19]
	cbz	w10, .LBB105_29
// %bb.27:
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_34
// %bb.28:
	mov	x8, x23
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_35
.LBB105_29:
	mov	w24, wzr
	cmp	x9, x8
	b.lo	.LBB105_36
.LBB105_30:
	ldr	w10, [x19]
	cbz	w10, .LBB105_33
// %bb.31:
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	mov	x20, x26
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_38
// %bb.32:
	mov	x8, x23
	ldrb	w26, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_39
.LBB105_33:
	mov	x20, x26
	mov	w26, wzr
	ldr	x10, [x23, #16]
	stur	x22, [x29, #-56]                // 8-byte Folded Spill
	cbnz	x10, .LBB105_40
	b	.LBB105_37
.LBB105_34:
	mov	w24, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_35:
	mov	x9, x27
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	str	x27, [x21]
	str	x8, [x10]
	cmp	x9, x8
	b.hs	.LBB105_30
.LBB105_36:
	add	x10, x9, #1
	mov	x20, x26
	str	x10, [x21]
	ldrb	w26, [x9]
	mov	x9, x10
	ldr	x10, [x23, #16]
	stur	x22, [x29, #-56]                // 8-byte Folded Spill
	cbnz	x10, .LBB105_40
.LBB105_37:
	cmp	x9, x8
	b.lo	.LBB105_43
	b	.LBB105_45
.LBB105_38:
	mov	w26, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_39:
	mov	x9, x27
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	str	x27, [x21]
	str	x8, [x10]
	ldr	x10, [x23, #16]
	stur	x22, [x29, #-56]                // 8-byte Folded Spill
	cbz	x10, .LBB105_37
.LBB105_40:
	ldp	x8, x0, [x23, #32]
	blr	x8
	cbz	w0, .LBB105_43
// %bb.41:
	ldr	w8, [x19]
	cbz	w8, .LBB105_45
// %bb.42:
	ldur	x8, [x29, #-48]                 // 8-byte Folded Reload
	ldr	x9, [x21]
	ldr	x8, [x8]
	cmp	x9, x8
	b.hs	.LBB105_45
.LBB105_43:
	bfi	w25, w28, #8, #8
	mov	w8, #268435456
	bfi	w26, w24, #8, #8
	udiv	w8, w8, w25
	cmp	w8, w26
	b.hs	.LBB105_46
// %bb.44:
	adrp	x9, .L.str.27
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.27
	mov	x0, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB105_215
.LBB105_45:
	adrp	x9, .L.str.94
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.94
	mov	x0, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB105_215
.LBB105_46:
	mov	x0, x23
	str	x26, [sp, #48]                  // 8-byte Folded Spill
	str	w25, [sp, #56]                  // 4-byte Folded Spill
	bl	_ZL13stbi__get32beP13stbi__context
	ldp	x9, x8, [x23, #184]
	cmp	x9, x8
	b.hs	.LBB105_48
// %bb.47:
	ldp	x11, x24, [x29, #-56]           // 16-byte Folded Reload
	add	x9, x9, #1
	mov	x22, x20
	b	.LBB105_53
.LBB105_48:
	ldp	x11, x24, [x29, #-56]           // 16-byte Folded Reload
	mov	x22, x20
	ldr	w10, [x19]
	cbz	w10, .LBB105_54
// %bb.49:
	ldr	x8, [x23, #16]
	mov	x1, x11
	ldr	x0, [x23, #40]
	mov	x20, x11
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_51
// %bb.50:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB105_52
.LBB105_51:
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x20]
.LBB105_52:
	mov	x11, x20
	mov	x9, x27
	str	x8, [x24]
.LBB105_53:
	str	x9, [x21]
.LBB105_54:
	cmp	x9, x8
	b.hs	.LBB105_56
// %bb.55:
	add	x9, x9, #1
	b	.LBB105_61
.LBB105_56:
	ldr	w10, [x19]
	cbz	w10, .LBB105_62
// %bb.57:
	ldr	x8, [x23, #16]
	mov	x1, x11
	ldr	x0, [x23, #40]
	mov	x20, x11
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_59
// %bb.58:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB105_60
.LBB105_59:
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x20]
.LBB105_60:
	mov	x11, x20
	mov	x9, x27
	str	x8, [x24]
.LBB105_61:
	str	x9, [x21]
.LBB105_62:
	cmp	x9, x8
	b.hs	.LBB105_64
// %bb.63:
	add	x9, x9, #1
	b	.LBB105_69
.LBB105_64:
	ldr	w10, [x19]
	cbz	w10, .LBB105_70
// %bb.65:
	ldr	x8, [x23, #16]
	mov	x1, x11
	ldr	x0, [x23, #40]
	mov	x20, x11
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_67
// %bb.66:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB105_68
.LBB105_67:
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x20]
.LBB105_68:
	mov	x11, x20
	mov	x9, x27
	str	x8, [x24]
.LBB105_69:
	str	x9, [x21]
.LBB105_70:
	cmp	x9, x8
	b.hs	.LBB105_72
// %bb.71:
	add	x9, x9, #1
	b	.LBB105_77
.LBB105_72:
	ldr	w8, [x19]
	cbz	w8, .LBB105_78
// %bb.73:
	ldr	x8, [x23, #16]
	mov	x1, x11
	ldr	x0, [x23, #40]
	mov	x20, x11
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_75
// %bb.74:
	add	x8, x23, w0, sxtw
	add	x8, x8, #56
	b	.LBB105_76
.LBB105_75:
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x20]
.LBB105_76:
	mov	x9, x27
	str	x8, [x24]
.LBB105_77:
	str	x9, [x21]
.LBB105_78:
	ldr	w8, [sp, #56]                   // 4-byte Folded Reload
	str	x22, [sp, #40]                  // 8-byte Folded Spill
	lsl	w9, w8, #2
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	mul	w20, w9, w8
	str	w9, [sp, #28]                   // 4-byte Folded Spill
	mov	x0, x20
	bl	malloc
	mov	w1, #255
	mov	x2, x20
	str	x0, [sp, #32]                   // 8-byte Folded Spill
	bl	memset
	sub	x8, x29, #32
	mov	x25, xzr
	mov	w20, wzr
	orr	x28, x8, #0x2
.LBB105_79:                             // =>This Inner Loop Header: Depth=1
	cmp	x25, #10
	b.eq	.LBB105_207
// %bb.80:                              //   in Loop: Header=BB105_79 Depth=1
	ldr	x9, [x21]
	ldr	x8, [x24]
	cmp	x9, x8
	b.hs	.LBB105_82
// %bb.81:                              //   in Loop: Header=BB105_79 Depth=1
	add	x10, x9, #1
	ldur	x22, [x29, #-56]                // 8-byte Folded Reload
	str	x10, [x21]
	ldrb	w26, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB105_86
	b	.LBB105_92
.LBB105_82:                             //   in Loop: Header=BB105_79 Depth=1
	ldr	w10, [x19]
	ldur	x22, [x29, #-56]                // 8-byte Folded Reload
	cbz	w10, .LBB105_85
// %bb.83:                              //   in Loop: Header=BB105_79 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_90
// %bb.84:                              //   in Loop: Header=BB105_79 Depth=1
	mov	x8, x23
	ldrb	w26, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_91
.LBB105_85:                             //   in Loop: Header=BB105_79 Depth=1
	mov	w26, wzr
	cmp	x9, x8
	b.lo	.LBB105_92
.LBB105_86:                             //   in Loop: Header=BB105_79 Depth=1
	ldr	w10, [x19]
	cbz	w10, .LBB105_89
// %bb.87:                              //   in Loop: Header=BB105_79 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_94
// %bb.88:                              //   in Loop: Header=BB105_79 Depth=1
	mov	x8, x23
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_95
.LBB105_89:                             //   in Loop: Header=BB105_79 Depth=1
	mov	w24, wzr
	cmp	x9, x8
	sturb	w24, [x28, #-2]
	b.lo	.LBB105_93
	b	.LBB105_96
.LBB105_90:                             //   in Loop: Header=BB105_79 Depth=1
	mov	w26, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_91:                             //   in Loop: Header=BB105_79 Depth=1
	mov	x9, x27
	str	x8, [x24]
	str	x27, [x21]
	cmp	x9, x8
	b.hs	.LBB105_86
.LBB105_92:                             //   in Loop: Header=BB105_79 Depth=1
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w24, [x9]
	mov	x9, x10
	cmp	x9, x8
	sturb	w24, [x28, #-2]
	b.hs	.LBB105_96
.LBB105_93:                             //   in Loop: Header=BB105_79 Depth=1
	add	x11, x9, #1
	str	x11, [x21]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB105_101
.LBB105_94:                             //   in Loop: Header=BB105_79 Depth=1
	mov	w24, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_95:                             //   in Loop: Header=BB105_79 Depth=1
	mov	x9, x27
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	str	x27, [x21]
	str	x8, [x10]
	cmp	x9, x8
	sturb	w24, [x28, #-2]
	b.lo	.LBB105_93
.LBB105_96:                             //   in Loop: Header=BB105_79 Depth=1
	ldr	w10, [x19]
	cbz	w10, .LBB105_101
// %bb.97:                              //   in Loop: Header=BB105_79 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_99
// %bb.98:                              //   in Loop: Header=BB105_79 Depth=1
	mov	x8, x23
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_100
.LBB105_99:                             //   in Loop: Header=BB105_79 Depth=1
	mov	w10, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_100:                            //   in Loop: Header=BB105_79 Depth=1
	mov	x9, x27
	ldur	x11, [x29, #-48]                // 8-byte Folded Reload
	str	x27, [x21]
	str	x8, [x11]
.LBB105_101:                            //   in Loop: Header=BB105_79 Depth=1
	cmp	x9, x8
	sturb	w10, [x28, #-1]
	b.hs	.LBB105_103
// %bb.102:                             //   in Loop: Header=BB105_79 Depth=1
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w22, [x9]
	mov	x9, x10
	ldr	x10, [x23, #16]
	strb	w22, [x28]
	cbnz	x10, .LBB105_109
	b	.LBB105_112
.LBB105_103:                            //   in Loop: Header=BB105_79 Depth=1
	ldr	w10, [x19]
	cbz	w10, .LBB105_106
// %bb.104:                             //   in Loop: Header=BB105_79 Depth=1
	ldr	x8, [x23, #16]
	mov	x1, x22
	ldr	x0, [x23, #40]
	str	x25, [sp, #64]                  // 8-byte Folded Spill
	ldr	w2, [x23, #52]
	mov	w25, w26
	mov	x26, x22
	blr	x8
	cbz	w0, .LBB105_107
// %bb.105:                             //   in Loop: Header=BB105_79 Depth=1
	mov	x8, x23
	ldrb	w22, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_108
.LBB105_106:                            //   in Loop: Header=BB105_79 Depth=1
	mov	w22, wzr
	ldr	x10, [x23, #16]
	strb	w22, [x28]
	cbnz	x10, .LBB105_109
	b	.LBB105_112
.LBB105_107:                            //   in Loop: Header=BB105_79 Depth=1
	mov	w22, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x26]
.LBB105_108:                            //   in Loop: Header=BB105_79 Depth=1
	mov	w26, w25
	mov	x9, x27
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	str	x27, [x21]
	ldr	x25, [sp, #64]                  // 8-byte Folded Reload
	str	x8, [x10]
	ldr	x10, [x23, #16]
	strb	w22, [x28]
	cbz	x10, .LBB105_112
.LBB105_109:                            //   in Loop: Header=BB105_79 Depth=1
	ldp	x8, x0, [x23, #32]
	blr	x8
	cbz	w0, .LBB105_113
// %bb.110:                             //   in Loop: Header=BB105_79 Depth=1
	ldr	w8, [x19]
	cbz	w8, .LBB105_208
// %bb.111:                             //   in Loop: Header=BB105_79 Depth=1
	ldur	x8, [x29, #-48]                 // 8-byte Folded Reload
	ldr	x9, [x21]
	ldr	x8, [x8]
.LBB105_112:                            //   in Loop: Header=BB105_79 Depth=1
	cmp	x9, x8
	b.hs	.LBB105_208
.LBB105_113:                            //   in Loop: Header=BB105_79 Depth=1
	cmp	w24, #8
	b.ne	.LBB105_207
// %bb.114:                             //   in Loop: Header=BB105_79 Depth=1
	orr	w20, w20, w22
	add	x28, x28, #3
	add	x25, x25, #1
	ldur	x24, [x29, #-48]                // 8-byte Folded Reload
	cbnz	w26, .LBB105_79
// %bb.115:
	tst	w20, #0x10
	mov	w8, #3
	cinc	w8, w8, ne
	ldr	x9, [sp, #40]                   // 8-byte Folded Reload
	ldur	x20, [x29, #-64]                // 8-byte Folded Reload
	ldr	x22, [sp, #72]                  // 8-byte Folded Reload
	str	w8, [x9]
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	cbz	w8, .LBB105_206
// %bb.116:
	mov	x9, xzr
.LBB105_117:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB105_119 Depth 2
                                        //       Child Loop BB105_124 Depth 3
                                        //         Child Loop BB105_140 Depth 4
                                        //       Child Loop BB105_181 Depth 3
                                        //       Child Loop BB105_176 Depth 3
	ldr	w8, [sp, #28]                   // 4-byte Folded Reload
	str	x9, [sp, #8]                    // 8-byte Folded Spill
	mov	x10, xzr
	mul	w8, w8, w9
	ldr	x9, [sp, #32]                   // 8-byte Folded Reload
	add	x8, x9, w8, sxtw
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	b	.LBB105_119
.LBB105_118:                            //   in Loop: Header=BB105_119 Depth=2
	ldp	x10, x22, [sp, #64]             // 16-byte Folded Reload
	ldur	x20, [x29, #-64]                // 8-byte Folded Reload
	add	x10, x10, #1
	cmp	x25, x10
	b.eq	.LBB105_205
.LBB105_119:                            //   Parent Loop BB105_117 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB105_124 Depth 3
                                        //         Child Loop BB105_140 Depth 4
                                        //       Child Loop BB105_181 Depth 3
                                        //       Child Loop BB105_176 Depth 3
	add	x8, x10, x10, lsl #1
	sub	x9, x29, #32
	add	x8, x9, x8
	str	x10, [sp, #64]                  // 8-byte Folded Spill
	ldrb	w8, [x8, #1]
	cbz	w8, .LBB105_174
// %bb.120:                             //   in Loop: Header=BB105_119 Depth=2
	ldr	w9, [sp, #56]                   // 4-byte Folded Reload
	cmp	w8, #1
	b.eq	.LBB105_178
// %bb.121:                             //   in Loop: Header=BB105_119 Depth=2
	cmp	w8, #2
	b.ne	.LBB105_207
// %bb.122:                             //   in Loop: Header=BB105_119 Depth=2
	cbz	w9, .LBB105_118
// %bb.123:                             //   in Loop: Header=BB105_119 Depth=2
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	sub	x9, x29, #32
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	add	x8, x8, x8, lsl #1
	add	x8, x9, x8
	add	x26, x8, #2
	ldr	w8, [sp, #56]                   // 4-byte Folded Reload
	str	w8, [sp, #24]                   // 4-byte Folded Spill
.LBB105_124:                            //   Parent Loop BB105_117 Depth=1
                                        //     Parent Loop BB105_119 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB105_140 Depth 4
	ldur	x22, [x29, #-48]                // 8-byte Folded Reload
	ldr	x9, [x21]
	ldr	x8, [x22]
	cmp	x9, x8
	b.hs	.LBB105_126
// %bb.125:                             //   in Loop: Header=BB105_124 Depth=3
	add	x10, x9, #1
	ldur	x24, [x29, #-56]                // 8-byte Folded Reload
	str	x10, [x21]
	ldrb	w20, [x9]
	mov	x9, x10
	b	.LBB105_132
.LBB105_126:                            //   in Loop: Header=BB105_124 Depth=3
	ldr	w10, [x19]
	ldur	x24, [x29, #-56]                // 8-byte Folded Reload
	cbz	w10, .LBB105_129
// %bb.127:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	x8, [x23, #16]
	mov	x1, x24
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_130
// %bb.128:                             //   in Loop: Header=BB105_124 Depth=3
	mov	x8, x23
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_131
.LBB105_129:                            //   in Loop: Header=BB105_124 Depth=3
	mov	w20, wzr
	b	.LBB105_132
.LBB105_130:                            //   in Loop: Header=BB105_124 Depth=3
	mov	w20, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x24]
.LBB105_131:                            //   in Loop: Header=BB105_124 Depth=3
	mov	x9, x27
	str	x8, [x22]
	str	x27, [x21]
.LBB105_132:                            //   in Loop: Header=BB105_124 Depth=3
	ldr	x10, [x23, #16]
	cbz	x10, .LBB105_136
// %bb.133:                             //   in Loop: Header=BB105_124 Depth=3
	ldp	x8, x0, [x23, #32]
	blr	x8
	ldur	x24, [x29, #-56]                // 8-byte Folded Reload
	cbz	w0, .LBB105_137
// %bb.134:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	w8, [x19]
	cbz	w8, .LBB105_208
// %bb.135:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	x9, [x21]
	ldr	x8, [x22]
.LBB105_136:                            //   in Loop: Header=BB105_124 Depth=3
	cmp	x9, x8
	b.hs	.LBB105_208
.LBB105_137:                            //   in Loop: Header=BB105_124 Depth=3
	tbnz	w20, #7, .LBB105_142
// %bb.138:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	w8, [sp, #24]                   // 4-byte Folded Reload
	cmp	w8, w20
	b.ls	.LBB105_208
// %bb.139:                             //   in Loop: Header=BB105_124 Depth=3
	add	w24, w20, #1
	ldrb	w20, [x26]
	mov	w22, w24
.LBB105_140:                            //   Parent Loop BB105_117 Depth=1
                                        //     Parent Loop BB105_119 Depth=2
                                        //       Parent Loop BB105_124 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	mov	x0, x23
	mov	w1, w20
	mov	x2, x28
	bl	_ZL13stbi__readvalP13stbi__contextiPh
	cbz	x0, .LBB105_210
// %bb.141:                             //   in Loop: Header=BB105_140 Depth=4
	add	x28, x28, #4
	subs	w22, w22, #1
	b.ne	.LBB105_140
	b	.LBB105_173
.LBB105_142:                            //   in Loop: Header=BB105_124 Depth=3
	cmp	w20, #128
	b.ne	.LBB105_145
// %bb.143:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	x9, [x21]
	ldr	x8, [x22]
	cmp	x9, x8
	b.hs	.LBB105_146
// %bb.144:                             //   in Loop: Header=BB105_124 Depth=3
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w20, [x9]
	mov	x9, x10
	b	.LBB105_152
.LBB105_145:                            //   in Loop: Header=BB105_124 Depth=3
	sub	w24, w20, #127
	b	.LBB105_160
.LBB105_146:                            //   in Loop: Header=BB105_124 Depth=3
	ldr	w10, [x19]
	cbz	w10, .LBB105_149
// %bb.147:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	x8, [x23, #16]
	mov	x1, x24
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_150
// %bb.148:                             //   in Loop: Header=BB105_124 Depth=3
	mov	x8, x23
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_151
.LBB105_149:                            //   in Loop: Header=BB105_124 Depth=3
	mov	w20, wzr
	b	.LBB105_152
.LBB105_150:                            //   in Loop: Header=BB105_124 Depth=3
	mov	w20, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x24]
.LBB105_151:                            //   in Loop: Header=BB105_124 Depth=3
	mov	x9, x27
	str	x8, [x22]
	str	x27, [x21]
.LBB105_152:                            //   in Loop: Header=BB105_124 Depth=3
	cmp	x9, x8
	b.hs	.LBB105_154
// %bb.153:                             //   in Loop: Header=BB105_124 Depth=3
	add	x8, x9, #1
	str	x8, [x21]
	ldrb	w24, [x9]
	bfi	w24, w20, #8, #8
	b	.LBB105_160
.LBB105_154:                            //   in Loop: Header=BB105_124 Depth=3
	ldr	w8, [x19]
	cbz	w8, .LBB105_157
// %bb.155:                             //   in Loop: Header=BB105_124 Depth=3
	ldr	x8, [x23, #16]
	mov	x1, x24
	ldr	x0, [x23, #40]
	mov	x22, x24
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB105_158
// %bb.156:                             //   in Loop: Header=BB105_124 Depth=3
	mov	x8, x23
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_159
.LBB105_157:                            //   in Loop: Header=BB105_124 Depth=3
	mov	w24, wzr
	bfi	w24, w20, #8, #8
	b	.LBB105_160
.LBB105_158:                            //   in Loop: Header=BB105_124 Depth=3
	mov	w24, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
.LBB105_159:                            //   in Loop: Header=BB105_124 Depth=3
	ldur	x9, [x29, #-48]                 // 8-byte Folded Reload
	str	x27, [x21]
	bfi	w24, w20, #8, #8
	str	x8, [x9]
.LBB105_160:                            //   in Loop: Header=BB105_124 Depth=3
	ldr	w8, [sp, #24]                   // 4-byte Folded Reload
	cmp	w24, w8
	b.gt	.LBB105_208
// %bb.161:                             //   in Loop: Header=BB105_124 Depth=3
	ldrb	w20, [x26]
	sub	x2, x29, #36
	mov	x0, x23
	mov	w1, w20
	bl	_ZL13stbi__readvalP13stbi__contextiPh
	cbz	x0, .LBB105_210
// %bb.162:                             //   in Loop: Header=BB105_124 Depth=3
	subs	w8, w24, #1
	b.lt	.LBB105_173
// %bb.163:                             //   in Loop: Header=BB105_124 Depth=3
	add	x28, x28, #4
	tbnz	w20, #7, .LBB105_168
.LBB105_164:                            //   in Loop: Header=BB105_124 Depth=3
	and	w9, w20, #0xff
	tbnz	w9, #6, .LBB105_169
.LBB105_165:                            //   in Loop: Header=BB105_124 Depth=3
	tbnz	w9, #5, .LBB105_170
.LBB105_166:                            //   in Loop: Header=BB105_124 Depth=3
	tbnz	w9, #4, .LBB105_171
.LBB105_167:                            //   in Loop: Header=BB105_124 Depth=3
	cbnz	w8, .LBB105_172
	b	.LBB105_173
.LBB105_168:                            //   in Loop: Header=BB105_124 Depth=3
	ldurb	w9, [x29, #-36]
	sturb	w9, [x28, #-4]
	and	w9, w20, #0xff
	tbz	w9, #6, .LBB105_165
.LBB105_169:                            //   in Loop: Header=BB105_124 Depth=3
	ldurb	w10, [x29, #-35]
	sturb	w10, [x28, #-3]
	tbz	w9, #5, .LBB105_166
.LBB105_170:                            //   in Loop: Header=BB105_124 Depth=3
	ldurb	w10, [x29, #-34]
	sturb	w10, [x28, #-2]
	tbz	w9, #4, .LBB105_167
.LBB105_171:                            //   in Loop: Header=BB105_124 Depth=3
	ldurb	w9, [x29, #-33]
	sturb	w9, [x28, #-1]
	cbz	w8, .LBB105_173
.LBB105_172:                            //   in Loop: Header=BB105_124 Depth=3
	ldrb	w20, [x26]
	sub	w8, w8, #1
	add	x28, x28, #4
	tbz	w20, #7, .LBB105_164
	b	.LBB105_168
.LBB105_173:                            //   in Loop: Header=BB105_124 Depth=3
	ldr	w8, [sp, #24]                   // 4-byte Folded Reload
	sub	w8, w8, w24
	cmp	w8, #0
	str	w8, [sp, #24]                   // 4-byte Folded Spill
	b.gt	.LBB105_124
	b	.LBB105_118
.LBB105_174:                            //   in Loop: Header=BB105_119 Depth=2
	ldr	w8, [sp, #56]                   // 4-byte Folded Reload
	cbz	w8, .LBB105_118
// %bb.175:                             //   in Loop: Header=BB105_119 Depth=2
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	sub	x9, x29, #32
	ldr	w22, [sp, #56]                  // 4-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	add	x8, x8, x8, lsl #1
	add	x8, x9, x8
	ldrb	w20, [x8, #2]
.LBB105_176:                            //   Parent Loop BB105_117 Depth=1
                                        //     Parent Loop BB105_119 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	mov	x0, x23
	mov	w1, w20
	mov	x2, x28
	bl	_ZL13stbi__readvalP13stbi__contextiPh
	cbz	x0, .LBB105_210
// %bb.177:                             //   in Loop: Header=BB105_176 Depth=3
	add	x28, x28, #4
	subs	w22, w22, #1
	b.ne	.LBB105_176
	b	.LBB105_118
.LBB105_178:                            //   in Loop: Header=BB105_119 Depth=2
	cbz	w9, .LBB105_118
// %bb.179:                             //   in Loop: Header=BB105_119 Depth=2
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	sub	x9, x29, #32
	ldr	w24, [sp, #56]                  // 4-byte Folded Reload
	ldr	x26, [sp, #16]                  // 8-byte Folded Reload
	add	x8, x8, x8, lsl #1
	add	x8, x9, x8
	add	x20, x8, #2
	b	.LBB105_181
.LBB105_180:                            //   in Loop: Header=BB105_181 Depth=3
	sub	w24, w24, w8
	cmp	w24, #0
	b.le	.LBB105_118
.LBB105_181:                            //   Parent Loop BB105_117 Depth=1
                                        //     Parent Loop BB105_119 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldur	x8, [x29, #-48]                 // 8-byte Folded Reload
	ldr	x9, [x21]
	ldr	x8, [x8]
	cmp	x9, x8
	b.hs	.LBB105_183
// %bb.182:                             //   in Loop: Header=BB105_181 Depth=3
	add	x10, x9, #1
	str	x10, [x21]
	ldrb	w22, [x9]
	mov	x9, x10
	ldr	x10, [x23, #16]
	cbnz	x10, .LBB105_189
	b	.LBB105_192
.LBB105_183:                            //   in Loop: Header=BB105_181 Depth=3
	ldr	w10, [x19]
	cbz	w10, .LBB105_186
// %bb.184:                             //   in Loop: Header=BB105_181 Depth=3
	ldur	x22, [x29, #-56]                // 8-byte Folded Reload
	ldr	x8, [x23, #16]
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	mov	x1, x22
	blr	x8
	cbz	w0, .LBB105_187
// %bb.185:                             //   in Loop: Header=BB105_181 Depth=3
	mov	x8, x23
	ldrb	w22, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB105_188
.LBB105_186:                            //   in Loop: Header=BB105_181 Depth=3
	mov	w22, wzr
	ldr	x10, [x23, #16]
	cbnz	x10, .LBB105_189
	b	.LBB105_192
.LBB105_187:                            //   in Loop: Header=BB105_181 Depth=3
	mov	w9, wzr
	mov	x8, x27
	str	wzr, [x19]
	strb	wzr, [x22]
	mov	w22, wzr
.LBB105_188:                            //   in Loop: Header=BB105_181 Depth=3
	mov	x9, x27
	ldur	x10, [x29, #-48]                // 8-byte Folded Reload
	str	x27, [x21]
	str	x8, [x10]
	ldr	x10, [x23, #16]
	cbz	x10, .LBB105_192
.LBB105_189:                            //   in Loop: Header=BB105_181 Depth=3
	ldp	x8, x0, [x23, #32]
	blr	x8
	cbz	w0, .LBB105_193
// %bb.190:                             //   in Loop: Header=BB105_181 Depth=3
	ldr	w8, [x19]
	cbz	w8, .LBB105_208
// %bb.191:                             //   in Loop: Header=BB105_181 Depth=3
	ldur	x8, [x29, #-48]                 // 8-byte Folded Reload
	ldr	x9, [x21]
	ldr	x8, [x8]
.LBB105_192:                            //   in Loop: Header=BB105_181 Depth=3
	cmp	x9, x8
	b.hs	.LBB105_208
.LBB105_193:                            //   in Loop: Header=BB105_181 Depth=3
	ldrb	w28, [x20]
	sub	x2, x29, #36
	mov	x0, x23
	mov	w1, w28
	bl	_ZL13stbi__readvalP13stbi__contextiPh
	cbz	x0, .LBB105_210
// %bb.194:                             //   in Loop: Header=BB105_181 Depth=3
	cmp	w24, w22
	csel	w8, w24, w22, lo
	ands	w8, w8, #0xff
	b.eq	.LBB105_180
// %bb.195:                             //   in Loop: Header=BB105_181 Depth=3
	sub	w9, w8, #1
	add	x26, x26, #4
	tbnz	w28, #7, .LBB105_200
.LBB105_196:                            //   in Loop: Header=BB105_181 Depth=3
	and	w10, w28, #0xff
	tbnz	w10, #6, .LBB105_201
.LBB105_197:                            //   in Loop: Header=BB105_181 Depth=3
	tbnz	w10, #5, .LBB105_202
.LBB105_198:                            //   in Loop: Header=BB105_181 Depth=3
	tbnz	w10, #4, .LBB105_203
.LBB105_199:                            //   in Loop: Header=BB105_181 Depth=3
	cbnz	w9, .LBB105_204
	b	.LBB105_180
.LBB105_200:                            //   in Loop: Header=BB105_181 Depth=3
	ldurb	w10, [x29, #-36]
	sturb	w10, [x26, #-4]
	and	w10, w28, #0xff
	tbz	w10, #6, .LBB105_197
.LBB105_201:                            //   in Loop: Header=BB105_181 Depth=3
	ldurb	w11, [x29, #-35]
	sturb	w11, [x26, #-3]
	tbz	w10, #5, .LBB105_198
.LBB105_202:                            //   in Loop: Header=BB105_181 Depth=3
	ldurb	w11, [x29, #-34]
	sturb	w11, [x26, #-2]
	tbz	w10, #4, .LBB105_199
.LBB105_203:                            //   in Loop: Header=BB105_181 Depth=3
	ldurb	w10, [x29, #-33]
	sturb	w10, [x26, #-1]
	cbz	w9, .LBB105_180
.LBB105_204:                            //   in Loop: Header=BB105_181 Depth=3
	ldrb	w28, [x20]
	sub	w9, w9, #1
	add	x26, x26, #4
	tbnz	w28, #7, .LBB105_200
	b	.LBB105_196
.LBB105_205:                            //   in Loop: Header=BB105_117 Depth=1
	ldr	x9, [sp, #8]                    // 8-byte Folded Reload
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	add	x9, x9, #1
	cmp	x9, x8
	b.ne	.LBB105_117
.LBB105_206:
	ldr	x0, [sp, #32]                   // 8-byte Folded Reload
	cbnz	x0, .LBB105_212
	b	.LBB105_211
.LBB105_207:
	adrp	x9, .L.str.95
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.95
	b	.LBB105_209
.LBB105_208:
	adrp	x9, .L.str.94
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.94
.LBB105_209:
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB105_210:
	ldur	x20, [x29, #-64]                // 8-byte Folded Reload
	ldr	x22, [sp, #72]                  // 8-byte Folded Reload
	ldr	x0, [sp, #32]                   // 8-byte Folded Reload
.LBB105_211:
	bl	free
	mov	x0, xzr
.LBB105_212:
	ldp	x8, x4, [sp, #40]               // 16-byte Folded Reload
	ldp	w3, w2, [sp, #56]               // 8-byte Folded Reload
	str	w3, [x22]
	str	w4, [x20]
	cbnz	w2, .LBB105_214
// %bb.213:
	ldr	w2, [x8]
.LBB105_214:
	mov	w1, #4
                                        // kill: def $w4 killed $w4 killed $x4
	bl	_ZL20stbi__convert_formatPhiijj
.LBB105_215:
	ldp	x20, x19, [sp, #224]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #208]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #192]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #176]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #160]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	add	sp, sp, #240
	ret
.Lfunc_end105:
	.size	_ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i, .Lfunc_end105-_ZL14stbi__pic_loadP13stbi__contextPiS1_S1_i
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__pnm_testP13stbi__context
	.type	_ZL14stbi__pnm_testP13stbi__context,@function
_ZL14stbi__pnm_testP13stbi__context:    // @_ZL14stbi__pnm_testP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldp	x9, x8, [x0, #184]
	mov	x19, x0
	cmp	x9, x8
	b.hs	.LBB106_2
// %bb.1:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB106_6
	b	.LBB106_11
.LBB106_2:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB106_5
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB106_9
// %bb.4:
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB106_10
.LBB106_5:
	mov	w20, wzr
	cmp	x9, x8
	b.lo	.LBB106_11
.LBB106_6:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB106_16
// %bb.7:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB106_12
// %bb.8:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB106_13
.LBB106_9:
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB106_10:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB106_6
.LBB106_11:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	cmp	w20, #80
	b.eq	.LBB106_14
	b	.LBB106_16
.LBB106_12:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB106_13:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
	cmp	w20, #80
	b.ne	.LBB106_16
.LBB106_14:
	sub	w8, w8, #55
	cmn	w8, #3
	b.ls	.LBB106_16
// %bb.15:
	mov	w0, #1
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB106_16:
	ldr	x8, [x19, #200]
	mov	w0, wzr
	str	x8, [x19, #184]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end106:
	.size	_ZL14stbi__pnm_testP13stbi__context, .Lfunc_end106-_ZL14stbi__pnm_testP13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i
	.type	_ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i,@function
_ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i: // @_ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	add	x22, x0, #8
	mov	x21, x3
	mov	x23, x2
	mov	x24, x1
	add	x2, x0, #4
	mov	x1, x0
	mov	x3, x22
	mov	w19, w4
	mov	x20, x0
	bl	_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_
	cbz	w0, .LBB107_5
// %bb.1:
	ldr	w8, [x20]
	str	w8, [x24]
	ldr	w8, [x20, #4]
	str	w8, [x23]
	ldr	w8, [x20, #8]
	str	w8, [x21]
	ldp	w10, w8, [x20, #4]
	ldr	w9, [x20]
	mul	w8, w9, w8
	mul	w23, w8, w10
	mov	x0, x23
	bl	malloc
	mov	x21, x0
	cbz	x0, .LBB107_6
// %bb.2:
	ldr	x25, [x20, #16]
	cbz	x25, .LBB107_7
// %bb.3:
	ldp	x1, x8, [x20, #184]
	sub	x9, x8, x1
	subs	w24, w23, w9
	b.le	.LBB107_8
// %bb.4:
	sxtw	x23, w9
	mov	x0, x21
	mov	x2, x23
	bl	memcpy
	ldr	x0, [x20, #40]
	add	x1, x21, x23
	mov	w2, w24
	blr	x25
	ldr	x8, [x20, #192]
	str	x8, [x20, #184]
	b	.LBB107_10
.LBB107_5:
	mov	x21, xzr
	b	.LBB107_13
.LBB107_6:
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB107_13
.LBB107_7:
	ldp	x1, x8, [x20, #184]
.LBB107_8:
                                        // kill: def $w23 killed $w23 killed $x23 def $x23
	sxtw	x2, w23
	add	x23, x1, x2
	cmp	x23, x8
	b.hi	.LBB107_10
// %bb.9:
	mov	x0, x21
	bl	memcpy
	str	x23, [x20, #184]
.LBB107_10:
	cbz	w19, .LBB107_13
// %bb.11:
	ldr	w1, [x22]
	cmp	w1, w19
	b.eq	.LBB107_13
// %bb.12:
	ldp	w3, w4, [x20]
	mov	x0, x21
	mov	w2, w19
	bl	_ZL20stbi__convert_formatPhiijj
	mov	x21, x0
.LBB107_13:
	mov	x0, x21
	ldr	x25, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.Lfunc_end107:
	.size	_ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i, .Lfunc_end107-_ZL14stbi__pnm_loadP13stbi__contextPiS1_S1_i
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i
	.type	_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i,@function
_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i: // @_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	str	d8, [sp, #-112]!                // 8-byte Folded Spill
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x28, x27, [sp, #32]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	sub	sp, sp, #1120
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -112
	mov	x25, x1
	add	x1, sp, #88
	mov	w21, w4
	mov	x23, x3
	mov	x24, x2
	mov	x19, x0
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	mov	x10, #16163
	mov	x11, #17473
	ldr	x8, [sp, #88]
	movk	x10, #16722, lsl #16
	ldur	x9, [sp, #91]
	movk	x11, #16713, lsl #16
	movk	x10, #18756, lsl #32
	movk	x11, #17230, lsl #32
	movk	x10, #20033, lsl #48
	movk	x11, #69, lsl #48
	eor	x8, x8, x10
	eor	x9, x9, x11
	orr	x8, x8, x9
	cbz	x8, .LBB108_2
// %bb.1:
	adrp	x9, .L.str.98
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.98
	b	.LBB108_12
.LBB108_2:
	add	x1, sp, #88
	mov	x0, x19
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	ldrb	w8, [sp, #88]
	cbz	w8, .LBB108_11
// %bb.3:
	mov	x22, #20294
	mov	x26, #11570
	mov	x27, #25964
	movk	x22, #19794, lsl #16
	movk	x26, #26978, lsl #16
	movk	x27, #29279, lsl #16
	movk	x22, #21569, lsl #32
	movk	x26, #24436, lsl #32
	movk	x27, #25191, lsl #32
	mov	w20, wzr
	movk	x22, #13117, lsl #48
	movk	x26, #27762, lsl #48
	movk	x27, #101, lsl #48
.LBB108_4:                              // =>This Inner Loop Header: Depth=1
	ldp	x8, x9, [sp, #88]
	add	x1, sp, #88
	mov	x0, x19
	ldur	x10, [sp, #103]
	eor	x8, x8, x22
	eor	x9, x9, x26
	eor	x10, x10, x27
	orr	x8, x8, x9
	orr	x8, x8, x10
	cmp	x8, #0
	csinc	w20, w20, wzr, ne
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	ldrb	w8, [sp, #88]
	cbnz	w8, .LBB108_4
// %bb.5:
	cbz	w20, .LBB108_11
// %bb.6:
	add	x1, sp, #88
	mov	x0, x19
	add	x20, sp, #88
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	ldrh	w8, [sp, #88]
	mov	w10, #22829
	ldrb	w9, [sp, #90]
	eor	w8, w8, w10
	eor	w9, w9, #0x20
	orr	w8, w8, w9
	cbnz	w8, .LBB108_10
// %bb.7:
	orr	x0, x20, #0x3
	sub	x1, x29, #8
	mov	w2, #10
	stur	x0, [x29, #-8]
	bl	strtol
	ldur	x8, [x29, #-8]
	mov	x28, x0
	sub	x22, x8, #1
.LBB108_8:                              // =>This Inner Loop Header: Depth=1
	ldrb	w8, [x22, #1]!
	cmp	w8, #32
	b.eq	.LBB108_8
// %bb.9:
	adrp	x1, .L.str.103
	mov	x0, x22
	add	x1, x1, :lo12:.L.str.103
	mov	w2, #3
	bl	strncmp
	cbz	w0, .LBB108_14
.LBB108_10:
	adrp	x9, .L.str.102
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.102
	b	.LBB108_12
.LBB108_11:
	adrp	x9, .L.str.100
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.100
.LBB108_12:
	mov	x24, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB108_13:
	mov	x0, x24
	add	sp, sp, #1120
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	d8, [sp], #112                  // 8-byte Folded Reload
	ret
.LBB108_14:
	add	x0, x22, #3
	mov	x1, xzr
	mov	w2, #10
	stur	x0, [x29, #-8]
	bl	strtol
	mov	x22, x0
	str	w22, [x25]
	str	w28, [x24]
	cbz	x23, .LBB108_16
// %bb.15:
	mov	w8, #3
	str	w8, [x23]
.LBB108_16:
	cmp	w21, #0
	mov	w8, #3
	csel	w23, w8, w21, eq
	mul	w27, w23, w22
	mul	w8, w27, w28
	sbfiz	x0, x8, #2, #32
	bl	malloc
	mov	x24, x0
	mov	w20, wzr
	sub	w8, w22, #8, lsl #12            // =32768
	mov	w9, #-32760
	cmp	w8, w9
	str	x0, [sp, #64]                   // 8-byte Folded Spill
	b.lo	.LBB108_110
// %bb.17:
	mov	x24, xzr
	cmp	w28, #1
	b.lt	.LBB108_106
// %bb.18:
	lsl	w9, w22, #2
	and	x10, x28, #0xffffffff
	smull	x8, w22, w23
	mov	x21, xzr
	mov	x24, xzr
	add	x25, x19, #56
	stp	x28, x9, [sp, #8]               // 16-byte Folded Spill
	and	x9, x22, #0xffffffff
	add	x26, x19, #57
	sbfiz	x28, x23, #2, #32
	fmov	s8, #3.00000000
	str	w27, [sp, #4]                   // 4-byte Folded Spill
	stp	x9, x10, [sp, #40]              // 16-byte Folded Spill
	lsl	x9, x8, #2
	ldr	x8, [sp, #64]                   // 8-byte Folded Reload
	stp	x28, x9, [sp, #24]              // 16-byte Folded Spill
	str	x8, [sp, #72]                   // 8-byte Folded Spill
	b	.LBB108_20
.LBB108_19:                             //   in Loop: Header=BB108_20 Depth=1
	ldr	x8, [sp, #32]                   // 8-byte Folded Reload
	ldr	x9, [sp, #72]                   // 8-byte Folded Reload
	add	x9, x9, x8
	ldp	x8, x21, [sp, #48]              // 16-byte Folded Reload
	add	x21, x21, #1
	cmp	x21, x8
	str	x9, [sp, #72]                   // 8-byte Folded Spill
	b.eq	.LBB108_106
.LBB108_20:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB108_56 Depth 2
                                        //       Child Loop BB108_59 Depth 3
                                        //         Child Loop BB108_87 Depth 4
                                        //         Child Loop BB108_90 Depth 4
                                        //     Child Loop BB108_94 Depth 2
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB108_22
// %bb.21:                              //   in Loop: Header=BB108_20 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w27, [x9]
	mov	x9, x10
	b	.LBB108_27
.LBB108_22:                             //   in Loop: Header=BB108_20 Depth=1
	ldr	w10, [x19, #48]
	mov	w27, wzr
	cbz	w10, .LBB108_27
// %bb.23:                              //   in Loop: Header=BB108_20 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_25
// %bb.24:                              //   in Loop: Header=BB108_20 Depth=1
	mov	x8, x19
	ldrb	w27, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB108_26
.LBB108_25:                             //   in Loop: Header=BB108_20 Depth=1
	mov	w27, wzr
	mov	x8, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB108_26:                             //   in Loop: Header=BB108_20 Depth=1
	mov	x9, x26
	stp	x26, x8, [x19, #184]
.LBB108_27:                             //   in Loop: Header=BB108_20 Depth=1
	cmp	x9, x8
	b.hs	.LBB108_29
// %bb.28:                              //   in Loop: Header=BB108_20 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w28, [x9]
	mov	x9, x10
	b	.LBB108_34
.LBB108_29:                             //   in Loop: Header=BB108_20 Depth=1
	ldr	w10, [x19, #48]
	mov	w28, wzr
	cbz	w10, .LBB108_34
// %bb.30:                              //   in Loop: Header=BB108_20 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_32
// %bb.31:                              //   in Loop: Header=BB108_20 Depth=1
	mov	x8, x19
	ldrb	w28, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB108_33
.LBB108_32:                             //   in Loop: Header=BB108_20 Depth=1
	mov	w28, wzr
	mov	x8, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB108_33:                             //   in Loop: Header=BB108_20 Depth=1
	mov	x9, x26
	stp	x26, x8, [x19, #184]
.LBB108_34:                             //   in Loop: Header=BB108_20 Depth=1
	cmp	x9, x8
	b.hs	.LBB108_36
// %bb.35:                              //   in Loop: Header=BB108_20 Depth=1
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB108_41
.LBB108_36:                             //   in Loop: Header=BB108_20 Depth=1
	ldr	w11, [x19, #48]
	mov	w10, wzr
	cbz	w11, .LBB108_41
// %bb.37:                              //   in Loop: Header=BB108_20 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_39
// %bb.38:                              //   in Loop: Header=BB108_20 Depth=1
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB108_40
.LBB108_39:                             //   in Loop: Header=BB108_20 Depth=1
	mov	w10, wzr
	mov	x8, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB108_40:                             //   in Loop: Header=BB108_20 Depth=1
	mov	x9, x26
	stp	x26, x8, [x19, #184]
.LBB108_41:                             //   in Loop: Header=BB108_20 Depth=1
	and	w11, w10, #0x80
	cmp	w27, #2
	b.ne	.LBB108_107
// %bb.42:                              //   in Loop: Header=BB108_20 Depth=1
	cmp	w28, #2
	b.ne	.LBB108_107
// %bb.43:                              //   in Loop: Header=BB108_20 Depth=1
	cbnz	w11, .LBB108_107
// %bb.44:                              //   in Loop: Header=BB108_20 Depth=1
	lsl	w20, w10, #8
	cmp	x9, x8
	b.hs	.LBB108_46
// %bb.45:                              //   in Loop: Header=BB108_20 Depth=1
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB108_51
.LBB108_46:                             //   in Loop: Header=BB108_20 Depth=1
	ldr	w9, [x19, #48]
	mov	w8, wzr
	cbz	w9, .LBB108_51
// %bb.47:                              //   in Loop: Header=BB108_20 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_49
// %bb.48:                              //   in Loop: Header=BB108_20 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB108_50
.LBB108_49:                             //   in Loop: Header=BB108_20 Depth=1
	mov	w8, wzr
	mov	x9, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB108_50:                             //   in Loop: Header=BB108_20 Depth=1
	stp	x26, x9, [x19, #184]
.LBB108_51:                             //   in Loop: Header=BB108_20 Depth=1
	orr	w8, w20, w8
	cmp	w8, w22
	b.ne	.LBB108_108
// %bb.52:                              //   in Loop: Header=BB108_20 Depth=1
	cbnz	x24, .LBB108_54
// %bb.53:                              //   in Loop: Header=BB108_20 Depth=1
	ldr	x0, [sp, #16]                   // 8-byte Folded Reload
	bl	malloc
	mov	x24, x0
.LBB108_54:                             //   in Loop: Header=BB108_20 Depth=1
	mov	w28, wzr
	str	x21, [sp, #56]                  // 8-byte Folded Spill
	b	.LBB108_56
.LBB108_55:                             //   in Loop: Header=BB108_56 Depth=2
	add	w28, w28, #1
	cmp	w28, #4
	b.eq	.LBB108_91
.LBB108_56:                             //   Parent Loop BB108_20 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB108_59 Depth 3
                                        //         Child Loop BB108_87 Depth 4
                                        //         Child Loop BB108_90 Depth 4
	mov	w27, wzr
	b	.LBB108_59
.LBB108_57:                             //   in Loop: Header=BB108_59 Depth=3
	add	w27, w27, w9
.LBB108_58:                             //   in Loop: Header=BB108_59 Depth=3
	cmp	w27, w22
	b.ge	.LBB108_55
.LBB108_59:                             //   Parent Loop BB108_20 Depth=1
                                        //     Parent Loop BB108_56 Depth=2
                                        // =>    This Loop Header: Depth=3
                                        //         Child Loop BB108_87 Depth 4
                                        //         Child Loop BB108_90 Depth 4
	ldp	x10, x8, [x19, #184]
	cmp	x10, x8
	b.hs	.LBB108_63
// %bb.60:                              //   in Loop: Header=BB108_59 Depth=3
	add	x9, x10, #1
	str	x9, [x19, #184]
	ldrb	w21, [x10]
	cmp	w21, #128
	b.ls	.LBB108_66
.LBB108_61:                             //   in Loop: Header=BB108_59 Depth=3
	cmp	x9, x8
	b.hs	.LBB108_76
// %bb.62:                              //   in Loop: Header=BB108_59 Depth=3
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB108_82
.LBB108_63:                             //   in Loop: Header=BB108_59 Depth=3
	ldr	w8, [x19, #48]
	cbz	w8, .LBB108_58
// %bb.64:                              //   in Loop: Header=BB108_59 Depth=3
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_79
// %bb.65:                              //   in Loop: Header=BB108_59 Depth=3
	mov	x8, x19
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x26
	stp	x26, x8, [x19, #184]
	cmp	w21, #128
	b.hi	.LBB108_61
.LBB108_66:                             //   in Loop: Header=BB108_59 Depth=3
	cbz	w21, .LBB108_58
// %bb.67:                              //   in Loop: Header=BB108_59 Depth=3
	add	w20, w28, w27, lsl #2
	add	w27, w27, #1
	sub	w21, w21, #1
	cmp	x9, x8
	b.hs	.LBB108_69
.LBB108_68:                             //   in Loop: Header=BB108_59 Depth=3
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB108_74
.LBB108_69:                             //   in Loop: Header=BB108_59 Depth=3
	ldr	w9, [x19, #48]
	mov	w8, wzr
	cbz	w9, .LBB108_74
// %bb.70:                              //   in Loop: Header=BB108_59 Depth=3
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_72
// %bb.71:                              //   in Loop: Header=BB108_59 Depth=3
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB108_73
.LBB108_72:                             //   in Loop: Header=BB108_59 Depth=3
	mov	w8, wzr
	mov	x9, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB108_73:                             //   in Loop: Header=BB108_59 Depth=3
	stp	x26, x9, [x19, #184]
.LBB108_74:                             //   in Loop: Header=BB108_59 Depth=3
	strb	w8, [x24, w20, sxtw]
	cbz	w21, .LBB108_58
// %bb.75:                              //   in Loop: Header=BB108_59 Depth=3
	ldp	x9, x8, [x19, #184]
	add	w20, w20, #4
	add	w27, w27, #1
	sub	w21, w21, #1
	cmp	x9, x8
	b.hs	.LBB108_69
	b	.LBB108_68
.LBB108_76:                             //   in Loop: Header=BB108_59 Depth=3
	ldr	w9, [x19, #48]
	mov	w8, wzr
	cbz	w9, .LBB108_82
// %bb.77:                              //   in Loop: Header=BB108_59 Depth=3
	ldr	x8, [x19, #16]
	mov	x1, x25
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB108_80
// %bb.78:                              //   in Loop: Header=BB108_59 Depth=3
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB108_81
.LBB108_79:                             //   in Loop: Header=BB108_59 Depth=3
	mov	w21, wzr
	mov	x8, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x9, x26
	stp	x26, x8, [x19, #184]
	cmp	w21, #128
	b.hi	.LBB108_61
	b	.LBB108_66
.LBB108_80:                             //   in Loop: Header=BB108_59 Depth=3
	mov	w8, wzr
	mov	x9, x26
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB108_81:                             //   in Loop: Header=BB108_59 Depth=3
	stp	x26, x9, [x19, #184]
.LBB108_82:                             //   in Loop: Header=BB108_59 Depth=3
	eor	w9, w21, #0x80
	cbz	w9, .LBB108_58
// %bb.83:                              //   in Loop: Header=BB108_59 Depth=3
	subs	w14, w9, #1
	mov	w11, w27
	add	x12, x14, #1
	mov	w10, wzr
	b.eq	.LBB108_89
// %bb.84:                              //   in Loop: Header=BB108_59 Depth=3
	lsl	x15, x14, #2
	lsl	w13, w27, #2
	tst	x15, #0xffffffff00000000
	add	w16, w28, w13
	cset	w14, ne
	add	w15, w16, w15
	cmp	w15, w16
	b.lt	.LBB108_89
// %bb.85:                              //   in Loop: Header=BB108_59 Depth=3
	tbnz	w14, #0, .LBB108_89
// %bb.86:                              //   in Loop: Header=BB108_59 Depth=3
	and	x10, x12, #0x1fffffffe
	add	w13, w28, w13
	add	x11, x10, x11
	mov	x14, x10
.LBB108_87:                             //   Parent Loop BB108_20 Depth=1
                                        //     Parent Loop BB108_56 Depth=2
                                        //       Parent Loop BB108_59 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	add	w15, w13, #4
	strb	w8, [x24, w13, sxtw]
	subs	x14, x14, #2
	add	w13, w13, #8
	strb	w8, [x24, w15, sxtw]
	b.ne	.LBB108_87
// %bb.88:                              //   in Loop: Header=BB108_59 Depth=3
	cmp	x12, x10
	b.eq	.LBB108_57
.LBB108_89:                             //   in Loop: Header=BB108_59 Depth=3
	add	w11, w28, w11, lsl #2
	sub	w10, w9, w10
.LBB108_90:                             //   Parent Loop BB108_20 Depth=1
                                        //     Parent Loop BB108_56 Depth=2
                                        //       Parent Loop BB108_59 Depth=3
                                        // =>      This Inner Loop Header: Depth=4
	strb	w8, [x24, w11, sxtw]
	add	w11, w11, #4
	subs	w10, w10, #1
	b.ne	.LBB108_90
	b	.LBB108_57
.LBB108_91:                             //   in Loop: Header=BB108_20 Depth=1
	add	x21, x24, #1
	ldr	x27, [sp, #40]                  // 8-byte Folded Reload
	ldr	x20, [sp, #72]                  // 8-byte Folded Reload
	ldr	x28, [sp, #24]                  // 8-byte Folded Reload
	b	.LBB108_94
.LBB108_92:                             //   in Loop: Header=BB108_94 Depth=2
	mov	w8, #1065353216
	str	w8, [x20, #12]
.LBB108_93:                             //   in Loop: Header=BB108_94 Depth=2
	add	x20, x20, x28
	subs	x27, x27, #1
	add	x21, x21, #4
	b.eq	.LBB108_19
.LBB108_94:                             //   Parent Loop BB108_20 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w8, [x21, #2]
	cbz	w8, .LBB108_97
// %bb.95:                              //   in Loop: Header=BB108_94 Depth=2
	sub	w0, w8, #136
	fmov	s0, #1.00000000
	bl	ldexpf
	ldurb	w8, [x21, #-1]
	cmp	w23, #2
	b.gt	.LBB108_100
// %bb.96:                              //   in Loop: Header=BB108_94 Depth=2
	ldrb	w9, [x21]
	ldrb	w10, [x21, #1]
	add	w8, w9, w8
	add	w8, w8, w10
	scvtf	s1, w8
	fmul	s0, s0, s1
	fdiv	s0, s0, s8
	str	s0, [x20]
	cmp	w23, #4
	b.ne	.LBB108_101
	b	.LBB108_92
.LBB108_97:                             //   in Loop: Header=BB108_94 Depth=2
	sub	w8, w23, #1
	cmp	w8, #3
	b.hi	.LBB108_93
// %bb.98:                              //   in Loop: Header=BB108_94 Depth=2
	adrp	x11, .LJTI108_0
	add	x11, x11, :lo12:.LJTI108_0
	adr	x9, .LBB108_99
	ldrb	w10, [x11, x8]
	add	x9, x9, x10, lsl #2
	br	x9
.LBB108_99:                             //   in Loop: Header=BB108_94 Depth=2
	mov	w8, #1065353216
	str	w8, [x20, #4]
	b	.LBB108_105
.LBB108_100:                            //   in Loop: Header=BB108_94 Depth=2
	ucvtf	s1, w8
	fmul	s1, s0, s1
	str	s1, [x20]
	ldr	b1, [x21]
	ucvtf	s1, s1
	fmul	s1, s0, s1
	str	s1, [x20, #4]
	ldr	b1, [x21, #1]
	ucvtf	s1, s1
	fmul	s0, s0, s1
	str	s0, [x20, #8]
	cmp	w23, #4
	b.eq	.LBB108_92
.LBB108_101:                            //   in Loop: Header=BB108_94 Depth=2
	cmp	w23, #2
	b.ne	.LBB108_93
// %bb.102:                             //   in Loop: Header=BB108_94 Depth=2
	mov	w8, #1065353216
	str	w8, [x20, #4]
	b	.LBB108_93
.LBB108_103:                            //   in Loop: Header=BB108_94 Depth=2
	mov	w8, #1065353216
	str	w8, [x20, #12]
.LBB108_104:                            //   in Loop: Header=BB108_94 Depth=2
	stp	wzr, wzr, [x20, #4]
.LBB108_105:                            //   in Loop: Header=BB108_94 Depth=2
	str	wzr, [x20]
	b	.LBB108_93
.LBB108_106:
	mov	x0, x24
	bl	free
	ldr	x24, [sp, #64]                  // 8-byte Folded Reload
	b	.LBB108_13
.LBB108_107:
	mov	x0, x19
	strb	w27, [sp, #80]
	strb	w28, [sp, #81]
	strb	w10, [sp, #82]
	bl	_ZL10stbi__get8P13stbi__context
	ldr	x20, [sp, #64]                  // 8-byte Folded Reload
	strb	w0, [sp, #83]
	add	x1, sp, #80
	mov	w2, w23
	mov	x0, x20
	bl	_ZL17stbi__hdr_convertPfPhi
	mov	x0, x24
	mov	x24, x20
	bl	free
	ldr	x28, [sp, #8]                   // 8-byte Folded Reload
	mov	w20, wzr
	ldr	w27, [sp, #4]                   // 4-byte Folded Reload
	mov	w25, #1
	b	.LBB108_112
.LBB108_108:
	ldr	x0, [sp, #64]                   // 8-byte Folded Reload
	bl	free
	mov	x0, x24
	bl	free
	adrp	x9, .L.str.104
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.104
	b	.LBB108_12
.LBB108_109:
	add	w20, w20, #1
.LBB108_110:
	mov	w25, wzr
	cmp	w20, w28
	b.ge	.LBB108_13
.LBB108_111:
	cmp	w25, w22
	b.ge	.LBB108_109
.LBB108_112:
	ldr	x21, [x19, #16]
	cbz	x21, .LBB108_115
// %bb.113:
	ldp	x1, x8, [x19, #184]
	sub	x26, x8, x1
	cmp	w26, #3
	b.gt	.LBB108_116
// %bb.114:
	sxtw	x24, w26
	add	x0, sp, #84
	mov	x2, x24
	bl	memcpy
	mov	w8, #4
	add	x9, sp, #84
	ldr	x0, [x19, #40]
	add	x1, x9, x24
	sub	w2, w8, w26
	ldr	x24, [sp, #64]                  // 8-byte Folded Reload
	blr	x21
	ldr	x8, [x19, #192]
	str	x8, [x19, #184]
	b	.LBB108_118
.LBB108_115:
	ldp	x1, x8, [x19, #184]
.LBB108_116:
	add	x9, x1, #4
	cmp	x9, x8
	b.hi	.LBB108_118
// %bb.117:
	ldr	w8, [x1]
	str	x9, [x19, #184]
	str	w8, [sp, #84]
.LBB108_118:
	mul	w8, w27, w20
	mul	w9, w25, w23
	add	x10, x24, w8, sxtw #2
	ldrb	w8, [sp, #87]
	add	x21, x10, w9, sxtw #2
	cbz	w8, .LBB108_123
// %bb.119:
	sub	w0, w8, #136
	fmov	s0, #1.00000000
	bl	ldexpf
	ldrb	w8, [sp, #84]
	cmp	w23, #2
	b.gt	.LBB108_126
// %bb.120:
	ldrb	w9, [sp, #85]
	ldrb	w10, [sp, #86]
	add	w8, w9, w8
	add	w8, w8, w10
	scvtf	s1, w8
	fmul	s0, s0, s1
	fmov	s1, #3.00000000
	fdiv	s0, s0, s1
	str	s0, [x21]
	cmp	w23, #4
	b.eq	.LBB108_127
.LBB108_121:
	cmp	w23, #2
	b.ne	.LBB108_131
// %bb.122:
	mov	w8, #1065353216
	add	w25, w25, #1
	str	w8, [x21, #4]
	b	.LBB108_111
.LBB108_123:
	sub	w8, w23, #1
	cmp	w8, #3
	b.hi	.LBB108_131
// %bb.124:
	adrp	x9, .LJTI108_1
	add	x9, x9, :lo12:.LJTI108_1
	adr	x10, .LBB108_125
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB108_125:
	mov	w8, #1065353216
	str	w8, [x21, #4]
	b	.LBB108_130
.LBB108_126:
	ldr	b1, [sp, #85]
	ucvtf	s3, w8
	ldr	b2, [sp, #86]
	ucvtf	s1, s1
	ucvtf	s2, s2
	fmul	s3, s0, s3
	fmul	s1, s0, s1
	fmul	s0, s0, s2
	str	s3, [x21]
	str	s1, [x21, #4]
	str	s0, [x21, #8]
	cmp	w23, #4
	b.ne	.LBB108_121
.LBB108_127:
	mov	w8, #1065353216
	add	w25, w25, #1
	str	w8, [x21, #12]
	b	.LBB108_111
.LBB108_128:
	mov	w8, #1065353216
	str	w8, [x21, #12]
.LBB108_129:
	stp	wzr, wzr, [x21, #4]
.LBB108_130:
	str	wzr, [x21]
.LBB108_131:
	add	w25, w25, #1
	b	.LBB108_111
.Lfunc_end108:
	.size	_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i, .Lfunc_end108-_ZL14stbi__hdr_loadP13stbi__contextPiS1_S1_i
	.cfi_endproc
	.section	.rodata,"a",@progbits
.LJTI108_0:
	.byte	(.LBB108_105-.LBB108_99)>>2
	.byte	(.LBB108_99-.LBB108_99)>>2
	.byte	(.LBB108_104-.LBB108_99)>>2
	.byte	(.LBB108_103-.LBB108_99)>>2
.LJTI108_1:
	.byte	(.LBB108_130-.LBB108_125)>>2
	.byte	(.LBB108_125-.LBB108_125)>>2
	.byte	(.LBB108_129-.LBB108_125)>>2
	.byte	(.LBB108_128-.LBB108_125)>>2
                                        // -- End function
	.text
	.p2align	2                               // -- Begin function _ZL16stbi__hdr_to_ldrPfiii
	.type	_ZL16stbi__hdr_to_ldrPfiii,@function
_ZL16stbi__hdr_to_ldrPfiii:             // @_ZL16stbi__hdr_to_ldrPfiii
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	d9, d8, [sp, #64]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	.cfi_offset b8, -104
	.cfi_offset b9, -112
	mul	w22, w2, w1
	mov	x20, x0
	mov	w23, w3
	mul	w8, w22, w3
	sxtw	x0, w8
	bl	malloc
	mov	x19, x0
	cbz	x0, .LBB109_9
// %bb.1:
	cmp	w22, #1
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	b.lt	.LBB109_18
// %bb.2:
	and	w8, w23, #0x1
	add	w8, w23, w8
	sub	w11, w8, #1
	cmp	w11, #1
	b.lt	.LBB109_10
// %bb.3:
	mov	w8, w11
	movi	d9, #0000000000000000
	sxtw	x8, w8
	adrp	x26, .L_MergedGlobals+8
	ldp	x27, x21, [sp, #16]             // 16-byte Folded Reload
	mov	x24, xzr
	sxtw	x9, w23
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	sbfiz	x8, x23, #2, #32
	mov	w28, #1132396544
	fmov	s8, #0.50000000
	add	x26, x26, :lo12:.L_MergedGlobals+8
	stur	x23, [x29, #-32]                // 8-byte Folded Spill
	stp	x8, x22, [sp, #32]              // 16-byte Folded Spill
	b	.LBB109_5
.LBB109_4:                              //   in Loop: Header=BB109_5 Depth=1
	mov	x9, x22
	add	x21, x21, x22
	ldp	x8, x22, [sp, #32]              // 16-byte Folded Reload
	add	x24, x24, #1
	add	x27, x27, x8
	cmp	x24, x22
	b.eq	.LBB109_18
.LBB109_5:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB109_6 Depth 2
	mul	x8, x24, x9
	mov	x22, x9
	mov	x25, x11
	mov	x23, x11
	mov	x19, x21
	mov	x20, x27
	stur	x8, [x29, #-24]                 // 8-byte Folded Spill
.LBB109_6:                              //   Parent Loop BB109_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	s1, s2, [x26]
	ldr	s0, [x20], #4
	fmul	s0, s0, s2
	bl	powf
	fmov	s1, w28
	subs	x23, x23, #1
	fmadd	s0, s0, s1, s8
	fmax	s0, s0, s9
	fmin	s0, s0, s1
	fcvtzs	w8, s0
	strb	w8, [x19], #1
	b.ne	.LBB109_6
// %bb.7:                               //   in Loop: Header=BB109_5 Depth=1
	ldur	x23, [x29, #-32]                // 8-byte Folded Reload
	mov	x11, x25
	cmp	w11, w23
	b.ge	.LBB109_4
// %bb.8:                               //   in Loop: Header=BB109_5 Depth=1
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	fmov	s1, w28
	ldur	x9, [x29, #-24]                 // 8-byte Folded Reload
	add	x8, x9, x8
	ldp	x9, x10, [sp, #16]              // 16-byte Folded Reload
	ldr	s0, [x9, x8, lsl #2]
	fmadd	s0, s0, s1, s8
	fmax	s0, s0, s9
	fmin	s0, s0, s1
	fcvtzs	w9, s0
	strb	w9, [x10, x8]
	b	.LBB109_4
.LBB109_9:
	mov	x0, x20
	bl	free
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB109_19
.LBB109_10:
	cmp	w23, #1
	b.lt	.LBB109_18
// %bb.11:
	mov	w8, w23
	cmp	w22, #2
	b.hs	.LBB109_13
// %bb.12:
	mov	x9, xzr
	b	.LBB109_16
.LBB109_13:
	ldp	x0, x18, [sp, #16]              // 16-byte Folded Reload
	and	x9, x22, #0xfffffffe
	movi	d0, #0000000000000000
	mov	x10, xzr
	lsl	x12, x8, #1
	mov	w14, #1132396544
	fmov	s1, #0.50000000
	add	x13, x0, x8, lsl #2
	mov	x15, x9
	add	x11, x18, x8
.LBB109_14:                             // =>This Inner Loop Header: Depth=1
	lsl	x16, x10, #2
	fmov	s3, w14
	subs	x15, x15, #2
	ldr	s2, [x0, x16]
	ldr	s4, [x13, x16]
	fmadd	s2, s2, s3, s1
	fmadd	s4, s4, s3, s1
	fmax	s2, s2, s0
	fmax	s4, s4, s0
	fmin	s2, s2, s3
	fmin	s3, s4, s3
	fcvtzs	w16, s2
	fcvtzs	w17, s3
	strb	w16, [x18, x10]
	strb	w17, [x11, x10]
	add	x10, x10, x12
	b.ne	.LBB109_14
// %bb.15:
	cmp	x9, x22
	b.eq	.LBB109_18
.LBB109_16:
	mul	x10, x9, x8
	movi	d0, #0000000000000000
	sub	x9, x22, x9
	mov	w11, #1132396544
	fmov	s1, #0.50000000
	ldr	x13, [sp, #24]                  // 8-byte Folded Reload
.LBB109_17:                             // =>This Inner Loop Header: Depth=1
	ldr	x12, [sp, #16]                  // 8-byte Folded Reload
	fmov	s3, w11
	subs	x9, x9, #1
	ldr	s2, [x12, x10, lsl #2]
	fmadd	s2, s2, s3, s1
	fmax	s2, s2, s0
	fmin	s2, s2, s3
	fcvtzs	w12, s2
	strb	w12, [x13, x10]
	add	x10, x10, x8
	b.ne	.LBB109_17
.LBB109_18:
	ldr	x0, [sp, #16]                   // 8-byte Folded Reload
	bl	free
	ldr	x19, [sp, #24]                  // 8-byte Folded Reload
.LBB109_19:
	mov	x0, x19
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end109:
	.size	_ZL16stbi__hdr_to_ldrPfiii, .Lfunc_end109-_ZL16stbi__hdr_to_ldrPfiii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__tga_testP13stbi__context
	.type	_ZL14stbi__tga_testP13stbi__context,@function
_ZL14stbi__tga_testP13stbi__context:    // @_ZL14stbi__tga_testP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldp	x10, x8, [x0, #184]
	mov	x19, x0
	cmp	x10, x8
	b.hs	.LBB110_2
// %bb.1:
	add	x10, x10, #1
	b	.LBB110_7
.LBB110_2:
	ldr	w9, [x19, #48]
	cbz	w9, .LBB110_8
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_5
// %bb.4:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_6
.LBB110_5:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_6:
	add	x10, x19, #57
	str	x8, [x19, #192]
.LBB110_7:
	str	x10, [x19, #184]
.LBB110_8:
	cmp	x10, x8
	b.hs	.LBB110_10
// %bb.9:
	add	x11, x10, #1
	str	x11, [x19, #184]
	ldrb	w9, [x10]
	mov	x10, x11
	cmp	w9, #1
	b.hi	.LBB110_13
	b	.LBB110_16
.LBB110_10:
	ldr	w9, [x19, #48]
	cbz	w9, .LBB110_16
// %bb.11:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_15
// %bb.12:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	w9, #1
	b.ls	.LBB110_16
.LBB110_13:
	mov	w0, wzr
.LBB110_14:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB110_15:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	w9, #1
	b.hi	.LBB110_13
.LBB110_16:
	cmp	x10, x8
	b.hs	.LBB110_18
// %bb.17:
	add	x9, x10, #1
	str	x9, [x19, #184]
	ldrb	w10, [x10]
	mov	w0, wzr
	cmp	w10, #11
	b.ls	.LBB110_22
	b	.LBB110_14
.LBB110_18:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB110_119
// %bb.19:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_21
// %bb.20:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	mov	w0, wzr
	cmp	w10, #11
	b.ls	.LBB110_22
	b	.LBB110_14
.LBB110_21:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	mov	w0, wzr
	cmp	w10, #11
	b.hi	.LBB110_14
.LBB110_22:
	mov	w11, #1
	lsl	w10, w11, w10
	mov	w11, #3598
	tst	w10, w11
	b.eq	.LBB110_14
// %bb.23:
	cmp	x9, x8
	b.hs	.LBB110_25
// %bb.24:
	add	x9, x9, #1
	b	.LBB110_30
.LBB110_25:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_31
// %bb.26:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_28
// %bb.27:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_29
.LBB110_28:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_29:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_30:
	str	x9, [x19, #184]
.LBB110_31:
	cmp	x9, x8
	b.hs	.LBB110_33
// %bb.32:
	add	x9, x9, #1
	b	.LBB110_38
.LBB110_33:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_39
// %bb.34:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_36
// %bb.35:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_37
.LBB110_36:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_37:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_38:
	str	x9, [x19, #184]
.LBB110_39:
	cmp	x9, x8
	b.hs	.LBB110_41
// %bb.40:
	add	x9, x9, #1
	b	.LBB110_46
.LBB110_41:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_47
// %bb.42:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_44
// %bb.43:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_45
.LBB110_44:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_45:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_46:
	str	x9, [x19, #184]
.LBB110_47:
	cmp	x9, x8
	b.hs	.LBB110_49
// %bb.48:
	add	x9, x9, #1
	b	.LBB110_54
.LBB110_49:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_55
// %bb.50:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_52
// %bb.51:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_53
.LBB110_52:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_53:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_54:
	str	x9, [x19, #184]
.LBB110_55:
	cmp	x9, x8
	b.hs	.LBB110_57
// %bb.56:
	add	x9, x9, #1
	b	.LBB110_62
.LBB110_57:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_63
// %bb.58:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_60
// %bb.59:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_61
.LBB110_60:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_61:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_62:
	str	x9, [x19, #184]
.LBB110_63:
	cmp	x9, x8
	b.hs	.LBB110_65
// %bb.64:
	add	x9, x9, #1
	b	.LBB110_70
.LBB110_65:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_71
// %bb.66:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_68
// %bb.67:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_69
.LBB110_68:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_69:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_70:
	str	x9, [x19, #184]
.LBB110_71:
	cmp	x9, x8
	b.hs	.LBB110_73
// %bb.72:
	add	x9, x9, #1
	b	.LBB110_78
.LBB110_73:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_79
// %bb.74:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_76
// %bb.75:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_77
.LBB110_76:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_77:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_78:
	str	x9, [x19, #184]
.LBB110_79:
	cmp	x9, x8
	b.hs	.LBB110_81
// %bb.80:
	add	x9, x9, #1
	b	.LBB110_86
.LBB110_81:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_87
// %bb.82:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_84
// %bb.83:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_85
.LBB110_84:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_85:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_86:
	str	x9, [x19, #184]
.LBB110_87:
	cmp	x9, x8
	b.hs	.LBB110_89
// %bb.88:
	add	x9, x9, #1
	b	.LBB110_94
.LBB110_89:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_95
// %bb.90:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_92
// %bb.91:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB110_93
.LBB110_92:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_93:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB110_94:
	str	x9, [x19, #184]
.LBB110_95:
	cmp	x9, x8
	b.hs	.LBB110_98
// %bb.96:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB110_103
.LBB110_97:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB110_106
.LBB110_98:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_101
// %bb.99:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_102
// %bb.100:
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB110_103
	b	.LBB110_97
.LBB110_101:
	mov	w20, wzr
	cmp	x9, x8
	b.lo	.LBB110_97
	b	.LBB110_103
.LBB110_102:
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB110_97
.LBB110_103:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_106
// %bb.104:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_113
// %bb.105:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w20, #8, #8
	cbnz	w10, .LBB110_107
	b	.LBB110_119
.LBB110_106:
	bfi	w10, w20, #8, #8
	cbz	w10, .LBB110_119
.LBB110_107:
	cmp	x9, x8
	b.hs	.LBB110_110
// %bb.108:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB110_116
.LBB110_109:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB110_120
.LBB110_110:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_114
// %bb.111:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_115
// %bb.112:
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB110_116
	b	.LBB110_109
.LBB110_113:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w20, #8, #8
	cbnz	w10, .LBB110_107
	b	.LBB110_119
.LBB110_114:
	mov	w20, wzr
	cmp	x9, x8
	b.lo	.LBB110_109
	b	.LBB110_116
.LBB110_115:
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB110_109
.LBB110_116:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB110_120
// %bb.117:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_126
// %bb.118:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w20, #8, #8
	cbnz	w10, .LBB110_121
.LBB110_119:
	mov	w0, wzr
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB110_120:
	bfi	w10, w20, #8, #8
	cbz	w10, .LBB110_119
.LBB110_121:
	cmp	x9, x8
	b.hs	.LBB110_123
// %bb.122:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB110_129
.LBB110_123:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB110_129
// %bb.124:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB110_127
// %bb.125:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB110_128
.LBB110_126:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w20, #8, #8
	cbnz	w10, .LBB110_121
	b	.LBB110_119
.LBB110_127:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB110_128:
	str	x9, [x19, #192]
.LBB110_129:
	sub	w8, w8, #8
	ubfx	w9, w8, #3, #5
	bfi	w9, w8, #5, #27
	and	w8, w9, #0xff
	cmp	w8, #4
	ldr	x8, [x19, #200]
	cset	w0, lo
	str	x8, [x19, #184]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end110:
	.size	_ZL14stbi__tga_testP13stbi__context, .Lfunc_end110-_ZL14stbi__tga_testP13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i
	.type	_ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i,@function
_ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i: // @_ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #96]             // 16-byte Folded Spill
	add	x29, sp, #96
	stp	x28, x27, [sp, #112]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #128]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x28, x0
	mov	w21, w4
	mov	x19, x3
	mov	x20, x0
	mov	x22, x2
	mov	x25, x1
	ldp	x23, x24, [x28, #184]!
	cmp	x23, x24
	b.hs	.LBB111_2
// %bb.1:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w26, [x23]
	mov	x23, x8
	cmp	x23, x24
	str	w26, [sp, #32]                  // 4-byte Folded Spill
	b.hs	.LBB111_6
	b	.LBB111_12
.LBB111_2:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_5
// %bb.3:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_10
// %bb.4:
	mov	x8, x20
	ldrb	w26, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_11
.LBB111_5:
	mov	w26, wzr
	cmp	x23, x24
	str	w26, [sp, #32]                  // 4-byte Folded Spill
	b.lo	.LBB111_12
.LBB111_6:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_9
// %bb.7:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_14
// %bb.8:
	mov	x8, x20
	ldrb	w26, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_15
.LBB111_9:
	mov	w26, wzr
	cmp	x23, x24
	b.lo	.LBB111_13
	b	.LBB111_16
.LBB111_10:
	mov	w26, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_11:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	str	w26, [sp, #32]                  // 4-byte Folded Spill
	b.hs	.LBB111_6
.LBB111_12:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w26, [x23]
	mov	x23, x8
	cmp	x23, x24
	b.hs	.LBB111_16
.LBB111_13:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w27, [x23]
	mov	x23, x8
	cmp	x23, x24
	b.hs	.LBB111_20
	b	.LBB111_26
.LBB111_14:
	mov	w26, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_15:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.lo	.LBB111_13
.LBB111_16:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_19
// %bb.17:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_24
// %bb.18:
	mov	x8, x20
	ldrb	w27, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_25
.LBB111_19:
	mov	w27, wzr
	cmp	x23, x24
	b.lo	.LBB111_26
.LBB111_20:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_23
// %bb.21:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_28
// %bb.22:
	mov	x8, x20
	ldrb	w9, [x8, #56]!
	add	x24, x8, w0, sxtw
	str	w9, [sp, #12]                   // 4-byte Folded Spill
	b	.LBB111_29
.LBB111_23:
	str	wzr, [sp, #12]                  // 4-byte Folded Spill
	cmp	x23, x24
	b.lo	.LBB111_27
	b	.LBB111_30
.LBB111_24:
	mov	w27, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_25:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.hs	.LBB111_20
.LBB111_26:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w9, [x23]
	mov	x23, x8
	str	w9, [sp, #12]                   // 4-byte Folded Spill
	cmp	x23, x24
	b.hs	.LBB111_30
.LBB111_27:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w9, [x23]
	mov	x23, x8
	str	w9, [sp, #8]                    // 4-byte Folded Spill
	cmp	x23, x24
	b.hs	.LBB111_34
	b	.LBB111_40
.LBB111_28:
	str	wzr, [sp, #12]                  // 4-byte Folded Spill
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_29:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.lo	.LBB111_27
.LBB111_30:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_33
// %bb.31:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_38
// %bb.32:
	mov	x8, x20
	ldrb	w9, [x8, #56]!
	add	x24, x8, w0, sxtw
	str	w9, [sp, #8]                    // 4-byte Folded Spill
	b	.LBB111_39
.LBB111_33:
	str	wzr, [sp, #8]                   // 4-byte Folded Spill
	cmp	x23, x24
	b.lo	.LBB111_40
.LBB111_34:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_37
// %bb.35:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_42
// %bb.36:
	mov	x8, x20
	ldrb	w9, [x8, #56]!
	add	x24, x8, w0, sxtw
	stur	w9, [x29, #-40]                 // 4-byte Folded Spill
	b	.LBB111_43
.LBB111_37:
	stur	wzr, [x29, #-40]                // 4-byte Folded Spill
	cmp	x23, x24
	b.lo	.LBB111_41
	b	.LBB111_44
.LBB111_38:
	str	wzr, [sp, #8]                   // 4-byte Folded Spill
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_39:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.hs	.LBB111_34
.LBB111_40:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w9, [x23]
	mov	x23, x8
	stur	w9, [x29, #-40]                 // 4-byte Folded Spill
	cmp	x23, x24
	b.hs	.LBB111_44
.LBB111_41:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w9, [x23]
	mov	x23, x8
	str	w9, [sp, #16]                   // 4-byte Folded Spill
	cmp	x23, x24
	b.hs	.LBB111_48
	b	.LBB111_54
.LBB111_42:
	stur	wzr, [x29, #-40]                // 4-byte Folded Spill
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_43:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.lo	.LBB111_41
.LBB111_44:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_47
// %bb.45:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_52
// %bb.46:
	mov	x8, x20
	ldrb	w9, [x8, #56]!
	add	x24, x8, w0, sxtw
	str	w9, [sp, #16]                   // 4-byte Folded Spill
	b	.LBB111_53
.LBB111_47:
	str	wzr, [sp, #16]                  // 4-byte Folded Spill
	cmp	x23, x24
	b.lo	.LBB111_54
.LBB111_48:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_51
// %bb.49:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_56
// %bb.50:
	mov	x8, x20
	ldrb	w9, [x8, #56]!
	add	x24, x8, w0, sxtw
	str	w9, [sp, #40]                   // 4-byte Folded Spill
	b	.LBB111_57
.LBB111_51:
	str	wzr, [sp, #40]                  // 4-byte Folded Spill
	cmp	x23, x24
	b.lo	.LBB111_55
	b	.LBB111_58
.LBB111_52:
	str	wzr, [sp, #16]                  // 4-byte Folded Spill
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_53:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.hs	.LBB111_48
.LBB111_54:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w9, [x23]
	mov	x23, x8
	str	w9, [sp, #40]                   // 4-byte Folded Spill
	cmp	x23, x24
	b.hs	.LBB111_58
.LBB111_55:
	add	x23, x23, #1
	b	.LBB111_63
.LBB111_56:
	str	wzr, [sp, #40]                  // 4-byte Folded Spill
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_57:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.lo	.LBB111_55
.LBB111_58:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_64
// %bb.59:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_61
// %bb.60:
	add	x8, x20, w0, sxtw
	add	x24, x8, #56
	b	.LBB111_62
.LBB111_61:
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_62:
	add	x23, x20, #57
	str	x24, [x20, #192]
.LBB111_63:
	str	x23, [x28]
.LBB111_64:
	cmp	x23, x24
	b.hs	.LBB111_66
// %bb.65:
	add	x23, x23, #1
	b	.LBB111_71
.LBB111_66:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_72
// %bb.67:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_69
// %bb.68:
	add	x8, x20, w0, sxtw
	add	x24, x8, #56
	b	.LBB111_70
.LBB111_69:
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_70:
	add	x23, x20, #57
	str	x24, [x20, #192]
.LBB111_71:
	str	x23, [x28]
.LBB111_72:
	cmp	x23, x24
	b.hs	.LBB111_74
// %bb.73:
	add	x23, x23, #1
	b	.LBB111_79
.LBB111_74:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_80
// %bb.75:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_77
// %bb.76:
	add	x8, x20, w0, sxtw
	add	x24, x8, #56
	b	.LBB111_78
.LBB111_77:
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_78:
	add	x23, x20, #57
	str	x24, [x20, #192]
.LBB111_79:
	str	x23, [x28]
.LBB111_80:
	cmp	x23, x24
	b.hs	.LBB111_82
// %bb.81:
	add	x23, x23, #1
	b	.LBB111_87
.LBB111_82:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_88
// %bb.83:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_85
// %bb.84:
	add	x8, x20, w0, sxtw
	add	x24, x8, #56
	b	.LBB111_86
.LBB111_85:
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_86:
	add	x23, x20, #57
	str	x24, [x20, #192]
.LBB111_87:
	str	x23, [x28]
.LBB111_88:
	cmp	x23, x24
	stur	x25, [x29, #-32]                // 8-byte Folded Spill
	b.hs	.LBB111_90
// %bb.89:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w25, [x23]
	mov	x23, x8
	cmp	x23, x24
	stur	w26, [x29, #-36]                // 4-byte Folded Spill
	str	x22, [sp, #48]                  // 8-byte Folded Spill
	b.hs	.LBB111_94
	b	.LBB111_100
.LBB111_90:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_93
// %bb.91:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_98
// %bb.92:
	mov	x8, x20
	ldrb	w25, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_99
.LBB111_93:
	mov	w25, wzr
	cmp	x23, x24
	stur	w26, [x29, #-36]                // 4-byte Folded Spill
	str	x22, [sp, #48]                  // 8-byte Folded Spill
	b.lo	.LBB111_100
.LBB111_94:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_97
// %bb.95:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	mov	x26, x19
	cbz	w0, .LBB111_102
// %bb.96:
	mov	x8, x20
	ldrb	w22, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_103
.LBB111_97:
	mov	x26, x19
	mov	w22, wzr
	cmp	x23, x24
	b.lo	.LBB111_101
	b	.LBB111_104
.LBB111_98:
	mov	w25, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_99:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	stur	w26, [x29, #-36]                // 4-byte Folded Spill
	str	x22, [sp, #48]                  // 8-byte Folded Spill
	b.hs	.LBB111_94
.LBB111_100:
	add	x8, x23, #1
	mov	x26, x19
	str	x8, [x28]
	ldrb	w22, [x23]
	mov	x23, x8
	cmp	x23, x24
	b.hs	.LBB111_104
.LBB111_101:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w19, [x23]
	mov	x23, x8
	cmp	x23, x24
	str	w21, [sp, #28]                  // 4-byte Folded Spill
	b.hs	.LBB111_108
	b	.LBB111_114
.LBB111_102:
	mov	w22, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_103:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	b.lo	.LBB111_101
.LBB111_104:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_107
// %bb.105:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_112
// %bb.106:
	mov	x8, x20
	ldrb	w19, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_113
.LBB111_107:
	mov	w19, wzr
	cmp	x23, x24
	str	w21, [sp, #28]                  // 4-byte Folded Spill
	b.lo	.LBB111_114
.LBB111_108:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_111
// %bb.109:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_116
// %bb.110:
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_117
.LBB111_111:
	mov	w21, wzr
	bfi	w25, w22, #8, #8
	cmp	x23, x24
	mov	w22, w25
	b.lo	.LBB111_115
	b	.LBB111_118
.LBB111_112:
	mov	w19, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_113:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	str	w21, [sp, #28]                  // 4-byte Folded Spill
	b.hs	.LBB111_108
.LBB111_114:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w21, [x23]
	mov	x23, x8
	bfi	w25, w22, #8, #8
	cmp	x23, x24
	mov	w22, w25
	b.hs	.LBB111_118
.LBB111_115:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w10, [x23]
	mov	x23, x8
	cmp	x23, x24
	stur	w10, [x29, #-20]                // 4-byte Folded Spill
	b.hs	.LBB111_122
	b	.LBB111_128
.LBB111_116:
	mov	w21, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_117:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	bfi	w25, w22, #8, #8
	cmp	x23, x24
	mov	w22, w25
	b.lo	.LBB111_115
.LBB111_118:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_121
// %bb.119:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_126
// %bb.120:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_127
.LBB111_121:
	mov	w10, wzr
	cmp	x23, x24
	stur	w10, [x29, #-20]                // 4-byte Folded Spill
	b.lo	.LBB111_128
.LBB111_122:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_125
// %bb.123:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_129
// %bb.124:
	mov	x8, x20
	ldrb	w25, [x8, #56]!
	add	x24, x8, w0, sxtw
	b	.LBB111_130
.LBB111_125:
	mov	w25, wzr
	sub	w8, w27, #8
	cmp	w27, #7
	csel	w8, w8, w27, hi
	stur	xzr, [x29, #-16]                // 8-byte Folded Spill
	cbnz	w22, .LBB111_131
	b	.LBB111_174
.LBB111_126:
	mov	w10, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_127:
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	cmp	x23, x24
	stur	w10, [x29, #-20]                // 4-byte Folded Spill
	b.hs	.LBB111_122
.LBB111_128:
	add	x8, x23, #1
	str	x8, [x28]
	ldrb	w25, [x23]
	mov	x23, x8
	sub	w8, w27, #8
	cmp	w27, #7
	csel	w8, w8, w27, hi
	stur	xzr, [x29, #-16]                // 8-byte Folded Spill
	cbnz	w22, .LBB111_131
	b	.LBB111_174
.LBB111_129:
	mov	w25, wzr
	add	x24, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_130:
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
	add	x23, x20, #57
	stp	x23, x24, [x20, #184]
	sub	w8, w27, #8
	cmp	w27, #7
	csel	w8, w8, w27, hi
	stur	xzr, [x29, #-16]                // 8-byte Folded Spill
	cbz	w22, .LBB111_174
.LBB111_131:
	bfi	w19, w21, #8, #8
	cbz	w19, .LBB111_174
// %bb.132:
	cmp	w8, #1
	b.lt	.LBB111_174
// %bb.133:
	cmp	w8, #3
	b.gt	.LBB111_174
// %bb.134:
	sub	w8, w10, #8
	ubfx	w9, w8, #3, #5
	bfi	w9, w8, #5, #27
	and	w8, w9, #0xff
	cmp	w8, #3
	b.hi	.LBB111_141
// %bb.135:
	lsr	w10, w10, #3
	ldr	w8, [sp, #40]                   // 4-byte Folded Reload
	ldur	w9, [x29, #-36]                 // 4-byte Folded Reload
	mov	w21, w19
	lsr	w8, w8, #3
	str	w10, [sp, #4]                   // 4-byte Folded Spill
	cmp	w9, #0
	csel	w9, w8, w10, ne
	ldur	x8, [x29, #-32]                 // 8-byte Folded Reload
	str	w22, [x8]
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	str	w19, [x8]
	cbz	x26, .LBB111_137
// %bb.136:
	str	w9, [x26]
.LBB111_137:
	mul	w19, w21, w22
	str	x9, [sp, #48]                   // 8-byte Folded Spill
	umull	x0, w9, w19
	bl	malloc
	cbz	x0, .LBB111_172
// %bb.138:
	str	w21, [sp]                       // 4-byte Folded Spill
	ldr	x8, [x20, #16]
	mov	w21, #1
	ldr	w9, [sp, #32]                   // 4-byte Folded Reload
	stur	x0, [x29, #-16]                 // 8-byte Folded Spill
	str	w27, [sp, #36]                  // 4-byte Folded Spill
	cbz	x8, .LBB111_142
// %bb.139:
	sub	w8, w24, w23
	subs	w1, w9, w8
	b.le	.LBB111_142
// %bb.140:
	ldr	x8, [x20, #24]
	str	x24, [x20, #184]
	ldr	x0, [x20, #40]
	blr	x8
	ldur	w27, [x29, #-36]                // 4-byte Folded Reload
	bic	w8, w21, w25, lsr #5
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
	stur	w8, [x29, #-32]                 // 4-byte Folded Spill
	str	w22, [sp, #32]                  // 4-byte Folded Spill
	cbz	w27, .LBB111_143
	b	.LBB111_154
.LBB111_141:
	stur	xzr, [x29, #-16]                // 8-byte Folded Spill
	b	.LBB111_174
.LBB111_142:
	add	x8, x23, w9, uxtw
	str	x8, [x28]
	ldur	w27, [x29, #-36]                // 4-byte Folded Reload
	bic	w8, w21, w25, lsr #5
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
	stur	w8, [x29, #-32]                 // 4-byte Folded Spill
	str	w22, [sp, #32]                  // 4-byte Folded Spill
	cbnz	w27, .LBB111_154
.LBB111_143:
	ldr	w8, [sp, #36]                   // 4-byte Folded Reload
	cmp	w8, #7
	b.hi	.LBB111_154
// %bb.144:
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	ldr	x27, [x20, #16]
	mul	w22, w8, w22
	cbz	x27, .LBB111_158
// %bb.145:
	ldr	w8, [sp]                        // 4-byte Folded Reload
	mov	w21, wzr
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	sub	w25, w8, #1
	ldur	w8, [x29, #-32]                 // 4-byte Folded Reload
	cmp	w8, #0
	csel	w8, w21, w25, eq
	mul	w8, w22, w8
	add	x23, x26, w8, sxtw
	cbz	x27, .LBB111_148
.LBB111_146:
	ldp	x1, x8, [x20, #184]
	sub	x26, x8, x1
	cmp	w22, w26
	b.le	.LBB111_149
// %bb.147:
	sxtw	x24, w26
	mov	x0, x23
	mov	x2, x24
	bl	memcpy
	ldr	x0, [x20, #40]
	add	x1, x23, x24
	sub	w2, w22, w26
	blr	x27
	ldr	x24, [x20, #192]
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	b	.LBB111_151
.LBB111_148:
	ldp	x1, x8, [x20, #184]
	add	x24, x1, x22
	cmp	x24, x8
	b.ls	.LBB111_150
	b	.LBB111_152
.LBB111_149:
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	add	x24, x1, x22
	cmp	x24, x8
	b.hi	.LBB111_152
.LBB111_150:
	mov	x0, x23
	mov	x2, x22
	bl	memcpy
.LBB111_151:
	str	x24, [x28]
.LBB111_152:
	cbz	w25, .LBB111_241
// %bb.153:
	ldr	x27, [x20, #16]
	sub	w25, w25, #1
	add	w21, w21, #1
	ldur	w8, [x29, #-32]                 // 4-byte Folded Reload
	cmp	w8, #0
	csel	w8, w21, w25, eq
	mul	w8, w22, w8
	add	x23, x26, w8, sxtw
	cbnz	x27, .LBB111_146
	b	.LBB111_148
.LBB111_154:
	ldur	w8, [x29, #-40]                 // 4-byte Folded Reload
	ldr	w9, [sp, #16]                   // 4-byte Folded Reload
	bfi	w8, w9, #8, #8
	stur	w8, [x29, #-40]                 // 4-byte Folded Spill
	cbz	w27, .LBB111_163
// %bb.155:
	ldp	w9, w11, [sp, #8]               // 8-byte Folded Reload
	ldr	x8, [x20, #16]
	bfi	w11, w9, #8, #8
	cbz	x8, .LBB111_164
// %bb.156:
	ldp	x8, x9, [x20, #184]
	sub	w10, w9, w8
	subs	w1, w11, w10
	b.le	.LBB111_165
// %bb.157:
	ldr	x8, [x20, #24]
	str	x9, [x20, #184]
	ldr	x0, [x20, #40]
	blr	x8
	b	.LBB111_166
.LBB111_158:
	ldp	x1, x20, [x20, #184]
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	add	x8, x1, x22
	cmp	x8, x20
	b.hi	.LBB111_241
// %bb.159:
	ldr	w8, [sp]                        // 4-byte Folded Reload
	mov	w21, wzr
	sub	w23, w8, #1
	b	.LBB111_161
.LBB111_160:                            //   in Loop: Header=BB111_161 Depth=1
	add	w21, w21, #1
	sub	w23, w23, #1
	cmn	w23, #1
	b.eq	.LBB111_241
.LBB111_161:                            // =>This Inner Loop Header: Depth=1
	add	x24, x1, x22
	cmp	x24, x20
	b.hi	.LBB111_160
// %bb.162:                             //   in Loop: Header=BB111_161 Depth=1
	ldur	w8, [x29, #-32]                 // 4-byte Folded Reload
	mov	x2, x22
	cmp	w8, #0
	csel	w8, w21, w23, eq
	mul	w8, w22, w8
	add	x0, x26, w8, sxtw
	bl	memcpy
	mov	x1, x24
	str	x24, [x28]
	b	.LBB111_160
.LBB111_163:
	str	xzr, [sp, #16]                  // 8-byte Folded Spill
	b	.LBB111_181
.LBB111_164:
	ldr	x8, [x28]
.LBB111_165:
	add	x8, x8, w11, uxtw
	str	x8, [x28]
.LBB111_166:
	ldur	w8, [x29, #-40]                 // 4-byte Folded Reload
	ldr	w9, [sp, #40]                   // 4-byte Folded Reload
	mul	w8, w8, w9
	lsr	w23, w8, #3
	mov	x0, x23
	bl	malloc
	cbz	x0, .LBB111_171
// %bb.167:
	mov	x25, x0
	ldr	x21, [x20, #16]
	cbz	x21, .LBB111_175
// %bb.168:
	ldp	x1, x8, [x20, #184]
	sub	x22, x8, x1
	cmp	w23, w22
	b.le	.LBB111_176
// %bb.169:
	sxtw	x24, w22
	mov	x0, x25
	mov	x2, x24
	bl	memcpy
	sub	w23, w23, w22
	ldr	x0, [x20, #40]
	add	x1, x25, x24
	mov	w2, w23
	blr	x21
	ldr	x8, [x20, #192]
	cmp	w0, w23
	ldr	w22, [sp, #32]                  // 4-byte Folded Reload
	str	x8, [x20, #184]
	b.ne	.LBB111_178
// %bb.170:
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	b	.LBB111_180
.LBB111_171:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	bl	free
.LBB111_172:
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	stur	xzr, [x29, #-16]                // 8-byte Folded Spill
	add	x9, x9, :lo12:.L.str.28
.LBB111_173:
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB111_174:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #96]             // 16-byte Folded Reload
	add	sp, sp, #192
	ret
.LBB111_175:
	ldp	x1, x8, [x20, #184]
	b	.LBB111_177
.LBB111_176:
	ldr	w22, [sp, #32]                  // 4-byte Folded Reload
.LBB111_177:
	add	x21, x1, x23
	cmp	x21, x8
	b.ls	.LBB111_179
.LBB111_178:
	ldur	x0, [x29, #-16]                 // 8-byte Folded Reload
	bl	free
	mov	x0, x25
	bl	free
	adrp	x9, .L.str.105
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.105
	stur	xzr, [x29, #-16]                // 8-byte Folded Spill
	b	.LBB111_173
.LBB111_179:
	mov	x0, x25
	mov	x2, x23
	str	x25, [sp, #16]                  // 8-byte Folded Spill
	bl	memcpy
	str	x21, [x28]
.LBB111_180:
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
.LBB111_181:
	cbz	w19, .LBB111_219
// %bb.182:
	sub	w8, w10, #1
	mov	x24, xzr
	lsr	w8, w8, #3
	mov	w26, wzr
	add	w8, w8, #1
	mov	w25, wzr
	add	x23, x20, #56
	add	x21, x20, #57
	str	x8, [sp, #40]                   // 8-byte Folded Spill
	mov	w8, #1
	b	.LBB111_184
.LBB111_183:                            //   in Loop: Header=BB111_184 Depth=1
	mov	w8, wzr
	sub	w25, w25, #1
	add	x24, x24, #1
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
	cmp	x24, x19
	b.eq	.LBB111_219
.LBB111_184:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB111_203 Depth 2
	ldr	w9, [sp, #36]                   // 4-byte Folded Reload
	cmp	w9, #8
	b.lo	.LBB111_196
// %bb.185:                             //   in Loop: Header=BB111_184 Depth=1
	cbz	w25, .LBB111_188
// %bb.186:                             //   in Loop: Header=BB111_184 Depth=1
	cmp	w26, #0
	cset	w9, eq
	cset	w26, ne
	orr	w8, w9, w8
	tbnz	w8, #0, .LBB111_196
// %bb.187:                             //   in Loop: Header=BB111_184 Depth=1
	mov	w26, #1
	b	.LBB111_217
.LBB111_188:                            //   in Loop: Header=BB111_184 Depth=1
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB111_190
// %bb.189:                             //   in Loop: Header=BB111_184 Depth=1
	add	x9, x8, #1
	str	x9, [x28]
	ldrb	w8, [x8]
	b	.LBB111_195
.LBB111_190:                            //   in Loop: Header=BB111_184 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_195
// %bb.191:                             //   in Loop: Header=BB111_184 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x23
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_193
// %bb.192:                             //   in Loop: Header=BB111_184 Depth=1
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB111_194
.LBB111_193:                            //   in Loop: Header=BB111_184 Depth=1
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_194:                            //   in Loop: Header=BB111_184 Depth=1
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
	stp	x21, x9, [x20, #184]
.LBB111_195:                            //   in Loop: Header=BB111_184 Depth=1
	and	w9, w8, #0x7f
	lsr	w26, w8, #7
	add	w25, w9, #1
.LBB111_196:                            //   in Loop: Header=BB111_184 Depth=1
	cbz	w27, .LBB111_199
// %bb.197:                             //   in Loop: Header=BB111_184 Depth=1
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB111_209
// %bb.198:                             //   in Loop: Header=BB111_184 Depth=1
	add	x9, x8, #1
	str	x9, [x28]
	ldrb	w8, [x8]
	b	.LBB111_215
.LBB111_199:                            //   in Loop: Header=BB111_184 Depth=1
	cbz	w10, .LBB111_217
// %bb.200:                             //   in Loop: Header=BB111_184 Depth=1
	ldp	x9, x8, [x20, #184]
	sub	x22, x29, #4
	ldr	x27, [sp, #40]                  // 8-byte Folded Reload
	b	.LBB111_203
.LBB111_201:                            //   in Loop: Header=BB111_203 Depth=2
	add	x11, x9, #1
	str	x11, [x28]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB111_202:                            //   in Loop: Header=BB111_203 Depth=2
	subs	x27, x27, #1
	strb	w10, [x22], #1
	b.eq	.LBB111_212
.LBB111_203:                            //   Parent Loop BB111_184 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	x9, x8
	b.lo	.LBB111_201
// %bb.204:                             //   in Loop: Header=BB111_203 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB111_202
// %bb.205:                             //   in Loop: Header=BB111_203 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x23
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_207
// %bb.206:                             //   in Loop: Header=BB111_203 Depth=2
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB111_208
.LBB111_207:                            //   in Loop: Header=BB111_203 Depth=2
	mov	w10, wzr
	mov	x8, x21
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_208:                            //   in Loop: Header=BB111_203 Depth=2
	mov	x9, x21
	stp	x21, x8, [x20, #184]
	b	.LBB111_202
.LBB111_209:                            //   in Loop: Header=BB111_184 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB111_215
// %bb.210:                             //   in Loop: Header=BB111_184 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x23
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB111_213
// %bb.211:                             //   in Loop: Header=BB111_184 Depth=1
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB111_214
.LBB111_212:                            //   in Loop: Header=BB111_184 Depth=1
	ldur	w27, [x29, #-36]                // 4-byte Folded Reload
	ldr	w22, [sp, #32]                  // 4-byte Folded Reload
	b	.LBB111_217
.LBB111_213:                            //   in Loop: Header=BB111_184 Depth=1
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB111_214:                            //   in Loop: Header=BB111_184 Depth=1
	ldur	w10, [x29, #-20]                // 4-byte Folded Reload
	stp	x21, x9, [x20, #184]
.LBB111_215:                            //   in Loop: Header=BB111_184 Depth=1
	cbz	w10, .LBB111_217
// %bb.216:                             //   in Loop: Header=BB111_184 Depth=1
	ldur	w9, [x29, #-40]                 // 4-byte Folded Reload
	sub	x0, x29, #4
	ldr	x2, [sp, #40]                   // 8-byte Folded Reload
	cmp	w9, w8
	ldr	w9, [sp, #4]                    // 4-byte Folded Reload
	csel	w8, w8, wzr, hi
	mul	w8, w8, w9
	ldr	x9, [sp, #16]                   // 8-byte Folded Reload
	add	x1, x9, x8
	bl	memcpy
.LBB111_217:                            //   in Loop: Header=BB111_184 Depth=1
	ldr	x2, [sp, #48]                   // 8-byte Folded Reload
	cbz	w2, .LBB111_183
// %bb.218:                             //   in Loop: Header=BB111_184 Depth=1
	ldur	x9, [x29, #-16]                 // 8-byte Folded Reload
	mul	w8, w2, w24
	sub	x1, x29, #4
	add	x0, x9, x8
	bl	memcpy
	b	.LBB111_183
.LBB111_219:
	ldr	w10, [sp]                       // 4-byte Folded Reload
	ldur	x26, [x29, #-16]                // 8-byte Folded Reload
	ldr	x0, [sp, #16]                   // 8-byte Folded Reload
	ldur	w8, [x29, #-32]                 // 4-byte Folded Reload
	cbz	w8, .LBB111_239
// %bb.220:
	ldr	x8, [sp, #48]                   // 8-byte Folded Reload
	mul	w8, w8, w22
	cbz	w8, .LBB111_239
// %bb.221:
	sub	w12, w10, #1
	sub	w11, w8, #1
	lsr	w10, w12, #1
	mov	w3, wzr
	mul	w2, w8, w12
	add	x12, x11, #1
	and	x14, x12, #0x1ffffffe0
	and	x16, x12, #0x1fffffff8
	mov	w9, wzr
	add	x13, x26, x12
	sub	w15, w8, w14
	and	x17, x12, #0x18
	sub	w18, w8, w16
	add	x22, x26, #16
	neg	x1, x16
	b	.LBB111_223
.LBB111_222:                            //   in Loop: Header=BB111_223 Depth=1
	add	w4, w9, #1
	cmp	w9, w10
	sub	w2, w2, w8
	add	w3, w3, w8
	mov	w9, w4
	b.eq	.LBB111_239
.LBB111_223:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB111_230 Depth 2
                                        //     Child Loop BB111_234 Depth 2
                                        //     Child Loop BB111_238 Depth 2
	sxtw	x2, w2
	mov	w3, w3
	cmp	w11, #7
	b.hs	.LBB111_225
// %bb.224:                             //   in Loop: Header=BB111_223 Depth=1
	mov	x4, x3
	mov	x5, x2
	mov	w6, w8
	b	.LBB111_237
.LBB111_225:                            //   in Loop: Header=BB111_223 Depth=1
	add	x4, x13, x2
	add	x5, x26, x3
	cmp	x5, x4
	b.hs	.LBB111_227
// %bb.226:                             //   in Loop: Header=BB111_223 Depth=1
	mov	x4, x3
	mov	x5, x2
	mov	w6, w8
	add	x7, x26, x2
	add	x20, x13, x3
	cmp	x7, x20
	b.lo	.LBB111_237
.LBB111_227:                            //   in Loop: Header=BB111_223 Depth=1
	cmp	w11, #31
	b.hs	.LBB111_229
// %bb.228:                             //   in Loop: Header=BB111_223 Depth=1
	mov	x7, xzr
	b	.LBB111_233
.LBB111_229:                            //   in Loop: Header=BB111_223 Depth=1
	add	x4, x22, x2
	add	x5, x22, x3
	mov	x6, x14
.LBB111_230:                            //   Parent Loop BB111_223 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x4, #-16]
	subs	x6, x6, #32
	ldp	q2, q3, [x5, #-16]
	stp	q0, q1, [x5, #-16]
	add	x5, x5, #32
	stp	q2, q3, [x4, #-16]
	add	x4, x4, #32
	b.ne	.LBB111_230
// %bb.231:                             //   in Loop: Header=BB111_223 Depth=1
	cmp	x12, x14
	b.eq	.LBB111_222
// %bb.232:                             //   in Loop: Header=BB111_223 Depth=1
	mov	x7, x14
	cbz	x17, .LBB111_236
.LBB111_233:                            //   in Loop: Header=BB111_223 Depth=1
	add	x20, x7, x2
	add	x21, x7, x3
	add	x4, x16, x3
	add	x5, x16, x2
	add	x6, x1, x7
	add	x7, x26, x20
	add	x20, x26, x21
.LBB111_234:                            //   Parent Loop BB111_223 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x7]
	adds	x6, x6, #8
	ldr	d1, [x20]
	str	d0, [x20], #8
	str	d1, [x7], #8
	b.ne	.LBB111_234
// %bb.235:                             //   in Loop: Header=BB111_223 Depth=1
	mov	w6, w18
	cmp	x12, x16
	b.eq	.LBB111_222
	b	.LBB111_237
.LBB111_236:                            //   in Loop: Header=BB111_223 Depth=1
	add	x5, x14, x2
	add	x4, x14, x3
	mov	w6, w15
.LBB111_237:                            //   in Loop: Header=BB111_223 Depth=1
	add	x4, x26, x4
	add	x5, x26, x5
	add	w6, w6, #1
.LBB111_238:                            //   Parent Loop BB111_223 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w7, [x5]
	sub	w6, w6, #1
	ldrb	w20, [x4]
	cmp	w6, #1
	strb	w7, [x4], #1
	strb	w20, [x5], #1
	b.gt	.LBB111_238
	b	.LBB111_222
.LBB111_239:
	cbz	x0, .LBB111_241
// %bb.240:
	bl	free
.LBB111_241:
	ldr	x1, [sp, #48]                   // 8-byte Folded Reload
	cmp	w1, #3
	b.lo	.LBB111_245
// %bb.242:
	cbz	w19, .LBB111_245
// %bb.243:
	add	x8, x26, #2
.LBB111_244:                            // =>This Inner Loop Header: Depth=1
	ldrb	w9, [x8]
	subs	w19, w19, #1
	ldurb	w10, [x8, #-2]
	sturb	w9, [x8, #-2]
	strb	w10, [x8]
	add	x8, x8, x1
	b.ne	.LBB111_244
.LBB111_245:
	ldp	w2, w3, [sp, #28]               // 8-byte Folded Reload
	ldr	w4, [sp]                        // 4-byte Folded Reload
	cbz	w2, .LBB111_174
// %bb.246:
	cmp	w1, w2
	b.eq	.LBB111_174
// %bb.247:
	mov	x0, x26
                                        // kill: def $w1 killed $w1 killed $x1
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #96]             // 16-byte Folded Reload
	add	sp, sp, #192
	b	_ZL20stbi__convert_formatPhiijj
.Lfunc_end111:
	.size	_ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i, .Lfunc_end111-_ZL14stbi__tga_loadP13stbi__contextPiS1_S1_i
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL24stbi__decode_jpeg_headerP10stbi__jpegi
	.type	_ZL24stbi__decode_jpeg_headerP10stbi__jpegi,@function
_ZL24stbi__decode_jpeg_headerP10stbi__jpegi: // @_ZL24stbi__decode_jpeg_headerP10stbi__jpegi
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	w8, #18216
	mov	x19, x0
	add	x21, x0, x8
	mov	w8, #255
	mov	w20, w1
	strb	w8, [x21]
	bl	_ZL16stbi__get_markerP10stbi__jpeg
	and	w8, w0, #0xff
	cmp	w8, #216
	b.ne	.LBB112_4
// %bb.1:
	cmp	w20, #1
	b.ne	.LBB112_5
// %bb.2:
	mov	w0, #1
.LBB112_3:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB112_4:
	adrp	x9, .L.str.10
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	add	x9, x9, :lo12:.L.str.10
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB112_5:
	mov	x0, x19
	bl	_ZL16stbi__get_markerP10stbi__jpeg
.LBB112_6:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB112_11 Depth 2
	and	w1, w0, #0xff
	cmp	w1, #194
	cset	w8, eq
	b.eq	.LBB112_14
// %bb.7:                               //   in Loop: Header=BB112_6 Depth=1
	and	w9, w0, #0xfe
	cmp	w9, #192
	b.eq	.LBB112_14
// %bb.8:                               //   in Loop: Header=BB112_6 Depth=1
	mov	x0, x19
	bl	_ZL20stbi__process_markerP10stbi__jpegi
	cbnz	w0, .LBB112_11
	b	.LBB112_3
.LBB112_9:                              //   in Loop: Header=BB112_11 Depth=2
	ldr	w8, [x22, #48]
	cbz	w8, .LBB112_15
.LBB112_10:                             //   in Loop: Header=BB112_11 Depth=2
	ldp	x8, x9, [x22, #184]
	cmp	x8, x9
	b.hs	.LBB112_15
.LBB112_11:                             //   Parent Loop BB112_6 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov	x0, x19
	bl	_ZL16stbi__get_markerP10stbi__jpeg
	mvn	w8, w0
	tst	w8, #0xff
	b.ne	.LBB112_6
// %bb.12:                              //   in Loop: Header=BB112_11 Depth=2
	ldr	x22, [x19]
	ldr	x8, [x22, #16]
	cbz	x8, .LBB112_10
// %bb.13:                              //   in Loop: Header=BB112_11 Depth=2
	ldp	x8, x0, [x22, #32]
	blr	x8
	cbnz	w0, .LBB112_9
	b	.LBB112_11
.LBB112_14:
	mov	x0, x19
	mov	w1, w20
	str	w8, [x21, #8]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	b	_ZL26stbi__process_frame_headerP10stbi__jpegi
.LBB112_15:
	adrp	x9, .L.str.11
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	add	x9, x9, :lo12:.L.str.11
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end112:
	.size	_ZL24stbi__decode_jpeg_headerP10stbi__jpegi, .Lfunc_end112-_ZL24stbi__decode_jpeg_headerP10stbi__jpegi
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL16stbi__idct_blockPhiPs
	.type	_ZL16stbi__idct_blockPhiPs,@function
_ZL16stbi__idct_blockPhiPs:             // @_ZL16stbi__idct_blockPhiPs
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #368
	stp	x29, x30, [sp, #272]            // 16-byte Folded Spill
	stp	x28, x27, [sp, #288]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #304]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #320]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #336]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #352]            // 16-byte Folded Spill
	.cfi_def_cfa_offset 368
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	add	x10, sp, #16
	mov	x8, xzr
	add	x9, x2, #64
	add	x10, x10, #128
	mov	w11, #2217
	mov	w12, #-7567
	mov	w13, #3135
	mov	w14, #4816
	mov	w15, #1223
	mov	w16, #8410
	mov	w17, #12586
	mov	w18, #6149
	mov	w2, #-3685
	mov	w3, #-10497
	mov	w4, #-8034
	mov	w5, #-1597
                                        // kill: def $w1 killed $w1 def $x1
.LBB113_1:                              // =>This Inner Loop Header: Depth=1
	add	x7, x9, x8
	ldursh	w6, [x7, #-48]
	ldurh	w19, [x7, #-32]
	orr	w20, w6, w19
	tst	w20, #0xffff
	b.ne	.LBB113_8
// %bb.2:                               //   in Loop: Header=BB113_1 Depth=1
	ldurh	w19, [x7, #-16]
	cbnz	w19, .LBB113_7
// %bb.3:                               //   in Loop: Header=BB113_1 Depth=1
	ldrh	w19, [x9, x8]
	cbnz	w19, .LBB113_7
// %bb.4:                               //   in Loop: Header=BB113_1 Depth=1
	add	x19, x9, x8
	ldrh	w20, [x19, #16]
	cbnz	w20, .LBB113_7
// %bb.5:                               //   in Loop: Header=BB113_1 Depth=1
	ldrh	w19, [x19, #32]
	cbnz	w19, .LBB113_7
// %bb.6:                               //   in Loop: Header=BB113_1 Depth=1
	add	x19, x9, x8
	ldrh	w19, [x19, #48]
	cbz	w19, .LBB113_9
.LBB113_7:                              //   in Loop: Header=BB113_1 Depth=1
	mov	w19, wzr
.LBB113_8:                              //   in Loop: Header=BB113_1 Depth=1
	ldrsh	w20, [x7, #32]
	sxth	w19, w19
	ldrsh	w21, [x7, #48]
	ldrsh	w22, [x7, #16]
	ldursh	w23, [x7, #-16]
	add	w24, w20, w19
	ldursh	w28, [x7, #-64]
	add	w29, w21, w6
	add	w26, w22, w6
	mul	w24, w24, w11
	add	w25, w23, w21
	ldrsh	w7, [x7]
	add	w27, w25, w26
	madd	w20, w20, w12, w24
	madd	w19, w19, w13, w24
	add	w24, w23, w22
	mul	w27, w27, w14
	add	w30, w7, w28
	mul	w26, w26, w5
	sub	w7, w28, w7
	mul	w25, w25, w4
	lsl	w7, w7, #12
	madd	w29, w29, w2, w27
	madd	w24, w24, w3, w27
	lsl	w27, w30, #12
	madd	w6, w6, w18, w26
	sub	w28, w27, w19
	madd	w23, w23, w17, w25
	add	w19, w19, w27
	sub	w30, w7, w20
	add	w6, w6, w29
	add	w19, w19, #512
	add	w7, w20, w7
	add	w23, w23, w24
	add	w7, w7, #512
	add	w20, w6, w19
	sub	w6, w19, w6
	asr	w20, w20, #10
	asr	w6, w6, #10
	add	w19, w23, w7
	sub	w7, w7, w23
	madd	w22, w22, w16, w26
	asr	w19, w19, #10
	madd	w21, w21, w15, w25
	asr	w7, w7, #10
	add	w22, w22, w24
	stur	w20, [x10, #-128]
	add	w21, w21, w29
	add	w20, w30, #512
	str	w6, [x10, #96]
	add	w6, w28, #512
	stur	w19, [x10, #-96]
	sub	w19, w20, w22
	str	w7, [x10, #64]
	add	w7, w22, w20
	add	w20, w21, w6
	sub	w6, w6, w21
	asr	w7, w7, #10
	asr	w19, w19, #10
	asr	w20, w20, #10
	asr	w6, w6, #10
	stur	w7, [x10, #-64]
	str	w19, [x10, #32]
	stur	w20, [x10, #-32]
	str	w6, [x10], #4
	add	x8, x8, #2
	cmp	w8, #16
	b.ne	.LBB113_1
	b	.LBB113_10
.LBB113_9:                              //   in Loop: Header=BB113_1 Depth=1
	ldursh	w6, [x7, #-64]
	lsl	w6, w6, #2
	str	w6, [x10, #96]
	str	w6, [x10, #64]
	str	w6, [x10, #32]
	str	w6, [x10]
	stur	w6, [x10, #-32]
	stur	w6, [x10, #-64]
	stur	w6, [x10, #-96]
	stur	w6, [x10, #-128]
	add	x8, x8, #2
	add	x10, x10, #4
	cmp	w8, #16
	b.ne	.LBB113_1
.LBB113_10:
	add	x11, sp, #16
	mov	x8, xzr
	sxtw	x9, w1
	add	x10, x0, #3
	add	x12, x11, #16
	mov	w13, #2217
	mov	w14, #-7567
	mov	w15, #3135
	mov	w16, #4816
	mov	w17, #1223
	mov	w18, #8410
	mov	w0, #12586
	mov	w1, #6149
	mov	w2, #-3685
	mov	w3, #-10497
	mov	w4, #-8034
	mov	w5, #-1597
	mov	w6, #16842752
.LBB113_11:                             // =>This Inner Loop Header: Depth=1
	add	x7, x12, x8
	ldr	w29, [x11, x8]
	add	x8, x8, #32
	ldp	w19, w20, [x7, #8]
	ldp	w22, w23, [x7, #-8]
	ldur	w24, [x7, #-12]
	ldp	w7, w21, [x7]
	add	w25, w19, w22
	add	w26, w23, w20
	add	w27, w24, w21
	add	w30, w24, w20
	mul	w25, w25, w13
	add	w28, w27, w26
	mul	w26, w26, w4
	mul	w27, w27, w5
	mul	w28, w28, w16
	madd	w19, w19, w14, w25
	madd	w22, w22, w15, w25
	add	w25, w23, w21
	madd	w23, w23, w0, w26
	madd	w25, w25, w3, w28
	madd	w21, w21, w18, w27
	madd	w30, w30, w2, w28
	add	w28, w7, w29
	madd	w24, w24, w1, w27
	add	w23, w23, w25
	add	w21, w21, w25
	lsl	w25, w28, #12
	madd	w20, w20, w17, w26
	sub	w26, w25, w22
	add	w22, w22, w25
	sub	w7, w29, w7
	add	w24, w24, w30
	add	w22, w22, w6
	lsl	w7, w7, #12
	add	w27, w24, w22
	sub	w25, w7, w19
	add	w7, w19, w7
	lsr	w19, w27, #25
	sub	w22, w22, w24
	cmp	w19, #0
	lsr	w19, w27, #17
	asr	w27, w27, #31
	add	w7, w7, w6
	csinv	w19, w19, w27, eq
	lsr	w27, w22, #25
	lsr	w24, w22, #17
	asr	w22, w22, #31
	cmp	w27, #0
	add	w20, w20, w30
	csinv	w22, w24, w22, eq
	add	w24, w23, w7
	sub	w7, w7, w23
	lsr	w23, w24, #25
	lsr	w27, w24, #17
	asr	w24, w24, #31
	cmp	w23, #0
	lsr	w23, w7, #25
	csinv	w24, w27, w24, eq
	cmp	w23, #0
	lsr	w23, w7, #17
	asr	w7, w7, #31
	csinv	w7, w23, w7, eq
	sturb	w19, [x10, #-3]
	add	w19, w25, w6
	strb	w22, [x10, #4]
	add	w22, w21, w19
	sub	w19, w19, w21
	strb	w7, [x10, #3]
	lsr	w7, w22, #25
	cmp	w7, #0
	lsr	w7, w22, #17
	asr	w22, w22, #31
	add	w23, w26, w6
	csinv	w7, w7, w22, eq
	lsr	w22, w19, #25
	lsr	w21, w19, #17
	asr	w19, w19, #31
	cmp	w22, #0
	sturb	w24, [x10, #-2]
	csinv	w19, w21, w19, eq
	add	w21, w20, w23
	sub	w20, w23, w20
	lsr	w23, w21, #25
	lsr	w22, w21, #17
	asr	w21, w21, #31
	cmp	w23, #0
	lsr	w23, w20, #25
	csinv	w21, w22, w21, eq
	cmp	w23, #0
	lsr	w22, w20, #17
	asr	w20, w20, #31
	sturb	w7, [x10, #-1]
	csinv	w7, w22, w20, eq
	strb	w19, [x10, #2]
	cmp	w8, #256
	strb	w21, [x10]
	strb	w7, [x10, #1]
	add	x10, x10, x9
	b.ne	.LBB113_11
// %bb.12:
	ldp	x20, x19, [sp, #352]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #336]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #320]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #304]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #288]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #272]            // 16-byte Folded Reload
	add	sp, sp, #368
	ret
.Lfunc_end113:
	.size	_ZL16stbi__idct_blockPhiPs, .Lfunc_end113-_ZL16stbi__idct_blockPhiPs
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii
	.type	_ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii,@function
_ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii: // @_ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii
	.cfi_startproc
// %bb.0:
	cmp	w4, #1
                                        // kill: def $w5 killed $w5 def $x5
	b.lt	.LBB114_3
// %bb.1:
	mov	w11, #28416
	mov	w12, #37632
	mov	w13, #32256
	mov	w14, #23040
	sxtw	x8, w5
	mov	w9, w4
	add	x10, x0, #1
	movk	w11, #22, lsl #16
	movk	w12, #65524, lsl #16
	movk	w13, #65530, lsl #16
	movk	w14, #28, lsl #16
	mov	w15, #255
.LBB114_2:                              // =>This Inner Loop Header: Depth=1
	ldrb	w16, [x1], #1
	ldrb	w17, [x3], #1
	ldrb	w18, [x2], #1
	mov	w0, #524288
	strb	w15, [x10, #2]
	sub	w17, w17, #128
	bfi	w0, w16, #20, #8
	sub	w16, w18, #128
	madd	w18, w17, w11, w0
	mul	w4, w16, w13
	madd	w17, w17, w12, w0
	cmp	w18, #0
	madd	w16, w16, w14, w0
	and	w0, w4, #0xffff0000
	lsr	w4, w18, #20
	lsr	w18, w18, #28
	add	w17, w17, w0
	csel	w0, wzr, w15, lt
	cmp	w18, #0
	lsr	w18, w17, #20
	csel	w0, w0, w4, ne
	cmp	w17, #0
	lsr	w17, w17, #28
	csel	w4, wzr, w15, lt
	cmp	w17, #0
	lsr	w17, w16, #20
	csel	w18, w4, w18, ne
	cmp	w16, #0
	lsr	w16, w16, #28
	csel	w4, wzr, w15, lt
	cmp	w16, #0
	sturb	w0, [x10, #-1]
	csel	w16, w4, w17, ne
	strb	w18, [x10]
	subs	x9, x9, #1
	strb	w16, [x10, #1]
	add	x10, x10, x8
	b.ne	.LBB114_2
.LBB114_3:
	ret
.Lfunc_end114:
	.size	_ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii, .Lfunc_end114-_ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL23stbi__resample_row_hv_2PhS_S_ii
	.type	_ZL23stbi__resample_row_hv_2PhS_S_ii,@function
_ZL23stbi__resample_row_hv_2PhS_S_ii:   // @_ZL23stbi__resample_row_hv_2PhS_S_ii
	.cfi_startproc
// %bb.0:
	ldrb	w8, [x1]
	cmp	w3, #1
	b.ne	.LBB115_2
// %bb.1:
	ldrb	w9, [x2]
	add	w8, w8, w8, lsl #1
	add	w8, w9, w8
	add	w8, w8, #2
	lsr	w8, w8, #2
	strb	w8, [x0, #1]
	strb	w8, [x0]
	ret
.LBB115_2:
	ldrb	w9, [x2]
	add	w8, w8, w8, lsl #1
	cmp	w3, #2
	add	w16, w8, w9
	add	w8, w16, #2
	lsr	w8, w8, #2
	strb	w8, [x0]
	b.lt	.LBB115_13
// %bb.3:
	mov	w8, w3
	sub	x9, x8, #1
	cmp	x9, #16
	b.hs	.LBB115_5
// %bb.4:
	mov	w10, #1
	b	.LBB115_10
.LBB115_5:
	add	x11, x0, x8, lsl #1
	add	x10, x0, #1
	sub	x13, x11, #1
	add	x11, x1, x8
	add	x12, x1, #1
	cmp	x10, x11
	cset	w11, lo
	cmp	x12, x13
	add	x12, x2, x8
	add	x14, x2, #1
	cset	w15, lo
	cmp	x10, x12
	and	w15, w11, w15
	cset	w11, lo
	cmp	x14, x13
	mov	w10, #1
	cset	w12, lo
	tbnz	w15, #0, .LBB115_10
// %bb.6:
	and	w11, w11, w12
	tbnz	w11, #0, .LBB115_10
// %bb.7:
	and	x11, x9, #0xfffffffffffffff0
	movi	v0.4h, #3
	movi	v1.4s, #3
	movi	v2.4h, #8
	add	x12, x1, #1
	orr	x10, x11, #0x1
	add	x13, x2, #1
	add	x14, x0, #1
	mov	x15, x11
	dup	v3.4s, w16
.LBB115_8:                              // =>This Inner Loop Header: Depth=1
	ldr	q4, [x12], #16
	ldr	q5, [x13], #16
	subs	x15, x15, #16
	ushll	v6.8h, v4.8b, #0
	ushll2	v4.8h, v4.16b, #0
	ushll	v7.8h, v5.8b, #0
	ushll2	v5.8h, v5.16b, #0
	ext	v16.16b, v6.16b, v6.16b, #8
	umull	v6.4s, v6.4h, v0.4h
	ext	v17.16b, v4.16b, v4.16b, #8
	umull	v4.4s, v4.4h, v0.4h
	umull	v16.4s, v16.4h, v0.4h
	uaddw	v6.4s, v6.4s, v7.4h
	umull	v17.4s, v17.4h, v0.4h
	uaddw	v4.4s, v4.4s, v5.4h
	uaddw2	v7.4s, v16.4s, v7.8h
	ext	v16.16b, v3.16b, v6.16b, #12
	uaddw2	v3.4s, v17.4s, v5.8h
	mov	v5.16b, v6.16b
	mov	v17.16b, v4.16b
	ext	v18.16b, v6.16b, v7.16b, #12
	ext	v19.16b, v7.16b, v4.16b, #12
	ext	v20.16b, v4.16b, v3.16b, #12
	mov	v21.16b, v7.16b
	mov	v22.16b, v3.16b
	mla	v5.4s, v16.4s, v1.4s
	mla	v16.4s, v6.4s, v1.4s
	mla	v21.4s, v18.4s, v1.4s
	mla	v17.4s, v19.4s, v1.4s
	mla	v22.4s, v20.4s, v1.4s
	mla	v18.4s, v7.4s, v1.4s
	mla	v19.4s, v4.4s, v1.4s
	mla	v20.4s, v3.4s, v1.4s
	xtn	v5.4h, v5.4s
	xtn	v4.4h, v16.4s
	xtn	v6.4h, v22.4s
	xtn	v7.4h, v17.4s
	xtn	v16.4h, v21.4s
	xtn	v17.4h, v20.4s
	xtn	v19.4h, v19.4s
	xtn	v18.4h, v18.4s
	add	v5.4h, v5.4h, v2.4h
	add	v6.4h, v6.4h, v2.4h
	add	v7.4h, v7.4h, v2.4h
	add	v16.4h, v16.4h, v2.4h
	add	v17.4h, v17.4h, v2.4h
	add	v19.4h, v19.4h, v2.4h
	add	v4.4h, v4.4h, v2.4h
	add	v18.4h, v18.4h, v2.4h
	ushr	v5.4h, v5.4h, #4
	ushr	v6.4h, v6.4h, #4
	ushr	v7.4h, v7.4h, #4
	ushr	v16.4h, v16.4h, #4
	ushr	v17.4h, v17.4h, #4
	ushr	v19.4h, v19.4h, #4
	ushr	v4.4h, v4.4h, #4
	ushr	v18.4h, v18.4h, #4
	mov	v7.d[1], v6.d[0]
	mov	v5.d[1], v16.d[0]
	mov	v19.d[1], v17.d[0]
	mov	v4.d[1], v18.d[0]
	uzp1	v5.16b, v5.16b, v7.16b
	uzp1	v6.16b, v4.16b, v19.16b
	st2	{ v5.16b, v6.16b }, [x14], #32
	b.ne	.LBB115_8
// %bb.9:
	mov	w16, v3.s[3]
	cmp	x9, x11
	mov	w13, w16
	b.eq	.LBB115_12
.LBB115_10:
	add	x9, x2, x10
	add	x11, x1, x10
	add	x12, x0, x10, lsl #1
	sub	x8, x8, x10
.LBB115_11:                             // =>This Inner Loop Header: Depth=1
	ldrb	w10, [x11], #1
	ldrb	w13, [x9], #1
	subs	x8, x8, #1
	add	w10, w10, w10, lsl #1
	add	w13, w10, w13
	add	w10, w16, w16, lsl #1
	add	w10, w10, w13
	add	w14, w13, w13, lsl #1
	add	w10, w10, #8
	add	w14, w16, w14
	lsr	w10, w10, #4
	add	w14, w14, #8
	mov	w16, w13
	lsr	w14, w14, #4
	sturb	w10, [x12, #-1]
	strb	w14, [x12], #2
	b.ne	.LBB115_11
.LBB115_12:
	add	w8, w13, #2
	lsr	w8, w8, #2
.LBB115_13:
	lsl	w9, w3, #1
	add	x9, x0, w9, sxtw
	sturb	w8, [x9, #-1]
	ret
.Lfunc_end115:
	.size	_ZL23stbi__resample_row_hv_2PhS_S_ii, .Lfunc_end115-_ZL23stbi__resample_row_hv_2PhS_S_ii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL16stbi__get_markerP10stbi__jpeg
	.type	_ZL16stbi__get_markerP10stbi__jpeg,@function
_ZL16stbi__get_markerP10stbi__jpeg:     // @_ZL16stbi__get_markerP10stbi__jpeg
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	w8, #18216
	mov	x19, x0
	add	x8, x0, x8
	ldrb	w0, [x8]
	cmp	w0, #255
	b.ne	.LBB116_3
// %bb.1:
	ldr	x20, [x19]
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB116_5
// %bb.2:
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w8, [x8]
	cmp	w8, #255
	b.eq	.LBB116_11
	b	.LBB116_9
.LBB116_3:
	mov	w9, #255
	strb	w9, [x8]
.LBB116_4:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB116_5:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB116_9
// %bb.6:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB116_8
// %bb.7:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	cmp	w8, #255
	b.eq	.LBB116_11
	b	.LBB116_9
.LBB116_8:
	mov	w8, wzr
	add	x9, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	cmp	w8, #255
	b.eq	.LBB116_11
.LBB116_9:
	mov	w0, #255
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB116_10:                             //   in Loop: Header=BB116_11 Depth=1
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w0, [x8]
	cmp	w0, #255
	b.ne	.LBB116_4
.LBB116_11:                             // =>This Inner Loop Header: Depth=1
	ldr	x20, [x19]
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.lo	.LBB116_10
// %bb.12:                              //   in Loop: Header=BB116_11 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB116_16
// %bb.13:                              //   in Loop: Header=BB116_11 Depth=1
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB116_15
// %bb.14:                              //   in Loop: Header=BB116_11 Depth=1
	mov	x9, x20
	mov	w8, w0
	ldrb	w0, [x9, #56]!
	add	x8, x9, w8, sxtw
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	w0, #255
	b.eq	.LBB116_11
	b	.LBB116_4
.LBB116_15:                             //   in Loop: Header=BB116_11 Depth=1
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	w0, #255
	b.eq	.LBB116_11
	b	.LBB116_4
.LBB116_16:
	mov	w0, wzr
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end116:
	.size	_ZL16stbi__get_markerP10stbi__jpeg, .Lfunc_end116-_ZL16stbi__get_markerP10stbi__jpeg
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL20stbi__process_markerP10stbi__jpegi
	.type	_ZL20stbi__process_markerP10stbi__jpegi,@function
_ZL20stbi__process_markerP10stbi__jpegi: // @_ZL20stbi__process_markerP10stbi__jpegi
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	stp	x28, x27, [sp, #96]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	cmp	w1, #220
	b.gt	.LBB117_6
// %bb.1:
	cmp	w1, #196
	b.eq	.LBB117_9
// %bb.2:
	cmp	w1, #219
	b.ne	.LBB117_15
// %bb.3:
	ldr	x20, [x19]
	ldp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_19
// %bb.4:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB117_35
.LBB117_5:
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	b	.LBB117_38
.LBB117_6:
	cmp	w1, #221
	b.eq	.LBB117_12
// %bb.7:
	cmp	w1, #255
	b.ne	.LBB117_15
// %bb.8:
	adrp	x9, .L.str.12
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.12
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB117_150
.LBB117_9:
	ldr	x20, [x19]
	ldp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_22
// %bb.10:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB117_61
.LBB117_11:
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	b	.LBB117_64
.LBB117_12:
	ldr	x20, [x19]
	ldp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_25
// %bb.13:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB117_110
.LBB117_14:
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	b	.LBB117_114
.LBB117_15:
	cmp	w1, #254
	b.eq	.LBB117_17
// %bb.16:
	and	w8, w1, #0xfffffff0
	cmp	w8, #224
	b.ne	.LBB117_108
.LBB117_17:
	ldr	x19, [x19]
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB117_28
// %bb.18:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	b	.LBB117_127
.LBB117_19:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB117_31
// %bb.20:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_34
// %bb.21:
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_35
	b	.LBB117_5
.LBB117_22:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB117_32
// %bb.23:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_60
// %bb.24:
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_61
	b	.LBB117_11
.LBB117_25:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB117_33
// %bb.26:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_109
// %bb.27:
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_110
	b	.LBB117_14
.LBB117_28:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB117_123
// %bb.29:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB117_125
// %bb.30:
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB117_126
.LBB117_31:
	mov	w21, wzr
	cmp	x9, x8
	b.lo	.LBB117_5
	b	.LBB117_35
.LBB117_32:
	mov	w21, wzr
	cmp	x9, x8
	b.lo	.LBB117_11
	b	.LBB117_61
.LBB117_33:
	mov	w21, wzr
	cmp	x9, x8
	b.lo	.LBB117_14
	b	.LBB117_110
.LBB117_34:
	mov	w21, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.lo	.LBB117_5
.LBB117_35:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB117_38
// %bb.36:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_59
// %bb.37:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	bfi	w8, w21, #8, #8
	sub	w20, w8, #2
	cmp	w20, #1
	b.ge	.LBB117_39
	b	.LBB117_121
.LBB117_38:
	bfi	w8, w21, #8, #8
	sub	w20, w8, #2
	cmp	w20, #1
	b.lt	.LBB117_121
.LBB117_39:
	adrp	x22, _ZL19stbi__jpeg_dezigzag
	mov	w21, #13448
	add	x22, x22, :lo12:_ZL19stbi__jpeg_dezigzag
	b	.LBB117_41
.LBB117_40:                             //   in Loop: Header=BB117_41 Depth=1
	subs	w20, w20, #65
	b.le	.LBB117_121
.LBB117_41:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB117_51 Depth 2
	ldr	x23, [x19]
	ldp	x8, x9, [x23, #184]
	cmp	x8, x9
	b.hs	.LBB117_43
// %bb.42:                              //   in Loop: Header=BB117_41 Depth=1
	add	x9, x8, #1
	str	x9, [x23, #184]
	ldrb	w8, [x8]
	cmp	w8, #16
	b.lo	.LBB117_47
	b	.LBB117_57
.LBB117_43:                             //   in Loop: Header=BB117_41 Depth=1
	ldr	w8, [x23, #48]
	cbz	w8, .LBB117_48
// %bb.44:                              //   in Loop: Header=BB117_41 Depth=1
	ldr	x8, [x23, #16]
	add	x1, x23, #56
	ldr	x0, [x23, #40]
	ldr	w2, [x23, #52]
	blr	x8
	cbz	w0, .LBB117_46
// %bb.45:                              //   in Loop: Header=BB117_41 Depth=1
	mov	x9, x23
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x23, #57
	stp	x10, x9, [x23, #184]
	cmp	w8, #16
	b.lo	.LBB117_47
	b	.LBB117_57
.LBB117_46:                             //   in Loop: Header=BB117_41 Depth=1
	mov	w8, wzr
	add	x9, x23, #57
	str	wzr, [x23, #48]
	strb	wzr, [x23, #56]
	add	x10, x23, #57
	stp	x10, x9, [x23, #184]
	cmp	w8, #16
	b.hs	.LBB117_57
.LBB117_47:                             //   in Loop: Header=BB117_41 Depth=1
	and	w8, w8, #0xf
	cmp	w8, #3
	b.hi	.LBB117_58
.LBB117_48:                             //   in Loop: Header=BB117_41 Depth=1
	mov	x23, xzr
	mov	w24, w8
	b	.LBB117_51
.LBB117_49:                             //   in Loop: Header=BB117_51 Depth=2
	add	x9, x8, #1
	str	x9, [x25, #184]
	ldrb	w8, [x8]
.LBB117_50:                             //   in Loop: Header=BB117_51 Depth=2
	ldrb	w9, [x22, x23]
	add	x10, x19, x24, lsl #6
	add	x23, x23, #1
	cmp	x23, #64
	add	x9, x10, x9
	strb	w8, [x9, x21]
	b.eq	.LBB117_40
.LBB117_51:                             //   Parent Loop BB117_41 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x25, [x19]
	ldp	x8, x9, [x25, #184]
	cmp	x8, x9
	b.lo	.LBB117_49
// %bb.52:                              //   in Loop: Header=BB117_51 Depth=2
	ldr	w8, [x25, #48]
	cbz	w8, .LBB117_50
// %bb.53:                              //   in Loop: Header=BB117_51 Depth=2
	ldr	x8, [x25, #16]
	add	x1, x25, #56
	ldr	x0, [x25, #40]
	ldr	w2, [x25, #52]
	blr	x8
	cbz	w0, .LBB117_55
// %bb.54:                              //   in Loop: Header=BB117_51 Depth=2
	mov	x9, x25
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB117_56
.LBB117_55:                             //   in Loop: Header=BB117_51 Depth=2
	mov	w8, wzr
	add	x9, x25, #57
	str	wzr, [x25, #48]
	strb	wzr, [x25, #56]
.LBB117_56:                             //   in Loop: Header=BB117_51 Depth=2
	add	x10, x25, #57
	stp	x10, x9, [x25, #184]
	b	.LBB117_50
.LBB117_57:
	adrp	x9, .L.str.14
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.14
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB117_150
.LBB117_58:
	adrp	x9, .L.str.15
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.15
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB117_150
.LBB117_59:
	mov	w8, wzr
	add	x9, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	bfi	w8, w21, #8, #8
	sub	w20, w8, #2
	cmp	w20, #1
	b.ge	.LBB117_39
	b	.LBB117_121
.LBB117_60:
	mov	w21, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.lo	.LBB117_11
.LBB117_61:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB117_64
// %bb.62:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_120
// %bb.63:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	bfi	w8, w21, #8, #8
	sub	w20, w8, #2
	cmp	w20, #1
	b.ge	.LBB117_65
	b	.LBB117_121
.LBB117_64:
	bfi	w8, w21, #8, #8
	sub	w20, w8, #2
	cmp	w20, #1
	b.lt	.LBB117_121
.LBB117_65:
	mov	w8, #13704
	mov	w9, #6728
	add	x8, x19, x8
	add	x23, sp, #16
	mov	w24, #1680
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	add	x8, x19, x9
	str	x8, [sp]                        // 8-byte Folded Spill
	b	.LBB117_67
.LBB117_66:                             //   in Loop: Header=BB117_67 Depth=1
	sub	w20, w8, w26
	cmp	w20, #0
	b.le	.LBB117_121
.LBB117_67:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB117_80 Depth 2
                                        //     Child Loop BB117_94 Depth 2
                                        //     Child Loop BB117_103 Depth 2
	ldr	x21, [x19]
	ldp	x8, x9, [x21, #184]
	cmp	x8, x9
	b.hs	.LBB117_69
// %bb.68:                              //   in Loop: Header=BB117_67 Depth=1
	add	x9, x8, #1
	str	x9, [x21, #184]
	ldrb	w27, [x8]
	b	.LBB117_75
.LBB117_69:                             //   in Loop: Header=BB117_67 Depth=1
	ldr	w8, [x21, #48]
	cbz	w8, .LBB117_72
// %bb.70:                              //   in Loop: Header=BB117_67 Depth=1
	ldr	x8, [x21, #16]
	add	x1, x21, #56
	ldr	x0, [x21, #40]
	ldr	w2, [x21, #52]
	blr	x8
	cbz	w0, .LBB117_73
// %bb.71:                              //   in Loop: Header=BB117_67 Depth=1
	mov	x8, x21
	ldrb	w27, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB117_74
.LBB117_72:                             //   in Loop: Header=BB117_67 Depth=1
	mov	w27, wzr
	b	.LBB117_75
.LBB117_73:                             //   in Loop: Header=BB117_67 Depth=1
	mov	w27, wzr
	add	x8, x21, #57
	str	wzr, [x21, #48]
	strb	wzr, [x21, #56]
.LBB117_74:                             //   in Loop: Header=BB117_67 Depth=1
	add	x9, x21, #57
	stp	x9, x8, [x21, #184]
.LBB117_75:                             //   in Loop: Header=BB117_67 Depth=1
	cmp	w27, #31
	b.hi	.LBB117_107
// %bb.76:                              //   in Loop: Header=BB117_67 Depth=1
	and	w21, w27, #0xf
	cmp	w21, #3
	b.hi	.LBB117_107
// %bb.77:                              //   in Loop: Header=BB117_67 Depth=1
	mov	w25, #7752
	mov	x28, xzr
	mov	w26, wzr
	b	.LBB117_80
.LBB117_78:                             //   in Loop: Header=BB117_80 Depth=2
	add	x9, x8, #1
	str	x9, [x22, #184]
	ldrb	w8, [x8]
.LBB117_79:                             //   in Loop: Header=BB117_80 Depth=2
	str	w8, [x23, x28]
	add	w26, w26, w8
	add	x28, x28, #4
	cmp	x28, #64
	b.eq	.LBB117_86
.LBB117_80:                             //   Parent Loop BB117_67 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x22, [x19]
	ldp	x8, x9, [x22, #184]
	cmp	x8, x9
	b.lo	.LBB117_78
// %bb.81:                              //   in Loop: Header=BB117_80 Depth=2
	ldr	w8, [x22, #48]
	cbz	w8, .LBB117_79
// %bb.82:                              //   in Loop: Header=BB117_80 Depth=2
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB117_84
// %bb.83:                              //   in Loop: Header=BB117_80 Depth=2
	mov	x9, x22
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB117_85
.LBB117_84:                             //   in Loop: Header=BB117_80 Depth=2
	mov	w8, wzr
	add	x9, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
.LBB117_85:                             //   in Loop: Header=BB117_80 Depth=2
	add	x10, x22, #57
	stp	x10, x9, [x22, #184]
	b	.LBB117_79
.LBB117_86:                             //   in Loop: Header=BB117_67 Depth=1
	madd	x8, x21, x24, x19
	cmp	w27, #15
	b.hi	.LBB117_89
// %bb.87:                              //   in Loop: Header=BB117_67 Depth=1
	add	x0, x8, #8
	add	x1, sp, #16
	bl	_ZL19stbi__build_huffmanP13stbi__huffmanPi
	cbz	w0, .LBB117_108
// %bb.88:                              //   in Loop: Header=BB117_67 Depth=1
	madd	x8, x21, x24, x19
	add	x28, x8, #1032
	cbnz	w26, .LBB117_91
	b	.LBB117_100
.LBB117_89:                             //   in Loop: Header=BB117_67 Depth=1
	mov	w9, #6728
	add	x1, sp, #16
	add	x0, x8, x9
	bl	_ZL19stbi__build_huffmanP13stbi__huffmanPi
	cbz	w0, .LBB117_108
// %bb.90:                              //   in Loop: Header=BB117_67 Depth=1
	madd	x8, x21, x24, x19
	add	x28, x8, x25
	cbz	w26, .LBB117_100
.LBB117_91:                             //   in Loop: Header=BB117_67 Depth=1
	mov	x22, x26
	b	.LBB117_94
.LBB117_92:                             //   in Loop: Header=BB117_94 Depth=2
	add	x9, x8, #1
	str	x9, [x25, #184]
	ldrb	w8, [x8]
.LBB117_93:                             //   in Loop: Header=BB117_94 Depth=2
	subs	x22, x22, #1
	strb	w8, [x28], #1
	b.eq	.LBB117_100
.LBB117_94:                             //   Parent Loop BB117_67 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	x25, [x19]
	ldp	x8, x9, [x25, #184]
	cmp	x8, x9
	b.lo	.LBB117_92
// %bb.95:                              //   in Loop: Header=BB117_94 Depth=2
	ldr	w8, [x25, #48]
	cbz	w8, .LBB117_93
// %bb.96:                              //   in Loop: Header=BB117_94 Depth=2
	ldr	x8, [x25, #16]
	add	x1, x25, #56
	ldr	x0, [x25, #40]
	ldr	w2, [x25, #52]
	blr	x8
	cbz	w0, .LBB117_98
// %bb.97:                              //   in Loop: Header=BB117_94 Depth=2
	mov	x9, x25
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB117_99
.LBB117_98:                             //   in Loop: Header=BB117_94 Depth=2
	mov	w8, wzr
	add	x9, x25, #57
	str	wzr, [x25, #48]
	strb	wzr, [x25, #56]
.LBB117_99:                             //   in Loop: Header=BB117_94 Depth=2
	add	x10, x25, #57
	stp	x10, x9, [x25, #184]
	b	.LBB117_93
.LBB117_100:                            //   in Loop: Header=BB117_67 Depth=1
	sub	w8, w20, #17
	mov	w17, #7752
	mov	w18, #8008
	mov	w0, #9
	mov	w1, #-1
	cmp	w27, #16
	b.lo	.LBB117_66
// %bb.101:                             //   in Loop: Header=BB117_67 Depth=1
	ldp	x10, x11, [sp]                  // 16-byte Folded Reload
	mov	x9, xzr
	madd	x10, x21, x24, x10
	add	x11, x11, x21, lsl #10
	b	.LBB117_103
.LBB117_102:                            //   in Loop: Header=BB117_103 Depth=2
	add	x9, x9, #1
	cmp	x9, #512
	b.eq	.LBB117_66
.LBB117_103:                            //   Parent Loop BB117_67 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w12, [x10, x9]
	strh	wzr, [x11, x9, lsl #1]
	cmp	x12, #255
	b.eq	.LBB117_102
// %bb.104:                             //   in Loop: Header=BB117_103 Depth=2
	madd	x13, x21, x24, x19
	add	x13, x13, x12
	ldrb	w12, [x13, x17]
	ldrb	w15, [x13, x18]
	and	w14, w12, #0xf
	cmp	w14, #0
	add	w13, w14, w15
	ccmp	w13, #9, #2, ne
	b.hi	.LBB117_102
// %bb.105:                             //   in Loop: Header=BB117_103 Depth=2
	lsl	w15, w9, w15
	sub	w16, w0, w14
	and	w15, w15, #0x1ff
	lsl	w14, w1, w14
	orr	w14, w14, #0x1
	cmp	w15, #256
	lsr	w15, w15, w16
	csel	w14, w14, wzr, lo
	add	w14, w14, w15
	cmp	w14, w14, sxtb
	b.ne	.LBB117_102
// %bb.106:                             //   in Loop: Header=BB117_103 Depth=2
	and	w12, w12, #0xf0
	add	w12, w13, w12
	add	w12, w12, w14, lsl #8
	strh	w12, [x11, x9, lsl #1]
	b	.LBB117_102
.LBB117_107:
	adrp	x9, .L.str.16
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.16
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB117_108:
	mov	w0, wzr
	b	.LBB117_150
.LBB117_109:
	mov	w21, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.lo	.LBB117_14
.LBB117_110:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB117_114
// %bb.111:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_122
// %bb.112:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	bfi	w8, w21, #8, #8
	cmp	w8, #4
	b.eq	.LBB117_115
.LBB117_113:
	adrp	x9, .L.str.13
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.13
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB117_150
.LBB117_114:
	bfi	w8, w21, #8, #8
	cmp	w8, #4
	b.ne	.LBB117_113
.LBB117_115:
	ldr	x20, [x19]
	ldp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.hs	.LBB117_117
// %bb.116:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	b	.LBB117_134
.LBB117_117:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB117_124
// %bb.118:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_132
// %bb.119:
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB117_133
.LBB117_120:
	mov	w8, wzr
	add	x9, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	bfi	w8, w21, #8, #8
	sub	w20, w8, #2
	cmp	w20, #1
	b.ge	.LBB117_65
.LBB117_121:
	cmp	w20, #0
	cset	w0, eq
	b	.LBB117_150
.LBB117_122:
	mov	w8, wzr
	add	x9, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
	bfi	w8, w21, #8, #8
	cmp	w8, #4
	b.eq	.LBB117_115
	b	.LBB117_113
.LBB117_123:
	mov	w20, wzr
	b	.LBB117_127
.LBB117_124:
	mov	w21, wzr
	b	.LBB117_134
.LBB117_125:
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB117_126:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB117_127:
	cmp	x9, x8
	b.hs	.LBB117_129
// %bb.128:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB117_141
.LBB117_129:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB117_141
// %bb.130:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB117_139
// %bb.131:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB117_140
.LBB117_132:
	mov	w21, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB117_133:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB117_134:
	cmp	x9, x8
	b.hs	.LBB117_136
// %bb.135:
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	b	.LBB117_149
.LBB117_136:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB117_149
// %bb.137:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB117_147
// %bb.138:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB117_148
.LBB117_139:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB117_140:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB117_141:
	bfi	w10, w20, #8, #8
	cmp	w10, #1
	b.ls	.LBB117_146
// %bb.142:
	ldr	x11, [x19, #16]
	sub	w10, w10, #2
	cbz	x11, .LBB117_145
// %bb.143:
	sub	w11, w8, w9
	subs	w1, w10, w11
	b.le	.LBB117_145
// %bb.144:
	ldr	x9, [x19, #24]
	str	x8, [x19, #184]
	ldr	x0, [x19, #40]
	blr	x9
	mov	w0, #1
	b	.LBB117_150
.LBB117_145:
	add	x8, x9, w10, uxtw
.LBB117_146:
	mov	w0, #1
	str	x8, [x19, #184]
	b	.LBB117_150
.LBB117_147:
	mov	w8, wzr
	add	x9, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB117_148:
	add	x10, x20, #57
	stp	x10, x9, [x20, #184]
.LBB117_149:
	mov	w9, #18268
	bfi	w8, w21, #8, #8
	mov	w0, #1
	str	w8, [x19, x9]
.LBB117_150:
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	add	sp, sp, #176
	ret
.Lfunc_end117:
	.size	_ZL20stbi__process_markerP10stbi__jpegi, .Lfunc_end117-_ZL20stbi__process_markerP10stbi__jpegi
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL26stbi__process_frame_headerP10stbi__jpegi
	.type	_ZL26stbi__process_frame_headerP10stbi__jpegi,@function
_ZL26stbi__process_frame_headerP10stbi__jpegi: // @_ZL26stbi__process_frame_headerP10stbi__jpegi
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #144
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x28, x27, [sp, #64]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	x22, [x0]
	mov	x19, x0
	mov	w20, w1
	ldp	x10, x8, [x22, #184]
	cmp	x10, x8
	b.hs	.LBB118_3
// %bb.1:
	add	x9, x10, #1
	str	x9, [x22, #184]
	ldrb	w23, [x10]
	mov	x10, x9
	cmp	x10, x8
	b.hs	.LBB118_8
.LBB118_2:
	add	x9, x10, #1
	str	x9, [x22, #184]
	ldrb	w21, [x10]
	mov	x10, x9
	bfi	w21, w23, #8, #8
	cmp	w21, #11
	b.hs	.LBB118_13
	b	.LBB118_97
.LBB118_3:
	ldr	w9, [x22, #48]
	cbz	w9, .LBB118_6
// %bb.4:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_7
// %bb.5:
	mov	x8, x22
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x22, #57
	stp	x10, x8, [x22, #184]
	cmp	x10, x8
	b.hs	.LBB118_8
	b	.LBB118_2
.LBB118_6:
	mov	w23, wzr
	cmp	x10, x8
	b.lo	.LBB118_2
	b	.LBB118_8
.LBB118_7:
	mov	w23, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x10, x22, #57
	stp	x10, x8, [x22, #184]
	cmp	x10, x8
	b.lo	.LBB118_2
.LBB118_8:
	ldr	w9, [x22, #48]
	cbz	w9, .LBB118_11
// %bb.9:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_12
// %bb.10:
	mov	x8, x22
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x22, #57
	stp	x10, x8, [x22, #184]
	bfi	w21, w23, #8, #8
	cmp	w21, #11
	b.lo	.LBB118_97
	b	.LBB118_13
.LBB118_11:
	mov	w21, wzr
	bfi	w21, w23, #8, #8
	cmp	w21, #11
	b.lo	.LBB118_97
	b	.LBB118_13
.LBB118_12:
	mov	w21, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x10, x22, #57
	stp	x10, x8, [x22, #184]
	bfi	w21, w23, #8, #8
	cmp	w21, #11
	b.lo	.LBB118_97
.LBB118_13:
	cmp	x10, x8
	b.hs	.LBB118_15
// %bb.14:
	add	x9, x10, #1
	str	x9, [x22, #184]
	ldrb	w10, [x10]
	cmp	w10, #8
	b.ne	.LBB118_25
	b	.LBB118_18
.LBB118_15:
	ldr	w8, [x22, #48]
	cbz	w8, .LBB118_25
// %bb.16:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_24
// %bb.17:
	mov	x8, x22
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	cmp	w10, #8
	b.ne	.LBB118_25
.LBB118_18:
	cmp	x9, x8
	b.hs	.LBB118_21
// %bb.19:
	add	x10, x9, #1
	str	x10, [x22, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB118_28
.LBB118_20:
	add	x11, x9, #1
	str	x11, [x22, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB118_32
.LBB118_21:
	ldr	w10, [x22, #48]
	cbz	w10, .LBB118_26
// %bb.22:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_27
// %bb.23:
	mov	x8, x22
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	cmp	x9, x8
	b.hs	.LBB118_28
	b	.LBB118_20
.LBB118_24:
	mov	w10, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	cmp	w10, #8
	b.eq	.LBB118_18
.LBB118_25:
	adrp	x23, .L.str.19
	add	x23, x23, :lo12:.L.str.19
	b	.LBB118_98
.LBB118_26:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB118_20
	b	.LBB118_28
.LBB118_27:
	mov	w23, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	cmp	x9, x8
	b.lo	.LBB118_20
.LBB118_28:
	ldr	w10, [x22, #48]
	cbz	w10, .LBB118_32
// %bb.29:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_39
// %bb.30:
	mov	x8, x22
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	bfi	w10, w23, #8, #8
	str	w10, [x22, #4]
	cbnz	w10, .LBB118_33
.LBB118_31:
	adrp	x23, .L.str.20
	add	x23, x23, :lo12:.L.str.20
	b	.LBB118_98
.LBB118_32:
	bfi	w10, w23, #8, #8
	str	w10, [x22, #4]
	cbz	w10, .LBB118_31
.LBB118_33:
	cmp	x9, x8
	b.hs	.LBB118_36
// %bb.34:
	add	x10, x9, #1
	str	x10, [x22, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB118_43
.LBB118_35:
	add	x11, x9, #1
	str	x11, [x22, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB118_47
.LBB118_36:
	ldr	w10, [x22, #48]
	cbz	w10, .LBB118_40
// %bb.37:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_41
// %bb.38:
	mov	x8, x22
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB118_42
.LBB118_39:
	mov	w10, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	bfi	w10, w23, #8, #8
	str	w10, [x22, #4]
	cbnz	w10, .LBB118_33
	b	.LBB118_31
.LBB118_40:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB118_35
	b	.LBB118_43
.LBB118_41:
	mov	w23, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
.LBB118_42:
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	cmp	x9, x8
	b.lo	.LBB118_35
.LBB118_43:
	ldr	w10, [x22, #48]
	cbz	w10, .LBB118_47
// %bb.44:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_53
// %bb.45:
	mov	x8, x22
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	bfi	w10, w23, #8, #8
	str	w10, [x22]
	cbnz	w10, .LBB118_48
.LBB118_46:
	adrp	x23, .L.str.21
	add	x23, x23, :lo12:.L.str.21
	b	.LBB118_98
.LBB118_47:
	bfi	w10, w23, #8, #8
	str	w10, [x22]
	cbz	w10, .LBB118_46
.LBB118_48:
	cmp	x9, x8
	b.hs	.LBB118_50
// %bb.49:
	add	x10, x9, #1
	str	x10, [x22, #184]
	ldrb	w9, [x9]
	and	w11, w9, #0xfffffffd
	cmp	w11, #1
	b.ne	.LBB118_58
	b	.LBB118_56
.LBB118_50:
	ldr	w8, [x22, #48]
	cbz	w8, .LBB118_58
// %bb.51:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_54
// %bb.52:
	mov	x8, x22
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB118_55
.LBB118_53:
	mov	w10, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x9, x22, #57
	stp	x9, x8, [x22, #184]
	bfi	w10, w23, #8, #8
	str	w10, [x22]
	cbnz	w10, .LBB118_48
	b	.LBB118_46
.LBB118_54:
	mov	w9, wzr
	add	x8, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
.LBB118_55:
	add	x10, x22, #57
	stp	x10, x8, [x22, #184]
	and	w11, w9, #0xfffffffd
	cmp	w11, #1
	b.ne	.LBB118_58
.LBB118_56:
	mov	w11, w9
	cmp	w9, #2
	str	w9, [x22, #8]
	b.hs	.LBB118_59
// %bb.57:
	mov	x12, xzr
	b	.LBB118_62
.LBB118_58:
	adrp	x23, .L.str.22
	add	x23, x23, :lo12:.L.str.22
	b	.LBB118_98
.LBB118_59:
	and	x12, x11, #0xfe
	mov	w13, #17992
	add	x13, x19, x13
	mov	x14, x12
.LBB118_60:                             // =>This Inner Loop Header: Depth=1
	subs	x14, x14, #2
	stur	xzr, [x13, #-120]
	stur	xzr, [x13, #-24]
	stur	xzr, [x13, #-96]
	str	xzr, [x13], #192
	b.ne	.LBB118_60
// %bb.61:
	cmp	x12, x11
	b.eq	.LBB118_64
.LBB118_62:
	mov	w13, #96
	mov	w14, #17872
	sub	x11, x11, x12
	madd	x13, x12, x13, x19
	add	x13, x13, x14
.LBB118_63:                             // =>This Inner Loop Header: Depth=1
	str	xzr, [x13]
	subs	x11, x11, #1
	str	xzr, [x13, #24]
	add	x13, x13, #96
	b.ne	.LBB118_63
.LBB118_64:
	add	w11, w9, w9, lsl #1
	add	w11, w11, #8
	cmp	w21, w11
	b.ne	.LBB118_97
// %bb.65:
	cbz	w9, .LBB118_95
// %bb.66:
	mov	w9, #17836
	adrp	x23, .L.str.23
	adrp	x26, .L.str.24
	mov	x28, xzr
	add	x21, x22, #56
	add	x25, x22, #57
	add	x24, x19, x9
	add	x23, x23, :lo12:.L.str.23
	add	x26, x26, :lo12:.L.str.24
.LBB118_67:                             // =>This Inner Loop Header: Depth=1
	cmp	x10, x8
	b.hs	.LBB118_69
// %bb.68:                              //   in Loop: Header=BB118_67 Depth=1
	add	x11, x10, #1
	str	x11, [x22, #184]
	ldrb	w9, [x10]
	mov	x10, x11
	b	.LBB118_74
.LBB118_69:                             //   in Loop: Header=BB118_67 Depth=1
	ldr	w9, [x22, #48]
	cbz	w9, .LBB118_74
// %bb.70:                              //   in Loop: Header=BB118_67 Depth=1
	ldr	x8, [x22, #16]
	mov	x1, x21
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_72
// %bb.71:                              //   in Loop: Header=BB118_67 Depth=1
	mov	x8, x22
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB118_73
.LBB118_72:                             //   in Loop: Header=BB118_67 Depth=1
	mov	w9, wzr
	mov	x8, x25
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
.LBB118_73:                             //   in Loop: Header=BB118_67 Depth=1
	mov	x10, x25
	stp	x25, x8, [x22, #184]
.LBB118_74:                             //   in Loop: Header=BB118_67 Depth=1
	add	x27, x28, #1
	mov	w11, w9
	cmp	x27, x11
	stur	w9, [x24, #-12]
	b.eq	.LBB118_76
// %bb.75:                              //   in Loop: Header=BB118_67 Depth=1
	cmp	x28, x11
	b.ne	.LBB118_98
.LBB118_76:                             //   in Loop: Header=BB118_67 Depth=1
	cmp	x10, x8
	b.hs	.LBB118_78
// %bb.77:                              //   in Loop: Header=BB118_67 Depth=1
	add	x11, x10, #1
	str	x11, [x22, #184]
	ldrb	w9, [x10]
	mov	x10, x11
	b	.LBB118_83
.LBB118_78:                             //   in Loop: Header=BB118_67 Depth=1
	ldr	w8, [x22, #48]
	cbz	w8, .LBB118_108
// %bb.79:                              //   in Loop: Header=BB118_67 Depth=1
	ldr	x8, [x22, #16]
	mov	x1, x21
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_81
// %bb.80:                              //   in Loop: Header=BB118_67 Depth=1
	mov	x8, x22
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB118_82
.LBB118_81:                             //   in Loop: Header=BB118_67 Depth=1
	mov	w9, wzr
	mov	x8, x25
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
.LBB118_82:                             //   in Loop: Header=BB118_67 Depth=1
	mov	x10, x25
	stp	x25, x8, [x22, #184]
.LBB118_83:                             //   in Loop: Header=BB118_67 Depth=1
	lsr	w11, w9, #4
	sub	w12, w9, #80
	cmn	w12, #64
	stur	w11, [x24, #-8]
	b.lo	.LBB118_102
// %bb.84:                              //   in Loop: Header=BB118_67 Depth=1
	and	w9, w9, #0xf
	sub	w11, w9, #5
	cmn	w11, #4
	stur	w9, [x24, #-4]
	b.lo	.LBB118_103
// %bb.85:                              //   in Loop: Header=BB118_67 Depth=1
	cmp	x10, x8
	b.hs	.LBB118_87
// %bb.86:                              //   in Loop: Header=BB118_67 Depth=1
	add	x11, x10, #1
	str	x11, [x22, #184]
	ldrb	w9, [x10]
	mov	x10, x11
	b	.LBB118_93
.LBB118_87:                             //   in Loop: Header=BB118_67 Depth=1
	ldr	w9, [x22, #48]
	cbz	w9, .LBB118_90
// %bb.88:                              //   in Loop: Header=BB118_67 Depth=1
	ldr	x8, [x22, #16]
	mov	x1, x21
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB118_91
// %bb.89:                              //   in Loop: Header=BB118_67 Depth=1
	mov	x8, x22
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB118_92
.LBB118_90:                             //   in Loop: Header=BB118_67 Depth=1
	str	wzr, [x24]
	b	.LBB118_94
.LBB118_91:                             //   in Loop: Header=BB118_67 Depth=1
	mov	w9, wzr
	mov	x8, x25
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
.LBB118_92:                             //   in Loop: Header=BB118_67 Depth=1
	mov	x10, x25
	stp	x25, x8, [x22, #184]
.LBB118_93:                             //   in Loop: Header=BB118_67 Depth=1
	cmp	w9, #3
	str	w9, [x24]
	b.hi	.LBB118_104
.LBB118_94:                             //   in Loop: Header=BB118_67 Depth=1
	ldrsw	x9, [x22, #8]
	add	x24, x24, #96
	mov	x28, x27
	cmp	x27, x9
	b.lt	.LBB118_67
.LBB118_95:
	cbz	w20, .LBB118_100
.LBB118_96:
	mov	w8, #1
	b	.LBB118_99
.LBB118_97:
	adrp	x23, .L.str.18
	add	x23, x23, :lo12:.L.str.18
.LBB118_98:
	adrp	x9, .L_MergedGlobals.126+8
	mov	w8, wzr
	str	x23, [x9, :lo12:.L_MergedGlobals.126+8]
.LBB118_99:
	ldp	x20, x19, [sp, #128]            // 16-byte Folded Reload
	mov	w0, w8
	ldp	x22, x21, [sp, #112]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	add	sp, sp, #144
	ret
.LBB118_100:
	ldp	w10, w11, [x22]
	mov	w8, #1073741824
	udiv	w8, w8, w10
	stp	w11, w10, [x29, #-8]            // 8-byte Folded Spill
	udiv	w8, w8, w9
	cmp	w8, w11
	b.hs	.LBB118_105
// %bb.101:
	adrp	x23, .L.str.27
	add	x23, x23, :lo12:.L.str.27
	b	.LBB118_98
.LBB118_102:
	mov	x23, x26
	b	.LBB118_98
.LBB118_103:
	adrp	x23, .L.str.25
	add	x23, x23, :lo12:.L.str.25
	b	.LBB118_98
.LBB118_104:
	adrp	x23, .L.str.26
	add	x23, x23, :lo12:.L.str.26
	b	.LBB118_98
.LBB118_105:
	mov	w8, #17808
	cmp	w9, #1
	add	x8, x19, x8
	stur	x8, [x29, #-16]                 // 8-byte Folded Spill
	b.lt	.LBB118_109
// %bb.106:
	mov	w8, w9
	cmp	w9, #1
	b.ne	.LBB118_110
// %bb.107:
	movi	v0.2s, #1
	mov	x10, xzr
	b	.LBB118_113
.LBB118_108:
	adrp	x23, .L.str.24
	stur	wzr, [x24, #-8]
	add	x23, x23, :lo12:.L.str.24
	b	.LBB118_98
.LBB118_109:
	movi	v0.2s, #1
	b	.LBB118_115
.LBB118_110:
	and	x10, x8, #0xfffffffe
	mov	w11, #17924
	movi	v0.2s, #1
	movi	v1.2s, #1
	add	x11, x19, x11
	mov	x12, x10
.LBB118_111:                            // =>This Inner Loop Header: Depth=1
	ldur	d2, [x11, #-96]
	subs	x12, x12, #2
	ldr	d3, [x11], #192
	smax	v0.2s, v2.2s, v0.2s
	smax	v1.2s, v3.2s, v1.2s
	b.ne	.LBB118_111
// %bb.112:
	smax	v0.2s, v0.2s, v1.2s
	cmp	x10, x8
	b.eq	.LBB118_115
.LBB118_113:
	mov	w11, #96
	mov	w12, #17828
	sub	x8, x8, x10
	madd	x11, x10, x11, x19
	add	x11, x11, x12
.LBB118_114:                            // =>This Inner Loop Header: Depth=1
	ldr	d1, [x11], #96
	subs	x8, x8, #1
	smax	v0.2s, v1.2s, v0.2s
	b.ne	.LBB118_114
.LBB118_115:
	shl	v1.2s, v0.2s, #3
	ldur	w10, [x29, #-4]                 // 4-byte Folded Reload
	cmp	w9, #1
	str	d0, [x19, #17800]
	fmov	w8, s1
	str	d1, [x19, #17816]
	add	w10, w10, w8
	sub	w10, w10, #1
	udiv	w11, w10, w8
	mov	w8, v1.s[1]
	ldur	w10, [x29, #-8]                 // 4-byte Folded Reload
	add	w10, w10, w8
	sub	w10, w10, #1
	udiv	w26, w10, w8
	ldur	x8, [x29, #-16]                 // 8-byte Folded Reload
	stur	w11, [x29, #-20]                // 4-byte Folded Spill
	stp	w11, w26, [x8]
	b.lt	.LBB118_96
// %bb.116:
	mov	w8, #17784
	mov	w12, v0.s[1]
	add	x8, x19, x8
	fmov	w28, s0
	mov	w10, #96
	mov	w11, #17916
	mov	x25, xzr
	add	x23, x19, x11
	str	x8, [sp, #8]                    // 8-byte Folded Spill
	umull	x8, w9, w10
	sub	w13, w28, #1
	mov	w22, w12
	sub	w21, w12, #1
	mov	w24, #1
	str	w13, [sp, #24]                  // 4-byte Folded Spill
	str	x8, [sp, #16]                   // 8-byte Folded Spill
	b	.LBB118_119
.LBB118_117:                            //   in Loop: Header=BB118_119 Depth=1
	mul	w8, w20, w27
	mov	w0, #15
	add	x9, x23, x25
	lsl	w8, w8, #6
	sxtw	x8, w8
	lsr	x8, x8, #6
	stp	w20, w27, [x9, #-4]
	bfi	x0, x8, #7, #57
	bl	malloc
	add	x8, x0, #15
	and	x9, x8, #0xfffffffffffffff0
.LBB118_118:                            //   in Loop: Header=BB118_119 Depth=1
	ldr	x11, [sp, #16]                  // 8-byte Folded Reload
	add	x10, x19, x25
	add	x24, x24, #1
	add	x25, x25, #96
	mov	w8, #1
	cmp	x11, x25
	str	x9, [x10, #17904]
	str	x0, [x10, #17888]
	b.eq	.LBB118_99
.LBB118_119:                            // =>This Inner Loop Header: Depth=1
	add	x8, x23, x25
	ldur	w11, [x29, #-4]                 // 4-byte Folded Reload
	ldr	w12, [sp, #24]                  // 4-byte Folded Reload
	ldur	w13, [x29, #-20]                // 4-byte Folded Reload
	ldp	w9, w10, [x8, #-88]
	madd	w11, w9, w11, w12
	ldur	w12, [x29, #-8]                 // 4-byte Folded Reload
	mul	w20, w9, w13
	mul	w27, w10, w26
	madd	w12, w10, w12, w21
	udiv	w11, w11, w28
	lsl	w10, w20, #3
	udiv	w9, w12, w22
	lsl	w12, w27, #3
	mul	w13, w12, w10
	stp	w10, w12, [x8, #-56]
	orr	w13, w13, #0xf
	sxtw	x0, w13
	stp	w11, w9, [x8, #-64]
	bl	malloc
	add	x8, x19, x25
	str	x0, [x8, #17880]
	cbz	x0, .LBB118_122
// %bb.120:                             //   in Loop: Header=BB118_119 Depth=1
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	add	x9, x0, #15
	and	x9, x9, #0xfffffffffffffff0
	str	xzr, [x8, #17896]
	ldr	w10, [x10, #416]
	str	x9, [x8, #17872]
	cbnz	w10, .LBB118_117
// %bb.121:                             //   in Loop: Header=BB118_119 Depth=1
	mov	x9, xzr
	mov	x0, xzr
	b	.LBB118_118
.LBB118_122:
	cmp	w24, #1
	b.ne	.LBB118_124
// %bb.123:
	adrp	x23, .L.str.28
	add	x23, x23, :lo12:.L.str.28
	b	.LBB118_98
.LBB118_124:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	adrp	x23, .L.str.28
	add	x23, x23, :lo12:.L.str.28
	add	x19, x8, x25
.LBB118_125:                            // =>This Inner Loop Header: Depth=1
	ldr	x0, [x19]
	bl	free
	stur	xzr, [x19, #-8]
	sub	x24, x24, #1
	sub	x19, x19, #96
	cmp	x24, #1
	b.gt	.LBB118_125
	b	.LBB118_98
.Lfunc_end118:
	.size	_ZL26stbi__process_frame_headerP10stbi__jpegi, .Lfunc_end118-_ZL26stbi__process_frame_headerP10stbi__jpegi
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL10stbi__get8P13stbi__context
	.type	_ZL10stbi__get8P13stbi__context,@function
_ZL10stbi__get8P13stbi__context:        // @_ZL10stbi__get8P13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldp	x8, x9, [x0, #184]
	mov	x19, x0
	cmp	x8, x9
	b.hs	.LBB119_2
// %bb.1:
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w0, [x8]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB119_2:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB119_5
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB119_6
// %bb.4:
	mov	x9, x19
	mov	w8, w0
	ldrb	w0, [x9, #56]!
	add	x8, x9, w8, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB119_5:
	mov	w0, wzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB119_6:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end119:
	.size	_ZL10stbi__get8P13stbi__context, .Lfunc_end119-_ZL10stbi__get8P13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL19stbi__build_huffmanP13stbi__huffmanPi
	.type	_ZL19stbi__build_huffmanP13stbi__huffmanPi,@function
_ZL19stbi__build_huffmanP13stbi__huffmanPi: // @_ZL19stbi__build_huffmanP13stbi__huffmanPi
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	stp	x24, x23, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldr	w8, [x1]
	mov	x19, x0
	cmp	w8, #1
	b.lt	.LBB120_18
// %bb.1:
	mov	x8, xzr
	add	x9, x19, #1280
	mov	w10, #1
.LBB120_2:                              // =>This Inner Loop Header: Depth=1
	strb	w10, [x9, x8]
	add	x8, x8, #1
	ldr	w11, [x1]
	cmp	w11, w8
	b.gt	.LBB120_2
// %bb.3:
	ldr	w9, [x1, #4]
	cmp	w9, #1
	b.ge	.LBB120_19
.LBB120_4:
	ldr	w9, [x1, #8]
	cmp	w9, #1
	b.ge	.LBB120_22
.LBB120_5:
	ldr	w9, [x1, #12]
	cmp	w9, #1
	b.ge	.LBB120_25
.LBB120_6:
	ldr	w9, [x1, #16]
	cmp	w9, #1
	b.ge	.LBB120_28
.LBB120_7:
	ldr	w9, [x1, #20]
	cmp	w9, #1
	b.ge	.LBB120_31
.LBB120_8:
	ldr	w9, [x1, #24]
	cmp	w9, #1
	b.ge	.LBB120_34
.LBB120_9:
	ldr	w9, [x1, #28]
	cmp	w9, #1
	b.ge	.LBB120_37
.LBB120_10:
	ldr	w9, [x1, #32]
	cmp	w9, #1
	b.ge	.LBB120_40
.LBB120_11:
	ldr	w9, [x1, #36]
	cmp	w9, #1
	b.ge	.LBB120_43
.LBB120_12:
	ldr	w9, [x1, #40]
	cmp	w9, #1
	b.ge	.LBB120_46
.LBB120_13:
	ldr	w9, [x1, #44]
	cmp	w9, #1
	b.ge	.LBB120_49
.LBB120_14:
	ldr	w9, [x1, #48]
	cmp	w9, #1
	b.ge	.LBB120_52
.LBB120_15:
	ldr	w9, [x1, #52]
	cmp	w9, #1
	b.ge	.LBB120_55
.LBB120_16:
	ldr	w9, [x1, #56]
	cmp	w9, #1
	b.ge	.LBB120_58
.LBB120_17:
	ldr	w9, [x1, #60]
	cmp	w9, #1
	b.ge	.LBB120_61
	b	.LBB120_64
.LBB120_18:
	mov	w8, wzr
	ldr	w9, [x1, #4]
	cmp	w9, #1
	b.lt	.LBB120_4
.LBB120_19:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #2
.LBB120_20:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #4]
	cmp	w9, w12
	b.lt	.LBB120_20
// %bb.21:
	add	w8, w8, w9
	ldr	w9, [x1, #8]
	cmp	w9, #1
	b.lt	.LBB120_5
.LBB120_22:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #3
.LBB120_23:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #8]
	cmp	w9, w12
	b.lt	.LBB120_23
// %bb.24:
	add	w8, w8, w9
	ldr	w9, [x1, #12]
	cmp	w9, #1
	b.lt	.LBB120_6
.LBB120_25:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #4
.LBB120_26:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #12]
	cmp	w9, w12
	b.lt	.LBB120_26
// %bb.27:
	add	w8, w8, w9
	ldr	w9, [x1, #16]
	cmp	w9, #1
	b.lt	.LBB120_7
.LBB120_28:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #5
.LBB120_29:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #16]
	cmp	w9, w12
	b.lt	.LBB120_29
// %bb.30:
	add	w8, w8, w9
	ldr	w9, [x1, #20]
	cmp	w9, #1
	b.lt	.LBB120_8
.LBB120_31:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #6
.LBB120_32:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #20]
	cmp	w9, w12
	b.lt	.LBB120_32
// %bb.33:
	add	w8, w8, w9
	ldr	w9, [x1, #24]
	cmp	w9, #1
	b.lt	.LBB120_9
.LBB120_34:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #7
.LBB120_35:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #24]
	cmp	w9, w12
	b.lt	.LBB120_35
// %bb.36:
	add	w8, w8, w9
	ldr	w9, [x1, #28]
	cmp	w9, #1
	b.lt	.LBB120_10
.LBB120_37:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #8
.LBB120_38:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #28]
	cmp	w9, w12
	b.lt	.LBB120_38
// %bb.39:
	add	w8, w8, w9
	ldr	w9, [x1, #32]
	cmp	w9, #1
	b.lt	.LBB120_11
.LBB120_40:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #9
.LBB120_41:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #32]
	cmp	w9, w12
	b.lt	.LBB120_41
// %bb.42:
	add	w8, w8, w9
	ldr	w9, [x1, #36]
	cmp	w9, #1
	b.lt	.LBB120_12
.LBB120_43:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #10
.LBB120_44:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #36]
	cmp	w9, w12
	b.lt	.LBB120_44
// %bb.45:
	add	w8, w8, w9
	ldr	w9, [x1, #40]
	cmp	w9, #1
	b.lt	.LBB120_13
.LBB120_46:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #11
.LBB120_47:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #40]
	cmp	w9, w12
	b.lt	.LBB120_47
// %bb.48:
	add	w8, w8, w9
	ldr	w9, [x1, #44]
	cmp	w9, #1
	b.lt	.LBB120_14
.LBB120_49:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #12
.LBB120_50:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #44]
	cmp	w9, w12
	b.lt	.LBB120_50
// %bb.51:
	add	w8, w8, w9
	ldr	w9, [x1, #48]
	cmp	w9, #1
	b.lt	.LBB120_15
.LBB120_52:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #13
.LBB120_53:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #48]
	cmp	w9, w12
	b.lt	.LBB120_53
// %bb.54:
	add	w8, w8, w9
	ldr	w9, [x1, #52]
	cmp	w9, #1
	b.lt	.LBB120_16
.LBB120_55:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #14
.LBB120_56:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #52]
	cmp	w9, w12
	b.lt	.LBB120_56
// %bb.57:
	add	w8, w8, w9
	ldr	w9, [x1, #56]
	cmp	w9, #1
	b.lt	.LBB120_17
.LBB120_58:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #15
.LBB120_59:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #56]
	cmp	w9, w12
	b.lt	.LBB120_59
// %bb.60:
	add	w8, w8, w9
	ldr	w9, [x1, #60]
	cmp	w9, #1
	b.lt	.LBB120_64
.LBB120_61:
	add	x10, x19, w8, sxtw
	mov	x9, xzr
	add	x10, x10, #1280
	mov	w11, #16
.LBB120_62:                             // =>This Inner Loop Header: Depth=1
	strb	w11, [x10, x9]
	add	x9, x9, #1
	ldr	w12, [x1, #60]
	cmp	w9, w12
	b.lt	.LBB120_62
// %bb.63:
	add	w8, w8, w9
.LBB120_64:
	mov	w10, wzr
	mov	w9, wzr
	add	x14, x19, w8, sxtw
	add	x8, x19, #1281
	mov	w11, #1
	mov	w12, #16
	mov	w13, #1
	strb	wzr, [x14, #1280]
	b	.LBB120_66
.LBB120_65:                             //   in Loop: Header=BB120_66 Depth=1
	sub	w15, w12, w13
	add	x13, x13, #1
	cmp	x13, #17
	lsl	w15, w10, w15
	lsl	w10, w10, #1
	str	w15, [x14, #1540]
	b.eq	.LBB120_71
.LBB120_66:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB120_67 Depth 2
	sub	w16, w9, w10
	add	x14, x19, x13, lsl #2
	sxtw	x15, w9
	add	x17, x19, x15
	str	w16, [x14, #1612]
	ldrb	w16, [x17, #1280]
	cmp	x13, x16
	b.ne	.LBB120_65
.LBB120_67:                             //   Parent Loop BB120_66 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x9, x8, x15, lsl #1
	sub	x9, x9, #769
	strh	w10, [x9]
	add	x9, x15, #1
	ldrb	w16, [x8, x15]
	add	w10, w10, #1
	mov	x15, x9
	cmp	x13, x16
	b.eq	.LBB120_67
// %bb.68:                              //   in Loop: Header=BB120_66 Depth=1
	lsl	w15, w11, w13
	sub	w16, w10, #1
	cmp	w16, w15
                                        // kill: def $w9 killed $w9 killed $x9 def $x9
	b.lt	.LBB120_65
// %bb.69:
	adrp	x9, .L.str.17
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.17
	mov	w20, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB120_70:
	mov	w0, w20
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB120_71:
	movi	v0.2d, #0xffffffffffffffff
	mov	w8, #-1
	mov	w20, #1
	cmp	w9, #1
	str	w8, [x19, #1608]
	stp	q0, q0, [x19]
	stp	q0, q0, [x19, #32]
	stp	q0, q0, [x19, #64]
	stp	q0, q0, [x19, #96]
	stp	q0, q0, [x19, #128]
	stp	q0, q0, [x19, #160]
	stp	q0, q0, [x19, #192]
	stp	q0, q0, [x19, #224]
	stp	q0, q0, [x19, #256]
	stp	q0, q0, [x19, #288]
	stp	q0, q0, [x19, #320]
	stp	q0, q0, [x19, #352]
	stp	q0, q0, [x19, #384]
	stp	q0, q0, [x19, #416]
	stp	q0, q0, [x19, #448]
	stp	q0, q0, [x19, #480]
	b.lt	.LBB120_70
// %bb.72:
	mov	x21, xzr
	mov	w22, w9
	add	x23, x19, #1280
	mov	w24, #9
	b	.LBB120_74
.LBB120_73:                             //   in Loop: Header=BB120_74 Depth=1
	add	x21, x21, #1
	cmp	x22, x21
	b.eq	.LBB120_76
.LBB120_74:                             // =>This Inner Loop Header: Depth=1
	ldrb	w8, [x23, x21]
	cmp	x8, #9
	b.hi	.LBB120_73
// %bb.75:                              //   in Loop: Header=BB120_74 Depth=1
	add	x9, x23, x21, lsl #1
	sub	x8, x24, x8
	sub	x9, x9, #768
	mov	w1, w21
	lsl	w2, w20, w8
	ldrh	w9, [x9]
	lsl	x9, x9, x8
	add	x0, x19, x9
	bl	memset
	b	.LBB120_73
.LBB120_76:
	mov	w20, #1
	mov	w0, w20
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end120:
	.size	_ZL19stbi__build_huffmanP13stbi__huffmanPi, .Lfunc_end120-_ZL19stbi__build_huffmanP13stbi__huffmanPi
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL10stbi__skipP13stbi__contexti
	.type	_ZL10stbi__skipP13stbi__contexti,@function
_ZL10stbi__skipP13stbi__contexti:       // @_ZL10stbi__skipP13stbi__contexti
	.cfi_startproc
// %bb.0:
	mov	x8, x0
	tbnz	w1, #31, .LBB121_4
// %bb.1:
	ldr	x9, [x8, #16]
	cbz	x9, .LBB121_5
// %bb.2:
	ldp	x10, x9, [x8, #184]
	sub	w11, w9, w10
	cmp	w11, w1
	b.ge	.LBB121_6
// %bb.3:
	ldr	x0, [x8, #40]
	sub	w1, w1, w11
	ldr	x2, [x8, #24]
	str	x9, [x8, #184]
	br	x2
.LBB121_4:
	ldr	x9, [x8, #192]
	str	x9, [x8, #184]
	ret
.LBB121_5:
	ldr	x10, [x8, #184]
.LBB121_6:
	add	x9, x10, w1, uxtw
	str	x9, [x8, #184]
	ret
.Lfunc_end121:
	.size	_ZL10stbi__skipP13stbi__contexti, .Lfunc_end121-_ZL10stbi__skipP13stbi__contexti
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14resample_row_1PhS_S_ii
	.type	_ZL14resample_row_1PhS_S_ii,@function
_ZL14resample_row_1PhS_S_ii:            // @_ZL14resample_row_1PhS_S_ii
	.cfi_startproc
// %bb.0:
	mov	x0, x1
	ret
.Lfunc_end122:
	.size	_ZL14resample_row_1PhS_S_ii, .Lfunc_end122-_ZL14resample_row_1PhS_S_ii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL22stbi__resample_row_v_2PhS_S_ii
	.type	_ZL22stbi__resample_row_v_2PhS_S_ii,@function
_ZL22stbi__resample_row_v_2PhS_S_ii:    // @_ZL22stbi__resample_row_v_2PhS_S_ii
	.cfi_startproc
// %bb.0:
	cmp	w3, #1
	b.lt	.LBB123_16
// %bb.1:
	mov	w8, w3
	cmp	w3, #8
	b.hs	.LBB123_3
// %bb.2:
	mov	x9, xzr
	b	.LBB123_14
.LBB123_3:
	add	x10, x1, x8
	add	x11, x0, x8
	cmp	x10, x0
	add	x12, x2, x8
	cset	w10, hi
	cmp	x11, x1
	cset	w13, hi
	cmp	x12, x0
	and	w12, w10, w13
	cset	w10, hi
	cmp	x11, x2
	mov	x9, xzr
	cset	w11, hi
	tbnz	w12, #0, .LBB123_14
// %bb.4:
	and	w10, w10, w11
	tbnz	w10, #0, .LBB123_14
// %bb.5:
	cmp	w3, #16
	b.hs	.LBB123_10
// %bb.6:
	mov	x9, xzr
.LBB123_7:
	mov	x13, x9
	and	x9, x8, #0xfffffff8
	movi	v0.8b, #3
	add	x10, x1, x13
	movi	v1.8h, #2
	add	x11, x2, x13
	add	x12, x0, x13
	sub	x13, x13, x9
.LBB123_8:                              // =>This Inner Loop Header: Depth=1
	ldr	d2, [x11], #8
	ldr	d3, [x10], #8
	adds	x13, x13, #8
	ushll	v2.8h, v2.8b, #0
	umlal	v2.8h, v3.8b, v0.8b
	add	v2.8h, v2.8h, v1.8h
	shrn	v2.8b, v2.8h, #2
	str	d2, [x12], #8
	b.ne	.LBB123_8
// %bb.9:
	cmp	x9, x8
	b.ne	.LBB123_14
	b	.LBB123_16
.LBB123_10:
	and	x9, x8, #0xfffffff0
	movi	v0.8b, #3
	movi	v1.8h, #2
	mov	x10, x0
	mov	x11, x9
	mov	x12, x2
	mov	x13, x1
.LBB123_11:                             // =>This Inner Loop Header: Depth=1
	ldr	q2, [x13], #16
	ldr	q3, [x12], #16
	subs	x11, x11, #16
	ext	v4.16b, v2.16b, v2.16b, #8
	ushll	v5.8h, v3.8b, #0
	umull	v4.8h, v4.8b, v0.8b
	umlal	v5.8h, v2.8b, v0.8b
	uaddw2	v2.8h, v4.8h, v3.16b
	add	v3.8h, v5.8h, v1.8h
	add	v2.8h, v2.8h, v1.8h
	shrn	v3.8b, v3.8h, #2
	shrn2	v3.16b, v2.8h, #2
	str	q3, [x10], #16
	b.ne	.LBB123_11
// %bb.12:
	cmp	x9, x8
	b.eq	.LBB123_16
// %bb.13:
	tbnz	w8, #3, .LBB123_7
.LBB123_14:
	add	x10, x0, x9
	add	x11, x2, x9
	add	x12, x1, x9
	sub	x8, x8, x9
.LBB123_15:                             // =>This Inner Loop Header: Depth=1
	ldrb	w9, [x12], #1
	ldrb	w13, [x11], #1
	subs	x8, x8, #1
	add	w9, w9, w9, lsl #1
	add	w9, w13, w9
	add	w9, w9, #2
	lsr	w9, w9, #2
	strb	w9, [x10], #1
	b.ne	.LBB123_15
.LBB123_16:
	ret
.Lfunc_end123:
	.size	_ZL22stbi__resample_row_v_2PhS_S_ii, .Lfunc_end123-_ZL22stbi__resample_row_v_2PhS_S_ii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL22stbi__resample_row_h_2PhS_S_ii
	.type	_ZL22stbi__resample_row_h_2PhS_S_ii,@function
_ZL22stbi__resample_row_h_2PhS_S_ii:    // @_ZL22stbi__resample_row_h_2PhS_S_ii
	.cfi_startproc
// %bb.0:
	subs	w8, w3, #1
	ldrb	w9, [x1]
	b.ne	.LBB124_2
// %bb.1:
	strb	w9, [x0, #1]
	strb	w9, [x0]
	ret
.LBB124_2:
	strb	w9, [x0]
	cmp	w3, #3
	ldrb	w9, [x1]
	ldrb	w10, [x1, #1]
	add	w9, w9, w9, lsl #1
	add	w9, w10, w9
	add	w9, w9, #2
	lsr	w9, w9, #2
	strb	w9, [x0, #1]
	b.lt	.LBB124_10
// %bb.3:
	sub	x9, x8, #1
	cmp	x9, #8
	b.lo	.LBB124_6
// %bb.4:
	add	x10, x8, x1
	add	x11, x0, #2
	add	x10, x10, #1
	cmp	x11, x10
	b.hs	.LBB124_12
// %bb.5:
	add	x10, x0, x8, lsl #1
	cmp	x10, x1
	b.ls	.LBB124_12
.LBB124_6:
	mov	w11, #1
.LBB124_7:
	add	x12, x0, x11, lsl #1
	sub	x9, x8, x11
	add	x10, x1, x11
	add	x11, x12, #1
.LBB124_8:                              // =>This Inner Loop Header: Depth=1
	ldrb	w12, [x10]
	subs	x9, x9, #1
	ldurb	w13, [x10, #-1]
	add	w12, w12, w12, lsl #1
	add	w12, w12, #2
	add	w13, w12, w13
	lsr	w13, w13, #2
	sturb	w13, [x11, #-1]
	ldrb	w13, [x10, #1]!
	add	w12, w12, w13
	lsr	w12, w12, #2
	strb	w12, [x11], #2
	b.ne	.LBB124_8
.LBB124_9:
	lsl	w9, w8, #1
	b	.LBB124_11
.LBB124_10:
	mov	w9, #2
.LBB124_11:
                                        // kill: def $w8 killed $w8 killed $x8 def $x8
	add	x10, x1, w3, sxtw
	mov	w9, w9
	sxtw	x8, w8
	ldurb	w10, [x10, #-2]
	ldrb	w11, [x1, x8]
	add	w10, w10, w10, lsl #1
	add	w10, w11, w10
	add	w10, w10, #2
	lsr	w10, w10, #2
	strb	w10, [x0, x9]
	orr	x9, x9, #0x1
	ldrb	w8, [x1, x8]
	strb	w8, [x0, x9]
	ret
.LBB124_12:
	cmp	x9, #16
	b.hs	.LBB124_17
// %bb.13:
	mov	x10, xzr
.LBB124_14:
	and	x12, x9, #0xfffffffffffffff8
	add	x13, x10, x1
	add	x14, x0, x10, lsl #1
	movi	v0.8b, #3
	orr	x11, x12, #0x1
	add	x13, x13, #2
	add	x14, x14, #2
	sub	x10, x10, x12
.LBB124_15:                             // =>This Inner Loop Header: Depth=1
	movi	v1.8h, #2
	ldur	d2, [x13, #-1]
	adds	x10, x10, #8
	umlal	v1.8h, v2.8b, v0.8b
	ldur	d2, [x13, #-2]
	ldr	d3, [x13], #8
	uaddw	v2.8h, v1.8h, v2.8b
	uaddw	v1.8h, v1.8h, v3.8b
	shrn	v2.8b, v2.8h, #2
	shrn	v3.8b, v1.8h, #2
	st2	{ v2.8b, v3.8b }, [x14], #16
	b.ne	.LBB124_15
// %bb.16:
	cmp	x9, x12
	b.ne	.LBB124_7
	b	.LBB124_9
.LBB124_17:
	and	x10, x9, #0xfffffffffffffff0
	movi	v0.8b, #3
	add	x11, x1, #2
	add	x12, x0, #2
	mov	x13, x10
.LBB124_18:                             // =>This Inner Loop Header: Depth=1
	movi	v2.8h, #2
	ldur	q1, [x11, #-1]
	movi	v3.8h, #2
	subs	x13, x13, #16
	ext	v4.16b, v1.16b, v1.16b, #8
	umlal	v2.8h, v1.8b, v0.8b
	ldur	q1, [x11, #-2]
	ldr	q5, [x11], #16
	umlal	v3.8h, v4.8b, v0.8b
	uaddw	v4.8h, v2.8h, v1.8b
	uaddw	v2.8h, v2.8h, v5.8b
	uaddw2	v1.8h, v3.8h, v1.16b
	shrn	v6.8b, v4.8h, #2
	shrn2	v6.16b, v1.8h, #2
	uaddw2	v1.8h, v3.8h, v5.16b
	shrn	v7.8b, v2.8h, #2
	shrn2	v7.16b, v1.8h, #2
	st2	{ v6.16b, v7.16b }, [x12], #32
	b.ne	.LBB124_18
// %bb.19:
	cmp	x9, x10
	b.eq	.LBB124_9
// %bb.20:
	tbnz	w9, #3, .LBB124_14
// %bb.21:
	orr	x11, x10, #0x1
	b	.LBB124_7
.Lfunc_end124:
	.size	_ZL22stbi__resample_row_h_2PhS_S_ii, .Lfunc_end124-_ZL22stbi__resample_row_h_2PhS_S_ii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL26stbi__resample_row_genericPhS_S_ii
	.type	_ZL26stbi__resample_row_genericPhS_S_ii,@function
_ZL26stbi__resample_row_genericPhS_S_ii: // @_ZL26stbi__resample_row_genericPhS_S_ii
	.cfi_startproc
// %bb.0:
	cmp	w3, #1
	b.lt	.LBB125_19
// %bb.1:
	cmp	w4, #1
	b.lt	.LBB125_19
// %bb.2:
	mov	w9, w4
	mov	x8, xzr
	and	x13, x9, #0xfffffff8
	mov	w10, w3
	and	x11, x9, #0xffffffe0
	and	x12, x9, #0x18
	add	x14, x0, #16
	neg	x15, x13
	mov	x16, x0
	b	.LBB125_4
.LBB125_3:                              //   in Loop: Header=BB125_4 Depth=1
	add	x8, x8, #1
	add	x14, x14, x9
	add	x16, x16, x9
	cmp	x8, x10
	b.eq	.LBB125_19
.LBB125_4:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB125_12 Depth 2
                                        //     Child Loop BB125_16 Depth 2
                                        //     Child Loop BB125_18 Depth 2
	cmp	w4, #8
	b.hs	.LBB125_6
// %bb.5:                               //   in Loop: Header=BB125_4 Depth=1
	mov	x17, xzr
	b	.LBB125_18
.LBB125_6:                              //   in Loop: Header=BB125_4 Depth=1
	mul	x18, x8, x9
	add	x17, x1, x8
	add	x2, x17, #1
	add	x3, x0, x18
	cmp	x3, x2
	b.hs	.LBB125_9
// %bb.7:                               //   in Loop: Header=BB125_4 Depth=1
	add	x18, x18, x9
	add	x18, x0, x18
	cmp	x17, x18
	b.hs	.LBB125_9
// %bb.8:                               //   in Loop: Header=BB125_4 Depth=1
	mov	x17, xzr
	b	.LBB125_18
.LBB125_9:                              //   in Loop: Header=BB125_4 Depth=1
	cmp	w4, #32
	b.hs	.LBB125_11
// %bb.10:                              //   in Loop: Header=BB125_4 Depth=1
	mov	x18, xzr
	b	.LBB125_15
.LBB125_11:                             //   in Loop: Header=BB125_4 Depth=1
	add	x17, x1, x8
	mov	x18, x14
	ld1r	{ v0.16b }, [x17]
	mov	x17, x11
.LBB125_12:                             //   Parent Loop BB125_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	stp	q0, q0, [x18, #-16]
	add	x18, x18, #32
	subs	x17, x17, #32
	b.ne	.LBB125_12
// %bb.13:                              //   in Loop: Header=BB125_4 Depth=1
	cmp	x11, x9
	b.eq	.LBB125_3
// %bb.14:                              //   in Loop: Header=BB125_4 Depth=1
	mov	x18, x11
	mov	x17, x11
	cbz	x12, .LBB125_18
.LBB125_15:                             //   in Loop: Header=BB125_4 Depth=1
	add	x17, x16, x18
	add	x18, x15, x18
.LBB125_16:                             //   Parent Loop BB125_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x2, x1, x8
	adds	x18, x18, #8
	ld1r	{ v0.8b }, [x2]
	str	d0, [x17], #8
	b.ne	.LBB125_16
// %bb.17:                              //   in Loop: Header=BB125_4 Depth=1
	mov	x17, x13
	cmp	x13, x9
	b.eq	.LBB125_3
.LBB125_18:                             //   Parent Loop BB125_4 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w18, [x1, x8]
	strb	w18, [x16, x17]
	add	x17, x17, #1
	cmp	x9, x17
	b.ne	.LBB125_18
	b	.LBB125_3
.LBB125_19:
	ret
.Lfunc_end125:
	.size	_ZL26stbi__resample_row_genericPhS_S_ii, .Lfunc_end125-_ZL26stbi__resample_row_genericPhS_S_ii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh
	.type	_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh,@function
_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh: // @_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	w8, #18212
	mov	x19, x6
	mov	w24, w5
	mov	x20, x0
	mov	x21, x4
	mov	x22, x3
	ldr	w8, [x0, x8]
	mov	x25, x2
	mov	x23, x1
	cmp	w8, #15
	b.gt	.LBB126_2
// %bb.1:
	mov	x0, x20
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB126_2:
	mov	x0, x20
	mov	x1, x25
	bl	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	tbnz	w0, #31, .LBB126_22
// %bb.3:
	movi	v0.2d, #0000000000000000
	mov	w8, #18208
	mov	w25, w0
	add	x26, x20, x8
	stp	q0, q0, [x23, #96]
	stp	q0, q0, [x23, #64]
	stp	q0, q0, [x23, #32]
	stp	q0, q0, [x23]
	cbz	w0, .LBB126_8
// %bb.4:
	ldr	w8, [x26, #4]
	cmp	w8, w25
	b.ge	.LBB126_6
// %bb.5:
	mov	x0, x20
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB126_6:
	cmp	w25, #17
	b.hs	.LBB126_25
// %bb.7:
	mov	w8, w25
	adrp	x12, _ZL11stbi__bmask
	lsl	x8, x8, #2
	adrp	x13, _ZL11stbi__jbias
	add	x12, x12, :lo12:_ZL11stbi__bmask
	add	x13, x13, :lo12:_ZL11stbi__jbias
	ldp	w9, w10, [x26]
	neg	w11, w25
	ldr	w12, [x12, x8]
	ldr	w8, [x13, x8]
	ror	w11, w9, w11
	cmp	w9, #0
	bic	w9, w11, w12
	and	w11, w12, w11
	csel	w8, wzr, w8, lt
	sub	w10, w10, w25
	add	w8, w8, w11
	stp	w9, w10, [x26]
	b	.LBB126_9
.LBB126_8:
	mov	w8, wzr
.LBB126_9:
	mov	w9, #96
	mov	w10, #17848
	adrp	x25, _ZL19stbi__jpeg_dezigzag
	mov	w27, #1
	smaddl	x9, w24, w9, x20
	add	x25, x25, :lo12:_ZL19stbi__jpeg_dezigzag
	ldr	w11, [x9, x10]
	add	w8, w11, w8
	str	w8, [x9, x10]
	ldrb	w9, [x19]
	mul	w8, w8, w9
	strh	w8, [x23]
	b	.LBB126_13
.LBB126_10:                             //   in Loop: Header=BB126_13 Depth=1
	ldr	w9, [x26]
	lsr	x8, x9, #22
	and	x8, x8, #0x3fe
	ldrh	w8, [x21, x8]
	cbz	w8, .LBB126_15
// %bb.11:                              //   in Loop: Header=BB126_13 Depth=1
	ubfx	x10, x8, #4, #4
	and	w11, w8, #0xf
	add	x10, x10, w27, sxtw
	ldr	w12, [x26, #4]
	sxth	w8, w8
	add	w27, w10, #1
	lsl	w9, w9, w11
	lsr	w8, w8, #8
	sub	w11, w12, w11
	ldrb	w12, [x25, x10]
	stp	w9, w11, [x26]
	ldrb	w9, [x19, x12]
	mul	w8, w8, w9
	strh	w8, [x23, x12, lsl #1]
.LBB126_12:                             //   in Loop: Header=BB126_13 Depth=1
	cmp	w27, #64
	b.ge	.LBB126_23
.LBB126_13:                             // =>This Inner Loop Header: Depth=1
	ldr	w8, [x26, #4]
	cmp	w8, #15
	b.gt	.LBB126_10
// %bb.14:                              //   in Loop: Header=BB126_13 Depth=1
	mov	x0, x20
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	b	.LBB126_10
.LBB126_15:                             //   in Loop: Header=BB126_13 Depth=1
	mov	x0, x20
	mov	x1, x22
	bl	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	tbnz	w0, #31, .LBB126_22
// %bb.16:                              //   in Loop: Header=BB126_13 Depth=1
	mov	w24, w0
	ands	w28, w0, #0xf
	b.eq	.LBB126_20
// %bb.17:                              //   in Loop: Header=BB126_13 Depth=1
	ldr	w8, [x26, #4]
	cmp	w8, w28
	b.ge	.LBB126_19
// %bb.18:                              //   in Loop: Header=BB126_13 Depth=1
	mov	x0, x20
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	ldr	w8, [x26, #4]
.LBB126_19:                             //   in Loop: Header=BB126_13 Depth=1
	lsl	x9, x28, #2
	adrp	x12, _ZL11stbi__bmask
	add	x12, x12, :lo12:_ZL11stbi__bmask
	ldr	w10, [x26]
	neg	w11, w28
	lsr	w13, w24, #4
	ldr	w12, [x12, x9]
	add	x13, x13, w27, sxtw
	adrp	x16, _ZL11stbi__jbias
	sub	w8, w8, w28
	ror	w11, w10, w11
	add	x16, x16, :lo12:_ZL11stbi__jbias
	ldrb	w15, [x25, x13]
	cmp	w10, #0
	bic	w14, w11, w12
	ldr	w9, [x16, x9]
	and	w10, w12, w11
	add	w27, w13, #1
	stp	w14, w8, [x26]
	ldrb	w8, [x19, x15]
	csel	w9, wzr, w9, lt
	add	w9, w9, w10
	mul	w8, w9, w8
	strh	w8, [x23, x15, lsl #1]
	b	.LBB126_12
.LBB126_20:                             //   in Loop: Header=BB126_13 Depth=1
	cmp	w24, #240
	b.ne	.LBB126_23
// %bb.21:                              //   in Loop: Header=BB126_13 Depth=1
	add	w27, w27, #16
	b	.LBB126_12
.LBB126_22:
	adrp	x9, .L.str.36
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	add	x9, x9, :lo12:.L.str.36
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB126_24
.LBB126_23:
	mov	w0, #1
.LBB126_24:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB126_25:
	adrp	x0, .L.str.39
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi
	add	x0, x0, :lo12:.L.str.39
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi
	mov	w2, #1649
	bl	__assert_fail
.Lfunc_end126:
	.size	_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh, .Lfunc_end126-_ZL23stbi__jpeg_decode_blockP10stbi__jpegPsP13stbi__huffmanS3_S1_iPh
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	.type	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg,@function
_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg: // @_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	w8, #18220
	mov	w9, #18208
	add	x20, x0, x9
	ldr	w8, [x0, x8]
	cbz	w8, .LBB127_3
// %bb.1:
	ldr	w8, [x20, #4]
	mov	w9, #17
	cmp	w8, #17
	csel	w9, w8, w9, gt
	sub	w9, w9, w8
	add	w9, w9, #7
	and	w9, w9, #0xfffffff8
	add	w8, w8, w9
	add	w8, w8, #8
	str	w8, [x20, #4]
.LBB127_2:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB127_3:
	mov	x19, x0
	mov	w21, #24
	cbz	w8, .LBB127_7
.LBB127_4:
	mov	w8, wzr
.LBB127_5:
	ldp	w10, w9, [x20]
	sub	w11, w21, w9
	cmp	w9, #16
	lsl	w8, w8, w11
	orr	w8, w8, w10
	add	w10, w9, #8
	stp	w8, w10, [x20]
	b.gt	.LBB127_2
// %bb.6:
	ldr	w8, [x20, #12]
	cbnz	w8, .LBB127_4
.LBB127_7:
	ldr	x22, [x19]
	ldp	x8, x9, [x22, #184]
	cmp	x8, x9
	b.hs	.LBB127_9
// %bb.8:
	add	x9, x8, #1
	str	x9, [x22, #184]
	ldrb	w8, [x8]
	cmp	w8, #255
	b.ne	.LBB127_5
	b	.LBB127_13
.LBB127_9:
	ldr	w8, [x22, #48]
	cbz	w8, .LBB127_5
// %bb.10:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB127_12
// %bb.11:
	mov	x9, x22
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x22, #57
	stp	x10, x9, [x22, #184]
	cmp	w8, #255
	b.ne	.LBB127_5
	b	.LBB127_13
.LBB127_12:
	mov	w8, wzr
	add	x9, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x10, x22, #57
	stp	x10, x9, [x22, #184]
	cmp	w8, #255
	b.ne	.LBB127_5
.LBB127_13:
	ldr	x22, [x19]
	ldp	x8, x9, [x22, #184]
	cmp	x8, x9
	b.hs	.LBB127_15
// %bb.14:
	add	x9, x8, #1
	str	x9, [x22, #184]
	ldrb	w8, [x8]
	cbz	w8, .LBB127_19
	b	.LBB127_20
.LBB127_15:
	ldr	w8, [x22, #48]
	cbz	w8, .LBB127_19
// %bb.16:
	ldr	x8, [x22, #16]
	add	x1, x22, #56
	ldr	x0, [x22, #40]
	ldr	w2, [x22, #52]
	blr	x8
	cbz	w0, .LBB127_18
// %bb.17:
	mov	x9, x22
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	add	x10, x22, #57
	stp	x10, x9, [x22, #184]
	cbz	w8, .LBB127_19
	b	.LBB127_20
.LBB127_18:
	mov	w8, wzr
	add	x9, x22, #57
	str	wzr, [x22, #48]
	strb	wzr, [x22, #56]
	add	x10, x22, #57
	stp	x10, x9, [x22, #184]
	cbnz	w8, .LBB127_20
.LBB127_19:
	mov	w8, #255
	b	.LBB127_5
.LBB127_20:
	mov	w9, #1
	strb	w8, [x20, #8]
	str	w9, [x20, #12]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end127:
	.size	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg, .Lfunc_end127-_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	.type	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman,@function
_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman: // @_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	w8, #18212
	mov	w9, #18208
	mov	x19, x1
	add	x20, x0, x9
	ldr	w8, [x0, x8]
	cmp	w8, #15
	b.gt	.LBB128_2
// %bb.1:
	bl	_ZL24stbi__grow_buffer_unsafeP10stbi__jpeg
.LBB128_2:
	ldr	w8, [x20]
	lsr	x9, x8, #23
	ldrb	w9, [x19, x9]
	cmp	x9, #255
	b.eq	.LBB128_5
// %bb.3:
	add	x9, x19, x9
	ldr	w11, [x20, #4]
	ldrb	w10, [x9, #1280]
	subs	w11, w11, w10
	b.ge	.LBB128_9
// %bb.4:
	mov	w0, #-1
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB128_5:
	mov	x9, xzr
	lsr	w10, w8, #16
	add	x11, x19, #1580
.LBB128_6:                              // =>This Inner Loop Header: Depth=1
	ldr	w12, [x11, x9, lsl #2]
	add	x9, x9, #1
	cmp	w10, w12
	b.hs	.LBB128_6
// %bb.7:
	ldr	w10, [x20, #4]
	cmp	w9, #8
	b.ne	.LBB128_10
// %bb.8:
	sub	w8, w10, #16
	mov	w0, #-1
	str	w8, [x20, #4]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB128_9:
	lsl	w8, w8, w10
	stp	w8, w11, [x20]
	ldrb	w0, [x9, #1024]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB128_10:
	add	x11, x9, #9
	cmp	w10, w11
	b.ge	.LBB128_12
// %bb.11:
	mov	w0, #-1
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB128_12:
	and	x12, x11, #0xffffffff
	adrp	x13, _ZL11stbi__bmask
	lsl	x12, x12, #2
	add	x13, x13, :lo12:_ZL11stbi__bmask
	mov	w14, #23
	add	x15, x19, x12
	sub	w14, w14, w9
	ldr	w12, [x13, x12]
	ldr	w15, [x15, #1612]
	lsr	w14, w8, w14
	and	w12, w12, w14
	add	w14, w12, w15
	sxtw	x12, w14
	add	x12, x19, x12
	add	x14, x19, w14, sxtw #1
	ldrb	w15, [x12, #1280]
	ldrh	w14, [x14, #512]
	neg	w16, w15
	ldr	w13, [x13, x15, lsl #2]
	lsr	w15, w8, w16
	and	w13, w15, w13
	cmp	w13, w14
	b.ne	.LBB128_14
// %bb.13:
	sub	w9, w10, w9
	lsl	w8, w8, w11
	sub	w9, w9, #9
	stp	w8, w9, [x20]
	ldrb	w0, [x12, #1024]
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB128_14:
	adrp	x0, .L.str.37
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	add	x0, x0, :lo12:.L.str.37
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	mov	w2, #1628
	bl	__assert_fail
.Lfunc_end128:
	.size	_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman, .Lfunc_end128-_ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL22stbi__check_png_headerP13stbi__context
	.type	_ZL22stbi__check_png_headerP13stbi__context,@function
_ZL22stbi__check_png_headerP13stbi__context: // @_ZL22stbi__check_png_headerP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x9, x8, [x0, #184]
	mov	x19, x0
	add	x20, x0, #56
	add	x21, x0, #57
	cmp	x9, x8
	b.hs	.LBB129_2
// %bb.1:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w9, [x9]
	cmp	w9, #137
	b.eq	.LBB129_6
	b	.LBB129_58
.LBB129_2:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.3:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_5
// %bb.4:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x10, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #137
	b.eq	.LBB129_6
	b	.LBB129_58
.LBB129_5:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x10, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #137
	b.ne	.LBB129_58
.LBB129_6:
	cmp	x10, x8
	b.hs	.LBB129_8
// %bb.7:
	add	x11, x10, #1
	str	x11, [x19, #184]
	ldrb	w9, [x10]
	cmp	w9, #80
	b.eq	.LBB129_12
	b	.LBB129_58
.LBB129_8:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.9:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_11
// %bb.10:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x11, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #80
	b.eq	.LBB129_12
	b	.LBB129_58
.LBB129_11:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x11, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #80
	b.ne	.LBB129_58
.LBB129_12:
	cmp	x11, x8
	b.hs	.LBB129_14
// %bb.13:
	add	x10, x11, #1
	str	x10, [x19, #184]
	ldrb	w9, [x11]
	cmp	w9, #78
	b.eq	.LBB129_18
	b	.LBB129_58
.LBB129_14:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.15:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_17
// %bb.16:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x10, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #78
	b.eq	.LBB129_18
	b	.LBB129_58
.LBB129_17:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x10, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #78
	b.ne	.LBB129_58
.LBB129_18:
	cmp	x10, x8
	b.hs	.LBB129_20
// %bb.19:
	add	x11, x10, #1
	str	x11, [x19, #184]
	ldrb	w9, [x10]
	cmp	w9, #71
	b.eq	.LBB129_25
	b	.LBB129_58
.LBB129_20:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.21:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_23
// %bb.22:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB129_24
.LBB129_23:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB129_24:
	mov	x11, x21
	stp	x21, x8, [x19, #184]
	cmp	w9, #71
	b.ne	.LBB129_58
.LBB129_25:
	cmp	x11, x8
	b.hs	.LBB129_27
// %bb.26:
	add	x10, x11, #1
	str	x10, [x19, #184]
	ldrb	w9, [x11]
	b	.LBB129_32
.LBB129_27:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.28:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_30
// %bb.29:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB129_31
.LBB129_30:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB129_31:
	mov	x10, x21
	stp	x21, x8, [x19, #184]
.LBB129_32:
	cmp	w9, #13
	b.ne	.LBB129_58
// %bb.33:
	cmp	x10, x8
	b.hs	.LBB129_35
// %bb.34:
	add	x11, x10, #1
	str	x11, [x19, #184]
	ldrb	w9, [x10]
	b	.LBB129_40
.LBB129_35:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.36:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_38
// %bb.37:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB129_39
.LBB129_38:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB129_39:
	mov	x11, x21
	stp	x21, x8, [x19, #184]
.LBB129_40:
	cmp	w9, #10
	b.ne	.LBB129_58
// %bb.41:
	cmp	x11, x8
	b.hs	.LBB129_43
// %bb.42:
	add	x10, x11, #1
	str	x10, [x19, #184]
	ldrb	w9, [x11]
	b	.LBB129_48
.LBB129_43:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.44:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_46
// %bb.45:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB129_47
.LBB129_46:
	mov	w9, wzr
	mov	x8, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB129_47:
	mov	x10, x21
	stp	x21, x8, [x19, #184]
.LBB129_48:
	cmp	w9, #26
	b.ne	.LBB129_58
// %bb.49:
	cmp	x10, x8
	b.hs	.LBB129_51
// %bb.50:
	add	x8, x10, #1
	str	x8, [x19, #184]
	ldrb	w8, [x10]
	b	.LBB129_56
.LBB129_51:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB129_58
// %bb.52:
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB129_54
// %bb.53:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB129_55
.LBB129_54:
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB129_55:
	stp	x21, x9, [x19, #184]
.LBB129_56:
	cmp	w8, #10
	b.ne	.LBB129_58
// %bb.57:
	mov	w0, #1
	b	.LBB129_59
.LBB129_58:
	adrp	x9, .L.str.41
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	add	x9, x9, :lo12:.L.str.41
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB129_59:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end129:
	.size	_ZL22stbi__check_png_headerP13stbi__context, .Lfunc_end129-_ZL22stbi__check_png_headerP13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL20stbi__parse_png_fileP9stbi__pngii
	.type	_ZL20stbi__parse_png_fileP9stbi__pngii,@function
_ZL20stbi__parse_png_fileP9stbi__pngii: // @_ZL20stbi__parse_png_fileP9stbi__pngii
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	stp	x28, x27, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #1, lsl #12             // =4096
	sub	sp, sp, #1168
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	x20, [x0]
	mov	x19, x0
	mov	x24, x0
	stp	xzr, xzr, [x0, #16]
	mov	w21, w2
	mov	w23, w1
	mov	x0, x20
	str	xzr, [x24, #8]!
	bl	_ZL22stbi__check_png_headerP13stbi__context
	cbz	w0, .LBB130_220
// %bb.1:
	mov	w22, #1
	cmp	w23, #1
	b.eq	.LBB130_221
// %bb.2:
	str	w21, [sp, #52]                  // 4-byte Folded Spill
	add	x8, sp, #136
	mov	w21, #17489
	stp	x24, xzr, [sp, #104]            // 16-byte Folded Spill
	str	w23, [sp, #96]                  // 4-byte Folded Spill
	mov	w25, wzr
	str	x19, [sp, #56]                  // 8-byte Folded Spill
	mov	w19, wzr
	mov	w24, wzr
	add	x26, x20, #56
	add	x23, x20, #57
	orr	x8, x8, #0x3
	movk	w21, #18760, lsl #16
	mov	w28, #1
	str	wzr, [sp, #80]                  // 4-byte Folded Spill
	str	xzr, [sp, #88]                  // 8-byte Folded Spill
	str	wzr, [sp, #120]                 // 4-byte Folded Spill
	str	wzr, [sp, #68]                  // 4-byte Folded Spill
	str	x8, [sp, #72]                   // 8-byte Folded Spill
	b	.LBB130_6
.LBB130_3:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #24]
	str	x9, [x20, #184]
	ldr	x0, [x20, #40]
	blr	x8
.LBB130_4:                              //   in Loop: Header=BB130_6 Depth=1
	mov	w28, wzr
.LBB130_5:                              //   in Loop: Header=BB130_6 Depth=1
	mov	x0, x20
	bl	_ZL13stbi__get32beP13stbi__context
.LBB130_6:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB130_20 Depth 2
                                        //     Child Loop BB130_99 Depth 2
                                        //     Child Loop BB130_52 Depth 2
                                        //     Child Loop BB130_35 Depth 2
	mov	x0, x20
	bl	_ZL13stbi__get32beP13stbi__context
	mov	w27, w0
	mov	x0, x20
	bl	_ZL13stbi__get32beP13stbi__context
	cmp	w0, w21
	b.le	.LBB130_26
// %bb.7:                               //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #17490
	movk	w8, #18760, lsl #16
	cmp	w0, w8
	b.eq	.LBB130_39
// %bb.8:                               //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #21573
	movk	w8, #20556, lsl #16
	cmp	w0, w8
	b.eq	.LBB130_45
// %bb.9:                               //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #20051
	movk	w8, #29778, lsl #16
	cmp	w0, w8
	b.ne	.LBB130_77
// %bb.10:                              //   in Loop: Header=BB130_6 Depth=1
	cbnz	w28, .LBB130_158
// %bb.11:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	ldr	x8, [x8]
	cbnz	x8, .LBB130_161
// %bb.12:                              //   in Loop: Header=BB130_6 Depth=1
	cbz	w24, .LBB130_93
// %bb.13:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [sp, #96]                   // 4-byte Folded Reload
	add	x28, sp, #136
	cmp	w8, #2
	b.eq	.LBB130_171
// %bb.14:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	cbz	w8, .LBB130_172
// %bb.15:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w8, w27
	b.lo	.LBB130_165
// %bb.16:                              //   in Loop: Header=BB130_6 Depth=1
	cbz	w27, .LBB130_122
// %bb.17:                              //   in Loop: Header=BB130_6 Depth=1
	ldp	x9, x8, [x20, #184]
	mov	w10, w27
	mov	x21, xzr
	lsl	x24, x10, #2
	b	.LBB130_20
.LBB130_18:                             //   in Loop: Header=BB130_20 Depth=2
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB130_19:                             //   in Loop: Header=BB130_20 Depth=2
	and	x11, x21, #0xfffffffc
	add	x21, x21, #4
	add	x11, x28, x11
	cmp	x24, x21
	strb	w10, [x11, #3]
	b.eq	.LBB130_114
.LBB130_20:                             //   Parent Loop BB130_6 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	x9, x8
	b.lo	.LBB130_18
// %bb.21:                              //   in Loop: Header=BB130_20 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_19
// %bb.22:                              //   in Loop: Header=BB130_20 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_24
// %bb.23:                              //   in Loop: Header=BB130_20 Depth=2
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB130_25
.LBB130_24:                             //   in Loop: Header=BB130_20 Depth=2
	mov	w10, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_25:                             //   in Loop: Header=BB130_20 Depth=2
	mov	x9, x23
	stp	x23, x8, [x20, #184]
	b	.LBB130_19
.LBB130_26:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #16969
	movk	w8, #17255, lsl #16
	cmp	w0, w8
	b.eq	.LBB130_72
// %bb.27:                              //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #16724
	movk	w8, #18756, lsl #16
	cmp	w0, w8
	b.ne	.LBB130_76
// %bb.28:                              //   in Loop: Header=BB130_6 Depth=1
	cbnz	w28, .LBB130_158
// %bb.29:                              //   in Loop: Header=BB130_6 Depth=1
	cbz	w24, .LBB130_31
// %bb.30:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	cbz	w8, .LBB130_162
.LBB130_31:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [sp, #96]                   // 4-byte Folded Reload
	cmp	w8, #2
	b.eq	.LBB130_164
// %bb.32:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [sp, #120]                  // 4-byte Folded Reload
	add	w21, w27, w8
	cmp	w21, w8
	b.lt	.LBB130_220
// %bb.33:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w21, w25
	b.ls	.LBB130_85
// %bb.34:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w27, #1, lsl #12                // =4096
	mov	w8, #4096
	csel	w8, w27, w8, hi
	cmp	w25, #0
	csel	w8, w8, w25, eq
	ldr	x28, [sp, #104]                 // 8-byte Folded Reload
.LBB130_35:                             //   Parent Loop BB130_6 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov	w25, w8
	lsl	w8, w8, #1
	cmp	w21, w25
	b.hi	.LBB130_35
// %bb.36:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x0, [x28]
	mov	w1, w25
	bl	realloc
	cbz	x0, .LBB130_253
// %bb.37:                              //   in Loop: Header=BB130_6 Depth=1
	mov	w22, w19
	str	x0, [x28]
	ldr	w9, [sp, #120]                  // 4-byte Folded Reload
	mov	w19, w24
	ldr	x8, [x20, #16]
	add	x28, x0, w9, uxtw
	cbnz	x8, .LBB130_86
.LBB130_38:                             //   in Loop: Header=BB130_6 Depth=1
	ldp	x1, x8, [x20, #184]
	b	.LBB130_89
.LBB130_39:                             //   in Loop: Header=BB130_6 Depth=1
	cbz	w28, .LBB130_159
// %bb.40:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w27, #13
	b.ne	.LBB130_160
// %bb.41:                              //   in Loop: Header=BB130_6 Depth=1
	mov	x0, x20
	bl	_ZL13stbi__get32beP13stbi__context
	mov	w19, #1
	str	w0, [x20]
	movk	w19, #256, lsl #16
	cmp	w0, w19
	b.hs	.LBB130_153
// %bb.42:                              //   in Loop: Header=BB130_6 Depth=1
	mov	x0, x20
	bl	_ZL13stbi__get32beP13stbi__context
	cmp	w0, w19
	str	w0, [x20, #4]
	b.hs	.LBB130_153
// %bb.43:                              //   in Loop: Header=BB130_6 Depth=1
	ldp	x10, x8, [x20, #184]
	cmp	x10, x8
	b.hs	.LBB130_82
// %bb.44:                              //   in Loop: Header=BB130_6 Depth=1
	add	x9, x10, #1
	str	x9, [x20, #184]
	ldrb	w19, [x10]
	b	.LBB130_125
.LBB130_45:                             //   in Loop: Header=BB130_6 Depth=1
	cbnz	w28, .LBB130_158
// %bb.46:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w27, #769
	b.hs	.LBB130_154
// %bb.47:                              //   in Loop: Header=BB130_6 Depth=1
	mov	w8, w27
	mov	w9, #43691
	and	x8, x8, #0xffff
	movk	w9, #43690, lsl #16
	mul	x8, x8, x9
	lsr	x8, x8, #33
	str	x8, [sp, #112]                  // 8-byte Folded Spill
	add	w8, w8, w8, lsl #1
	cmp	w8, w27
	b.ne	.LBB130_154
// %bb.48:                              //   in Loop: Header=BB130_6 Depth=1
	and	w8, w27, #0xffff
	cmp	w8, #3
	b.lo	.LBB130_4
// %bb.49:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [sp, #112]                  // 8-byte Folded Reload
	ldr	x28, [sp, #72]                  // 8-byte Folded Reload
	cmp	w8, #1
	csinc	w27, w8, wzr, hi
	ldp	x9, x8, [x20, #184]
	b	.LBB130_52
.LBB130_50:                             //   in Loop: Header=BB130_52 Depth=2
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB130_51:                             //   in Loop: Header=BB130_52 Depth=2
	sturb	w10, [x28, #-1]
	mov	w10, #255
	subs	x27, x27, #1
	strb	w10, [x28], #4
	b.eq	.LBB130_4
.LBB130_52:                             //   Parent Loop BB130_6 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	x9, x8
	b.hs	.LBB130_54
// %bb.53:                              //   in Loop: Header=BB130_52 Depth=2
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB130_59
.LBB130_54:                             //   in Loop: Header=BB130_52 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_59
// %bb.55:                              //   in Loop: Header=BB130_52 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_57
// %bb.56:                              //   in Loop: Header=BB130_52 Depth=2
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB130_58
.LBB130_57:                             //   in Loop: Header=BB130_52 Depth=2
	mov	w10, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_58:                             //   in Loop: Header=BB130_52 Depth=2
	mov	x9, x23
	stp	x23, x8, [x20, #184]
.LBB130_59:                             //   in Loop: Header=BB130_52 Depth=2
	cmp	x9, x8
	sturb	w10, [x28, #-3]
	b.hs	.LBB130_61
// %bb.60:                              //   in Loop: Header=BB130_52 Depth=2
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB130_66
.LBB130_61:                             //   in Loop: Header=BB130_52 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_66
// %bb.62:                              //   in Loop: Header=BB130_52 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_64
// %bb.63:                              //   in Loop: Header=BB130_52 Depth=2
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB130_65
.LBB130_64:                             //   in Loop: Header=BB130_52 Depth=2
	mov	w10, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_65:                             //   in Loop: Header=BB130_52 Depth=2
	mov	x9, x23
	stp	x23, x8, [x20, #184]
.LBB130_66:                             //   in Loop: Header=BB130_52 Depth=2
	cmp	x9, x8
	sturb	w10, [x28, #-2]
	b.lo	.LBB130_50
// %bb.67:                              //   in Loop: Header=BB130_52 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_51
// %bb.68:                              //   in Loop: Header=BB130_52 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_70
// %bb.69:                              //   in Loop: Header=BB130_52 Depth=2
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB130_71
.LBB130_70:                             //   in Loop: Header=BB130_52 Depth=2
	mov	w10, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_71:                             //   in Loop: Header=BB130_52 Depth=2
	mov	x9, x23
	stp	x23, x8, [x20, #184]
	b	.LBB130_51
.LBB130_72:                             //   in Loop: Header=BB130_6 Depth=1
	tbnz	w27, #31, .LBB130_92
// %bb.73:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #16]
	cbz	x8, .LBB130_116
// %bb.74:                              //   in Loop: Header=BB130_6 Depth=1
	ldp	x8, x9, [x20, #184]
	sub	w10, w9, w8
	subs	w1, w27, w10
	b.le	.LBB130_117
// %bb.75:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #24]
	str	x9, [x20, #184]
	ldr	x0, [x20, #40]
	blr	x8
	mov	w8, #1
	str	w8, [sp, #92]                   // 4-byte Folded Spill
	b	.LBB130_5
.LBB130_76:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #20036
	movk	w8, #18757, lsl #16
	cmp	w0, w8
	b.eq	.LBB130_157
.LBB130_77:                             //   in Loop: Header=BB130_6 Depth=1
	cbnz	w28, .LBB130_158
// %bb.78:                              //   in Loop: Header=BB130_6 Depth=1
	tbz	w0, #29, .LBB130_163
// %bb.79:                              //   in Loop: Header=BB130_6 Depth=1
	tbnz	w27, #31, .LBB130_113
// %bb.80:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #16]
	cbz	x8, .LBB130_119
// %bb.81:                              //   in Loop: Header=BB130_6 Depth=1
	ldp	x8, x9, [x20, #184]
	sub	w10, w9, w8
	subs	w1, w27, w10
	b.gt	.LBB130_3
	b	.LBB130_120
.LBB130_82:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB130_170
// %bb.83:                              //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_123
// %bb.84:                              //   in Loop: Header=BB130_6 Depth=1
	mov	x8, x20
	ldrb	w19, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB130_124
.LBB130_85:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	mov	w22, w19
	ldr	x0, [x8]
	ldr	w9, [sp, #120]                  // 4-byte Folded Reload
	mov	w19, w24
	ldr	x8, [x20, #16]
	add	x28, x0, w9, uxtw
	cbz	x8, .LBB130_38
.LBB130_86:                             //   in Loop: Header=BB130_6 Depth=1
	ldp	x1, x8, [x20, #184]
	sub	x9, x8, x1
	subs	w24, w27, w9
	b.le	.LBB130_89
// %bb.87:                              //   in Loop: Header=BB130_6 Depth=1
	sxtw	x27, w9
	mov	x0, x28
	mov	x2, x27
	bl	memcpy
	ldr	x8, [x20, #16]
	add	x1, x28, x27
	ldr	x0, [x20, #40]
	mov	w2, w24
	blr	x8
	ldr	x8, [x20, #192]
	cmp	w0, w24
	str	x8, [x20, #184]
	b.ne	.LBB130_166
// %bb.88:                              //   in Loop: Header=BB130_6 Depth=1
	mov	w28, wzr
	str	w21, [sp, #120]                 // 4-byte Folded Spill
	b	.LBB130_91
.LBB130_89:                             //   in Loop: Header=BB130_6 Depth=1
	sxtw	x24, w27
	add	x9, x1, x24
	cmp	x9, x8
	b.hi	.LBB130_166
// %bb.90:                              //   in Loop: Header=BB130_6 Depth=1
	mov	x0, x28
	mov	x2, x24
	bl	memcpy
	ldr	x8, [x20, #184]
	mov	w28, wzr
	str	w21, [sp, #120]                 // 4-byte Folded Spill
	add	x8, x8, x24
	str	x8, [x20, #184]
.LBB130_91:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w21, #17489
	mov	w24, w19
	mov	w19, w22
	mov	w22, #1
	movk	w21, #18760, lsl #16
	b	.LBB130_5
.LBB130_92:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #192]
	b	.LBB130_118
.LBB130_93:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [x20, #8]
	tbz	w8, #0, .LBB130_175
// %bb.94:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w27, w8, lsl #1
	b.ne	.LBB130_165
// %bb.95:                              //   in Loop: Header=BB130_6 Depth=1
	cmp	w8, #1
	b.lt	.LBB130_115
// %bb.96:                              //   in Loop: Header=BB130_6 Depth=1
	ldp	x9, x8, [x20, #184]
	mov	x27, xzr
	mov	w28, w19
	add	x24, sp, #132
	b	.LBB130_99
.LBB130_97:                             //   in Loop: Header=BB130_99 Depth=2
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB130_98:                             //   in Loop: Header=BB130_99 Depth=2
	adrp	x11, _ZL23stbi__depth_scale_table
	add	x11, x11, :lo12:_ZL23stbi__depth_scale_table
	ldrb	w11, [x11, x28]
	mul	w10, w11, w10
	ldrsw	x11, [x20, #8]
	strb	w10, [x24, x27]
	add	x27, x27, #1
	cmp	x27, x11
	b.ge	.LBB130_115
.LBB130_99:                             //   Parent Loop BB130_6 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	x9, x8
	b.hs	.LBB130_101
// %bb.100:                             //   in Loop: Header=BB130_99 Depth=2
	add	x9, x9, #1
	b	.LBB130_106
.LBB130_101:                            //   in Loop: Header=BB130_99 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_107
// %bb.102:                             //   in Loop: Header=BB130_99 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_104
// %bb.103:                             //   in Loop: Header=BB130_99 Depth=2
	add	x8, x20, w0, sxtw
	add	x8, x8, #56
	b	.LBB130_105
.LBB130_104:                            //   in Loop: Header=BB130_99 Depth=2
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_105:                            //   in Loop: Header=BB130_99 Depth=2
	mov	x9, x23
	str	x8, [x20, #192]
.LBB130_106:                            //   in Loop: Header=BB130_99 Depth=2
	str	x9, [x20, #184]
.LBB130_107:                            //   in Loop: Header=BB130_99 Depth=2
	cmp	x9, x8
	b.lo	.LBB130_97
// %bb.108:                             //   in Loop: Header=BB130_99 Depth=2
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_98
// %bb.109:                             //   in Loop: Header=BB130_99 Depth=2
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_111
// %bb.110:                             //   in Loop: Header=BB130_99 Depth=2
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB130_112
.LBB130_111:                            //   in Loop: Header=BB130_99 Depth=2
	mov	w10, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_112:                            //   in Loop: Header=BB130_99 Depth=2
	mov	x9, x23
	stp	x23, x8, [x20, #184]
	b	.LBB130_98
.LBB130_113:                            //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #192]
	b	.LBB130_121
.LBB130_114:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w21, #17489
	mov	w28, wzr
	mov	w24, #4
	movk	w21, #18760, lsl #16
	b	.LBB130_5
.LBB130_115:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w8, #1
	mov	w28, wzr
	mov	w24, wzr
	str	w8, [sp, #68]                   // 4-byte Folded Spill
	b	.LBB130_5
.LBB130_116:                            //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #184]
.LBB130_117:                            //   in Loop: Header=BB130_6 Depth=1
	add	x8, x8, w27, uxtw
.LBB130_118:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w9, #1
	str	x8, [x20, #184]
	str	w9, [sp, #92]                   // 4-byte Folded Spill
	b	.LBB130_5
.LBB130_119:                            //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #184]
.LBB130_120:                            //   in Loop: Header=BB130_6 Depth=1
	add	x8, x8, w27, uxtw
.LBB130_121:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w28, wzr
	str	x8, [x20, #184]
	b	.LBB130_5
.LBB130_122:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w28, wzr
	mov	w24, #4
	b	.LBB130_5
.LBB130_123:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w19, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB130_124:                            //   in Loop: Header=BB130_6 Depth=1
	mov	x9, x23
	stp	x23, x8, [x20, #184]
.LBB130_125:                            //   in Loop: Header=BB130_6 Depth=1
	cmp	w19, #8
	b.hi	.LBB130_170
// %bb.126:                             //   in Loop: Header=BB130_6 Depth=1
	lsl	w10, w22, w19
	mov	w11, #278
	tst	w10, w11
	b.eq	.LBB130_170
// %bb.127:                             //   in Loop: Header=BB130_6 Depth=1
	cmp	x9, x8
	b.hs	.LBB130_129
// %bb.128:                             //   in Loop: Header=BB130_6 Depth=1
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	w21, #7
	b.lo	.LBB130_134
	b	.LBB130_156
.LBB130_129:                            //   in Loop: Header=BB130_6 Depth=1
	ldr	w10, [x20, #48]
	cbz	w10, .LBB130_132
// %bb.130:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_133
// %bb.131:                             //   in Loop: Header=BB130_6 Depth=1
	mov	x8, x20
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x23
	stp	x23, x8, [x20, #184]
	cmp	w21, #7
	b.lo	.LBB130_134
	b	.LBB130_156
.LBB130_132:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w21, wzr
	b	.LBB130_137
.LBB130_133:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w21, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	mov	x9, x23
	stp	x23, x8, [x20, #184]
	cmp	w21, #7
	b.hs	.LBB130_156
.LBB130_134:                            //   in Loop: Header=BB130_6 Depth=1
	cmp	w21, #3
	b.ne	.LBB130_136
// %bb.135:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w24, #3
	b	.LBB130_137
.LBB130_136:                            //   in Loop: Header=BB130_6 Depth=1
	tbnz	w21, #0, .LBB130_156
.LBB130_137:                            //   in Loop: Header=BB130_6 Depth=1
	cmp	x9, x8
	b.hs	.LBB130_139
// %bb.138:                             //   in Loop: Header=BB130_6 Depth=1
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	cbz	w8, .LBB130_143
	b	.LBB130_169
.LBB130_139:                            //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB130_143
// %bb.140:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x26
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB130_142
// %bb.141:                             //   in Loop: Header=BB130_6 Depth=1
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	stp	x23, x9, [x20, #184]
	cbz	w8, .LBB130_143
	b	.LBB130_169
.LBB130_142:                            //   in Loop: Header=BB130_6 Depth=1
	mov	w8, wzr
	mov	x9, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
	stp	x23, x9, [x20, #184]
	cbnz	w8, .LBB130_169
.LBB130_143:                            //   in Loop: Header=BB130_6 Depth=1
	mov	x0, x20
	bl	_ZL10stbi__get8P13stbi__context
	tst	w0, #0xff
	b.ne	.LBB130_167
// %bb.144:                             //   in Loop: Header=BB130_6 Depth=1
	mov	x0, x20
	bl	_ZL10stbi__get8P13stbi__context
	and	w11, w0, #0xff
	cmp	w11, #2
	b.hs	.LBB130_168
// %bb.145:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	w9, [x20]
	cbz	w9, .LBB130_155
// %bb.146:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [x20, #4]
	cbz	w8, .LBB130_155
// %bb.147:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w10, #1073741824
	str	w21, [sp, #88]                  // 4-byte Folded Spill
	str	w11, [sp, #80]                  // 4-byte Folded Spill
	udiv	w9, w10, w9
	cbz	w24, .LBB130_150
// %bb.148:                             //   in Loop: Header=BB130_6 Depth=1
	cmp	w8, w9, lsr #2
	str	w22, [x20, #8]
	b.hi	.LBB130_153
// %bb.149:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w21, #17489
	mov	w28, wzr
	movk	w21, #18760, lsl #16
	b	.LBB130_5
.LBB130_150:                            //   in Loop: Header=BB130_6 Depth=1
	and	w10, w21, #0x2
	bfxil	w10, w21, #2, #1
	add	w10, w10, #1
	udiv	w9, w9, w10
	str	w10, [x20, #8]
	cmp	w9, w8
	b.lo	.LBB130_153
// %bb.151:                             //   in Loop: Header=BB130_6 Depth=1
	ldr	w8, [sp, #96]                   // 4-byte Folded Reload
	cmp	w8, #2
	b.eq	.LBB130_174
// %bb.152:                             //   in Loop: Header=BB130_6 Depth=1
	mov	w21, #17489
	mov	w28, wzr
	mov	w24, wzr
	movk	w21, #18760, lsl #16
	b	.LBB130_5
.LBB130_153:
	adrp	x9, .L.str.27
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.27
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_154:
	adrp	x9, .L.str.51
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.51
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_155:
	adrp	x9, .L.str.49
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.49
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_156:
	adrp	x9, .L.str.45
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.45
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_157:
	cbz	w28, .LBB130_173
.LBB130_158:
	adrp	x9, .L.str.50
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.50
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_159:
	adrp	x9, .L.str.42
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.42
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_160:
	adrp	x9, .L.str.43
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.43
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_161:
	adrp	x9, .L.str.52
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.52
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_162:
	adrp	x9, .L.str.56
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.56
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_163:
	adrp	x11, _ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk
	adrp	x8, _ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk
	rev	w9, w0
	adrp	x10, .L_MergedGlobals.126+8
	add	x11, x11, :lo12:_ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk
	mov	w22, wzr
	str	w9, [x8, :lo12:_ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk]
	str	x11, [x10, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_164:
	mov	w22, #1
	str	w24, [x20, #8]
	b	.LBB130_221
.LBB130_165:
	adrp	x9, .L.str.54
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.54
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_166:
	adrp	x9, .L.str.57
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.57
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_167:
	adrp	x9, .L.str.47
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.47
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_168:
	adrp	x9, .L.str.48
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.48
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_169:
	adrp	x9, .L.str.46
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.46
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_170:
	adrp	x9, .L.str.44
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.44
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_171:
	mov	w8, #4
	mov	w22, #1
	str	w8, [x20, #8]
	b	.LBB130_221
.LBB130_172:
	adrp	x9, .L.str.53
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.53
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_173:
	ldr	w8, [sp, #96]                   // 4-byte Folded Reload
	cbz	w8, .LBB130_176
.LBB130_174:
	mov	w22, #1
	b	.LBB130_221
.LBB130_175:
	adrp	x9, .L.str.55
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.55
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_176:
	ldr	x8, [sp, #104]                  // 8-byte Folded Reload
	str	w19, [sp, #72]                  // 4-byte Folded Spill
	ldr	x19, [x8]
	cbz	x19, .LBB130_195
// %bb.177:
	ldp	w8, w9, [x20]
	ldr	w12, [sp, #72]                  // 4-byte Folded Reload
	orr	w11, wzr, #0x7
	ldr	w10, [x20, #8]
	str	w24, [sp, #16]                  // 4-byte Folded Spill
	madd	w8, w8, w12, w11
	mul	w10, w10, w9
	lsr	w8, w8, #3
	madd	w24, w10, w8, w9
	sxtw	x0, w24
	bl	malloc
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	cbz	x0, .LBB130_197
// %bb.178:
	ldr	w8, [sp, #92]                   // 4-byte Folded Reload
	add	x9, sp, #1160
	mov	x1, x0
	add	x0, sp, #1160
	mov	w2, w24
	mov	w3, #1
	cmp	w8, #0
	ldr	w8, [sp, #120]                  // 4-byte Folded Reload
	cset	w4, eq
	str	x19, [x9]
	add	x8, x19, w8, sxtw
	add	x19, sp, #1160
	str	x8, [x19, #8]
	bl	_ZL13stbi__do_zlibP10stbi__zbufPciii
	cbz	w0, .LBB130_196
// %bb.179:
	ldr	x8, [x19, #32]
	ldr	w9, [sp, #1184]
	str	x8, [x23, #16]
	cbz	x8, .LBB130_220
// %bb.180:
	ldr	x0, [x23, #8]
	sub	w22, w9, w8
	bl	free
	str	xzr, [x23, #8]
	ldr	w19, [sp, #16]                  // 4-byte Folded Reload
	ldr	w8, [x20, #8]
	ldr	w10, [sp, #52]                  // 4-byte Folded Reload
	cmp	w19, #0
	add	w9, w8, #1
	ccmp	w9, w10, #0, eq
	ldr	w9, [sp, #68]                   // 4-byte Folded Reload
	ccmp	w10, #3, #4, eq
	ccmp	w9, #0, #0, eq
	cinc	w24, w8, ne
	ldr	w8, [sp, #80]                   // 4-byte Folded Reload
	str	w24, [x20, #12]
	ldr	x21, [x23]
	ldr	x1, [x23, #16]
	ldp	w27, w25, [x21]
	cbz	w8, .LBB130_199
// %bb.181:
	mul	w8, w27, w24
	mov	x19, x1
	mul	w0, w8, w25
	bl	malloc
	adrp	x11, .L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig
	adrp	x12, .L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc
	mov	x15, x23
	mov	x1, x19
	mov	x10, xzr
	add	x11, x11, :lo12:.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig
	add	x12, x12, :lo12:.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc
	sxtw	x28, w24
	mov	w2, w22
	str	x0, [sp, #8]                    // 8-byte Folded Spill
	str	x24, [sp, #24]                  // 8-byte Folded Spill
.LBB130_182:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB130_188 Depth 2
                                        //       Child Loop BB130_189 Depth 3
	lsl	x8, x10, #2
	ldrsw	x14, [x11, x8]
	ldrsw	x24, [x12, x8]
	mvn	w9, w14
	add	w9, w27, w9
	add	w9, w9, w24
	cmp	w24, w9
	b.hi	.LBB130_193
// %bb.183:                             //   in Loop: Header=BB130_182 Depth=1
	adrp	x13, .L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yorig
	add	x13, x13, :lo12:.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yorig
	ldr	w26, [x13, x8]
	adrp	x13, .L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yspc
	add	x13, x13, :lo12:.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yspc
	ldr	w19, [x13, x8]
	mvn	w8, w26
	add	w8, w25, w8
	add	w8, w8, w19
	cmp	w19, w8
	b.hi	.LBB130_193
// %bb.184:                             //   in Loop: Header=BB130_182 Depth=1
	udiv	w25, w9, w24
	mov	x0, x15
	ldr	w6, [sp, #72]                   // 4-byte Folded Reload
	str	x14, [sp, #120]                 // 8-byte Folded Spill
	ldr	w7, [sp, #88]                   // 4-byte Folded Reload
	str	x10, [sp, #40]                  // 8-byte Folded Spill
	mov	x22, x15
	str	x1, [sp, #80]                   // 8-byte Folded Spill
	mov	w27, w2
	mov	w4, w25
	udiv	w23, w8, w19
	ldr	w8, [x21, #8]
	ldr	x21, [sp, #24]                  // 8-byte Folded Reload
	str	w8, [sp, #36]                   // 4-byte Folded Spill
	mov	w3, w21
	mov	w5, w23
	bl	_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	cbz	w0, .LBB130_219
// %bb.185:                             //   in Loop: Header=BB130_182 Depth=1
	cmp	w23, #1
	ccmp	w25, #0, #4, ge
	b.gt	.LBB130_187
// %bb.186:                             //   in Loop: Header=BB130_182 Depth=1
	ldr	x24, [x22, #24]
	b	.LBB130_192
.LBB130_187:                            //   in Loop: Header=BB130_182 Depth=1
	mov	x8, x21
	ldr	x10, [sp, #120]                 // 8-byte Folded Reload
	str	w27, [sp, #20]                  // 4-byte Folded Spill
	mov	x9, xzr
	mul	w21, w8, w26
	ldr	x27, [x22]
	mul	w8, w8, w19
	str	x23, [sp, #112]                 // 8-byte Folded Spill
	mul	x19, x28, x24
	ldr	x24, [x22, #24]
	str	w8, [sp, #104]                  // 4-byte Folded Spill
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	madd	x8, x28, x10, x8
	str	x8, [sp, #96]                   // 8-byte Folded Spill
.LBB130_188:                            //   Parent Loop BB130_182 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB130_189 Depth 3
	mul	x22, x9, x25
	mov	x26, xzr
	ldr	x23, [sp, #96]                  // 8-byte Folded Reload
	str	x9, [sp, #120]                  // 8-byte Folded Spill
.LBB130_189:                            //   Parent Loop BB130_182 Depth=1
                                        //     Parent Loop BB130_188 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	w8, [x27]
	add	x9, x26, x22
	mov	x2, x28
	madd	x1, x9, x28, x24
	mul	w8, w21, w8
	add	x0, x23, x8
	bl	memcpy
	add	x26, x26, #1
	add	x23, x23, x19
	cmp	x26, x25
	b.ne	.LBB130_189
// %bb.190:                             //   in Loop: Header=BB130_188 Depth=2
	ldp	x23, x9, [sp, #112]             // 16-byte Folded Reload
	ldr	w8, [sp, #104]                  // 4-byte Folded Reload
	add	x9, x9, #1
	add	w21, w21, w8
	cmp	x9, x23
	b.ne	.LBB130_188
// %bb.191:                             //   in Loop: Header=BB130_182 Depth=1
	ldr	x22, [sp, #56]                  // 8-byte Folded Reload
	ldr	w27, [sp, #20]                  // 4-byte Folded Reload
.LBB130_192:                            //   in Loop: Header=BB130_182 Depth=1
	ldr	w8, [sp, #72]                   // 4-byte Folded Reload
	orr	w9, wzr, #0x7
	ldr	w10, [sp, #36]                  // 4-byte Folded Reload
	mov	x0, x24
	mul	w8, w25, w8
	madd	w8, w8, w10, w9
	asr	w8, w8, #3
	madd	w19, w23, w8, w23
	bl	free
	ldr	x1, [sp, #80]                   // 8-byte Folded Reload
	adrp	x11, .L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig
	adrp	x12, .L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc
	sub	w2, w27, w19
	ldr	x10, [sp, #40]                  // 8-byte Folded Reload
	add	x11, x11, :lo12:.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig
	add	x1, x1, w19, uxtw
	add	x12, x12, :lo12:.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc
	mov	x15, x22
.LBB130_193:                            //   in Loop: Header=BB130_182 Depth=1
	add	x10, x10, #1
	cmp	x10, #7
	b.eq	.LBB130_198
// %bb.194:                             //   in Loop: Header=BB130_182 Depth=1
	ldr	x21, [x15]
	ldp	w27, w25, [x21]
	b	.LBB130_182
.LBB130_195:
	adrp	x9, .L.str.58
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.58
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_196:
	ldr	x0, [x19, #32]
	bl	free
.LBB130_197:
	mov	w22, wzr
	str	xzr, [x23, #16]
	b	.LBB130_221
.LBB130_198:
	ldr	x8, [sp, #8]                    // 8-byte Folded Reload
	ldr	w19, [sp, #16]                  // 4-byte Folded Reload
	str	x8, [x15, #24]
	b	.LBB130_200
.LBB130_199:
	mov	x0, x23
	mov	w2, w22
	mov	w3, w24
	mov	w4, w27
	mov	w5, w25
	ldr	w6, [sp, #72]                   // 4-byte Folded Reload
	ldr	w7, [sp, #88]                   // 4-byte Folded Reload
	bl	_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	mov	x15, x23
	cbz	w0, .LBB130_220
.LBB130_200:
	ldr	w8, [sp, #68]                   // 4-byte Folded Reload
	cbz	w8, .LBB130_243
// %bb.201:
	ldr	x8, [x15]
	ldr	w9, [x20, #12]
	ldp	w10, w8, [x8]
	cmp	w9, #2
	mul	w8, w8, w10
	ldr	x10, [x15, #24]
	b.eq	.LBB130_222
// %bb.202:
	cmp	w9, #4
	b.ne	.LBB130_259
// %bb.203:
	mov	x3, x15
	ldr	w19, [sp, #16]                  // 4-byte Folded Reload
	cbz	w8, .LBB130_243
// %bb.204:
	ldrb	w9, [sp, #132]
	subs	w13, w8, #1
	ldrb	w11, [sp, #133]
	ldrb	w12, [sp, #134]
	b.eq	.LBB130_228
// %bb.205:
	add	x15, x13, #1
	and	x13, x15, #0x1fffffffe
	mov	x16, x13
	add	x14, x10, x13, lsl #2
	add	x10, x10, #3
	b	.LBB130_207
.LBB130_206:                            //   in Loop: Header=BB130_207 Depth=1
	subs	x16, x16, #2
	add	x10, x10, #8
	b.eq	.LBB130_225
.LBB130_207:                            // =>This Inner Loop Header: Depth=1
	ldurb	w17, [x10, #-3]
                                        // implicit-def: $w18
	cmp	w17, w9
	b.ne	.LBB130_209
// %bb.208:                             //   in Loop: Header=BB130_207 Depth=1
	ldurb	w18, [x10, #-2]
.LBB130_209:                            //   in Loop: Header=BB130_207 Depth=1
	ldrb	w1, [x10, #1]
                                        // implicit-def: $w0
	cmp	w1, w9
	b.ne	.LBB130_211
// %bb.210:                             //   in Loop: Header=BB130_207 Depth=1
	ldrb	w0, [x10, #2]
.LBB130_211:                            //   in Loop: Header=BB130_207 Depth=1
	cmp	w1, w9
	cset	w1, eq
	cmp	w17, w9
	cset	w17, eq
	cmp	w18, w11
	cset	w2, eq
	cmp	w0, w11
	cset	w18, eq
	and	w17, w17, w2
	cmp	w17, #1
                                        // implicit-def: $w0
	b.ne	.LBB130_213
// %bb.212:                             //   in Loop: Header=BB130_207 Depth=1
	ldurb	w0, [x10, #-1]
.LBB130_213:                            //   in Loop: Header=BB130_207 Depth=1
	and	w18, w1, w18
                                        // implicit-def: $w1
	cbz	w18, .LBB130_215
// %bb.214:                             //   in Loop: Header=BB130_207 Depth=1
	ldrb	w1, [x10, #3]
.LBB130_215:                            //   in Loop: Header=BB130_207 Depth=1
	cmp	w0, w12
	cset	w2, eq
	cmp	w1, w12
	cset	w0, eq
	and	w17, w17, w2
	cmp	w17, #1
	b.ne	.LBB130_217
// %bb.216:                             //   in Loop: Header=BB130_207 Depth=1
	strb	wzr, [x10]
	and	w17, w18, w0
	cbz	w17, .LBB130_206
	b	.LBB130_218
.LBB130_217:                            //   in Loop: Header=BB130_207 Depth=1
	and	w17, w18, w0
	cbz	w17, .LBB130_206
.LBB130_218:                            //   in Loop: Header=BB130_207 Depth=1
	strb	wzr, [x10, #4]
	b	.LBB130_206
.LBB130_219:
	ldr	x0, [sp, #8]                    // 8-byte Folded Reload
	bl	free
.LBB130_220:
	mov	w22, wzr
.LBB130_221:
	mov	w0, w22
	add	sp, sp, #1, lsl #12             // =4096
	add	sp, sp, #1168
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB130_222:
	cbz	w8, .LBB130_243
// %bb.223:
	mov	x22, x15
	ldrb	w9, [sp, #132]
	sub	w11, w8, #1
	cmp	w11, #8
	b.hs	.LBB130_226
// %bb.224:
	mov	w13, wzr
	b	.LBB130_241
.LBB130_225:
	cmp	x15, x13
	mov	x15, x3
	ldr	w19, [sp, #16]                  // 4-byte Folded Reload
	b.ne	.LBB130_229
	b	.LBB130_243
.LBB130_226:
	cmp	w11, #16
	b.hs	.LBB130_235
// %bb.227:
	mov	x12, xzr
	b	.LBB130_239
.LBB130_228:
	ldr	w19, [sp, #16]                  // 4-byte Folded Reload
	mov	x14, x10
	mov	x15, x3
.LBB130_229:
	add	x10, x14, #3
	sub	w8, w8, w13
	b	.LBB130_231
.LBB130_230:                            //   in Loop: Header=BB130_231 Depth=1
	add	x10, x10, #4
	subs	w8, w8, #1
	b.eq	.LBB130_243
.LBB130_231:                            // =>This Inner Loop Header: Depth=1
	ldurb	w13, [x10, #-3]
	cmp	w13, w9
	b.ne	.LBB130_230
// %bb.232:                             //   in Loop: Header=BB130_231 Depth=1
	ldurb	w13, [x10, #-2]
	cmp	w13, w11
	b.ne	.LBB130_230
// %bb.233:                             //   in Loop: Header=BB130_231 Depth=1
	ldurb	w13, [x10, #-1]
	cmp	w13, w12
	b.ne	.LBB130_230
// %bb.234:                             //   in Loop: Header=BB130_231 Depth=1
	strb	wzr, [x10]
	b	.LBB130_230
.LBB130_235:
	add	x13, x11, #1
	mov	w14, #16
	and	x12, x13, #0xf
	tst	x13, #0xf
	csel	x14, x14, x12, eq
	add	x15, x10, #15
	sub	x12, x13, x14
	dup	v0.16b, w9
.LBB130_236:                            // =>This Inner Loop Header: Depth=1
	sub	x16, x15, #15
	sub	x17, x15, #12
	sub	x18, x15, #10
	sub	x0, x15, #8
	sub	x13, x13, #16
	ld2	{ v1.16b, v2.16b }, [x16]
	sub	x16, x15, #14
	cmp	x14, x13
	cmeq	v1.16b, v1.16b, v0.16b
	mvn	v1.16b, v1.16b
	st1	{ v1.b }[0], [x16]
	sub	x16, x15, #6
	st1	{ v1.b }[1], [x17]
	sub	x17, x15, #4
	st1	{ v1.b }[2], [x18]
	sub	x18, x15, #2
	st1	{ v1.b }[4], [x16]
	add	x16, x15, #2
	st1	{ v1.b }[5], [x17]
	add	x17, x15, #4
	st1	{ v1.b }[6], [x18]
	add	x18, x15, #6
	st1	{ v1.b }[8], [x16]
	add	x16, x15, #10
	st1	{ v1.b }[3], [x0]
	add	x0, x15, #8
	st1	{ v1.b }[7], [x15]
	st1	{ v1.b }[9], [x17]
	add	x17, x15, #12
	st1	{ v1.b }[10], [x18]
	add	x18, x15, #14
	st1	{ v1.b }[12], [x16]
	add	x16, x15, #16
	add	x15, x15, #32
	st1	{ v1.b }[11], [x0]
	st1	{ v1.b }[13], [x17]
	st1	{ v1.b }[14], [x18]
	st1	{ v1.b }[15], [x16]
	b.ne	.LBB130_236
// %bb.237:
	cmp	x14, #8
	b.hi	.LBB130_239
// %bb.238:
	add	x10, x10, x12, lsl #1
	mov	w13, w12
	b	.LBB130_241
.LBB130_239:
	add	x13, x11, #1
	mov	w14, #8
	and	x15, x13, #0x7
	tst	x13, #0x7
	csel	x14, x14, x15, eq
	dup	v0.8b, w9
	sub	x13, x13, x14
	mvn	x11, x11
	add	x15, x10, x12, lsl #1
	add	x12, x14, x12
	add	x10, x10, x13, lsl #1
	add	x11, x11, x12
	add	x12, x15, #7
.LBB130_240:                            // =>This Inner Loop Header: Depth=1
	sub	x14, x12, #7
	sub	x15, x12, #4
	sub	x16, x12, #2
	adds	x11, x11, #8
	ld2	{ v1.8b, v2.8b }, [x14]
	sub	x14, x12, #6
	cmeq	v1.8b, v1.8b, v0.8b
	mvn	v1.8b, v1.8b
	st1	{ v1.b }[0], [x14]
	add	x14, x12, #2
	st1	{ v1.b }[1], [x15]
	add	x15, x12, #4
	st1	{ v1.b }[2], [x16]
	add	x16, x12, #6
	st1	{ v1.b }[3], [x12]
	st1	{ v1.b }[4], [x14]
	add	x14, x12, #8
	add	x12, x12, #16
	st1	{ v1.b }[5], [x15]
	st1	{ v1.b }[6], [x16]
	st1	{ v1.b }[7], [x14]
	b.ne	.LBB130_240
.LBB130_241:
	sub	w8, w8, w13
	mov	x15, x22
	ldr	w19, [sp, #16]                  // 4-byte Folded Reload
.LBB130_242:                            // =>This Inner Loop Header: Depth=1
	ldrb	w11, [x10]
	cmp	w11, w9
	csetm	w11, ne
	subs	w8, w8, #1
	strb	w11, [x10, #1]
	add	x10, x10, #2
	b.ne	.LBB130_242
.LBB130_243:
	ldr	w8, [sp, #92]                   // 4-byte Folded Reload
	cbz	w8, .LBB130_247
// %bb.244:
	adrp	x8, .L_MergedGlobals.126+4
	ldr	w8, [x8, :lo12:.L_MergedGlobals.126+4]
	cbz	w8, .LBB130_247
// %bb.245:
	ldr	w8, [x20, #12]
	cmp	w8, #3
	b.lt	.LBB130_247
// %bb.246:
	ldr	x8, [x15]
	mov	x21, x15
	ldr	x3, [x15, #24]
	ldp	w0, w1, [x8]
	ldr	w2, [x8, #12]
	bl	_ZL15stbi__de_iphoneP9stbi__png
	mov	x15, x21
.LBB130_247:
	cbz	w19, .LBB130_258
// %bb.248:
	ldr	w8, [sp, #52]                   // 4-byte Folded Reload
	mov	x23, x15
	cmp	w8, #2
	csel	w22, w8, w19, gt
	stp	w19, w22, [x20, #8]
	ldr	x8, [x15]
	ldr	x20, [x15, #24]
	ldp	w9, w8, [x8]
	mul	w19, w8, w9
	mul	w0, w19, w22
	bl	malloc
	cbz	x0, .LBB130_253
// %bb.249:
	mov	x21, x0
	cmp	w22, #3
	b.ne	.LBB130_254
// %bb.250:
	cbz	w19, .LBB130_257
// %bb.251:
	add	x8, sp, #136
	mov	x9, x20
	mov	x10, x21
.LBB130_252:                            // =>This Inner Loop Header: Depth=1
	ldrb	w11, [x9], #1
	subs	x19, x19, #1
	add	x11, x8, x11, lsl #2
	ldrh	w12, [x11]
	ldrb	w11, [x11, #2]
	strh	w12, [x10]
	strb	w11, [x10, #2]
	add	x10, x10, #3
	b.ne	.LBB130_252
	b	.LBB130_257
.LBB130_253:
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	mov	w22, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	b	.LBB130_221
.LBB130_254:
	cbz	w19, .LBB130_257
// %bb.255:
	add	x8, sp, #136
	mov	x9, x20
	mov	x10, x21
.LBB130_256:                            // =>This Inner Loop Header: Depth=1
	ldrb	w11, [x9], #1
	subs	x19, x19, #1
	ldr	w11, [x8, x11, lsl #2]
	str	w11, [x10], #4
	b.ne	.LBB130_256
.LBB130_257:
	mov	x0, x20
	bl	free
	mov	x15, x23
	str	x21, [x23, #24]
.LBB130_258:
	ldr	x0, [x15, #16]
	mov	x19, x15
	bl	free
	mov	w22, #1
	str	xzr, [x19, #16]
	b	.LBB130_221
.LBB130_259:
	adrp	x0, .L.str.65
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL26stbi__compute_transparencyP9stbi__pngPhi
	add	x0, x0, :lo12:.L.str.65
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL26stbi__compute_transparencyP9stbi__pngPhi
	mov	w2, #4186
	bl	__assert_fail
.Lfunc_end130:
	.size	_ZL20stbi__parse_png_fileP9stbi__pngii, .Lfunc_end130-_ZL20stbi__parse_png_fileP9stbi__pngii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL20stbi__convert_formatPhiijj
	.type	_ZL20stbi__convert_formatPhiijj,@function
_ZL20stbi__convert_formatPhiijj:        // @_ZL20stbi__convert_formatPhiijj
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #400
	stp	x29, x30, [sp, #304]            // 16-byte Folded Spill
	add	x29, sp, #304
	stp	x28, x27, [sp, #320]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #336]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #352]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #368]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #384]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x19, x0
	cmp	w2, w1
	b.eq	.LBB131_176
// %bb.1:
	mov	w21, w2
	sub	w8, w2, #1
	cmp	w8, #4
	b.hs	.LBB131_177
// %bb.2:
	mul	w25, w3, w21
	mov	w24, w4
	mov	w20, w3
	mov	w22, w1
	mul	w0, w25, w4
	bl	malloc
	cbz	x0, .LBB131_175
// %bb.3:
	mov	x23, x0
	cmp	w24, #1
	b.lt	.LBB131_174
// %bb.4:
	add	w14, w21, w22, lsl #3
	cmp	w14, #35
	b.hi	.LBB131_178
// %bb.5:
	mov	x9, #7168
	mov	w8, #1
	movk	x9, #5658, lsl #16
	lsl	x8, x8, x14
	movk	x9, #14, lsl #32
	tst	x8, x9
	b.eq	.LBB131_178
// %bb.6:
	sub	w9, w20, #1
	mov	w17, #16
	add	x10, x9, #1
	mov	w11, w24
	and	x16, x10, #0x1fffffff0
	and	x0, x10, #0x1fffffff8
	lsl	x15, x16, #2
	tst	x10, #0xf
	lsl	x18, x16, #1
	lsl	x1, x0, #1
	stur	x16, [x29, #-56]                // 8-byte Folded Spill
	sub	w24, w14, #10
	str	x15, [sp, #8]                   // 8-byte Folded Spill
	sub	w15, w9, w16
	add	x16, x18, x16
	str	x18, [sp, #64]                  // 8-byte Folded Spill
	mov	w18, #32
	movi	v4.8b, #77
	str	w15, [sp, #80]                  // 4-byte Folded Spill
	sub	w15, w9, w0
	str	x16, [sp, #40]                  // 8-byte Folded Spill
	add	x16, x1, x0
	movi	v1.2d, #0xffffffffffffffff
	movi	v5.8b, #150
	stur	w15, [x29, #-36]                // 4-byte Folded Spill
	lsl	x15, x0, #2
	stp	x16, x1, [x29, #-104]           // 16-byte Folded Spill
	and	x16, x10, #0x1ffffffe0
	lsl	x1, x16, #1
	movi	v6.8b, #29
	stur	x15, [x29, #-88]                // 8-byte Folded Spill
	and	x15, x10, #0xf
	csel	x2, x17, x15, eq
	and	x15, x10, #0x7
	tst	x10, #0x7
	mov	w17, #8
	csel	x15, x17, x15, eq
	tst	x10, #0x1f
	str	x2, [sp, #128]                  // 8-byte Folded Spill
	sub	x2, x10, x2
	lsl	x17, x2, #2
	sub	x3, x10, x15
	str	x1, [sp, #24]                   // 8-byte Folded Spill
	add	x1, x1, x16
	stur	x16, [x29, #-32]                // 8-byte Folded Spill
	mov	w13, wzr
	str	x17, [sp, #56]                  // 8-byte Folded Spill
	sub	w17, w9, w2
	movi	v3.2d, #0xffffffffffffffff
	mov	w12, wzr
	mov	x8, xzr
	str	x1, [sp, #16]                   // 8-byte Folded Spill
	str	w17, [sp, #52]                  // 4-byte Folded Spill
	sub	w17, w9, w3
	stur	x3, [x29, #-112]                // 8-byte Folded Spill
	add	x28, x23, #64
	stur	x0, [x29, #-24]                 // 8-byte Folded Spill
	add	x1, x19, #32
	stur	w17, [x29, #-68]                // 4-byte Folded Spill
	lsl	x17, x3, #2
	mov	w26, #77
	mov	w30, #150
	str	x2, [sp, #152]                  // 8-byte Folded Spill
	stur	x17, [x29, #-136]               // 8-byte Folded Spill
	and	x17, x10, #0x1f
	csel	x18, x18, x17, eq
	mvn	x17, x9
	add	x15, x17, x15
	sub	x14, x10, x18
	add	x17, x23, #32
	stur	x10, [x29, #-16]                // 8-byte Folded Spill
	stur	x18, [x29, #-120]               // 8-byte Folded Spill
	stur	x15, [x29, #-80]                // 8-byte Folded Spill
	lsl	x15, x16, #2
	stur	x14, [x29, #-64]                // 8-byte Folded Spill
	str	x15, [sp, #72]                  // 8-byte Folded Spill
	sub	w15, w9, w16
	and	x16, x10, #0x18
	str	w15, [sp, #84]                  // 4-byte Folded Spill
	lsl	x15, x14, #1
	str	x16, [sp, #144]                 // 8-byte Folded Spill
	add	x16, x19, #64
	str	x15, [sp, #120]                 // 8-byte Folded Spill
	add	x15, x15, x14
	stp	x16, x17, [sp, #88]             // 16-byte Folded Spill
	str	x15, [sp, #112]                 // 8-byte Folded Spill
	sub	w15, w9, w14
	lsl	x14, x14, #2
	str	w15, [sp, #140]                 // 4-byte Folded Spill
	lsl	x15, x3, #1
	str	x14, [sp, #32]                  // 8-byte Folded Spill
	mul	w14, w20, w22
	stur	x15, [x29, #-128]               // 8-byte Folded Spill
	add	x15, x15, x3
	mov	w3, #29
	stur	x15, [x29, #-144]               // 8-byte Folded Spill
	neg	x15, x0
	mov	w0, #255
	stur	x15, [x29, #-48]                // 8-byte Folded Spill
	add	x15, x23, #16
	str	x15, [sp, #104]                 // 8-byte Folded Spill
	add	x15, x19, #16
	b	.LBB131_8
.LBB131_7:                              //   in Loop: Header=BB131_8 Depth=1
	add	x8, x8, #1
	add	w12, w2, w14
	add	w13, w13, w25
	cmp	x8, x11
	b.eq	.LBB131_174
.LBB131_8:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB131_66 Depth 2
                                        //     Child Loop BB131_71 Depth 2
                                        //     Child Loop BB131_74 Depth 2
                                        //     Child Loop BB131_142 Depth 2
                                        //     Child Loop BB131_146 Depth 2
                                        //     Child Loop BB131_149 Depth 2
                                        //     Child Loop BB131_135 Depth 2
                                        //     Child Loop BB131_139 Depth 2
                                        //     Child Loop BB131_173 Depth 2
                                        //     Child Loop BB131_125 Depth 2
                                        //     Child Loop BB131_130 Depth 2
                                        //     Child Loop BB131_133 Depth 2
                                        //     Child Loop BB131_115 Depth 2
                                        //     Child Loop BB131_120 Depth 2
                                        //     Child Loop BB131_123 Depth 2
                                        //     Child Loop BB131_108 Depth 2
                                        //     Child Loop BB131_112 Depth 2
                                        //     Child Loop BB131_170 Depth 2
                                        //     Child Loop BB131_99 Depth 2
                                        //     Child Loop BB131_103 Depth 2
                                        //     Child Loop BB131_106 Depth 2
                                        //     Child Loop BB131_90 Depth 2
                                        //     Child Loop BB131_94 Depth 2
                                        //     Child Loop BB131_97 Depth 2
                                        //     Child Loop BB131_83 Depth 2
                                        //     Child Loop BB131_87 Depth 2
                                        //     Child Loop BB131_167 Depth 2
                                        //     Child Loop BB131_76 Depth 2
                                        //     Child Loop BB131_80 Depth 2
                                        //     Child Loop BB131_164 Depth 2
                                        //     Child Loop BB131_59 Depth 2
                                        //     Child Loop BB131_63 Depth 2
                                        //     Child Loop BB131_161 Depth 2
                                        //     Child Loop BB131_151 Depth 2
                                        //     Child Loop BB131_155 Depth 2
                                        //     Child Loop BB131_158 Depth 2
	mul	w17, w8, w20
	mov	w13, w13
	mov	w2, w12
	add	x7, x23, x13
	cmp	w24, #24
	mul	w18, w17, w22
	mul	w17, w17, w21
	add	x18, x19, x18
	add	x17, x23, x17
	b.hi	.LBB131_54
// %bb.9:                               //   in Loop: Header=BB131_8 Depth=1
	adrp	x10, .LJTI131_0
	add	x27, x15, x2
	add	x10, x10, :lo12:.LJTI131_0
	add	x5, x28, x13
	add	x12, x1, x2
	add	x4, x19, x2
	adr	x16, .LBB131_10
	ldrb	w6, [x10, x24]
	add	x16, x16, x6, lsl #2
	br	x16
.LBB131_10:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.11:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_160
// %bb.12:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #31
	b.hs	.LBB131_58
// %bb.13:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_62
.LBB131_14:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.15:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_73
// %bb.16:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #15
	b.hs	.LBB131_65
// %bb.17:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_70
.LBB131_18:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.19:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_163
// %bb.20:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #31
	b.hs	.LBB131_75
// %bb.21:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_79
.LBB131_22:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.23:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_166
// %bb.24:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #31
	b.hs	.LBB131_82
// %bb.25:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_86
.LBB131_26:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.27:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w4, w9
	cmp	w9, #8
	b.lo	.LBB131_96
// %bb.28:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #32
	b.hs	.LBB131_89
// %bb.29:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_93
.LBB131_30:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.31:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w4, w9
	cmp	w9, #8
	b.lo	.LBB131_105
// %bb.32:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #32
	b.hs	.LBB131_98
// %bb.33:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_102
.LBB131_34:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.35:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w4, w9
	cmp	w9, #7
	b.lo	.LBB131_169
// %bb.36:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #31
	b.hs	.LBB131_107
// %bb.37:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_111
.LBB131_38:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.39:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_122
// %bb.40:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #15
	b.hs	.LBB131_114
// %bb.41:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_119
.LBB131_42:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.43:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_132
// %bb.44:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #15
	b.hs	.LBB131_124
// %bb.45:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_129
.LBB131_46:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.47:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #7
	b.lo	.LBB131_172
// %bb.48:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #31
	b.hs	.LBB131_134
// %bb.49:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_138
.LBB131_50:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.51:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #8
	b.lo	.LBB131_148
// %bb.52:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #16
	b.hs	.LBB131_141
// %bb.53:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_145
.LBB131_54:                             //   in Loop: Header=BB131_8 Depth=1
	tbnz	w9, #31, .LBB131_7
// %bb.55:                              //   in Loop: Header=BB131_8 Depth=1
	mov	w12, w9
	cmp	w9, #8
	b.lo	.LBB131_157
// %bb.56:                              //   in Loop: Header=BB131_8 Depth=1
	cmp	w9, #32
	b.hs	.LBB131_150
// %bb.57:                              //   in Loop: Header=BB131_8 Depth=1
	mov	x5, xzr
	b	.LBB131_154
.LBB131_58:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #96]                  // 8-byte Folded Reload
	ldur	x4, [x29, #-32]                 // 8-byte Folded Reload
	add	x12, x12, x13
.LBB131_59:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q18, q16, [x27, #-16]
	mov	v17.16b, v1.16b
	sub	x16, x12, #32
	mov	v19.16b, v1.16b
	add	x27, x27, #32
	subs	x4, x4, #32
	st2	{ v16.16b, v17.16b }, [x12]
	add	x12, x12, #64
	st2	{ v18.16b, v19.16b }, [x16]
	b.ne	.LBB131_59
// %bb.60:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.61:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	cbz	x12, .LBB131_159
.LBB131_62:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-96]                // 8-byte Folded Reload
	add	x16, x13, x5, lsl #1
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-24]                // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x5, x2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_63:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d2, [x12], #8
	adds	x5, x5, #8
	st2	{ v2.8b, v3.8b }, [x4], #16
	b.ne	.LBB131_63
// %bb.64:                              //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
	b	.LBB131_160
.LBB131_65:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
.LBB131_66:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld4	{ v16.16b, v17.16b, v18.16b, v19.16b }, [x4], #64
	ext	v7.16b, v17.16b, v17.16b, #8
	subs	x12, x12, #16
	umull	v20.8h, v17.8b, v5.8b
	ext	v21.16b, v16.16b, v16.16b, #8
	ext	v22.16b, v18.16b, v18.16b, #8
	umull	v7.8h, v7.8b, v5.8b
	umlal	v20.8h, v16.8b, v4.8b
	umull	v23.8h, v18.8b, v6.8b
	umull	v22.8h, v22.8b, v6.8b
	umlal	v7.8h, v21.8b, v4.8b
	addhn	v18.8b, v20.8h, v23.8h
	addhn2	v18.16b, v7.8h, v22.8h
	st2	{ v18.16b, v19.16b }, [x7], #32
	b.ne	.LBB131_66
// %bb.67:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.68:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-56]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w10, #3, .LBB131_70
// %bb.69:                              //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #8]                   // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #64]                  // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #80]                  // 4-byte Folded Reload
	b	.LBB131_73
.LBB131_70:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-96]                // 8-byte Folded Reload
	add	x16, x13, x5, lsl #1
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-88]                // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x2, x5, lsl #2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_71:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld4	{ v16.8b, v17.8b, v18.8b, v19.8b }, [x12], #32
	umull	v7.8h, v17.8b, v5.8b
	adds	x5, x5, #8
	umull	v20.8h, v18.8b, v6.8b
	umlal	v7.8h, v16.8b, v4.8b
	addhn	v18.8b, v7.8h, v20.8h
	st2	{ v18.8b, v19.8b }, [x4], #16
	b.ne	.LBB131_71
// %bb.72:                              //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
.LBB131_73:                             //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_74:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	sub	w12, w12, #1
	ldrb	w4, [x18, #1]
	cmp	w12, #0
	ldrb	w5, [x18, #2]
	mul	w16, w16, w26
	madd	w16, w4, w30, w16
	ldrb	w4, [x18, #3]
	add	x18, x18, #4
	madd	w16, w5, w3, w16
	strb	w4, [x17, #1]
	lsr	w16, w16, #8
	strb	w16, [x17], #2
	b.gt	.LBB131_74
	b	.LBB131_7
.LBB131_75:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
.LBB131_76:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q16, q19, [x27, #-16]
	add	x16, x7, #96
	add	x27, x27, #32
	subs	x12, x12, #32
	mov	v17.16b, v16.16b
	mov	v18.16b, v16.16b
	mov	v20.16b, v19.16b
	mov	v21.16b, v19.16b
	st3	{ v16.16b, v17.16b, v18.16b }, [x7], #48
	st3	{ v19.16b, v20.16b, v21.16b }, [x7]
	mov	x7, x16
	b.ne	.LBB131_76
// %bb.77:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.78:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	cbz	x12, .LBB131_162
.LBB131_79:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-104]               // 8-byte Folded Reload
	add	x16, x5, x5, lsl #1
	add	x16, x16, x13
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-24]                // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x5, x2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_80:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d16, [x12], #8
	adds	x5, x5, #8
	fmov	d17, d16
	fmov	d18, d16
	st3	{ v16.8b, v17.8b, v18.8b }, [x4], #24
	b.ne	.LBB131_80
// %bb.81:                              //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
	b	.LBB131_163
.LBB131_82:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
.LBB131_83:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q20, q16, [x27, #-16]
	sub	x16, x5, #64
	add	x27, x27, #32
	subs	x12, x12, #32
	mov	v21.16b, v20.16b
	mov	v22.16b, v20.16b
	mov	v17.16b, v16.16b
	mov	v18.16b, v16.16b
	mov	v19.16b, v1.16b
	mov	v23.16b, v1.16b
	st4	{ v16.16b, v17.16b, v18.16b, v19.16b }, [x5]
	add	x5, x5, #128
	st4	{ v20.16b, v21.16b, v22.16b, v23.16b }, [x16]
	b.ne	.LBB131_83
// %bb.84:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.85:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	cbz	x12, .LBB131_165
.LBB131_86:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-88]                // 8-byte Folded Reload
	add	x16, x13, x5, lsl #2
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-24]                // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x5, x2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_87:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d16, [x12], #8
	adds	x5, x5, #8
	fmov	d17, d16
	fmov	d18, d16
	fmov	d19, d1
	st4	{ v16.8b, v17.8b, v18.8b, v19.8b }, [x4], #32
	b.ne	.LBB131_87
// %bb.88:                              //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
	b	.LBB131_166
.LBB131_89:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x16, [sp, #104]                 // 8-byte Folded Reload
	ldur	x5, [x29, #-64]                 // 8-byte Folded Reload
	add	x4, x16, x13
.LBB131_90:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	sub	x16, x12, #32
	ld2	{ v16.16b, v17.16b }, [x12]
	add	x12, x12, #64
	subs	x5, x5, #32
	ld2	{ v18.16b, v19.16b }, [x16]
	stp	q18, q16, [x4, #-16]
	add	x4, x4, #32
	b.ne	.LBB131_90
// %bb.91:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-120]               // 8-byte Folded Reload
	ldur	x5, [x29, #-64]                 // 8-byte Folded Reload
	cmp	x12, #8
	b.hi	.LBB131_93
// %bb.92:                              //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #120]                 // 8-byte Folded Reload
	ldr	w4, [sp, #140]                  // 4-byte Folded Reload
	add	x18, x18, x12
	ldur	x12, [x29, #-64]                // 8-byte Folded Reload
	add	x17, x17, x12
	b	.LBB131_96
.LBB131_93:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-112]               // 8-byte Folded Reload
	add	x16, x5, x13
	add	x4, x23, x16
	ldur	x16, [x29, #-80]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-128]               // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x2, x5, lsl #1
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_94:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v16.8b, v17.8b }, [x12], #16
	adds	x5, x5, #8
	str	d16, [x4], #8
	b.ne	.LBB131_94
// %bb.95:                              //   in Loop: Header=BB131_8 Depth=1
	ldur	w4, [x29, #-68]                 // 4-byte Folded Reload
.LBB131_96:                             //   in Loop: Header=BB131_8 Depth=1
	add	w12, w4, #1
.LBB131_97:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18], #2
	sub	w12, w12, #1
	cmp	w12, #0
	strb	w16, [x17], #1
	b.gt	.LBB131_97
	b	.LBB131_7
.LBB131_98:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x4, [x29, #-64]                 // 8-byte Folded Reload
.LBB131_99:                             //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	sub	x16, x12, #32
	ld2	{ v19.16b, v20.16b }, [x12]
	add	x12, x12, #64
	subs	x4, x4, #32
	ld2	{ v16.16b, v17.16b }, [x16]
	add	x16, x7, #96
	mov	v20.16b, v19.16b
	mov	v21.16b, v19.16b
	mov	v17.16b, v16.16b
	mov	v18.16b, v16.16b
	st3	{ v16.16b, v17.16b, v18.16b }, [x7], #48
	st3	{ v19.16b, v20.16b, v21.16b }, [x7]
	mov	x7, x16
	b.ne	.LBB131_99
// %bb.100:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-120]               // 8-byte Folded Reload
	ldur	x5, [x29, #-64]                 // 8-byte Folded Reload
	cmp	x12, #8
	b.hi	.LBB131_102
// %bb.101:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #120]                 // 8-byte Folded Reload
	ldr	w4, [sp, #140]                  // 4-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #112]                 // 8-byte Folded Reload
	add	x17, x17, x12
	b	.LBB131_105
.LBB131_102:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-144]               // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-128]               // 8-byte Folded Reload
	add	x18, x18, x12
	lsl	x12, x5, #1
	add	x16, x12, x2
	add	x4, x12, x5
	add	x12, x19, x16
	add	x16, x4, x13
	add	x4, x23, x16
	ldur	x16, [x29, #-80]                // 8-byte Folded Reload
	add	x5, x16, x5
.LBB131_103:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v16.8b, v17.8b }, [x12], #16
	fmov	d17, d16
	adds	x5, x5, #8
	fmov	d18, d16
	st3	{ v16.8b, v17.8b, v18.8b }, [x4], #24
	b.ne	.LBB131_103
// %bb.104:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	w4, [x29, #-68]                 // 4-byte Folded Reload
.LBB131_105:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w4, #1
	add	x17, x17, #2
.LBB131_106:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18], #2
	sub	w12, w12, #1
	cmp	w12, #0
	strb	w16, [x17]
	sturb	w16, [x17, #-1]
	sturb	w16, [x17, #-2]
	add	x17, x17, #3
	b.gt	.LBB131_106
	b	.LBB131_7
.LBB131_107:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x4, [x29, #-32]                 // 8-byte Folded Reload
.LBB131_108:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v18.16b, v19.16b }, [x12]
	sub	x16, x12, #32
	add	x12, x12, #64
	subs	x4, x4, #32
	ld2	{ v22.16b, v23.16b }, [x16]
	sub	x16, x5, #64
	mov	v16.16b, v18.16b
	mov	v17.16b, v18.16b
	mov	v20.16b, v22.16b
	mov	v21.16b, v22.16b
	st4	{ v16.16b, v17.16b, v18.16b, v19.16b }, [x5]
	add	x5, x5, #128
	st4	{ v20.16b, v21.16b, v22.16b, v23.16b }, [x16]
	b.ne	.LBB131_108
// %bb.109:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.110:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	cbz	x12, .LBB131_168
.LBB131_111:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-88]                // 8-byte Folded Reload
	add	x16, x13, x5, lsl #2
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-96]                // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x2, x5, lsl #1
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_112:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld2	{ v18.8b, v19.8b }, [x12], #16
	fmov	d16, d18
	adds	x5, x5, #8
	fmov	d17, d18
	st4	{ v16.8b, v17.8b, v18.8b, v19.8b }, [x4], #32
	b.ne	.LBB131_112
// %bb.113:                             //   in Loop: Header=BB131_8 Depth=1
	ldp	x12, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w4, [x29, #-36]                 // 4-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
	b	.LBB131_169
.LBB131_114:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
.LBB131_115:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld3	{ v16.16b, v17.16b, v18.16b }, [x4], #48
	ext	v7.16b, v17.16b, v17.16b, #8
	subs	x12, x12, #16
	umull	v19.8h, v17.8b, v5.8b
	ext	v20.16b, v16.16b, v16.16b, #8
	ext	v21.16b, v18.16b, v18.16b, #8
	umull	v7.8h, v7.8b, v5.8b
	umlal	v19.8h, v16.8b, v4.8b
	umull	v16.8h, v18.8b, v6.8b
	umull	v17.8h, v21.8b, v6.8b
	umlal	v7.8h, v20.8b, v4.8b
	addhn	v16.8b, v19.8h, v16.8h
	addhn2	v16.16b, v7.8h, v17.8h
	str	q16, [x7], #16
	b.ne	.LBB131_115
// %bb.116:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.117:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-56]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w10, #3, .LBB131_119
// %bb.118:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #40]                  // 8-byte Folded Reload
	add	x18, x18, x12
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #80]                  // 4-byte Folded Reload
	b	.LBB131_122
.LBB131_119:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x16, [x29, #-104]               // 8-byte Folded Reload
	ldur	x12, [x29, #-24]                // 8-byte Folded Reload
	add	x18, x18, x16
	add	x16, x5, x13
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	add	x12, x5, x5, lsl #1
	add	x12, x12, x2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_120:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld3	{ v16.8b, v17.8b, v18.8b }, [x12], #24
	umull	v7.8h, v17.8b, v5.8b
	adds	x5, x5, #8
	umlal	v7.8h, v16.8b, v4.8b
	umull	v16.8h, v18.8b, v6.8b
	addhn	v7.8b, v7.8h, v16.8h
	str	d7, [x4], #8
	b.ne	.LBB131_120
// %bb.121:                             //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
.LBB131_122:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_123:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	sub	w12, w12, #1
	ldrb	w4, [x18, #1]
	cmp	w12, #0
	ldrb	w5, [x18, #2]
	add	x18, x18, #3
	mul	w16, w16, w26
	madd	w16, w4, w30, w16
	madd	w16, w5, w3, w16
	lsr	w16, w16, #8
	strb	w16, [x17], #1
	b.gt	.LBB131_123
	b	.LBB131_7
.LBB131_124:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
.LBB131_125:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld3	{ v16.16b, v17.16b, v18.16b }, [x4], #48
	ext	v7.16b, v17.16b, v17.16b, #8
	subs	x12, x12, #16
	umull	v19.8h, v17.8b, v5.8b
	ext	v20.16b, v16.16b, v16.16b, #8
	ext	v21.16b, v18.16b, v18.16b, #8
	umull	v7.8h, v7.8b, v5.8b
	umlal	v19.8h, v16.8b, v4.8b
	umull	v16.8h, v18.8b, v6.8b
	umull	v17.8h, v21.8b, v6.8b
	umlal	v7.8h, v20.8b, v4.8b
	addhn	v0.8b, v19.8h, v16.8h
	addhn2	v0.16b, v7.8h, v17.8h
	st2	{ v0.16b, v1.16b }, [x7], #32
	b.ne	.LBB131_125
// %bb.126:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-56]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.127:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-56]                 // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w10, #3, .LBB131_129
// %bb.128:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #40]                  // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #64]                  // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #80]                  // 4-byte Folded Reload
	b	.LBB131_132
.LBB131_129:                            //   in Loop: Header=BB131_8 Depth=1
	ldp	x4, x16, [x29, #-104]           // 16-byte Folded Reload
	lsl	x12, x5, #1
	add	x18, x18, x4
	add	x4, x12, x13
	add	x17, x17, x16
	add	x16, x12, x5
	add	x16, x16, x2
	add	x4, x23, x4
	add	x12, x19, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x5, x16, x5
.LBB131_130:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld3	{ v16.8b, v17.8b, v18.8b }, [x12], #24
	umull	v7.8h, v17.8b, v5.8b
	adds	x5, x5, #8
	umlal	v7.8h, v16.8b, v4.8b
	umull	v16.8h, v18.8b, v6.8b
	addhn	v16.8b, v7.8h, v16.8h
	fmov	d17, d1
	st2	{ v16.8b, v17.8b }, [x4], #16
	b.ne	.LBB131_130
// %bb.131:                             //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
.LBB131_132:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_133:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	sub	w12, w12, #1
	ldrb	w4, [x18, #1]
	cmp	w12, #0
	ldrb	w5, [x18, #2]
	add	x18, x18, #3
	mul	w16, w16, w26
	strb	w0, [x17, #1]
	madd	w16, w4, w30, w16
	madd	w16, w5, w3, w16
	lsr	w16, w16, #8
	strb	w16, [x17], #2
	b.gt	.LBB131_133
	b	.LBB131_7
.LBB131_134:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
.LBB131_135:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	mov	x16, x4
	add	x4, x4, #96
	subs	x12, x12, #32
	ld3	{ v16.16b, v17.16b, v18.16b }, [x16], #48
	mov	v19.16b, v1.16b
	ld3	{ v20.16b, v21.16b, v22.16b }, [x16]
	sub	x16, x5, #64
	mov	v23.16b, v1.16b
	st4	{ v16.16b, v17.16b, v18.16b, v19.16b }, [x16]
	st4	{ v20.16b, v21.16b, v22.16b, v23.16b }, [x5]
	add	x5, x5, #128
	b.ne	.LBB131_135
// %bb.136:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	ldur	x10, [x29, #-16]                // 8-byte Folded Reload
	cmp	x10, x12
	b.eq	.LBB131_7
// %bb.137:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x5, [x29, #-32]                 // 8-byte Folded Reload
	ldr	x12, [sp, #144]                 // 8-byte Folded Reload
	cbz	x12, .LBB131_171
.LBB131_138:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x16, [x29, #-104]               // 8-byte Folded Reload
	ldur	x12, [x29, #-88]                // 8-byte Folded Reload
	add	x18, x18, x16
	add	x16, x13, x5, lsl #2
	add	x4, x23, x16
	ldur	x16, [x29, #-48]                // 8-byte Folded Reload
	add	x17, x17, x12
	add	x12, x5, x5, lsl #1
	add	x12, x12, x2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_139:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld3	{ v16.8b, v17.8b, v18.8b }, [x12], #24
	fmov	d19, d1
	adds	x5, x5, #8
	st4	{ v16.8b, v17.8b, v18.8b, v19.8b }, [x4], #32
	b.ne	.LBB131_139
// %bb.140:                             //   in Loop: Header=BB131_8 Depth=1
	ldp	x16, x10, [x29, #-24]           // 16-byte Folded Reload
	ldur	w12, [x29, #-36]                // 4-byte Folded Reload
	cmp	x10, x16
	b.eq	.LBB131_7
	b	.LBB131_172
.LBB131_141:                            //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #152]                 // 8-byte Folded Reload
.LBB131_142:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld4	{ v16.16b, v17.16b, v18.16b, v19.16b }, [x4], #64
	ext	v7.16b, v17.16b, v17.16b, #8
	subs	x12, x12, #16
	umull	v20.8h, v17.8b, v5.8b
	ext	v21.16b, v16.16b, v16.16b, #8
	ext	v22.16b, v18.16b, v18.16b, #8
	umull	v7.8h, v7.8b, v5.8b
	umlal	v20.8h, v16.8b, v4.8b
	umull	v16.8h, v18.8b, v6.8b
	umull	v17.8h, v22.8b, v6.8b
	umlal	v7.8h, v21.8b, v4.8b
	addhn	v16.8b, v20.8h, v16.8h
	addhn2	v16.16b, v7.8h, v17.8h
	str	q16, [x7], #16
	b.ne	.LBB131_142
// %bb.143:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #128]                 // 8-byte Folded Reload
	ldr	x5, [sp, #152]                  // 8-byte Folded Reload
	cmp	x12, #8
	b.hi	.LBB131_145
// %bb.144:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #56]                  // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #152]                 // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #52]                  // 4-byte Folded Reload
	b	.LBB131_148
.LBB131_145:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-112]               // 8-byte Folded Reload
	add	x16, x5, x13
	add	x4, x23, x16
	ldur	x16, [x29, #-80]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-136]               // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x2, x5, lsl #2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_146:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld4	{ v16.8b, v17.8b, v18.8b, v19.8b }, [x12], #32
	umull	v7.8h, v17.8b, v5.8b
	adds	x5, x5, #8
	umlal	v7.8h, v16.8b, v4.8b
	umull	v16.8h, v18.8b, v6.8b
	addhn	v7.8b, v7.8h, v16.8h
	str	d7, [x4], #8
	b.ne	.LBB131_146
// %bb.147:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	w12, [x29, #-68]                // 4-byte Folded Reload
.LBB131_148:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_149:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	sub	w12, w12, #1
	ldrb	w4, [x18, #1]
	cmp	w12, #0
	ldrb	w5, [x18, #2]
	add	x18, x18, #4
	mul	w16, w16, w26
	madd	w16, w4, w30, w16
	madd	w16, w5, w3, w16
	lsr	w16, w16, #8
	strb	w16, [x17], #1
	b.gt	.LBB131_149
	b	.LBB131_7
.LBB131_150:                            //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #88]                  // 8-byte Folded Reload
	ldur	x4, [x29, #-64]                 // 8-byte Folded Reload
	add	x12, x12, x2
.LBB131_151:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	sub	x16, x12, #64
	ld4	{ v20.16b, v21.16b, v22.16b, v23.16b }, [x12]
	add	x12, x12, #128
	subs	x4, x4, #32
	ld4	{ v16.16b, v17.16b, v18.16b, v19.16b }, [x16]
	add	x16, x7, #96
	st3	{ v16.16b, v17.16b, v18.16b }, [x7], #48
	st3	{ v20.16b, v21.16b, v22.16b }, [x7]
	mov	x7, x16
	b.ne	.LBB131_151
// %bb.152:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-120]               // 8-byte Folded Reload
	ldur	x5, [x29, #-64]                 // 8-byte Folded Reload
	cmp	x12, #8
	b.hi	.LBB131_154
// %bb.153:                             //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #32]                  // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #112]                 // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #140]                 // 4-byte Folded Reload
	b	.LBB131_157
.LBB131_154:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-144]               // 8-byte Folded Reload
	add	x16, x5, x5, lsl #1
	add	x16, x16, x13
	add	x4, x23, x16
	ldur	x16, [x29, #-80]                // 8-byte Folded Reload
	add	x17, x17, x12
	ldur	x12, [x29, #-136]               // 8-byte Folded Reload
	add	x18, x18, x12
	add	x12, x2, x5, lsl #2
	add	x12, x19, x12
	add	x5, x16, x5
.LBB131_155:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ld4	{ v16.8b, v17.8b, v18.8b, v19.8b }, [x12], #32
	st3	{ v16.8b, v17.8b, v18.8b }, [x4], #24
	adds	x5, x5, #8
	b.ne	.LBB131_155
// %bb.156:                             //   in Loop: Header=BB131_8 Depth=1
	ldur	w12, [x29, #-68]                // 4-byte Folded Reload
.LBB131_157:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_158:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	sub	w12, w12, #1
	ldurh	w4, [x18, #1]
	add	x18, x18, #4
	cmp	w12, #0
	strb	w16, [x17]
	sturh	w4, [x17, #1]
	add	x17, x17, #3
	b.gt	.LBB131_158
	b	.LBB131_7
.LBB131_159:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #24]                  // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #84]                  // 4-byte Folded Reload
.LBB131_160:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_161:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18], #1
	sub	w12, w12, #1
	strb	w0, [x17, #1]
	cmp	w12, #0
	strb	w16, [x17], #2
	b.gt	.LBB131_161
	b	.LBB131_7
.LBB131_162:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #16]                  // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #84]                  // 4-byte Folded Reload
.LBB131_163:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
	add	x17, x17, #2
.LBB131_164:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18], #1
	sub	w12, w12, #1
	cmp	w12, #0
	strb	w16, [x17]
	sturb	w16, [x17, #-1]
	sturb	w16, [x17, #-2]
	add	x17, x17, #3
	b.gt	.LBB131_164
	b	.LBB131_7
.LBB131_165:                            //   in Loop: Header=BB131_8 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #72]                  // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #84]                  // 4-byte Folded Reload
.LBB131_166:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
	add	x17, x17, #3
.LBB131_167:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18], #1
	strb	w0, [x17]
	sub	w12, w12, #1
	cmp	w12, #0
	sturb	w16, [x17, #-1]
	sturb	w16, [x17, #-2]
	sturb	w16, [x17, #-3]
	add	x17, x17, #4
	b.gt	.LBB131_167
	b	.LBB131_7
.LBB131_168:                            //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #24]                  // 8-byte Folded Reload
	ldr	w4, [sp, #84]                   // 4-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #72]                  // 8-byte Folded Reload
	add	x17, x17, x12
.LBB131_169:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w4, #1
	add	x17, x17, #3
.LBB131_170:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	sub	w12, w12, #1
	ldrb	w4, [x18, #1]
	add	x18, x18, #2
	cmp	w12, #0
	sturb	w16, [x17, #-1]
	sturb	w16, [x17, #-2]
	sturb	w16, [x17, #-3]
	strb	w4, [x17], #4
	b.gt	.LBB131_170
	b	.LBB131_7
.LBB131_171:                            //   in Loop: Header=BB131_8 Depth=1
	ldr	x12, [sp, #16]                  // 8-byte Folded Reload
	add	x18, x18, x12
	ldr	x12, [sp, #72]                  // 8-byte Folded Reload
	add	x17, x17, x12
	ldr	w12, [sp, #84]                  // 4-byte Folded Reload
.LBB131_172:                            //   in Loop: Header=BB131_8 Depth=1
	add	w12, w12, #1
.LBB131_173:                            //   Parent Loop BB131_8 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w16, [x18]
	strb	w0, [x17, #3]
	ldurh	w4, [x18, #1]
	sub	w12, w12, #1
	add	x18, x18, #3
	cmp	w12, #0
	strb	w16, [x17]
	sturh	w4, [x17, #1]
	add	x17, x17, #4
	b.gt	.LBB131_173
	b	.LBB131_7
.LBB131_174:
	mov	x0, x19
	bl	free
	mov	x19, x23
	b	.LBB131_176
.LBB131_175:
	mov	x0, x19
	bl	free
	adrp	x9, .L.str.28
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.28
	mov	x19, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB131_176:
	mov	x0, x19
	ldp	x20, x19, [sp, #384]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #368]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #352]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #336]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #320]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #304]            // 16-byte Folded Reload
	add	sp, sp, #400
	ret
.LBB131_177:
	adrp	x0, .L.str.67
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj
	add	x0, x0, :lo12:.L.str.67
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj
	mov	w2, #1325
	bl	__assert_fail
.LBB131_178:
	adrp	x0, .L.str.68
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj
	add	x0, x0, :lo12:.L.str.68
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj
	mov	w2, #1354
	bl	__assert_fail
.Lfunc_end131:
	.size	_ZL20stbi__convert_formatPhiijj, .Lfunc_end131-_ZL20stbi__convert_formatPhiijj
	.cfi_endproc
	.section	.rodata,"a",@progbits
.LJTI131_0:
	.byte	(.LBB131_10-.LBB131_10)>>2
	.byte	(.LBB131_18-.LBB131_10)>>2
	.byte	(.LBB131_22-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_26-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_30-.LBB131_10)>>2
	.byte	(.LBB131_34-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_38-.LBB131_10)>>2
	.byte	(.LBB131_42-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_46-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_54-.LBB131_10)>>2
	.byte	(.LBB131_50-.LBB131_10)>>2
	.byte	(.LBB131_14-.LBB131_10)>>2
                                        // -- End function
	.text
	.p2align	2                               // -- Begin function _ZL13stbi__get32beP13stbi__context
	.type	_ZL13stbi__get32beP13stbi__context,@function
_ZL13stbi__get32beP13stbi__context:     // @_ZL13stbi__get32beP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x9, x8, [x0, #184]
	mov	x19, x0
	cmp	x9, x8
	b.hs	.LBB132_2
// %bb.1:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB132_6
	b	.LBB132_12
.LBB132_2:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB132_5
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB132_10
// %bb.4:
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB132_11
.LBB132_5:
	mov	w20, wzr
	cmp	x9, x8
	b.lo	.LBB132_12
.LBB132_6:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB132_9
// %bb.7:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB132_14
// %bb.8:
	mov	x8, x19
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB132_15
.LBB132_9:
	mov	w21, wzr
	cmp	x9, x8
	b.lo	.LBB132_13
	b	.LBB132_16
.LBB132_10:
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB132_11:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB132_6
.LBB132_12:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB132_16
.LBB132_13:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w22, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB132_20
	b	.LBB132_25
.LBB132_14:
	mov	w21, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB132_15:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB132_13
.LBB132_16:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB132_19
// %bb.17:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB132_23
// %bb.18:
	mov	x8, x19
	ldrb	w22, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB132_24
.LBB132_19:
	mov	w22, wzr
	cmp	x9, x8
	b.lo	.LBB132_25
.LBB132_20:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB132_28
// %bb.21:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB132_26
// %bb.22:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB132_27
.LBB132_23:
	mov	w22, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB132_24:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB132_20
.LBB132_25:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB132_28
.LBB132_26:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB132_27:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB132_28:
	lsl	w9, w20, #24
	bfi	w8, w22, #8, #8
	bfi	w9, w21, #16, #8
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	orr	w0, w8, w9
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end132:
	.size	_ZL13stbi__get32beP13stbi__context, .Lfunc_end132-_ZL13stbi__get32beP13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL15stbi__de_iphoneP9stbi__png
	.type	_ZL15stbi__de_iphoneP9stbi__png,@function
_ZL15stbi__de_iphoneP9stbi__png:        // @_ZL15stbi__de_iphoneP9stbi__png
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-16]!           // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mul	w8, w1, w0
	cmp	w2, #4
	b.eq	.LBB133_7
// %bb.1:
	cmp	w2, #3
	b.ne	.LBB133_25
// %bb.2:
	cbz	w8, .LBB133_24
// %bb.3:
	subs	w9, w8, #1
	b.eq	.LBB133_18
// %bb.4:
	add	x11, x9, #1
	add	x12, x3, #2
	and	x10, x11, #0x1fffffffe
	mov	x13, x10
	add	x9, x10, x10, lsl #1
	add	x9, x3, x9
.LBB133_5:                              // =>This Inner Loop Header: Depth=1
	ldrb	w14, [x12]
	subs	x13, x13, #2
	ldrb	w15, [x12, #3]
	ldurb	w16, [x12, #-2]
	ldrb	w17, [x12, #1]
	sturb	w14, [x12, #-2]
	strb	w15, [x12, #1]
	strb	w16, [x12]
	strb	w17, [x12, #3]
	add	x12, x12, #6
	b.ne	.LBB133_5
// %bb.6:
	cmp	x11, x10
	b.ne	.LBB133_19
	b	.LBB133_24
.LBB133_7:
	adrp	x9, _ZL27stbi__unpremultiply_on_load
	ldr	w9, [x9, :lo12:_ZL27stbi__unpremultiply_on_load]
	cbz	w9, .LBB133_13
// %bb.8:
	cbz	w8, .LBB133_24
// %bb.9:
	add	x9, x3, #1
	b	.LBB133_11
.LBB133_10:                             //   in Loop: Header=BB133_11 Depth=1
	sturb	w12, [x9, #-1]
	strb	w10, [x9, #1]
	subs	w8, w8, #1
	add	x9, x9, #4
	b.eq	.LBB133_24
.LBB133_11:                             // =>This Inner Loop Header: Depth=1
	ldrb	w11, [x9, #2]
	ldurb	w10, [x9, #-1]
	ldrb	w12, [x9, #1]
	cbz	w11, .LBB133_10
// %bb.12:                              //   in Loop: Header=BB133_11 Depth=1
	lsl	w13, w12, #8
	sub	w12, w13, w12
	ldrb	w13, [x9]
	udiv	w12, w12, w11
	lsl	w14, w13, #8
	sub	w13, w14, w13
	lsl	w14, w10, #8
	sub	w10, w14, w10
	udiv	w13, w13, w11
	sturb	w12, [x9, #-1]
	udiv	w10, w10, w11
	strb	w13, [x9]
	strb	w10, [x9, #1]
	subs	w8, w8, #1
	add	x9, x9, #4
	b.ne	.LBB133_11
	b	.LBB133_24
.LBB133_13:
	cbz	w8, .LBB133_24
// %bb.14:
	subs	w9, w8, #1
	b.eq	.LBB133_21
// %bb.15:
	add	x11, x9, #1
	add	x12, x3, #4
	and	x10, x11, #0x1fffffffe
	mov	x13, x10
	add	x9, x3, x10, lsl #2
.LBB133_16:                             // =>This Inner Loop Header: Depth=1
	ldurb	w14, [x12, #-2]
	subs	x13, x13, #2
	ldrb	w15, [x12, #2]
	ldurb	w16, [x12, #-4]
	ldrb	w17, [x12]
	sturb	w14, [x12, #-4]
	strb	w15, [x12]
	sturb	w16, [x12, #-2]
	strb	w17, [x12, #2]
	add	x12, x12, #8
	b.ne	.LBB133_16
// %bb.17:
	cmp	x11, x10
	b.ne	.LBB133_22
	b	.LBB133_24
.LBB133_18:
	mov	w10, wzr
	mov	x9, x3
.LBB133_19:
	sub	w8, w8, w10
.LBB133_20:                             // =>This Inner Loop Header: Depth=1
	ldrb	w10, [x9, #2]
	subs	w8, w8, #1
	ldrb	w11, [x9]
	strb	w10, [x9]
	strb	w11, [x9, #2]
	add	x9, x9, #3
	b.ne	.LBB133_20
	b	.LBB133_24
.LBB133_21:
	mov	w10, wzr
	mov	x9, x3
.LBB133_22:
	sub	w8, w8, w10
.LBB133_23:                             // =>This Inner Loop Header: Depth=1
	ldrb	w10, [x9, #2]
	subs	w8, w8, #1
	ldrb	w11, [x9]
	strb	w10, [x9]
	strb	w11, [x9, #2]
	add	x9, x9, #4
	b.ne	.LBB133_23
.LBB133_24:
	ldp	x29, x30, [sp], #16             // 16-byte Folded Reload
	ret
.LBB133_25:
	adrp	x0, .L.str.66
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL15stbi__de_iphoneP9stbi__png
	add	x0, x0, :lo12:.L.str.66
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL15stbi__de_iphoneP9stbi__png
	mov	w2, #4267
	bl	__assert_fail
.Lfunc_end133:
	.size	_ZL15stbi__de_iphoneP9stbi__png, .Lfunc_end133-_ZL15stbi__de_iphoneP9stbi__png
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	.type	_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii,@function
_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii: // @_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #288
	stp	x29, x30, [sp, #192]            // 16-byte Folded Spill
	add	x29, sp, #192
	stp	x28, x27, [sp, #208]            // 16-byte Folded Spill
	stp	x26, x25, [sp, #224]            // 16-byte Folded Spill
	stp	x24, x23, [sp, #240]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #256]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #272]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	ldr	x19, [x0]
	stur	x6, [x29, #-16]                 // 8-byte Folded Spill
	ldr	w27, [x19, #8]
	add	w8, w27, #1
	cmp	w27, w3
	ccmp	w8, w3, #4, ne
	stur	w8, [x29, #-36]                 // 4-byte Folded Spill
	b.ne	.LBB134_316
// %bb.1:
	mul	w23, w4, w3
	mov	x21, x0
	mov	w20, w7
	mov	w22, w3
	mov	w24, w5
	mov	w26, w2
	mul	w0, w23, w5
	mov	x25, x1
	mov	w28, w4
	bl	malloc
	str	x0, [x21, #24]
	cbz	x0, .LBB134_10
// %bb.2:
	mul	w11, w27, w28
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	orr	w9, wzr, #0x7
	ldr	w10, [x19]
	mov	x8, x0
	mov	w4, w28
	madd	w9, w11, w30, w9
	cmp	w10, w28
	lsr	w12, w9, #3
	madd	w9, w24, w12, w24
	b.ne	.LBB134_6
// %bb.3:
	ldr	w10, [x19, #4]
	cmp	w10, w24
	b.ne	.LBB134_6
// %bb.4:
	cmp	w9, w26
	b.eq	.LBB134_7
.LBB134_5:
	adrp	x9, .L.str.60
	add	x9, x9, :lo12:.L.str.60
	b	.LBB134_11
.LBB134_6:
	cmp	w9, w26
	b.hi	.LBB134_5
.LBB134_7:
	cbz	w24, .LBB134_315
// %bb.8:
	cmp	w27, w22
	ldrb	w13, [x25]
	cset	w9, eq
	cmp	w30, #8
	cset	w10, lt
	cmp	w13, #4
	b.ls	.LBB134_13
.LBB134_9:
	adrp	x9, .L.str.61
	add	x9, x9, :lo12:.L.str.61
	b	.LBB134_11
.LBB134_10:
	adrp	x9, .L.str.28
	add	x9, x9, :lo12:.L.str.28
.LBB134_11:
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB134_12:
	ldp	x20, x19, [sp, #272]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #256]            // 16-byte Folded Reload
	ldp	x24, x23, [sp, #240]            // 16-byte Folded Reload
	ldp	x26, x25, [sp, #224]            // 16-byte Folded Reload
	ldp	x28, x27, [sp, #208]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #192]            // 16-byte Folded Reload
	add	sp, sp, #288
	ret
.LBB134_13:
	orr	w9, w10, w9
	stur	x21, [x29, #-64]                // 8-byte Folded Spill
	sxtw	x21, w22
	mov	x10, x23
	neg	x5, x21
	str	w11, [sp, #8]                   // 4-byte Folded Spill
	stur	w9, [x29, #-52]                 // 4-byte Folded Spill
	sub	w9, w4, #1
	mov	w11, w27
	stur	x22, [x29, #-48]                // 8-byte Folded Spill
	and	x28, x27, #0xffffffe0
	adrp	x22, .LJTI134_0
	str	x9, [sp, #80]                   // 8-byte Folded Spill
	mov	w9, w24
	str	w20, [sp, #12]                  // 4-byte Folded Spill
	mov	x26, xzr
	neg	x14, x23
	sxtw	x19, w11
	stur	x9, [x29, #-24]                 // 8-byte Folded Spill
	sub	x9, x27, x21
	sub	w11, w23, w12
	and	x23, x27, #0xfffffff8
	neg	x20, x28
	add	x22, x22, :lo12:.LJTI134_0
	str	x9, [sp, #40]                   // 8-byte Folded Spill
	and	x9, x27, #0x18
	mov	w6, #255
	stur	x14, [x29, #-32]                // 8-byte Folded Spill
	stp	x11, x12, [sp, #88]             // 16-byte Folded Spill
	str	x9, [sp, #48]                   // 8-byte Folded Spill
	and	x9, x27, #0xfffffff0
	stur	x10, [x29, #-72]                // 8-byte Folded Spill
	stur	w4, [x29, #-76]                 // 4-byte Folded Spill
	str	x9, [sp, #32]                   // 8-byte Folded Spill
	sub	x9, x5, x10
	stur	x5, [x29, #-88]                 // 8-byte Folded Spill
	str	x9, [sp, #16]                   // 8-byte Folded Spill
	mov	w9, #16
	sub	x9, x9, x10
	str	x9, [sp, #24]                   // 8-byte Folded Spill
.LBB134_14:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB134_24 Depth 2
                                        //     Child Loop BB134_182 Depth 2
                                        //       Child Loop BB134_191 Depth 3
                                        //       Child Loop BB134_194 Depth 3
                                        //       Child Loop BB134_185 Depth 3
                                        //     Child Loop BB134_165 Depth 2
                                        //       Child Loop BB134_174 Depth 3
                                        //       Child Loop BB134_177 Depth 3
                                        //       Child Loop BB134_168 Depth 3
                                        //     Child Loop BB134_144 Depth 2
                                        //       Child Loop BB134_155 Depth 3
                                        //       Child Loop BB134_158 Depth 3
                                        //       Child Loop BB134_147 Depth 3
                                        //     Child Loop BB134_124 Depth 2
                                        //       Child Loop BB134_134 Depth 3
                                        //       Child Loop BB134_137 Depth 3
                                        //       Child Loop BB134_127 Depth 3
                                        //     Child Loop BB134_107 Depth 2
                                        //       Child Loop BB134_116 Depth 3
                                        //       Child Loop BB134_119 Depth 3
                                        //       Child Loop BB134_110 Depth 3
                                        //     Child Loop BB134_90 Depth 2
                                        //       Child Loop BB134_99 Depth 3
                                        //       Child Loop BB134_102 Depth 3
                                        //       Child Loop BB134_93 Depth 3
                                        //     Child Loop BB134_38 Depth 2
                                        //       Child Loop BB134_47 Depth 3
                                        //       Child Loop BB134_50 Depth 3
                                        //       Child Loop BB134_52 Depth 3
                                        //     Child Loop BB134_262 Depth 2
                                        //     Child Loop BB134_266 Depth 2
                                        //     Child Loop BB134_85 Depth 2
                                        //     Child Loop BB134_255 Depth 2
                                        //     Child Loop BB134_259 Depth 2
                                        //     Child Loop BB134_80 Depth 2
                                        //     Child Loop BB134_251 Depth 2
                                        //     Child Loop BB134_219 Depth 2
                                        //     Child Loop BB134_75 Depth 2
                                        //     Child Loop BB134_244 Depth 2
                                        //     Child Loop BB134_248 Depth 2
                                        //     Child Loop BB134_71 Depth 2
                                        //     Child Loop BB134_237 Depth 2
                                        //     Child Loop BB134_241 Depth 2
                                        //     Child Loop BB134_66 Depth 2
                                        //     Child Loop BB134_230 Depth 2
                                        //     Child Loop BB134_234 Depth 2
                                        //     Child Loop BB134_61 Depth 2
	mov	x9, x8
	mov	w14, w27
	mov	w15, w4
	cmp	w30, #7
	b.gt	.LBB134_17
// %bb.15:                              //   in Loop: Header=BB134_14 Depth=1
	ldr	x10, [sp, #96]                  // 8-byte Folded Reload
	cmp	w10, w4
	b.hi	.LBB134_317
// %bb.16:                              //   in Loop: Header=BB134_14 Depth=1
	ldr	x9, [sp, #88]                   // 8-byte Folded Reload
	mov	w14, #1
	mov	w15, w10
	add	x9, x8, x9
.LBB134_17:                             //   in Loop: Header=BB134_14 Depth=1
	cbz	x26, .LBB134_19
// %bb.18:                              //   in Loop: Header=BB134_14 Depth=1
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	cmp	w14, #1
	add	x12, x8, x10
	add	x10, x25, #1
	b.ge	.LBB134_20
	b	.LBB134_28
.LBB134_19:                             //   in Loop: Header=BB134_14 Depth=1
	and	x10, x13, #0xff
	adrp	x11, _ZL16first_row_filter
	add	x11, x11, :lo12:_ZL16first_row_filter
	ldrb	w13, [x11, x10]
	ldur	x10, [x29, #-32]                // 8-byte Folded Reload
	cmp	w14, #1
	add	x12, x8, x10
	add	x10, x25, #1
	b.lt	.LBB134_28
.LBB134_20:                             //   in Loop: Header=BB134_14 Depth=1
	mov	w11, w14
	mov	x16, x12
	mov	x17, x10
	mov	x18, x9
	b	.LBB134_24
.LBB134_21:                             //   in Loop: Header=BB134_24 Depth=2
	ldrb	w0, [x17]
.LBB134_22:                             //   in Loop: Header=BB134_24 Depth=2
	strb	w0, [x18]
.LBB134_23:                             //   in Loop: Header=BB134_24 Depth=2
	add	x18, x18, #1
	add	x17, x17, #1
	add	x16, x16, #1
	subs	x11, x11, #1
	b.eq	.LBB134_28
.LBB134_24:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	cmp	w13, #6
	b.hi	.LBB134_23
// %bb.25:                              //   in Loop: Header=BB134_24 Depth=2
	mov	w0, w13
	adr	x1, .LBB134_21
	ldrb	w2, [x22, x0]
	add	x1, x1, x2, lsl #2
	br	x1
.LBB134_26:                             //   in Loop: Header=BB134_24 Depth=2
	ldrb	w0, [x17]
	ldrb	w1, [x16]
	add	w0, w1, w0
	b	.LBB134_22
.LBB134_27:                             //   in Loop: Header=BB134_24 Depth=2
	ldrb	w0, [x17]
	ldrb	w1, [x16]
	add	w0, w0, w1, lsr #1
	b	.LBB134_22
.LBB134_28:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w30, #8
	b.ne	.LBB134_53
// %bb.29:                              //   in Loop: Header=BB134_14 Depth=1
	ldur	x11, [x29, #-48]                // 8-byte Folded Reload
	cmp	w27, w11
	b.eq	.LBB134_31
// %bb.30:                              //   in Loop: Header=BB134_14 Depth=1
	strb	w6, [x9, x19]
.LBB134_31:                             //   in Loop: Header=BB134_14 Depth=1
	add	x24, x10, x19
	mov	x10, x21
	add	x0, x9, x10
	add	x11, x12, x10
	ldur	w16, [x29, #-52]                // 4-byte Folded Reload
	cbnz	w16, .LBB134_54
.LBB134_32:                             //   in Loop: Header=BB134_14 Depth=1
	ldur	x14, [x29, #-48]                // 8-byte Folded Reload
	ldur	w15, [x29, #-36]                // 4-byte Folded Reload
	cmp	w15, w14
	b.ne	.LBB134_318
// %bb.33:                              //   in Loop: Header=BB134_14 Depth=1
	cmp	w13, #6
	b.hi	.LBB134_196
// %bb.34:                              //   in Loop: Header=BB134_14 Depth=1
	adrp	x16, .LJTI134_1
	mov	w13, w13
	add	x16, x16, :lo12:.LJTI134_1
	adr	x14, .LBB134_35
	ldrh	w15, [x16, x13, lsl #1]
	add	x14, x14, x15, lsl #2
	br	x14
.LBB134_35:                             //   in Loop: Header=BB134_14 Depth=1
	ldr	x11, [sp, #80]                  // 8-byte Folded Reload
	cbz	w11, .LBB134_196
// %bb.36:                              //   in Loop: Header=BB134_14 Depth=1
	mov	x8, xzr
	add	x10, x10, x27
	mov	x25, x24
                                        // kill: def $w11 killed $w11 killed $x11
	b	.LBB134_38
.LBB134_37:                             //   in Loop: Header=BB134_38 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	subs	w11, w11, #1
	add	x8, x8, #1
	b.eq	.LBB134_197
.LBB134_38:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_47 Depth 3
                                        //       Child Loop BB134_50 Depth 3
                                        //       Child Loop BB134_52 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_37
// %bb.39:                              //   in Loop: Header=BB134_38 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_41
// %bb.40:                              //   in Loop: Header=BB134_38 Depth=2
	mov	x12, xzr
	b	.LBB134_52
.LBB134_41:                             //   in Loop: Header=BB134_38 Depth=2
	mul	x12, x8, x19
	add	x12, x12, x27
	add	x12, x24, x12
	cmp	x0, x12
	b.hs	.LBB134_44
// %bb.42:                              //   in Loop: Header=BB134_38 Depth=2
	madd	x12, x8, x21, x10
	add	x12, x9, x12
	cmp	x25, x12
	b.hs	.LBB134_44
// %bb.43:                              //   in Loop: Header=BB134_38 Depth=2
	mov	x12, xzr
	b	.LBB134_52
.LBB134_44:                             //   in Loop: Header=BB134_38 Depth=2
	cmp	w27, #32
	b.hs	.LBB134_46
// %bb.45:                              //   in Loop: Header=BB134_38 Depth=2
	mov	x13, xzr
	b	.LBB134_50
.LBB134_46:                             //   in Loop: Header=BB134_38 Depth=2
	mov	w12, #16
.LBB134_47:                             //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_38 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x13, x25, x12
	add	x14, x0, x12
	add	x12, x12, #32
	ldp	q0, q1, [x13, #-16]
	add	x13, x20, x12
	cmp	x13, #16
	stp	q0, q1, [x14, #-16]
	b.ne	.LBB134_47
// %bb.48:                              //   in Loop: Header=BB134_38 Depth=2
	cmp	x28, x27
	b.eq	.LBB134_37
// %bb.49:                              //   in Loop: Header=BB134_38 Depth=2
	mov	x13, x28
	mov	x12, x28
	ldr	x14, [sp, #48]                  // 8-byte Folded Reload
	cbz	x14, .LBB134_52
.LBB134_50:                             //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_38 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x25, x13]
	str	d0, [x0, x13]
	add	x13, x13, #8
	cmp	x23, x13
	b.ne	.LBB134_50
// %bb.51:                              //   in Loop: Header=BB134_38 Depth=2
	mov	x12, x23
	cmp	x23, x27
	b.eq	.LBB134_37
.LBB134_52:                             //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_38 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w13, [x25, x12]
	strb	w13, [x0, x12]
	add	x12, x12, #1
	cmp	x27, x12
	b.ne	.LBB134_52
	b	.LBB134_37
.LBB134_53:                             //   in Loop: Header=BB134_14 Depth=1
	add	x24, x25, #2
	mov	w10, #1
	add	x0, x9, x10
	add	x11, x12, x10
	ldur	w16, [x29, #-52]                // 4-byte Folded Reload
	cbz	w16, .LBB134_32
.LBB134_54:                             //   in Loop: Header=BB134_14 Depth=1
	sub	w15, w15, #1
	cmp	w13, #6
	mul	w25, w15, w27
	b.hi	.LBB134_86
// %bb.55:                              //   in Loop: Header=BB134_14 Depth=1
	adrp	x17, .LJTI134_2
	mov	w13, w13
	add	x17, x17, :lo12:.LJTI134_2
	adr	x15, .LBB134_56
	ldrb	w16, [x17, x13]
	add	x15, x15, x16, lsl #2
	br	x15
.LBB134_56:                             //   in Loop: Header=BB134_14 Depth=1
	mov	w8, w25
	mov	x1, x24
	sxtw	x2, w8
	bl	memcpy
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	mov	w6, #255
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	add	x25, x24, w25, sxtw
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	b	.LBB134_197
.LBB134_57:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #1
	b.lt	.LBB134_86
// %bb.58:                              //   in Loop: Header=BB134_14 Depth=1
                                        // kill: def $w14 killed $w14 killed $x14 def $x14
	sxtw	x8, w14
	cmp	w25, #8
	b.hs	.LBB134_199
// %bb.59:                              //   in Loop: Header=BB134_14 Depth=1
	mov	x11, xzr
.LBB134_60:                             //   in Loop: Header=BB134_14 Depth=1
	add	x10, x11, x10
	neg	x8, x8
	add	x9, x9, x10
	add	x10, x24, x11
	sub	x11, x25, x11
.LBB134_61:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w12, [x9, x8]
	subs	x11, x11, #1
	ldrb	w13, [x10], #1
	add	w12, w12, w13
	strb	w12, [x9], #1
	b.ne	.LBB134_61
	b	.LBB134_86
.LBB134_62:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #1
	b.lt	.LBB134_86
// %bb.63:                              //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #8
	b.hs	.LBB134_203
// %bb.64:                              //   in Loop: Header=BB134_14 Depth=1
	mov	x13, xzr
.LBB134_65:                             //   in Loop: Header=BB134_14 Depth=1
	ldur	x11, [x29, #-32]                // 8-byte Folded Reload
	add	x10, x13, x10
	add	x11, x8, x11
	add	x8, x9, x10
	add	x9, x11, x10
	add	x10, x24, x13
	sub	x11, x25, x13
.LBB134_66:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w12, [x10], #1
	ldrb	w13, [x9], #1
	subs	x11, x11, #1
	add	w12, w13, w12
	strb	w12, [x8], #1
	b.ne	.LBB134_66
	b	.LBB134_86
.LBB134_67:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #1
	b.lt	.LBB134_86
// %bb.68:                              //   in Loop: Header=BB134_14 Depth=1
                                        // kill: def $w14 killed $w14 killed $x14 def $x14
	sxtw	x13, w14
	cmp	w25, #8
	b.hs	.LBB134_207
// %bb.69:                              //   in Loop: Header=BB134_14 Depth=1
	mov	x14, xzr
.LBB134_70:                             //   in Loop: Header=BB134_14 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	add	x10, x14, x10
	neg	x11, x13
	add	x12, x8, x12
	add	x8, x9, x10
	add	x9, x12, x10
	add	x10, x24, x14
	sub	x12, x25, x14
.LBB134_71:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w13, [x8, x11]
	subs	x12, x12, #1
	ldrb	w14, [x9], #1
	ldrb	w15, [x10], #1
	add	w13, w13, w14
	add	w13, w15, w13, lsr #1
	strb	w13, [x8], #1
	b.ne	.LBB134_71
	b	.LBB134_86
.LBB134_72:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #1
	b.lt	.LBB134_86
// %bb.73:                              //   in Loop: Header=BB134_14 Depth=1
                                        // kill: def $w14 killed $w14 killed $x14 def $x14
	sxtw	x15, w14
	mov	w13, w25
	mov	x14, xzr
	cmp	w25, #8
	b.hs	.LBB134_212
.LBB134_74:                             //   in Loop: Header=BB134_14 Depth=1
	ldur	x12, [x29, #-32]                // 8-byte Folded Reload
	sub	x10, x10, x15
	add	x12, x8, x12
	add	x8, x9, x10
	add	x9, x12, x10
	mov	x10, x24
.LBB134_75:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w12, [x8, x14]
	add	x8, x8, #1
	ldrb	w15, [x11, x14]
	add	x11, x11, #1
	ldrb	w16, [x9, x14]
	add	x9, x9, #1
	sub	x13, x13, #1
	add	w17, w15, w12
	sub	w17, w17, w16
	subs	w18, w17, w12
	cneg	w18, w18, mi
	subs	w1, w17, w15
	cneg	w1, w1, mi
	subs	w17, w17, w16
	cneg	w17, w17, mi
	cmp	w1, w17
	csel	w15, w16, w15, hi
	cmp	w18, w17
	ldrb	w16, [x10, x14]
	ccmp	w18, w1, #2, ls
	add	x10, x10, #1
	csel	w12, w15, w12, hi
	cmp	x14, x13
	add	w12, w12, w16
	strb	w12, [x0, x14]
	add	x0, x0, #1
	b.ne	.LBB134_75
	b	.LBB134_86
.LBB134_76:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #1
	b.lt	.LBB134_86
// %bb.77:                              //   in Loop: Header=BB134_14 Depth=1
                                        // kill: def $w14 killed $w14 killed $x14 def $x14
	sxtw	x8, w14
	cmp	w25, #8
	b.hs	.LBB134_221
// %bb.78:                              //   in Loop: Header=BB134_14 Depth=1
	mov	x11, xzr
.LBB134_79:                             //   in Loop: Header=BB134_14 Depth=1
	add	x10, x11, x10
	neg	x8, x8
	add	x9, x9, x10
	add	x10, x24, x11
	sub	x11, x25, x11
.LBB134_80:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w12, [x9, x8]
	subs	x11, x11, #1
	ldrb	w13, [x10], #1
	add	w12, w13, w12, lsr #1
	strb	w12, [x9], #1
	b.ne	.LBB134_80
	b	.LBB134_86
.LBB134_81:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #1
	b.lt	.LBB134_86
// %bb.82:                              //   in Loop: Header=BB134_14 Depth=1
	sxtw	x8, w14
	cmp	w25, #8
	b.hs	.LBB134_225
// %bb.83:                              //   in Loop: Header=BB134_14 Depth=1
	mov	x11, xzr
.LBB134_84:                             //   in Loop: Header=BB134_14 Depth=1
	add	x10, x11, x10
	neg	x8, x8
	add	x9, x9, x10
	add	x10, x24, x11
	sub	x11, x25, x11
.LBB134_85:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w12, [x9, x8]
	subs	x11, x11, #1
	ldrb	w13, [x10], #1
	add	w12, w12, w13
	strb	w12, [x9], #1
	b.ne	.LBB134_85
.LBB134_86:                             //   in Loop: Header=BB134_14 Depth=1
	add	x25, x24, w25, sxtw
	b	.LBB134_197
.LBB134_87:                             //   in Loop: Header=BB134_14 Depth=1
	ldr	x15, [sp, #80]                  // 8-byte Folded Reload
	cbz	w15, .LBB134_196
// %bb.88:                              //   in Loop: Header=BB134_14 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	add	x14, x9, x5
	mov	x8, xzr
	add	x11, x10, x27
	sub	x12, x10, x21
	mov	x25, x24
	add	x13, x13, x10
	add	x10, x14, x10
	mov	w14, w15
	b	.LBB134_90
.LBB134_89:                             //   in Loop: Header=BB134_90 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	subs	w14, w14, #1
	add	x8, x8, #1
	add	x10, x10, x21
	b.eq	.LBB134_197
.LBB134_90:                             //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_99 Depth 3
                                        //       Child Loop BB134_102 Depth 3
                                        //       Child Loop BB134_93 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_89
// %bb.91:                              //   in Loop: Header=BB134_90 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_94
// %bb.92:                              //   in Loop: Header=BB134_90 Depth=2
	mov	x15, xzr
.LBB134_93:                             //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_90 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w16, [x25, x15]
	ldrb	w17, [x10, x15]
	add	w16, w17, w16
	strb	w16, [x0, x15]
	add	x15, x15, #1
	cmp	x27, x15
	b.ne	.LBB134_93
	b	.LBB134_89
.LBB134_94:                             //   in Loop: Header=BB134_90 Depth=2
	mul	x16, x8, x19
	mov	x15, xzr
	mul	x17, x8, x21
	add	x16, x16, x27
	add	x18, x11, x17
	add	x16, x24, x16
	add	x18, x9, x18
	cmp	x0, x16
	cset	w16, lo
	cmp	x25, x18
	cset	w1, lo
	and	w1, w16, w1
	add	x16, x13, x17
	add	x17, x12, x17
	add	x16, x9, x16
	add	x17, x9, x17
	cmp	x0, x16
	cset	w16, lo
	cmp	x17, x18
	cset	w17, lo
	tbnz	w1, #0, .LBB134_93
// %bb.95:                              //   in Loop: Header=BB134_90 Depth=2
	and	w16, w16, w17
	tbnz	w16, #0, .LBB134_93
// %bb.96:                              //   in Loop: Header=BB134_90 Depth=2
	cmp	w27, #32
	b.hs	.LBB134_98
// %bb.97:                              //   in Loop: Header=BB134_90 Depth=2
	mov	x16, xzr
	b	.LBB134_102
.LBB134_98:                             //   in Loop: Header=BB134_90 Depth=2
	mov	x15, xzr
	add	x16, x0, x5
.LBB134_99:                             //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_90 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x17, x25, x15
	add	x18, x16, x15
	ldr	q0, [x16, x15]
	ldp	q1, q2, [x17]
	add	x17, x0, x15
	add	x15, x15, #32
	cmp	x28, x15
	add	v0.16b, v0.16b, v1.16b
	ldr	q3, [x18, #16]
	add	v1.16b, v3.16b, v2.16b
	stp	q0, q1, [x17]
	b.ne	.LBB134_99
// %bb.100:                             //   in Loop: Header=BB134_90 Depth=2
	cmp	x28, x27
	b.eq	.LBB134_89
// %bb.101:                             //   in Loop: Header=BB134_90 Depth=2
	mov	x16, x28
	mov	x15, x28
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	cbz	x17, .LBB134_93
.LBB134_102:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_90 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x25, x16]
	ldr	d1, [x10, x16]
	add	v0.8b, v1.8b, v0.8b
	str	d0, [x0, x16]
	add	x16, x16, #8
	cmp	x23, x16
	b.ne	.LBB134_102
// %bb.103:                             //   in Loop: Header=BB134_90 Depth=2
	mov	x15, x23
	cmp	x23, x27
	b.ne	.LBB134_93
	b	.LBB134_89
.LBB134_104:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x13, [sp, #80]                  // 8-byte Folded Reload
	cbz	w13, .LBB134_196
// %bb.105:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x8, xzr
	add	x10, x10, x27
	mov	x25, x24
                                        // kill: def $w13 killed $w13 killed $x13
	b	.LBB134_107
.LBB134_106:                            //   in Loop: Header=BB134_107 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	add	x11, x11, x21
	subs	w13, w13, #1
	add	x8, x8, #1
	b.eq	.LBB134_197
.LBB134_107:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_116 Depth 3
                                        //       Child Loop BB134_119 Depth 3
                                        //       Child Loop BB134_110 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_106
// %bb.108:                             //   in Loop: Header=BB134_107 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_111
// %bb.109:                             //   in Loop: Header=BB134_107 Depth=2
	mov	x14, xzr
.LBB134_110:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_107 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w15, [x25, x14]
	ldrb	w16, [x11, x14]
	add	w15, w16, w15
	strb	w15, [x0, x14]
	add	x14, x14, #1
	cmp	x27, x14
	b.ne	.LBB134_110
	b	.LBB134_106
.LBB134_111:                            //   in Loop: Header=BB134_107 Depth=2
	mul	x15, x8, x19
	mov	x14, xzr
	madd	x16, x8, x21, x10
	add	x15, x15, x27
	add	x15, x24, x15
	add	x17, x9, x16
	cmp	x0, x15
	add	x16, x12, x16
	cset	w15, lo
	cmp	x25, x17
	cset	w18, lo
	cmp	x0, x16
	and	w18, w15, w18
	cset	w15, lo
	cmp	x11, x17
	cset	w16, lo
	tbnz	w18, #0, .LBB134_110
// %bb.112:                             //   in Loop: Header=BB134_107 Depth=2
	and	w15, w15, w16
	tbnz	w15, #0, .LBB134_110
// %bb.113:                             //   in Loop: Header=BB134_107 Depth=2
	cmp	w27, #32
	b.hs	.LBB134_115
// %bb.114:                             //   in Loop: Header=BB134_107 Depth=2
	mov	x15, xzr
	b	.LBB134_119
.LBB134_115:                            //   in Loop: Header=BB134_107 Depth=2
	mov	x14, xzr
.LBB134_116:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_107 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x15, x25, x14
	add	x16, x11, x14
	ldp	q0, q1, [x15]
	add	x15, x0, x14
	add	x14, x14, #32
	cmp	x28, x14
	ldp	q2, q3, [x16]
	add	v0.16b, v2.16b, v0.16b
	add	v1.16b, v3.16b, v1.16b
	stp	q0, q1, [x15]
	b.ne	.LBB134_116
// %bb.117:                             //   in Loop: Header=BB134_107 Depth=2
	cmp	x28, x27
	b.eq	.LBB134_106
// %bb.118:                             //   in Loop: Header=BB134_107 Depth=2
	mov	x15, x28
	mov	x14, x28
	ldr	x16, [sp, #48]                  // 8-byte Folded Reload
	cbz	x16, .LBB134_110
.LBB134_119:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_107 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x25, x15]
	ldr	d1, [x11, x15]
	add	v0.8b, v1.8b, v0.8b
	str	d0, [x0, x15]
	add	x15, x15, #8
	cmp	x23, x15
	b.ne	.LBB134_119
// %bb.120:                             //   in Loop: Header=BB134_107 Depth=2
	mov	x14, x23
	cmp	x23, x27
	b.ne	.LBB134_110
	b	.LBB134_106
.LBB134_121:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x14, [sp, #80]                  // 8-byte Folded Reload
	cbz	w14, .LBB134_196
// %bb.122:                             //   in Loop: Header=BB134_14 Depth=1
	ldr	x18, [sp, #24]                  // 8-byte Folded Reload
	add	x15, x10, x27
	ldr	x16, [sp, #40]                  // 8-byte Folded Reload
	add	x17, x9, x10
	mov	x13, xzr
	add	x17, x17, #16
	add	x8, x8, x18
	add	x18, x9, x5
	str	x15, [sp, #72]                  // 8-byte Folded Spill
	sub	x15, x10, x21
	add	x16, x16, x10
	add	x8, x8, x10
	add	x10, x18, x10
	mov	w18, w14
	mov	x25, x24
	b	.LBB134_124
.LBB134_123:                            //   in Loop: Header=BB134_124 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	add	x11, x11, x21
	subs	w18, w18, #1
	add	x13, x13, #1
	add	x17, x17, x21
	add	x8, x8, x21
	add	x10, x10, x21
	b.eq	.LBB134_197
.LBB134_124:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_134 Depth 3
                                        //       Child Loop BB134_137 Depth 3
                                        //       Child Loop BB134_127 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_123
// %bb.125:                             //   in Loop: Header=BB134_124 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_128
// %bb.126:                             //   in Loop: Header=BB134_124 Depth=2
	mov	x1, xzr
.LBB134_127:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_124 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w14, [x11, x1]
	ldrb	w2, [x10, x1]
	ldrb	w3, [x25, x1]
	add	w14, w2, w14
	add	w14, w3, w14, lsr #1
	strb	w14, [x0, x1]
	add	x1, x1, #1
	cmp	x27, x1
	b.ne	.LBB134_127
	b	.LBB134_123
.LBB134_128:                            //   in Loop: Header=BB134_124 Depth=2
	mul	x3, x13, x19
	ldr	x14, [sp, #72]                  // 8-byte Folded Reload
	mul	x2, x13, x21
	mov	x1, xzr
	add	x3, x3, x27
	add	x4, x14, x2
	add	x3, x24, x3
	add	x5, x9, x4
	cmp	x0, x3
	add	x4, x12, x4
	cset	w30, lo
	cmp	x25, x5
	add	x6, x15, x2
	add	x2, x16, x2
	cset	w14, lo
	cmp	x0, x4
	add	x7, x9, x2
	cset	w2, lo
	cmp	x11, x5
	cset	w4, lo
	cmp	x0, x7
	add	x6, x9, x6
	cset	w3, lo
	cmp	x6, x5
	and	w14, w30, w14
	cset	w5, lo
	tbnz	w14, #0, .LBB134_139
// %bb.129:                             //   in Loop: Header=BB134_124 Depth=2
	and	w14, w2, w4
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	mov	w6, #255
	tbnz	w14, #0, .LBB134_140
// %bb.130:                             //   in Loop: Header=BB134_124 Depth=2
	and	w14, w3, w5
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	tbnz	w14, #0, .LBB134_127
// %bb.131:                             //   in Loop: Header=BB134_124 Depth=2
	cmp	w27, #32
	b.hs	.LBB134_133
// %bb.132:                             //   in Loop: Header=BB134_124 Depth=2
	mov	x2, xzr
	b	.LBB134_137
.LBB134_133:                            //   in Loop: Header=BB134_124 Depth=2
	mov	x1, x8
	mov	x2, x17
	mov	w3, #16
.LBB134_134:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_124 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x14, x2, x5
	ldp	q2, q3, [x1, #-16]
	add	x1, x1, #32
	ldp	q0, q1, [x14, #-16]
	add	x14, x25, x3
	add	x3, x3, #32
	uhadd	v0.16b, v0.16b, v2.16b
	ldp	q4, q2, [x14, #-16]
	uhadd	v1.16b, v1.16b, v3.16b
	add	x14, x20, x3
	cmp	x14, #16
	add	v0.16b, v4.16b, v0.16b
	add	v1.16b, v2.16b, v1.16b
	stp	q0, q1, [x2, #-16]
	add	x2, x2, #32
	b.ne	.LBB134_134
// %bb.135:                             //   in Loop: Header=BB134_124 Depth=2
	cmp	x28, x27
	b.eq	.LBB134_123
// %bb.136:                             //   in Loop: Header=BB134_124 Depth=2
	mov	x2, x28
	mov	x1, x28
	ldr	x14, [sp, #48]                  // 8-byte Folded Reload
	cbz	x14, .LBB134_127
.LBB134_137:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_124 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x11, x2]
	ldr	d1, [x10, x2]
	ldr	d2, [x25, x2]
	uhadd	v0.8b, v1.8b, v0.8b
	add	v0.8b, v2.8b, v0.8b
	str	d0, [x0, x2]
	add	x2, x2, #8
	cmp	x23, x2
	b.ne	.LBB134_137
// %bb.138:                             //   in Loop: Header=BB134_124 Depth=2
	mov	x1, x23
	cmp	x23, x27
	b.ne	.LBB134_127
	b	.LBB134_123
.LBB134_139:                            //   in Loop: Header=BB134_124 Depth=2
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	mov	w6, #255
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	b	.LBB134_127
.LBB134_140:                            //   in Loop: Header=BB134_124 Depth=2
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	b	.LBB134_127
.LBB134_141:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x14, [sp, #80]                  // 8-byte Folded Reload
	cbz	w14, .LBB134_196
// %bb.142:                             //   in Loop: Header=BB134_14 Depth=1
	add	x15, x10, x27
	add	x17, x9, x5
	mov	x13, xzr
	mov	x25, x24
	str	x15, [sp, #72]                  // 8-byte Folded Spill
	sub	x15, x10, x21
	str	x15, [sp, #64]                  // 8-byte Folded Spill
	ldr	x15, [sp, #40]                  // 8-byte Folded Reload
	add	x15, x15, x10
	str	x15, [sp, #56]                  // 8-byte Folded Spill
	ldr	x15, [sp, #16]                  // 8-byte Folded Reload
	add	x8, x8, x15
	add	x8, x8, x10
	add	x10, x17, x10
	mov	w17, w14
	b	.LBB134_144
.LBB134_143:                            //   in Loop: Header=BB134_144 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	add	x11, x11, x21
	subs	w17, w17, #1
	add	x13, x13, #1
	add	x8, x8, x21
	add	x10, x10, x21
	b.eq	.LBB134_197
.LBB134_144:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_155 Depth 3
                                        //       Child Loop BB134_158 Depth 3
                                        //       Child Loop BB134_147 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_143
// %bb.145:                             //   in Loop: Header=BB134_144 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_148
// %bb.146:                             //   in Loop: Header=BB134_144 Depth=2
	mov	x18, xzr
.LBB134_147:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_144 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w14, [x10, x18]
	ldrb	w15, [x11, x18]
	ldrb	w16, [x8, x18]
	add	w1, w15, w14
	sub	w1, w1, w16
	subs	w2, w1, w14
	cneg	w2, w2, mi
	subs	w3, w1, w15
	cneg	w3, w3, mi
	subs	w1, w1, w16
	cneg	w1, w1, mi
	cmp	w3, w1
	csel	w15, w16, w15, hi
	cmp	w2, w1
	ldrb	w16, [x25, x18]
	ccmp	w2, w3, #2, ls
	csel	w14, w15, w14, hi
	add	w14, w14, w16
	strb	w14, [x0, x18]
	add	x18, x18, #1
	cmp	x27, x18
	b.ne	.LBB134_147
	b	.LBB134_143
.LBB134_148:                            //   in Loop: Header=BB134_144 Depth=2
	ldr	x14, [sp, #72]                  // 8-byte Folded Reload
	mul	x1, x13, x21
	mul	x2, x13, x19
	mov	x18, xzr
	add	x3, x14, x1
	ldr	x14, [sp, #64]                  // 8-byte Folded Reload
	add	x2, x2, x27
	add	x6, x9, x3
	add	x2, x24, x2
	add	x30, x12, x3
	add	x4, x14, x1
	ldr	x14, [sp, #56]                  // 8-byte Folded Reload
	cmp	x0, x2
	add	x5, x9, x4
	cset	w15, lo
	cmp	x25, x6
	add	x1, x14, x1
	cset	w16, lo
	add	x7, x9, x1
	add	x14, x12, x1
	cmp	x0, x7
	cset	w1, lo
	cmp	x5, x6
	cset	w3, lo
	cmp	x0, x30
	cset	w2, lo
	cmp	x11, x6
	cset	w5, lo
	cmp	x0, x14
	add	x14, x12, x4
	cset	w4, lo
	cmp	x14, x6
	and	w14, w15, w16
	cset	w6, lo
	tbnz	w14, #0, .LBB134_160
// %bb.149:                             //   in Loop: Header=BB134_144 Depth=2
	and	w14, w1, w3
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	tbnz	w14, #0, .LBB134_161
// %bb.150:                             //   in Loop: Header=BB134_144 Depth=2
	and	w14, w2, w5
	tbnz	w14, #0, .LBB134_161
// %bb.151:                             //   in Loop: Header=BB134_144 Depth=2
	and	w14, w4, w6
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	mov	w6, #255
	tbnz	w14, #0, .LBB134_147
// %bb.152:                             //   in Loop: Header=BB134_144 Depth=2
	cmp	w27, #16
	b.hs	.LBB134_154
// %bb.153:                             //   in Loop: Header=BB134_144 Depth=2
	mov	x1, xzr
	b	.LBB134_158
.LBB134_154:                            //   in Loop: Header=BB134_144 Depth=2
	mov	x18, xzr
	ldr	x14, [sp, #32]                  // 8-byte Folded Reload
.LBB134_155:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_144 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	q0, [x10, x18]
	ldr	q1, [x11, x18]
	ldr	q2, [x8, x18]
	ushll2	v3.8h, v0.16b, #0
	ushll	v5.8h, v0.8b, #0
	ushll2	v4.8h, v1.16b, #0
	ushll	v6.8h, v1.8b, #0
	ushll	v7.8h, v2.8b, #0
	ushll2	v16.8h, v2.16b, #0
	uaddl2	v17.4s, v4.8h, v3.8h
	uaddl	v18.4s, v4.4h, v3.4h
	uaddl2	v19.4s, v6.8h, v5.8h
	uaddl	v20.4s, v6.4h, v5.4h
	usubw2	v17.4s, v17.4s, v16.8h
	usubw	v18.4s, v18.4s, v16.4h
	usubw2	v19.4s, v19.4s, v7.8h
	usubw	v20.4s, v20.4s, v7.4h
	usubw2	v21.4s, v17.4s, v3.8h
	usubw	v3.4s, v18.4s, v3.4h
	usubw2	v22.4s, v19.4s, v5.8h
	usubw	v5.4s, v20.4s, v5.4h
	usubw2	v23.4s, v17.4s, v4.8h
	usubw	v4.4s, v18.4s, v4.4h
	usubw2	v24.4s, v19.4s, v6.8h
	usubw	v6.4s, v20.4s, v6.4h
	usubw2	v17.4s, v17.4s, v16.8h
	usubw	v16.4s, v18.4s, v16.4h
	usubw2	v18.4s, v19.4s, v7.8h
	usubw	v7.4s, v20.4s, v7.4h
	abs	v21.4s, v21.4s
	abs	v3.4s, v3.4s
	abs	v22.4s, v22.4s
	abs	v5.4s, v5.4s
	abs	v23.4s, v23.4s
	abs	v4.4s, v4.4s
	abs	v24.4s, v24.4s
	abs	v6.4s, v6.4s
	abs	v17.4s, v17.4s
	abs	v16.4s, v16.4s
	abs	v18.4s, v18.4s
	abs	v7.4s, v7.4s
	cmhi	v19.4s, v5.4s, v6.4s
	cmhi	v20.4s, v22.4s, v24.4s
	cmhi	v25.4s, v3.4s, v4.4s
	cmhi	v26.4s, v21.4s, v23.4s
	cmhi	v21.4s, v21.4s, v17.4s
	cmhi	v3.4s, v3.4s, v16.4s
	cmhi	v5.4s, v5.4s, v7.4s
	cmhi	v22.4s, v22.4s, v18.4s
	cmhi	v17.4s, v23.4s, v17.4s
	cmhi	v4.4s, v4.4s, v16.4s
	cmhi	v16.4s, v24.4s, v18.4s
	cmhi	v6.4s, v6.4s, v7.4s
	orr	v21.16b, v26.16b, v21.16b
	orr	v3.16b, v25.16b, v3.16b
	orr	v7.16b, v20.16b, v22.16b
	orr	v5.16b, v19.16b, v5.16b
	uzp1	v4.8h, v4.8h, v17.8h
	uzp1	v6.8h, v6.8h, v16.8h
	uzp1	v3.8h, v3.8h, v21.8h
	uzp1	v5.8h, v5.8h, v7.8h
	uzp1	v4.16b, v6.16b, v4.16b
	uzp1	v3.16b, v5.16b, v3.16b
	bit	v1.16b, v2.16b, v4.16b
	ldr	q2, [x25, x18]
	bit	v0.16b, v1.16b, v3.16b
	add	v0.16b, v0.16b, v2.16b
	str	q0, [x0, x18]
	add	x18, x18, #16
	cmp	x14, x18
	b.ne	.LBB134_155
// %bb.156:                             //   in Loop: Header=BB134_144 Depth=2
	cmp	x14, x27
	b.eq	.LBB134_143
// %bb.157:                             //   in Loop: Header=BB134_144 Depth=2
	ldr	x18, [sp, #32]                  // 8-byte Folded Reload
	mov	x1, x18
	tbz	w27, #3, .LBB134_147
.LBB134_158:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_144 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x10, x1]
	ldr	d1, [x11, x1]
	ldr	d2, [x8, x1]
	ushll	v3.8h, v0.8b, #0
	ushll	v4.8h, v1.8b, #0
	ushll	v5.8h, v2.8b, #0
	uaddl	v6.4s, v4.4h, v3.4h
	uaddl2	v7.4s, v4.8h, v3.8h
	usubw	v6.4s, v6.4s, v5.4h
	usubw2	v7.4s, v7.4s, v5.8h
	usubw	v16.4s, v6.4s, v3.4h
	usubw2	v3.4s, v7.4s, v3.8h
	usubw	v17.4s, v6.4s, v4.4h
	usubw2	v4.4s, v7.4s, v4.8h
	usubw	v6.4s, v6.4s, v5.4h
	usubw2	v5.4s, v7.4s, v5.8h
	abs	v3.4s, v3.4s
	abs	v7.4s, v16.4s
	abs	v16.4s, v17.4s
	abs	v4.4s, v4.4s
	abs	v6.4s, v6.4s
	abs	v5.4s, v5.4s
	cmhi	v17.4s, v7.4s, v16.4s
	cmhi	v18.4s, v3.4s, v4.4s
	cmhi	v7.4s, v7.4s, v6.4s
	cmhi	v3.4s, v3.4s, v5.4s
	cmhi	v4.4s, v4.4s, v5.4s
	cmhi	v5.4s, v16.4s, v6.4s
	orr	v6.16b, v17.16b, v7.16b
	orr	v3.16b, v18.16b, v3.16b
	uzp1	v4.8h, v5.8h, v4.8h
	uzp1	v3.8h, v6.8h, v3.8h
	xtn	v4.8b, v4.8h
	bit	v1.8b, v2.8b, v4.8b
	xtn	v2.8b, v3.8h
	ldr	d3, [x25, x1]
	bit	v0.8b, v1.8b, v2.8b
	add	v0.8b, v0.8b, v3.8b
	str	d0, [x0, x1]
	add	x1, x1, #8
	cmp	x23, x1
	b.ne	.LBB134_158
// %bb.159:                             //   in Loop: Header=BB134_144 Depth=2
	mov	x18, x23
	cmp	x23, x27
	b.ne	.LBB134_147
	b	.LBB134_143
.LBB134_160:                            //   in Loop: Header=BB134_144 Depth=2
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
.LBB134_161:                            //   in Loop: Header=BB134_144 Depth=2
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	mov	w6, #255
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	b	.LBB134_147
.LBB134_162:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x15, [sp, #80]                  // 8-byte Folded Reload
	cbz	w15, .LBB134_196
// %bb.163:                             //   in Loop: Header=BB134_14 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	add	x14, x9, x5
	mov	x8, xzr
	add	x11, x10, x27
	sub	x12, x10, x21
	mov	x25, x24
	add	x13, x13, x10
	add	x10, x14, x10
	mov	w14, w15
	b	.LBB134_165
.LBB134_164:                            //   in Loop: Header=BB134_165 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	subs	w14, w14, #1
	add	x8, x8, #1
	add	x10, x10, x21
	b.eq	.LBB134_197
.LBB134_165:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_174 Depth 3
                                        //       Child Loop BB134_177 Depth 3
                                        //       Child Loop BB134_168 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_164
// %bb.166:                             //   in Loop: Header=BB134_165 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_169
// %bb.167:                             //   in Loop: Header=BB134_165 Depth=2
	mov	x15, xzr
.LBB134_168:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_165 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w16, [x25, x15]
	ldrb	w17, [x10, x15]
	add	w16, w16, w17, lsr #1
	strb	w16, [x0, x15]
	add	x15, x15, #1
	cmp	x27, x15
	b.ne	.LBB134_168
	b	.LBB134_164
.LBB134_169:                            //   in Loop: Header=BB134_165 Depth=2
	mul	x16, x8, x19
	mov	x15, xzr
	mul	x17, x8, x21
	add	x16, x16, x27
	add	x18, x11, x17
	add	x16, x24, x16
	add	x18, x9, x18
	cmp	x0, x16
	cset	w16, lo
	cmp	x25, x18
	cset	w1, lo
	and	w1, w16, w1
	add	x16, x13, x17
	add	x17, x12, x17
	add	x16, x9, x16
	add	x17, x9, x17
	cmp	x0, x16
	cset	w16, lo
	cmp	x17, x18
	cset	w17, lo
	tbnz	w1, #0, .LBB134_168
// %bb.170:                             //   in Loop: Header=BB134_165 Depth=2
	and	w16, w16, w17
	tbnz	w16, #0, .LBB134_168
// %bb.171:                             //   in Loop: Header=BB134_165 Depth=2
	cmp	w27, #32
	b.hs	.LBB134_173
// %bb.172:                             //   in Loop: Header=BB134_165 Depth=2
	mov	x16, xzr
	b	.LBB134_177
.LBB134_173:                            //   in Loop: Header=BB134_165 Depth=2
	mov	x15, xzr
	add	x16, x0, x5
.LBB134_174:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_165 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x17, x25, x15
	add	x18, x16, x15
	ldr	q0, [x16, x15]
	ldp	q1, q2, [x17]
	add	x17, x0, x15
	add	x15, x15, #32
	cmp	x28, x15
	usra	v1.16b, v0.16b, #1
	ldr	q3, [x18, #16]
	usra	v2.16b, v3.16b, #1
	stp	q1, q2, [x17]
	b.ne	.LBB134_174
// %bb.175:                             //   in Loop: Header=BB134_165 Depth=2
	cmp	x28, x27
	b.eq	.LBB134_164
// %bb.176:                             //   in Loop: Header=BB134_165 Depth=2
	mov	x16, x28
	mov	x15, x28
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	cbz	x17, .LBB134_168
.LBB134_177:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_165 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x25, x16]
	ldr	d1, [x10, x16]
	usra	v0.8b, v1.8b, #1
	str	d0, [x0, x16]
	add	x16, x16, #8
	cmp	x23, x16
	b.ne	.LBB134_177
// %bb.178:                             //   in Loop: Header=BB134_165 Depth=2
	mov	x15, x23
	cmp	x23, x27
	b.ne	.LBB134_168
	b	.LBB134_164
.LBB134_179:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x15, [sp, #80]                  // 8-byte Folded Reload
	cbz	w15, .LBB134_196
// %bb.180:                             //   in Loop: Header=BB134_14 Depth=1
	ldr	x13, [sp, #40]                  // 8-byte Folded Reload
	add	x14, x9, x5
	mov	x8, xzr
	add	x11, x10, x27
	sub	x12, x10, x21
	mov	x25, x24
	add	x13, x13, x10
	add	x10, x14, x10
	mov	w14, w15
	b	.LBB134_182
.LBB134_181:                            //   in Loop: Header=BB134_182 Depth=2
	strb	w6, [x0, x19]
	add	x25, x25, x19
	add	x0, x0, x21
	subs	w14, w14, #1
	add	x8, x8, #1
	add	x10, x10, x21
	b.eq	.LBB134_197
.LBB134_182:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Loop Header: Depth=2
                                        //       Child Loop BB134_191 Depth 3
                                        //       Child Loop BB134_194 Depth 3
                                        //       Child Loop BB134_185 Depth 3
	cmp	w27, #1
	b.lt	.LBB134_181
// %bb.183:                             //   in Loop: Header=BB134_182 Depth=2
	cmp	w27, #8
	b.hs	.LBB134_186
// %bb.184:                             //   in Loop: Header=BB134_182 Depth=2
	mov	x15, xzr
.LBB134_185:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_182 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldrb	w16, [x25, x15]
	ldrb	w17, [x10, x15]
	add	w16, w17, w16
	strb	w16, [x0, x15]
	add	x15, x15, #1
	cmp	x27, x15
	b.ne	.LBB134_185
	b	.LBB134_181
.LBB134_186:                            //   in Loop: Header=BB134_182 Depth=2
	mul	x16, x8, x19
	mov	x15, xzr
	mul	x17, x8, x21
	add	x16, x16, x27
	add	x18, x11, x17
	add	x16, x24, x16
	add	x18, x9, x18
	cmp	x0, x16
	cset	w16, lo
	cmp	x25, x18
	cset	w1, lo
	and	w1, w16, w1
	add	x16, x13, x17
	add	x17, x12, x17
	add	x16, x9, x16
	add	x17, x9, x17
	cmp	x0, x16
	cset	w16, lo
	cmp	x17, x18
	cset	w17, lo
	tbnz	w1, #0, .LBB134_185
// %bb.187:                             //   in Loop: Header=BB134_182 Depth=2
	and	w16, w16, w17
	tbnz	w16, #0, .LBB134_185
// %bb.188:                             //   in Loop: Header=BB134_182 Depth=2
	cmp	w27, #32
	b.hs	.LBB134_190
// %bb.189:                             //   in Loop: Header=BB134_182 Depth=2
	mov	x16, xzr
	b	.LBB134_194
.LBB134_190:                            //   in Loop: Header=BB134_182 Depth=2
	mov	x15, xzr
	add	x16, x0, x5
.LBB134_191:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_182 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	add	x17, x25, x15
	add	x18, x16, x15
	ldr	q0, [x16, x15]
	ldp	q1, q2, [x17]
	add	x17, x0, x15
	add	x15, x15, #32
	cmp	x28, x15
	add	v0.16b, v0.16b, v1.16b
	ldr	q3, [x18, #16]
	add	v1.16b, v3.16b, v2.16b
	stp	q0, q1, [x17]
	b.ne	.LBB134_191
// %bb.192:                             //   in Loop: Header=BB134_182 Depth=2
	cmp	x28, x27
	b.eq	.LBB134_181
// %bb.193:                             //   in Loop: Header=BB134_182 Depth=2
	mov	x16, x28
	mov	x15, x28
	ldr	x17, [sp, #48]                  // 8-byte Folded Reload
	cbz	x17, .LBB134_185
.LBB134_194:                            //   Parent Loop BB134_14 Depth=1
                                        //     Parent Loop BB134_182 Depth=2
                                        // =>    This Inner Loop Header: Depth=3
	ldr	d0, [x25, x16]
	ldr	d1, [x10, x16]
	add	v0.8b, v1.8b, v0.8b
	str	d0, [x0, x16]
	add	x16, x16, #8
	cmp	x23, x16
	b.ne	.LBB134_194
// %bb.195:                             //   in Loop: Header=BB134_182 Depth=2
	mov	x15, x23
	cmp	x23, x27
	b.ne	.LBB134_185
	b	.LBB134_181
.LBB134_196:                            //   in Loop: Header=BB134_14 Depth=1
	mov	x25, x24
.LBB134_197:                            //   in Loop: Header=BB134_14 Depth=1
	ldur	x8, [x29, #-24]                 // 8-byte Folded Reload
	add	x26, x26, #1
	cmp	x26, x8
	b.eq	.LBB134_270
// %bb.198:                             //   in Loop: Header=BB134_14 Depth=1
	ldp	x9, x8, [x29, #-72]             // 16-byte Folded Reload
	ldrb	w13, [x25]
	mul	w9, w9, w26
	ldr	x8, [x8, #24]
	cmp	w13, #4
	add	x8, x8, x9
	b.ls	.LBB134_14
	b	.LBB134_9
.LBB134_199:                            //   in Loop: Header=BB134_14 Depth=1
	add	x12, x10, x25
	add	x13, x24, x25
	add	x14, x9, x12
	cmp	x0, x13
	cset	w13, lo
	cmp	x24, x14
	cset	w15, lo
	sub	x12, x12, x8
	and	w15, w13, w15
	sub	x13, x10, x8
	add	x12, x9, x12
	add	x13, x9, x13
	cmp	x0, x12
	mov	x11, xzr
	cset	w12, lo
	cmp	x13, x14
	cset	w13, lo
	tbnz	w15, #0, .LBB134_60
// %bb.200:                             //   in Loop: Header=BB134_14 Depth=1
	and	w12, w12, w13
	tbnz	w12, #0, .LBB134_60
// %bb.201:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #32
	b.hs	.LBB134_229
// %bb.202:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x11, xzr
	b	.LBB134_233
.LBB134_203:                            //   in Loop: Header=BB134_14 Depth=1
	add	x14, x10, x25
	add	x15, x24, x25
	add	x16, x9, x14
	cmp	x0, x15
	cset	w15, lo
	cmp	x24, x16
	add	x12, x12, x14
	cset	w14, lo
	cmp	x0, x12
	mov	x13, xzr
	cset	w12, lo
	cmp	x11, x16
	and	w14, w15, w14
	cset	w11, lo
	tbnz	w14, #0, .LBB134_65
// %bb.204:                             //   in Loop: Header=BB134_14 Depth=1
	and	w11, w12, w11
	tbnz	w11, #0, .LBB134_65
// %bb.205:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #32
	b.hs	.LBB134_236
// %bb.206:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x13, xzr
	b	.LBB134_240
.LBB134_207:                            //   in Loop: Header=BB134_14 Depth=1
	add	x15, x10, x25
	add	x16, x24, x25
	add	x17, x9, x15
	cmp	x0, x16
	cset	w16, lo
	cmp	x24, x17
	add	x12, x12, x15
	cset	w18, lo
	sub	x15, x15, x13
	cmp	x0, x12
	and	w18, w16, w18
	sub	x16, x10, x13
	add	x1, x9, x15
	cset	w12, lo
	cmp	x11, x17
	add	x16, x9, x16
	cset	w15, lo
	cmp	x0, x1
	cset	w11, lo
	cmp	x16, x17
	mov	x14, xzr
	cset	w16, lo
	tbnz	w18, #0, .LBB134_70
// %bb.208:                             //   in Loop: Header=BB134_14 Depth=1
	and	w12, w12, w15
	tbnz	w12, #0, .LBB134_70
// %bb.209:                             //   in Loop: Header=BB134_14 Depth=1
	and	w11, w11, w16
	tbnz	w11, #0, .LBB134_70
// %bb.210:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #32
	b.hs	.LBB134_243
// %bb.211:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x14, xzr
	b	.LBB134_247
.LBB134_212:                            //   in Loop: Header=BB134_14 Depth=1
	add	x17, x10, x13
	add	x18, x24, x13
	add	x3, x9, x17
	sub	x2, x17, x15
	cmp	x0, x18
	sub	x16, x10, x15
	add	x4, x9, x2
	cset	w7, lo
	cmp	x24, x3
	add	x1, x9, x16
	cset	w30, lo
	cmp	x0, x4
	add	x5, x12, x17
	cset	w17, lo
	cmp	x1, x3
	add	x6, x12, x2
	cset	w1, lo
	cmp	x0, x5
	cset	w18, lo
	cmp	x11, x3
	cset	w2, lo
	cmp	x0, x6
	add	x4, x12, x16
	cset	w12, lo
	cmp	x4, x3
	and	w4, w7, w30
	cset	w3, lo
	tbnz	w4, #0, .LBB134_268
// %bb.213:                             //   in Loop: Header=BB134_14 Depth=1
	and	w17, w17, w1
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	mov	w6, #255
	tbnz	w17, #0, .LBB134_269
// %bb.214:                             //   in Loop: Header=BB134_14 Depth=1
	and	w17, w18, w2
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	tbnz	w17, #0, .LBB134_74
// %bb.215:                             //   in Loop: Header=BB134_14 Depth=1
	and	w12, w12, w3
	tbnz	w12, #0, .LBB134_74
// %bb.216:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #16
	b.hs	.LBB134_250
// %bb.217:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x14, xzr
.LBB134_218:                            //   in Loop: Header=BB134_14 Depth=1
	ldur	x17, [x29, #-32]                // 8-byte Folded Reload
	and	x12, x13, #0xfffffff8
	mov	x18, x0
	mov	x2, x11
	mov	x3, x24
	add	x1, x8, x17
	add	x17, x9, x16
	add	x16, x1, x16
	mov	x1, x12
.LBB134_219:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x17, x14]
	add	x17, x17, #8
	ldr	d1, [x2, x14]
	add	x2, x2, #8
	ldr	d2, [x16, x14]
	add	x16, x16, #8
	sub	x1, x1, #8
	ushll	v3.8h, v0.8b, #0
	cmp	x14, x1
	ushll	v4.8h, v1.8b, #0
	ushll	v5.8h, v2.8b, #0
	uaddl	v6.4s, v4.4h, v3.4h
	uaddl2	v7.4s, v4.8h, v3.8h
	usubw	v6.4s, v6.4s, v5.4h
	usubw2	v7.4s, v7.4s, v5.8h
	usubw	v16.4s, v6.4s, v3.4h
	usubw2	v3.4s, v7.4s, v3.8h
	usubw	v17.4s, v6.4s, v4.4h
	usubw2	v4.4s, v7.4s, v4.8h
	usubw	v6.4s, v6.4s, v5.4h
	usubw2	v5.4s, v7.4s, v5.8h
	abs	v3.4s, v3.4s
	abs	v7.4s, v16.4s
	abs	v16.4s, v17.4s
	abs	v4.4s, v4.4s
	abs	v6.4s, v6.4s
	abs	v5.4s, v5.4s
	cmhi	v17.4s, v7.4s, v16.4s
	cmhi	v18.4s, v3.4s, v4.4s
	cmhi	v7.4s, v7.4s, v6.4s
	cmhi	v3.4s, v3.4s, v5.4s
	cmhi	v4.4s, v4.4s, v5.4s
	cmhi	v5.4s, v16.4s, v6.4s
	orr	v6.16b, v17.16b, v7.16b
	orr	v3.16b, v18.16b, v3.16b
	uzp1	v4.8h, v5.8h, v4.8h
	uzp1	v3.8h, v6.8h, v3.8h
	xtn	v4.8b, v4.8h
	bit	v1.8b, v2.8b, v4.8b
	xtn	v2.8b, v3.8h
	ldr	d3, [x3, x14]
	add	x3, x3, #8
	bit	v0.8b, v1.8b, v2.8b
	add	v0.8b, v0.8b, v3.8b
	str	d0, [x18, x14]
	add	x18, x18, #8
	b.ne	.LBB134_219
// %bb.220:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x14, x12
	cmp	x12, x13
	b.ne	.LBB134_74
	b	.LBB134_86
.LBB134_221:                            //   in Loop: Header=BB134_14 Depth=1
	add	x12, x10, x25
	add	x13, x24, x25
	add	x14, x9, x12
	cmp	x0, x13
	cset	w13, lo
	cmp	x24, x14
	cset	w15, lo
	sub	x12, x12, x8
	and	w15, w13, w15
	sub	x13, x10, x8
	add	x12, x9, x12
	add	x13, x9, x13
	cmp	x0, x12
	mov	x11, xzr
	cset	w12, lo
	cmp	x13, x14
	cset	w13, lo
	tbnz	w15, #0, .LBB134_79
// %bb.222:                             //   in Loop: Header=BB134_14 Depth=1
	and	w12, w12, w13
	tbnz	w12, #0, .LBB134_79
// %bb.223:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #32
	b.hs	.LBB134_254
// %bb.224:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x11, xzr
	b	.LBB134_258
.LBB134_225:                            //   in Loop: Header=BB134_14 Depth=1
	add	x12, x10, x25
	add	x13, x24, x25
	add	x14, x9, x12
	cmp	x0, x13
	cset	w13, lo
	cmp	x24, x14
	cset	w15, lo
	sub	x12, x12, x8
	and	w15, w13, w15
	sub	x13, x10, x8
	add	x12, x9, x12
	add	x13, x9, x13
	cmp	x0, x12
	mov	x11, xzr
	cset	w12, lo
	cmp	x13, x14
	cset	w13, lo
	tbnz	w15, #0, .LBB134_84
// %bb.226:                             //   in Loop: Header=BB134_14 Depth=1
	and	w12, w12, w13
	tbnz	w12, #0, .LBB134_84
// %bb.227:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	w25, #32
	b.hs	.LBB134_261
// %bb.228:                             //   in Loop: Header=BB134_14 Depth=1
	mov	x11, xzr
	b	.LBB134_265
.LBB134_229:                            //   in Loop: Header=BB134_14 Depth=1
	and	x11, x25, #0xffffffe0
	add	x13, x9, x10
	add	x12, x24, #16
	add	x13, x13, #16
	neg	x14, x8
	mov	x15, x11
.LBB134_230:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x16, x13, x14
	subs	x15, x15, #32
	ldp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	ldp	q2, q3, [x16, #-16]
	add	v0.16b, v2.16b, v0.16b
	add	v1.16b, v3.16b, v1.16b
	stp	q0, q1, [x13, #-16]
	add	x13, x13, #32
	b.ne	.LBB134_230
// %bb.231:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x11, x25
	b.eq	.LBB134_86
// %bb.232:                             //   in Loop: Header=BB134_14 Depth=1
	tst	x25, #0x18
	b.eq	.LBB134_60
.LBB134_233:                            //   in Loop: Header=BB134_14 Depth=1
	mov	x15, x11
	and	x11, x25, #0xfffffff8
	add	x14, x15, x10
	add	x12, x24, x15
	neg	x13, x8
	add	x14, x9, x14
	sub	x15, x15, x11
.LBB134_234:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x14, x13]
	adds	x15, x15, #8
	ldr	d1, [x12], #8
	add	v0.8b, v0.8b, v1.8b
	str	d0, [x14], #8
	b.ne	.LBB134_234
// %bb.235:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x11, x25
	b.ne	.LBB134_60
	b	.LBB134_86
.LBB134_236:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x14, [sp, #24]                  // 8-byte Folded Reload
	and	x13, x25, #0xffffffe0
	add	x12, x9, x10
	add	x11, x24, #16
	add	x12, x12, #16
	mov	x15, x13
	add	x14, x8, x14
	add	x14, x14, x10
.LBB134_237:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	q0, q1, [x11, #-16]
	subs	x15, x15, #32
	add	x11, x11, #32
	ldp	q2, q3, [x14, #-16]
	add	x14, x14, #32
	add	v0.16b, v2.16b, v0.16b
	add	v1.16b, v3.16b, v1.16b
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB134_237
// %bb.238:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x13, x25
	b.eq	.LBB134_86
// %bb.239:                             //   in Loop: Header=BB134_14 Depth=1
	tst	x25, #0x18
	b.eq	.LBB134_65
.LBB134_240:                            //   in Loop: Header=BB134_14 Depth=1
	ldur	x11, [x29, #-32]                // 8-byte Folded Reload
	mov	x15, x13
	and	x13, x25, #0xfffffff8
	add	x14, x15, x10
	add	x12, x8, x11
	add	x11, x24, x15
	add	x12, x12, x14
	add	x14, x9, x14
	sub	x15, x15, x13
.LBB134_241:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x11], #8
	ldr	d1, [x12], #8
	adds	x15, x15, #8
	add	v0.8b, v1.8b, v0.8b
	str	d0, [x14], #8
	b.ne	.LBB134_241
// %bb.242:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x13, x25
	b.ne	.LBB134_65
	b	.LBB134_86
.LBB134_243:                            //   in Loop: Header=BB134_14 Depth=1
	ldr	x15, [sp, #24]                  // 8-byte Folded Reload
	and	x14, x25, #0xffffffe0
	add	x12, x9, x10
	add	x11, x24, #16
	add	x12, x12, #16
	neg	x16, x13
	add	x15, x8, x15
	mov	x17, x14
	add	x15, x15, x10
.LBB134_244:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x18, x12, x16
	subs	x17, x17, #32
	ldp	q0, q1, [x15, #-16]
	add	x15, x15, #32
	ldp	q2, q3, [x18, #-16]
	uhadd	v0.16b, v2.16b, v0.16b
	ldp	q4, q2, [x11, #-16]
	uhadd	v1.16b, v3.16b, v1.16b
	add	x11, x11, #32
	add	v0.16b, v4.16b, v0.16b
	add	v1.16b, v2.16b, v1.16b
	stp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	b.ne	.LBB134_244
// %bb.245:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x14, x25
	b.eq	.LBB134_86
// %bb.246:                             //   in Loop: Header=BB134_14 Depth=1
	tst	x25, #0x18
	b.eq	.LBB134_70
.LBB134_247:                            //   in Loop: Header=BB134_14 Depth=1
	ldur	x11, [x29, #-32]                // 8-byte Folded Reload
	mov	x17, x14
	and	x14, x25, #0xfffffff8
	add	x16, x17, x10
	neg	x15, x13
	add	x12, x8, x11
	add	x11, x24, x17
	add	x12, x12, x16
	add	x16, x9, x16
	sub	x17, x17, x14
.LBB134_248:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x16, x15]
	adds	x17, x17, #8
	ldr	d1, [x12], #8
	uhadd	v0.8b, v0.8b, v1.8b
	ldr	d1, [x11], #8
	add	v0.8b, v1.8b, v0.8b
	str	d0, [x16], #8
	b.ne	.LBB134_248
// %bb.249:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x14, x25
	b.ne	.LBB134_70
	b	.LBB134_86
.LBB134_250:                            //   in Loop: Header=BB134_14 Depth=1
	and	x14, x13, #0xfffffff0
	neg	x12, x15
	mov	x17, x0
	mov	x18, x14
	mov	x1, x11
	mov	x2, x24
.LBB134_251:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	q0, [x17, x12]
	subs	x18, x18, #16
	ldr	q1, [x1]
	ldr	q2, [x1, x12]
	add	x1, x1, #16
	ushll2	v3.8h, v1.16b, #0
	ushll	v5.8h, v1.8b, #0
	ushll2	v4.8h, v0.16b, #0
	ushll	v6.8h, v0.8b, #0
	ushll	v7.8h, v2.8b, #0
	ushll2	v16.8h, v2.16b, #0
	uaddl2	v17.4s, v3.8h, v4.8h
	uaddl	v18.4s, v3.4h, v4.4h
	uaddl2	v19.4s, v5.8h, v6.8h
	uaddl	v20.4s, v5.4h, v6.4h
	usubw2	v17.4s, v17.4s, v16.8h
	usubw	v18.4s, v18.4s, v16.4h
	usubw2	v19.4s, v19.4s, v7.8h
	usubw	v20.4s, v20.4s, v7.4h
	usubw2	v21.4s, v17.4s, v4.8h
	usubw	v4.4s, v18.4s, v4.4h
	usubw2	v22.4s, v19.4s, v6.8h
	usubw	v6.4s, v20.4s, v6.4h
	usubw2	v23.4s, v17.4s, v3.8h
	usubw	v3.4s, v18.4s, v3.4h
	usubw2	v24.4s, v19.4s, v5.8h
	usubw	v5.4s, v20.4s, v5.4h
	usubw2	v17.4s, v17.4s, v16.8h
	usubw	v16.4s, v18.4s, v16.4h
	usubw2	v18.4s, v19.4s, v7.8h
	usubw	v7.4s, v20.4s, v7.4h
	abs	v21.4s, v21.4s
	abs	v4.4s, v4.4s
	abs	v22.4s, v22.4s
	abs	v6.4s, v6.4s
	abs	v23.4s, v23.4s
	abs	v3.4s, v3.4s
	abs	v24.4s, v24.4s
	abs	v5.4s, v5.4s
	abs	v17.4s, v17.4s
	abs	v16.4s, v16.4s
	abs	v18.4s, v18.4s
	abs	v7.4s, v7.4s
	cmhi	v19.4s, v6.4s, v5.4s
	cmhi	v20.4s, v22.4s, v24.4s
	cmhi	v25.4s, v4.4s, v3.4s
	cmhi	v26.4s, v21.4s, v23.4s
	cmhi	v21.4s, v21.4s, v17.4s
	cmhi	v4.4s, v4.4s, v16.4s
	cmhi	v6.4s, v6.4s, v7.4s
	cmhi	v22.4s, v22.4s, v18.4s
	cmhi	v17.4s, v23.4s, v17.4s
	cmhi	v3.4s, v3.4s, v16.4s
	cmhi	v16.4s, v24.4s, v18.4s
	cmhi	v5.4s, v5.4s, v7.4s
	orr	v21.16b, v26.16b, v21.16b
	orr	v4.16b, v25.16b, v4.16b
	orr	v7.16b, v20.16b, v22.16b
	orr	v6.16b, v19.16b, v6.16b
	uzp1	v3.8h, v3.8h, v17.8h
	uzp1	v5.8h, v5.8h, v16.8h
	uzp1	v4.8h, v4.8h, v21.8h
	uzp1	v6.8h, v6.8h, v7.8h
	uzp1	v3.16b, v5.16b, v3.16b
	uzp1	v4.16b, v6.16b, v4.16b
	bit	v1.16b, v2.16b, v3.16b
	bit	v0.16b, v1.16b, v4.16b
	ldr	q1, [x2], #16
	add	v0.16b, v0.16b, v1.16b
	str	q0, [x17], #16
	b.ne	.LBB134_251
// %bb.252:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x14, x13
	b.eq	.LBB134_86
// %bb.253:                             //   in Loop: Header=BB134_14 Depth=1
	tbz	w13, #3, .LBB134_74
	b	.LBB134_218
.LBB134_254:                            //   in Loop: Header=BB134_14 Depth=1
	and	x11, x25, #0xffffffe0
	add	x13, x9, x10
	add	x12, x24, #16
	add	x13, x13, #16
	neg	x14, x8
	mov	x15, x11
.LBB134_255:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x16, x13, x14
	subs	x15, x15, #32
	ldp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	ldp	q2, q3, [x16, #-16]
	usra	v0.16b, v2.16b, #1
	usra	v1.16b, v3.16b, #1
	stp	q0, q1, [x13, #-16]
	add	x13, x13, #32
	b.ne	.LBB134_255
// %bb.256:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x11, x25
	b.eq	.LBB134_86
// %bb.257:                             //   in Loop: Header=BB134_14 Depth=1
	tst	x25, #0x18
	b.eq	.LBB134_79
.LBB134_258:                            //   in Loop: Header=BB134_14 Depth=1
	mov	x15, x11
	and	x11, x25, #0xfffffff8
	add	x14, x15, x10
	add	x12, x24, x15
	neg	x13, x8
	add	x14, x9, x14
	sub	x15, x15, x11
.LBB134_259:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x14, x13]
	adds	x15, x15, #8
	ldr	d1, [x12], #8
	usra	v1.8b, v0.8b, #1
	str	d1, [x14], #8
	b.ne	.LBB134_259
// %bb.260:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x11, x25
	b.ne	.LBB134_79
	b	.LBB134_86
.LBB134_261:                            //   in Loop: Header=BB134_14 Depth=1
	and	x11, x25, #0xffffffe0
	add	x13, x9, x10
	add	x12, x24, #16
	add	x13, x13, #16
	neg	x14, x8
	mov	x15, x11
.LBB134_262:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	x16, x13, x14
	subs	x15, x15, #32
	ldp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	ldp	q2, q3, [x16, #-16]
	add	v0.16b, v2.16b, v0.16b
	add	v1.16b, v3.16b, v1.16b
	stp	q0, q1, [x13, #-16]
	add	x13, x13, #32
	b.ne	.LBB134_262
// %bb.263:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x11, x25
	b.eq	.LBB134_86
// %bb.264:                             //   in Loop: Header=BB134_14 Depth=1
	tst	x25, #0x18
	b.eq	.LBB134_84
.LBB134_265:                            //   in Loop: Header=BB134_14 Depth=1
	mov	x15, x11
	and	x11, x25, #0xfffffff8
	add	x14, x15, x10
	add	x12, x24, x15
	neg	x13, x8
	add	x14, x9, x14
	sub	x15, x15, x11
.LBB134_266:                            //   Parent Loop BB134_14 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldr	d0, [x14, x13]
	adds	x15, x15, #8
	ldr	d1, [x12], #8
	add	v0.8b, v0.8b, v1.8b
	str	d0, [x14], #8
	b.ne	.LBB134_266
// %bb.267:                             //   in Loop: Header=BB134_14 Depth=1
	cmp	x11, x25
	b.ne	.LBB134_84
	b	.LBB134_86
.LBB134_268:                            //   in Loop: Header=BB134_14 Depth=1
	ldur	x30, [x29, #-16]                // 8-byte Folded Reload
	mov	w6, #255
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	ldur	x5, [x29, #-88]                 // 8-byte Folded Reload
	b	.LBB134_74
.LBB134_269:                            //   in Loop: Header=BB134_14 Depth=1
	ldur	w4, [x29, #-76]                 // 4-byte Folded Reload
	b	.LBB134_74
.LBB134_270:
	ldr	x12, [sp, #96]                  // 8-byte Folded Reload
	cmp	w30, #7
	ldr	x15, [sp, #80]                  // 8-byte Folded Reload
	b.gt	.LBB134_315
// %bb.271:
	ldp	x23, x21, [x29, #-72]           // 16-byte Folded Reload
	sxtw	x11, w15
	lsl	w14, w4, #2
	add	x15, x11, w15, sxtw #1
	lsl	w16, w4, #1
	adrp	x18, _ZL23stbi__depth_scale_table
	mov	w5, wzr
	ldp	w24, w20, [sp, #8]              // 8-byte Folded Reload
	mov	x8, xzr
	neg	x9, x12
	sxtw	x10, w30
	sub	x12, x23, x12
	sub	x13, x11, #1
	sub	w14, w14, #4
	add	x15, x15, #2
	sub	w16, w16, #1
	mov	w17, #255
	add	x18, x18, :lo12:_ZL23stbi__depth_scale_table
	ldur	x22, [x29, #-48]                // 8-byte Folded Reload
	b	.LBB134_273
.LBB134_272:                            //   in Loop: Header=BB134_273 Depth=1
	ldur	x1, [x29, #-24]                 // 8-byte Folded Reload
	add	x8, x8, #1
	add	w5, w0, w23
	mov	w0, #1
	cmp	x8, x1
	b.eq	.LBB134_12
.LBB134_273:                            // =>This Loop Header: Depth=1
                                        //     Child Loop BB134_281 Depth 2
                                        //     Child Loop BB134_299 Depth 2
                                        //     Child Loop BB134_293 Depth 2
                                        //     Child Loop BB134_311 Depth 2
                                        //     Child Loop BB134_314 Depth 2
	cbz	w20, .LBB134_275
// %bb.274:                             //   in Loop: Header=BB134_273 Depth=1
	mov	w1, #1
	b	.LBB134_276
.LBB134_275:                            //   in Loop: Header=BB134_273 Depth=1
	ldrb	w1, [x18, x10]
.LBB134_276:                            //   in Loop: Header=BB134_273 Depth=1
	ldr	x3, [x21, #24]
	mul	w2, w23, w8
	mov	w0, w5
	cmp	w30, #4
	add	x4, x3, x2
	add	x6, x4, x23
	add	x5, x6, x9
	b.eq	.LBB134_291
// %bb.277:                             //   in Loop: Header=BB134_273 Depth=1
	cmp	w30, #2
	b.eq	.LBB134_297
// %bb.278:                             //   in Loop: Header=BB134_273 Depth=1
	cmp	w30, #1
	b.ne	.LBB134_306
// %bb.279:                             //   in Loop: Header=BB134_273 Depth=1
	mov	w6, w24
	cmp	w24, #8
	b.lt	.LBB134_283
// %bb.280:                             //   in Loop: Header=BB134_273 Depth=1
	add	x4, x3, x12
	mov	w6, w24
.LBB134_281:                            //   Parent Loop BB134_273 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrsb	w5, [x4, x0]
	add	x7, x3, x0
	mov	w19, w6
	sub	w6, w6, #8
	add	x3, x3, #8
	cmp	w19, #15
	and	w5, w1, w5, lsr #7
	strb	w5, [x7]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #6, #1
	mul	w5, w5, w1
	strb	w5, [x7, #1]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #5, #1
	mul	w5, w5, w1
	strb	w5, [x7, #2]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #4, #1
	mul	w5, w5, w1
	strb	w5, [x7, #3]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #3, #1
	mul	w5, w5, w1
	strb	w5, [x7, #4]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #2, #1
	mul	w5, w5, w1
	strb	w5, [x7, #5]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #1, #1
	mul	w5, w5, w1
	strb	w5, [x7, #6]
	ldrb	w5, [x4, x0]
	add	x4, x4, #1
	and	w5, w5, #0x1
	mul	w5, w5, w1
	strb	w5, [x7, #7]
	b.hi	.LBB134_281
// %bb.282:                             //   in Loop: Header=BB134_273 Depth=1
	add	x5, x4, x0
	add	x4, x3, x0
.LBB134_283:                            //   in Loop: Header=BB134_273 Depth=1
	cmp	w6, #1
	b.lt	.LBB134_306
// %bb.284:                             //   in Loop: Header=BB134_273 Depth=1
	ldrsb	w3, [x5]
	cmp	w6, #1
	and	w3, w1, w3, lsr #7
	strb	w3, [x4]
	b.eq	.LBB134_306
// %bb.285:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #3
	ubfx	w3, w3, #6, #1
	mul	w3, w3, w1
	strb	w3, [x4, #1]
	b.lo	.LBB134_306
// %bb.286:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #3
	ubfx	w3, w3, #5, #1
	mul	w3, w3, w1
	strb	w3, [x4, #2]
	b.eq	.LBB134_306
// %bb.287:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #5
	ubfx	w3, w3, #4, #1
	mul	w3, w3, w1
	strb	w3, [x4, #3]
	b.lo	.LBB134_306
// %bb.288:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #5
	ubfx	w3, w3, #3, #1
	mul	w3, w3, w1
	strb	w3, [x4, #4]
	b.eq	.LBB134_306
// %bb.289:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #7
	ubfx	w3, w3, #2, #1
	mul	w3, w3, w1
	strb	w3, [x4, #5]
	b.lo	.LBB134_306
// %bb.290:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	add	x4, x4, #6
	ubfx	w3, w3, #1, #1
	b	.LBB134_305
.LBB134_291:                            //   in Loop: Header=BB134_273 Depth=1
	mov	w6, w24
	cmp	w24, #2
	b.lt	.LBB134_295
// %bb.292:                             //   in Loop: Header=BB134_273 Depth=1
	add	x4, x3, x12
	mov	w6, w24
.LBB134_293:                            //   Parent Loop BB134_273 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w5, [x4, x0]
	add	x7, x3, x0
	mov	w19, w6
	sub	w6, w6, #2
	add	x3, x3, #2
	cmp	w19, #3
	lsr	w5, w5, #4
	mul	w5, w5, w1
	strb	w5, [x7]
	ldrb	w5, [x4, x0]
	add	x4, x4, #1
	and	w5, w5, #0xf
	mul	w5, w5, w1
	strb	w5, [x7, #1]
	b.hi	.LBB134_293
// %bb.294:                             //   in Loop: Header=BB134_273 Depth=1
	add	x5, x4, x0
	add	x4, x3, x0
.LBB134_295:                            //   in Loop: Header=BB134_273 Depth=1
	cmp	w6, #1
	b.ne	.LBB134_306
// %bb.296:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	lsr	w3, w3, #4
	b	.LBB134_305
.LBB134_297:                            //   in Loop: Header=BB134_273 Depth=1
	mov	w6, w24
	cmp	w24, #4
	b.lt	.LBB134_301
// %bb.298:                             //   in Loop: Header=BB134_273 Depth=1
	add	x4, x3, x12
	mov	w6, w24
.LBB134_299:                            //   Parent Loop BB134_273 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldrb	w5, [x4, x0]
	add	x7, x3, x0
	mov	w19, w6
	sub	w6, w6, #4
	add	x3, x3, #4
	cmp	w19, #7
	lsr	w5, w5, #6
	mul	w5, w5, w1
	strb	w5, [x7]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #4, #2
	mul	w5, w5, w1
	strb	w5, [x7, #1]
	ldrb	w5, [x4, x0]
	ubfx	w5, w5, #2, #2
	mul	w5, w5, w1
	strb	w5, [x7, #2]
	ldrb	w5, [x4, x0]
	add	x4, x4, #1
	and	w5, w5, #0x3
	mul	w5, w5, w1
	strb	w5, [x7, #3]
	b.hi	.LBB134_299
// %bb.300:                             //   in Loop: Header=BB134_273 Depth=1
	add	x5, x4, x0
	add	x4, x3, x0
.LBB134_301:                            //   in Loop: Header=BB134_273 Depth=1
	cmp	w6, #1
	b.lt	.LBB134_306
// %bb.302:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #1
	lsr	w3, w3, #6
	mul	w3, w3, w1
	strb	w3, [x4]
	b.eq	.LBB134_306
// %bb.303:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	cmp	w6, #3
	ubfx	w3, w3, #4, #2
	mul	w3, w3, w1
	strb	w3, [x4, #1]
	b.lo	.LBB134_306
// %bb.304:                             //   in Loop: Header=BB134_273 Depth=1
	ldrb	w3, [x5]
	add	x4, x4, #2
	ubfx	w3, w3, #2, #2
.LBB134_305:                            //   in Loop: Header=BB134_273 Depth=1
	mul	w1, w3, w1
	strb	w1, [x4]
.LBB134_306:                            //   in Loop: Header=BB134_273 Depth=1
	cmp	w27, w22
	b.eq	.LBB134_272
// %bb.307:                             //   in Loop: Header=BB134_273 Depth=1
	ldr	x3, [x21, #24]
	cmp	w27, #1
	add	x1, x3, x2
	b.eq	.LBB134_312
// %bb.308:                             //   in Loop: Header=BB134_273 Depth=1
	cmp	w27, #3
	b.ne	.LBB134_319
// %bb.309:                             //   in Loop: Header=BB134_273 Depth=1
	tbnz	w11, #31, .LBB134_272
// %bb.310:                             //   in Loop: Header=BB134_273 Depth=1
	add	x2, x3, x15
	mov	w3, w14
	add	x2, x2, x0
	mov	x4, x13
.LBB134_311:                            //   Parent Loop BB134_273 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add	w5, w3, #3
	add	w6, w3, #2
	add	w7, w3, #1
	strb	w17, [x1, w5, sxtw]
	ldrb	w5, [x2]
	strb	w5, [x1, w6, sxtw]
	ldurb	w5, [x2, #-1]
	strb	w5, [x1, w7, sxtw]
	sub	x5, x4, #1
	ldurb	w6, [x2, #-2]
	mov	w7, w4
	sub	x2, x2, #3
	mov	x4, x5
	strb	w6, [x1, w3, sxtw]
	sub	w3, w3, #4
	tbz	w7, #31, .LBB134_311
	b	.LBB134_272
.LBB134_312:                            //   in Loop: Header=BB134_273 Depth=1
	tbnz	w11, #31, .LBB134_272
// %bb.313:                             //   in Loop: Header=BB134_273 Depth=1
	add	x2, x3, x0
	mov	w3, w16
	mov	x4, x11
.LBB134_314:                            //   Parent Loop BB134_273 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	strb	w17, [x1, w3, sxtw]
	sub	w5, w3, #1
	ldrb	w6, [x2, x4]
	sub	x4, x4, #1
	sub	w3, w3, #2
	strb	w6, [x1, w5, sxtw]
	tbz	w4, #31, .LBB134_314
	b	.LBB134_272
.LBB134_315:
	mov	w0, #1
	b	.LBB134_12
.LBB134_316:
	adrp	x0, .L.str.59
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	add	x0, x0, :lo12:.L.str.59
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	mov	w2, #3966
	bl	__assert_fail
.LBB134_317:
	adrp	x0, .L.str.62
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	add	x0, x0, :lo12:.L.str.62
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	mov	w2, #3988
	bl	__assert_fail
.LBB134_318:
	adrp	x0, .L.str.63
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	add	x0, x0, :lo12:.L.str.63
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	mov	w2, #4041
	bl	__assert_fail
.LBB134_319:
	adrp	x0, .L.str.64
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	add	x0, x0, :lo12:.L.str.64
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	mov	w2, #4121
	bl	__assert_fail
.Lfunc_end134:
	.size	_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii, .Lfunc_end134-_ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
	.cfi_endproc
	.section	.rodata,"a",@progbits
.LJTI134_0:
	.byte	(.LBB134_21-.LBB134_21)>>2
	.byte	(.LBB134_21-.LBB134_21)>>2
	.byte	(.LBB134_26-.LBB134_21)>>2
	.byte	(.LBB134_27-.LBB134_21)>>2
	.byte	(.LBB134_26-.LBB134_21)>>2
	.byte	(.LBB134_21-.LBB134_21)>>2
	.byte	(.LBB134_21-.LBB134_21)>>2
	.p2align	1
.LJTI134_1:
	.hword	(.LBB134_35-.LBB134_35)>>2
	.hword	(.LBB134_87-.LBB134_35)>>2
	.hword	(.LBB134_104-.LBB134_35)>>2
	.hword	(.LBB134_121-.LBB134_35)>>2
	.hword	(.LBB134_141-.LBB134_35)>>2
	.hword	(.LBB134_162-.LBB134_35)>>2
	.hword	(.LBB134_179-.LBB134_35)>>2
.LJTI134_2:
	.byte	(.LBB134_56-.LBB134_56)>>2
	.byte	(.LBB134_57-.LBB134_56)>>2
	.byte	(.LBB134_62-.LBB134_56)>>2
	.byte	(.LBB134_67-.LBB134_56)>>2
	.byte	(.LBB134_72-.LBB134_56)>>2
	.byte	(.LBB134_76-.LBB134_56)>>2
	.byte	(.LBB134_81-.LBB134_56)>>2
                                        // -- End function
	.text
	.p2align	2                               // -- Begin function _ZL13stbi__get32leP13stbi__context
	.type	_ZL13stbi__get32leP13stbi__context,@function
_ZL13stbi__get32leP13stbi__context:     // @_ZL13stbi__get32leP13stbi__context
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x9, x8, [x0, #184]
	mov	x19, x0
	cmp	x9, x8
	b.hs	.LBB135_2
// %bb.1:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w20, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB135_6
	b	.LBB135_12
.LBB135_2:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB135_5
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB135_10
// %bb.4:
	mov	x8, x19
	ldrb	w20, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB135_11
.LBB135_5:
	mov	w20, wzr
	cmp	x9, x8
	b.lo	.LBB135_12
.LBB135_6:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB135_9
// %bb.7:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB135_14
// %bb.8:
	mov	x8, x19
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB135_15
.LBB135_9:
	mov	w21, wzr
	cmp	x9, x8
	b.lo	.LBB135_13
	b	.LBB135_16
.LBB135_10:
	mov	w20, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB135_11:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB135_6
.LBB135_12:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB135_16
.LBB135_13:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w22, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB135_20
	b	.LBB135_25
.LBB135_14:
	mov	w21, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB135_15:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB135_13
.LBB135_16:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB135_19
// %bb.17:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB135_23
// %bb.18:
	mov	x8, x19
	ldrb	w22, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB135_24
.LBB135_19:
	mov	w22, wzr
	cmp	x9, x8
	b.lo	.LBB135_25
.LBB135_20:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB135_28
// %bb.21:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB135_26
// %bb.22:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB135_27
.LBB135_23:
	mov	w22, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB135_24:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB135_20
.LBB135_25:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB135_28
.LBB135_26:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB135_27:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB135_28:
	lsl	w9, w22, #16
	bfi	w20, w21, #8, #8
	bfi	w9, w8, #24, #8
	orr	w0, w9, w20
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end135:
	.size	_ZL13stbi__get32leP13stbi__context, .Lfunc_end135-_ZL13stbi__get32leP13stbi__context
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__high_bitj
	.type	_ZL14stbi__high_bitj,@function
_ZL14stbi__high_bitj:                   // @_ZL14stbi__high_bitj
	.cfi_startproc
// %bb.0:
	cbz	w0, .LBB136_2
// %bb.1:
	lsr	w8, w0, #16
	mov	w11, #8
	cmp	w8, #0
	cset	w9, ne
	csel	w8, w8, w0, ne
	lsr	w10, w8, #8
	cmp	w8, #255
	csel	w8, w10, w8, hi
	lsl	w10, w9, #4
	bfi	w11, w9, #4, #1
	lsr	w9, w8, #4
	csel	w10, w11, w10, hi
	cmp	w8, #15
	orr	w11, w10, #0x4
	csel	w8, w9, w8, hi
	csel	w9, w11, w10, hi
	lsr	w10, w8, #2
	cmp	w8, #3
	orr	w11, w9, #0x2
	csel	w8, w10, w8, hi
	csel	w9, w11, w9, hi
	cmp	w8, #1
	cinc	w0, w9, hi
	ret
.LBB136_2:
	mov	w0, #-1
	ret
.Lfunc_end136:
	.size	_ZL14stbi__high_bitj, .Lfunc_end136-_ZL14stbi__high_bitj
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__bitcountj
	.type	_ZL14stbi__bitcountj,@function
_ZL14stbi__bitcountj:                   // @_ZL14stbi__bitcountj
	.cfi_startproc
// %bb.0:
	lsr	w8, w0, #1
	and	w9, w0, #0x55555555
	and	w8, w8, #0x55555555
	add	w8, w8, w9
	lsr	w9, w8, #2
	and	w8, w8, #0x33333333
	and	w9, w9, #0x33333333
	add	w8, w9, w8
	add	w8, w8, w8, lsr #4
	and	w8, w8, #0xf0f0f0f
	add	w8, w8, w8, lsr #8
	add	w8, w8, w8, lsr #16
	and	w0, w8, #0x3f
	ret
.Lfunc_end137:
	.size	_ZL14stbi__bitcountj, .Lfunc_end137-_ZL14stbi__bitcountj
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii
	.type	_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii,@function
_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii: // @_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x9, x8, [x0, #184]
	mov	w21, w3
	mov	x22, x2
	mov	x19, x0
	mov	x20, x1
	cmp	x9, x8
	b.hs	.LBB138_2
// %bb.1:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w9, [x9]
	cmp	w9, #71
	b.eq	.LBB138_6
	b	.LBB138_44
.LBB138_2:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_44
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_5
// %bb.4:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	w9, #71
	b.eq	.LBB138_6
	b	.LBB138_44
.LBB138_5:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	w9, #71
	b.ne	.LBB138_44
.LBB138_6:
	cmp	x10, x8
	b.hs	.LBB138_8
// %bb.7:
	add	x11, x10, #1
	str	x11, [x19, #184]
	ldrb	w9, [x10]
	cmp	w9, #73
	b.eq	.LBB138_12
	b	.LBB138_44
.LBB138_8:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_44
// %bb.9:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_11
// %bb.10:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x11, x19, #57
	stp	x11, x8, [x19, #184]
	cmp	w9, #73
	b.eq	.LBB138_12
	b	.LBB138_44
.LBB138_11:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x11, x19, #57
	stp	x11, x8, [x19, #184]
	cmp	w9, #73
	b.ne	.LBB138_44
.LBB138_12:
	cmp	x11, x8
	b.hs	.LBB138_14
// %bb.13:
	add	x10, x11, #1
	str	x10, [x19, #184]
	ldrb	w9, [x11]
	cmp	w9, #70
	b.eq	.LBB138_18
	b	.LBB138_44
.LBB138_14:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_44
// %bb.15:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_17
// %bb.16:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	w9, #70
	b.eq	.LBB138_18
	b	.LBB138_44
.LBB138_17:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	w9, #70
	b.ne	.LBB138_44
.LBB138_18:
	cmp	x10, x8
	b.hs	.LBB138_20
// %bb.19:
	add	x11, x10, #1
	str	x11, [x19, #184]
	ldrb	w9, [x10]
	cmp	w9, #56
	b.eq	.LBB138_25
	b	.LBB138_44
.LBB138_20:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_44
// %bb.21:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_23
// %bb.22:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_24
.LBB138_23:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_24:
	add	x11, x19, #57
	stp	x11, x8, [x19, #184]
	cmp	w9, #56
	b.ne	.LBB138_44
.LBB138_25:
	cmp	x11, x8
	b.hs	.LBB138_27
// %bb.26:
	add	x10, x11, #1
	str	x10, [x19, #184]
	ldrb	w9, [x11]
	b	.LBB138_32
.LBB138_27:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_44
// %bb.28:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_30
// %bb.29:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_31
.LBB138_30:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_31:
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
.LBB138_32:
	cmp	w9, #55
	b.eq	.LBB138_34
// %bb.33:
	cmp	w9, #57
	b.ne	.LBB138_44
.LBB138_34:
	cmp	x10, x8
	b.hs	.LBB138_36
// %bb.35:
	add	x9, x10, #1
	str	x9, [x19, #184]
	ldrb	w10, [x10]
	b	.LBB138_41
.LBB138_36:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_44
// %bb.37:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_39
// %bb.38:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_40
.LBB138_39:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_40:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_41:
	cmp	w10, #97
	b.ne	.LBB138_44
// %bb.42:
	adrp	x11, .L.str.82
	adrp	x10, .L_MergedGlobals.126+8
	add	x11, x11, :lo12:.L.str.82
	cmp	x9, x8
	str	x11, [x10, :lo12:.L_MergedGlobals.126+8]
	b.hs	.LBB138_45
// %bb.43:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	b	.LBB138_51
.LBB138_44:
	adrp	x9, .L.str.81
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.81
	mov	w0, wzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB138_45:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB138_48
// %bb.46:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_49
// %bb.47:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_50
.LBB138_48:
	mov	w23, wzr
	b	.LBB138_51
.LBB138_49:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_50:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_51:
	cmp	x9, x8
	b.hs	.LBB138_53
// %bb.52:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB138_58
.LBB138_53:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB138_58
// %bb.54:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_56
// %bb.55:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_57
.LBB138_56:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_57:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_58:
	bfi	w23, w10, #8, #8
	cmp	x9, x8
	str	w23, [x20]
	b.hs	.LBB138_60
// %bb.59:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	b	.LBB138_66
.LBB138_60:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB138_63
// %bb.61:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_64
// %bb.62:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_65
.LBB138_63:
	mov	w23, wzr
	b	.LBB138_66
.LBB138_64:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_65:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_66:
	cmp	x9, x8
	b.hs	.LBB138_68
// %bb.67:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB138_73
.LBB138_68:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB138_73
// %bb.69:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_71
// %bb.70:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_72
.LBB138_71:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_72:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_73:
	bfi	w23, w10, #8, #8
	cmp	x9, x8
	str	w23, [x20, #4]
	b.hs	.LBB138_75
// %bb.74:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB138_80
.LBB138_75:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB138_80
// %bb.76:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_78
// %bb.77:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_79
.LBB138_78:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_79:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_80:
	cmp	x9, x8
	str	w10, [x20, #16]
	b.hs	.LBB138_82
// %bb.81:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB138_87
.LBB138_82:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB138_87
// %bb.83:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_85
// %bb.84:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB138_86
.LBB138_85:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_86:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB138_87:
	cmp	x9, x8
	str	w10, [x20, #20]
	b.hs	.LBB138_89
// %bb.88:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB138_94
.LBB138_89:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB138_94
// %bb.90:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB138_92
// %bb.91:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB138_93
.LBB138_92:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB138_93:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB138_94:
	mov	w9, #-1
	stp	w8, w9, [x20, #24]
	cbz	x22, .LBB138_96
// %bb.95:
	mov	w8, #4
	str	w8, [x22]
.LBB138_96:
	cbnz	w21, .LBB138_99
// %bb.97:
	ldr	w8, [x20, #16]
	tbz	w8, #7, .LBB138_99
// %bb.98:
	and	w8, w8, #0x7
	mov	w9, #2
	add	x1, x20, #36
	mov	x0, x19
	mov	w3, #-1
	lsl	w2, w9, w8
	bl	_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii
.LBB138_99:
	mov	w0, #1
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end138:
	.size	_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii, .Lfunc_end138-_ZL16stbi__gif_headerP13stbi__contextP9stbi__gifPii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii
	.type	_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii,@function
_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii: // @_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	stp	x24, x23, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	cmp	w2, #1
	b.lt	.LBB139_24
// %bb.1:
	mov	x19, x0
	add	x20, x0, #56
	add	x21, x0, #57
	mov	w22, w3
	mov	w23, w2
	add	x24, x1, #3
	b	.LBB139_4
.LBB139_2:                              //   in Loop: Header=BB139_4 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
.LBB139_3:                              //   in Loop: Header=BB139_4 Depth=1
	subs	x22, x22, #1
	sturb	w8, [x24, #-3]
	cset	w9, hs
	subs	x23, x23, #1
	sbfx	w9, w9, #0, #1
	strb	w9, [x24], #4
	b.eq	.LBB139_24
.LBB139_4:                              // =>This Inner Loop Header: Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB139_6
// %bb.5:                               //   in Loop: Header=BB139_4 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB139_11
.LBB139_6:                              //   in Loop: Header=BB139_4 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB139_11
// %bb.7:                               //   in Loop: Header=BB139_4 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB139_9
// %bb.8:                               //   in Loop: Header=BB139_4 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB139_10
.LBB139_9:                              //   in Loop: Header=BB139_4 Depth=1
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB139_10:                             //   in Loop: Header=BB139_4 Depth=1
	stp	x21, x9, [x19, #184]
.LBB139_11:                             //   in Loop: Header=BB139_4 Depth=1
	sturb	w8, [x24, #-1]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB139_13
// %bb.12:                              //   in Loop: Header=BB139_4 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w8, [x8]
	b	.LBB139_18
.LBB139_13:                             //   in Loop: Header=BB139_4 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB139_18
// %bb.14:                              //   in Loop: Header=BB139_4 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB139_16
// %bb.15:                              //   in Loop: Header=BB139_4 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB139_17
.LBB139_16:                             //   in Loop: Header=BB139_4 Depth=1
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB139_17:                             //   in Loop: Header=BB139_4 Depth=1
	stp	x21, x9, [x19, #184]
.LBB139_18:                             //   in Loop: Header=BB139_4 Depth=1
	sturb	w8, [x24, #-2]
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB139_2
// %bb.19:                              //   in Loop: Header=BB139_4 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB139_3
// %bb.20:                              //   in Loop: Header=BB139_4 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x20
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB139_22
// %bb.21:                              //   in Loop: Header=BB139_4 Depth=1
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB139_23
.LBB139_22:                             //   in Loop: Header=BB139_4 Depth=1
	mov	w8, wzr
	mov	x9, x21
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB139_23:                             //   in Loop: Header=BB139_4 Depth=1
	stp	x21, x9, [x19, #184]
	b	.LBB139_3
.LBB139_24:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end139:
	.size	_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii, .Lfunc_end139-_ZL26stbi__gif_parse_colortableP13stbi__contextPA4_hii
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL18stbi__out_gif_codeP9stbi__gift
	.type	_ZL18stbi__out_gif_codeP9stbi__gift,@function
_ZL18stbi__out_gif_codeP9stbi__gift:    // @_ZL18stbi__out_gif_codeP9stbi__gift
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	add	x9, x0, w1, uxth #2
	mov	w8, #18480
	mov	w20, w1
	mov	x19, x0
	add	x21, x0, x8
	ldrsh	w1, [x9, #2084]
	tbnz	w1, #31, .LBB140_2
// %bb.1:
	mov	x0, x19
	bl	_ZL18stbi__out_gif_codeP9stbi__gift
.LBB140_2:
	ldr	w8, [x21, #32]
	ldr	w9, [x21, #24]
	cmp	w8, w9
	b.ge	.LBB140_10
// %bb.3:
	and	x9, x20, #0xffff
	ldr	x10, [x19, #18472]
	add	x9, x19, x9, lsl #2
	ldrb	w9, [x9, #2087]
	add	x9, x10, x9, lsl #2
	ldr	w10, [x21, #28]
	ldrsb	w11, [x9, #3]
	tbnz	w11, #31, .LBB140_5
// %bb.4:
	ldr	w8, [x21, #20]
	add	w9, w10, #4
	cmp	w9, w8
	str	w9, [x21, #28]
	b.ge	.LBB140_6
	b	.LBB140_10
.LBB140_5:
	ldr	x11, [x19, #8]
	add	w8, w10, w8
	ldrb	w10, [x9, #2]
	add	x8, x11, w8, sxtw
	strb	w10, [x8]
	ldrb	w10, [x9, #1]
	strb	w10, [x8, #1]
	ldrb	w10, [x9]
	strb	w10, [x8, #2]
	ldrb	w9, [x9, #3]
	strb	w9, [x8, #3]
	ldr	w10, [x21, #28]
	ldr	w8, [x21, #20]
	add	w9, w10, #4
	cmp	w9, w8
	str	w9, [x21, #28]
	b.lt	.LBB140_10
.LBB140_6:
	ldr	w9, [x21, #4]
	ldr	w10, [x21, #32]
	ldr	w8, [x21, #24]
	ldr	w11, [x21, #12]
	add	w9, w10, w9
	cmp	w9, w8
	stp	w11, w9, [x21, #28]
	b.lt	.LBB140_10
// %bb.7:
	ldr	w9, [x21]
.LBB140_8:                              // =>This Inner Loop Header: Depth=1
	subs	w10, w9, #1
	b.lt	.LBB140_10
// %bb.9:                               //   in Loop: Header=BB140_8 Depth=1
	ldr	w11, [x21, #36]
	ldr	w12, [x21, #16]
	lsl	w11, w11, w9
	mov	w9, w10
	add	w12, w12, w11, asr #1
	cmp	w12, w8
	stp	w10, w11, [x21]
	str	w12, [x21, #32]
	b.ge	.LBB140_8
.LBB140_10:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end140:
	.size	_ZL18stbi__out_gif_codeP9stbi__gift, .Lfunc_end140-_ZL18stbi__out_gif_codeP9stbi__gift
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL13stbi__pic_is4P13stbi__contextPKc
	.type	_ZL13stbi__pic_is4P13stbi__contextPKc,@function
_ZL13stbi__pic_is4P13stbi__contextPKc:  // @_ZL13stbi__pic_is4P13stbi__contextPKc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	stp	x22, x21, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x9, x8, [x0, #184]
	mov	x19, x1
	mov	x20, x0
	add	x21, x0, #56
	add	x22, x0, #57
	cmp	x9, x8
	b.hs	.LBB141_2
// %bb.1:
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB141_7
.LBB141_2:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB141_7
// %bb.3:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB141_5
// %bb.4:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB141_6
.LBB141_5:
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB141_6:
	mov	x9, x22
	stp	x22, x8, [x20, #184]
.LBB141_7:
	ldrb	w11, [x19]
	cmp	w10, w11
	b.ne	.LBB141_26
// %bb.8:
	cmp	x9, x8
	b.hs	.LBB141_10
// %bb.9:
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB141_15
.LBB141_10:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB141_15
// %bb.11:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB141_13
// %bb.12:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB141_14
.LBB141_13:
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB141_14:
	mov	x9, x22
	stp	x22, x8, [x20, #184]
.LBB141_15:
	ldrb	w11, [x19, #1]
	cmp	w10, w11
	b.ne	.LBB141_26
// %bb.16:
	cmp	x9, x8
	b.hs	.LBB141_18
// %bb.17:
	add	x11, x9, #1
	str	x11, [x20, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	b	.LBB141_23
.LBB141_18:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB141_23
// %bb.19:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB141_21
// %bb.20:
	mov	x8, x20
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB141_22
.LBB141_21:
	mov	w10, wzr
	mov	x8, x22
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB141_22:
	mov	x9, x22
	stp	x22, x8, [x20, #184]
.LBB141_23:
	ldrb	w11, [x19, #2]
	cmp	w10, w11
	b.ne	.LBB141_26
// %bb.24:
	cmp	x9, x8
	b.hs	.LBB141_27
// %bb.25:
	add	x8, x9, #1
	str	x8, [x20, #184]
	ldrb	w8, [x9]
	b	.LBB141_32
.LBB141_26:
	mov	w0, wzr
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB141_27:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB141_32
// %bb.28:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB141_30
// %bb.29:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB141_31
.LBB141_30:
	mov	w8, wzr
	mov	x9, x22
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB141_31:
	stp	x22, x9, [x20, #184]
.LBB141_32:
	ldrb	w9, [x19, #3]
	cmp	w8, w9
	cset	w0, eq
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end141:
	.size	_ZL13stbi__pic_is4P13stbi__contextPKc, .Lfunc_end141-_ZL13stbi__pic_is4P13stbi__contextPKc
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL13stbi__readvalP13stbi__contextiPh
	.type	_ZL13stbi__readvalP13stbi__contextiPh,@function
_ZL13stbi__readvalP13stbi__contextiPh:  // @_ZL13stbi__readvalP13stbi__contextiPh
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x19, x2
	mov	w22, w1
	mov	x20, x0
	add	x21, x0, #56
	add	x23, x0, #57
	tbz	w1, #7, .LBB142_14
// %bb.1:
	ldr	x8, [x20, #16]
	cbz	x8, .LBB142_4
// %bb.2:
	ldp	x8, x0, [x20, #32]
	blr	x8
	cbz	w0, .LBB142_7
// %bb.3:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_47
.LBB142_4:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB142_47
// %bb.5:
	cmp	x8, x9
	b.hs	.LBB142_8
.LBB142_6:
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w8, [x8]
	b	.LBB142_13
.LBB142_7:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.lo	.LBB142_6
.LBB142_8:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_13
// %bb.9:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB142_11
// %bb.10:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB142_12
.LBB142_11:
	mov	w8, wzr
	mov	x9, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB142_12:
	stp	x23, x9, [x20, #184]
.LBB142_13:
	strb	w8, [x19]
.LBB142_14:
	tbz	w22, #6, .LBB142_28
// %bb.15:
	ldr	x8, [x20, #16]
	cbz	x8, .LBB142_18
// %bb.16:
	ldp	x8, x0, [x20, #32]
	blr	x8
	cbz	w0, .LBB142_21
// %bb.17:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_47
.LBB142_18:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB142_47
// %bb.19:
	cmp	x8, x9
	b.hs	.LBB142_22
.LBB142_20:
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w8, [x8]
	b	.LBB142_27
.LBB142_21:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.lo	.LBB142_20
.LBB142_22:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_27
// %bb.23:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB142_25
// %bb.24:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB142_26
.LBB142_25:
	mov	w8, wzr
	mov	x9, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB142_26:
	stp	x23, x9, [x20, #184]
.LBB142_27:
	strb	w8, [x19, #1]
.LBB142_28:
	tbz	w22, #5, .LBB142_42
// %bb.29:
	ldr	x8, [x20, #16]
	cbz	x8, .LBB142_32
// %bb.30:
	ldp	x8, x0, [x20, #32]
	blr	x8
	cbz	w0, .LBB142_35
// %bb.31:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_47
.LBB142_32:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB142_47
// %bb.33:
	cmp	x8, x9
	b.hs	.LBB142_36
.LBB142_34:
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w8, [x8]
	b	.LBB142_41
.LBB142_35:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.lo	.LBB142_34
.LBB142_36:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_41
// %bb.37:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB142_39
// %bb.38:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB142_40
.LBB142_39:
	mov	w8, wzr
	mov	x9, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB142_40:
	stp	x23, x9, [x20, #184]
.LBB142_41:
	strb	w8, [x19, #2]
.LBB142_42:
	tbz	w22, #4, .LBB142_48
// %bb.43:
	ldr	x8, [x20, #16]
	cbz	x8, .LBB142_46
// %bb.44:
	ldp	x8, x0, [x20, #32]
	blr	x8
	cbz	w0, .LBB142_49
// %bb.45:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_47
.LBB142_46:
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.lo	.LBB142_50
.LBB142_47:
	adrp	x9, .L.str.94
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.94
	mov	x19, xzr
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
.LBB142_48:
	mov	x0, x19
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB142_49:
	ldp	x8, x9, [x20, #184]
.LBB142_50:
	cmp	x8, x9
	b.hs	.LBB142_52
// %bb.51:
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w8, [x8]
	b	.LBB142_57
.LBB142_52:
	ldr	w8, [x20, #48]
	cbz	w8, .LBB142_57
// %bb.53:
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB142_55
// %bb.54:
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB142_56
.LBB142_55:
	mov	w8, wzr
	mov	x9, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB142_56:
	stp	x23, x9, [x20, #184]
.LBB142_57:
	strb	w8, [x19, #3]
	mov	x0, x19
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end142:
	.size	_ZL13stbi__readvalP13stbi__contextiPh, .Lfunc_end142-_ZL13stbi__readvalP13stbi__contextiPh
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_
	.type	_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_,@function
_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_: // @_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	stp	x26, x25, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	ldp	x8, x10, [x0, #192]
	mov	x21, x3
	mov	x20, x2
	mov	x19, x0
	mov	x22, x1
	cmp	x10, x8
	str	x10, [x0, #184]
	b.hs	.LBB143_2
// %bb.1:
	add	x9, x10, #1
	str	x9, [x19, #184]
	ldrb	w23, [x10]
	mov	x10, x9
	cmp	x10, x8
	b.hs	.LBB143_6
	b	.LBB143_11
.LBB143_2:
	ldr	w9, [x19, #48]
	cbz	w9, .LBB143_5
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_9
// %bb.4:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_10
.LBB143_5:
	mov	w23, wzr
	cmp	x10, x8
	b.lo	.LBB143_11
.LBB143_6:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_17
// %bb.7:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_12
// %bb.8:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_13
.LBB143_9:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_10:
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	cmp	x10, x8
	b.hs	.LBB143_6
.LBB143_11:
	add	x9, x10, #1
	str	x9, [x19, #184]
	ldrb	w10, [x10]
	cmp	w23, #80
	b.eq	.LBB143_14
	b	.LBB143_17
.LBB143_12:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_13:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w23, #80
	b.ne	.LBB143_17
.LBB143_14:
	sub	w11, w10, #55
	cmn	w11, #3
	b.ls	.LBB143_17
// %bb.15:
	cmp	w10, #54
	mov	w10, #3
	csinc	w10, w10, wzr, eq
	cmp	x9, x8
	str	w10, [x21]
	b.hs	.LBB143_18
// %bb.16:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w24, [x9]
	mov	x9, x10
	b	.LBB143_24
.LBB143_17:
	ldr	x8, [x19, #200]
	mov	w0, wzr
	str	x8, [x19, #184]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB143_18:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB143_21
// %bb.19:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_22
// %bb.20:
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_23
.LBB143_21:
	mov	w24, wzr
	b	.LBB143_24
.LBB143_22:
	mov	w24, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_23:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB143_24:
	add	x21, x19, #56
	add	x23, x19, #57
	b	.LBB143_26
.LBB143_25:                             //   in Loop: Header=BB143_26 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w24, [x9]
	mov	x9, x10
.LBB143_26:                             // =>This Inner Loop Header: Depth=1
	ldr	x10, [x19, #16]
	cbz	x10, .LBB143_30
// %bb.27:                              //   in Loop: Header=BB143_26 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB143_31
// %bb.28:                              //   in Loop: Header=BB143_26 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_39
// %bb.29:                              //   in Loop: Header=BB143_26 Depth=1
	ldp	x9, x8, [x19, #184]
.LBB143_30:                             //   in Loop: Header=BB143_26 Depth=1
	cmp	x9, x8
	b.hs	.LBB143_39
.LBB143_31:                             //   in Loop: Header=BB143_26 Depth=1
	sub	w8, w24, #9
	cmp	w8, #5
	b.hs	.LBB143_36
.LBB143_32:                             //   in Loop: Header=BB143_26 Depth=1
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB143_25
// %bb.33:                              //   in Loop: Header=BB143_26 Depth=1
	ldr	w10, [x19, #48]
	mov	w24, wzr
	cbz	w10, .LBB143_26
// %bb.34:                              //   in Loop: Header=BB143_26 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_37
// %bb.35:                              //   in Loop: Header=BB143_26 Depth=1
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_38
.LBB143_36:                             //   in Loop: Header=BB143_26 Depth=1
	cmp	w24, #32
	b.eq	.LBB143_32
	b	.LBB143_39
.LBB143_37:                             //   in Loop: Header=BB143_26 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_38:                             //   in Loop: Header=BB143_26 Depth=1
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	b	.LBB143_26
.LBB143_39:
	mov	w25, wzr
	mov	w26, #10
	b	.LBB143_41
.LBB143_40:                             //   in Loop: Header=BB143_41 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w24, [x8]
.LBB143_41:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #16]
	cbz	x8, .LBB143_44
// %bb.42:                              //   in Loop: Header=BB143_41 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB143_50
// %bb.43:                              //   in Loop: Header=BB143_41 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_54
.LBB143_44:                             //   in Loop: Header=BB143_41 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB143_54
// %bb.45:                              //   in Loop: Header=BB143_41 Depth=1
	sub	w10, w24, #58
	cmn	w10, #10
	b.lo	.LBB143_54
// %bb.46:                              //   in Loop: Header=BB143_41 Depth=1
	madd	w10, w25, w26, w24
	cmp	x8, x9
	sub	w25, w10, #48
	b.lo	.LBB143_40
.LBB143_47:                             //   in Loop: Header=BB143_41 Depth=1
	ldr	w8, [x19, #48]
	mov	w24, wzr
	cbz	w8, .LBB143_41
// %bb.48:                              //   in Loop: Header=BB143_41 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_52
// %bb.49:                              //   in Loop: Header=BB143_41 Depth=1
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_53
.LBB143_50:                             //   in Loop: Header=BB143_41 Depth=1
	sub	w8, w24, #58
	cmn	w8, #10
	b.lo	.LBB143_54
// %bb.51:                              //   in Loop: Header=BB143_41 Depth=1
	ldp	x8, x9, [x19, #184]
	madd	w10, w25, w26, w24
	cmp	x8, x9
	sub	w25, w10, #48
	b.lo	.LBB143_40
	b	.LBB143_47
.LBB143_52:                             //   in Loop: Header=BB143_41 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_53:                             //   in Loop: Header=BB143_41 Depth=1
	stp	x23, x8, [x19, #184]
	b	.LBB143_41
.LBB143_54:
	str	w25, [x22]
	b	.LBB143_56
.LBB143_55:                             //   in Loop: Header=BB143_56 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w24, [x8]
.LBB143_56:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #16]
	cbz	x8, .LBB143_59
// %bb.57:                              //   in Loop: Header=BB143_56 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB143_60
// %bb.58:                              //   in Loop: Header=BB143_56 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_68
.LBB143_59:                             //   in Loop: Header=BB143_56 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB143_68
.LBB143_60:                             //   in Loop: Header=BB143_56 Depth=1
	sub	w8, w24, #9
	cmp	w8, #5
	b.hs	.LBB143_65
.LBB143_61:                             //   in Loop: Header=BB143_56 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB143_55
// %bb.62:                              //   in Loop: Header=BB143_56 Depth=1
	ldr	w8, [x19, #48]
	mov	w24, wzr
	cbz	w8, .LBB143_56
// %bb.63:                              //   in Loop: Header=BB143_56 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_66
// %bb.64:                              //   in Loop: Header=BB143_56 Depth=1
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_67
.LBB143_65:                             //   in Loop: Header=BB143_56 Depth=1
	cmp	w24, #32
	b.eq	.LBB143_61
	b	.LBB143_68
.LBB143_66:                             //   in Loop: Header=BB143_56 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_67:                             //   in Loop: Header=BB143_56 Depth=1
	stp	x23, x8, [x19, #184]
	b	.LBB143_56
.LBB143_68:
	mov	w22, wzr
	mov	w25, #10
	b	.LBB143_70
.LBB143_69:                             //   in Loop: Header=BB143_70 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w24, [x8]
.LBB143_70:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #16]
	cbz	x8, .LBB143_73
// %bb.71:                              //   in Loop: Header=BB143_70 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB143_79
// %bb.72:                              //   in Loop: Header=BB143_70 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_83
.LBB143_73:                             //   in Loop: Header=BB143_70 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB143_83
// %bb.74:                              //   in Loop: Header=BB143_70 Depth=1
	sub	w10, w24, #58
	cmn	w10, #10
	b.lo	.LBB143_83
// %bb.75:                              //   in Loop: Header=BB143_70 Depth=1
	madd	w10, w22, w25, w24
	cmp	x8, x9
	sub	w22, w10, #48
	b.lo	.LBB143_69
.LBB143_76:                             //   in Loop: Header=BB143_70 Depth=1
	ldr	w8, [x19, #48]
	mov	w24, wzr
	cbz	w8, .LBB143_70
// %bb.77:                              //   in Loop: Header=BB143_70 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_81
// %bb.78:                              //   in Loop: Header=BB143_70 Depth=1
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_82
.LBB143_79:                             //   in Loop: Header=BB143_70 Depth=1
	sub	w8, w24, #58
	cmn	w8, #10
	b.lo	.LBB143_83
// %bb.80:                              //   in Loop: Header=BB143_70 Depth=1
	ldp	x8, x9, [x19, #184]
	madd	w10, w22, w25, w24
	cmp	x8, x9
	sub	w22, w10, #48
	b.lo	.LBB143_69
	b	.LBB143_76
.LBB143_81:                             //   in Loop: Header=BB143_70 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_82:                             //   in Loop: Header=BB143_70 Depth=1
	stp	x23, x8, [x19, #184]
	b	.LBB143_70
.LBB143_83:
	str	w22, [x20]
	b	.LBB143_85
.LBB143_84:                             //   in Loop: Header=BB143_85 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w24, [x8]
.LBB143_85:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #16]
	cbz	x8, .LBB143_88
// %bb.86:                              //   in Loop: Header=BB143_85 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB143_89
// %bb.87:                              //   in Loop: Header=BB143_85 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_97
.LBB143_88:                             //   in Loop: Header=BB143_85 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB143_97
.LBB143_89:                             //   in Loop: Header=BB143_85 Depth=1
	sub	w8, w24, #9
	cmp	w8, #5
	b.hs	.LBB143_94
.LBB143_90:                             //   in Loop: Header=BB143_85 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.lo	.LBB143_84
// %bb.91:                              //   in Loop: Header=BB143_85 Depth=1
	ldr	w8, [x19, #48]
	mov	w24, wzr
	cbz	w8, .LBB143_85
// %bb.92:                              //   in Loop: Header=BB143_85 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_95
// %bb.93:                              //   in Loop: Header=BB143_85 Depth=1
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_96
.LBB143_94:                             //   in Loop: Header=BB143_85 Depth=1
	cmp	w24, #32
	b.eq	.LBB143_90
	b	.LBB143_97
.LBB143_95:                             //   in Loop: Header=BB143_85 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_96:                             //   in Loop: Header=BB143_85 Depth=1
	stp	x23, x8, [x19, #184]
	b	.LBB143_85
.LBB143_97:
	mov	w20, wzr
	mov	w22, #10
	b	.LBB143_99
.LBB143_98:                             //   in Loop: Header=BB143_99 Depth=1
	add	x9, x8, #1
	str	x9, [x19, #184]
	ldrb	w24, [x8]
.LBB143_99:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x19, #16]
	cbz	x8, .LBB143_102
// %bb.100:                             //   in Loop: Header=BB143_99 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB143_108
// %bb.101:                             //   in Loop: Header=BB143_99 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB143_112
.LBB143_102:                            //   in Loop: Header=BB143_99 Depth=1
	ldp	x8, x9, [x19, #184]
	cmp	x8, x9
	b.hs	.LBB143_112
// %bb.103:                             //   in Loop: Header=BB143_99 Depth=1
	sub	w10, w24, #58
	cmn	w10, #10
	b.lo	.LBB143_112
// %bb.104:                             //   in Loop: Header=BB143_99 Depth=1
	madd	w10, w20, w22, w24
	cmp	x8, x9
	sub	w20, w10, #48
	b.lo	.LBB143_98
.LBB143_105:                            //   in Loop: Header=BB143_99 Depth=1
	ldr	w8, [x19, #48]
	mov	w24, wzr
	cbz	w8, .LBB143_99
// %bb.106:                             //   in Loop: Header=BB143_99 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB143_110
// %bb.107:                             //   in Loop: Header=BB143_99 Depth=1
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB143_111
.LBB143_108:                            //   in Loop: Header=BB143_99 Depth=1
	sub	w8, w24, #58
	cmn	w8, #10
	b.lo	.LBB143_112
// %bb.109:                             //   in Loop: Header=BB143_99 Depth=1
	ldp	x8, x9, [x19, #184]
	madd	w10, w20, w22, w24
	cmp	x8, x9
	sub	w20, w10, #48
	b.lo	.LBB143_98
	b	.LBB143_105
.LBB143_110:                            //   in Loop: Header=BB143_99 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB143_111:                            //   in Loop: Header=BB143_99 Depth=1
	stp	x23, x8, [x19, #184]
	b	.LBB143_99
.LBB143_112:
	cmp	w20, #256
	b.lt	.LBB143_114
// %bb.113:
	adrp	x9, .L.str.96
	adrp	x8, .L_MergedGlobals.126+8
	mov	w0, wzr
	add	x9, x9, :lo12:.L.str.96
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.LBB143_114:
	mov	w0, #1
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.Lfunc_end143:
	.size	_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_, .Lfunc_end143-_ZL14stbi__pnm_infoP13stbi__contextPiS1_S1_
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL18stbi__hdr_gettokenP13stbi__contextPc
	.type	_ZL18stbi__hdr_gettokenP13stbi__contextPc,@function
_ZL18stbi__hdr_gettokenP13stbi__contextPc: // @_ZL18stbi__hdr_gettokenP13stbi__contextPc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	stp	x24, x23, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x9, x8, [x0, #184]
	mov	x20, x0
	mov	x19, x1
	cmp	x9, x8
	b.hs	.LBB144_2
// %bb.1:
	add	x10, x9, #1
	str	x10, [x20, #184]
	ldrb	w24, [x9]
	mov	x9, x10
	b	.LBB144_8
.LBB144_2:
	ldr	w10, [x20, #48]
	cbz	w10, .LBB144_5
// %bb.3:
	ldr	x8, [x20, #16]
	add	x1, x20, #56
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB144_6
// %bb.4:
	mov	x8, x20
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB144_7
.LBB144_5:
	mov	w24, wzr
	b	.LBB144_8
.LBB144_6:
	mov	w24, wzr
	add	x8, x20, #57
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB144_7:
	add	x9, x20, #57
	stp	x9, x8, [x20, #184]
.LBB144_8:
	mov	x22, xzr
	add	x21, x20, #56
	add	x23, x20, #57
	b	.LBB144_10
.LBB144_9:                              //   in Loop: Header=BB144_10 Depth=1
	add	x10, x9, #1
	add	x22, x22, #1
	str	x10, [x20, #184]
	ldrb	w24, [x9]
	mov	x9, x10
.LBB144_10:                             // =>This Inner Loop Header: Depth=1
	ldr	x10, [x20, #16]
	cbz	x10, .LBB144_14
// %bb.11:                              //   in Loop: Header=BB144_10 Depth=1
	ldp	x8, x0, [x20, #32]
	blr	x8
	cbz	w0, .LBB144_15
// %bb.12:                              //   in Loop: Header=BB144_10 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB144_39
// %bb.13:                              //   in Loop: Header=BB144_10 Depth=1
	ldp	x9, x8, [x20, #184]
.LBB144_14:                             //   in Loop: Header=BB144_10 Depth=1
	cmp	x9, x8
	cset	w8, hs
	cmp	w24, #10
	b.ne	.LBB144_16
	b	.LBB144_39
.LBB144_15:                             //   in Loop: Header=BB144_10 Depth=1
	mov	w8, wzr
	cmp	w24, #10
	b.eq	.LBB144_39
.LBB144_16:                             //   in Loop: Header=BB144_10 Depth=1
	cbnz	w8, .LBB144_39
// %bb.17:                              //   in Loop: Header=BB144_10 Depth=1
	cmp	x22, #1022
	strb	w24, [x19, x22]
	b.eq	.LBB144_25
// %bb.18:                              //   in Loop: Header=BB144_10 Depth=1
	ldp	x9, x8, [x20, #184]
	cmp	x9, x8
	b.lo	.LBB144_9
// %bb.19:                              //   in Loop: Header=BB144_10 Depth=1
	ldr	w10, [x20, #48]
	cbz	w10, .LBB144_22
// %bb.20:                              //   in Loop: Header=BB144_10 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB144_23
// %bb.21:                              //   in Loop: Header=BB144_10 Depth=1
	mov	x8, x20
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB144_24
.LBB144_22:                             //   in Loop: Header=BB144_10 Depth=1
	mov	w24, wzr
	add	x22, x22, #1
	b	.LBB144_10
.LBB144_23:                             //   in Loop: Header=BB144_10 Depth=1
	mov	w24, wzr
	mov	x8, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB144_24:                             //   in Loop: Header=BB144_10 Depth=1
	mov	x9, x23
	stp	x23, x8, [x20, #184]
	add	x22, x22, #1
	b	.LBB144_10
.LBB144_25:
	mov	w22, #1023
	b	.LBB144_28
.LBB144_26:                             //   in Loop: Header=BB144_28 Depth=1
	add	x9, x8, #1
	str	x9, [x20, #184]
	ldrb	w8, [x8]
.LBB144_27:                             //   in Loop: Header=BB144_28 Depth=1
	cmp	w8, #10
	b.eq	.LBB144_39
.LBB144_28:                             // =>This Inner Loop Header: Depth=1
	ldr	x8, [x20, #16]
	cbz	x8, .LBB144_31
// %bb.29:                              //   in Loop: Header=BB144_28 Depth=1
	ldp	x8, x0, [x20, #32]
	blr	x8
	cbz	w0, .LBB144_36
// %bb.30:                              //   in Loop: Header=BB144_28 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB144_39
.LBB144_31:                             //   in Loop: Header=BB144_28 Depth=1
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.hs	.LBB144_39
// %bb.32:                              //   in Loop: Header=BB144_28 Depth=1
	cmp	x8, x9
	b.lo	.LBB144_26
.LBB144_33:                             //   in Loop: Header=BB144_28 Depth=1
	ldr	w8, [x20, #48]
	cbz	w8, .LBB144_27
// %bb.34:                              //   in Loop: Header=BB144_28 Depth=1
	ldr	x8, [x20, #16]
	mov	x1, x21
	ldr	x0, [x20, #40]
	ldr	w2, [x20, #52]
	blr	x8
	cbz	w0, .LBB144_37
// %bb.35:                              //   in Loop: Header=BB144_28 Depth=1
	mov	x9, x20
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB144_38
.LBB144_36:                             //   in Loop: Header=BB144_28 Depth=1
	ldp	x8, x9, [x20, #184]
	cmp	x8, x9
	b.lo	.LBB144_26
	b	.LBB144_33
.LBB144_37:                             //   in Loop: Header=BB144_28 Depth=1
	mov	w8, wzr
	mov	x9, x23
	str	wzr, [x20, #48]
	strb	wzr, [x20, #56]
.LBB144_38:                             //   in Loop: Header=BB144_28 Depth=1
	stp	x23, x9, [x20, #184]
	b	.LBB144_27
.LBB144_39:
	mov	x0, x19
	strb	wzr, [x19, x22]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end144:
	.size	_ZL18stbi__hdr_gettokenP13stbi__contextPc, .Lfunc_end144-_ZL18stbi__hdr_gettokenP13stbi__contextPc
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL17stbi__hdr_convertPfPhi
	.type	_ZL17stbi__hdr_convertPfPhi,@function
_ZL17stbi__hdr_convertPfPhi:            // @_ZL17stbi__hdr_convertPfPhi
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	w20, w2
	ldrb	w8, [x1, #3]
	mov	x19, x0
	cbz	w8, .LBB145_6
// %bb.1:
	sub	w0, w8, #136
	fmov	s0, #1.00000000
	mov	x21, x1
	bl	ldexpf
	ldrb	w8, [x21]
	cmp	w20, #2
	b.gt	.LBB145_10
// %bb.2:
	ldrb	w9, [x21, #1]
	ldrb	w10, [x21, #2]
	add	w8, w9, w8
	add	w8, w8, w10
	scvtf	s1, w8
	fmul	s0, s0, s1
	fmov	s1, #3.00000000
	fdiv	s0, s0, s1
	str	s0, [x19]
	cmp	w20, #4
	b.eq	.LBB145_11
.LBB145_3:
	cmp	w20, #2
	b.ne	.LBB145_5
// %bb.4:
	mov	w8, #1065353216
	str	w8, [x19, #4]
.LBB145_5:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB145_6:
	sub	w8, w20, #1
	cmp	w8, #3
	b.hi	.LBB145_5
// %bb.7:
	adrp	x9, .LJTI145_0
	add	x9, x9, :lo12:.LJTI145_0
	adr	x10, .LBB145_8
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
.LBB145_8:
	mov	w8, #1065353216
	str	w8, [x19, #4]
.LBB145_9:
	str	wzr, [x19]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB145_10:
	ucvtf	s1, w8
	fmul	s1, s0, s1
	str	s1, [x19]
	ldr	b1, [x21, #1]
	ucvtf	s1, s1
	fmul	s1, s0, s1
	str	s1, [x19, #4]
	ldr	b1, [x21, #2]
	ucvtf	s1, s1
	fmul	s0, s0, s1
	str	s0, [x19, #8]
	cmp	w20, #4
	b.ne	.LBB145_3
.LBB145_11:
	mov	w8, #1065353216
	str	w8, [x19, #12]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.LBB145_12:
	mov	w8, #1065353216
	str	w8, [x19, #12]
.LBB145_13:
	stp	wzr, wzr, [x19, #4]
	str	wzr, [x19]
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end145:
	.size	_ZL17stbi__hdr_convertPfPhi, .Lfunc_end145-_ZL17stbi__hdr_convertPfPhi
	.cfi_endproc
	.section	.rodata,"a",@progbits
.LJTI145_0:
	.byte	(.LBB145_9-.LBB145_8)>>2
	.byte	(.LBB145_8-.LBB145_8)>>2
	.byte	(.LBB145_13-.LBB145_8)>>2
	.byte	(.LBB145_12-.LBB145_8)>>2
                                        // -- End function
	.text
	.p2align	2                               // -- Begin function _ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	.type	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi,@function
_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi: // @_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #192
	stp	x29, x30, [sp, #144]            // 16-byte Folded Spill
	add	x29, sp, #144
	str	x21, [sp, #160]                 // 8-byte Folded Spill
	stp	x20, x19, [sp, #176]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	movi	v0.2d, #0000000000000000
	mov	w21, w2
	mov	x19, x1
	mov	w1, wzr
	mov	w2, #1024
	mov	x20, x0
	str	wzr, [sp, #64]
	stp	q0, q0, [sp, #32]
	stp	q0, q0, [sp]
	bl	memset
	cmp	w21, #1
	b.lt	.LBB146_5
// %bb.1:
	mov	w8, w21
	mov	x9, sp
	mov	x10, x19
.LBB146_2:                              // =>This Inner Loop Header: Depth=1
	ldrb	w11, [x10], #1
	subs	x8, x8, #1
	lsl	x11, x11, #2
	ldr	w12, [x9, x11]
	add	w12, w12, #1
	str	w12, [x9, x11]
	b.ne	.LBB146_2
// %bb.3:
	ldr	w2, [sp, #4]
	str	wzr, [sp]
	cmp	w2, #2
	b.gt	.LBB146_19
// %bb.4:
	ldr	w3, [sp, #8]
	cmp	w3, #4
	b.le	.LBB146_6
	b	.LBB146_19
.LBB146_5:
	mov	w2, wzr
	ldr	w3, [sp, #8]
	cmp	w3, #4
	b.gt	.LBB146_19
.LBB146_6:
	ldr	w1, [sp, #12]
	cmp	w1, #8
	b.gt	.LBB146_19
// %bb.7:
	ldr	w0, [sp, #16]
	cmp	w0, #16
	b.gt	.LBB146_19
// %bb.8:
	ldr	w18, [sp, #20]
	cmp	w18, #32
	b.gt	.LBB146_19
// %bb.9:
	ldr	w17, [sp, #24]
	cmp	w17, #64
	b.gt	.LBB146_19
// %bb.10:
	ldr	w16, [sp, #28]
	cmp	w16, #128
	b.gt	.LBB146_19
// %bb.11:
	ldr	w15, [sp, #32]
	cmp	w15, #256
	b.gt	.LBB146_19
// %bb.12:
	ldr	w14, [sp, #36]
	cmp	w14, #512
	b.gt	.LBB146_19
// %bb.13:
	ldr	w13, [sp, #40]
	cmp	w13, #1024
	b.gt	.LBB146_19
// %bb.14:
	ldr	w12, [sp, #44]
	cmp	w12, #2048
	b.gt	.LBB146_19
// %bb.15:
	ldr	w11, [sp, #48]
	cmp	w11, #1, lsl #12                // =4096
	b.gt	.LBB146_19
// %bb.16:
	ldr	w10, [sp, #52]
	cmp	w10, #2, lsl #12                // =8192
	b.gt	.LBB146_19
// %bb.17:
	ldr	w9, [sp, #56]
	cmp	w9, #4, lsl #12                 // =16384
	b.gt	.LBB146_19
// %bb.18:
	ldr	w8, [sp, #60]
	cmp	w8, #8, lsl #12                 // =32768
	b.le	.LBB146_22
.LBB146_19:
	adrp	x8, .L.str.113
	add	x8, x8, :lo12:.L.str.113
.LBB146_20:
	adrp	x9, .L_MergedGlobals.126+8
	mov	w0, wzr
	str	x8, [x9, :lo12:.L_MergedGlobals.126+8]
.LBB146_21:
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	ldr	x21, [sp, #160]                 // 8-byte Folded Reload
	add	sp, sp, #192
	ret
.LBB146_22:
	lsl	w4, w2, #15
	lsl	w5, w2, #1
	strh	wzr, [x20, #1026]
	strh	wzr, [x20, #1126]
	str	w4, [x20, #1060]
	add	w4, w3, w5
	stp	wzr, w5, [x29, #-60]
	strh	w5, [x20, #1028]
	strh	w2, [x20, #1128]
	cbz	w3, .LBB146_24
// %bb.23:
	cmp	w4, #4
	b.gt	.LBB146_50
.LBB146_24:
	lsl	w5, w4, #14
	lsl	w4, w4, #1
	add	w2, w3, w2
	add	w3, w1, w4
	str	w5, [x20, #1064]
	stur	w4, [x29, #-52]
	strh	w4, [x20, #1030]
	strh	w2, [x20, #1130]
	cbz	w1, .LBB146_26
// %bb.25:
	cmp	w3, #8
	b.gt	.LBB146_50
.LBB146_26:
	lsl	w4, w3, #13
	lsl	w3, w3, #1
	add	w1, w1, w2
	add	w2, w0, w3
	str	w4, [x20, #1068]
	stur	w3, [x29, #-48]
	strh	w3, [x20, #1032]
	strh	w1, [x20, #1132]
	cbz	w0, .LBB146_28
// %bb.27:
	cmp	w2, #16
	b.gt	.LBB146_50
.LBB146_28:
	lsl	w3, w2, #12
	lsl	w2, w2, #1
	add	w0, w0, w1
	add	w1, w18, w2
	str	w3, [x20, #1072]
	stur	w2, [x29, #-44]
	strh	w2, [x20, #1034]
	strh	w0, [x20, #1134]
	cbz	w18, .LBB146_30
// %bb.29:
	cmp	w1, #32
	b.gt	.LBB146_50
.LBB146_30:
	lsl	w2, w1, #11
	lsl	w1, w1, #1
	add	w18, w18, w0
	add	w0, w17, w1
	str	w2, [x20, #1076]
	stur	w1, [x29, #-40]
	strh	w1, [x20, #1036]
	strh	w18, [x20, #1136]
	cbz	w17, .LBB146_32
// %bb.31:
	cmp	w0, #64
	b.gt	.LBB146_50
.LBB146_32:
	lsl	w1, w0, #10
	lsl	w0, w0, #1
	add	w17, w17, w18
	add	w18, w16, w0
	str	w1, [x20, #1080]
	stur	w0, [x29, #-36]
	strh	w0, [x20, #1038]
	strh	w17, [x20, #1138]
	cbz	w16, .LBB146_34
// %bb.33:
	cmp	w18, #128
	b.gt	.LBB146_50
.LBB146_34:
	lsl	w0, w18, #9
	lsl	w18, w18, #1
	add	w16, w16, w17
	add	w17, w15, w18
	str	w0, [x20, #1084]
	stur	w18, [x29, #-32]
	strh	w18, [x20, #1040]
	strh	w16, [x20, #1140]
	cbz	w15, .LBB146_36
// %bb.35:
	cmp	w17, #256
	b.gt	.LBB146_50
.LBB146_36:
	lsl	w18, w17, #8
	lsl	w17, w17, #1
	add	w15, w15, w16
	add	w16, w14, w17
	str	w18, [x20, #1088]
	stur	w17, [x29, #-28]
	strh	w17, [x20, #1042]
	strh	w15, [x20, #1142]
	cbz	w14, .LBB146_38
// %bb.37:
	cmp	w16, #512
	b.gt	.LBB146_50
.LBB146_38:
	lsl	w17, w16, #7
	lsl	w16, w16, #1
	add	w14, w14, w15
	add	w15, w13, w16
	str	w17, [x20, #1092]
	stur	w16, [x29, #-24]
	strh	w16, [x20, #1044]
	strh	w14, [x20, #1144]
	cbz	w13, .LBB146_40
// %bb.39:
	cmp	w15, #1024
	b.gt	.LBB146_50
.LBB146_40:
	lsl	w16, w15, #6
	lsl	w15, w15, #1
	add	w13, w13, w14
	add	w14, w12, w15
	str	w16, [x20, #1096]
	stur	w15, [x29, #-20]
	strh	w15, [x20, #1046]
	strh	w13, [x20, #1146]
	cbz	w12, .LBB146_42
// %bb.41:
	cmp	w14, #2048
	b.gt	.LBB146_50
.LBB146_42:
	lsl	w15, w14, #5
	lsl	w14, w14, #1
	add	w12, w12, w13
	add	w13, w11, w14
	str	w15, [x20, #1100]
	stur	w14, [x29, #-16]
	strh	w14, [x20, #1048]
	strh	w12, [x20, #1148]
	cbz	w11, .LBB146_44
// %bb.43:
	cmp	w13, #1, lsl #12                // =4096
	b.gt	.LBB146_50
.LBB146_44:
	lsl	w14, w13, #4
	lsl	w13, w13, #1
	add	w11, w11, w12
	add	w12, w10, w13
	str	w14, [x20, #1104]
	stur	w13, [x29, #-12]
	strh	w13, [x20, #1050]
	strh	w11, [x20, #1150]
	cbz	w10, .LBB146_46
// %bb.45:
	cmp	w12, #2, lsl #12                // =8192
	b.gt	.LBB146_50
.LBB146_46:
	lsl	w13, w12, #3
	lsl	w12, w12, #1
	add	w10, w10, w11
	add	w11, w9, w12
	str	w13, [x20, #1108]
	stur	w12, [x29, #-8]
	strh	w12, [x20, #1052]
	strh	w10, [x20, #1152]
	cbz	w9, .LBB146_48
// %bb.47:
	cmp	w11, #4, lsl #12                // =16384
	b.gt	.LBB146_50
.LBB146_48:
	lsl	w12, w11, #2
	lsl	w11, w11, #1
	add	w10, w9, w10
	add	w9, w8, w11
	str	w12, [x20, #1112]
	stur	w11, [x29, #-4]
	strh	w11, [x20, #1054]
	strh	w10, [x20, #1154]
	cbz	w8, .LBB146_51
// %bb.49:
	cmp	w9, #8, lsl #12                 // =32768
	b.le	.LBB146_51
.LBB146_50:
	adrp	x8, .L.str.114
	add	x8, x8, :lo12:.L.str.114
	b	.LBB146_20
.LBB146_51:
	lsl	w9, w9, #1
	mov	w10, #65536
	mov	w8, #1
	cmp	w21, #1
	str	w9, [x20, #1116]
	str	w10, [x20, #1120]
	b.lt	.LBB146_60
// %bb.52:
	mov	x9, xzr
	mov	w10, w21
	sub	x11, x29, #64
	mov	w12, #16
	mov	w0, #1
	b	.LBB146_55
.LBB146_53:                             //   in Loop: Header=BB146_55 Depth=1
	add	w14, w14, #1
	str	w14, [x11, x13, lsl #2]
.LBB146_54:                             //   in Loop: Header=BB146_55 Depth=1
	add	x9, x9, #1
	cmp	x9, x10
	b.eq	.LBB146_21
.LBB146_55:                             // =>This Loop Header: Depth=1
                                        //     Child Loop BB146_59 Depth 2
	ldrb	w13, [x19, x9]
	cbz	w13, .LBB146_54
// %bb.56:                              //   in Loop: Header=BB146_55 Depth=1
	add	x15, x20, x13, lsl #1
	ldr	w14, [x11, x13, lsl #2]
	cmp	w13, #9
	ldrh	w16, [x15, #1024]
	ldrh	w15, [x15, #1124]
	sub	w16, w14, w16
	add	x15, x15, w16, sxtw
	add	x16, x20, x15
	add	x15, x20, x15, lsl #1
	strb	w13, [x16, #1156]
	strh	w9, [x15, #1444]
	b.hi	.LBB146_53
// %bb.57:                              //   in Loop: Header=BB146_55 Depth=1
	sub	w15, w12, w13
	rbit	w16, w14
	lsr	w16, w16, #16
	lsr	w15, w16, w15
	cmp	w15, #511
	b.hi	.LBB146_53
// %bb.58:                              //   in Loop: Header=BB146_55 Depth=1
	lsl	w17, w8, w13
	orr	w16, w9, w13, lsl #9
	sxtw	x17, w17
.LBB146_59:                             //   Parent Loop BB146_55 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	strh	w16, [x20, x15, lsl #1]
	add	x15, x15, x17
	cmp	x15, #512
	b.lt	.LBB146_59
	b	.LBB146_53
.LBB146_60:
	mov	w0, #1
	ldp	x20, x19, [sp, #176]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #144]            // 16-byte Folded Reload
	ldr	x21, [sp, #160]                 // 8-byte Folded Reload
	add	sp, sp, #192
	ret
.Lfunc_end146:
	.size	_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi, .Lfunc_end146-_ZL20stbi__zbuild_huffmanP14stbi__zhuffmanPhi
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman
	.type	_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman,@function
_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman: // @_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-16]!           // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	ldr	w9, [x0, #16]
	cmp	w9, #16
	b.ge	.LBB147_7
// %bb.1:
	ldr	w8, [x0, #20]
	mov	w10, w9
	b	.LBB147_4
.LBB147_2:                              //   in Loop: Header=BB147_4 Depth=1
	add	x11, x9, #1
	str	x11, [x0]
	ldrb	w9, [x9]
.LBB147_3:                              //   in Loop: Header=BB147_4 Depth=1
	lsl	w11, w9, w10
	add	w9, w10, #8
	orr	w8, w11, w8
	cmp	w10, #17
	mov	w10, w9
	stp	w9, w8, [x0, #16]
	b.ge	.LBB147_8
.LBB147_4:                              // =>This Inner Loop Header: Depth=1
	lsr	w9, w8, w10
	cbnz	w9, .LBB147_17
// %bb.5:                               //   in Loop: Header=BB147_4 Depth=1
	ldp	x9, x11, [x0]
	cmp	x9, x11
	b.lo	.LBB147_2
// %bb.6:                               //   in Loop: Header=BB147_4 Depth=1
	mov	w9, wzr
	b	.LBB147_3
.LBB147_7:
	ldr	w8, [x0, #20]
.LBB147_8:
	and	w10, w8, #0x1ff
	ldrh	w10, [x1, w10, uxtw #1]
	cbz	w10, .LBB147_10
// %bb.9:
	lsr	w11, w10, #9
	sub	w9, w9, w11
	lsr	w12, w8, w11
	and	w8, w10, #0x1ff
	b	.LBB147_16
.LBB147_10:
	rbit	w11, w8
	mov	x10, xzr
	lsr	w11, w11, #16
	add	x12, x1, #1096
.LBB147_11:                             // =>This Inner Loop Header: Depth=1
	ldr	w13, [x12, x10, lsl #2]
	add	x10, x10, #1
	cmp	w13, w11
	b.le	.LBB147_11
// %bb.12:
	cmp	w10, #7
	b.ne	.LBB147_14
// %bb.13:
	mov	w8, #-1
	mov	w0, w8
	ldp	x29, x30, [sp], #16             // 16-byte Folded Reload
	ret
.LBB147_14:
	add	x12, x10, #9
	mov	w14, #7
	and	x13, x12, #0xffffffff
	sub	w14, w14, w10
	add	x13, x1, x13, lsl #1
	lsr	w11, w11, w14
	ldrh	w15, [x13, #1024]
	ldrh	w13, [x13, #1124]
	sub	w11, w11, w15
	add	x11, x13, w11, sxtw
	add	x13, x1, x11
	ldrb	w13, [x13, #1156]
	sub	w13, w10, w13
	cmn	w13, #9
	b.ne	.LBB147_18
// %bb.15:
	add	x11, x1, x11, lsl #1
	lsr	w12, w8, w12
	sub	w8, w9, w10
	sub	w9, w8, #9
	ldrh	w8, [x11, #1444]
.LBB147_16:
	stp	w9, w12, [x0, #16]
	mov	w0, w8
	ldp	x29, x30, [sp], #16             // 16-byte Folded Reload
	ret
.LBB147_17:
	adrp	x0, .L.str.108
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf
	add	x0, x0, :lo12:.L.str.108
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf
	mov	w2, #3545
	bl	__assert_fail
.LBB147_18:
	adrp	x0, .L.str.117
	adrp	x1, .L.str.38
	adrp	x3, .L__PRETTY_FUNCTION__._ZL30stbi__zhuffman_decode_slowpathP10stbi__zbufP14stbi__zhuffman
	add	x0, x0, :lo12:.L.str.117
	add	x1, x1, :lo12:.L.str.38
	add	x3, x3, :lo12:.L__PRETTY_FUNCTION__._ZL30stbi__zhuffman_decode_slowpathP10stbi__zbufP14stbi__zhuffman
	mov	w2, #3573
	bl	__assert_fail
.Lfunc_end147:
	.size	_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman, .Lfunc_end147-_ZL21stbi__zhuffman_decodeP10stbi__zbufP14stbi__zhuffman
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__psd_infoP13stbi__contextPiS1_S1_
	.type	_ZL14stbi__psd_infoP13stbi__contextPiS1_S1_,@function
_ZL14stbi__psd_infoP13stbi__contextPiS1_S1_: // @_ZL14stbi__psd_infoP13stbi__contextPiS1_S1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x20, x3
	mov	x22, x2
	mov	x21, x1
	mov	x19, x0
	bl	_ZL13stbi__get32beP13stbi__context
	mov	w8, #20563
	movk	w8, #14402, lsl #16
	cmp	w0, w8
	b.ne	.LBB148_66
// %bb.1:
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB148_3
// %bb.2:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB148_7
	b	.LBB148_12
.LBB148_3:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB148_6
// %bb.4:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_10
// %bb.5:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB148_11
.LBB148_6:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB148_12
.LBB148_7:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB148_13
// %bb.8:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_14
// %bb.9:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB148_15
.LBB148_10:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_11:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB148_7
.LBB148_12:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB148_13:
	bfi	w10, w23, #8, #8
	cmp	w10, #1
	b.eq	.LBB148_16
	b	.LBB148_66
.LBB148_14:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_15:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w23, #8, #8
	cmp	w10, #1
	b.ne	.LBB148_66
.LBB148_16:
	ldr	x10, [x19, #16]
	cbz	x10, .LBB148_22
// %bb.17:
	sub	w10, w8, w9
	cmp	w10, #5
	b.gt	.LBB148_22
// %bb.18:
	mov	w11, #6
	ldr	x9, [x19, #24]
	ldr	x0, [x19, #40]
	sub	w1, w11, w10
	str	x8, [x19, #184]
	blr	x9
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB148_23
.LBB148_19:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB148_24
// %bb.20:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_28
// %bb.21:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB148_29
.LBB148_22:
	add	x9, x9, #6
	str	x9, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB148_19
.LBB148_23:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB148_25
	b	.LBB148_30
.LBB148_24:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB148_30
.LBB148_25:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB148_31
// %bb.26:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_32
// %bb.27:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB148_33
.LBB148_28:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_29:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB148_25
.LBB148_30:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
.LBB148_31:
	bfi	w8, w23, #8, #8
	cmp	w8, #17
	b.lo	.LBB148_34
	b	.LBB148_66
.LBB148_32:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_33:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
	bfi	w8, w23, #8, #8
	cmp	w8, #17
	b.hs	.LBB148_66
.LBB148_34:
	mov	x0, x19
	bl	_ZL13stbi__get32beP13stbi__context
	str	w0, [x22]
	mov	x0, x19
	bl	_ZL13stbi__get32beP13stbi__context
	ldp	x9, x8, [x19, #184]
	str	w0, [x21]
	cmp	x9, x8
	b.hs	.LBB148_36
// %bb.35:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB148_40
	b	.LBB148_45
.LBB148_36:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB148_39
// %bb.37:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_43
// %bb.38:
	mov	x8, x19
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB148_44
.LBB148_39:
	mov	w21, wzr
	cmp	x9, x8
	b.lo	.LBB148_45
.LBB148_40:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB148_46
// %bb.41:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_47
// %bb.42:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB148_48
.LBB148_43:
	mov	w21, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_44:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB148_40
.LBB148_45:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB148_46:
	bfi	w10, w21, #8, #8
	cmp	w10, #8
	b.eq	.LBB148_49
	b	.LBB148_66
.LBB148_47:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_48:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w21, #8, #8
	cmp	w10, #8
	b.ne	.LBB148_66
.LBB148_49:
	cmp	x9, x8
	b.hs	.LBB148_51
// %bb.50:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w21, [x9]
	mov	x9, x10
	b	.LBB148_57
.LBB148_51:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB148_54
// %bb.52:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_55
// %bb.53:
	mov	x8, x19
	ldrb	w21, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB148_56
.LBB148_54:
	mov	w21, wzr
	b	.LBB148_57
.LBB148_55:
	mov	w21, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_56:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
.LBB148_57:
	cmp	x9, x8
	b.hs	.LBB148_59
// %bb.58:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB148_64
.LBB148_59:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB148_64
// %bb.60:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB148_62
// %bb.61:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB148_63
.LBB148_62:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB148_63:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB148_64:
	bfi	w8, w21, #8, #8
	cmp	w8, #3
	b.ne	.LBB148_66
// %bb.65:
	mov	w8, #4
	mov	w0, #1
	str	w8, [x20]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB148_66:
	ldr	x8, [x19, #200]
	mov	w0, wzr
	str	x8, [x19, #184]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end148:
	.size	_ZL14stbi__psd_infoP13stbi__contextPiS1_S1_, .Lfunc_end148-_ZL14stbi__psd_infoP13stbi__contextPiS1_S1_
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__pic_infoP13stbi__contextPiS1_S1_
	.type	_ZL14stbi__pic_infoP13stbi__contextPiS1_S1_,@function
_ZL14stbi__pic_infoP13stbi__contextPiS1_S1_: // @_ZL14stbi__pic_infoP13stbi__contextPiS1_S1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	str	x27, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x20, x3
	mov	x21, x2
	mov	x19, x0
	ldr	x8, [x0, #16]
	mov	x22, x1
	cbz	x8, .LBB149_16
// %bb.1:
	ldp	x9, x8, [x19, #184]
	sub	w10, w8, w9
	cmp	w10, #91
	b.gt	.LBB149_17
// %bb.2:
	mov	w11, #92
	ldr	x9, [x19, #24]
	ldr	x0, [x19, #40]
	sub	w1, w11, w10
	str	x8, [x19, #184]
	blr	x9
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB149_18
.LBB149_3:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_33
// %bb.4:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_75
// %bb.5:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB149_19
.LBB149_6:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_20
// %bb.7:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_76
// %bb.8:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w23, #8, #8
	cmp	x9, x8
	str	w10, [x22]
	b.lo	.LBB149_21
.LBB149_9:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_34
// %bb.10:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_77
// %bb.11:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB149_22
.LBB149_12:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_23
// %bb.13:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_78
// %bb.14:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w23, #8, #8
	ldr	x11, [x19, #16]
	str	w10, [x21]
	cbnz	x11, .LBB149_24
.LBB149_15:
	cmp	x9, x8
	b.lo	.LBB149_27
	b	.LBB149_73
.LBB149_16:
	ldr	x9, [x19, #184]
.LBB149_17:
	add	x9, x9, #92
	str	x9, [x19, #184]
	ldr	x8, [x19, #192]
	cmp	x9, x8
	b.hs	.LBB149_3
.LBB149_18:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB149_6
.LBB149_19:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB149_20:
	bfi	w10, w23, #8, #8
	cmp	x9, x8
	str	w10, [x22]
	b.hs	.LBB149_9
.LBB149_21:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB149_12
.LBB149_22:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB149_23:
	bfi	w10, w23, #8, #8
	ldr	x11, [x19, #16]
	str	w10, [x21]
	cbz	x11, .LBB149_15
.LBB149_24:
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB149_27
// %bb.25:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB149_73
// %bb.26:
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB149_73
.LBB149_27:
	ldr	w8, [x22]
	cbz	w8, .LBB149_30
// %bb.28:
	mov	w9, #268435456
	sdiv	w8, w9, w8
	ldr	w9, [x21]
	cmp	w8, w9
	b.ge	.LBB149_30
.LBB149_29:
	ldr	x8, [x19, #200]
	mov	w0, wzr
	str	x8, [x19, #184]
	b	.LBB149_74
.LBB149_30:
	ldr	x8, [x19, #16]
	cbz	x8, .LBB149_35
// %bb.31:
	ldp	x9, x8, [x19, #184]
	sub	w10, w8, w9
	cmp	w10, #7
	b.gt	.LBB149_36
// %bb.32:
	mov	w11, #8
	ldr	x9, [x19, #24]
	ldr	x0, [x19, #40]
	sub	w1, w11, w10
	str	x8, [x19, #184]
	blr	x9
	b	.LBB149_37
.LBB149_33:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB149_19
	b	.LBB149_6
.LBB149_34:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB149_22
	b	.LBB149_12
.LBB149_35:
	ldr	x9, [x19, #184]
.LBB149_36:
	add	x8, x9, #8
	str	x8, [x19, #184]
.LBB149_37:
	mov	w22, wzr
	add	x21, x19, #56
	add	x23, x19, #57
	mov	w24, #11
.LBB149_38:                             // =>This Inner Loop Header: Depth=1
	subs	w24, w24, #1
	b.eq	.LBB149_73
// %bb.39:                              //   in Loop: Header=BB149_38 Depth=1
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB149_43
// %bb.40:                              //   in Loop: Header=BB149_38 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w25, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB149_48
.LBB149_41:                             //   in Loop: Header=BB149_38 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w26, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB149_53
.LBB149_42:                             //   in Loop: Header=BB149_38 Depth=1
	add	x9, x9, #1
	b	.LBB149_58
.LBB149_43:                             //   in Loop: Header=BB149_38 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_46
// %bb.44:                              //   in Loop: Header=BB149_38 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_47
// %bb.45:                              //   in Loop: Header=BB149_38 Depth=1
	mov	x8, x19
	ldrb	w25, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB149_48
	b	.LBB149_41
.LBB149_46:                             //   in Loop: Header=BB149_38 Depth=1
	mov	w25, wzr
	cmp	x9, x8
	b.lo	.LBB149_41
	b	.LBB149_48
.LBB149_47:                             //   in Loop: Header=BB149_38 Depth=1
	mov	w25, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB149_41
.LBB149_48:                             //   in Loop: Header=BB149_38 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_51
// %bb.49:                              //   in Loop: Header=BB149_38 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_52
// %bb.50:                              //   in Loop: Header=BB149_38 Depth=1
	mov	x8, x19
	ldrb	w26, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB149_42
	b	.LBB149_53
.LBB149_51:                             //   in Loop: Header=BB149_38 Depth=1
	mov	w26, wzr
	cmp	x9, x8
	b.lo	.LBB149_42
	b	.LBB149_53
.LBB149_52:                             //   in Loop: Header=BB149_38 Depth=1
	mov	w26, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB149_42
.LBB149_53:                             //   in Loop: Header=BB149_38 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_59
// %bb.54:                              //   in Loop: Header=BB149_38 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_56
// %bb.55:                              //   in Loop: Header=BB149_38 Depth=1
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB149_57
.LBB149_56:                             //   in Loop: Header=BB149_38 Depth=1
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB149_57:                             //   in Loop: Header=BB149_38 Depth=1
	mov	x9, x23
	str	x8, [x19, #192]
.LBB149_58:                             //   in Loop: Header=BB149_38 Depth=1
	str	x9, [x19, #184]
.LBB149_59:                             //   in Loop: Header=BB149_38 Depth=1
	cmp	x9, x8
	b.hs	.LBB149_61
// %bb.60:                              //   in Loop: Header=BB149_38 Depth=1
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w27, [x9]
	mov	x9, x10
	ldr	x10, [x19, #16]
	cbnz	x10, .LBB149_66
	b	.LBB149_69
.LBB149_61:                             //   in Loop: Header=BB149_38 Depth=1
	ldr	w10, [x19, #48]
	cbz	w10, .LBB149_64
// %bb.62:                              //   in Loop: Header=BB149_38 Depth=1
	ldr	x8, [x19, #16]
	mov	x1, x21
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB149_65
// %bb.63:                              //   in Loop: Header=BB149_38 Depth=1
	mov	x8, x19
	ldrb	w27, [x8, #56]!
	add	x8, x8, w0, sxtw
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	ldr	x10, [x19, #16]
	cbnz	x10, .LBB149_66
	b	.LBB149_69
.LBB149_64:                             //   in Loop: Header=BB149_38 Depth=1
	mov	w27, wzr
	ldr	x10, [x19, #16]
	cbnz	x10, .LBB149_66
	b	.LBB149_69
.LBB149_65:                             //   in Loop: Header=BB149_38 Depth=1
	mov	w27, wzr
	mov	x8, x23
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	mov	x9, x23
	stp	x23, x8, [x19, #184]
	ldr	x10, [x19, #16]
	cbz	x10, .LBB149_69
.LBB149_66:                             //   in Loop: Header=BB149_38 Depth=1
	ldp	x8, x0, [x19, #32]
	blr	x8
	cbz	w0, .LBB149_70
// %bb.67:                              //   in Loop: Header=BB149_38 Depth=1
	ldr	w8, [x19, #48]
	cbz	w8, .LBB149_29
// %bb.68:                              //   in Loop: Header=BB149_38 Depth=1
	ldp	x9, x8, [x19, #184]
.LBB149_69:                             //   in Loop: Header=BB149_38 Depth=1
	cmp	x9, x8
	b.hs	.LBB149_29
.LBB149_70:                             //   in Loop: Header=BB149_38 Depth=1
	cmp	w26, #8
	b.ne	.LBB149_29
// %bb.71:                              //   in Loop: Header=BB149_38 Depth=1
	orr	w22, w22, w27
	cbnz	w25, .LBB149_38
// %bb.72:
	tst	w22, #0x10
	mov	w8, #3
	cinc	w8, w8, ne
	mov	w0, #1
	str	w8, [x20]
	b	.LBB149_74
.LBB149_73:
	mov	w0, wzr
.LBB149_74:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB149_75:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB149_6
	b	.LBB149_19
.LBB149_76:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w23, #8, #8
	cmp	x9, x8
	str	w10, [x22]
	b.lo	.LBB149_21
	b	.LBB149_9
.LBB149_77:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB149_12
	b	.LBB149_22
.LBB149_78:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w10, w23, #8, #8
	ldr	x11, [x19, #16]
	str	w10, [x21]
	cbnz	x11, .LBB149_24
	b	.LBB149_15
.Lfunc_end149:
	.size	_ZL14stbi__pic_infoP13stbi__contextPiS1_S1_, .Lfunc_end149-_ZL14stbi__pic_infoP13stbi__contextPiS1_S1_
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_
	.type	_ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_,@function
_ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_: // @_ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	str	x28, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	sub	sp, sp, #1024
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x21, x1
	mov	x1, sp
	mov	x20, x3
	mov	x22, x2
	mov	x19, x0
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	mov	x10, #16163
	mov	x11, #17473
	ldr	x8, [sp]
	movk	x10, #16722, lsl #16
	ldur	x9, [sp, #3]
	movk	x11, #16713, lsl #16
	movk	x10, #18756, lsl #32
	movk	x11, #17230, lsl #32
	movk	x10, #20033, lsl #48
	movk	x11, #69, lsl #48
	eor	x8, x8, x10
	eor	x9, x9, x11
	orr	x8, x8, x9
	cbz	x8, .LBB150_3
.LBB150_1:
	ldr	x8, [x19, #200]
	mov	w0, wzr
	str	x8, [x19, #184]
.LBB150_2:
	add	sp, sp, #1024
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldr	x28, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB150_3:
	mov	x1, sp
	mov	x0, x19
	mov	x23, sp
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	ldrb	w8, [sp]
	cbz	w8, .LBB150_12
// %bb.4:
	mov	x24, #20294
	mov	x25, #11570
	mov	x26, #25964
	movk	x24, #19794, lsl #16
	movk	x25, #26978, lsl #16
	movk	x26, #29279, lsl #16
	movk	x24, #21569, lsl #32
	movk	x25, #24436, lsl #32
	movk	x26, #25191, lsl #32
	mov	w23, wzr
	movk	x24, #13117, lsl #48
	movk	x25, #27762, lsl #48
	movk	x26, #101, lsl #48
.LBB150_5:                              // =>This Inner Loop Header: Depth=1
	ldp	x8, x9, [sp]
	mov	x1, sp
	mov	x0, x19
	ldur	x10, [sp, #15]
	eor	x8, x8, x24
	eor	x9, x9, x25
	eor	x10, x10, x26
	orr	x8, x8, x9
	orr	x8, x8, x10
	cmp	x8, #0
	csinc	w23, w23, wzr, ne
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	ldrb	w8, [sp]
	cbnz	w8, .LBB150_5
// %bb.6:
	cbz	w23, .LBB150_1
// %bb.7:
	mov	x1, sp
	mov	x0, x19
	mov	x23, sp
	bl	_ZL18stbi__hdr_gettokenP13stbi__contextPc
	ldrh	w8, [sp]
	mov	w10, #22829
	ldrb	w9, [sp, #2]
	eor	w8, w8, w10
	eor	w9, w9, #0x20
	orr	w8, w8, w9
	cbnz	w8, .LBB150_1
// %bb.8:
	orr	x0, x23, #0x3
	add	x1, x29, #24
	mov	w2, #10
	str	x0, [x29, #24]
	bl	strtol
	ldr	x8, [x29, #24]
	str	w0, [x22]
	sub	x23, x8, #1
.LBB150_9:                              // =>This Inner Loop Header: Depth=1
	ldrb	w8, [x23, #1]!
	cmp	w8, #32
	b.eq	.LBB150_9
// %bb.10:
	adrp	x1, .L.str.103
	mov	x0, x23
	add	x1, x1, :lo12:.L.str.103
	mov	w2, #3
	mov	w22, #3
	bl	strncmp
	cbnz	w0, .LBB150_1
// %bb.11:
	add	x0, x23, #3
	mov	x1, xzr
	mov	w2, #10
	str	x0, [x29, #24]
	bl	strtol
	mov	x8, x0
	mov	w0, #1
	str	w8, [x21]
	str	w22, [x20]
	b	.LBB150_2
.LBB150_12:
	str	x23, [x29, #24]
	b	.LBB150_1
.Lfunc_end150:
	.size	_ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_, .Lfunc_end150-_ZL14stbi__hdr_infoP13stbi__contextPiS1_S1_
	.cfi_endproc
                                        // -- End function
	.p2align	2                               // -- Begin function _ZL14stbi__tga_infoP13stbi__contextPiS1_S1_
	.type	_ZL14stbi__tga_infoP13stbi__contextPiS1_S1_,@function
_ZL14stbi__tga_infoP13stbi__contextPiS1_S1_: // @_ZL14stbi__tga_infoP13stbi__contextPiS1_S1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	stp	x24, x23, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x9, x8, [x0, #184]
	mov	x20, x3
	mov	x21, x2
	mov	x19, x0
	mov	x22, x1
	cmp	x9, x8
	b.hs	.LBB151_2
// %bb.1:
	add	x9, x9, #1
	b	.LBB151_7
.LBB151_2:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB151_8
// %bb.3:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_5
// %bb.4:
	add	x8, x19, w0, sxtw
	add	x8, x8, #56
	b	.LBB151_6
.LBB151_5:
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB151_6:
	add	x9, x19, #57
	str	x8, [x19, #192]
.LBB151_7:
	str	x9, [x19, #184]
.LBB151_8:
	cmp	x9, x8
	b.hs	.LBB151_10
// %bb.9:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
	cmp	w10, #2
	b.lo	.LBB151_14
	b	.LBB151_70
.LBB151_10:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB151_14
// %bb.11:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_13
// %bb.12:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w10, #2
	b.lo	.LBB151_14
	b	.LBB151_70
.LBB151_13:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	w10, #2
	b.hs	.LBB151_70
.LBB151_14:
	cmp	x9, x8
	b.hs	.LBB151_16
// %bb.15:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w9, [x9]
	mov	w0, wzr
	cmp	w9, #11
	b.ls	.LBB151_22
	b	.LBB151_20
.LBB151_16:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB151_19
// %bb.17:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_21
// %bb.18:
	mov	x8, x19
	ldrb	w9, [x8, #56]!
	add	x8, x8, w0, sxtw
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	mov	w0, wzr
	cmp	w9, #11
	b.ls	.LBB151_22
	b	.LBB151_20
.LBB151_19:
	mov	w0, wzr
.LBB151_20:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB151_21:
	mov	w9, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
	add	x10, x19, #57
	stp	x10, x8, [x19, #184]
	mov	w0, wzr
	cmp	w9, #11
	b.hi	.LBB151_20
.LBB151_22:
	mov	w11, #1
	lsl	w9, w11, w9
	mov	w11, #3598
	tst	w9, w11
	b.eq	.LBB151_20
// %bb.23:
	ldr	x9, [x19, #16]
	cbz	x9, .LBB151_29
// %bb.24:
	sub	w9, w8, w10
	cmp	w9, #8
	b.gt	.LBB151_29
// %bb.25:
	mov	w11, #9
	ldr	x10, [x19, #24]
	ldr	x0, [x19, #40]
	sub	w1, w11, w9
	str	x8, [x19, #184]
	blr	x10
	ldp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.lo	.LBB151_30
.LBB151_26:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB151_31
// %bb.27:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_35
// %bb.28:
	mov	x8, x19
	ldrb	w23, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB151_36
.LBB151_29:
	add	x9, x10, #9
	str	x9, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB151_26
.LBB151_30:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w23, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB151_32
	b	.LBB151_37
.LBB151_31:
	mov	w23, wzr
	cmp	x9, x8
	b.lo	.LBB151_37
.LBB151_32:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB151_38
// %bb.33:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_39
// %bb.34:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB151_40
.LBB151_35:
	mov	w23, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB151_36:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB151_32
.LBB151_37:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB151_38:
	bfi	w23, w10, #8, #8
	cbnz	w23, .LBB151_41
	b	.LBB151_70
.LBB151_39:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB151_40:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w23, w10, #8, #8
	cbz	w23, .LBB151_70
.LBB151_41:
	cmp	x9, x8
	b.hs	.LBB151_43
// %bb.42:
	add	x10, x9, #1
	str	x10, [x19, #184]
	ldrb	w24, [x9]
	mov	x9, x10
	cmp	x9, x8
	b.hs	.LBB151_47
	b	.LBB151_52
.LBB151_43:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB151_46
// %bb.44:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_50
// %bb.45:
	mov	x8, x19
	ldrb	w24, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB151_51
.LBB151_46:
	mov	w24, wzr
	cmp	x9, x8
	b.lo	.LBB151_52
.LBB151_47:
	ldr	w10, [x19, #48]
	cbz	w10, .LBB151_53
// %bb.48:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_54
// %bb.49:
	mov	x8, x19
	ldrb	w10, [x8, #56]!
	add	x8, x8, w0, sxtw
	b	.LBB151_55
.LBB151_50:
	mov	w24, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB151_51:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	cmp	x9, x8
	b.hs	.LBB151_47
.LBB151_52:
	add	x11, x9, #1
	str	x11, [x19, #184]
	ldrb	w10, [x9]
	mov	x9, x11
.LBB151_53:
	bfi	w24, w10, #8, #8
	cbnz	w24, .LBB151_56
	b	.LBB151_70
.LBB151_54:
	mov	w10, wzr
	add	x8, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB151_55:
	add	x9, x19, #57
	stp	x9, x8, [x19, #184]
	bfi	w24, w10, #8, #8
	cbz	w24, .LBB151_70
.LBB151_56:
	cmp	x9, x8
	b.hs	.LBB151_58
// %bb.57:
	add	x8, x9, #1
	str	x8, [x19, #184]
	ldrb	w8, [x9]
	b	.LBB151_63
.LBB151_58:
	ldr	w8, [x19, #48]
	cbz	w8, .LBB151_63
// %bb.59:
	ldr	x8, [x19, #16]
	add	x1, x19, #56
	ldr	x0, [x19, #40]
	ldr	w2, [x19, #52]
	blr	x8
	cbz	w0, .LBB151_61
// %bb.60:
	mov	x9, x19
	ldrb	w8, [x9, #56]!
	add	x9, x9, w0, sxtw
	b	.LBB151_62
.LBB151_61:
	mov	w8, wzr
	add	x9, x19, #57
	str	wzr, [x19, #48]
	strb	wzr, [x19, #56]
.LBB151_62:
	add	x10, x19, #57
	stp	x10, x9, [x19, #184]
.LBB151_63:
	sub	w9, w8, #8
	ubfx	w10, w9, #3, #5
	bfi	w10, w9, #5, #27
	and	w9, w10, #0xff
	cmp	w9, #4
	b.hs	.LBB151_70
// %bb.64:
	cbz	x22, .LBB151_66
// %bb.65:
	str	w23, [x22]
.LBB151_66:
	cbz	x21, .LBB151_68
// %bb.67:
	str	w24, [x21]
.LBB151_68:
	cbz	x20, .LBB151_71
// %bb.69:
	lsr	w8, w8, #3
	mov	w0, #1
	str	w8, [x20]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB151_70:
	ldr	x8, [x19, #200]
	mov	w0, wzr
	str	x8, [x19, #184]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB151_71:
	mov	w0, #1
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end151:
	.size	_ZL14stbi__tga_infoP13stbi__contextPiS1_S1_, .Lfunc_end151-_ZL14stbi__tga_infoP13stbi__contextPiS1_S1_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end152:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end152-_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end153:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end153-_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV7xy_rect+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV7xy_rect+16
	str	x8, [x0, #16]
	cbz	x19, .LBB154_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB154_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB154_4
	b	.LBB154_8
.LBB154_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB154_8
.LBB154_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB154_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB154_8
.LBB154_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB154_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB154_6
.LBB154_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end154:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end154-_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end155:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end155-_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB156_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB156_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB156_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB156_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB156_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB156_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end156:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end156-_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldp	x23, x19, [x7]
	mov	x20, x1
	ldr	d8, [x4]
	ldr	d12, [x2]
	ldr	d11, [x3]
	ldr	d9, [x5]
	ldr	d10, [x6]
	cbz	x19, .LBB157_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB157_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7xy_rect+16
	add	x9, x9, :lo12:_ZTV7xy_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB157_5
.LBB157_3:
	adrp	x8, _ZTV7xy_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7xy_rect+16
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB157_13
.LBB157_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7xy_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7xy_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB157_11
.LBB157_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB157_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB157_13
.LBB157_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB157_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB157_10
	b	.LBB157_13
.LBB157_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB157_13
.LBB157_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB157_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	cbnz	w8, .LBB157_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB157_7
.LBB157_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end157:
	.size	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_, .Lfunc_end157-_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end158:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end158-_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end159:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end159-_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV7xz_rect+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV7xz_rect+16
	str	x8, [x0, #16]
	cbz	x19, .LBB160_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB160_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB160_4
	b	.LBB160_8
.LBB160_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB160_8
.LBB160_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB160_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB160_8
.LBB160_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB160_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB160_6
.LBB160_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end160:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end160-_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end161:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end161-_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB162_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB162_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB162_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB162_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB162_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB162_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end162:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end162-_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldp	x23, x19, [x7]
	mov	x20, x1
	ldr	d8, [x4]
	ldr	d12, [x2]
	ldr	d11, [x3]
	ldr	d9, [x5]
	ldr	d10, [x6]
	cbz	x19, .LBB163_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB163_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7xz_rect+16
	add	x9, x9, :lo12:_ZTV7xz_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB163_5
.LBB163_3:
	adrp	x8, _ZTV7xz_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7xz_rect+16
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB163_13
.LBB163_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7xz_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7xz_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB163_11
.LBB163_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB163_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB163_13
.LBB163_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB163_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB163_10
	b	.LBB163_13
.LBB163_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB163_13
.LBB163_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB163_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	cbnz	w8, .LBB163_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB163_7
.LBB163_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end163:
	.size	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_, .Lfunc_end163-_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end164:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end164-_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end165:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end165-_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV7yz_rect+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV7yz_rect+16
	str	x8, [x0, #16]
	cbz	x19, .LBB166_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB166_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB166_4
	b	.LBB166_8
.LBB166_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB166_8
.LBB166_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB166_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB166_8
.LBB166_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB166_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB166_6
.LBB166_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end166:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end166-_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end167:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end167-_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB168_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB168_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB168_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB168_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB168_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB168_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end168:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end168-_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldp	x23, x19, [x7]
	mov	x20, x1
	ldr	d8, [x4]
	ldr	d12, [x2]
	ldr	d11, [x3]
	ldr	d9, [x5]
	ldr	d10, [x6]
	cbz	x19, .LBB169_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB169_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7yz_rect+16
	add	x9, x9, :lo12:_ZTV7yz_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB169_5
.LBB169_3:
	adrp	x8, _ZTV7yz_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7yz_rect+16
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB169_13
.LBB169_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7yz_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7yz_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB169_11
.LBB169_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB169_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB169_13
.LBB169_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB169_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB169_10
	b	.LBB169_13
.LBB169_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB169_13
.LBB169_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB169_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d8, d9, [x20, #40]
	str	d10, [x20, #56]
	cbnz	w8, .LBB169_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB169_7
.LBB169_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end169:
	.size	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_, .Lfunc_end169-_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JdddddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_,"axG",@progbits,_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_,comdat
	.weak	_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_ // -- Begin function _ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_
	.p2align	2
	.type	_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_,@function
_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_: // @_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	sub	x8, x1, x0
	cmp	x8, #257
	b.lt	.LBB170_6
// %bb.1:
	mov	x21, x3
	mov	x20, x1
	mov	x19, x0
	add	x22, x0, #16
	sub	x23, x2, #1
.LBB170_2:                              // =>This Inner Loop Header: Depth=1
	cmn	x23, #1
	b.eq	.LBB170_4
// %bb.3:                               //   in Loop: Header=BB170_2 Depth=1
	lsr	x8, x8, #1
	sub	x3, x20, #16
	and	x8, x8, #0x7ffffffffffffff0
	mov	x0, x19
	add	x2, x19, x8
	mov	x1, x22
	mov	x4, x21
	bl	_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_
	mov	x0, x22
	mov	x1, x20
	mov	x2, x19
	mov	x3, x21
	bl	_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_
	mov	x1, x20
	mov	x2, x23
	mov	x3, x21
	mov	x24, x0
	bl	_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_
	sub	x8, x24, x19
	sub	x23, x23, #1
	mov	x20, x24
	cmp	x8, #256
	b.gt	.LBB170_2
	b	.LBB170_6
.LBB170_4:
	add	x2, sp, #8
	mov	x0, x19
	mov	x1, x20
	stp	x21, x21, [sp]
	bl	_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_
	neg	x21, x19
.LBB170_5:                              // =>This Inner Loop Header: Depth=1
	sub	x20, x20, #16
	mov	x3, sp
	mov	x0, x19
	mov	x1, x20
	mov	x2, x20
	bl	_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_
	add	x8, x21, x20
	cmp	x8, #16
	b.gt	.LBB170_5
.LBB170_6:
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.Lfunc_end170:
	.size	_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_, .Lfunc_end170-_ZSt16__introsort_loopIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElNS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_T1_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_,"axG",@progbits,_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_,comdat
	.weak	_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_ // -- Begin function _ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_
	.p2align	2
	.type	_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_,@function
_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_: // @_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_
.Lfunc_begin19:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception19
// %bb.0:
	sub	sp, sp, #112
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	str	x25, [sp, #48]                  // 8-byte Folded Spill
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	sub	x8, x1, x0
	cmp	x8, #32
	b.ge	.LBB171_2
.LBB171_1:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	ldr	x25, [sp, #48]                  // 8-byte Folded Reload
	add	sp, sp, #112
	ret
.LBB171_2:
	asr	x21, x8, #4
	adrp	x25, :got:__libc_single_threaded
	sub	x8, x21, #2
	mov	x19, x2
	lsr	x22, x8, #1
	mov	x20, x0
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
	add	x8, x0, x22, lsl #4
	add	x24, x8, #8
	b	.LBB171_4
.LBB171_3:                              //   in Loop: Header=BB171_4 Depth=1
	sub	x24, x24, #16
	cmn	x22, #1
	b.eq	.LBB171_1
.LBB171_4:                              // =>This Inner Loop Header: Depth=1
	ldur	x8, [x24, #-8]
	str	x8, [sp, #16]
	ldr	x8, [x24]
	stp	xzr, xzr, [x24, #-8]
	ldr	x9, [sp, #16]
	stp	xzr, xzr, [sp, #16]
	ldr	x4, [x19]
	stp	x9, x8, [sp]
.Ltmp782:
	mov	x3, sp
	mov	x0, x20
	mov	x1, x22
	mov	x2, x21
	bl	_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_
.Ltmp783:
// %bb.5:                               //   in Loop: Header=BB171_4 Depth=1
	ldr	x23, [sp, #8]
	cbz	x23, .LBB171_12
// %bb.6:                               //   in Loop: Header=BB171_4 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB171_8
// %bb.7:                               //   in Loop: Header=BB171_4 Depth=1
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.eq	.LBB171_9
	b	.LBB171_12
.LBB171_8:                              //   in Loop: Header=BB171_4 Depth=1
	add	x1, x23, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB171_12
.LBB171_9:                              //   in Loop: Header=BB171_4 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB171_18
// %bb.10:                              //   in Loop: Header=BB171_4 Depth=1
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	cmp	w0, #1
	b.ne	.LBB171_12
.LBB171_11:                             //   in Loop: Header=BB171_4 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
.LBB171_12:                             //   in Loop: Header=BB171_4 Depth=1
	ldr	x23, [sp, #24]
	sub	x22, x22, #1
	cbz	x23, .LBB171_3
// %bb.13:                              //   in Loop: Header=BB171_4 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB171_15
// %bb.14:                              //   in Loop: Header=BB171_4 Depth=1
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.ne	.LBB171_3
	b	.LBB171_16
.LBB171_15:                             //   in Loop: Header=BB171_4 Depth=1
	add	x1, x23, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB171_3
.LBB171_16:                             //   in Loop: Header=BB171_4 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB171_19
// %bb.17:                              //   in Loop: Header=BB171_4 Depth=1
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	cmp	w0, #1
	b.ne	.LBB171_3
	b	.LBB171_20
.LBB171_18:                             //   in Loop: Header=BB171_4 Depth=1
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB171_11
	b	.LBB171_12
.LBB171_19:                             //   in Loop: Header=BB171_4 Depth=1
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB171_3
.LBB171_20:                             //   in Loop: Header=BB171_4 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB171_3
.LBB171_21:
.Ltmp784:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end171:
	.size	_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_, .Lfunc_end171-_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_
	.cfi_endproc
	.section	.gcc_except_table._ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_,"aG",@progbits,_ZSt11__make_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_RT0_,comdat
	.p2align	2
GCC_except_table171:
.Lexception19:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end19-.Lcst_begin19
.Lcst_begin19:
	.uleb128 .Ltmp782-.Lfunc_begin19        // >> Call Site 1 <<
	.uleb128 .Ltmp783-.Ltmp782              //   Call between .Ltmp782 and .Ltmp783
	.uleb128 .Ltmp784-.Lfunc_begin19        //     jumps to .Ltmp784
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp783-.Lfunc_begin19        // >> Call Site 2 <<
	.uleb128 .Lfunc_end171-.Ltmp783         //   Call between .Ltmp783 and .Lfunc_end171
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end19:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_,"axG",@progbits,_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_,comdat
	.weak	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_ // -- Begin function _ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	.p2align	2
	.type	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_,@function
_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_: // @_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
.Lfunc_begin20:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception20
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	str	x21, [sp, #48]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	mov	x19, x2
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x1]
	ldr	x20, [x0]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB172_3
// %bb.1:
	ldrb	w9, [x21]
	cbz	w9, .LBB172_6
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB172_3:
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbz	x8, .LBB172_8
.LBB172_4:
	ldrb	w9, [x21]
	cbz	w9, .LBB172_7
// %bb.5:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB172_8
.LBB172_6:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB172_4
	b	.LBB172_8
.LBB172_7:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB172_8:
.Ltmp785:
	add	x0, sp, #16
	mov	x1, sp
	blr	x20
.Ltmp786:
// %bb.9:
	mov	w19, w0
	ldr	x20, [sp, #8]
	cbz	x20, .LBB172_16
// %bb.10:
	ldrb	w8, [x21]
	cbz	w8, .LBB172_12
// %bb.11:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB172_13
	b	.LBB172_16
.LBB172_12:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB172_16
.LBB172_13:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB172_23
// %bb.14:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB172_16
.LBB172_15:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB172_16:
	ldr	x20, [sp, #24]
	cbz	x20, .LBB172_19
// %bb.17:
	ldrb	w8, [x21]
	cbz	w8, .LBB172_20
// %bb.18:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB172_21
.LBB172_19:
	and	w0, w19, #0x1
	ldr	x21, [sp, #48]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB172_20:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB172_19
.LBB172_21:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB172_24
// %bb.22:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB172_19
	b	.LBB172_25
.LBB172_23:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB172_15
	b	.LBB172_16
.LBB172_24:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB172_19
.LBB172_25:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
	and	w0, w19, #0x1
	ldr	x21, [sp, #48]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB172_26:
.Ltmp787:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end172:
	.size	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_, .Lfunc_end172-_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_,"aG",@progbits,_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_,comdat
	.p2align	2
GCC_except_table172:
.Lexception20:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end20-.Lcst_begin20
.Lcst_begin20:
	.uleb128 .Lfunc_begin20-.Lfunc_begin20  // >> Call Site 1 <<
	.uleb128 .Ltmp785-.Lfunc_begin20        //   Call between .Lfunc_begin20 and .Ltmp785
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp785-.Lfunc_begin20        // >> Call Site 2 <<
	.uleb128 .Ltmp786-.Ltmp785              //   Call between .Ltmp785 and .Ltmp786
	.uleb128 .Ltmp787-.Lfunc_begin20        //     jumps to .Ltmp787
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp786-.Lfunc_begin20        // >> Call Site 3 <<
	.uleb128 .Lfunc_end172-.Ltmp786         //   Call between .Ltmp786 and .Lfunc_end172
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end20:
	.p2align	2
                                        // -- End function
	.section	.text._ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_,"axG",@progbits,_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_,comdat
	.weak	_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_ // -- Begin function _ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_
	.p2align	2
	.type	_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_,@function
_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_: // @_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_
.Lfunc_begin21:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception21
// %bb.0:
	sub	sp, sp, #96
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	str	x23, [sp, #48]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	adrp	x23, :got:__libc_single_threaded
	mov	x20, x3
	mov	x21, x1
	mov	x19, x0
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	ldp	x8, x9, [x2]
	str	x8, [sp, #16]
	stp	xzr, xzr, [x2]
	str	x9, [sp, #24]
	ldp	x8, x9, [x0]
	stp	xzr, xzr, [x0]
	ldr	x22, [x2, #8]
	stp	x8, x9, [x2]
	cbz	x22, .LBB173_7
// %bb.1:
	ldrb	w8, [x23]
	cbz	w8, .LBB173_3
// %bb.2:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.eq	.LBB173_4
	b	.LBB173_7
.LBB173_3:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB173_7
.LBB173_4:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB173_22
// %bb.5:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB173_7
.LBB173_6:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB173_7:
	ldp	x8, x9, [sp, #16]
	sub	x10, x21, x19
	stp	xzr, xzr, [sp, #16]
	ldr	x4, [x20]
	asr	x2, x10, #4
	stp	x8, x9, [sp]
.Ltmp788:
	mov	x3, sp
	mov	x0, x19
	mov	x1, xzr
	bl	_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_
.Ltmp789:
// %bb.8:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB173_15
// %bb.9:
	ldrb	w8, [x23]
	cbz	w8, .LBB173_11
// %bb.10:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB173_12
	b	.LBB173_15
.LBB173_11:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB173_15
.LBB173_12:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB173_23
// %bb.13:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB173_15
.LBB173_14:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB173_15:
	ldr	x19, [sp, #24]
	cbz	x19, .LBB173_18
// %bb.16:
	ldrb	w8, [x23]
	cbz	w8, .LBB173_19
// %bb.17:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB173_20
.LBB173_18:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #48]                  // 8-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB173_19:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB173_18
.LBB173_20:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB173_24
// %bb.21:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB173_18
	b	.LBB173_25
.LBB173_22:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB173_6
	b	.LBB173_7
.LBB173_23:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB173_14
	b	.LBB173_15
.LBB173_24:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB173_18
.LBB173_25:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #48]                  // 8-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB173_26:
.Ltmp790:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end173:
	.size	_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_, .Lfunc_end173-_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_
	.cfi_endproc
	.section	.gcc_except_table._ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_,"aG",@progbits,_ZSt10__pop_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_RT0_,comdat
	.p2align	2
GCC_except_table173:
.Lexception21:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end21-.Lcst_begin21
.Lcst_begin21:
	.uleb128 .Lfunc_begin21-.Lfunc_begin21  // >> Call Site 1 <<
	.uleb128 .Ltmp788-.Lfunc_begin21        //   Call between .Lfunc_begin21 and .Ltmp788
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp788-.Lfunc_begin21        // >> Call Site 2 <<
	.uleb128 .Ltmp789-.Ltmp788              //   Call between .Ltmp788 and .Ltmp789
	.uleb128 .Ltmp790-.Lfunc_begin21        //     jumps to .Ltmp790
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp789-.Lfunc_begin21        // >> Call Site 3 <<
	.uleb128 .Lfunc_end173-.Ltmp789         //   Call between .Ltmp789 and .Lfunc_end173
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end21:
	.p2align	2
                                        // -- End function
	.section	.text._ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_,"axG",@progbits,_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_,comdat
	.weak	_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_ // -- Begin function _ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_
	.p2align	2
	.type	_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_,@function
_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_: // @_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_
.Lfunc_begin22:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception22
// %bb.0:
	sub	sp, sp, #128
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x28, x27, [sp, #48]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	sub	x25, x2, #1
	adrp	x24, :got:__libc_single_threaded
	cmp	x25, #0
	mov	x21, x3
	csel	x8, x2, x25, lt
	mov	x22, x2
	mov	x19, x1
	mov	x20, x0
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	asr	x27, x8, #1
	mov	x26, x1
	cmp	x27, x1
	stur	x4, [x29, #-8]
	b.le	.LBB174_11
// %bb.1:
	mov	x26, x19
	b	.LBB174_4
.LBB174_2:                              //   in Loop: Header=BB174_4 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
.LBB174_3:                              //   in Loop: Header=BB174_4 Depth=1
	cmp	x26, x27
	b.ge	.LBB174_11
.LBB174_4:                              // =>This Inner Loop Header: Depth=1
	lsl	x8, x26, #1
	mov	w23, #1
	add	x28, x8, #2
	bfi	x23, x26, #1, #63
	sub	x0, x29, #8
	add	x1, x20, x28, lsl #4
	add	x2, x20, x23, lsl #4
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tst	w0, #0x1
	add	x8, x20, x26, lsl #4
	csel	x26, x23, x28, ne
	add	x9, x20, x26, lsl #4
	ldp	x10, x11, [x9]
	stp	xzr, xzr, [x9]
	ldr	x23, [x8, #8]
	stp	x10, x11, [x8]
	cbz	x23, .LBB174_3
// %bb.5:                               //   in Loop: Header=BB174_4 Depth=1
	ldrb	w8, [x24]
	cbz	w8, .LBB174_7
// %bb.6:                               //   in Loop: Header=BB174_4 Depth=1
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.ne	.LBB174_3
	b	.LBB174_8
.LBB174_7:                              //   in Loop: Header=BB174_4 Depth=1
	add	x1, x23, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB174_3
.LBB174_8:                              //   in Loop: Header=BB174_4 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB174_10
// %bb.9:                               //   in Loop: Header=BB174_4 Depth=1
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	cmp	w0, #1
	b.ne	.LBB174_3
	b	.LBB174_2
.LBB174_10:                             //   in Loop: Header=BB174_4 Depth=1
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB174_3
	b	.LBB174_2
.LBB174_11:
	tbnz	w22, #0, .LBB174_16
// %bb.12:
	sub	x8, x22, #2
	cmp	x8, #0
	csel	x8, x25, x8, lt
	cmp	x26, x8, asr #1
	b.ne	.LBB174_16
// %bb.13:
	mov	w22, #1
	add	x9, x20, x26, lsl #4
	bfi	x22, x26, #1, #63
	add	x8, x20, x22, lsl #4
	ldp	x10, x11, [x8]
	stp	xzr, xzr, [x8]
	ldr	x23, [x9, #8]
	stp	x10, x11, [x9]
	cbz	x23, .LBB174_17
// %bb.14:
	ldrb	w8, [x24]
	cbz	w8, .LBB174_27
// %bb.15:
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.ne	.LBB174_17
	b	.LBB174_28
.LBB174_16:
	mov	x22, x26
.LBB174_17:
	ldp	x9, x10, [x21]
	stp	xzr, xzr, [x21]
	ldur	x8, [x29, #-8]
	str	x9, [sp]
	stp	x10, x8, [sp, #8]
.Ltmp791:
	mov	x3, sp
	add	x4, sp, #16
	mov	x0, x20
	mov	x1, x22
	mov	x2, x19
	bl	_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_
.Ltmp792:
// %bb.18:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB174_25
// %bb.19:
	ldrb	w8, [x24]
	cbz	w8, .LBB174_21
// %bb.20:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB174_22
	b	.LBB174_25
.LBB174_21:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB174_25
.LBB174_22:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB174_26
// %bb.23:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB174_25
.LBB174_24:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB174_25:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB174_26:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB174_24
	b	.LBB174_25
.LBB174_27:
	add	x1, x23, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB174_17
.LBB174_28:
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB174_30
// %bb.29:
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	cmp	w0, #1
	b.ne	.LBB174_17
	b	.LBB174_31
.LBB174_30:
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB174_17
.LBB174_31:
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB174_17
.LBB174_32:
.Ltmp793:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end174:
	.size	_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_, .Lfunc_end174-_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_
	.cfi_endproc
	.section	.gcc_except_table._ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_,"aG",@progbits,_ZSt13__adjust_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_T0_SG_T1_T2_,comdat
	.p2align	2
GCC_except_table174:
.Lexception22:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end22-.Lcst_begin22
.Lcst_begin22:
	.uleb128 .Lfunc_begin22-.Lfunc_begin22  // >> Call Site 1 <<
	.uleb128 .Ltmp791-.Lfunc_begin22        //   Call between .Lfunc_begin22 and .Ltmp791
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp791-.Lfunc_begin22        // >> Call Site 2 <<
	.uleb128 .Ltmp792-.Ltmp791              //   Call between .Ltmp791 and .Ltmp792
	.uleb128 .Ltmp793-.Lfunc_begin22        //     jumps to .Ltmp793
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp792-.Lfunc_begin22        // >> Call Site 3 <<
	.uleb128 .Lfunc_end174-.Ltmp792         //   Call between .Ltmp792 and .Lfunc_end174
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end22:
	.p2align	2
                                        // -- End function
	.section	.text._ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_,"axG",@progbits,_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_,comdat
	.weak	_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_ // -- Begin function _ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_
	.p2align	2
	.type	_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_,@function
_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_: // @_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-80]!           // 16-byte Folded Spill
	stp	x26, x25, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	stp	x24, x23, [sp, #32]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	adrp	x25, :got:__libc_single_threaded
	mov	x19, x3
	mov	x23, x1
	mov	x20, x0
	cmp	x1, x2
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
	b.le	.LBB175_12
// %bb.1:
	mov	x21, x4
	mov	x22, x2
	b	.LBB175_3
.LBB175_2:                              //   in Loop: Header=BB175_3 Depth=1
	mov	x23, x26
	cmp	x26, x22
	b.le	.LBB175_13
.LBB175_3:                              // =>This Inner Loop Header: Depth=1
	sub	x8, x23, #1
	mov	x0, x21
	cmp	x8, #0
	mov	x2, x19
	csel	x8, x23, x8, lt
	asr	x26, x8, #1
	add	x24, x20, x26, lsl #4
	mov	x1, x24
	bl	_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_
	tbz	w0, #0, .LBB175_16
// %bb.4:                               //   in Loop: Header=BB175_3 Depth=1
	add	x8, x20, x23, lsl #4
	ldp	x9, x10, [x24]
	stp	xzr, xzr, [x24]
	ldr	x23, [x8, #8]
	stp	x9, x10, [x8]
	cbz	x23, .LBB175_2
// %bb.5:                               //   in Loop: Header=BB175_3 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB175_7
// %bb.6:                               //   in Loop: Header=BB175_3 Depth=1
	ldr	w0, [x23, #8]
	sub	w8, w0, #1
	str	w8, [x23, #8]
	cmp	w0, #1
	b.ne	.LBB175_2
	b	.LBB175_8
.LBB175_7:                              //   in Loop: Header=BB175_3 Depth=1
	add	x1, x23, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB175_2
.LBB175_8:                              //   in Loop: Header=BB175_3 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB175_10
// %bb.9:                               //   in Loop: Header=BB175_3 Depth=1
	ldr	w0, [x23, #12]
	sub	w8, w0, #1
	str	w8, [x23, #12]
	cmp	w0, #1
	b.ne	.LBB175_2
	b	.LBB175_11
.LBB175_10:                             //   in Loop: Header=BB175_3 Depth=1
	add	x1, x23, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB175_2
.LBB175_11:                             //   in Loop: Header=BB175_3 Depth=1
	ldr	x8, [x23]
	mov	x0, x23
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB175_2
.LBB175_12:
	mov	x26, x23
.LBB175_13:
	add	x8, x20, x26, lsl #4
	ldp	x9, x10, [x19]
	stp	xzr, xzr, [x19]
	ldr	x19, [x8, #8]
	stp	x9, x10, [x8]
	cbz	x19, .LBB175_22
.LBB175_14:
	ldrb	w8, [x25]
	cbz	w8, .LBB175_17
// %bb.15:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB175_18
	b	.LBB175_22
.LBB175_16:
	mov	x26, x23
	add	x8, x20, x26, lsl #4
	ldp	x9, x10, [x19]
	stp	xzr, xzr, [x19]
	ldr	x19, [x8, #8]
	stp	x9, x10, [x8]
	cbnz	x19, .LBB175_14
	b	.LBB175_22
.LBB175_17:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB175_22
.LBB175_18:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB175_21
// %bb.19:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB175_22
.LBB175_20:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	br	x1
.LBB175_21:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB175_20
.LBB175_22:
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #80             // 16-byte Folded Reload
	ret
.Lfunc_end175:
	.size	_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_, .Lfunc_end175-_ZSt11__push_heapIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEElS4_NS0_5__ops14_Iter_comp_valIPFbS4_S4_EEEEvT_T0_SG_T1_RT2_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	ldr	x19, [x0, #8]
	cbz	x19, .LBB176_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB176_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB176_4
	b	.LBB176_8
.LBB176_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB176_8
.LBB176_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB176_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB176_8
.LBB176_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB176_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB176_6
.LBB176_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end176:
	.size	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end176-_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_,"axG",@progbits,_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_,comdat
	.weak	_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_ // -- Begin function _ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_
	.p2align	2
	.type	_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_,@function
_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_: // @_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_
.Lfunc_begin23:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception23
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	str	x21, [sp, #48]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	mov	x19, x2
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x1]
	ldr	x20, [x0]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB177_3
// %bb.1:
	ldrb	w9, [x21]
	cbz	w9, .LBB177_6
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB177_3:
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbz	x8, .LBB177_8
.LBB177_4:
	ldrb	w9, [x21]
	cbz	w9, .LBB177_7
// %bb.5:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB177_8
.LBB177_6:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB177_4
	b	.LBB177_8
.LBB177_7:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB177_8:
.Ltmp794:
	add	x0, sp, #16
	mov	x1, sp
	blr	x20
.Ltmp795:
// %bb.9:
	mov	w19, w0
	ldr	x20, [sp, #8]
	cbz	x20, .LBB177_16
// %bb.10:
	ldrb	w8, [x21]
	cbz	w8, .LBB177_12
// %bb.11:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB177_13
	b	.LBB177_16
.LBB177_12:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB177_16
.LBB177_13:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB177_23
// %bb.14:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB177_16
.LBB177_15:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB177_16:
	ldr	x20, [sp, #24]
	cbz	x20, .LBB177_19
// %bb.17:
	ldrb	w8, [x21]
	cbz	w8, .LBB177_20
// %bb.18:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB177_21
.LBB177_19:
	and	w0, w19, #0x1
	ldr	x21, [sp, #48]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB177_20:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB177_19
.LBB177_21:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB177_24
// %bb.22:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB177_19
	b	.LBB177_25
.LBB177_23:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB177_15
	b	.LBB177_16
.LBB177_24:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB177_19
.LBB177_25:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
	and	w0, w19, #0x1
	ldr	x21, [sp, #48]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB177_26:
.Ltmp796:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end177:
	.size	_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_, .Lfunc_end177-_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_,"aG",@progbits,_ZN9__gnu_cxx5__ops14_Iter_comp_valIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEES4_EEbT_RT0_,comdat
	.p2align	2
GCC_except_table177:
.Lexception23:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end23-.Lcst_begin23
.Lcst_begin23:
	.uleb128 .Lfunc_begin23-.Lfunc_begin23  // >> Call Site 1 <<
	.uleb128 .Ltmp794-.Lfunc_begin23        //   Call between .Lfunc_begin23 and .Ltmp794
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp794-.Lfunc_begin23        // >> Call Site 2 <<
	.uleb128 .Ltmp795-.Ltmp794              //   Call between .Ltmp794 and .Ltmp795
	.uleb128 .Ltmp796-.Lfunc_begin23        //     jumps to .Ltmp796
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp795-.Lfunc_begin23        // >> Call Site 3 <<
	.uleb128 .Lfunc_end177-.Ltmp795         //   Call between .Ltmp795 and .Lfunc_end177
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end23:
	.p2align	2
                                        // -- End function
	.section	.text._ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_,"axG",@progbits,_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_,comdat
	.weak	_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_ // -- Begin function _ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_
	.p2align	2
	.type	_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_,@function
_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_: // @_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	mov	x19, x0
	add	x0, sp, #8
	mov	x20, x3
	mov	x21, x2
	mov	x22, x1
	str	x4, [sp, #8]
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tbz	w0, #0, .LBB178_3
// %bb.1:
	add	x0, sp, #8
	mov	x1, x21
	mov	x2, x20
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tbnz	w0, #0, .LBB178_7
// %bb.2:
	add	x0, sp, #8
	mov	x1, x22
	mov	x2, x20
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tbz	w0, #0, .LBB178_4
	b	.LBB178_6
.LBB178_3:
	add	x0, sp, #8
	mov	x1, x22
	mov	x2, x20
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tbz	w0, #0, .LBB178_5
.LBB178_4:
	ldr	x8, [x22]
	ldr	x9, [x19]
	str	x8, [x19]
	str	x9, [x22]
	ldr	x9, [x22, #8]
	ldr	x8, [x19, #8]
	str	x8, [x22, #8]
	str	x9, [x19, #8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB178_5:
	add	x0, sp, #8
	mov	x1, x21
	mov	x2, x20
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tbz	w0, #0, .LBB178_7
.LBB178_6:
	ldr	x8, [x20]
	ldr	x9, [x19]
	str	x8, [x19]
	str	x9, [x20]
	ldr	x9, [x20, #8]
	ldr	x8, [x19, #8]
	str	x8, [x20, #8]
	str	x9, [x19, #8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB178_7:
	ldr	x8, [x21]
	ldr	x9, [x19]
	str	x8, [x19]
	str	x9, [x21]
	ldr	x9, [x21, #8]
	ldr	x8, [x19, #8]
	str	x8, [x21, #8]
	str	x9, [x19, #8]
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.Lfunc_end178:
	.size	_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_, .Lfunc_end178-_ZSt22__move_median_to_firstIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_SF_SF_T0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_,"axG",@progbits,_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_,comdat
	.weak	_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_ // -- Begin function _ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_
	.p2align	2
	.type	_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_,@function
_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_: // @_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_
.Lfunc_begin24:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception24
// %bb.0:
	sub	sp, sp, #112
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x26, x25, [sp, #48]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 80
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w30, -72
	.cfi_offset w29, -80
	adrp	x25, :got:__libc_single_threaded
	mov	x19, x3
	mov	x20, x2
	mov	x21, x1
	mov	x22, x0
	ldr	x25, [x25, :got_lo12:__libc_single_threaded]
.LBB179_1:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB179_29 Depth 2
	mov	x26, x22
	ldr	x8, [x26]
	str	x8, [sp, #16]
	ldr	x8, [x26, #8]
	str	x8, [sp, #24]
	cbz	x8, .LBB179_4
.LBB179_2:                              //   in Loop: Header=BB179_1 Depth=1
	ldrb	w9, [x25]
	cbz	w9, .LBB179_7
// %bb.3:                               //   in Loop: Header=BB179_1 Depth=1
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB179_4:                              //   in Loop: Header=BB179_1 Depth=1
	ldp	x9, x8, [x20]
	stp	x9, x8, [sp]
	cbz	x8, .LBB179_9
.LBB179_5:                              //   in Loop: Header=BB179_1 Depth=1
	ldrb	w9, [x25]
	cbz	w9, .LBB179_8
// %bb.6:                               //   in Loop: Header=BB179_1 Depth=1
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB179_9
.LBB179_7:                              //   in Loop: Header=BB179_1 Depth=1
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x20]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB179_5
	b	.LBB179_9
.LBB179_8:                              //   in Loop: Header=BB179_1 Depth=1
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB179_9:                              //   in Loop: Header=BB179_1 Depth=1
.Ltmp797:
	add	x0, sp, #16
	mov	x1, sp
	blr	x19
.Ltmp798:
// %bb.10:                              //   in Loop: Header=BB179_1 Depth=1
	mov	w23, w0
	ldr	x24, [sp, #8]
	cbz	x24, .LBB179_17
// %bb.11:                              //   in Loop: Header=BB179_1 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB179_13
// %bb.12:                              //   in Loop: Header=BB179_1 Depth=1
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB179_14
	b	.LBB179_17
.LBB179_13:                             //   in Loop: Header=BB179_1 Depth=1
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB179_17
.LBB179_14:                             //   in Loop: Header=BB179_1 Depth=1
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB179_26
// %bb.15:                              //   in Loop: Header=BB179_1 Depth=1
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB179_17
.LBB179_16:                             //   in Loop: Header=BB179_1 Depth=1
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB179_17:                             //   in Loop: Header=BB179_1 Depth=1
	ldr	x24, [sp, #24]
	cbz	x24, .LBB179_24
// %bb.18:                              //   in Loop: Header=BB179_1 Depth=1
	ldrb	w8, [x25]
	cbz	w8, .LBB179_20
// %bb.19:                              //   in Loop: Header=BB179_1 Depth=1
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB179_21
	b	.LBB179_24
.LBB179_20:                             //   in Loop: Header=BB179_1 Depth=1
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB179_24
.LBB179_21:                             //   in Loop: Header=BB179_1 Depth=1
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB179_27
// %bb.22:                              //   in Loop: Header=BB179_1 Depth=1
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB179_24
.LBB179_23:                             //   in Loop: Header=BB179_1 Depth=1
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB179_24:                             //   in Loop: Header=BB179_1 Depth=1
	tbz	w23, #0, .LBB179_29
// %bb.25:                              //   in Loop: Header=BB179_1 Depth=1
	add	x22, x22, #16
	ldr	x8, [x26, #16]!
	str	x8, [sp, #16]
	ldr	x8, [x26, #8]
	str	x8, [sp, #24]
	cbnz	x8, .LBB179_2
	b	.LBB179_4
.LBB179_26:                             //   in Loop: Header=BB179_1 Depth=1
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB179_16
	b	.LBB179_17
.LBB179_27:                             //   in Loop: Header=BB179_1 Depth=1
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB179_23
	b	.LBB179_24
.LBB179_28:                             //   in Loop: Header=BB179_29 Depth=2
	tbz	w23, #0, .LBB179_54
.LBB179_29:                             //   Parent Loop BB179_1 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	x9, x8, [x20]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB179_32
// %bb.30:                              //   in Loop: Header=BB179_29 Depth=2
	ldrb	w9, [x25]
	cbz	w9, .LBB179_35
// %bb.31:                              //   in Loop: Header=BB179_29 Depth=2
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB179_32:                             //   in Loop: Header=BB179_29 Depth=2
	ldur	x8, [x21, #-16]
	str	x8, [sp]
	ldur	x8, [x21, #-8]
	str	x8, [sp, #8]
	cbz	x8, .LBB179_37
.LBB179_33:                             //   in Loop: Header=BB179_29 Depth=2
	ldrb	w9, [x25]
	cbz	w9, .LBB179_36
// %bb.34:                              //   in Loop: Header=BB179_29 Depth=2
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB179_37
.LBB179_35:                             //   in Loop: Header=BB179_29 Depth=2
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldur	x8, [x21, #-16]
	str	x8, [sp]
	ldur	x8, [x21, #-8]
	str	x8, [sp, #8]
	cbnz	x8, .LBB179_33
	b	.LBB179_37
.LBB179_36:                             //   in Loop: Header=BB179_29 Depth=2
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB179_37:                             //   in Loop: Header=BB179_29 Depth=2
.Ltmp800:
	add	x0, sp, #16
	mov	x1, sp
	blr	x19
.Ltmp801:
// %bb.38:                              //   in Loop: Header=BB179_29 Depth=2
	mov	w23, w0
	ldr	x24, [sp, #8]
	cbz	x24, .LBB179_45
// %bb.39:                              //   in Loop: Header=BB179_29 Depth=2
	ldrb	w8, [x25]
	cbz	w8, .LBB179_41
// %bb.40:                              //   in Loop: Header=BB179_29 Depth=2
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.eq	.LBB179_42
	b	.LBB179_45
.LBB179_41:                             //   in Loop: Header=BB179_29 Depth=2
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB179_45
.LBB179_42:                             //   in Loop: Header=BB179_29 Depth=2
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB179_51
// %bb.43:                              //   in Loop: Header=BB179_29 Depth=2
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB179_45
.LBB179_44:                             //   in Loop: Header=BB179_29 Depth=2
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
.LBB179_45:                             //   in Loop: Header=BB179_29 Depth=2
	ldr	x24, [sp, #24]
	sub	x21, x21, #16
	cbz	x24, .LBB179_28
// %bb.46:                              //   in Loop: Header=BB179_29 Depth=2
	ldrb	w8, [x25]
	cbz	w8, .LBB179_48
// %bb.47:                              //   in Loop: Header=BB179_29 Depth=2
	ldr	w0, [x24, #8]
	sub	w8, w0, #1
	str	w8, [x24, #8]
	cmp	w0, #1
	b.ne	.LBB179_28
	b	.LBB179_49
.LBB179_48:                             //   in Loop: Header=BB179_29 Depth=2
	add	x1, x24, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB179_28
.LBB179_49:                             //   in Loop: Header=BB179_29 Depth=2
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbz	w8, .LBB179_52
// %bb.50:                              //   in Loop: Header=BB179_29 Depth=2
	ldr	w0, [x24, #12]
	sub	w8, w0, #1
	str	w8, [x24, #12]
	cmp	w0, #1
	b.ne	.LBB179_28
	b	.LBB179_53
.LBB179_51:                             //   in Loop: Header=BB179_29 Depth=2
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB179_44
	b	.LBB179_45
.LBB179_52:                             //   in Loop: Header=BB179_29 Depth=2
	add	x1, x24, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB179_28
.LBB179_53:                             //   in Loop: Header=BB179_29 Depth=2
	ldr	x8, [x24]
	mov	x0, x24
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB179_28
.LBB179_54:                             //   in Loop: Header=BB179_1 Depth=1
	cmp	x26, x21
	b.hs	.LBB179_56
// %bb.55:                              //   in Loop: Header=BB179_1 Depth=1
	ldr	x8, [x21]
	add	x22, x26, #16
	ldr	x9, [x26]
	str	x8, [x26]
	str	x9, [x21]
	ldr	x9, [x21, #8]
	ldr	x8, [x26, #8]
	str	x8, [x21, #8]
	str	x9, [x26, #8]
	b	.LBB179_1
.LBB179_56:
	mov	x0, x22
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #112
	ret
.LBB179_57:
.Ltmp802:
	b	.LBB179_59
.LBB179_58:
.Ltmp799:
.LBB179_59:
	ldr	x20, [sp, #8]
	mov	x19, x0
	cbz	x20, .LBB179_69
// %bb.60:
	ldrb	w8, [x25]
	cbnz	w8, .LBB179_62
// %bb.61:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB179_63
.LBB179_62:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
.LBB179_63:
	cmp	w0, #1
	b.ne	.LBB179_69
// %bb.64:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbnz	w8, .LBB179_66
// %bb.65:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB179_67
.LBB179_66:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
.LBB179_67:
	cmp	w0, #1
	b.ne	.LBB179_69
// %bb.68:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB179_69:
	ldr	x20, [sp, #24]
	cbz	x20, .LBB179_79
// %bb.70:
	ldrb	w8, [x25]
	cbnz	w8, .LBB179_72
// %bb.71:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB179_73
.LBB179_72:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
.LBB179_73:
	cmp	w0, #1
	b.ne	.LBB179_79
// %bb.74:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x25]
	cbnz	w8, .LBB179_76
// %bb.75:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB179_77
.LBB179_76:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
.LBB179_77:
	cmp	w0, #1
	b.ne	.LBB179_79
// %bb.78:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB179_79:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end179:
	.size	_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_, .Lfunc_end179-_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_
	.cfi_endproc
	.section	.gcc_except_table._ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_,"aG",@progbits,_ZSt21__unguarded_partitionIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEET_SF_SF_SF_T0_,comdat
	.p2align	2
GCC_except_table179:
.Lexception24:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end24-.Lcst_begin24
.Lcst_begin24:
	.uleb128 .Lfunc_begin24-.Lfunc_begin24  // >> Call Site 1 <<
	.uleb128 .Ltmp797-.Lfunc_begin24        //   Call between .Lfunc_begin24 and .Ltmp797
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp797-.Lfunc_begin24        // >> Call Site 2 <<
	.uleb128 .Ltmp798-.Ltmp797              //   Call between .Ltmp797 and .Ltmp798
	.uleb128 .Ltmp799-.Lfunc_begin24        //     jumps to .Ltmp799
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp798-.Lfunc_begin24        // >> Call Site 3 <<
	.uleb128 .Ltmp800-.Ltmp798              //   Call between .Ltmp798 and .Ltmp800
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp800-.Lfunc_begin24        // >> Call Site 4 <<
	.uleb128 .Ltmp801-.Ltmp800              //   Call between .Ltmp800 and .Ltmp801
	.uleb128 .Ltmp802-.Lfunc_begin24        //     jumps to .Ltmp802
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp801-.Lfunc_begin24        // >> Call Site 5 <<
	.uleb128 .Lfunc_end179-.Ltmp801         //   Call between .Ltmp801 and .Lfunc_end179
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end24:
	.p2align	2
                                        // -- End function
	.section	.text._ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_,"axG",@progbits,_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_,comdat
	.weak	_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_ // -- Begin function _ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_
	.p2align	2
	.type	_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_,@function
_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_: // @_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #112
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x28, x27, [sp, #32]             // 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	cmp	x0, x1
	str	x2, [sp, #8]
	b.eq	.LBB180_25
// %bb.1:
	mov	x25, x1
	mov	x20, x0
	add	x8, x0, #16
	cmp	x8, x1
	b.eq	.LBB180_25
// %bb.2:
	adrp	x24, :got:__libc_single_threaded
	mov	w23, #16
	add	x19, x20, #24
	mov	x21, x20
	ldr	x24, [x24, :got_lo12:__libc_single_threaded]
	str	x25, [sp]                       // 8-byte Folded Spill
	b	.LBB180_5
.LBB180_3:                              //   in Loop: Header=BB180_5 Depth=1
	ldr	x1, [sp, #8]
	mov	x0, x21
	bl	_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_
.LBB180_4:                              //   in Loop: Header=BB180_5 Depth=1
	add	x8, x21, #16
	add	x23, x23, #16
	add	x19, x19, #16
	cmp	x8, x25
	b.eq	.LBB180_25
.LBB180_5:                              // =>This Loop Header: Depth=1
                                        //     Child Loop BB180_9 Depth 2
	add	x0, sp, #8
	mov	x1, x8
	mov	x2, x20
	mov	x22, x21
	mov	x21, x8
	bl	_ZN9__gnu_cxx5__ops15_Iter_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclINS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEESE_EEbT_T0_
	tbz	w0, #0, .LBB180_3
// %bb.6:                               //   in Loop: Header=BB180_5 Depth=1
	ldr	x26, [x21]
	sub	x8, x21, x20
	ldr	x27, [x22, #24]
	cmp	x8, #1
	str	xzr, [x22, #24]
	str	xzr, [x21]
	b.lt	.LBB180_17
// %bb.7:                               //   in Loop: Header=BB180_5 Depth=1
	lsr	x8, x23, #4
	mov	x25, x19
	add	x28, x8, #1
	b	.LBB180_9
.LBB180_8:                              //   in Loop: Header=BB180_9 Depth=2
	sub	x28, x28, #1
	sub	x25, x25, #16
	cmp	x28, #1
	b.le	.LBB180_17
.LBB180_9:                              //   Parent Loop BB180_5 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	ldp	x8, x9, [x25, #-24]
	stp	xzr, xzr, [x25, #-24]
	ldr	x22, [x25]
	stp	x8, x9, [x25, #-8]
	cbz	x22, .LBB180_8
// %bb.10:                              //   in Loop: Header=BB180_9 Depth=2
	ldrb	w8, [x24]
	cbz	w8, .LBB180_12
// %bb.11:                              //   in Loop: Header=BB180_9 Depth=2
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.ne	.LBB180_8
	b	.LBB180_13
.LBB180_12:                             //   in Loop: Header=BB180_9 Depth=2
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB180_8
.LBB180_13:                             //   in Loop: Header=BB180_9 Depth=2
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB180_15
// %bb.14:                              //   in Loop: Header=BB180_9 Depth=2
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB180_8
	b	.LBB180_16
.LBB180_15:                             //   in Loop: Header=BB180_9 Depth=2
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB180_8
.LBB180_16:                             //   in Loop: Header=BB180_9 Depth=2
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB180_8
.LBB180_17:                             //   in Loop: Header=BB180_5 Depth=1
	ldr	x22, [x20, #8]
	stp	x26, x27, [x20]
	ldr	x25, [sp]                       // 8-byte Folded Reload
	cbz	x22, .LBB180_4
// %bb.18:                              //   in Loop: Header=BB180_5 Depth=1
	ldrb	w8, [x24]
	cbz	w8, .LBB180_20
// %bb.19:                              //   in Loop: Header=BB180_5 Depth=1
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.ne	.LBB180_4
	b	.LBB180_21
.LBB180_20:                             //   in Loop: Header=BB180_5 Depth=1
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB180_4
.LBB180_21:                             //   in Loop: Header=BB180_5 Depth=1
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x24]
	cbz	w8, .LBB180_23
// %bb.22:                              //   in Loop: Header=BB180_5 Depth=1
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.ne	.LBB180_4
	b	.LBB180_24
.LBB180_23:                             //   in Loop: Header=BB180_5 Depth=1
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB180_4
.LBB180_24:                             //   in Loop: Header=BB180_5 Depth=1
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB180_4
.LBB180_25:
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             // 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #112
	ret
.Lfunc_end180:
	.size	_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_, .Lfunc_end180-_ZSt16__insertion_sortIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops15_Iter_comp_iterIPFbS4_S4_EEEEvT_SF_T0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_,"axG",@progbits,_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_,comdat
	.weak	_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_ // -- Begin function _ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_
	.p2align	2
	.type	_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_,@function
_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_: // @_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_
.Lfunc_begin25:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception25
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x22, x21, [sp, #48]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	stur	x1, [x29, #-8]
	mov	x22, x0
	ldr	x8, [x0]
	adrp	x21, :got:__libc_single_threaded
	sub	x19, x0, #16
	str	x8, [sp, #8]
	str	xzr, [x0]
	ldr	x8, [x22, #8]!
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	str	xzr, [x22]
	str	x8, [sp, #16]
	b	.LBB181_2
.LBB181_1:                              //   in Loop: Header=BB181_2 Depth=1
	sub	x22, x22, #16
	sub	x19, x19, #16
.LBB181_2:                              // =>This Inner Loop Header: Depth=1
.Ltmp803:
	sub	x0, x29, #8
	add	x1, sp, #8
	mov	x2, x19
	bl	_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_
.Ltmp804:
// %bb.3:                               //   in Loop: Header=BB181_2 Depth=1
	tbz	w0, #0, .LBB181_12
// %bb.4:                               //   in Loop: Header=BB181_2 Depth=1
	ldp	x8, x9, [x22, #-24]
	stp	xzr, xzr, [x22, #-24]
	ldr	x20, [x22]
	stp	x8, x9, [x22, #-8]
	cbz	x20, .LBB181_1
// %bb.5:                               //   in Loop: Header=BB181_2 Depth=1
	ldrb	w8, [x21]
	cbz	w8, .LBB181_7
// %bb.6:                               //   in Loop: Header=BB181_2 Depth=1
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.ne	.LBB181_1
	b	.LBB181_8
.LBB181_7:                              //   in Loop: Header=BB181_2 Depth=1
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB181_1
.LBB181_8:                              //   in Loop: Header=BB181_2 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB181_10
// %bb.9:                               //   in Loop: Header=BB181_2 Depth=1
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB181_1
	b	.LBB181_11
.LBB181_10:                             //   in Loop: Header=BB181_2 Depth=1
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB181_1
.LBB181_11:                             //   in Loop: Header=BB181_2 Depth=1
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB181_1
.LBB181_12:
	ldp	x8, x9, [sp, #8]
	stp	xzr, xzr, [sp, #8]
	ldr	x19, [x22]
	stp	x8, x9, [x22, #-8]
	cbz	x19, .LBB181_19
// %bb.13:
	ldrb	w8, [x21]
	cbz	w8, .LBB181_15
// %bb.14:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB181_16
	b	.LBB181_19
.LBB181_15:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB181_19
.LBB181_16:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB181_26
// %bb.17:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB181_19
.LBB181_18:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB181_19:
	ldr	x19, [sp, #16]
	cbz	x19, .LBB181_22
// %bb.20:
	ldrb	w8, [x21]
	cbz	w8, .LBB181_23
// %bb.21:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB181_24
.LBB181_22:
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB181_23:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB181_22
.LBB181_24:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB181_27
// %bb.25:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB181_22
	b	.LBB181_28
.LBB181_26:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB181_18
	b	.LBB181_19
.LBB181_27:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB181_22
.LBB181_28:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB181_29:
.Ltmp805:
	mov	x19, x0
	add	x0, sp, #8
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end181:
	.size	_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_, .Lfunc_end181-_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_
	.cfi_endproc
	.section	.gcc_except_table._ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_,"aG",@progbits,_ZSt25__unguarded_linear_insertIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrI8hittableESt6vectorIS4_SaIS4_EEEENS0_5__ops14_Val_comp_iterIPFbS4_S4_EEEEvT_T0_,comdat
	.p2align	2
GCC_except_table181:
.Lexception25:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end25-.Lcst_begin25
.Lcst_begin25:
	.uleb128 .Ltmp803-.Lfunc_begin25        // >> Call Site 1 <<
	.uleb128 .Ltmp804-.Ltmp803              //   Call between .Ltmp803 and .Ltmp804
	.uleb128 .Ltmp805-.Lfunc_begin25        //     jumps to .Ltmp805
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp804-.Lfunc_begin25        // >> Call Site 2 <<
	.uleb128 .Lfunc_end181-.Ltmp804         //   Call between .Ltmp804 and .Lfunc_end181
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end25:
	.p2align	2
                                        // -- End function
	.section	.text._ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_,"axG",@progbits,_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_,comdat
	.weak	_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_ // -- Begin function _ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_
	.p2align	2
	.type	_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_,@function
_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_: // @_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_
.Lfunc_begin26:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception26
// %bb.0:
	sub	sp, sp, #80
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	str	x21, [sp, #48]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #64]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	mov	x19, x2
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x1]
	ldr	x20, [x0]
	stp	x9, x8, [sp, #16]
	cbz	x8, .LBB182_3
// %bb.1:
	ldrb	w9, [x21]
	cbz	w9, .LBB182_6
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
.LBB182_3:
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbz	x8, .LBB182_8
.LBB182_4:
	ldrb	w9, [x21]
	cbz	w9, .LBB182_7
// %bb.5:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB182_8
.LBB182_6:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
	ldp	x9, x8, [x19]
	stp	x9, x8, [sp]
	cbnz	x8, .LBB182_4
	b	.LBB182_8
.LBB182_7:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB182_8:
.Ltmp806:
	add	x0, sp, #16
	mov	x1, sp
	blr	x20
.Ltmp807:
// %bb.9:
	mov	w19, w0
	ldr	x20, [sp, #8]
	cbz	x20, .LBB182_16
// %bb.10:
	ldrb	w8, [x21]
	cbz	w8, .LBB182_12
// %bb.11:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB182_13
	b	.LBB182_16
.LBB182_12:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB182_16
.LBB182_13:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB182_23
// %bb.14:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB182_16
.LBB182_15:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB182_16:
	ldr	x20, [sp, #24]
	cbz	x20, .LBB182_19
// %bb.17:
	ldrb	w8, [x21]
	cbz	w8, .LBB182_20
// %bb.18:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB182_21
.LBB182_19:
	and	w0, w19, #0x1
	ldr	x21, [sp, #48]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB182_20:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB182_19
.LBB182_21:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB182_24
// %bb.22:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB182_19
	b	.LBB182_25
.LBB182_23:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB182_15
	b	.LBB182_16
.LBB182_24:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB182_19
.LBB182_25:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
	and	w0, w19, #0x1
	ldr	x21, [sp, #48]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	add	sp, sp, #80
	ret
.LBB182_26:
.Ltmp808:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	add	x0, sp, #16
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end182:
	.size	_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_, .Lfunc_end182-_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_,"aG",@progbits,_ZN9__gnu_cxx5__ops14_Val_comp_iterIPFbSt10shared_ptrI8hittableES4_EEclIS4_NS_17__normal_iteratorIPS4_St6vectorIS4_SaIS4_EEEEEEbRT_T0_,comdat
	.p2align	2
GCC_except_table182:
.Lexception26:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end26-.Lcst_begin26
.Lcst_begin26:
	.uleb128 .Lfunc_begin26-.Lfunc_begin26  // >> Call Site 1 <<
	.uleb128 .Ltmp806-.Lfunc_begin26        //   Call between .Lfunc_begin26 and .Ltmp806
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp806-.Lfunc_begin26        // >> Call Site 2 <<
	.uleb128 .Ltmp807-.Ltmp806              //   Call between .Ltmp806 and .Ltmp807
	.uleb128 .Ltmp808-.Lfunc_begin26        //     jumps to .Ltmp808
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp807-.Lfunc_begin26        // >> Call Site 3 <<
	.uleb128 .Lfunc_end182-.Ltmp807         //   Call between .Ltmp807 and .Lfunc_end182
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end26:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end183:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end183-_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end184:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end184-_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	add	x0, x0, #16
	mov	x1, x0
	b	_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_
.Lfunc_end185:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end185-_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end186:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end186-_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB187_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB187_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB187_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB187_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB187_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB187_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end187:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end187-_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_,@function
_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_: // @_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	adrp	x8, _ZTV8bvh_node+16
	mov	x19, x1
	ldr	x20, [x1, #32]
	add	x8, x8, :lo12:_ZTV8bvh_node+16
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	str	x8, [x1]
	cbz	x20, .LBB188_7
// %bb.1:
	ldrb	w8, [x21]
	cbz	w8, .LBB188_3
// %bb.2:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB188_4
	b	.LBB188_7
.LBB188_3:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB188_7
.LBB188_4:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB188_14
// %bb.5:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB188_7
.LBB188_6:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB188_7:
	ldr	x19, [x19, #16]
	cbz	x19, .LBB188_16
// %bb.8:
	ldrb	w8, [x21]
	cbz	w8, .LBB188_10
// %bb.9:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB188_11
	b	.LBB188_16
.LBB188_10:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB188_16
.LBB188_11:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB188_15
// %bb.12:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB188_16
.LBB188_13:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	br	x1
.LBB188_14:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB188_6
	b	.LBB188_7
.LBB188_15:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB188_13
.LBB188_16:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end188:
	.size	_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_, .Lfunc_end188-_ZN9__gnu_cxx13new_allocatorI8bvh_nodeE7destroyIS1_EEvPT_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end189:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end189-_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end190:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end190-_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	add	x0, x0, #16
	mov	x1, x0
	b	_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_
.Lfunc_end191:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end191-_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end192:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end192-_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB193_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB193_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB193_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB193_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB193_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB193_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end193:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end193-_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_
.Lfunc_begin27:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception27
// %bb.0:
	sub	sp, sp, #96
	str	d10, [sp, #32]                  // 8-byte Folded Spill
	stp	d9, d8, [sp, #40]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #56]             // 16-byte Folded Spill
	add	x29, sp, #56
	str	x21, [sp, #72]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 40
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w30, -32
	.cfi_offset w29, -40
	.cfi_offset b8, -48
	.cfi_offset b9, -56
	.cfi_offset b10, -64
	adrp	x8, _ZTV15checker_texture+16
	ldr	q1, [x2]
	ldr	q0, [x3]
	add	x8, x8, :lo12:_ZTV15checker_texture+16
	mov	w0, #48
	ldr	d8, [x2, #16]
	ldr	d10, [x3, #16]
	mov	x19, x1
	stp	q1, q0, [sp]                    // 32-byte Folded Spill
	str	x8, [x1]
	bl	_Znwm
	movi	v9.2s, #1
	adrp	x20, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	adrp	x21, _ZTV11solid_color+16
	add	x20, x20, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	ldr	q0, [sp, #16]                   // 16-byte Folded Reload
	mov	x8, x0
	add	x21, x21, :lo12:_ZTV11solid_color+16
	str	d10, [x0, #40]
	str	x20, [x0]
	stur	q0, [x0, #24]
	str	d9, [x0, #8]
	str	x21, [x8, #16]!
	stp	x8, x0, [x19, #8]
.Ltmp809:
	mov	w0, #48
	bl	_Znwm
.Ltmp810:
// %bb.1:
	mov	x8, x0
	str	d9, [x0, #8]
	str	x20, [x0]
	ldr	q0, [sp]                        // 16-byte Folded Reload
	str	d8, [x0, #40]
	ldr	d10, [sp, #32]                  // 8-byte Folded Reload
	str	x21, [x8, #16]!
	stp	x8, x0, [x19, #24]
	ldr	x21, [sp, #72]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	stur	q0, [x0, #24]
	ldp	x29, x30, [sp, #56]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #40]               // 16-byte Folded Reload
	add	sp, sp, #96
	ret
.LBB194_2:
.Ltmp811:
	ldr	x20, [x19, #16]
	mov	x19, x0
	cbz	x20, .LBB194_12
// %bb.3:
	adrp	x21, :got:__libc_single_threaded
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x21]
	cbnz	w8, .LBB194_5
// %bb.4:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB194_6
.LBB194_5:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
.LBB194_6:
	cmp	w0, #1
	b.ne	.LBB194_12
// %bb.7:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbnz	w8, .LBB194_9
// %bb.8:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB194_10
.LBB194_9:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
.LBB194_10:
	cmp	w0, #1
	b.ne	.LBB194_12
// %bb.11:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB194_12:
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end194:
	.size	_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_, .Lfunc_end194-_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_,"aG",@progbits,_ZN9__gnu_cxx13new_allocatorI15checker_textureE9constructIS1_J4vec3S4_EEEvPT_DpOT0_,comdat
	.p2align	2
GCC_except_table194:
.Lexception27:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end27-.Lcst_begin27
.Lcst_begin27:
	.uleb128 .Lfunc_begin27-.Lfunc_begin27  // >> Call Site 1 <<
	.uleb128 .Ltmp809-.Lfunc_begin27        //   Call between .Lfunc_begin27 and .Ltmp809
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp809-.Lfunc_begin27        // >> Call Site 2 <<
	.uleb128 .Ltmp810-.Ltmp809              //   Call between .Ltmp809 and .Ltmp810
	.uleb128 .Ltmp811-.Lfunc_begin27        //     jumps to .Ltmp811
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp810-.Lfunc_begin27        // >> Call Site 3 <<
	.uleb128 .Lfunc_end194-.Ltmp810         //   Call between .Ltmp810 and .Lfunc_end194
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end27:
	.p2align	2
                                        // -- End function
	.section	.text._ZNK15checker_texture5valueEddRK4vec3,"axG",@progbits,_ZNK15checker_texture5valueEddRK4vec3,comdat
	.weak	_ZNK15checker_texture5valueEddRK4vec3 // -- Begin function _ZNK15checker_texture5valueEddRK4vec3
	.p2align	2
	.type	_ZNK15checker_texture5valueEddRK4vec3,@function
_ZNK15checker_texture5valueEddRK4vec3:  // @_ZNK15checker_texture5valueEddRK4vec3
	.cfi_startproc
// %bb.0:
	stp	d11, d10, [sp, #-64]!           // 16-byte Folded Spill
	stp	d9, d8, [sp, #16]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             // 16-byte Folded Spill
	add	x29, sp, #32
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	.cfi_offset b8, -40
	.cfi_offset b9, -48
	.cfi_offset b10, -56
	.cfi_offset b11, -64
	fmov	d9, d0
	fmov	d11, #10.00000000
	ldr	d0, [x1]
	mov	x19, x1
	fmov	d8, d1
	mov	x20, x0
	fmul	d0, d0, d11
	bl	sin
	ldr	d1, [x19, #8]
	fmov	d10, d0
	fmul	d1, d1, d11
	fmov	d0, d1
	bl	sin
	ldr	d1, [x19, #16]
	fmul	d10, d10, d0
	fmul	d0, d1, d11
	bl	sin
	fmul	d0, d10, d0
	add	x8, x20, #24
	add	x9, x20, #8
	fmov	d1, d8
	mov	x1, x19
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	fcmp	d0, #0.0
	fmov	d0, d9
	ldp	x29, x30, [sp, #32]             // 16-byte Folded Reload
	csel	x8, x9, x8, mi
	ldp	d9, d8, [sp, #16]               // 16-byte Folded Reload
	ldr	x0, [x8]
	ldr	x8, [x0]
	ldr	x2, [x8]
	ldp	d11, d10, [sp], #64             // 16-byte Folded Reload
	br	x2
.Lfunc_end195:
	.size	_ZNK15checker_texture5valueEddRK4vec3, .Lfunc_end195-_ZNK15checker_texture5valueEddRK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end196:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end196-_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end197:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end197-_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end198:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end198-_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end199:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end199-_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB200_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB200_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB200_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB200_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB200_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB200_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end200:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end200-_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK11solid_color5valueEddRK4vec3,"axG",@progbits,_ZNK11solid_color5valueEddRK4vec3,comdat
	.weak	_ZNK11solid_color5valueEddRK4vec3 // -- Begin function _ZNK11solid_color5valueEddRK4vec3
	.p2align	2
	.type	_ZNK11solid_color5valueEddRK4vec3,@function
_ZNK11solid_color5valueEddRK4vec3:      // @_ZNK11solid_color5valueEddRK4vec3
	.cfi_startproc
// %bb.0:
	ldp	d0, d1, [x0, #8]
	ldr	d2, [x0, #24]
	ret
.Lfunc_end201:
	.size	_ZNK11solid_color5valueEddRK4vec3, .Lfunc_end201-_ZNK11solid_color5valueEddRK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_,@function
_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_: // @_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	adrp	x8, _ZTV15checker_texture+16
	mov	x19, x1
	ldr	x20, [x1, #32]
	add	x8, x8, :lo12:_ZTV15checker_texture+16
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	str	x8, [x1]
	cbz	x20, .LBB202_7
// %bb.1:
	ldrb	w8, [x21]
	cbz	w8, .LBB202_3
// %bb.2:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB202_4
	b	.LBB202_7
.LBB202_3:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB202_7
.LBB202_4:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB202_14
// %bb.5:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB202_7
.LBB202_6:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB202_7:
	ldr	x19, [x19, #16]
	cbz	x19, .LBB202_16
// %bb.8:
	ldrb	w8, [x21]
	cbz	w8, .LBB202_10
// %bb.9:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB202_11
	b	.LBB202_16
.LBB202_10:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB202_16
.LBB202_11:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB202_15
// %bb.12:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB202_16
.LBB202_13:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	br	x1
.LBB202_14:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB202_6
	b	.LBB202_7
.LBB202_15:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB202_13
.LBB202_16:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end202:
	.size	_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_, .Lfunc_end202-_ZN9__gnu_cxx13new_allocatorI15checker_textureE7destroyIS1_EEvPT_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end203:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end203-_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end204:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end204-_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV10lambertian+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV10lambertian+16
	str	x8, [x0, #16]
	cbz	x19, .LBB205_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB205_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB205_4
	b	.LBB205_8
.LBB205_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB205_8
.LBB205_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB205_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB205_8
.LBB205_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB205_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB205_6
.LBB205_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end205:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end205-_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end206:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end206-_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB207_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB207_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB207_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB207_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB207_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB207_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end207:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end207-_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK8material7emittedEddRK4vec3,"axG",@progbits,_ZNK8material7emittedEddRK4vec3,comdat
	.weak	_ZNK8material7emittedEddRK4vec3 // -- Begin function _ZNK8material7emittedEddRK4vec3
	.p2align	2
	.type	_ZNK8material7emittedEddRK4vec3,@function
_ZNK8material7emittedEddRK4vec3:        // @_ZNK8material7emittedEddRK4vec3
	.cfi_startproc
// %bb.0:
	movi	d0, #0000000000000000
	movi	d1, #0000000000000000
	movi	d2, #0000000000000000
	ret
.Lfunc_end208:
	.size	_ZNK8material7emittedEddRK4vec3, .Lfunc_end208-_ZNK8material7emittedEddRK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst8,"aM",@progbits,8
	.p2align	3                               // -- Begin function _ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_
.LCPI209_0:
	.xword	0x3e45798ee2308c3a              // double 1.0E-8
	.section	.text._ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_,"axG",@progbits,_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_,comdat
	.weak	_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_
	.p2align	2
	.type	_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_,@function
_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_: // @_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_startproc
// %bb.0:
	stp	d13, d12, [sp, #-112]!          // 16-byte Folded Spill
	stp	d11, d10, [sp, #16]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #32]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	.cfi_offset b8, -72
	.cfi_offset b9, -80
	.cfi_offset b10, -88
	.cfi_offset b11, -96
	.cfi_offset b12, -104
	.cfi_offset b13, -112
	mov	x21, x4
	mov	x19, x3
	mov	x20, x2
	mov	x23, x1
	mov	x22, x0
	mov	x24, #4467570830351532032
	fmov	d10, #-1.00000000
	fmov	d11, #2.00000000
	fmov	d12, #1.00000000
.LBB209_1:                              // =>This Inner Loop Header: Depth=1
	bl	rand
	scvtf	d0, w0
	fmov	d13, x24
	fmul	d0, d0, d13
	fmadd	d8, d0, d11, d10
	bl	rand
	scvtf	d0, w0
	fmul	d0, d0, d13
	fmadd	d9, d0, d11, d10
	bl	rand
	scvtf	d1, w0
	fmul	d0, d9, d9
	fmul	d1, d1, d13
	fmadd	d0, d8, d8, d0
	fmadd	d2, d1, d11, d10
	fmadd	d0, d2, d2, d0
	fcmp	d0, d12
	b.ge	.LBB209_1
// %bb.2:
	fsqrt	d1, d0
	fcmp	d1, d1
	b.vs	.LBB209_4
.LBB209_3:
	fmov	d0, #1.00000000
	adrp	x8, .LCPI209_0
	ldp	d3, d5, [x20, #24]
	mov	x1, x20
	fdiv	d0, d0, d1
	ldr	d7, [x8, :lo12:.LCPI209_0]
	fmul	d1, d8, d0
	fmul	d4, d9, d0
	fmul	d0, d2, d0
	ldr	d2, [x20, #40]
	fadd	d1, d3, d1
	fadd	d4, d5, d4
	fadd	d0, d0, d2
	fabs	d6, d1
	fabs	d16, d4
	fcmp	d6, d7
	fabs	d6, d0
	cset	w8, mi
	fcmp	d16, d7
	cset	w9, mi
	fcmp	d6, d7
	and	w8, w8, w9
	ldr	q6, [x20]
	cset	w9, mi
	tst	w8, w9
	ldr	x8, [x20, #16]
	fcsel	d1, d3, d1, ne
	fcsel	d4, d5, d4, ne
	fcsel	d0, d2, d0, ne
	ldr	d3, [x23, #48]
	str	x8, [x21, #16]
	str	q6, [x21]
	stp	d1, d4, [x21, #24]
	stp	d0, d3, [x21, #40]
	ldr	x0, [x22, #8]
	ldp	d0, d1, [x20, #72]
	ldr	x8, [x0]
	ldr	x8, [x8]
	blr	x8
	stp	d0, d1, [x19]
	mov	w0, #1
	str	d2, [x19, #16]
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #32]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #16]             // 16-byte Folded Reload
	ldp	d13, d12, [sp], #112            // 16-byte Folded Reload
	ret
.LBB209_4:
	fmov	d10, d2
	bl	sqrt
	fmov	d2, d10
	fmov	d1, d0
	b	.LBB209_3
.Lfunc_end209:
	.size	_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_, .Lfunc_end209-_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end210:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end210-_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end211:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end211-_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV6sphere+16
	ldr	x19, [x0, #64]
	add	x8, x8, :lo12:_ZTV6sphere+16
	str	x8, [x0, #16]
	cbz	x19, .LBB212_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB212_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB212_4
	b	.LBB212_8
.LBB212_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB212_8
.LBB212_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB212_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB212_8
.LBB212_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB212_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB212_6
.LBB212_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end212:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end212-_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end213:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end213-_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB214_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB214_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB214_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB214_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB214_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB214_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end214:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end214-_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end215:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end215-_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end216:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end216-_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV13moving_sphere+16
	ldr	x19, [x0, #104]
	add	x8, x8, :lo12:_ZTV13moving_sphere+16
	str	x8, [x0, #16]
	cbz	x19, .LBB217_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB217_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB217_4
	b	.LBB217_8
.LBB217_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB217_8
.LBB217_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB217_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB217_8
.LBB217_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB217_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB217_6
.LBB217_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end217:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end217-_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end218:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end218-_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB219_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB219_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB219_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB219_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB219_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB219_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end219:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end219-_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	str	d12, [sp, #32]                  // 8-byte Folded Spill
	stp	d11, d10, [sp, #48]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #64]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	.cfi_offset b10, -72
	.cfi_offset b11, -80
	.cfi_offset b12, -96
	adrp	x21, :got:__libc_single_threaded
	mov	x20, x1
	ldp	x22, x19, [x7]
	ldr	d8, [x6]
	ldr	d9, [x4]
	ldr	q0, [x2]
	ldr	d10, [x2, #16]
	ldr	q1, [x3]
	ldr	d11, [x3, #16]
	ldr	d12, [x5]
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	cbz	x19, .LBB220_4
// %bb.1:
	ldrb	w8, [x21]
	cbz	w8, .LBB220_3
// %bb.2:
	ldr	w8, [x19, #8]
	add	w8, w8, #1
	str	w8, [x19, #8]
	b	.LBB220_4
.LBB220_3:
	add	x1, x19, #8
	mov	w0, #1
	stp	q1, q0, [sp]                    // 32-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldp	q1, q0, [sp]                    // 32-byte Folded Reload
.LBB220_4:
	adrp	x8, _ZTV13moving_sphere+16
	stur	q0, [x20, #8]
	add	x8, x8, :lo12:_ZTV13moving_sphere+16
	str	d10, [x20, #24]
	str	q1, [x20, #32]
	str	d11, [x20, #48]
	str	x8, [x20]
	str	d9, [x20, #56]
	str	d12, [x20, #64]
	str	d8, [x20, #72]
	stp	x22, x19, [x20, #80]
	cbz	x19, .LBB220_14
// %bb.5:
	ldrb	w8, [x21]
	cbz	w8, .LBB220_7
// %bb.6:
	ldr	w8, [x19, #8]
	add	w8, w8, #1
	str	w8, [x19, #8]
	mov	w0, w8
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB220_9
	b	.LBB220_14
.LBB220_7:
	add	x20, x19, #8
	mov	w0, #1
	mov	x1, x20
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x21]
	cbz	w8, .LBB220_13
// %bb.8:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB220_14
.LBB220_9:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB220_11
// %bb.10:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB220_12
	b	.LBB220_14
.LBB220_11:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB220_14
.LBB220_12:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #48]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	d12, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #128
	br	x1
.LBB220_13:
	mov	w0, #-1
	mov	x1, x20
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB220_9
.LBB220_14:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #48]             // 16-byte Folded Reload
	ldr	d12, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #128
	ret
.Lfunc_end220:
	.size	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_, .Lfunc_end220-_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_dddRSt10shared_ptrI8materialEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end221:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end221-_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end222:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end222-_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end223:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end223-_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end224:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end224-_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB225_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB225_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB225_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB225_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB225_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB225_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end225:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end225-_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_,"axG",@progbits,_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_,comdat
	.weak	_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_ // -- Begin function _ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_
	.p2align	2
	.type	_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_,@function
_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_: // @_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #176
	stp	d15, d14, [sp, #48]             // 16-byte Folded Spill
	stp	d13, d12, [sp, #64]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #80]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #96]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            // 16-byte Folded Spill
	add	x29, sp, #112
	stp	x24, x23, [sp, #128]            // 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            // 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	.cfi_offset b8, -72
	.cfi_offset b9, -80
	.cfi_offset b10, -88
	.cfi_offset b11, -96
	.cfi_offset b12, -104
	.cfi_offset b13, -112
	.cfi_offset b14, -120
	.cfi_offset b15, -128
	ldp	d9, d8, [x1, #24]
	mov	x19, x4
	mov	x21, x3
	ldr	d10, [x1, #40]
	mov	x22, x1
	mov	x20, x2
	mov	x23, x0
	fmul	d0, d8, d8
	fmadd	d0, d9, d9, d0
	fmadd	d1, d10, d10, d0
	fsqrt	d0, d1
	fcmp	d0, d0
	b.vs	.LBB226_4
.LBB226_1:
	fmov	d15, #1.00000000
	ldr	d2, [x20, #24]
	ldp	d1, d14, [x20, #32]
	mov	x24, #4467570830351532032
	fdiv	d0, d15, d0
	ldr	d12, [x23, #32]
	stp	d1, d2, [sp, #8]                // 16-byte Folded Spill
	fmul	d2, d9, d0
	fmul	d1, d8, d0
	fmul	d0, d10, d0
	fmov	d9, #-1.00000000
	fmov	d10, #2.00000000
	stp	d2, d1, [sp, #24]               // 16-byte Folded Spill
	str	d0, [sp, #40]                   // 8-byte Folded Spill
.LBB226_2:                              // =>This Inner Loop Header: Depth=1
	bl	rand
	scvtf	d0, w0
	fmov	d13, x24
	fmul	d0, d0, d13
	fmadd	d8, d0, d10, d9
	bl	rand
	scvtf	d0, w0
	fmul	d0, d0, d13
	fmadd	d11, d0, d10, d9
	bl	rand
	fmul	d0, d11, d11
	scvtf	d1, w0
	fmadd	d2, d8, d8, d0
	fmul	d0, d1, d13
	fmadd	d0, d0, d10, d9
	fmadd	d1, d0, d0, d2
	fcmp	d1, d15
	b.ge	.LBB226_2
// %bb.3:
	ldp	d5, d7, [sp, #24]               // 16-byte Folded Reload
	fmul	d4, d12, d8
	fmul	d0, d12, d0
	ldp	d3, d2, [sp, #8]                // 16-byte Folded Reload
	ldr	d6, [sp, #40]                   // 8-byte Folded Reload
	ldr	x8, [x20, #16]
	fmul	d1, d7, d3
	ldp	x29, x30, [sp, #112]            // 16-byte Folded Reload
	ldp	d9, d8, [sp, #96]               // 16-byte Folded Reload
	fmadd	d1, d5, d2, d1
	fmadd	d1, d6, d14, d1
	fadd	d1, d1, d1
	fmul	d2, d2, d1
	fmul	d3, d3, d1
	fmul	d1, d14, d1
	ldp	d15, d14, [sp, #48]             // 16-byte Folded Reload
	fsub	d2, d5, d2
	fmul	d5, d12, d11
	fsub	d3, d7, d3
	fsub	d1, d6, d1
	ldr	q6, [x20]
	ldp	d11, d10, [sp, #80]             // 16-byte Folded Reload
	fadd	d2, d2, d4
	fadd	d3, d3, d5
	fadd	d0, d1, d0
	ldr	d4, [x22, #48]
	str	x8, [x19, #16]
	str	q6, [x19]
	ldp	d13, d12, [sp, #64]             // 16-byte Folded Reload
	stp	d2, d3, [x19, #24]
	stp	d0, d4, [x19, #40]
	ldr	x8, [x23, #24]
	ldur	q0, [x23, #8]
	ldp	x24, x23, [sp, #128]            // 16-byte Folded Reload
	str	x8, [x21, #16]
	str	q0, [x21]
	ldp	d2, d0, [x19, #24]
	ldr	d1, [x20, #32]
	ldr	d3, [x19, #40]
	ldp	x22, x21, [sp, #144]            // 16-byte Folded Reload
	fmul	d0, d0, d1
	ldr	d1, [x20, #24]
	fmadd	d0, d2, d1, d0
	ldr	d1, [x20, #40]
	ldp	x20, x19, [sp, #160]            // 16-byte Folded Reload
	fmadd	d0, d3, d1, d0
	fcmp	d0, #0.0
	cset	w0, gt
	add	sp, sp, #176
	ret
.LBB226_4:
	fmov	d0, d1
	bl	sqrt
	b	.LBB226_1
.Lfunc_end226:
	.size	_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_, .Lfunc_end226-_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end227:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end227-_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end228:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end228-_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end229:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end229-_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end230:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end230-_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB231_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB231_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB231_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB231_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB231_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB231_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end231:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end231-_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_,"axG",@progbits,_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_,comdat
	.weak	_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_ // -- Begin function _ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_
	.p2align	2
	.type	_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_,@function
_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_: // @_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	stp	d15, d14, [sp, #16]             // 16-byte Folded Spill
	stp	d13, d12, [sp, #32]             // 16-byte Folded Spill
	stp	d11, d10, [sp, #48]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #64]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	str	x21, [sp, #96]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	.cfi_offset b10, -72
	.cfi_offset b11, -80
	.cfi_offset b12, -88
	.cfi_offset b13, -96
	.cfi_offset b14, -104
	.cfi_offset b15, -112
	fmov	v0.2d, #1.00000000
	mov	x8, #4607182418800017408
	fmov	d14, #1.00000000
	mov	x19, x1
	mov	x21, x2
	mov	x20, x4
	str	x8, [x3, #16]
	str	q0, [x3]
	ldp	d4, d15, [x1, #24]
	ldr	d11, [x1, #40]
	ldr	d2, [x0, #8]
	ldrb	w8, [x2, #88]
	fmul	d0, d15, d15
	fdiv	d3, d14, d2
	cmp	w8, #0
	fmadd	d0, d4, d4, d0
	fmadd	d1, d11, d11, d0
	fsqrt	d0, d1
	fcsel	d8, d2, d3, eq
	fcmp	d0, d0
	b.vs	.LBB232_8
.LBB232_1:
	fdiv	d13, d14, d0
	ldp	d1, d0, [x21, #24]
	fnmul	d3, d15, d13
	fmul	d12, d4, d13
	fmul	d9, d11, d13
	fmul	d0, d0, d3
	fmsub	d0, d12, d1, d0
	ldr	d1, [x21, #40]
	fmsub	d0, d9, d1, d0
	fminnm	d10, d0, d14
	fmsub	d1, d10, d10, d14
	fsqrt	d0, d1
	fcmp	d0, d0
	b.vs	.LBB232_9
// %bb.2:
	fmul	d1, d8, d0
	fmov	d0, #1.00000000
	fmul	d15, d15, d13
	fcmp	d1, d0
	b.gt	.LBB232_4
.LBB232_3:
	fsub	d1, d0, d8
	fadd	d2, d8, d0
	str	d8, [x29, #24]                  // 8-byte Folded Spill
	fmov	d8, d11
	fmov	d11, d3
	fdiv	d1, d1, d2
	fmul	d14, d1, d1
	fsub	d1, d0, d14
	fsub	d0, d0, d10
	fmov	d10, d4
	str	d1, [sp, #8]                    // 8-byte Folded Spill
	fmov	d1, #5.00000000
	bl	pow
	ldr	d1, [sp, #8]                    // 8-byte Folded Reload
	fmadd	d14, d1, d0, d14
	bl	rand
	mov	x8, #4467570830351532032
	scvtf	d0, w0
	ldr	d5, [x29, #24]                  // 8-byte Folded Reload
	fmov	d1, x8
	fmul	d0, d0, d1
	fcmp	d14, d0
	b.le	.LBB232_5
.LBB232_4:
	ldp	d2, d0, [x21, #24]
	ldr	d3, [x21, #40]
	fmul	d1, d15, d0
	fmadd	d1, d12, d2, d1
	fmadd	d1, d9, d3, d1
	fadd	d1, d1, d1
	fmul	d2, d2, d1
	fmul	d0, d0, d1
	fmul	d3, d3, d1
	fsub	d1, d12, d2
	fsub	d2, d15, d0
	fsub	d0, d9, d3
	b	.LBB232_7
.LBB232_5:
	ldp	d3, d0, [x21, #24]
	fnmul	d1, d10, d13
	fnmul	d4, d8, d13
	fmul	d2, d0, d11
	fmadd	d1, d1, d3, d2
	ldr	d2, [x21, #40]
	fmadd	d1, d4, d2, d1
	fmov	d4, #1.00000000
	fminnm	d1, d1, d4
	fmul	d0, d0, d1
	fmul	d3, d3, d1
	fmul	d1, d2, d1
	fadd	d0, d15, d0
	fadd	d2, d12, d3
	fmul	d10, d5, d0
	fadd	d0, d9, d1
	fmul	d9, d5, d2
	fmul	d1, d10, d10
	fmul	d8, d5, d0
	fmadd	d0, d9, d9, d1
	fmadd	d0, d8, d8, d0
	fabd	d1, d4, d0
	fsqrt	d0, d1
	fcmp	d0, d0
	b.vs	.LBB232_10
.LBB232_6:
	ldp	d1, d2, [x21, #24]
	ldr	d3, [x21, #40]
	fmul	d1, d0, d1
	fmul	d2, d0, d2
	fmul	d0, d0, d3
	fsub	d1, d9, d1
	fsub	d2, d10, d2
	fsub	d0, d8, d0
.LBB232_7:
	ldr	d3, [x19, #48]
	mov	w0, #1
	ldr	x8, [x21, #16]
	ldr	q4, [x21]
	stp	d1, d2, [x20, #24]
	stp	d0, d3, [x20, #40]
	ldr	x21, [sp, #96]                  // 8-byte Folded Reload
	str	x8, [x20, #16]
	str	q4, [x20]
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #48]             // 16-byte Folded Reload
	ldp	d13, d12, [sp, #32]             // 16-byte Folded Reload
	ldp	d15, d14, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #128
	ret
.LBB232_8:
	fmov	d0, d1
	fmov	d9, d4
	bl	sqrt
	fmov	d4, d9
	b	.LBB232_1
.LBB232_9:
	fmov	d0, d1
	fmov	d14, d4
	str	d8, [x29, #24]                  // 8-byte Folded Spill
	fmov	d8, d11
	fmov	d11, d3
	bl	sqrt
	fmov	d3, d11
	fmov	d11, d8
	fmov	d4, d14
	ldr	d8, [x29, #24]                  // 8-byte Folded Reload
	fmul	d1, d8, d0
	fmov	d0, #1.00000000
	fmul	d15, d15, d13
	fcmp	d1, d0
	b.le	.LBB232_3
	b	.LBB232_4
.LBB232_10:
	fmov	d0, d1
	bl	sqrt
	b	.LBB232_6
.Lfunc_end232:
	.size	_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_, .Lfunc_end232-_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end233:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end233-_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end234:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end234-_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV13noise_texture+16
	mov	x19, x0
	ldr	x0, [x0, #24]
	add	x8, x8, :lo12:_ZTV13noise_texture+16
	str	x8, [x19, #16]
	cbz	x0, .LBB235_2
// %bb.1:
	bl	_ZdaPv
.LBB235_2:
	ldr	x0, [x19, #32]
	cbz	x0, .LBB235_4
// %bb.3:
	bl	_ZdaPv
.LBB235_4:
	ldr	x0, [x19, #40]
	cbz	x0, .LBB235_6
// %bb.5:
	bl	_ZdaPv
.LBB235_6:
	ldr	x0, [x19, #48]
	cbz	x0, .LBB235_8
// %bb.7:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	_ZdaPv
.LBB235_8:
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end235:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end235-_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end236:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end236-_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB237_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB237_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB237_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB237_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB237_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB237_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end237:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end237-_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.rodata.cst16,"aM",@progbits,16
	.p2align	4                               // -- Begin function _ZN6perlinC2Ev
.LCPI238_0:
	.word	0                               // 0x0
	.word	1                               // 0x1
	.word	2                               // 0x2
	.word	3                               // 0x3
.LCPI238_1:
	.word	4                               // 0x4
	.word	5                               // 0x5
	.word	6                               // 0x6
	.word	7                               // 0x7
.LCPI238_2:
	.word	8                               // 0x8
	.word	9                               // 0x9
	.word	10                              // 0xa
	.word	11                              // 0xb
.LCPI238_3:
	.word	12                              // 0xc
	.word	13                              // 0xd
	.word	14                              // 0xe
	.word	15                              // 0xf
.LCPI238_4:
	.word	16                              // 0x10
	.word	17                              // 0x11
	.word	18                              // 0x12
	.word	19                              // 0x13
.LCPI238_5:
	.word	20                              // 0x14
	.word	21                              // 0x15
	.word	22                              // 0x16
	.word	23                              // 0x17
.LCPI238_6:
	.word	24                              // 0x18
	.word	25                              // 0x19
	.word	26                              // 0x1a
	.word	27                              // 0x1b
.LCPI238_7:
	.word	28                              // 0x1c
	.word	29                              // 0x1d
	.word	30                              // 0x1e
	.word	31                              // 0x1f
.LCPI238_8:
	.word	32                              // 0x20
	.word	33                              // 0x21
	.word	34                              // 0x22
	.word	35                              // 0x23
.LCPI238_9:
	.word	36                              // 0x24
	.word	37                              // 0x25
	.word	38                              // 0x26
	.word	39                              // 0x27
.LCPI238_10:
	.word	40                              // 0x28
	.word	41                              // 0x29
	.word	42                              // 0x2a
	.word	43                              // 0x2b
.LCPI238_11:
	.word	44                              // 0x2c
	.word	45                              // 0x2d
	.word	46                              // 0x2e
	.word	47                              // 0x2f
.LCPI238_12:
	.word	48                              // 0x30
	.word	49                              // 0x31
	.word	50                              // 0x32
	.word	51                              // 0x33
.LCPI238_13:
	.word	52                              // 0x34
	.word	53                              // 0x35
	.word	54                              // 0x36
	.word	55                              // 0x37
.LCPI238_14:
	.word	56                              // 0x38
	.word	57                              // 0x39
	.word	58                              // 0x3a
	.word	59                              // 0x3b
.LCPI238_15:
	.word	60                              // 0x3c
	.word	61                              // 0x3d
	.word	62                              // 0x3e
	.word	63                              // 0x3f
.LCPI238_16:
	.word	64                              // 0x40
	.word	65                              // 0x41
	.word	66                              // 0x42
	.word	67                              // 0x43
.LCPI238_17:
	.word	68                              // 0x44
	.word	69                              // 0x45
	.word	70                              // 0x46
	.word	71                              // 0x47
.LCPI238_18:
	.word	72                              // 0x48
	.word	73                              // 0x49
	.word	74                              // 0x4a
	.word	75                              // 0x4b
.LCPI238_19:
	.word	76                              // 0x4c
	.word	77                              // 0x4d
	.word	78                              // 0x4e
	.word	79                              // 0x4f
.LCPI238_20:
	.word	80                              // 0x50
	.word	81                              // 0x51
	.word	82                              // 0x52
	.word	83                              // 0x53
.LCPI238_21:
	.word	84                              // 0x54
	.word	85                              // 0x55
	.word	86                              // 0x56
	.word	87                              // 0x57
.LCPI238_22:
	.word	88                              // 0x58
	.word	89                              // 0x59
	.word	90                              // 0x5a
	.word	91                              // 0x5b
.LCPI238_23:
	.word	92                              // 0x5c
	.word	93                              // 0x5d
	.word	94                              // 0x5e
	.word	95                              // 0x5f
.LCPI238_24:
	.word	96                              // 0x60
	.word	97                              // 0x61
	.word	98                              // 0x62
	.word	99                              // 0x63
.LCPI238_25:
	.word	100                             // 0x64
	.word	101                             // 0x65
	.word	102                             // 0x66
	.word	103                             // 0x67
.LCPI238_26:
	.word	104                             // 0x68
	.word	105                             // 0x69
	.word	106                             // 0x6a
	.word	107                             // 0x6b
.LCPI238_27:
	.word	108                             // 0x6c
	.word	109                             // 0x6d
	.word	110                             // 0x6e
	.word	111                             // 0x6f
.LCPI238_28:
	.word	112                             // 0x70
	.word	113                             // 0x71
	.word	114                             // 0x72
	.word	115                             // 0x73
.LCPI238_29:
	.word	116                             // 0x74
	.word	117                             // 0x75
	.word	118                             // 0x76
	.word	119                             // 0x77
.LCPI238_30:
	.word	120                             // 0x78
	.word	121                             // 0x79
	.word	122                             // 0x7a
	.word	123                             // 0x7b
.LCPI238_31:
	.word	124                             // 0x7c
	.word	125                             // 0x7d
	.word	126                             // 0x7e
	.word	127                             // 0x7f
.LCPI238_32:
	.word	128                             // 0x80
	.word	129                             // 0x81
	.word	130                             // 0x82
	.word	131                             // 0x83
.LCPI238_33:
	.word	132                             // 0x84
	.word	133                             // 0x85
	.word	134                             // 0x86
	.word	135                             // 0x87
.LCPI238_34:
	.word	136                             // 0x88
	.word	137                             // 0x89
	.word	138                             // 0x8a
	.word	139                             // 0x8b
.LCPI238_35:
	.word	140                             // 0x8c
	.word	141                             // 0x8d
	.word	142                             // 0x8e
	.word	143                             // 0x8f
.LCPI238_36:
	.word	144                             // 0x90
	.word	145                             // 0x91
	.word	146                             // 0x92
	.word	147                             // 0x93
.LCPI238_37:
	.word	148                             // 0x94
	.word	149                             // 0x95
	.word	150                             // 0x96
	.word	151                             // 0x97
.LCPI238_38:
	.word	152                             // 0x98
	.word	153                             // 0x99
	.word	154                             // 0x9a
	.word	155                             // 0x9b
.LCPI238_39:
	.word	156                             // 0x9c
	.word	157                             // 0x9d
	.word	158                             // 0x9e
	.word	159                             // 0x9f
.LCPI238_40:
	.word	160                             // 0xa0
	.word	161                             // 0xa1
	.word	162                             // 0xa2
	.word	163                             // 0xa3
.LCPI238_41:
	.word	164                             // 0xa4
	.word	165                             // 0xa5
	.word	166                             // 0xa6
	.word	167                             // 0xa7
.LCPI238_42:
	.word	168                             // 0xa8
	.word	169                             // 0xa9
	.word	170                             // 0xaa
	.word	171                             // 0xab
.LCPI238_43:
	.word	172                             // 0xac
	.word	173                             // 0xad
	.word	174                             // 0xae
	.word	175                             // 0xaf
.LCPI238_44:
	.word	176                             // 0xb0
	.word	177                             // 0xb1
	.word	178                             // 0xb2
	.word	179                             // 0xb3
.LCPI238_45:
	.word	180                             // 0xb4
	.word	181                             // 0xb5
	.word	182                             // 0xb6
	.word	183                             // 0xb7
.LCPI238_46:
	.word	184                             // 0xb8
	.word	185                             // 0xb9
	.word	186                             // 0xba
	.word	187                             // 0xbb
.LCPI238_47:
	.word	188                             // 0xbc
	.word	189                             // 0xbd
	.word	190                             // 0xbe
	.word	191                             // 0xbf
.LCPI238_48:
	.word	192                             // 0xc0
	.word	193                             // 0xc1
	.word	194                             // 0xc2
	.word	195                             // 0xc3
.LCPI238_49:
	.word	196                             // 0xc4
	.word	197                             // 0xc5
	.word	198                             // 0xc6
	.word	199                             // 0xc7
.LCPI238_50:
	.word	200                             // 0xc8
	.word	201                             // 0xc9
	.word	202                             // 0xca
	.word	203                             // 0xcb
.LCPI238_51:
	.word	204                             // 0xcc
	.word	205                             // 0xcd
	.word	206                             // 0xce
	.word	207                             // 0xcf
.LCPI238_52:
	.word	208                             // 0xd0
	.word	209                             // 0xd1
	.word	210                             // 0xd2
	.word	211                             // 0xd3
.LCPI238_53:
	.word	212                             // 0xd4
	.word	213                             // 0xd5
	.word	214                             // 0xd6
	.word	215                             // 0xd7
.LCPI238_54:
	.word	216                             // 0xd8
	.word	217                             // 0xd9
	.word	218                             // 0xda
	.word	219                             // 0xdb
.LCPI238_55:
	.word	220                             // 0xdc
	.word	221                             // 0xdd
	.word	222                             // 0xde
	.word	223                             // 0xdf
.LCPI238_56:
	.word	224                             // 0xe0
	.word	225                             // 0xe1
	.word	226                             // 0xe2
	.word	227                             // 0xe3
.LCPI238_57:
	.word	228                             // 0xe4
	.word	229                             // 0xe5
	.word	230                             // 0xe6
	.word	231                             // 0xe7
.LCPI238_58:
	.word	232                             // 0xe8
	.word	233                             // 0xe9
	.word	234                             // 0xea
	.word	235                             // 0xeb
.LCPI238_59:
	.word	236                             // 0xec
	.word	237                             // 0xed
	.word	238                             // 0xee
	.word	239                             // 0xef
.LCPI238_60:
	.word	240                             // 0xf0
	.word	241                             // 0xf1
	.word	242                             // 0xf2
	.word	243                             // 0xf3
.LCPI238_61:
	.word	244                             // 0xf4
	.word	245                             // 0xf5
	.word	246                             // 0xf6
	.word	247                             // 0xf7
.LCPI238_62:
	.word	248                             // 0xf8
	.word	249                             // 0xf9
	.word	250                             // 0xfa
	.word	251                             // 0xfb
.LCPI238_63:
	.word	252                             // 0xfc
	.word	253                             // 0xfd
	.word	254                             // 0xfe
	.word	255                             // 0xff
	.section	.text._ZN6perlinC2Ev,"axG",@progbits,_ZN6perlinC2Ev,comdat
	.weak	_ZN6perlinC2Ev
	.p2align	2
	.type	_ZN6perlinC2Ev,@function
_ZN6perlinC2Ev:                         // @_ZN6perlinC2Ev
	.cfi_startproc
// %bb.0:
	stp	d13, d12, [sp, #-112]!          // 16-byte Folded Spill
	stp	d11, d10, [sp, #16]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #32]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x28, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	sub	sp, sp, #1024
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w28, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	.cfi_offset b8, -72
	.cfi_offset b9, -80
	.cfi_offset b10, -88
	.cfi_offset b11, -96
	.cfi_offset b12, -104
	.cfi_offset b13, -112
	mov	x19, x0
	mov	w0, #6144
	bl	_Znam
	mov	w1, wzr
	mov	w2, #6144
	mov	x20, x0
	bl	memset
	mov	x21, #-6144
	mov	x22, #4467570830351532032
	fmov	d8, #-1.00000000
	fmov	d9, #2.00000000
	fmov	d10, #1.00000000
	str	x20, [x19]
.LBB238_1:                              // =>This Inner Loop Header: Depth=1
	bl	rand
	scvtf	d0, w0
	fmov	d13, x22
	fmul	d0, d0, d13
	fmadd	d11, d0, d9, d8
	bl	rand
	scvtf	d0, w0
	fmul	d0, d0, d13
	fmadd	d12, d0, d9, d8
	bl	rand
	scvtf	d1, w0
	fmul	d0, d12, d12
	fmul	d1, d1, d13
	fmadd	d0, d11, d11, d0
	fmadd	d2, d1, d9, d8
	fmadd	d1, d2, d2, d0
	fsqrt	d0, d1
	fcmp	d0, d0
	b.vs	.LBB238_3
.LBB238_2:                              //   in Loop: Header=BB238_1 Depth=1
	fdiv	d0, d10, d0
	ldr	x8, [x19]
	add	x8, x8, x21
	adds	x21, x21, #24
	fmul	d1, d11, d0
	fmul	d3, d12, d0
	fmul	d0, d0, d2
	str	d1, [x8, #6144]
	str	d3, [x8, #6152]
	str	d0, [x8, #6160]
	b.ne	.LBB238_1
	b	.LBB238_4
.LBB238_3:                              //   in Loop: Header=BB238_1 Depth=1
	fmov	d0, d1
	stur	d2, [x29, #-64]                 // 8-byte Folded Spill
	bl	sqrt
	ldur	d2, [x29, #-64]                 // 8-byte Folded Reload
	b	.LBB238_2
.LBB238_4:
	mov	w0, #1024
	bl	_Znam
	adrp	x8, .LCPI238_0
	adrp	x9, .LCPI238_1
	adrp	x10, .LCPI238_2
	adrp	x11, .LCPI238_3
	movi	d8, #0000000000000000
	mov	x20, x0
	ldr	q0, [x8, :lo12:.LCPI238_0]
	adrp	x8, .LCPI238_4
	ldr	q1, [x9, :lo12:.LCPI238_1]
	adrp	x9, .LCPI238_5
	ldr	q2, [x10, :lo12:.LCPI238_2]
	adrp	x10, .LCPI238_6
	stur	q0, [x29, #-64]                 // 16-byte Folded Spill
	mov	w21, #255
	stp	q0, q1, [x0]
	ldr	q0, [x11, :lo12:.LCPI238_3]
	stur	q1, [x29, #-80]                 // 16-byte Folded Spill
	ldr	q1, [x8, :lo12:.LCPI238_4]
	adrp	x8, .LCPI238_7
	ldr	q3, [x9, :lo12:.LCPI238_5]
	stp	q0, q2, [x29, #-112]            // 32-byte Folded Spill
	adrp	x9, .LCPI238_9
	stp	q2, q0, [x0, #32]
	ldr	q2, [x10, :lo12:.LCPI238_6]
	ldr	q0, [x8, :lo12:.LCPI238_7]
	adrp	x8, .LCPI238_8
	adrp	x10, .LCPI238_10
	stp	q1, q3, [x0, #64]
	stp	q2, q3, [x29, #-176]            // 32-byte Folded Spill
	adrp	x11, .LCPI238_35
	stp	q0, q1, [x29, #-144]            // 32-byte Folded Spill
	ldr	q1, [x9, :lo12:.LCPI238_9]
	stp	q2, q0, [x0, #96]
	ldr	q0, [x8, :lo12:.LCPI238_8]
	adrp	x8, .LCPI238_11
	adrp	x9, .LCPI238_12
	ldr	q2, [x10, :lo12:.LCPI238_10]
	adrp	x10, .LCPI238_13
	stp	q1, q0, [x29, #-208]            // 32-byte Folded Spill
	mov	x22, #4467570830351532032
	ldr	q3, [x8, :lo12:.LCPI238_11]
	stp	q0, q1, [x0, #128]
	ldr	q1, [x9, :lo12:.LCPI238_12]
	adrp	x8, .LCPI238_14
	ldr	q0, [x10, :lo12:.LCPI238_13]
	adrp	x9, .LCPI238_15
	adrp	x10, .LCPI238_16
	stur	q2, [x29, #-224]                // 16-byte Folded Spill
	stp	q2, q3, [x0, #160]
	str	q1, [sp, #800]                  // 16-byte Folded Spill
	stp	q1, q0, [x0, #192]
	ldr	q1, [x9, :lo12:.LCPI238_15]
	stur	q0, [x29, #-240]                // 16-byte Folded Spill
	ldr	q0, [x8, :lo12:.LCPI238_14]
	adrp	x8, .LCPI238_17
	adrp	x9, .LCPI238_18
	ldr	q2, [x10, :lo12:.LCPI238_16]
	adrp	x10, .LCPI238_19
	stur	q3, [x29, #-256]                // 16-byte Folded Spill
	ldr	q3, [x8, :lo12:.LCPI238_17]
	stp	q1, q0, [sp, #768]              // 32-byte Folded Spill
	stp	q0, q1, [x0, #224]
	ldr	q1, [x9, :lo12:.LCPI238_18]
	ldr	q0, [x10, :lo12:.LCPI238_19]
	adrp	x8, .LCPI238_20
	adrp	x9, .LCPI238_21
	adrp	x10, .LCPI238_22
	stp	q2, q3, [x0, #256]
	stp	q0, q2, [sp, #736]              // 32-byte Folded Spill
	stp	q1, q3, [sp, #704]              // 32-byte Folded Spill
	ldr	q2, [x10, :lo12:.LCPI238_22]
	stp	q1, q0, [x0, #288]
	ldr	q0, [x8, :lo12:.LCPI238_20]
	adrp	x8, .LCPI238_23
	ldr	q1, [x9, :lo12:.LCPI238_21]
	adrp	x9, .LCPI238_24
	adrp	x10, .LCPI238_25
	ldr	q3, [x8, :lo12:.LCPI238_23]
	stp	q1, q0, [sp, #672]              // 32-byte Folded Spill
	stp	q0, q1, [x0, #320]
	ldr	q1, [x9, :lo12:.LCPI238_24]
	ldr	q0, [x10, :lo12:.LCPI238_25]
	adrp	x8, .LCPI238_26
	adrp	x9, .LCPI238_27
	adrp	x10, .LCPI238_28
	stp	q2, q3, [x0, #352]
	stp	q0, q2, [sp, #640]              // 32-byte Folded Spill
	stp	q1, q3, [sp, #608]              // 32-byte Folded Spill
	ldr	q2, [x10, :lo12:.LCPI238_28]
	stp	q1, q0, [x0, #384]
	ldr	q0, [x8, :lo12:.LCPI238_26]
	adrp	x8, .LCPI238_29
	ldr	q1, [x9, :lo12:.LCPI238_27]
	adrp	x9, .LCPI238_30
	adrp	x10, .LCPI238_31
	ldr	q3, [x8, :lo12:.LCPI238_29]
	stp	q1, q0, [sp, #576]              // 32-byte Folded Spill
	stp	q0, q1, [x0, #416]
	ldr	q1, [x9, :lo12:.LCPI238_30]
	ldr	q0, [x10, :lo12:.LCPI238_31]
	adrp	x8, .LCPI238_32
	adrp	x9, .LCPI238_33
	adrp	x10, .LCPI238_34
	stp	q1, q3, [sp, #512]              // 32-byte Folded Spill
	stp	q0, q2, [sp, #544]              // 32-byte Folded Spill
	stp	q1, q0, [x0, #480]
	ldr	q0, [x8, :lo12:.LCPI238_32]
	ldr	q1, [x9, :lo12:.LCPI238_33]
	stp	q2, q3, [x0, #448]
	adrp	x8, .LCPI238_36
	adrp	x9, .LCPI238_37
	ldr	q2, [x10, :lo12:.LCPI238_34]
	str	q0, [sp, #496]                  // 16-byte Folded Spill
	stp	q0, q1, [x0, #512]
	ldr	q0, [x11, :lo12:.LCPI238_35]
	str	q1, [sp, #480]                  // 16-byte Folded Spill
	ldr	q1, [x8, :lo12:.LCPI238_36]
	str	q2, [sp, #416]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_38
	stp	q2, q0, [x0, #544]
	ldr	q2, [x9, :lo12:.LCPI238_37]
	adrp	x9, .LCPI238_39
	stp	q1, q0, [sp, #448]              // 32-byte Folded Spill
	adrp	x10, .LCPI238_40
	adrp	x11, .LCPI238_41
	stp	q1, q2, [x0, #576]
	ldr	q0, [x8, :lo12:.LCPI238_38]
	ldr	q1, [x9, :lo12:.LCPI238_39]
	str	q2, [sp, #432]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_42
	adrp	x9, .LCPI238_43
	ldr	q2, [x10, :lo12:.LCPI238_40]
	str	q0, [sp, #400]                  // 16-byte Folded Spill
	stp	q0, q1, [x0, #608]
	ldr	q0, [x11, :lo12:.LCPI238_41]
	str	q1, [sp, #384]                  // 16-byte Folded Spill
	ldr	q1, [x8, :lo12:.LCPI238_42]
	str	q2, [sp, #320]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_44
	stp	q2, q0, [x0, #640]
	ldr	q2, [x9, :lo12:.LCPI238_43]
	adrp	x9, .LCPI238_45
	stp	q1, q0, [sp, #352]              // 32-byte Folded Spill
	adrp	x10, .LCPI238_46
	adrp	x11, .LCPI238_47
	stp	q1, q2, [x0, #672]
	ldr	q0, [x8, :lo12:.LCPI238_44]
	ldr	q1, [x9, :lo12:.LCPI238_45]
	str	q2, [sp, #336]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_48
	adrp	x9, .LCPI238_49
	ldr	q2, [x10, :lo12:.LCPI238_46]
	str	q0, [sp, #304]                  // 16-byte Folded Spill
	stp	q0, q1, [x0, #704]
	ldr	q0, [x11, :lo12:.LCPI238_47]
	str	q1, [sp, #288]                  // 16-byte Folded Spill
	ldr	q1, [x8, :lo12:.LCPI238_48]
	str	q2, [sp, #224]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_50
	stp	q2, q0, [x0, #736]
	ldr	q2, [x9, :lo12:.LCPI238_49]
	adrp	x9, .LCPI238_51
	stp	q1, q0, [sp, #256]              // 32-byte Folded Spill
	adrp	x10, .LCPI238_52
	adrp	x11, .LCPI238_53
	stp	q1, q2, [x0, #768]
	ldr	q0, [x8, :lo12:.LCPI238_50]
	ldr	q1, [x9, :lo12:.LCPI238_51]
	str	q2, [sp, #240]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_54
	adrp	x9, .LCPI238_55
	ldr	q2, [x10, :lo12:.LCPI238_52]
	str	q0, [sp, #208]                  // 16-byte Folded Spill
	stp	q0, q1, [x0, #800]
	ldr	q0, [x11, :lo12:.LCPI238_53]
	str	q1, [sp, #192]                  // 16-byte Folded Spill
	ldr	q1, [x8, :lo12:.LCPI238_54]
	str	q2, [sp, #128]                  // 16-byte Folded Spill
	adrp	x8, .LCPI238_56
	stp	q2, q0, [x0, #832]
	ldr	q2, [x9, :lo12:.LCPI238_55]
	adrp	x9, .LCPI238_57
	stp	q1, q0, [sp, #160]              // 32-byte Folded Spill
	adrp	x10, .LCPI238_58
	ldr	q0, [x8, :lo12:.LCPI238_56]
	stp	q1, q2, [x0, #864]
	adrp	x8, .LCPI238_59
	ldr	q1, [x9, :lo12:.LCPI238_57]
	adrp	x9, .LCPI238_60
	adrp	x11, .LCPI238_61
	str	q0, [sp, #112]                  // 16-byte Folded Spill
	str	q2, [sp, #144]                  // 16-byte Folded Spill
	stp	q0, q1, [x0, #896]
	ldr	q0, [x10, :lo12:.LCPI238_58]
	str	q1, [sp, #96]                   // 16-byte Folded Spill
	ldr	q1, [x8, :lo12:.LCPI238_59]
	adrp	x8, .LCPI238_62
	ldr	q2, [x9, :lo12:.LCPI238_60]
	str	q0, [sp, #48]                   // 16-byte Folded Spill
	adrp	x9, .LCPI238_63
	stp	q0, q1, [x0, #928]
	ldr	q0, [x11, :lo12:.LCPI238_61]
	str	q2, [sp]                        // 16-byte Folded Spill
	stp	q0, q1, [sp, #16]               // 32-byte Folded Spill
	ldr	q1, [x9, :lo12:.LCPI238_63]
	stp	q2, q0, [x0, #960]
	ldr	q0, [x8, :lo12:.LCPI238_62]
	stp	q1, q0, [sp, #64]               // 32-byte Folded Spill
	stp	q0, q1, [x0, #992]
.LBB238_5:                              // =>This Inner Loop Header: Depth=1
	add	x23, x21, #1
	scvtf	d9, w23
	bl	rand
	scvtf	d0, w0
	fmov	d1, x22
	lsl	x9, x21, #2
	sub	x21, x21, #1
	cmp	x23, #2
	fmul	d0, d0, d1
	ldr	w11, [x20, x9]
	fmadd	d0, d9, d0, d8
	fcvtzs	w8, d0
	sbfiz	x8, x8, #2, #32
	ldr	w10, [x20, x8]
	str	w10, [x20, x9]
	str	w11, [x20, x8]
	b.hi	.LBB238_5
// %bb.6:
	mov	w0, #1024
	str	x20, [x19, #8]
	bl	_Znam
	ldp	q0, q1, [x29, #-80]             // 32-byte Folded Reload
	movi	d8, #0000000000000000
	mov	x20, x0
	mov	w21, #255
	mov	x22, #4467570830351532032
	stp	q1, q0, [x0]
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	stp	q1, q0, [x0, #32]
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #64]
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #96]
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	stp	q1, q0, [x0, #128]
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #160]
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #192]
	ldp	q0, q1, [sp, #768]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #224]
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #256]
	ldr	q1, [sp, #704]                  // 16-byte Folded Reload
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #288]
	ldp	q0, q1, [sp, #672]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #320]
	ldr	q1, [sp, #656]                  // 16-byte Folded Reload
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #352]
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #384]
	ldp	q0, q1, [sp, #576]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #416]
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #448]
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	ldr	q0, [sp, #544]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #480]
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #512]
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #544]
	ldp	q0, q1, [sp, #432]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #576]
	ldp	q0, q1, [sp, #384]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #608]
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #640]
	ldp	q0, q1, [sp, #336]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #672]
	ldp	q0, q1, [sp, #288]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #704]
	ldr	q1, [sp, #224]                  // 16-byte Folded Reload
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #736]
	ldp	q0, q1, [sp, #240]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #768]
	ldp	q0, q1, [sp, #192]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #800]
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	ldr	q0, [sp, #176]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #832]
	ldp	q0, q1, [sp, #144]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #864]
	ldp	q0, q1, [sp, #96]               // 32-byte Folded Reload
	stp	q1, q0, [x0, #896]
	ldp	q0, q1, [sp, #32]               // 32-byte Folded Reload
	stp	q1, q0, [x0, #928]
	ldp	q1, q0, [sp]                    // 32-byte Folded Reload
	stp	q1, q0, [x0, #960]
	ldp	q0, q1, [sp, #64]               // 32-byte Folded Reload
	stp	q1, q0, [x0, #992]
.LBB238_7:                              // =>This Inner Loop Header: Depth=1
	add	x23, x21, #1
	scvtf	d9, w23
	bl	rand
	scvtf	d0, w0
	fmov	d1, x22
	lsl	x9, x21, #2
	sub	x21, x21, #1
	cmp	x23, #2
	fmul	d0, d0, d1
	ldr	w11, [x20, x9]
	fmadd	d0, d9, d0, d8
	fcvtzs	w8, d0
	sbfiz	x8, x8, #2, #32
	ldr	w10, [x20, x8]
	str	w10, [x20, x9]
	str	w11, [x20, x8]
	b.hi	.LBB238_7
// %bb.8:
	mov	w0, #1024
	str	x20, [x19, #16]
	bl	_Znam
	ldp	q0, q1, [x29, #-80]             // 32-byte Folded Reload
	movi	d8, #0000000000000000
	mov	x20, x0
	mov	w21, #255
	mov	x22, #4467570830351532032
	stp	q1, q0, [x0]
	ldp	q0, q1, [x29, #-112]            // 32-byte Folded Reload
	stp	q1, q0, [x0, #32]
	ldur	q1, [x29, #-128]                // 16-byte Folded Reload
	ldur	q0, [x29, #-160]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #64]
	ldur	q1, [x29, #-176]                // 16-byte Folded Reload
	ldur	q0, [x29, #-144]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #96]
	ldp	q0, q1, [x29, #-208]            // 32-byte Folded Reload
	stp	q1, q0, [x0, #128]
	ldur	q1, [x29, #-224]                // 16-byte Folded Reload
	ldur	q0, [x29, #-256]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #160]
	ldr	q1, [sp, #800]                  // 16-byte Folded Reload
	ldur	q0, [x29, #-240]                // 16-byte Folded Reload
	stp	q1, q0, [x0, #192]
	ldp	q0, q1, [sp, #768]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #224]
	ldr	q1, [sp, #752]                  // 16-byte Folded Reload
	ldr	q0, [sp, #720]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #256]
	ldr	q1, [sp, #704]                  // 16-byte Folded Reload
	ldr	q0, [sp, #736]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #288]
	ldp	q0, q1, [sp, #672]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #320]
	ldr	q1, [sp, #656]                  // 16-byte Folded Reload
	ldr	q0, [sp, #624]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #352]
	ldr	q1, [sp, #608]                  // 16-byte Folded Reload
	ldr	q0, [sp, #640]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #384]
	ldp	q0, q1, [sp, #576]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #416]
	ldr	q1, [sp, #560]                  // 16-byte Folded Reload
	ldr	q0, [sp, #528]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #448]
	ldr	q1, [sp, #512]                  // 16-byte Folded Reload
	ldr	q0, [sp, #544]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #480]
	ldp	q0, q1, [sp, #480]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #512]
	ldr	q1, [sp, #416]                  // 16-byte Folded Reload
	ldr	q0, [sp, #464]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #544]
	ldp	q0, q1, [sp, #432]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #576]
	ldp	q0, q1, [sp, #384]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #608]
	ldr	q1, [sp, #320]                  // 16-byte Folded Reload
	ldr	q0, [sp, #368]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #640]
	ldp	q0, q1, [sp, #336]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #672]
	ldp	q0, q1, [sp, #288]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #704]
	ldr	q1, [sp, #224]                  // 16-byte Folded Reload
	ldr	q0, [sp, #272]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #736]
	ldp	q0, q1, [sp, #240]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #768]
	ldp	q0, q1, [sp, #192]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #800]
	ldr	q1, [sp, #128]                  // 16-byte Folded Reload
	ldr	q0, [sp, #176]                  // 16-byte Folded Reload
	stp	q1, q0, [x0, #832]
	ldp	q0, q1, [sp, #144]              // 32-byte Folded Reload
	stp	q1, q0, [x0, #864]
	ldp	q0, q1, [sp, #96]               // 32-byte Folded Reload
	stp	q1, q0, [x0, #896]
	ldp	q0, q1, [sp, #32]               // 32-byte Folded Reload
	stp	q1, q0, [x0, #928]
	ldp	q1, q0, [sp]                    // 32-byte Folded Reload
	stp	q1, q0, [x0, #960]
	ldp	q0, q1, [sp, #64]               // 32-byte Folded Reload
	stp	q1, q0, [x0, #992]
.LBB238_9:                              // =>This Inner Loop Header: Depth=1
	add	x23, x21, #1
	scvtf	d9, w23
	bl	rand
	scvtf	d0, w0
	fmov	d1, x22
	lsl	x9, x21, #2
	sub	x21, x21, #1
	cmp	x23, #2
	fmul	d0, d0, d1
	ldr	w11, [x20, x9]
	fmadd	d0, d9, d0, d8
	fcvtzs	w8, d0
	sbfiz	x8, x8, #2, #32
	ldr	w10, [x20, x8]
	str	w10, [x20, x9]
	str	w11, [x20, x8]
	b.hi	.LBB238_9
// %bb.10:
	str	x20, [x19, #24]
	add	sp, sp, #1024
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x28, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #32]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #16]             // 16-byte Folded Reload
	ldp	d13, d12, [sp], #112            // 16-byte Folded Reload
	ret
.Lfunc_end238:
	.size	_ZN6perlinC2Ev, .Lfunc_end238-_ZN6perlinC2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK13noise_texture5valueEddRK4vec3,"axG",@progbits,_ZNK13noise_texture5valueEddRK4vec3,comdat
	.weak	_ZNK13noise_texture5valueEddRK4vec3 // -- Begin function _ZNK13noise_texture5valueEddRK4vec3
	.p2align	2
	.type	_ZNK13noise_texture5valueEddRK4vec3,@function
_ZNK13noise_texture5valueEddRK4vec3:    // @_ZNK13noise_texture5valueEddRK4vec3
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #96
	stp	d11, d10, [sp, #32]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #48]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             // 16-byte Folded Spill
	add	x29, sp, #64
	str	x19, [sp, #80]                  // 8-byte Folded Spill
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	.cfi_offset b8, -40
	.cfi_offset b9, -48
	.cfi_offset b10, -56
	.cfi_offset b11, -64
	add	x19, x0, #8
	ldr	d8, [x0, #40]
	ldr	q0, [x1]
	mov	x0, x19
	ldr	x8, [x1, #16]
	ldr	d9, [x1, #16]
	mov	x1, sp
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	ldr	q1, [sp]
	movi	d2, #0000000000000000
	ldr	d3, [sp, #16]
	mov	x1, sp
	mov	x0, x19
	fadd	v1.2d, v1.2d, v1.2d
	fadd	d3, d3, d3
	fadd	d11, d0, d2
	str	q1, [sp]
	str	d3, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	ldr	q1, [sp]
	fmov	d10, #0.50000000
	ldr	d2, [sp, #16]
	mov	x1, sp
	mov	x0, x19
	fadd	v1.2d, v1.2d, v1.2d
	fmadd	d11, d0, d10, d11
	fadd	d2, d2, d2
	str	q1, [sp]
	str	d2, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	ldr	q1, [sp]
	fmov	d3, #0.25000000
	ldr	d2, [sp, #16]
	mov	x1, sp
	mov	x0, x19
	fadd	v1.2d, v1.2d, v1.2d
	fmadd	d11, d0, d3, d11
	fadd	d2, d2, d2
	str	q1, [sp]
	str	d2, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	ldr	q1, [sp]
	fmov	d3, #0.12500000
	ldr	d2, [sp, #16]
	mov	x1, sp
	mov	x0, x19
	fadd	v1.2d, v1.2d, v1.2d
	fmadd	d11, d0, d3, d11
	fadd	d2, d2, d2
	str	q1, [sp]
	str	d2, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	ldr	q1, [sp]
	mov	x8, #4589168020290535424
	ldr	d2, [sp, #16]
	mov	x1, sp
	mov	x0, x19
	fadd	v1.2d, v1.2d, v1.2d
	fmov	d3, x8
	fadd	d2, d2, d2
	fmadd	d11, d0, d3, d11
	str	q1, [sp]
	str	d2, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	ldr	q1, [sp]
	mov	x8, #4584664420663164928
	ldr	d2, [sp, #16]
	mov	x1, sp
	mov	x0, x19
	fadd	v1.2d, v1.2d, v1.2d
	fmov	d3, x8
	fadd	d2, d2, d2
	fmadd	d11, d0, d3, d11
	str	q1, [sp]
	str	d2, [sp, #16]
	bl	_ZNK6perlin5noiseERK4vec3
	mov	x8, #4580160821035794432
	fmov	d1, x8
	fmadd	d0, d0, d1, d11
	fmov	d1, #10.00000000
	fabs	d0, d0
	fmul	d0, d0, d1
	fmadd	d0, d8, d9, d0
	bl	sin
	fmov	d1, #1.00000000
	ldr	x19, [sp, #80]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp, #64]             // 16-byte Folded Reload
	fadd	d0, d0, d1
	ldp	d9, d8, [sp, #48]               // 16-byte Folded Reload
	fmul	d0, d0, d10
	ldp	d11, d10, [sp, #32]             // 16-byte Folded Reload
	fmov	d1, d0
	fmov	d2, d0
	add	sp, sp, #96
	ret
.Lfunc_end239:
	.size	_ZNK13noise_texture5valueEddRK4vec3, .Lfunc_end239-_ZNK13noise_texture5valueEddRK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK6perlin5noiseERK4vec3,"axG",@progbits,_ZNK6perlin5noiseERK4vec3,comdat
	.weak	_ZNK6perlin5noiseERK4vec3       // -- Begin function _ZNK6perlin5noiseERK4vec3
	.p2align	2
	.type	_ZNK6perlin5noiseERK4vec3,@function
_ZNK6perlin5noiseERK4vec3:              // @_ZNK6perlin5noiseERK4vec3
	.cfi_startproc
// %bb.0:
	ldp	d0, d1, [x1]
	fmov	d2, #3.00000000
	fmov	d4, #-2.00000000
	ldr	d3, [x1, #16]
	mov	w8, #24
	ldp	x9, x10, [x0]
	fcvtms	w11, d0
	frintm	d5, d0
	fcvtms	w12, d1
	fcvtms	w13, d3
	frintm	d6, d1
	frintm	d7, d3
	ldp	x14, x15, [x0, #16]
	and	w16, w11, #0xff
	and	w17, w12, #0xff
	and	w18, w13, #0xff
	add	w13, w13, #1
	fsub	d5, d0, d5
	fsub	d1, d1, d6
	ldr	w16, [x10, w16, uxtw #2]
	and	w13, w13, #0xff
	ldr	w17, [x14, w17, uxtw #2]
	fsub	d0, d3, d7
	ldr	w18, [x15, w18, uxtw #2]
	add	w12, w12, #1
	fmul	d3, d5, d5
	fmadd	d6, d5, d4, d2
	fmul	d7, d1, d1
	fmadd	d16, d1, d4, d2
	ldr	w13, [x15, w13, uxtw #2]
	eor	w15, w17, w16
	eor	w0, w15, w18
	fmul	d17, d0, d0
	fmadd	d2, d0, d4, d2
	fmul	d3, d3, d6
	smaddl	x0, w0, w8, x9
	fmul	d4, d7, d16
	fmov	d6, #1.00000000
	and	w12, w12, #0xff
	movi	d16, #0000000000000000
	eor	w15, w15, w13
	fmul	d2, d17, d2
	fmov	d25, #-1.00000000
	ldp	d21, d18, [x0]
	fsub	d7, d6, d3
	fsub	d17, d6, d4
	ldr	w12, [x14, w12, uxtw #2]
	smaddl	x14, w15, w8, x9
	fsub	d6, d6, d2
	add	w11, w11, #1
	and	w11, w11, #0xff
	fadd	d28, d1, d25
	fmadd	d19, d3, d16, d7
	fmadd	d20, d4, d16, d17
	fmul	d18, d1, d18
	eor	w15, w12, w16
	ldp	d26, d22, [x14]
	fmadd	d23, d2, d16, d6
	eor	w16, w15, w18
	fmul	d24, d19, d20
	fmul	d6, d6, d16
	fmadd	d18, d21, d5, d18
	ldr	d21, [x0, #16]
	smaddl	x16, w16, w8, x9
	fmul	d17, d17, d16
	fmul	d22, d1, d22
	ldr	w10, [x10, w11, uxtw #2]
	fmul	d27, d24, d23
	fadd	d2, d2, d6
	fmadd	d18, d21, d0, d18
	fadd	d21, d0, d25
	fadd	d4, d4, d17
	fmul	d7, d7, d16
	fmadd	d22, d26, d5, d22
	ldr	d26, [x14, #16]
	eor	w14, w15, w13
	fmul	d24, d24, d2
	fmadd	d18, d27, d18, d16
	smaddl	x11, w14, w8, x9
	eor	w14, w17, w10
	fmadd	d6, d26, d21, d22
	ldp	d22, d27, [x16]
	fmul	d17, d28, d27
	eor	w15, w14, w18
	fmul	d19, d19, d4
	eor	w14, w14, w13
	smaddl	x15, w15, w8, x9
	fadd	d3, d3, d7
	fmadd	d6, d24, d6, d18
	ldr	d18, [x11, #8]
	fmadd	d17, d22, d5, d17
	ldr	d22, [x16, #16]
	fmul	d24, d23, d19
	eor	w10, w12, w10
	fmul	d18, d28, d18
	ldr	d16, [x15, #8]
	eor	w12, w10, w18
	fmul	d19, d19, d2
	fmadd	d17, d22, d0, d17
	ldr	d22, [x11]
	fmul	d7, d1, d16
	ldr	d16, [x15]
	smaddl	x12, w12, w8, x9
	fmul	d20, d3, d20
	eor	w10, w10, w13
	fmul	d3, d3, d4
	fmadd	d6, d24, d17, d6
	fmadd	d17, d22, d5, d18
	fadd	d5, d5, d25
	ldr	d18, [x11, #16]
	smaddl	x11, w14, w8, x9
	smaddl	x8, w10, w8, x9
	fmadd	d17, d18, d21, d17
	fmadd	d7, d16, d5, d7
	ldr	d16, [x15, #16]
	ldr	d18, [x11, #8]
	fmadd	d6, d19, d17, d6
	ldr	d17, [x12, #8]
	fmul	d1, d1, d18
	ldr	d18, [x11]
	fmul	d19, d20, d23
	fmadd	d7, d16, d0, d7
	fmul	d17, d28, d17
	ldr	d16, [x11, #16]
	fmadd	d1, d18, d5, d1
	ldr	d18, [x12]
	fmadd	d6, d19, d7, d6
	ldr	d7, [x8, #8]
	fmadd	d4, d18, d5, d17
	ldr	d17, [x12, #16]
	fmadd	d1, d16, d21, d1
	fmul	d16, d20, d2
	fmul	d7, d28, d7
	ldr	d18, [x8]
	fmul	d2, d3, d2
	fmadd	d0, d17, d0, d4
	fmul	d4, d23, d3
	fmadd	d1, d16, d1, d6
	ldr	d6, [x8, #16]
	fmadd	d5, d18, d5, d7
	fmadd	d0, d4, d0, d1
	fmadd	d1, d6, d21, d5
	fmadd	d0, d2, d1, d0
	ret
.Lfunc_end240:
	.size	_ZNK6perlin5noiseERK4vec3, .Lfunc_end240-_ZNK6perlin5noiseERK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end241:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end241-_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end242:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end242-_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	adrp	x9, _ZTV13image_texture+16
	mov	x8, x0
	ldr	x0, [x0, #24]
	add	x9, x9, :lo12:_ZTV13image_texture+16
	str	x9, [x8, #16]
	b	free
.Lfunc_end243:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end243-_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end244:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end244-_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB245_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB245_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB245_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB245_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB245_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB245_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end245:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end245-_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN13image_textureC2EPKc,"axG",@progbits,_ZN13image_textureC2EPKc,comdat
	.weak	_ZN13image_textureC2EPKc        // -- Begin function _ZN13image_textureC2EPKc
	.p2align	2
	.type	_ZN13image_textureC2EPKc,@function
_ZN13image_textureC2EPKc:               // @_ZN13image_textureC2EPKc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	mov	x21, x1
	adrp	x9, _ZTV13image_texture+16
	adrp	x1, .L.str.1
	mov	x19, x0
	mov	x20, x0
	mov	w8, #3
	add	x9, x9, :lo12:_ZTV13image_texture+16
	add	x1, x1, :lo12:.L.str.1
	mov	x0, x21
	str	w8, [x29, #28]
	str	x9, [x20], #16
	bl	fopen
	cbz	x0, .LBB246_3
// %bb.1:
	add	x2, x19, #20
	add	x3, x29, #28
	mov	x1, x20
	mov	w4, #3
	mov	x22, x0
	bl	stbi_load_from_file
	mov	x23, x0
	mov	x0, x22
	bl	fclose
	str	x23, [x19, #8]
	cbz	x23, .LBB246_4
// %bb.2:
	ldr	w8, [x20]
	add	w8, w8, w8, lsl #1
	str	w8, [x19, #24]
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.LBB246_3:
	adrp	x9, .L.str.2
	adrp	x8, .L_MergedGlobals.126+8
	add	x9, x9, :lo12:.L.str.2
	str	x9, [x8, :lo12:.L_MergedGlobals.126+8]
	str	xzr, [x19, #8]
.LBB246_4:
	adrp	x22, :got:_ZSt4cerr
	adrp	x1, .L.str.120
	add	x1, x1, :lo12:.L.str.120
	mov	w2, #42
	ldr	x22, [x22, :got_lo12:_ZSt4cerr]
	mov	x0, x22
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
	cbz	x21, .LBB246_6
// %bb.5:
	mov	x0, x21
	bl	strlen
	mov	x2, x0
	adrp	x0, :got:_ZSt4cerr
	mov	x1, x21
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
	b	.LBB246_7
.LBB246_6:
	ldr	x8, [x22]
	ldur	x8, [x8, #-24]
	add	x0, x22, x8
	ldr	w8, [x0, #32]
	orr	w1, w8, #0x1
	bl	_ZNSt9basic_iosIcSt11char_traitsIcEE5clearESt12_Ios_Iostate
.LBB246_7:
	adrp	x0, :got:_ZSt4cerr
	adrp	x1, .L.str.121
	add	x1, x1, :lo12:.L.str.121
	mov	w2, #3
	ldr	x0, [x0, :got_lo12:_ZSt4cerr]
	bl	_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
	mov	w8, wzr
	str	xzr, [x20]
	str	w8, [x19, #24]
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end246:
	.size	_ZN13image_textureC2EPKc, .Lfunc_end246-_ZN13image_textureC2EPKc
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK13image_texture5valueEddRK4vec3,"axG",@progbits,_ZNK13image_texture5valueEddRK4vec3,comdat
	.weak	_ZNK13image_texture5valueEddRK4vec3 // -- Begin function _ZNK13image_texture5valueEddRK4vec3
	.p2align	2
	.type	_ZNK13image_texture5valueEddRK4vec3,@function
_ZNK13image_texture5valueEddRK4vec3:    // @_ZNK13image_texture5valueEddRK4vec3
	.cfi_startproc
// %bb.0:
	ldr	x8, [x0, #8]
	cbz	x8, .LBB247_2
// %bb.1:
	fmov	d2, #1.00000000
	fcmp	d0, #0.0
	movi	d3, #0000000000000000
	ldp	w9, w10, [x0, #16]
	fmin	d4, d0, d2
	fmin	d0, d1, d2
	sub	w13, w9, #1
	fsub	d0, d2, d0
	fcsel	d3, d3, d4, mi
	fcmp	d1, #0.0
	scvtf	d1, w9
	fcsel	d0, d2, d0, mi
	scvtf	d2, w10
	fmul	d1, d3, d1
	fmul	d0, d0, d2
	fcvtzs	w11, d1
	fcvtzs	w12, d0
	cmp	w9, w11
	sub	w9, w10, #1
	csel	w11, w11, w13, gt
	cmp	w10, w12
	ldrsw	x10, [x0, #24]
	csel	w9, w12, w9, gt
	sxtw	x12, w11
	sxtw	x9, w9
	madd	x8, x9, x10, x8
	add	x9, x12, w11, sxtw #1
	add	x8, x8, x9
	mov	x9, #1157442765409226768
	movk	x9, #16240, lsl #48
	ldr	b0, [x8]
	ldr	b1, [x8, #1]
	fmov	d3, x9
	ldr	b2, [x8, #2]
	ucvtf	d0, d0
	ucvtf	d1, d1
	ucvtf	d2, d2
	fmul	d0, d0, d3
	fmul	d1, d1, d3
	fmul	d2, d2, d3
	ret
.LBB247_2:
	movi	d0, #0000000000000000
	fmov	d2, #1.00000000
	fmov	d1, #1.00000000
	ret
.Lfunc_end247:
	.size	_ZNK13image_texture5valueEddRK4vec3, .Lfunc_end247-_ZNK13image_texture5valueEddRK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end248:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end248-_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end249:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end249-_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV13diffuse_light+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV13diffuse_light+16
	str	x8, [x0, #16]
	cbz	x19, .LBB250_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB250_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB250_4
	b	.LBB250_8
.LBB250_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB250_8
.LBB250_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB250_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB250_8
.LBB250_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB250_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB250_6
.LBB250_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end250:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end250-_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end251:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end251-_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB252_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB252_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB252_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB252_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB252_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB252_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end252:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end252-_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK13diffuse_light7emittedEddRK4vec3,"axG",@progbits,_ZNK13diffuse_light7emittedEddRK4vec3,comdat
	.weak	_ZNK13diffuse_light7emittedEddRK4vec3 // -- Begin function _ZNK13diffuse_light7emittedEddRK4vec3
	.p2align	2
	.type	_ZNK13diffuse_light7emittedEddRK4vec3,@function
_ZNK13diffuse_light7emittedEddRK4vec3:  // @_ZNK13diffuse_light7emittedEddRK4vec3
	.cfi_startproc
// %bb.0:
	ldr	x0, [x0, #8]
	ldr	x8, [x0]
	ldr	x2, [x8]
	br	x2
.Lfunc_end253:
	.size	_ZNK13diffuse_light7emittedEddRK4vec3, .Lfunc_end253-_ZNK13diffuse_light7emittedEddRK4vec3
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_,"axG",@progbits,_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_,comdat
	.weak	_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_ // -- Begin function _ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_
	.p2align	2
	.type	_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_,@function
_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_: // @_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_startproc
// %bb.0:
	mov	w0, wzr
	ret
.Lfunc_end254:
	.size	_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_, .Lfunc_end254-_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldr	s0, [x6]
	mov	x20, x1
	ldr	s1, [x4]
	ldr	s2, [x2]
	ldr	s3, [x3]
	sshll	v0.2d, v0.2s, #0
	ldr	s4, [x5]
	sshll	v1.2d, v1.2s, #0
	sshll	v2.2d, v2.2s, #0
	sshll	v3.2d, v3.2s, #0
	sshll	v4.2d, v4.2s, #0
	scvtf	d8, d0
	ldp	x23, x19, [x7]
	scvtf	d12, d2
	scvtf	d10, d1
	scvtf	d11, d3
	scvtf	d9, d4
	cbz	x19, .LBB255_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB255_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7xy_rect+16
	add	x9, x9, :lo12:_ZTV7xy_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB255_5
.LBB255_3:
	adrp	x8, _ZTV7xy_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7xy_rect+16
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB255_13
.LBB255_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7xy_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7xy_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB255_11
.LBB255_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB255_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB255_13
.LBB255_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB255_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB255_10
	b	.LBB255_13
.LBB255_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB255_13
.LBB255_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB255_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	cbnz	w8, .LBB255_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB255_7
.LBB255_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end255:
	.size	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_, .Lfunc_end255-_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldr	s0, [x6]
	mov	x20, x1
	ldr	s1, [x4]
	ldr	s2, [x2]
	ldr	s3, [x3]
	sshll	v0.2d, v0.2s, #0
	ldr	s4, [x5]
	sshll	v1.2d, v1.2s, #0
	sshll	v2.2d, v2.2s, #0
	sshll	v3.2d, v3.2s, #0
	sshll	v4.2d, v4.2s, #0
	scvtf	d8, d0
	ldp	x23, x19, [x7]
	scvtf	d12, d2
	scvtf	d10, d1
	scvtf	d11, d3
	scvtf	d9, d4
	cbz	x19, .LBB256_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB256_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7yz_rect+16
	add	x9, x9, :lo12:_ZTV7yz_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB256_5
.LBB256_3:
	adrp	x8, _ZTV7yz_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7yz_rect+16
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB256_13
.LBB256_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7yz_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7yz_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB256_11
.LBB256_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB256_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB256_13
.LBB256_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB256_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB256_10
	b	.LBB256_13
.LBB256_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB256_13
.LBB256_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB256_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	cbnz	w8, .LBB256_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB256_7
.LBB256_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end256:
	.size	_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_, .Lfunc_end256-_ZN9__gnu_cxx13new_allocatorI7yz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldr	s0, [x6]
	mov	x20, x1
	ldr	s1, [x4]
	ldr	s2, [x2]
	ldr	s3, [x3]
	sshll	v0.2d, v0.2s, #0
	ldr	s4, [x5]
	sshll	v1.2d, v1.2s, #0
	sshll	v2.2d, v2.2s, #0
	sshll	v3.2d, v3.2s, #0
	sshll	v4.2d, v4.2s, #0
	scvtf	d8, d0
	ldp	x23, x19, [x7]
	scvtf	d12, d2
	scvtf	d10, d1
	scvtf	d11, d3
	scvtf	d9, d4
	cbz	x19, .LBB257_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB257_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7xz_rect+16
	add	x9, x9, :lo12:_ZTV7xz_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB257_5
.LBB257_3:
	adrp	x8, _ZTV7xz_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7xz_rect+16
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB257_13
.LBB257_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7xz_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7xz_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB257_11
.LBB257_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB257_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB257_13
.LBB257_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB257_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB257_10
	b	.LBB257_13
.LBB257_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB257_13
.LBB257_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB257_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	cbnz	w8, .LBB257_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB257_7
.LBB257_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end257:
	.size	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_, .Lfunc_end257-_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI13diffuse_lightEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldr	s0, [x6]
	mov	x20, x1
	ldr	s1, [x4]
	ldr	s2, [x2]
	ldr	s3, [x3]
	sshll	v0.2d, v0.2s, #0
	ldr	s4, [x5]
	sshll	v1.2d, v1.2s, #0
	sshll	v2.2d, v2.2s, #0
	sshll	v3.2d, v3.2s, #0
	sshll	v4.2d, v4.2s, #0
	scvtf	d8, d0
	ldp	x23, x19, [x7]
	scvtf	d12, d2
	scvtf	d10, d1
	scvtf	d11, d3
	scvtf	d9, d4
	cbz	x19, .LBB258_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB258_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7xz_rect+16
	add	x9, x9, :lo12:_ZTV7xz_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB258_5
.LBB258_3:
	adrp	x8, _ZTV7xz_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7xz_rect+16
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB258_13
.LBB258_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7xz_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7xz_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB258_11
.LBB258_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB258_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB258_13
.LBB258_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB258_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB258_10
	b	.LBB258_13
.LBB258_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB258_13
.LBB258_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB258_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	cbnz	w8, .LBB258_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB258_7
.LBB258_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end258:
	.size	_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_, .Lfunc_end258-_ZN9__gnu_cxx13new_allocatorI7xz_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #8]              // 16-byte Folded Spill
	stp	d9, d8, [sp, #24]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #40]             // 16-byte Folded Spill
	add	x29, sp, #40
	str	x23, [sp, #56]                  // 8-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 56
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w30, -48
	.cfi_offset w29, -56
	.cfi_offset b8, -64
	.cfi_offset b9, -72
	.cfi_offset b10, -80
	.cfi_offset b11, -88
	.cfi_offset b12, -96
	ldr	s0, [x6]
	mov	x20, x1
	ldr	s1, [x4]
	ldr	s2, [x2]
	ldr	s3, [x3]
	sshll	v0.2d, v0.2s, #0
	ldr	s4, [x5]
	sshll	v1.2d, v1.2s, #0
	sshll	v2.2d, v2.2s, #0
	sshll	v3.2d, v3.2s, #0
	sshll	v4.2d, v4.2s, #0
	scvtf	d8, d0
	ldp	x23, x19, [x7]
	scvtf	d12, d2
	scvtf	d10, d1
	scvtf	d11, d3
	scvtf	d9, d4
	cbz	x19, .LBB259_3
// %bb.1:
	adrp	x22, :got:__libc_single_threaded
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x22]
	cbz	w8, .LBB259_4
// %bb.2:
	ldr	w8, [x19, #8]
	adrp	x9, _ZTV7xy_rect+16
	add	x9, x9, :lo12:_ZTV7xy_rect+16
	str	x19, [x20, #16]
	add	w8, w8, #1
	stp	x9, x23, [x20]
	str	w8, [x19, #8]
	b	.LBB259_5
.LBB259_3:
	adrp	x8, _ZTV7xy_rect+16
	str	xzr, [x20, #16]
	add	x8, x8, :lo12:_ZTV7xy_rect+16
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	stp	x8, x23, [x20]
	b	.LBB259_13
.LBB259_4:
	add	x21, x19, #8
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV7xy_rect+16
	ldrb	w8, [x22]
	add	x9, x9, :lo12:_ZTV7xy_rect+16
	str	x19, [x20, #16]
	stp	x9, x23, [x20]
	cbz	w8, .LBB259_11
.LBB259_5:
	ldr	w8, [x19, #8]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	add	w8, w8, #1
	str	w8, [x19, #8]
.LBB259_6:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB259_13
.LBB259_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB259_9
// %bb.8:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB259_10
	b	.LBB259_13
.LBB259_9:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB259_13
.LBB259_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	br	x1
.LBB259_11:
	mov	w0, #1
	mov	x1, x21
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x22]
	stp	d12, d11, [x20, #24]
	stp	d10, d9, [x20, #40]
	str	d8, [x20, #56]
	cbnz	w8, .LBB259_6
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB259_7
.LBB259_13:
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #40]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #24]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #8]              // 16-byte Folded Reload
	ldr	x23, [sp, #56]                  // 8-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.Lfunc_end259:
	.size	_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_, .Lfunc_end259-_ZN9__gnu_cxx13new_allocatorI7xy_rectE9constructIS1_JiiiiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end260:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end260-_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end261:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end261-_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-64]!           // 16-byte Folded Spill
	str	x23, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	ldp	x19, x22, [x0, #80]
	adrp	x8, _ZTV3box+16
	adrp	x9, _ZTV13hittable_list+16
	add	x8, x8, :lo12:_ZTV3box+16
	add	x9, x9, :lo12:_ZTV13hittable_list+16
	cmp	x19, x22
	str	x8, [x0, #16]
	str	x9, [x0, #72]
	b.eq	.LBB262_12
// %bb.1:
	adrp	x23, :got:__libc_single_threaded
	mov	x20, x0
	ldr	x23, [x23, :got_lo12:__libc_single_threaded]
	b	.LBB262_3
.LBB262_2:                              //   in Loop: Header=BB262_3 Depth=1
	add	x19, x19, #16
	cmp	x19, x22
	b.eq	.LBB262_11
.LBB262_3:                              // =>This Inner Loop Header: Depth=1
	ldr	x21, [x19, #8]
	cbz	x21, .LBB262_2
// %bb.4:                               //   in Loop: Header=BB262_3 Depth=1
	ldrb	w8, [x23]
	cbz	w8, .LBB262_6
// %bb.5:                               //   in Loop: Header=BB262_3 Depth=1
	ldr	w0, [x21, #8]
	sub	w8, w0, #1
	str	w8, [x21, #8]
	cmp	w0, #1
	b.ne	.LBB262_2
	b	.LBB262_7
.LBB262_6:                              //   in Loop: Header=BB262_3 Depth=1
	add	x1, x21, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB262_2
.LBB262_7:                              //   in Loop: Header=BB262_3 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x23]
	cbz	w8, .LBB262_9
// %bb.8:                               //   in Loop: Header=BB262_3 Depth=1
	ldr	w0, [x21, #12]
	sub	w8, w0, #1
	str	w8, [x21, #12]
	cmp	w0, #1
	b.ne	.LBB262_2
	b	.LBB262_10
.LBB262_9:                              //   in Loop: Header=BB262_3 Depth=1
	add	x1, x21, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB262_2
.LBB262_10:                             //   in Loop: Header=BB262_3 Depth=1
	ldr	x8, [x21]
	mov	x0, x21
	ldr	x8, [x8, #24]
	blr	x8
	b	.LBB262_2
.LBB262_11:
	ldr	x19, [x20, #80]
.LBB262_12:
	cbz	x19, .LBB262_14
// %bb.13:
	mov	x0, x19
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	b	_ZdlPv
.LBB262_14:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldr	x23, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #64             // 16-byte Folded Reload
	ret
.Lfunc_end262:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end262-_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end263:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end263-_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB264_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB264_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB264_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB264_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB264_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB264_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end264:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end264-_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
.Lfunc_begin28:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception28
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x22, :got:__libc_single_threaded
	mov	x19, x3
	mov	x20, x2
	mov	x21, x1
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x4]
	stp	x9, x8, [sp]
	cbz	x8, .LBB265_4
// %bb.1:
	ldrb	w9, [x22]
	cbz	w9, .LBB265_3
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB265_4
.LBB265_3:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB265_4:
.Ltmp812:
	mov	x3, sp
	mov	x0, x21
	mov	x1, x20
	mov	x2, x19
	bl	_ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE
.Ltmp813:
// %bb.5:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB265_8
// %bb.6:
	ldrb	w8, [x22]
	cbz	w8, .LBB265_9
// %bb.7:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB265_10
.LBB265_8:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB265_9:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB265_8
.LBB265_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB265_12
// %bb.11:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB265_8
	b	.LBB265_13
.LBB265_12:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB265_8
.LBB265_13:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB265_14:
.Ltmp814:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8materialLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end265:
	.size	_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_, .Lfunc_end265-_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,"aG",@progbits,_ZN9__gnu_cxx13new_allocatorI3boxE9constructIS1_J4vec3S4_RSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,comdat
	.p2align	2
GCC_except_table265:
.Lexception28:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end28-.Lcst_begin28
.Lcst_begin28:
	.uleb128 .Lfunc_begin28-.Lfunc_begin28  // >> Call Site 1 <<
	.uleb128 .Ltmp812-.Lfunc_begin28        //   Call between .Lfunc_begin28 and .Ltmp812
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp812-.Lfunc_begin28        // >> Call Site 2 <<
	.uleb128 .Ltmp813-.Ltmp812              //   Call between .Ltmp812 and .Ltmp813
	.uleb128 .Ltmp814-.Lfunc_begin28        //     jumps to .Ltmp814
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp813-.Lfunc_begin28        // >> Call Site 3 <<
	.uleb128 .Lfunc_end265-.Ltmp813         //   Call between .Ltmp813 and .Lfunc_end265
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end28:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end266:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end266-_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end267:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end267-_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV8rotate_y+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV8rotate_y+16
	str	x8, [x0, #16]
	cbz	x19, .LBB268_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB268_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB268_4
	b	.LBB268_8
.LBB268_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB268_8
.LBB268_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB268_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB268_8
.LBB268_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB268_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB268_6
.LBB268_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end268:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end268-_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end269:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end269-_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB270_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB270_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB270_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB270_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB270_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB270_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end270:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end270-_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
.Lfunc_begin29:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception29
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x21, [sp, #32]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	mov	x20, x3
	mov	x19, x1
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x2]
	stp	x9, x8, [sp]
	cbz	x8, .LBB271_4
// %bb.1:
	ldrb	w9, [x21]
	cbz	w9, .LBB271_3
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB271_4
.LBB271_3:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB271_4:
	ldr	s0, [x20]
	sshll	v0.2d, v0.2s, #0
	scvtf	d0, d0
.Ltmp815:
	mov	x1, sp
	mov	x0, x19
	bl	_ZN8rotate_yC2ESt10shared_ptrI8hittableEd
.Ltmp816:
// %bb.5:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB271_13
// %bb.6:
	ldrb	w8, [x21]
	cbz	w8, .LBB271_8
// %bb.7:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB271_9
	b	.LBB271_13
.LBB271_8:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB271_13
.LBB271_9:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB271_12
// %bb.10:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB271_13
.LBB271_11:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #64
	br	x1
.LBB271_12:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB271_11
.LBB271_13:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB271_14:
.Ltmp817:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end271:
	.size	_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_, .Lfunc_end271-_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_,"aG",@progbits,_ZN9__gnu_cxx13new_allocatorI8rotate_yE9constructIS1_JRSt10shared_ptrI8hittableEiEEEvPT_DpOT0_,comdat
	.p2align	2
GCC_except_table271:
.Lexception29:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end29-.Lcst_begin29
.Lcst_begin29:
	.uleb128 .Lfunc_begin29-.Lfunc_begin29  // >> Call Site 1 <<
	.uleb128 .Ltmp815-.Lfunc_begin29        //   Call between .Lfunc_begin29 and .Ltmp815
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp815-.Lfunc_begin29        // >> Call Site 2 <<
	.uleb128 .Ltmp816-.Ltmp815              //   Call between .Ltmp815 and .Ltmp816
	.uleb128 .Ltmp817-.Lfunc_begin29        //     jumps to .Ltmp817
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp816-.Lfunc_begin29        // >> Call Site 3 <<
	.uleb128 .Lfunc_end271-.Ltmp816         //   Call between .Ltmp816 and .Lfunc_end271
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end29:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_,"axG",@progbits,_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_,comdat
	.weak	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_ // -- Begin function _ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
	.p2align	2
	.type	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_,@function
_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_: // @_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-96]!           // 16-byte Folded Spill
	str	x27, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x26, x25, [sp, #32]             // 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 96
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w25, -56
	.cfi_offset w26, -64
	.cfi_offset w27, -80
	.cfi_offset w30, -88
	.cfi_offset w29, -96
	mov	x20, x0
	mov	w0, #64
	mov	x23, x4
	mov	x24, x3
	mov	x19, x1
	bl	_Znwm
	ldp	x27, x22, [x24]
	movi	v0.2s, #1
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x25, x0, #16
	str	d0, [x0, #8]
	str	x8, [x0]
	cbz	x22, .LBB272_3
// %bb.1:
	adrp	x26, :got:__libc_single_threaded
	ldr	x26, [x26, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x26]
	cbz	w8, .LBB272_4
// %bb.2:
	adrp	x9, _ZTV9translate+16
	ldr	w8, [x22, #8]
	add	x9, x9, :lo12:_ZTV9translate+16
	str	x22, [x21, #32]
	add	w8, w8, #1
	stp	x9, x27, [x21, #16]
	b	.LBB272_6
.LBB272_3:
	adrp	x8, _ZTV9translate+16
	ldr	q0, [x23]
	add	x8, x8, :lo12:_ZTV9translate+16
	str	xzr, [x21, #32]
	stur	q0, [x21, #40]
	stp	x8, x27, [x21, #16]
	ldr	x8, [x23, #16]
	str	x8, [x21, #56]
	b	.LBB272_12
.LBB272_4:
	add	x24, x22, #8
	mov	w0, #1
	mov	x1, x24
	bl	__aarch64_ldadd4_acq_rel
	adrp	x9, _ZTV9translate+16
	ldrb	w8, [x26]
	add	x9, x9, :lo12:_ZTV9translate+16
	str	x22, [x21, #32]
	stp	x9, x27, [x21, #16]
	cbz	w8, .LBB272_13
// %bb.5:
	ldr	w8, [x22, #8]
.LBB272_6:
	add	w8, w8, #1
	str	w8, [x22, #8]
	ldr	q0, [x23]
	ldr	x8, [x23, #16]
	stur	q0, [x21, #40]
	str	x8, [x21, #56]
.LBB272_7:
	ldr	w0, [x22, #8]
	sub	w8, w0, #1
	str	w8, [x22, #8]
	cmp	w0, #1
	b.ne	.LBB272_12
.LBB272_8:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x26]
	cbz	w8, .LBB272_10
// %bb.9:
	ldr	w0, [x22, #12]
	sub	w8, w0, #1
	str	w8, [x22, #12]
	cmp	w0, #1
	b.eq	.LBB272_11
	b	.LBB272_12
.LBB272_10:
	add	x1, x22, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB272_12
.LBB272_11:
	ldr	x8, [x22]
	mov	x0, x22
	ldr	x8, [x8, #24]
	blr	x8
.LBB272_12:
	str	x21, [x20]
	ldr	x27, [sp, #16]                  // 8-byte Folded Reload
	str	x25, [x19]
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             // 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #96             // 16-byte Folded Reload
	ret
.LBB272_13:
	mov	w0, #1
	mov	x1, x24
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x26]
	ldr	q0, [x23]
	ldr	x9, [x23, #16]
	stur	q0, [x21, #40]
	str	x9, [x21, #56]
	cbnz	w8, .LBB272_7
// %bb.14:
	add	x1, x22, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB272_8
	b	.LBB272_12
.Lfunc_end272:
	.size	_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_, .Lfunc_end272-_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2I9translateSaIS4_EJRSt10shared_ptrI8hittableE4vec3EEERPT_St20_Sp_alloc_shared_tagIT0_EDpOT1_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end273:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end273-_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end274:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end274-_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV9translate+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV9translate+16
	str	x8, [x0, #16]
	cbz	x19, .LBB275_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB275_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB275_4
	b	.LBB275_8
.LBB275_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB275_8
.LBB275_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB275_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB275_8
.LBB275_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB275_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB275_6
.LBB275_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end275:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end275-_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end276:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end276-_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB277_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB277_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB277_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB277_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB277_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB277_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end277:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end277-_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end278:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end278-_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end279:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end279-_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	add	x0, x0, #16
	mov	x1, x0
	b	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_
.Lfunc_end280:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end280-_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end281:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end281-_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB282_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB282_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB282_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB282_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB282_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB282_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end282:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end282-_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_
.Lfunc_begin30:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception30
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x22, :got:__libc_single_threaded
	mov	x20, x4
	mov	x21, x3
	mov	x19, x1
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x2]
	stp	x9, x8, [sp]
	cbz	x8, .LBB283_4
// %bb.1:
	ldrb	w9, [x22]
	cbz	w9, .LBB283_3
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB283_4
.LBB283_3:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB283_4:
	ldp	d1, d2, [x20]
	ldr	d0, [x21]
	ldr	d3, [x20, #16]
.Ltmp818:
	mov	x1, sp
	mov	x0, x19
	bl	_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3
.Ltmp819:
// %bb.5:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB283_8
// %bb.6:
	ldrb	w8, [x22]
	cbz	w8, .LBB283_9
// %bb.7:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB283_10
.LBB283_8:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB283_9:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB283_8
.LBB283_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB283_12
// %bb.11:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB283_8
	b	.LBB283_13
.LBB283_12:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB283_8
.LBB283_13:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB283_14:
.Ltmp820:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end283:
	.size	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_, .Lfunc_end283-_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_,"aG",@progbits,_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI8hittableEd4vec3EEEvPT_DpOT0_,comdat
	.p2align	2
GCC_except_table283:
.Lexception30:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end30-.Lcst_begin30
.Lcst_begin30:
	.uleb128 .Lfunc_begin30-.Lfunc_begin30  // >> Call Site 1 <<
	.uleb128 .Ltmp818-.Lfunc_begin30        //   Call between .Lfunc_begin30 and .Ltmp818
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp818-.Lfunc_begin30        // >> Call Site 2 <<
	.uleb128 .Ltmp819-.Ltmp818              //   Call between .Ltmp818 and .Ltmp819
	.uleb128 .Ltmp820-.Lfunc_begin30        //     jumps to .Ltmp820
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp819-.Lfunc_begin30        // >> Call Site 3 <<
	.uleb128 .Lfunc_end283-.Ltmp819         //   Call between .Ltmp819 and .Lfunc_end283
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end30:
	.p2align	2
                                        // -- End function
	.section	.text._ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3,"axG",@progbits,_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3,comdat
	.weak	_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3 // -- Begin function _ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3
	.p2align	2
	.type	_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3,@function
_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3: // @_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3
.Lfunc_begin31:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception31
// %bb.0:
	str	d12, [sp, #-96]!                // 8-byte Folded Spill
	stp	d11, d10, [sp, #16]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #32]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x22, x21, [sp, #64]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	.cfi_offset b10, -72
	.cfi_offset b11, -80
	.cfi_offset b12, -96
	ldp	x10, x8, [x1]
	fmov	d8, d3
	fmov	d9, d2
	fmov	d10, d1
	fmov	d11, d0
	adrp	x9, _ZTV15constant_medium+16
	mov	x19, x0
	add	x9, x9, :lo12:_ZTV15constant_medium+16
	mov	x20, x0
	str	x8, [x0, #16]
	str	x9, [x0]
	str	x10, [x20, #8]!
	cbz	x8, .LBB284_4
// %bb.1:
	adrp	x9, :got:__libc_single_threaded
	ldr	x9, [x9, :got_lo12:__libc_single_threaded]
	ldrb	w9, [x9]
	cbz	w9, .LBB284_3
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB284_4
.LBB284_3:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB284_4:
.Ltmp821:
	mov	w0, #40
	bl	_Znwm
.Ltmp822:
// %bb.5:
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	movi	v12.2s, #1
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x21, x0
	mov	x22, x0
	str	x8, [x0]
	adrp	x8, _ZTV9isotropic+16
	add	x8, x8, :lo12:_ZTV9isotropic+16
	str	d12, [x0, #8]
	str	x8, [x22, #16]!
.Ltmp824:
	mov	w0, #48
	bl	_Znwm
.Ltmp825:
// %bb.6:
	fmov	d0, #-1.00000000
	adrp	x8, _ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	add	x8, x8, :lo12:_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE+16
	mov	x9, x0
	str	d10, [x0, #24]
	fdiv	d0, d0, d11
	str	d9, [x0, #32]
	str	x8, [x0]
	adrp	x8, _ZTV11solid_color+16
	add	x8, x8, :lo12:_ZTV11solid_color+16
	str	d8, [x0, #40]
	stp	x22, x21, [x19, #24]
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	str	x8, [x9, #16]!
	stp	x9, x0, [x21, #24]
	ldp	x22, x21, [sp, #64]             // 16-byte Folded Reload
	str	d12, [x0, #8]
	ldp	d9, d8, [sp, #32]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #16]             // 16-byte Folded Reload
	str	d0, [x19, #40]
	ldp	x20, x19, [sp, #80]             // 16-byte Folded Reload
	ldr	d12, [sp], #96                  // 8-byte Folded Reload
	ret
.LBB284_7:
.Ltmp826:
	mov	x19, x0
	mov	x0, x21
	bl	_ZdlPv
	b	.LBB284_9
.LBB284_8:
.Ltmp823:
	mov	x19, x0
.LBB284_9:
	mov	x0, x20
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end284:
	.size	_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3, .Lfunc_end284-_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3
	.cfi_endproc
	.section	.gcc_except_table._ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3,"aG",@progbits,_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3,comdat
	.p2align	2
GCC_except_table284:
.Lexception31:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end31-.Lcst_begin31
.Lcst_begin31:
	.uleb128 .Lfunc_begin31-.Lfunc_begin31  // >> Call Site 1 <<
	.uleb128 .Ltmp821-.Lfunc_begin31        //   Call between .Lfunc_begin31 and .Ltmp821
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp821-.Lfunc_begin31        // >> Call Site 2 <<
	.uleb128 .Ltmp822-.Ltmp821              //   Call between .Ltmp821 and .Ltmp822
	.uleb128 .Ltmp823-.Lfunc_begin31        //     jumps to .Ltmp823
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp824-.Lfunc_begin31        // >> Call Site 3 <<
	.uleb128 .Ltmp825-.Ltmp824              //   Call between .Ltmp824 and .Ltmp825
	.uleb128 .Ltmp826-.Lfunc_begin31        //     jumps to .Ltmp826
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp825-.Lfunc_begin31        // >> Call Site 4 <<
	.uleb128 .Lfunc_end284-.Ltmp825         //   Call between .Ltmp825 and .Lfunc_end284
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end31:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_startproc
// %bb.0:
	ret
.Lfunc_end285:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev, .Lfunc_end285-_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev,@function
_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev: // @_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end286:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev, .Lfunc_end286-_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv: // @_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	stp	x20, x19, [sp, #16]             // 16-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x8, _ZTV9isotropic+16
	ldr	x19, [x0, #32]
	add	x8, x8, :lo12:_ZTV9isotropic+16
	str	x8, [x0, #16]
	cbz	x19, .LBB287_8
// %bb.1:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB287_3
// %bb.2:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB287_4
	b	.LBB287_8
.LBB287_3:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB287_8
.LBB287_4:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB287_7
// %bb.5:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB287_8
.LBB287_6:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	br	x1
.LBB287_7:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB287_6
.LBB287_8:
	ldp	x20, x19, [sp, #16]             // 16-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end287:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv, .Lfunc_end287-_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv,@function
_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv: // @_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_startproc
// %bb.0:
	b	_ZdlPv
.Lfunc_end288:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv, .Lfunc_end288-_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,"axG",@progbits,_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,comdat
	.weak	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info // -- Begin function _ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.p2align	2
	.type	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info,@function
_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info: // @_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	mov	x19, x0
	adrp	x8, _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	add	x8, x8, :lo12:_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	cmp	x1, x8
	b.eq	.LBB289_6
// %bb.1:
	ldr	x0, [x1, #8]
	adrp	x8, _ZTSSt19_Sp_make_shared_tag
	add	x8, x8, :lo12:_ZTSSt19_Sp_make_shared_tag
	cmp	x0, x8
	b.eq	.LBB289_6
// %bb.2:
	ldrb	w8, [x0]
	cmp	w8, #42
	b.ne	.LBB289_4
// %bb.3:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB289_4:
	adrp	x1, _ZTSSt19_Sp_make_shared_tag
	add	x1, x1, :lo12:_ZTSSt19_Sp_make_shared_tag
	bl	strcmp
	cbz	w0, .LBB289_6
// %bb.5:
	mov	x0, xzr
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.LBB289_6:
	add	x0, x19, #16
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	ret
.Lfunc_end289:
	.size	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info, .Lfunc_end289-_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.cfi_endproc
                                        // -- End function
	.section	.text._ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_,"axG",@progbits,_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_,comdat
	.weak	_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_ // -- Begin function _ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_
	.p2align	2
	.type	_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_,@function
_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_: // @_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_startproc
// %bb.0:
	stp	d13, d12, [sp, #-112]!          // 16-byte Folded Spill
	stp	d11, d10, [sp, #16]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #32]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             // 16-byte Folded Spill
	add	x29, sp, #48
	stp	x24, x23, [sp, #64]             // 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 64
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w23, -40
	.cfi_offset w24, -48
	.cfi_offset w30, -56
	.cfi_offset w29, -64
	.cfi_offset b8, -72
	.cfi_offset b9, -80
	.cfi_offset b10, -88
	.cfi_offset b11, -96
	.cfi_offset b12, -104
	.cfi_offset b13, -112
	mov	x21, x4
	mov	x19, x3
	mov	x20, x2
	mov	x23, x1
	mov	x22, x0
	mov	x24, #4467570830351532032
	fmov	d8, #-1.00000000
	fmov	d9, #2.00000000
	fmov	d10, #1.00000000
.LBB290_1:                              // =>This Inner Loop Header: Depth=1
	bl	rand
	scvtf	d0, w0
	fmov	d13, x24
	fmul	d0, d0, d13
	fmadd	d11, d0, d9, d8
	bl	rand
	scvtf	d0, w0
	fmul	d0, d0, d13
	fmadd	d12, d0, d9, d8
	bl	rand
	fmul	d0, d12, d12
	scvtf	d1, w0
	fmadd	d2, d11, d11, d0
	fmul	d0, d1, d13
	fmadd	d0, d0, d9, d8
	fmadd	d1, d0, d0, d2
	fcmp	d1, d10
	b.ge	.LBB290_1
// %bb.2:
	ldr	d1, [x23, #48]
	mov	x1, x20
	ldr	x8, [x20, #16]
	ldr	q2, [x20]
	stp	d11, d12, [x21, #24]
	stp	d0, d1, [x21, #40]
	str	x8, [x21, #16]
	str	q2, [x21]
	ldr	x0, [x22, #8]
	ldp	d0, d1, [x20, #72]
	ldr	x8, [x0]
	ldr	x8, [x8]
	blr	x8
	stp	d0, d1, [x19]
	mov	w0, #1
	str	d2, [x19, #16]
	ldp	x20, x19, [sp, #96]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             // 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #48]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #32]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #16]             // 16-byte Folded Reload
	ldp	d13, d12, [sp], #112            // 16-byte Folded Reload
	ret
.Lfunc_end290:
	.size	_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_, .Lfunc_end290-_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_,@function
_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_: // @_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-48]!           // 16-byte Folded Spill
	str	x21, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	stp	x20, x19, [sp, #32]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x21, :got:__libc_single_threaded
	adrp	x8, _ZTV15constant_medium+16
	mov	x19, x1
	ldr	x20, [x1, #32]
	add	x8, x8, :lo12:_ZTV15constant_medium+16
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	str	x8, [x1]
	cbz	x20, .LBB291_7
// %bb.1:
	ldrb	w8, [x21]
	cbz	w8, .LBB291_3
// %bb.2:
	ldr	w0, [x20, #8]
	sub	w8, w0, #1
	str	w8, [x20, #8]
	cmp	w0, #1
	b.eq	.LBB291_4
	b	.LBB291_7
.LBB291_3:
	add	x1, x20, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB291_7
.LBB291_4:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB291_14
// %bb.5:
	ldr	w0, [x20, #12]
	sub	w8, w0, #1
	str	w8, [x20, #12]
	cmp	w0, #1
	b.ne	.LBB291_7
.LBB291_6:
	ldr	x8, [x20]
	mov	x0, x20
	ldr	x8, [x8, #24]
	blr	x8
.LBB291_7:
	ldr	x19, [x19, #16]
	cbz	x19, .LBB291_16
// %bb.8:
	ldrb	w8, [x21]
	cbz	w8, .LBB291_10
// %bb.9:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB291_11
	b	.LBB291_16
.LBB291_10:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB291_16
.LBB291_11:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB291_15
// %bb.12:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB291_16
.LBB291_13:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	br	x1
.LBB291_14:
	add	x1, x20, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB291_6
	b	.LBB291_7
.LBB291_15:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB291_13
.LBB291_16:
	ldp	x20, x19, [sp, #32]             // 16-byte Folded Reload
	ldr	x21, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #48             // 16-byte Folded Reload
	ret
.Lfunc_end291:
	.size	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_, .Lfunc_end291-_ZN9__gnu_cxx13new_allocatorI15constant_mediumE7destroyIS1_EEvPT_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_startproc
// %bb.0:
	sub	sp, sp, #128
	str	d12, [sp, #32]                  // 8-byte Folded Spill
	stp	d11, d10, [sp, #48]             // 16-byte Folded Spill
	stp	d9, d8, [sp, #64]               // 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             // 16-byte Folded Spill
	add	x29, sp, #80
	stp	x22, x21, [sp, #96]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	.cfi_offset b8, -56
	.cfi_offset b9, -64
	.cfi_offset b10, -72
	.cfi_offset b11, -80
	.cfi_offset b12, -96
	ldr	s0, [x6]
	adrp	x21, :got:__libc_single_threaded
	ldr	s1, [x4]
	mov	x20, x1
	ldr	s2, [x5]
	sshll	v0.2d, v0.2s, #0
	ldr	q3, [x2]
	sshll	v1.2d, v1.2s, #0
	ldr	d8, [x2, #16]
	sshll	v2.2d, v2.2s, #0
	ldr	q4, [x3]
	ldp	x22, x19, [x7]
	scvtf	d12, d0
	scvtf	d10, d1
	ldr	d11, [x3, #16]
	scvtf	d9, d2
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	cbz	x19, .LBB292_4
// %bb.1:
	ldrb	w8, [x21]
	cbz	w8, .LBB292_3
// %bb.2:
	ldr	w8, [x19, #8]
	add	w8, w8, #1
	str	w8, [x19, #8]
	b	.LBB292_4
.LBB292_3:
	add	x1, x19, #8
	mov	w0, #1
	stp	q4, q3, [sp]                    // 32-byte Folded Spill
	bl	__aarch64_ldadd4_acq_rel
	ldp	q4, q3, [sp]                    // 32-byte Folded Reload
.LBB292_4:
	adrp	x8, _ZTV13moving_sphere+16
	stur	q3, [x20, #8]
	add	x8, x8, :lo12:_ZTV13moving_sphere+16
	str	d8, [x20, #24]
	str	q4, [x20, #32]
	str	d11, [x20, #48]
	str	x8, [x20]
	str	d10, [x20, #56]
	str	d9, [x20, #64]
	str	d12, [x20, #72]
	stp	x22, x19, [x20, #80]
	cbz	x19, .LBB292_14
// %bb.5:
	ldrb	w8, [x21]
	cbz	w8, .LBB292_7
// %bb.6:
	ldr	w8, [x19, #8]
	add	w8, w8, #1
	str	w8, [x19, #8]
	mov	w0, w8
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB292_9
	b	.LBB292_14
.LBB292_7:
	add	x20, x19, #8
	mov	w0, #1
	mov	x1, x20
	bl	__aarch64_ldadd4_acq_rel
	ldrb	w8, [x21]
	cbz	w8, .LBB292_13
// %bb.8:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.ne	.LBB292_14
.LBB292_9:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbz	w8, .LBB292_11
// %bb.10:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.eq	.LBB292_12
	b	.LBB292_14
.LBB292_11:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB292_14
.LBB292_12:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #48]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	d12, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #128
	br	x1
.LBB292_13:
	mov	w0, #-1
	mov	x1, x20
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB292_9
.LBB292_14:
	ldp	x20, x19, [sp, #112]            // 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #80]             // 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               // 16-byte Folded Reload
	ldp	d11, d10, [sp, #48]             // 16-byte Folded Reload
	ldr	d12, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #128
	ret
.Lfunc_end292:
	.size	_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_, .Lfunc_end292-_ZN9__gnu_cxx13new_allocatorI13moving_sphereE9constructIS1_JR4vec3S5_iiiRSt10shared_ptrI10lambertianEEEEvPT_DpOT0_
	.cfi_endproc
                                        // -- End function
	.section	.text._ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_,"axG",@progbits,_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_,comdat
	.weak	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_ // -- Begin function _ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_
	.p2align	2
	.type	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_,@function
_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_: // @_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_
.Lfunc_begin32:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception32
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	stp	x22, x21, [sp, #32]             // 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -24
	.cfi_offset w22, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	adrp	x22, :got:__libc_single_threaded
	mov	x20, x4
	mov	x21, x3
	mov	x19, x1
	ldr	x22, [x22, :got_lo12:__libc_single_threaded]
	ldp	x9, x8, [x2]
	stp	x9, x8, [sp]
	cbz	x8, .LBB293_4
// %bb.1:
	ldrb	w9, [x22]
	cbz	w9, .LBB293_3
// %bb.2:
	ldr	w9, [x8, #8]
	add	w9, w9, #1
	str	w9, [x8, #8]
	b	.LBB293_4
.LBB293_3:
	add	x1, x8, #8
	mov	w0, #1
	bl	__aarch64_ldadd4_acq_rel
.LBB293_4:
	ldp	d1, d2, [x20]
	ldr	d0, [x21]
	ldr	d3, [x20, #16]
.Ltmp827:
	mov	x1, sp
	mov	x0, x19
	bl	_ZN15constant_mediumC2ESt10shared_ptrI8hittableEd4vec3
.Ltmp828:
// %bb.5:
	ldr	x19, [sp, #8]
	cbz	x19, .LBB293_8
// %bb.6:
	ldrb	w8, [x22]
	cbz	w8, .LBB293_9
// %bb.7:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB293_10
.LBB293_8:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB293_9:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB293_8
.LBB293_10:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x22]
	cbz	w8, .LBB293_12
// %bb.11:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB293_8
	b	.LBB293_13
.LBB293_12:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB293_8
.LBB293_13:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB293_14:
.Ltmp829:
	mov	x19, x0
	mov	x0, sp
	bl	_ZNSt12__shared_ptrI8hittableLN9__gnu_cxx12_Lock_policyE2EED2Ev
	mov	x0, x19
	bl	_Unwind_Resume
.Lfunc_end293:
	.size	_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_, .Lfunc_end293-_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_
	.cfi_endproc
	.section	.gcc_except_table._ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_,"aG",@progbits,_ZN9__gnu_cxx13new_allocatorI15constant_mediumE9constructIS1_JRSt10shared_ptrI6sphereEd4vec3EEEvPT_DpOT0_,comdat
	.p2align	2
GCC_except_table293:
.Lexception32:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end32-.Lcst_begin32
.Lcst_begin32:
	.uleb128 .Lfunc_begin32-.Lfunc_begin32  // >> Call Site 1 <<
	.uleb128 .Ltmp827-.Lfunc_begin32        //   Call between .Lfunc_begin32 and .Ltmp827
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp827-.Lfunc_begin32        // >> Call Site 2 <<
	.uleb128 .Ltmp828-.Ltmp827              //   Call between .Ltmp827 and .Ltmp828
	.uleb128 .Ltmp829-.Lfunc_begin32        //     jumps to .Ltmp829
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp828-.Lfunc_begin32        // >> Call Site 3 <<
	.uleb128 .Lfunc_end293-.Ltmp828         //   Call between .Ltmp828 and .Lfunc_end293
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end32:
	.p2align	2
                                        // -- End function
	.section	.text._ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_,"axG",@progbits,_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_,comdat
	.weak	_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_ // -- Begin function _ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_
	.p2align	2
	.type	_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_,@function
_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_: // @_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_
.Lfunc_begin33:
	.cfi_startproc
	.cfi_personality 156, DW.ref.__gxx_personality_v0
	.cfi_lsda 28, .Lexception33
// %bb.0:
	sub	sp, sp, #64
	stp	x29, x30, [sp, #16]             // 16-byte Folded Spill
	add	x29, sp, #16
	str	x21, [sp, #32]                  // 8-byte Folded Spill
	stp	x20, x19, [sp, #48]             // 16-byte Folded Spill
	.cfi_def_cfa w29, 48
	.cfi_offset w19, -8
	.cfi_offset w20, -16
	.cfi_offset w21, -32
	.cfi_offset w30, -40
	.cfi_offset w29, -48
	ldp	x8, x19, [x2]
	stp	xzr, xzr, [x2]
	mov	x0, x1
	ldr	s0, [x3]
	sshll	v0.2d, v0.2s, #0
	stp	x8, x19, [sp]
	scvtf	d0, d0
.Ltmp830:
	mov	x1, sp
	bl	_ZN8rotate_yC2ESt10shared_ptrI8hittableEd
.Ltmp831:
// %bb.1:
	cbz	x19, .LBB294_9
// %bb.2:
	adrp	x20, :got:__libc_single_threaded
	ldr	x20, [x20, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x20]
	cbz	w8, .LBB294_4
// %bb.3:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
	cmp	w0, #1
	b.eq	.LBB294_5
	b	.LBB294_9
.LBB294_4:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.ne	.LBB294_9
.LBB294_5:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x20]
	cbz	w8, .LBB294_8
// %bb.6:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
	cmp	w0, #1
	b.ne	.LBB294_9
.LBB294_7:
	ldr	x8, [x19]
	mov	x0, x19
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x1, [x8, #24]
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #64
	br	x1
.LBB294_8:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	cmp	w0, #1
	b.eq	.LBB294_7
.LBB294_9:
	ldp	x20, x19, [sp, #48]             // 16-byte Folded Reload
	ldp	x29, x30, [sp, #16]             // 16-byte Folded Reload
	ldr	x21, [sp, #32]                  // 8-byte Folded Reload
	add	sp, sp, #64
	ret
.LBB294_10:
.Ltmp832:
	mov	x20, x0
	cbz	x19, .LBB294_20
// %bb.11:
	adrp	x21, :got:__libc_single_threaded
	ldr	x21, [x21, :got_lo12:__libc_single_threaded]
	ldrb	w8, [x21]
	cbnz	w8, .LBB294_13
// %bb.12:
	add	x1, x19, #8
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB294_14
.LBB294_13:
	ldr	w0, [x19, #8]
	sub	w8, w0, #1
	str	w8, [x19, #8]
.LBB294_14:
	cmp	w0, #1
	b.ne	.LBB294_20
// %bb.15:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #16]
	blr	x8
	ldrb	w8, [x21]
	cbnz	w8, .LBB294_17
// %bb.16:
	add	x1, x19, #12
	mov	w0, #-1
	bl	__aarch64_ldadd4_acq_rel
	b	.LBB294_18
.LBB294_17:
	ldr	w0, [x19, #12]
	sub	w8, w0, #1
	str	w8, [x19, #12]
.LBB294_18:
	cmp	w0, #1
	b.ne	.LBB294_20
// %bb.19:
	ldr	x8, [x19]
	mov	x0, x19
	ldr	x8, [x8, #24]
	blr	x8
.LBB294_20:
	mov	x0, x20
	bl	_Unwind_Resume
.Lfunc_end294:
	.size	_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_, .Lfunc_end294-_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_
	.cfi_endproc
	.section	.gcc_except_table._ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_,"aG",@progbits,_ZNSt16allocator_traitsISaI8rotate_yEE9constructIS0_JSt10shared_ptrI8bvh_nodeEiEEEvRS1_PT_DpOT0_,comdat
	.p2align	2
GCC_except_table294:
.Lexception33:
	.byte	255                             // @LPStart Encoding = omit
	.byte	255                             // @TType Encoding = omit
	.byte	1                               // Call site Encoding = uleb128
	.uleb128 .Lcst_end33-.Lcst_begin33
.Lcst_begin33:
	.uleb128 .Ltmp830-.Lfunc_begin33        // >> Call Site 1 <<
	.uleb128 .Ltmp831-.Ltmp830              //   Call between .Ltmp830 and .Ltmp831
	.uleb128 .Ltmp832-.Lfunc_begin33        //     jumps to .Ltmp832
	.byte	0                               //   On action: cleanup
	.uleb128 .Ltmp831-.Lfunc_begin33        // >> Call Site 2 <<
	.uleb128 .Lfunc_end294-.Ltmp831         //   Call between .Ltmp831 and .Lfunc_end294
	.byte	0                               //     has no landing pad
	.byte	0                               //   On action: cleanup
.Lcst_end33:
	.p2align	2
                                        // -- End function
	.section	.text.startup,"ax",@progbits
	.p2align	2                               // -- Begin function _GLOBAL__sub_I_main.cc
	.type	_GLOBAL__sub_I_main.cc,@function
_GLOBAL__sub_I_main.cc:                 // @_GLOBAL__sub_I_main.cc
	.cfi_startproc
// %bb.0:
	stp	x29, x30, [sp, #-32]!           // 16-byte Folded Spill
	str	x19, [sp, #16]                  // 8-byte Folded Spill
	mov	x29, sp
	.cfi_def_cfa w29, 32
	.cfi_offset w19, -16
	.cfi_offset w30, -24
	.cfi_offset w29, -32
	adrp	x19, _ZStL8__ioinit
	add	x19, x19, :lo12:_ZStL8__ioinit
	mov	x0, x19
	bl	_ZNSt8ios_base4InitC1Ev
	adrp	x0, :got:_ZNSt8ios_base4InitD1Ev
	mov	x1, x19
	adrp	x2, __dso_handle
	add	x2, x2, :lo12:__dso_handle
	ldr	x0, [x0, :got_lo12:_ZNSt8ios_base4InitD1Ev]
	ldr	x19, [sp, #16]                  // 8-byte Folded Reload
	ldp	x29, x30, [sp], #32             // 16-byte Folded Reload
	b	__cxa_atexit
.Lfunc_end295:
	.size	_GLOBAL__sub_I_main.cc, .Lfunc_end295-_GLOBAL__sub_I_main.cc
	.cfi_endproc
                                        // -- End function
	.type	_ZStL8__ioinit,@object          // @_ZStL8__ioinit
	.local	_ZStL8__ioinit
	.comm	_ZStL8__ioinit,1,1
	.hidden	__dso_handle
	.type	_ZTV8rotate_y,@object           // @_ZTV8rotate_y
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTV8rotate_y
	.p2align	3
_ZTV8rotate_y:
	.xword	0
	.xword	_ZTI8rotate_y
	.xword	_ZNK8rotate_y3hitERK3rayddR10hit_record
	.xword	_ZNK8rotate_y12bounding_boxEddR4aabb
	.size	_ZTV8rotate_y, 32

	.type	_ZTV3box,@object                // @_ZTV3box
	.globl	_ZTV3box
	.p2align	3
_ZTV3box:
	.xword	0
	.xword	_ZTI3box
	.xword	_ZNK3box3hitERK3rayddR10hit_record
	.xword	_ZNK3box12bounding_boxEddR4aabb
	.size	_ZTV3box, 32

	.type	_ZTV8bvh_node,@object           // @_ZTV8bvh_node
	.globl	_ZTV8bvh_node
	.p2align	3
_ZTV8bvh_node:
	.xword	0
	.xword	_ZTI8bvh_node
	.xword	_ZNK8bvh_node3hitERK3rayddR10hit_record
	.xword	_ZNK8bvh_node12bounding_boxEddR4aabb
	.size	_ZTV8bvh_node, 32

	.type	.L.str,@object                  // @.str
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str:
	.asciz	"No bounding box in bvh_node constructor.\n"
	.size	.L.str, 42

	.type	.L.str.1,@object                // @.str.1
.L.str.1:
	.asciz	"rb"
	.size	.L.str.1, 3

	.type	.L.str.2,@object                // @.str.2
.L.str.2:
	.asciz	"can't fopen"
	.size	.L.str.2, 12

	.type	_ZL27stbi__unpremultiply_on_load,@object // @_ZL27stbi__unpremultiply_on_load
	.local	_ZL27stbi__unpremultiply_on_load
	.comm	_ZL27stbi__unpremultiply_on_load,4,4
	.type	.L.str.3,@object                // @.str.3
.L.str.3:
	.asciz	"earthmap.jpg"
	.size	.L.str.3, 13

	.type	.L.str.4,@object                // @.str.4
.L.str.4:
	.asciz	"P3\n"
	.size	.L.str.4, 4

	.type	.L.str.5,@object                // @.str.5
.L.str.5:
	.asciz	"\n255\n"
	.size	.L.str.5, 6

	.type	.L.str.6,@object                // @.str.6
.L.str.6:
	.asciz	"\rScanlines remaining: "
	.size	.L.str.6, 23

	.type	.L.str.7,@object                // @.str.7
.L.str.7:
	.asciz	"\nDone.\n"
	.size	.L.str.7, 8

	.type	_ZTV9translate,@object          // @_ZTV9translate
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTV9translate
	.p2align	3
_ZTV9translate:
	.xword	0
	.xword	_ZTI9translate
	.xword	_ZNK9translate3hitERK3rayddR10hit_record
	.xword	_ZNK9translate12bounding_boxEddR4aabb
	.size	_ZTV9translate, 32

	.type	_ZTS9translate,@object          // @_ZTS9translate
	.section	.rodata,"a",@progbits
	.globl	_ZTS9translate
_ZTS9translate:
	.asciz	"9translate"
	.size	_ZTS9translate, 11

	.type	_ZTS8hittable,@object           // @_ZTS8hittable
	.section	.rodata._ZTS8hittable,"aG",@progbits,_ZTS8hittable,comdat
	.weak	_ZTS8hittable
_ZTS8hittable:
	.asciz	"8hittable"
	.size	_ZTS8hittable, 10

	.type	_ZTI8hittable,@object           // @_ZTI8hittable
	.section	.data.rel.ro._ZTI8hittable,"aGw",@progbits,_ZTI8hittable,comdat
	.weak	_ZTI8hittable
	.p2align	3
_ZTI8hittable:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTS8hittable
	.size	_ZTI8hittable, 16

	.type	_ZTI9translate,@object          // @_ZTI9translate
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI9translate
	.p2align	3
_ZTI9translate:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS9translate
	.xword	_ZTI8hittable
	.size	_ZTI9translate, 24

	.type	_ZTS8rotate_y,@object           // @_ZTS8rotate_y
	.section	.rodata,"a",@progbits
	.globl	_ZTS8rotate_y
_ZTS8rotate_y:
	.asciz	"8rotate_y"
	.size	_ZTS8rotate_y, 10

	.type	_ZTI8rotate_y,@object           // @_ZTI8rotate_y
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI8rotate_y
	.p2align	3
_ZTI8rotate_y:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS8rotate_y
	.xword	_ZTI8hittable
	.size	_ZTI8rotate_y, 24

	.type	_ZTV7xy_rect,@object            // @_ZTV7xy_rect
	.globl	_ZTV7xy_rect
	.p2align	3
_ZTV7xy_rect:
	.xword	0
	.xword	_ZTI7xy_rect
	.xword	_ZNK7xy_rect3hitERK3rayddR10hit_record
	.xword	_ZNK7xy_rect12bounding_boxEddR4aabb
	.size	_ZTV7xy_rect, 32

	.type	_ZTS7xy_rect,@object            // @_ZTS7xy_rect
	.section	.rodata,"a",@progbits
	.globl	_ZTS7xy_rect
_ZTS7xy_rect:
	.asciz	"7xy_rect"
	.size	_ZTS7xy_rect, 9

	.type	_ZTI7xy_rect,@object            // @_ZTI7xy_rect
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI7xy_rect
	.p2align	3
_ZTI7xy_rect:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS7xy_rect
	.xword	_ZTI8hittable
	.size	_ZTI7xy_rect, 24

	.type	_ZTV7xz_rect,@object            // @_ZTV7xz_rect
	.globl	_ZTV7xz_rect
	.p2align	3
_ZTV7xz_rect:
	.xword	0
	.xword	_ZTI7xz_rect
	.xword	_ZNK7xz_rect3hitERK3rayddR10hit_record
	.xword	_ZNK7xz_rect12bounding_boxEddR4aabb
	.size	_ZTV7xz_rect, 32

	.type	_ZTS7xz_rect,@object            // @_ZTS7xz_rect
	.section	.rodata,"a",@progbits
	.globl	_ZTS7xz_rect
_ZTS7xz_rect:
	.asciz	"7xz_rect"
	.size	_ZTS7xz_rect, 9

	.type	_ZTI7xz_rect,@object            // @_ZTI7xz_rect
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI7xz_rect
	.p2align	3
_ZTI7xz_rect:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS7xz_rect
	.xword	_ZTI8hittable
	.size	_ZTI7xz_rect, 24

	.type	_ZTV7yz_rect,@object            // @_ZTV7yz_rect
	.globl	_ZTV7yz_rect
	.p2align	3
_ZTV7yz_rect:
	.xword	0
	.xword	_ZTI7yz_rect
	.xword	_ZNK7yz_rect3hitERK3rayddR10hit_record
	.xword	_ZNK7yz_rect12bounding_boxEddR4aabb
	.size	_ZTV7yz_rect, 32

	.type	_ZTS7yz_rect,@object            // @_ZTS7yz_rect
	.section	.rodata,"a",@progbits
	.globl	_ZTS7yz_rect
_ZTS7yz_rect:
	.asciz	"7yz_rect"
	.size	_ZTS7yz_rect, 9

	.type	_ZTI7yz_rect,@object            // @_ZTI7yz_rect
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI7yz_rect
	.p2align	3
_ZTI7yz_rect:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS7yz_rect
	.xword	_ZTI8hittable
	.size	_ZTI7yz_rect, 24

	.type	_ZTV13hittable_list,@object     // @_ZTV13hittable_list
	.globl	_ZTV13hittable_list
	.p2align	3
_ZTV13hittable_list:
	.xword	0
	.xword	_ZTI13hittable_list
	.xword	_ZNK13hittable_list3hitERK3rayddR10hit_record
	.xword	_ZNK13hittable_list12bounding_boxEddR4aabb
	.size	_ZTV13hittable_list, 32

	.type	_ZTS13hittable_list,@object     // @_ZTS13hittable_list
	.section	.rodata,"a",@progbits
	.globl	_ZTS13hittable_list
_ZTS13hittable_list:
	.asciz	"13hittable_list"
	.size	_ZTS13hittable_list, 16

	.type	_ZTI13hittable_list,@object     // @_ZTI13hittable_list
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI13hittable_list
	.p2align	3
_ZTI13hittable_list:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS13hittable_list
	.xword	_ZTI8hittable
	.size	_ZTI13hittable_list, 24

	.type	_ZTS3box,@object                // @_ZTS3box
	.section	.rodata,"a",@progbits
	.globl	_ZTS3box
_ZTS3box:
	.asciz	"3box"
	.size	_ZTS3box, 5

	.type	_ZTI3box,@object                // @_ZTI3box
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI3box
	.p2align	3
_ZTI3box:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS3box
	.xword	_ZTI8hittable
	.size	_ZTI3box, 24

	.type	_ZTS8bvh_node,@object           // @_ZTS8bvh_node
	.section	.rodata,"a",@progbits
	.globl	_ZTS8bvh_node
_ZTS8bvh_node:
	.asciz	"8bvh_node"
	.size	_ZTS8bvh_node, 10

	.type	_ZTI8bvh_node,@object           // @_ZTI8bvh_node
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI8bvh_node
	.p2align	3
_ZTI8bvh_node:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS8bvh_node
	.xword	_ZTI8hittable
	.size	_ZTI8bvh_node, 24

	.type	_ZTV15constant_medium,@object   // @_ZTV15constant_medium
	.globl	_ZTV15constant_medium
	.p2align	3
_ZTV15constant_medium:
	.xword	0
	.xword	_ZTI15constant_medium
	.xword	_ZNK15constant_medium3hitERK3rayddR10hit_record
	.xword	_ZNK15constant_medium12bounding_boxEddR4aabb
	.size	_ZTV15constant_medium, 32

	.type	_ZTS15constant_medium,@object   // @_ZTS15constant_medium
	.section	.rodata,"a",@progbits
	.globl	_ZTS15constant_medium
_ZTS15constant_medium:
	.asciz	"15constant_medium"
	.size	_ZTS15constant_medium, 18

	.type	_ZTI15constant_medium,@object   // @_ZTI15constant_medium
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI15constant_medium
	.p2align	3
_ZTI15constant_medium:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS15constant_medium
	.xword	_ZTI8hittable
	.size	_ZTI15constant_medium, 24

	.type	_ZTV13moving_sphere,@object     // @_ZTV13moving_sphere
	.globl	_ZTV13moving_sphere
	.p2align	3
_ZTV13moving_sphere:
	.xword	0
	.xword	_ZTI13moving_sphere
	.xword	_ZNK13moving_sphere3hitERK3rayddR10hit_record
	.xword	_ZNK13moving_sphere12bounding_boxEddR4aabb
	.size	_ZTV13moving_sphere, 32

	.type	_ZTS13moving_sphere,@object     // @_ZTS13moving_sphere
	.section	.rodata,"a",@progbits
	.globl	_ZTS13moving_sphere
_ZTS13moving_sphere:
	.asciz	"13moving_sphere"
	.size	_ZTS13moving_sphere, 16

	.type	_ZTI13moving_sphere,@object     // @_ZTI13moving_sphere
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI13moving_sphere
	.p2align	3
_ZTI13moving_sphere:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS13moving_sphere
	.xword	_ZTI8hittable
	.size	_ZTI13moving_sphere, 24

	.type	_ZTV6sphere,@object             // @_ZTV6sphere
	.globl	_ZTV6sphere
	.p2align	3
_ZTV6sphere:
	.xword	0
	.xword	_ZTI6sphere
	.xword	_ZNK6sphere3hitERK3rayddR10hit_record
	.xword	_ZNK6sphere12bounding_boxEddR4aabb
	.size	_ZTV6sphere, 32

	.type	_ZTS6sphere,@object             // @_ZTS6sphere
	.section	.rodata,"a",@progbits
	.globl	_ZTS6sphere
_ZTS6sphere:
	.asciz	"6sphere"
	.size	_ZTS6sphere, 8

	.type	_ZTI6sphere,@object             // @_ZTI6sphere
	.section	.data.rel.ro,"aw",@progbits
	.globl	_ZTI6sphere
	.p2align	3
_ZTI6sphere:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS6sphere
	.xword	_ZTI8hittable
	.size	_ZTI6sphere, 24

	.type	.L.str.8,@object                // @.str.8
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.8:
	.asciz	"vector::_M_realloc_insert"
	.size	.L.str.8, 26

	.type	_ZL21stbi__stdio_callbacks,@object // @_ZL21stbi__stdio_callbacks
	.section	.data.rel.ro,"aw",@progbits
	.p2align	3
_ZL21stbi__stdio_callbacks:
	.xword	_ZL16stbi__stdio_readPvPci
	.xword	_ZL16stbi__stdio_skipPvi
	.xword	_ZL15stbi__stdio_eofPv
	.size	_ZL21stbi__stdio_callbacks, 24

	.type	.L.str.9,@object                // @.str.9
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.9:
	.asciz	"unknown image type"
	.size	.L.str.9, 19

	.type	.L.str.10,@object               // @.str.10
.L.str.10:
	.asciz	"no SOI"
	.size	.L.str.10, 7

	.type	.L.str.11,@object               // @.str.11
.L.str.11:
	.asciz	"no SOF"
	.size	.L.str.11, 7

	.type	.L.str.12,@object               // @.str.12
.L.str.12:
	.asciz	"expected marker"
	.size	.L.str.12, 16

	.type	.L.str.13,@object               // @.str.13
.L.str.13:
	.asciz	"bad DRI len"
	.size	.L.str.13, 12

	.type	.L.str.14,@object               // @.str.14
.L.str.14:
	.asciz	"bad DQT type"
	.size	.L.str.14, 13

	.type	.L.str.15,@object               // @.str.15
.L.str.15:
	.asciz	"bad DQT table"
	.size	.L.str.15, 14

	.type	_ZL19stbi__jpeg_dezigzag,@object // @_ZL19stbi__jpeg_dezigzag
	.section	.rodata,"a",@progbits
_ZL19stbi__jpeg_dezigzag:
	.ascii	"\000\001\b\020\t\002\003\n\021\030 \031\022\013\004\005\f\023\032!(0)\"\033\024\r\006\007\016\025\034#*1892+$\035\026\017\027\036%,3:;4-&\037'.5<=6/7>????????????????"
	.size	_ZL19stbi__jpeg_dezigzag, 79

	.type	.L.str.16,@object               // @.str.16
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.16:
	.asciz	"bad DHT header"
	.size	.L.str.16, 15

	.type	.L.str.17,@object               // @.str.17
.L.str.17:
	.asciz	"bad code lengths"
	.size	.L.str.17, 17

	.type	.L.str.18,@object               // @.str.18
.L.str.18:
	.asciz	"bad SOF len"
	.size	.L.str.18, 12

	.type	.L.str.19,@object               // @.str.19
.L.str.19:
	.asciz	"only 8-bit"
	.size	.L.str.19, 11

	.type	.L.str.20,@object               // @.str.20
.L.str.20:
	.asciz	"no header height"
	.size	.L.str.20, 17

	.type	.L.str.21,@object               // @.str.21
.L.str.21:
	.asciz	"0 width"
	.size	.L.str.21, 8

	.type	.L.str.22,@object               // @.str.22
.L.str.22:
	.asciz	"bad component count"
	.size	.L.str.22, 20

	.type	.L.str.23,@object               // @.str.23
.L.str.23:
	.asciz	"bad component ID"
	.size	.L.str.23, 17

	.type	.L.str.24,@object               // @.str.24
.L.str.24:
	.asciz	"bad H"
	.size	.L.str.24, 6

	.type	.L.str.25,@object               // @.str.25
.L.str.25:
	.asciz	"bad V"
	.size	.L.str.25, 6

	.type	.L.str.26,@object               // @.str.26
.L.str.26:
	.asciz	"bad TQ"
	.size	.L.str.26, 7

	.type	.L.str.27,@object               // @.str.27
.L.str.27:
	.asciz	"too large"
	.size	.L.str.27, 10

	.type	.L.str.28,@object               // @.str.28
.L.str.28:
	.asciz	"outofmem"
	.size	.L.str.28, 9

	.type	.L.str.29,@object               // @.str.29
.L.str.29:
	.asciz	"bad req_comp"
	.size	.L.str.29, 13

	.type	.L.str.30,@object               // @.str.30
.L.str.30:
	.asciz	"junk before marker"
	.size	.L.str.30, 19

	.type	.L.str.31,@object               // @.str.31
.L.str.31:
	.asciz	"bad SOS component count"
	.size	.L.str.31, 24

	.type	.L.str.32,@object               // @.str.32
.L.str.32:
	.asciz	"bad SOS len"
	.size	.L.str.32, 12

	.type	.L.str.33,@object               // @.str.33
.L.str.33:
	.asciz	"bad DC huff"
	.size	.L.str.33, 12

	.type	.L.str.34,@object               // @.str.34
.L.str.34:
	.asciz	"bad AC huff"
	.size	.L.str.34, 12

	.type	.L.str.35,@object               // @.str.35
.L.str.35:
	.asciz	"bad SOS"
	.size	.L.str.35, 8

	.type	.L.str.36,@object               // @.str.36
.L.str.36:
	.asciz	"bad huffman code"
	.size	.L.str.36, 17

	.type	_ZL11stbi__bmask,@object        // @_ZL11stbi__bmask
	.section	.rodata,"a",@progbits
	.p2align	2
_ZL11stbi__bmask:
	.word	0                               // 0x0
	.word	1                               // 0x1
	.word	3                               // 0x3
	.word	7                               // 0x7
	.word	15                              // 0xf
	.word	31                              // 0x1f
	.word	63                              // 0x3f
	.word	127                             // 0x7f
	.word	255                             // 0xff
	.word	511                             // 0x1ff
	.word	1023                            // 0x3ff
	.word	2047                            // 0x7ff
	.word	4095                            // 0xfff
	.word	8191                            // 0x1fff
	.word	16383                           // 0x3fff
	.word	32767                           // 0x7fff
	.word	65535                           // 0xffff
	.size	_ZL11stbi__bmask, 68

	.type	.L.str.37,@object               // @.str.37
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.37:
	.asciz	"(((j->code_buffer) >> (32 - h->size[c])) & stbi__bmask[h->size[c]]) == h->code[c]"
	.size	.L.str.37, 82

	.type	.L.str.38,@object               // @.str.38
.L.str.38:
	.asciz	"raytracing.github.io/src/common/external/stb_image.h"
	.size	.L.str.38, 53

	.type	.L__PRETTY_FUNCTION__._ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman,@object // @__PRETTY_FUNCTION__._ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman
.L__PRETTY_FUNCTION__._ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman:
	.asciz	"int stbi__jpeg_huff_decode(stbi__jpeg *, stbi__huffman *)"
	.size	.L__PRETTY_FUNCTION__._ZL22stbi__jpeg_huff_decodeP10stbi__jpegP13stbi__huffman, 58

	.type	.L.str.39,@object               // @.str.39
.L.str.39:
	.asciz	"n >= 0 && n < (int) (sizeof(stbi__bmask)/sizeof(*stbi__bmask))"
	.size	.L.str.39, 63

	.type	.L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi,@object // @__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi
.L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi:
	.asciz	"int stbi__extend_receive(stbi__jpeg *, int)"
	.size	.L__PRETTY_FUNCTION__._ZL20stbi__extend_receiveP10stbi__jpegi, 44

	.type	_ZL11stbi__jbias,@object        // @_ZL11stbi__jbias
	.section	.rodata,"a",@progbits
	.p2align	2
_ZL11stbi__jbias:
	.word	0                               // 0x0
	.word	4294967295                      // 0xffffffff
	.word	4294967293                      // 0xfffffffd
	.word	4294967289                      // 0xfffffff9
	.word	4294967281                      // 0xfffffff1
	.word	4294967265                      // 0xffffffe1
	.word	4294967233                      // 0xffffffc1
	.word	4294967169                      // 0xffffff81
	.word	4294967041                      // 0xffffff01
	.word	4294966785                      // 0xfffffe01
	.word	4294966273                      // 0xfffffc01
	.word	4294965249                      // 0xfffff801
	.word	4294963201                      // 0xfffff001
	.word	4294959105                      // 0xffffe001
	.word	4294950913                      // 0xffffc001
	.word	4294934529                      // 0xffff8001
	.size	_ZL11stbi__jbias, 64

	.type	.L.str.40,@object               // @.str.40
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.40:
	.asciz	"can't merge dc and ac"
	.size	.L.str.40, 22

	.type	.L.str.41,@object               // @.str.41
.L.str.41:
	.asciz	"bad png sig"
	.size	.L.str.41, 12

	.type	.L.str.42,@object               // @.str.42
.L.str.42:
	.asciz	"multiple IHDR"
	.size	.L.str.42, 14

	.type	.L.str.43,@object               // @.str.43
.L.str.43:
	.asciz	"bad IHDR len"
	.size	.L.str.43, 13

	.type	.L.str.44,@object               // @.str.44
.L.str.44:
	.asciz	"1/2/4/8-bit only"
	.size	.L.str.44, 17

	.type	.L.str.45,@object               // @.str.45
.L.str.45:
	.asciz	"bad ctype"
	.size	.L.str.45, 10

	.type	.L.str.46,@object               // @.str.46
.L.str.46:
	.asciz	"bad comp method"
	.size	.L.str.46, 16

	.type	.L.str.47,@object               // @.str.47
.L.str.47:
	.asciz	"bad filter method"
	.size	.L.str.47, 18

	.type	.L.str.48,@object               // @.str.48
.L.str.48:
	.asciz	"bad interlace method"
	.size	.L.str.48, 21

	.type	.L.str.49,@object               // @.str.49
.L.str.49:
	.asciz	"0-pixel image"
	.size	.L.str.49, 14

	.type	.L.str.50,@object               // @.str.50
.L.str.50:
	.asciz	"first not IHDR"
	.size	.L.str.50, 15

	.type	.L.str.51,@object               // @.str.51
.L.str.51:
	.asciz	"invalid PLTE"
	.size	.L.str.51, 13

	.type	.L.str.52,@object               // @.str.52
.L.str.52:
	.asciz	"tRNS after IDAT"
	.size	.L.str.52, 16

	.type	.L.str.53,@object               // @.str.53
.L.str.53:
	.asciz	"tRNS before PLTE"
	.size	.L.str.53, 17

	.type	.L.str.54,@object               // @.str.54
.L.str.54:
	.asciz	"bad tRNS len"
	.size	.L.str.54, 13

	.type	.L.str.55,@object               // @.str.55
.L.str.55:
	.asciz	"tRNS with alpha"
	.size	.L.str.55, 16

	.type	_ZL23stbi__depth_scale_table,@object // @_ZL23stbi__depth_scale_table
	.section	.rodata,"a",@progbits
_ZL23stbi__depth_scale_table:
	.ascii	"\000\377U\000\021\000\000\000\001"
	.size	_ZL23stbi__depth_scale_table, 9

	.type	.L.str.56,@object               // @.str.56
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.56:
	.asciz	"no PLTE"
	.size	.L.str.56, 8

	.type	.L.str.57,@object               // @.str.57
.L.str.57:
	.asciz	"outofdata"
	.size	.L.str.57, 10

	.type	.L.str.58,@object               // @.str.58
.L.str.58:
	.asciz	"no IDAT"
	.size	.L.str.58, 8

	.type	_ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk,@object // @_ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk
	.data
	.p2align	2
_ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk:
	.asciz	"XXXX PNG chunk not known"
	.size	_ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk, 25

	.type	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig,@object // @__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig
	.section	.rodata,"a",@progbits
	.p2align	2
.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig:
	.word	0                               // 0x0
	.word	4                               // 0x4
	.word	0                               // 0x0
	.word	2                               // 0x2
	.word	0                               // 0x0
	.word	1                               // 0x1
	.word	0                               // 0x0
	.size	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xorig, 28

	.type	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yorig,@object // @__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yorig
	.p2align	2
.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yorig:
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	4                               // 0x4
	.word	0                               // 0x0
	.word	2                               // 0x2
	.word	0                               // 0x0
	.word	1                               // 0x1
	.size	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yorig, 28

	.type	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc,@object // @__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc
	.p2align	2
.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc:
	.word	8                               // 0x8
	.word	8                               // 0x8
	.word	4                               // 0x4
	.word	4                               // 0x4
	.word	2                               // 0x2
	.word	2                               // 0x2
	.word	1                               // 0x1
	.size	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.xspc, 28

	.type	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yspc,@object // @__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yspc
	.p2align	2
.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yspc:
	.word	8                               // 0x8
	.word	8                               // 0x8
	.word	8                               // 0x8
	.word	4                               // 0x4
	.word	4                               // 0x4
	.word	2                               // 0x2
	.word	2                               // 0x2
	.size	.L__const._ZL22stbi__create_png_imageP9stbi__pngPhjiiii.yspc, 28

	.type	.L.str.59,@object               // @.str.59
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.59:
	.asciz	"out_n == s->img_n || out_n == s->img_n+1"
	.size	.L.str.59, 41

	.type	.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii,@object // @__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii
.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii:
	.asciz	"int stbi__create_png_image_raw(stbi__png *, stbi_uc *, stbi__uint32, int, stbi__uint32, stbi__uint32, int, int)"
	.size	.L__PRETTY_FUNCTION__._ZL26stbi__create_png_image_rawP9stbi__pngPhjijjii, 112

	.type	.L.str.60,@object               // @.str.60
.L.str.60:
	.asciz	"not enough pixels"
	.size	.L.str.60, 18

	.type	.L.str.61,@object               // @.str.61
.L.str.61:
	.asciz	"invalid filter"
	.size	.L.str.61, 15

	.type	.L.str.62,@object               // @.str.62
.L.str.62:
	.asciz	"img_width_bytes <= x"
	.size	.L.str.62, 21

	.type	_ZL16first_row_filter,@object   // @_ZL16first_row_filter
	.section	.rodata,"a",@progbits
_ZL16first_row_filter:
	.ascii	"\000\001\000\005\006"
	.size	_ZL16first_row_filter, 5

	.type	.L.str.63,@object               // @.str.63
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.63:
	.asciz	"img_n+1 == out_n"
	.size	.L.str.63, 17

	.type	.L.str.64,@object               // @.str.64
.L.str.64:
	.asciz	"img_n == 3"
	.size	.L.str.64, 11

	.type	.L.str.65,@object               // @.str.65
.L.str.65:
	.asciz	"out_n == 2 || out_n == 4"
	.size	.L.str.65, 25

	.type	.L__PRETTY_FUNCTION__._ZL26stbi__compute_transparencyP9stbi__pngPhi,@object // @__PRETTY_FUNCTION__._ZL26stbi__compute_transparencyP9stbi__pngPhi
.L__PRETTY_FUNCTION__._ZL26stbi__compute_transparencyP9stbi__pngPhi:
	.asciz	"int stbi__compute_transparency(stbi__png *, stbi_uc *, int)"
	.size	.L__PRETTY_FUNCTION__._ZL26stbi__compute_transparencyP9stbi__pngPhi, 60

	.type	.L.str.66,@object               // @.str.66
.L.str.66:
	.asciz	"s->img_out_n == 4"
	.size	.L.str.66, 18

	.type	.L__PRETTY_FUNCTION__._ZL15stbi__de_iphoneP9stbi__png,@object // @__PRETTY_FUNCTION__._ZL15stbi__de_iphoneP9stbi__png
.L__PRETTY_FUNCTION__._ZL15stbi__de_iphoneP9stbi__png:
	.asciz	"void stbi__de_iphone(stbi__png *)"
	.size	.L__PRETTY_FUNCTION__._ZL15stbi__de_iphoneP9stbi__png, 34

	.type	.L.str.67,@object               // @.str.67
.L.str.67:
	.asciz	"req_comp >= 1 && req_comp <= 4"
	.size	.L.str.67, 31

	.type	.L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj,@object // @__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj
.L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj:
	.asciz	"unsigned char *stbi__convert_format(unsigned char *, int, int, unsigned int, unsigned int)"
	.size	.L__PRETTY_FUNCTION__._ZL20stbi__convert_formatPhiijj, 91

	.type	.L.str.68,@object               // @.str.68
.L.str.68:
	.asciz	"0"
	.size	.L.str.68, 2

	.type	.L.str.69,@object               // @.str.69
.L.str.69:
	.asciz	"not BMP"
	.size	.L.str.69, 8

	.type	.L.str.70,@object               // @.str.70
.L.str.70:
	.asciz	"unknown BMP"
	.size	.L.str.70, 12

	.type	.L.str.71,@object               // @.str.71
.L.str.71:
	.asciz	"bad BMP"
	.size	.L.str.71, 8

	.type	.L.str.72,@object               // @.str.72
.L.str.72:
	.asciz	"monochrome"
	.size	.L.str.72, 11

	.type	.L.str.73,@object               // @.str.73
.L.str.73:
	.asciz	"BMP RLE"
	.size	.L.str.73, 8

	.type	.L.str.74,@object               // @.str.74
.L.str.74:
	.asciz	"hsz == 108 || hsz == 124"
	.size	.L.str.74, 25

	.type	.L__PRETTY_FUNCTION__._ZL14stbi__bmp_loadP13stbi__contextPiS1_S1_i,@object // @__PRETTY_FUNCTION__._ZL14stbi__bmp_loadP13stbi__contextPiS1_S1_i
.L__PRETTY_FUNCTION__._ZL14stbi__bmp_loadP13stbi__contextPiS1_S1_i:
	.asciz	"stbi_uc *stbi__bmp_load(stbi__context *, int *, int *, int *, int)"
	.size	.L__PRETTY_FUNCTION__._ZL14stbi__bmp_loadP13stbi__contextPiS1_S1_i, 67

	.type	.L.str.75,@object               // @.str.75
.L.str.75:
	.asciz	"invalid"
	.size	.L.str.75, 8

	.type	.L.str.76,@object               // @.str.76
.L.str.76:
	.asciz	"bad bpp"
	.size	.L.str.76, 8

	.type	.L.str.77,@object               // @.str.77
.L.str.77:
	.asciz	"bad masks"
	.size	.L.str.77, 10

	.type	.L.str.78,@object               // @.str.78
.L.str.78:
	.asciz	"bad Image Descriptor"
	.size	.L.str.78, 21

	.type	.L.str.79,@object               // @.str.79
.L.str.79:
	.asciz	"missing color table"
	.size	.L.str.79, 20

	.type	.L.str.80,@object               // @.str.80
.L.str.80:
	.asciz	"unknown code"
	.size	.L.str.80, 13

	.type	.L.str.81,@object               // @.str.81
.L.str.81:
	.asciz	"not GIF"
	.size	.L.str.81, 8

	.type	.L.str.82,@object               // @.str.82
.L.str.82:
	.zero	1
	.size	.L.str.82, 1

	.type	.L.str.83,@object               // @.str.83
.L.str.83:
	.asciz	"no clear code"
	.size	.L.str.83, 14

	.type	.L.str.84,@object               // @.str.84
.L.str.84:
	.asciz	"too many codes"
	.size	.L.str.84, 15

	.type	.L.str.85,@object               // @.str.85
.L.str.85:
	.asciz	"illegal code in raster"
	.size	.L.str.85, 23

	.type	.L.str.86,@object               // @.str.86
.L.str.86:
	.asciz	"not PSD"
	.size	.L.str.86, 8

	.type	.L.str.87,@object               // @.str.87
.L.str.87:
	.asciz	"wrong version"
	.size	.L.str.87, 14

	.type	.L.str.88,@object               // @.str.88
.L.str.88:
	.asciz	"wrong channel count"
	.size	.L.str.88, 20

	.type	.L.str.89,@object               // @.str.89
.L.str.89:
	.asciz	"unsupported bit depth"
	.size	.L.str.89, 22

	.type	.L.str.90,@object               // @.str.90
.L.str.90:
	.asciz	"wrong color format"
	.size	.L.str.90, 19

	.type	.L.str.91,@object               // @.str.91
.L.str.91:
	.asciz	"bad compression"
	.size	.L.str.91, 16

	.type	.L.str.92,@object               // @.str.92
.L.str.92:
	.asciz	"S\200\3664"
	.size	.L.str.92, 5

	.type	.L.str.93,@object               // @.str.93
.L.str.93:
	.asciz	"PICT"
	.size	.L.str.93, 5

	.type	.L.str.94,@object               // @.str.94
.L.str.94:
	.asciz	"bad file"
	.size	.L.str.94, 9

	.type	.L.str.95,@object               // @.str.95
.L.str.95:
	.asciz	"bad format"
	.size	.L.str.95, 11

	.type	.L.str.96,@object               // @.str.96
.L.str.96:
	.asciz	"max value > 255"
	.size	.L.str.96, 16

	.type	.L.str.97,@object               // @.str.97
.L.str.97:
	.asciz	"#?RADIANCE"
	.size	.L.str.97, 11

	.type	.L.str.98,@object               // @.str.98
.L.str.98:
	.asciz	"not HDR"
	.size	.L.str.98, 8

	.type	.L.str.99,@object               // @.str.99
.L.str.99:
	.asciz	"FORMAT=32-bit_rle_rgbe"
	.size	.L.str.99, 23

	.type	.L.str.100,@object              // @.str.100
.L.str.100:
	.asciz	"unsupported format"
	.size	.L.str.100, 19

	.type	.L.str.101,@object              // @.str.101
.L.str.101:
	.asciz	"-Y "
	.size	.L.str.101, 4

	.type	.L.str.102,@object              // @.str.102
.L.str.102:
	.asciz	"unsupported data layout"
	.size	.L.str.102, 24

	.type	.L.str.103,@object              // @.str.103
.L.str.103:
	.asciz	"+X "
	.size	.L.str.103, 4

	.type	.L.str.104,@object              // @.str.104
.L.str.104:
	.asciz	"invalid decoded scanline length"
	.size	.L.str.104, 32

	.type	.L.str.105,@object              // @.str.105
.L.str.105:
	.asciz	"bad palette"
	.size	.L.str.105, 12

	.type	.L.str.106,@object              // @.str.106
.L.str.106:
	.asciz	"bad zlib header"
	.size	.L.str.106, 16

	.type	.L.str.107,@object              // @.str.107
.L.str.107:
	.asciz	"no preset dict"
	.size	.L.str.107, 15

	.type	.L.str.108,@object              // @.str.108
.L.str.108:
	.asciz	"z->code_buffer < (1U << z->num_bits)"
	.size	.L.str.108, 37

	.type	.L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf,@object // @__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf
.L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf:
	.asciz	"void stbi__fill_bits(stbi__zbuf *)"
	.size	.L__PRETTY_FUNCTION__._ZL15stbi__fill_bitsP10stbi__zbuf, 35

	.type	.L.str.109,@object              // @.str.109
.L.str.109:
	.asciz	"a->num_bits == 0"
	.size	.L.str.109, 17

	.type	.L__PRETTY_FUNCTION__._ZL30stbi__parse_uncomperssed_blockP10stbi__zbuf,@object // @__PRETTY_FUNCTION__._ZL30stbi__parse_uncomperssed_blockP10stbi__zbuf
.L__PRETTY_FUNCTION__._ZL30stbi__parse_uncomperssed_blockP10stbi__zbuf:
	.asciz	"int stbi__parse_uncomperssed_block(stbi__zbuf *)"
	.size	.L__PRETTY_FUNCTION__._ZL30stbi__parse_uncomperssed_blockP10stbi__zbuf, 49

	.type	.L.str.110,@object              // @.str.110
.L.str.110:
	.asciz	"zlib corrupt"
	.size	.L.str.110, 13

	.type	.L.str.111,@object              // @.str.111
.L.str.111:
	.asciz	"read past buffer"
	.size	.L.str.111, 17

	.type	.L.str.112,@object              // @.str.112
.L.str.112:
	.asciz	"output buffer limit"
	.size	.L.str.112, 20

	.type	.L.str.113,@object              // @.str.113
.L.str.113:
	.asciz	"bad sizes"
	.size	.L.str.113, 10

	.type	.L.str.114,@object              // @.str.114
.L.str.114:
	.asciz	"bad codelengths"
	.size	.L.str.114, 16

	.type	_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag,@object // @_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag
	.section	.rodata,"a",@progbits
_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag:
	.ascii	"\020\021\022\000\b\007\t\006\n\005\013\004\f\003\r\002\016\001\017"
	.size	_ZZL27stbi__compute_huffman_codesP10stbi__zbufE15length_dezigzag, 19

	.type	.L.str.117,@object              // @.str.117
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.117:
	.asciz	"z->size[b] == s"
	.size	.L.str.117, 16

	.type	.L__PRETTY_FUNCTION__._ZL30stbi__zhuffman_decode_slowpathP10stbi__zbufP14stbi__zhuffman,@object // @__PRETTY_FUNCTION__._ZL30stbi__zhuffman_decode_slowpathP10stbi__zbufP14stbi__zhuffman
.L__PRETTY_FUNCTION__._ZL30stbi__zhuffman_decode_slowpathP10stbi__zbufP14stbi__zhuffman:
	.asciz	"int stbi__zhuffman_decode_slowpath(stbi__zbuf *, stbi__zhuffman *)"
	.size	.L__PRETTY_FUNCTION__._ZL30stbi__zhuffman_decode_slowpathP10stbi__zbufP14stbi__zhuffman, 67

	.type	_ZL18stbi__zlength_base,@object // @_ZL18stbi__zlength_base
	.section	.rodata,"a",@progbits
	.p2align	2
_ZL18stbi__zlength_base:
	.word	3                               // 0x3
	.word	4                               // 0x4
	.word	5                               // 0x5
	.word	6                               // 0x6
	.word	7                               // 0x7
	.word	8                               // 0x8
	.word	9                               // 0x9
	.word	10                              // 0xa
	.word	11                              // 0xb
	.word	13                              // 0xd
	.word	15                              // 0xf
	.word	17                              // 0x11
	.word	19                              // 0x13
	.word	23                              // 0x17
	.word	27                              // 0x1b
	.word	31                              // 0x1f
	.word	35                              // 0x23
	.word	43                              // 0x2b
	.word	51                              // 0x33
	.word	59                              // 0x3b
	.word	67                              // 0x43
	.word	83                              // 0x53
	.word	99                              // 0x63
	.word	115                             // 0x73
	.word	131                             // 0x83
	.word	163                             // 0xa3
	.word	195                             // 0xc3
	.word	227                             // 0xe3
	.word	258                             // 0x102
	.word	0                               // 0x0
	.word	0                               // 0x0
	.size	_ZL18stbi__zlength_base, 124

	.type	_ZL19stbi__zlength_extra,@object // @_ZL19stbi__zlength_extra
	.p2align	2
_ZL19stbi__zlength_extra:
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	1                               // 0x1
	.word	1                               // 0x1
	.word	1                               // 0x1
	.word	1                               // 0x1
	.word	2                               // 0x2
	.word	2                               // 0x2
	.word	2                               // 0x2
	.word	2                               // 0x2
	.word	3                               // 0x3
	.word	3                               // 0x3
	.word	3                               // 0x3
	.word	3                               // 0x3
	.word	4                               // 0x4
	.word	4                               // 0x4
	.word	4                               // 0x4
	.word	4                               // 0x4
	.word	5                               // 0x5
	.word	5                               // 0x5
	.word	5                               // 0x5
	.word	5                               // 0x5
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.size	_ZL19stbi__zlength_extra, 124

	.type	_ZL16stbi__zdist_base,@object   // @_ZL16stbi__zdist_base
	.p2align	2
_ZL16stbi__zdist_base:
	.word	1                               // 0x1
	.word	2                               // 0x2
	.word	3                               // 0x3
	.word	4                               // 0x4
	.word	5                               // 0x5
	.word	7                               // 0x7
	.word	9                               // 0x9
	.word	13                              // 0xd
	.word	17                              // 0x11
	.word	25                              // 0x19
	.word	33                              // 0x21
	.word	49                              // 0x31
	.word	65                              // 0x41
	.word	97                              // 0x61
	.word	129                             // 0x81
	.word	193                             // 0xc1
	.word	257                             // 0x101
	.word	385                             // 0x181
	.word	513                             // 0x201
	.word	769                             // 0x301
	.word	1025                            // 0x401
	.word	1537                            // 0x601
	.word	2049                            // 0x801
	.word	3073                            // 0xc01
	.word	4097                            // 0x1001
	.word	6145                            // 0x1801
	.word	8193                            // 0x2001
	.word	12289                           // 0x3001
	.word	16385                           // 0x4001
	.word	24577                           // 0x6001
	.word	0                               // 0x0
	.word	0                               // 0x0
	.size	_ZL16stbi__zdist_base, 128

	.type	_ZL17stbi__zdist_extra,@object  // @_ZL17stbi__zdist_extra
	.p2align	2
_ZL17stbi__zdist_extra:
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	0                               // 0x0
	.word	1                               // 0x1
	.word	1                               // 0x1
	.word	2                               // 0x2
	.word	2                               // 0x2
	.word	3                               // 0x3
	.word	3                               // 0x3
	.word	4                               // 0x4
	.word	4                               // 0x4
	.word	5                               // 0x5
	.word	5                               // 0x5
	.word	6                               // 0x6
	.word	6                               // 0x6
	.word	7                               // 0x7
	.word	7                               // 0x7
	.word	8                               // 0x8
	.word	8                               // 0x8
	.word	9                               // 0x9
	.word	9                               // 0x9
	.word	10                              // 0xa
	.word	10                              // 0xa
	.word	11                              // 0xb
	.word	11                              // 0xb
	.word	12                              // 0xc
	.word	12                              // 0xc
	.word	13                              // 0xd
	.word	13                              // 0xd
	.word	0                               // 0x0
	.word	0                               // 0x0
	.size	_ZL17stbi__zdist_extra, 128

	.type	.L.str.118,@object              // @.str.118
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.118:
	.asciz	"bad dist"
	.size	.L.str.118, 9

	.type	.L.str.119,@object              // @.str.119
.L.str.119:
	.asciz	"#?RADIANCE\n"
	.size	.L.str.119, 12

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 74

	.type	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE, 52

	.type	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE, 47

	.type	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE, 16

	.type	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTSSt19_Sp_make_shared_tag,@object // @_ZTSSt19_Sp_make_shared_tag
	.section	.rodata._ZTSSt19_Sp_make_shared_tag,"aG",@progbits,_ZTSSt19_Sp_make_shared_tag,comdat
	.weak	_ZTSSt19_Sp_make_shared_tag
_ZTSSt19_Sp_make_shared_tag:
	.asciz	"St19_Sp_make_shared_tag"
	.size	_ZTSSt19_Sp_make_shared_tag, 24

	.type	_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag,@object // @_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	.section	.rodata._ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag,"aG",@progbits,_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag,comdat
	.weak	_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	.p2align	3
_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag:
	.zero	16
	.size	_ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag, 16

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 74

	.type	_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 74

	.type	_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 75

	.type	_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 83

	.type	_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV15checker_texture,@object   // @_ZTV15checker_texture
	.section	.data.rel.ro._ZTV15checker_texture,"aGw",@progbits,_ZTV15checker_texture,comdat
	.weak	_ZTV15checker_texture
	.p2align	3
_ZTV15checker_texture:
	.xword	0
	.xword	_ZTI15checker_texture
	.xword	_ZNK15checker_texture5valueEddRK4vec3
	.size	_ZTV15checker_texture, 24

	.type	_ZTS15checker_texture,@object   // @_ZTS15checker_texture
	.section	.rodata._ZTS15checker_texture,"aG",@progbits,_ZTS15checker_texture,comdat
	.weak	_ZTS15checker_texture
_ZTS15checker_texture:
	.asciz	"15checker_texture"
	.size	_ZTS15checker_texture, 18

	.type	_ZTS7texture,@object            // @_ZTS7texture
	.section	.rodata._ZTS7texture,"aG",@progbits,_ZTS7texture,comdat
	.weak	_ZTS7texture
_ZTS7texture:
	.asciz	"7texture"
	.size	_ZTS7texture, 9

	.type	_ZTI7texture,@object            // @_ZTI7texture
	.section	.data.rel.ro._ZTI7texture,"aGw",@progbits,_ZTI7texture,comdat
	.weak	_ZTI7texture
	.p2align	3
_ZTI7texture:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTS7texture
	.size	_ZTI7texture, 16

	.type	_ZTI15checker_texture,@object   // @_ZTI15checker_texture
	.section	.data.rel.ro._ZTI15checker_texture,"aGw",@progbits,_ZTI15checker_texture,comdat
	.weak	_ZTI15checker_texture
	.p2align	3
_ZTI15checker_texture:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS15checker_texture
	.xword	_ZTI7texture
	.size	_ZTI15checker_texture, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 79

	.type	_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV11solid_color,@object       // @_ZTV11solid_color
	.section	.data.rel.ro._ZTV11solid_color,"aGw",@progbits,_ZTV11solid_color,comdat
	.weak	_ZTV11solid_color
	.p2align	3
_ZTV11solid_color:
	.xword	0
	.xword	_ZTI11solid_color
	.xword	_ZNK11solid_color5valueEddRK4vec3
	.size	_ZTV11solid_color, 24

	.type	_ZTS11solid_color,@object       // @_ZTS11solid_color
	.section	.rodata._ZTS11solid_color,"aG",@progbits,_ZTS11solid_color,comdat
	.weak	_ZTS11solid_color
_ZTS11solid_color:
	.asciz	"11solid_color"
	.size	_ZTS11solid_color, 14

	.type	_ZTI11solid_color,@object       // @_ZTI11solid_color
	.section	.data.rel.ro._ZTI11solid_color,"aGw",@progbits,_ZTI11solid_color,comdat
	.weak	_ZTI11solid_color
	.p2align	3
_ZTI11solid_color:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS11solid_color
	.xword	_ZTI7texture
	.size	_ZTI11solid_color, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 78

	.type	_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV10lambertian,@object        // @_ZTV10lambertian
	.section	.data.rel.ro._ZTV10lambertian,"aGw",@progbits,_ZTV10lambertian,comdat
	.weak	_ZTV10lambertian
	.p2align	3
_ZTV10lambertian:
	.xword	0
	.xword	_ZTI10lambertian
	.xword	_ZNK8material7emittedEddRK4vec3
	.xword	_ZNK10lambertian7scatterERK3rayRK10hit_recordR4vec3RS0_
	.size	_ZTV10lambertian, 32

	.type	_ZTS10lambertian,@object        // @_ZTS10lambertian
	.section	.rodata._ZTS10lambertian,"aG",@progbits,_ZTS10lambertian,comdat
	.weak	_ZTS10lambertian
_ZTS10lambertian:
	.asciz	"10lambertian"
	.size	_ZTS10lambertian, 13

	.type	_ZTS8material,@object           // @_ZTS8material
	.section	.rodata._ZTS8material,"aG",@progbits,_ZTS8material,comdat
	.weak	_ZTS8material
_ZTS8material:
	.asciz	"8material"
	.size	_ZTS8material, 10

	.type	_ZTI8material,@object           // @_ZTI8material
	.section	.data.rel.ro._ZTI8material,"aGw",@progbits,_ZTI8material,comdat
	.weak	_ZTI8material
	.p2align	3
_ZTI8material:
	.xword	_ZTVN10__cxxabiv117__class_type_infoE+16
	.xword	_ZTS8material
	.size	_ZTI8material, 16

	.type	_ZTI10lambertian,@object        // @_ZTI10lambertian
	.section	.data.rel.ro._ZTI10lambertian,"aGw",@progbits,_ZTI10lambertian,comdat
	.weak	_ZTI10lambertian
	.p2align	3
_ZTI10lambertian:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS10lambertian
	.xword	_ZTI8material
	.size	_ZTI10lambertian, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 73

	.type	_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 81

	.type	_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 72

	.type	_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV5metal,@object              // @_ZTV5metal
	.section	.data.rel.ro._ZTV5metal,"aGw",@progbits,_ZTV5metal,comdat
	.weak	_ZTV5metal
	.p2align	3
_ZTV5metal:
	.xword	0
	.xword	_ZTI5metal
	.xword	_ZNK8material7emittedEddRK4vec3
	.xword	_ZNK5metal7scatterERK3rayRK10hit_recordR4vec3RS0_
	.size	_ZTV5metal, 32

	.type	_ZTS5metal,@object              // @_ZTS5metal
	.section	.rodata._ZTS5metal,"aG",@progbits,_ZTS5metal,comdat
	.weak	_ZTS5metal
_ZTS5metal:
	.asciz	"5metal"
	.size	_ZTS5metal, 7

	.type	_ZTI5metal,@object              // @_ZTI5metal
	.section	.data.rel.ro._ZTI5metal,"aGw",@progbits,_ZTI5metal,comdat
	.weak	_ZTI5metal
	.p2align	3
_ZTI5metal:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS5metal
	.xword	_ZTI8material
	.size	_ZTI5metal, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 78

	.type	_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV10dielectric,@object        // @_ZTV10dielectric
	.section	.data.rel.ro._ZTV10dielectric,"aGw",@progbits,_ZTV10dielectric,comdat
	.weak	_ZTV10dielectric
	.p2align	3
_ZTV10dielectric:
	.xword	0
	.xword	_ZTI10dielectric
	.xword	_ZNK8material7emittedEddRK4vec3
	.xword	_ZNK10dielectric7scatterERK3rayRK10hit_recordR4vec3RS0_
	.size	_ZTV10dielectric, 32

	.type	_ZTS10dielectric,@object        // @_ZTS10dielectric
	.section	.rodata._ZTS10dielectric,"aG",@progbits,_ZTS10dielectric,comdat
	.weak	_ZTS10dielectric
_ZTS10dielectric:
	.asciz	"10dielectric"
	.size	_ZTS10dielectric, 13

	.type	_ZTI10dielectric,@object        // @_ZTI10dielectric
	.section	.data.rel.ro._ZTI10dielectric,"aGw",@progbits,_ZTI10dielectric,comdat
	.weak	_ZTI10dielectric
	.p2align	3
_ZTI10dielectric:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS10dielectric
	.xword	_ZTI8material
	.size	_ZTI10dielectric, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 81

	.type	_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV13noise_texture,@object     // @_ZTV13noise_texture
	.section	.data.rel.ro._ZTV13noise_texture,"aGw",@progbits,_ZTV13noise_texture,comdat
	.weak	_ZTV13noise_texture
	.p2align	3
_ZTV13noise_texture:
	.xword	0
	.xword	_ZTI13noise_texture
	.xword	_ZNK13noise_texture5valueEddRK4vec3
	.size	_ZTV13noise_texture, 24

	.type	_ZTS13noise_texture,@object     // @_ZTS13noise_texture
	.section	.rodata._ZTS13noise_texture,"aG",@progbits,_ZTS13noise_texture,comdat
	.weak	_ZTS13noise_texture
_ZTS13noise_texture:
	.asciz	"13noise_texture"
	.size	_ZTS13noise_texture, 16

	.type	_ZTI13noise_texture,@object     // @_ZTI13noise_texture
	.section	.data.rel.ro._ZTI13noise_texture,"aGw",@progbits,_ZTI13noise_texture,comdat
	.weak	_ZTI13noise_texture
	.p2align	3
_ZTI13noise_texture:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS13noise_texture
	.xword	_ZTI7texture
	.size	_ZTI13noise_texture, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 81

	.type	_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV13image_texture,@object     // @_ZTV13image_texture
	.section	.data.rel.ro._ZTV13image_texture,"aGw",@progbits,_ZTV13image_texture,comdat
	.weak	_ZTV13image_texture
	.p2align	3
_ZTV13image_texture:
	.xword	0
	.xword	_ZTI13image_texture
	.xword	_ZNK13image_texture5valueEddRK4vec3
	.size	_ZTV13image_texture, 24

	.type	.L.str.120,@object              // @.str.120
	.section	.rodata.str1.1,"aMS",@progbits,1
.L.str.120:
	.asciz	"ERROR: Could not load texture image file '"
	.size	.L.str.120, 43

	.type	.L.str.121,@object              // @.str.121
.L.str.121:
	.asciz	"'.\n"
	.size	.L.str.121, 4

	.type	_ZTS13image_texture,@object     // @_ZTS13image_texture
	.section	.rodata._ZTS13image_texture,"aG",@progbits,_ZTS13image_texture,comdat
	.weak	_ZTS13image_texture
_ZTS13image_texture:
	.asciz	"13image_texture"
	.size	_ZTS13image_texture, 16

	.type	_ZTI13image_texture,@object     // @_ZTI13image_texture
	.section	.data.rel.ro._ZTI13image_texture,"aGw",@progbits,_ZTI13image_texture,comdat
	.weak	_ZTI13image_texture
	.p2align	3
_ZTI13image_texture:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS13image_texture
	.xword	_ZTI7texture
	.size	_ZTI13image_texture, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 81

	.type	_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV13diffuse_light,@object     // @_ZTV13diffuse_light
	.section	.data.rel.ro._ZTV13diffuse_light,"aGw",@progbits,_ZTV13diffuse_light,comdat
	.weak	_ZTV13diffuse_light
	.p2align	3
_ZTV13diffuse_light:
	.xword	0
	.xword	_ZTI13diffuse_light
	.xword	_ZNK13diffuse_light7emittedEddRK4vec3
	.xword	_ZNK13diffuse_light7scatterERK3rayRK10hit_recordR4vec3RS0_
	.size	_ZTV13diffuse_light, 32

	.type	_ZTS13diffuse_light,@object     // @_ZTS13diffuse_light
	.section	.rodata._ZTS13diffuse_light,"aG",@progbits,_ZTS13diffuse_light,comdat
	.weak	_ZTS13diffuse_light
_ZTS13diffuse_light:
	.asciz	"13diffuse_light"
	.size	_ZTS13diffuse_light, 16

	.type	_ZTI13diffuse_light,@object     // @_ZTI13diffuse_light
	.section	.data.rel.ro._ZTI13diffuse_light,"aGw",@progbits,_ZTI13diffuse_light,comdat
	.weak	_ZTI13diffuse_light
	.p2align	3
_ZTI13diffuse_light:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS13diffuse_light
	.xword	_ZTI8material
	.size	_ZTI13diffuse_light, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 70

	.type	_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 75

	.type	_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 76

	.type	_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 83

	.type	_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	0
	.xword	_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED2Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EED0Ev
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE10_M_destroyEv
	.xword	_ZNSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE14_M_get_deleterERKSt9type_info
	.size	_ZTVSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 56

	.type	_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.rodata._ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aG",@progbits,_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.asciz	"St23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE"
	.size	_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 76

	.type	_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,@object // @_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.section	.data.rel.ro._ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,"aGw",@progbits,_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE,comdat
	.weak	_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.p2align	3
_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.xword	_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.size	_ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE, 24

	.type	_ZTV9isotropic,@object          // @_ZTV9isotropic
	.section	.data.rel.ro._ZTV9isotropic,"aGw",@progbits,_ZTV9isotropic,comdat
	.weak	_ZTV9isotropic
	.p2align	3
_ZTV9isotropic:
	.xword	0
	.xword	_ZTI9isotropic
	.xword	_ZNK8material7emittedEddRK4vec3
	.xword	_ZNK9isotropic7scatterERK3rayRK10hit_recordR4vec3RS0_
	.size	_ZTV9isotropic, 32

	.type	_ZTS9isotropic,@object          // @_ZTS9isotropic
	.section	.rodata._ZTS9isotropic,"aG",@progbits,_ZTS9isotropic,comdat
	.weak	_ZTS9isotropic
_ZTS9isotropic:
	.asciz	"9isotropic"
	.size	_ZTS9isotropic, 11

	.type	_ZTI9isotropic,@object          // @_ZTI9isotropic
	.section	.data.rel.ro._ZTI9isotropic,"aGw",@progbits,_ZTI9isotropic,comdat
	.weak	_ZTI9isotropic
	.p2align	3
_ZTI9isotropic:
	.xword	_ZTVN10__cxxabiv120__si_class_type_infoE+16
	.xword	_ZTS9isotropic
	.xword	_ZTI8material
	.size	_ZTI9isotropic, 24

	.section	.init_array,"aw",@init_array
	.p2align	3
	.xword	_GLOBAL__sub_I_main.cc
	.type	.L_MergedGlobals,@object        // @_MergedGlobals
	.data
	.p2align	2
.L_MergedGlobals:
	.word	0x400ccccd                      // float 2.20000005
	.word	0x3f800000                      // float 1
	.word	0x3ee8ba2e                      // float 0.454545438
	.word	0x3f800000                      // float 1
	.size	.L_MergedGlobals, 16

	.type	.L_MergedGlobals.126,@object    // @_MergedGlobals.126
	.local	.L_MergedGlobals.126
	.comm	.L_MergedGlobals.126,336,8
	.hidden	DW.ref.__gxx_personality_v0
	.weak	DW.ref.__gxx_personality_v0
	.section	.data.DW.ref.__gxx_personality_v0,"aGw",@progbits,DW.ref.__gxx_personality_v0,comdat
	.p2align	3
	.type	DW.ref.__gxx_personality_v0,@object
	.size	DW.ref.__gxx_personality_v0, 8
DW.ref.__gxx_personality_v0:
	.xword	__gxx_personality_v0
	.globl	_ZN8rotate_yC1ESt10shared_ptrI8hittableEd
	.type	_ZN8rotate_yC1ESt10shared_ptrI8hittableEd,@function
.set _ZN8rotate_yC1ESt10shared_ptrI8hittableEd, _ZN8rotate_yC2ESt10shared_ptrI8hittableEd
	.globl	_ZN3boxC1ERK4vec3S2_St10shared_ptrI8materialE
	.type	_ZN3boxC1ERK4vec3S2_St10shared_ptrI8materialE,@function
.set _ZN3boxC1ERK4vec3S2_St10shared_ptrI8materialE, _ZN3boxC2ERK4vec3S2_St10shared_ptrI8materialE
	.globl	_ZN8bvh_nodeC1ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
	.type	_ZN8bvh_nodeC1ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd,@function
.set _ZN8bvh_nodeC1ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd, _ZN8bvh_nodeC2ERKSt6vectorISt10shared_ptrI8hittableESaIS3_EEmmdd
.set _ZL15stbi__l2h_gamma, .L_MergedGlobals
	.size	_ZL15stbi__l2h_gamma, 4
.set _ZL15stbi__l2h_scale, .L_MergedGlobals+4
	.size	_ZL15stbi__l2h_scale, 4
.set _ZL17stbi__h2l_gamma_i, .L_MergedGlobals+8
	.size	_ZL17stbi__h2l_gamma_i, 4
.set _ZL17stbi__h2l_scale_i, .L_MergedGlobals+12
	.size	_ZL17stbi__h2l_scale_i, 4
.set _ZL29stbi__vertically_flip_on_load, .L_MergedGlobals.126
	.size	_ZL29stbi__vertically_flip_on_load, 4
.set _ZL20stbi__de_iphone_flag, .L_MergedGlobals.126+4
	.size	_ZL20stbi__de_iphone_flag, 4
.set _ZL22stbi__g_failure_reason, .L_MergedGlobals.126+8
	.size	_ZL22stbi__g_failure_reason, 8
.set _ZL23stbi__zdefault_distance, .L_MergedGlobals.126+16
	.size	_ZL23stbi__zdefault_distance, 32
.set _ZL21stbi__zdefault_length, .L_MergedGlobals.126+48
	.size	_ZL21stbi__zdefault_length, 288
	.ident	"Ubuntu clang version 14.0.0-1ubuntu1.1"
	.section	".note.GNU-stack","",@progbits
	.addrsig
	.addrsig_sym __gxx_personality_v0
	.addrsig_sym _Z13box_x_compareSt10shared_ptrI8hittableES1_
	.addrsig_sym _Z13box_y_compareSt10shared_ptrI8hittableES1_
	.addrsig_sym _Z13box_z_compareSt10shared_ptrI8hittableES1_
	.addrsig_sym _ZL16stbi__stdio_readPvPci
	.addrsig_sym _ZL16stbi__stdio_skipPvi
	.addrsig_sym _ZL15stbi__stdio_eofPv
	.addrsig_sym _ZL16stbi__idct_blockPhiPs
	.addrsig_sym _ZL22stbi__YCbCr_to_RGB_rowPhPKhS1_S1_ii
	.addrsig_sym _ZL23stbi__resample_row_hv_2PhS_S_ii
	.addrsig_sym _ZL14resample_row_1PhS_S_ii
	.addrsig_sym _ZL22stbi__resample_row_v_2PhS_S_ii
	.addrsig_sym _ZL22stbi__resample_row_h_2PhS_S_ii
	.addrsig_sym _ZL26stbi__resample_row_genericPhS_S_ii
	.addrsig_sym _GLOBAL__sub_I_main.cc
	.addrsig_sym _Unwind_Resume
	.addrsig_sym _ZStL8__ioinit
	.addrsig_sym __dso_handle
	.addrsig_sym _ZSt4cerr
	.addrsig_sym _ZSt4cout
	.addrsig_sym _ZTVN10__cxxabiv120__si_class_type_infoE
	.addrsig_sym _ZTS9translate
	.addrsig_sym _ZTVN10__cxxabiv117__class_type_infoE
	.addrsig_sym _ZTS8hittable
	.addrsig_sym _ZTI8hittable
	.addrsig_sym _ZTI9translate
	.addrsig_sym _ZTS8rotate_y
	.addrsig_sym _ZTI8rotate_y
	.addrsig_sym _ZTS7xy_rect
	.addrsig_sym _ZTI7xy_rect
	.addrsig_sym _ZTS7xz_rect
	.addrsig_sym _ZTI7xz_rect
	.addrsig_sym _ZTS7yz_rect
	.addrsig_sym _ZTI7yz_rect
	.addrsig_sym _ZTS13hittable_list
	.addrsig_sym _ZTI13hittable_list
	.addrsig_sym _ZTS3box
	.addrsig_sym _ZTI3box
	.addrsig_sym _ZTS8bvh_node
	.addrsig_sym _ZTI8bvh_node
	.addrsig_sym _ZTS15constant_medium
	.addrsig_sym _ZTI15constant_medium
	.addrsig_sym _ZTS13moving_sphere
	.addrsig_sym _ZTI13moving_sphere
	.addrsig_sym _ZTS6sphere
	.addrsig_sym _ZTI6sphere
	.addrsig_sym _ZZL20stbi__parse_png_fileP9stbi__pngiiE13invalid_chunk
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI7xy_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt19_Sp_make_shared_tag
	.addrsig_sym _ZZNSt19_Sp_make_shared_tag5_S_tiEvE5__tag
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI7xz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI7yz_rectSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI8bvh_nodeSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI15checker_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS15checker_texture
	.addrsig_sym _ZTS7texture
	.addrsig_sym _ZTI7texture
	.addrsig_sym _ZTI15checker_texture
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI11solid_colorSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS11solid_color
	.addrsig_sym _ZTI11solid_color
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI10lambertianSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS10lambertian
	.addrsig_sym _ZTS8material
	.addrsig_sym _ZTI8material
	.addrsig_sym _ZTI10lambertian
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI6sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI13moving_sphereSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI5metalSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS5metal
	.addrsig_sym _ZTI5metal
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI10dielectricSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS10dielectric
	.addrsig_sym _ZTI10dielectric
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI13noise_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS13noise_texture
	.addrsig_sym _ZTI13noise_texture
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI13image_textureSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS13image_texture
	.addrsig_sym _ZTI13image_texture
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI13diffuse_lightSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS13diffuse_light
	.addrsig_sym _ZTI13diffuse_light
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI3boxSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI8rotate_ySaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI9translateSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI15constant_mediumSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTSSt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTISt23_Sp_counted_ptr_inplaceI9isotropicSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
	.addrsig_sym _ZTS9isotropic
	.addrsig_sym _ZTI9isotropic
	.addrsig_sym .L_MergedGlobals
	.addrsig_sym .L_MergedGlobals.126
